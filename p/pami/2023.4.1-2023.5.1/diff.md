# Comparing `tmp/pami-2023.4.1.tar.gz` & `tmp/pami-2023.5.1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "pami-2023.4.1.tar", last modified: Thu Jun  1 12:58:36 2023, max compression
+gzip compressed data, was "pami-2023.5.1.tar", last modified: Tue Jun 20 07:29:48 2023, max compression
```

## Comparing `pami-2023.4.1.tar` & `pami-2023.5.1.tar`

### file list

```diff
@@ -1,401 +1,390 @@
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.389941 pami-2023.4.1/
--rw-r--r--   0 likhitha   (505) staff       (20)    35149 2022-05-26 01:58:44.000000 pami-2023.4.1/LICENSE
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.260545 pami-2023.4.1/PAMI/
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.261036 pami-2023.4.1/PAMI/AssociationRules/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/AssociationRules/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.263624 pami-2023.4.1/PAMI/AssociationRules/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)     7975 2023-05-24 23:17:26.000000 pami-2023.4.1/PAMI/AssociationRules/basic/ARWithConfidence.py
--rw-r--r--   0 likhitha   (505) staff       (20)     8038 2023-04-05 02:08:01.000000 pami-2023.4.1/PAMI/AssociationRules/basic/ARWithLeverage.py
--rw-r--r--   0 likhitha   (505) staff       (20)     8085 2023-04-05 02:08:01.000000 pami-2023.4.1/PAMI/AssociationRules/basic/ARWithLift.py
--rw-r--r--   0 likhitha   (505) staff       (20)    12384 2022-10-26 03:59:07.000000 pami-2023.4.1/PAMI/AssociationRules/basic/RuleMiner.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-20 06:22:26.000000 pami-2023.4.1/PAMI/AssociationRules/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6547 2023-04-05 02:08:01.000000 pami-2023.4.1/PAMI/AssociationRules/basic/abstract.py
--rw-r--r--   0 likhitha   (505) staff       (20)      139 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.263957 pami-2023.4.1/PAMI/correlatedPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/correlatedPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.266733 pami-2023.4.1/PAMI/correlatedPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    25349 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/correlatedPattern/basic/CPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)    26794 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/correlatedPattern/basic/CPGrowthPlus.py
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/correlatedPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6055 2022-09-13 03:26:07.000000 pami-2023.4.1/PAMI/correlatedPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.267035 pami-2023.4.1/PAMI/coveragePatterns/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-06-30 05:11:02.000000 pami-2023.4.1/PAMI/coveragePatterns/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.268983 pami-2023.4.1/PAMI/coveragePatterns/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    13144 2022-09-20 06:22:26.000000 pami-2023.4.1/PAMI/coveragePatterns/basic/CMine.py
--rw-r--r--   0 likhitha   (505) staff       (20)    16908 2022-09-20 06:22:26.000000 pami-2023.4.1/PAMI/coveragePatterns/basic/CPPG.py
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-09-12 09:34:32.000000 pami-2023.4.1/PAMI/coveragePatterns/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6938 2022-09-13 03:26:08.000000 pami-2023.4.1/PAMI/coveragePatterns/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.271385 pami-2023.4.1/PAMI/extras/
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.273986 pami-2023.4.1/PAMI/extras/DF2DB/
--rw-r--r--   0 likhitha   (505) staff       (20)     2517 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/extras/DF2DB/DF2DB.py
--rw-r--r--   0 likhitha   (505) staff       (20)     2418 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/extras/DF2DB/DF2DBPlus.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/extras/DF2DB/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     1629 2022-09-13 03:26:08.000000 pami-2023.4.1/PAMI/extras/DF2DB/createTDB.py
--rw-r--r--   0 likhitha   (505) staff       (20)    10145 2023-06-01 12:40:35.000000 pami-2023.4.1/PAMI/extras/DF2DB/denseDF2DB.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5354 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/extras/DF2DB/denseDF2DBPlus.py
--rw-r--r--   0 likhitha   (505) staff       (20)     3822 2023-01-08 10:45:15.000000 pami-2023.4.1/PAMI/extras/DF2DB/sparseDF2DB.py
--rw-r--r--   0 likhitha   (505) staff       (20)     3503 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/extras/DF2DB/sparseDF2DBPlus.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/extras/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.274692 pami-2023.4.1/PAMI/extras/calculateMISValues/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-07-01 00:24:16.000000 pami-2023.4.1/PAMI/extras/calculateMISValues/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     3741 2022-09-13 03:26:07.000000 pami-2023.4.1/PAMI/extras/calculateMISValues/usingBeta.py
--rw-r--r--   0 likhitha   (505) staff       (20)     3794 2022-09-13 03:26:07.000000 pami-2023.4.1/PAMI/extras/calculateMISValues/usingSD.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.284331 pami-2023.4.1/PAMI/extras/dbStats/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/extras/dbStats/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)    13000 2022-09-10 01:57:05.000000 pami-2023.4.1/PAMI/extras/dbStats/fuzzyDatabaseStats.py
--rw-r--r--   0 likhitha   (505) staff       (20)    14610 2022-09-10 01:57:05.000000 pami-2023.4.1/PAMI/extras/dbStats/temporalDatabaseStats.py
--rw-r--r--   0 likhitha   (505) staff       (20)    10399 2022-09-10 01:57:05.000000 pami-2023.4.1/PAMI/extras/dbStats/transactionalDatabaseStats.py
--rw-r--r--   0 likhitha   (505) staff       (20)    13209 2023-01-08 10:45:15.000000 pami-2023.4.1/PAMI/extras/dbStats/uncertainTemporalDatabaseStats.py
--rw-r--r--   0 likhitha   (505) staff       (20)     9982 2022-10-03 04:23:08.000000 pami-2023.4.1/PAMI/extras/dbStats/uncertainTransactionalDatabaseStats.py
--rw-r--r--   0 likhitha   (505) staff       (20)    12903 2022-09-10 01:57:05.000000 pami-2023.4.1/PAMI/extras/dbStats/utilityDatabaseStats.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.285616 pami-2023.4.1/PAMI/extras/fuzzyTransformation/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2023-03-01 01:58:12.000000 pami-2023.4.1/PAMI/extras/fuzzyTransformation/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5195 2023-03-01 01:58:42.000000 pami-2023.4.1/PAMI/extras/fuzzyTransformation/abstract.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5925 2023-03-01 02:03:56.000000 pami-2023.4.1/PAMI/extras/fuzzyTransformation/temporalToFuzzy.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5919 2023-03-21 05:53:43.000000 pami-2023.4.1/PAMI/extras/fuzzyTransformation/transactionalToFuzzyTimeSeries.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5803 2023-03-21 05:53:43.000000 pami-2023.4.1/PAMI/extras/fuzzyTransformation/utilityToFuzzy.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.286693 pami-2023.4.1/PAMI/extras/generateDatabase/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/extras/generateDatabase/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     2877 2022-06-10 00:52:41.000000 pami-2023.4.1/PAMI/extras/generateDatabase/generateSpatioTemporalDatabase.py
--rw-r--r--   0 likhitha   (505) staff       (20)     7069 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/extras/generateDatabase/generateTemporalDatabase.py
--rw-r--r--   0 likhitha   (505) staff       (20)     3399 2022-05-30 08:10:33.000000 pami-2023.4.1/PAMI/extras/generateDatabase/generateTransactionalDatabase.py
--rw-r--r--   0 likhitha   (505) staff       (20)     3593 2022-06-20 05:11:46.000000 pami-2023.4.1/PAMI/extras/generateLatexGraphFile.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.288578 pami-2023.4.1/PAMI/extras/graph/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/extras/graph/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     1656 2022-06-24 01:22:27.000000 pami-2023.4.1/PAMI/extras/graph/dataFrameInToFigures.py
--rw-r--r--   0 likhitha   (505) staff       (20)     2954 2022-06-30 05:09:24.000000 pami-2023.4.1/PAMI/extras/graph/generateLatexFileFromDataFrame.py
--rw-r--r--   0 likhitha   (505) staff       (20)     1167 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/extras/graph/plotLineGraphFromDictionary.py
--rw-r--r--   0 likhitha   (505) staff       (20)     1753 2022-06-20 05:11:45.000000 pami-2023.4.1/PAMI/extras/graph/plotLineGraphsFromDataFrame.py
--rw-r--r--   0 likhitha   (505) staff       (20)     2203 2022-11-27 01:07:51.000000 pami-2023.4.1/PAMI/extras/graph/visualizePatterns.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.288934 pami-2023.4.1/PAMI/extras/image2Database/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-10 01:57:05.000000 pami-2023.4.1/PAMI/extras/image2Database/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.289221 pami-2023.4.1/PAMI/extras/imageProcessing/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-09-10 01:57:05.000000 pami-2023.4.1/PAMI/extras/imageProcessing/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     4582 2022-09-10 01:57:05.000000 pami-2023.4.1/PAMI/extras/imageProcessing/imagery2Databases.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.289634 pami-2023.4.1/PAMI/extras/neighbours/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/extras/neighbours/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     2834 2022-09-10 01:57:05.000000 pami-2023.4.1/PAMI/extras/neighbours/findNeighboursUsingEuclidean.py
--rw-r--r--   0 likhitha   (505) staff       (20)     3031 2022-07-28 04:00:44.000000 pami-2023.4.1/PAMI/extras/plotPointOnMap.py
--rw-r--r--   0 likhitha   (505) staff       (20)     3214 2022-07-28 04:00:44.000000 pami-2023.4.1/PAMI/extras/plotPointOnMap_dump.py
--rw-r--r--   0 likhitha   (505) staff       (20)     2178 2022-05-30 08:10:33.000000 pami-2023.4.1/PAMI/extras/scatterPlotSpatialPoints.py
--rw-r--r--   0 likhitha   (505) staff       (20)     1827 2022-09-13 03:26:07.000000 pami-2023.4.1/PAMI/extras/topKPatterns.py
--rw-r--r--   0 likhitha   (505) staff       (20)      473 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/extras/uncertaindb_convert.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.289816 pami-2023.4.1/PAMI/faultTolerantFrequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/faultTolerantFrequentPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.291501 pami-2023.4.1/PAMI/faultTolerantFrequentPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    15077 2023-04-05 02:08:01.000000 pami-2023.4.1/PAMI/faultTolerantFrequentPattern/basic/FTApriori.py
--rw-r--r--   0 likhitha   (505) staff       (20)    20676 2023-03-21 05:53:43.000000 pami-2023.4.1/PAMI/faultTolerantFrequentPattern/basic/FTFPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)    15543 2023-04-05 02:08:01.000000 pami-2023.4.1/PAMI/faultTolerantFrequentPattern/basic/VBFTMine.py
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-09-10 01:57:05.000000 pami-2023.4.1/PAMI/faultTolerantFrequentPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6691 2022-09-16 08:22:43.000000 pami-2023.4.1/PAMI/faultTolerantFrequentPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.292431 pami-2023.4.1/PAMI/faultTolerantFrequentPattern/maximal/
--rw-r--r--   0 likhitha   (505) staff       (20)     1173 2023-06-01 12:40:35.000000 pami-2023.4.1/PAMI/faultTolerantFrequentPattern/maximal/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6645 2022-09-22 03:52:49.000000 pami-2023.4.1/PAMI/faultTolerantFrequentPattern/maximal/abstract.py
--rw-r--r--   0 likhitha   (505) staff       (20)    11948 2022-09-22 04:41:50.000000 pami-2023.4.1/PAMI/faultTolerantFrequentPattern/maximal/maxFTP.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.292706 pami-2023.4.1/PAMI/frequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/frequentPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.295626 pami-2023.4.1/PAMI/frequentPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    13475 2022-09-13 07:44:04.000000 pami-2023.4.1/PAMI/frequentPattern/basic/Apriori.py
--rw-r--r--   0 likhitha   (505) staff       (20)    13441 2022-09-13 07:44:04.000000 pami-2023.4.1/PAMI/frequentPattern/basic/ECLAT.py
--rw-r--r--   0 likhitha   (505) staff       (20)    13555 2023-05-26 00:41:32.000000 pami-2023.4.1/PAMI/frequentPattern/basic/ECLATDiffset.py
--rw-r--r--   0 likhitha   (505) staff       (20)    12389 2022-09-13 07:44:04.000000 pami-2023.4.1/PAMI/frequentPattern/basic/ECLATbitset.py
--rw-r--r--   0 likhitha   (505) staff       (20)    20353 2022-09-22 03:48:55.000000 pami-2023.4.1/PAMI/frequentPattern/basic/FPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/frequentPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     7733 2022-09-13 03:26:07.000000 pami-2023.4.1/PAMI/frequentPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.296616 pami-2023.4.1/PAMI/frequentPattern/closed/
--rw-r--r--   0 likhitha   (505) staff       (20)    20234 2022-09-13 07:44:04.000000 pami-2023.4.1/PAMI/frequentPattern/closed/CHARM.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/frequentPattern/closed/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6445 2022-09-13 03:26:07.000000 pami-2023.4.1/PAMI/frequentPattern/closed/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.297581 pami-2023.4.1/PAMI/frequentPattern/cuda/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/frequentPattern/cuda/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5003 2022-09-12 05:08:17.000000 pami-2023.4.1/PAMI/frequentPattern/cuda/cudaAprioriGCT.py
--rw-r--r--   0 likhitha   (505) staff       (20)     7921 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/frequentPattern/cuda/cudaAprioriTID.py
--rw-r--r--   0 likhitha   (505) staff       (20)     4839 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/frequentPattern/cuda/cudaEclatGCT.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.298489 pami-2023.4.1/PAMI/frequentPattern/maximal/
--rw-r--r--   0 likhitha   (505) staff       (20)    25382 2023-02-07 05:06:18.000000 pami-2023.4.1/PAMI/frequentPattern/maximal/MaxFPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/frequentPattern/maximal/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6436 2022-10-26 03:59:07.000000 pami-2023.4.1/PAMI/frequentPattern/maximal/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.299962 pami-2023.4.1/PAMI/frequentPattern/pyspark/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/frequentPattern/pyspark/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5603 2022-09-13 03:26:08.000000 pami-2023.4.1/PAMI/frequentPattern/pyspark/abstract.py
--rw-r--r--   0 likhitha   (505) staff       (20)    12024 2022-09-13 07:46:37.000000 pami-2023.4.1/PAMI/frequentPattern/pyspark/parallelApriori.py
--rw-r--r--   0 likhitha   (505) staff       (20)    10490 2022-09-13 07:50:03.000000 pami-2023.4.1/PAMI/frequentPattern/pyspark/parallelECLAT.py
--rw-r--r--   0 likhitha   (505) staff       (20)    15608 2022-09-13 07:50:03.000000 pami-2023.4.1/PAMI/frequentPattern/pyspark/parallelFPGrowth.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.300902 pami-2023.4.1/PAMI/frequentPattern/topk/
--rw-r--r--   0 likhitha   (505) staff       (20)    15148 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/frequentPattern/topk/FAE.py
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/frequentPattern/topk/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     4575 2022-09-12 06:50:04.000000 pami-2023.4.1/PAMI/frequentPattern/topk/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.301215 pami-2023.4.1/PAMI/frequentSpatialPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/frequentSpatialPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.303363 pami-2023.4.1/PAMI/frequentSpatialPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    18316 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/frequentSpatialPattern/basic/FSPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)    17714 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/frequentSpatialPattern/basic/SpatialECLAT.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/frequentSpatialPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6680 2022-09-13 03:26:08.000000 pami-2023.4.1/PAMI/frequentSpatialPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.303821 pami-2023.4.1/PAMI/fuzzyCorrelatedPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/fuzzyCorrelatedPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.304595 pami-2023.4.1/PAMI/fuzzyCorrelatedPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    26118 2022-09-20 06:22:26.000000 pami-2023.4.1/PAMI/fuzzyCorrelatedPattern/basic/FCPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/fuzzyCorrelatedPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6635 2022-09-13 08:04:20.000000 pami-2023.4.1/PAMI/fuzzyCorrelatedPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.304922 pami-2023.4.1/PAMI/fuzzyFrequentPatterns/
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/fuzzyFrequentPatterns/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.307146 pami-2023.4.1/PAMI/fuzzyFrequentPatterns/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    20926 2023-03-02 03:15:52.000000 pami-2023.4.1/PAMI/fuzzyFrequentPatterns/basic/FFIMiner.py
--rw-r--r--   0 likhitha   (505) staff       (20)    26037 2023-03-01 01:53:49.000000 pami-2023.4.1/PAMI/fuzzyFrequentPatterns/basic/FFIMiner_old.py
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/fuzzyFrequentPatterns/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6450 2023-03-01 02:51:05.000000 pami-2023.4.1/PAMI/fuzzyFrequentPatterns/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.307613 pami-2023.4.1/PAMI/fuzzyFrequentSpatialPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/fuzzyFrequentSpatialPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.310931 pami-2023.4.1/PAMI/fuzzyFrequentSpatialPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    24222 2023-03-02 04:09:41.000000 pami-2023.4.1/PAMI/fuzzyFrequentSpatialPattern/basic/FFSPMiner.py
--rw-r--r--   0 likhitha   (505) staff       (20)    26791 2023-03-01 01:58:20.000000 pami-2023.4.1/PAMI/fuzzyFrequentSpatialPattern/basic/FFSPMiner_old.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/fuzzyFrequentSpatialPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6580 2022-09-13 03:26:08.000000 pami-2023.4.1/PAMI/fuzzyFrequentSpatialPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.311239 pami-2023.4.1/PAMI/fuzzyPeriodicFrequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/fuzzyPeriodicFrequentPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.315636 pami-2023.4.1/PAMI/fuzzyPeriodicFrequentPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    22613 2023-03-21 05:53:43.000000 pami-2023.4.1/PAMI/fuzzyPeriodicFrequentPattern/basic/FPFPMiner.py
--rw-r--r--   0 likhitha   (505) staff       (20)    25345 2023-03-01 01:58:20.000000 pami-2023.4.1/PAMI/fuzzyPeriodicFrequentPattern/basic/FPFPMiner_old.py
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/fuzzyPeriodicFrequentPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6668 2022-09-13 03:26:08.000000 pami-2023.4.1/PAMI/fuzzyPeriodicFrequentPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.319127 pami-2023.4.1/PAMI/fuzzySpatialPeriodicFrequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/fuzzySpatialPeriodicFrequentPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.320342 pami-2023.4.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    27112 2023-03-21 05:53:43.000000 pami-2023.4.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/FGPFPMiner.py
--rw-r--r--   0 likhitha   (505) staff       (20)    32216 2023-03-01 01:58:20.000000 pami-2023.4.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/FGPFPMiner_old.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-16 08:22:43.000000 pami-2023.4.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6618 2023-03-21 05:53:43.000000 pami-2023.4.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.321514 pami-2023.4.1/PAMI/geoReferencedFrequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)    27553 2023-06-01 12:40:35.000000 pami-2023.4.1/PAMI/geoReferencedFrequentPattern/GFPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2023-04-03 08:12:11.000000 pami-2023.4.1/PAMI/geoReferencedFrequentPattern/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5006 2023-06-01 12:40:35.000000 pami-2023.4.1/PAMI/geoReferencedFrequentPattern/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.321732 pami-2023.4.1/PAMI/geoReferencedPeriodicFrequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-09-10 01:57:05.000000 pami-2023.4.1/PAMI/geoReferencedPeriodicFrequentPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.322662 pami-2023.4.1/PAMI/geoReferencedPeriodicFrequentPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    18686 2023-05-26 00:41:32.000000 pami-2023.4.1/PAMI/geoReferencedPeriodicFrequentPattern/basic/GPFPMiner.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-12 13:22:01.000000 pami-2023.4.1/PAMI/geoReferencedPeriodicFrequentPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6774 2022-09-13 03:26:08.000000 pami-2023.4.1/PAMI/geoReferencedPeriodicFrequentPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.323425 pami-2023.4.1/PAMI/highUtilityFrequentPatterns/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/highUtilityFrequentPatterns/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.324624 pami-2023.4.1/PAMI/highUtilityFrequentPatterns/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    35252 2023-02-07 03:37:24.000000 pami-2023.4.1/PAMI/highUtilityFrequentPatterns/basic/HUFIM.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/highUtilityFrequentPatterns/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6081 2022-09-13 03:26:08.000000 pami-2023.4.1/PAMI/highUtilityFrequentPatterns/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.324948 pami-2023.4.1/PAMI/highUtilityFrequentSpatialPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/highUtilityFrequentSpatialPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.327036 pami-2023.4.1/PAMI/highUtilityFrequentSpatialPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    38373 2022-09-15 06:00:15.000000 pami-2023.4.1/PAMI/highUtilityFrequentSpatialPattern/basic/SHUFIM.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/highUtilityFrequentSpatialPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6181 2022-09-13 03:26:07.000000 pami-2023.4.1/PAMI/highUtilityFrequentSpatialPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.327408 pami-2023.4.1/PAMI/highUtilityPatterns/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/highUtilityPatterns/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.329445 pami-2023.4.1/PAMI/highUtilityPatterns/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    31875 2023-02-07 03:55:11.000000 pami-2023.4.1/PAMI/highUtilityPatterns/basic/EFIM.py
--rw-r--r--   0 likhitha   (505) staff       (20)    23450 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/highUtilityPatterns/basic/HMiner.py
--rw-r--r--   0 likhitha   (505) staff       (20)    25807 2023-02-07 03:54:20.000000 pami-2023.4.1/PAMI/highUtilityPatterns/basic/UPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/highUtilityPatterns/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5053 2022-09-13 03:26:07.000000 pami-2023.4.1/PAMI/highUtilityPatterns/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.337014 pami-2023.4.1/PAMI/highUtilitySpatialPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/highUtilitySpatialPattern/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6718 2022-09-13 03:26:07.000000 pami-2023.4.1/PAMI/highUtilitySpatialPattern/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.338319 pami-2023.4.1/PAMI/highUtilitySpatialPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    25729 2023-02-07 04:08:34.000000 pami-2023.4.1/PAMI/highUtilitySpatialPattern/basic/HDSHUIM.py
--rw-r--r--   0 likhitha   (505) staff       (20)    32747 2023-02-04 06:23:46.000000 pami-2023.4.1/PAMI/highUtilitySpatialPattern/basic/SHUIM.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/highUtilitySpatialPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5955 2022-09-13 03:26:06.000000 pami-2023.4.1/PAMI/highUtilitySpatialPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.339227 pami-2023.4.1/PAMI/highUtilitySpatialPattern/topk/
--rw-r--r--   0 likhitha   (505) staff       (20)    33511 2023-02-07 04:26:57.000000 pami-2023.4.1/PAMI/highUtilitySpatialPattern/topk/TKSHUIM.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/highUtilitySpatialPattern/topk/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6625 2023-02-07 04:28:07.000000 pami-2023.4.1/PAMI/highUtilitySpatialPattern/topk/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.339524 pami-2023.4.1/PAMI/localPeriodicPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/localPeriodicPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.340771 pami-2023.4.1/PAMI/localPeriodicPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    30377 2022-09-15 07:36:55.000000 pami-2023.4.1/PAMI/localPeriodicPattern/basic/LPPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)    19626 2022-09-15 07:36:55.000000 pami-2023.4.1/PAMI/localPeriodicPattern/basic/LPPMBreadth.py
--rw-r--r--   0 likhitha   (505) staff       (20)    18711 2022-09-15 07:36:55.000000 pami-2023.4.1/PAMI/localPeriodicPattern/basic/LPPMDepth.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/localPeriodicPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     8378 2022-09-15 07:26:35.000000 pami-2023.4.1/PAMI/localPeriodicPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.341055 pami-2023.4.1/PAMI/multipleMinimumSupportBasedFrequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-06-21 09:08:43.000000 pami-2023.4.1/PAMI/multipleMinimumSupportBasedFrequentPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.342475 pami-2023.4.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    22172 2023-03-21 05:53:43.000000 pami-2023.4.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/CFPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)    21275 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/CFPGrowthPlus.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-12 07:16:58.000000 pami-2023.4.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5913 2022-09-13 03:26:08.000000 pami-2023.4.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.342745 pami-2023.4.1/PAMI/partialPeriodicFrequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/partialPeriodicFrequentPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.343989 pami-2023.4.1/PAMI/partialPeriodicFrequentPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    25450 2022-10-12 03:45:33.000000 pami-2023.4.1/PAMI/partialPeriodicFrequentPattern/basic/GPFgrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)    19431 2022-10-12 03:52:53.000000 pami-2023.4.1/PAMI/partialPeriodicFrequentPattern/basic/PPF_DFS.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/partialPeriodicFrequentPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5392 2022-09-13 07:44:04.000000 pami-2023.4.1/PAMI/partialPeriodicFrequentPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.344426 pami-2023.4.1/PAMI/partialPeriodicPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.347156 pami-2023.4.1/PAMI/partialPeriodicPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    49814 2023-03-02 08:48:22.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/basic/GThreePGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)     4195 2022-09-13 03:26:07.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/basic/Gabstract.py
--rw-r--r--   0 likhitha   (505) staff       (20)    23287 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/basic/PPPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)    16901 2023-05-26 00:41:32.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/basic/PPP_ECLAT.py
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5572 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.348181 pami-2023.4.1/PAMI/partialPeriodicPattern/closed/
--rw-r--r--   0 likhitha   (505) staff       (20)    19695 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/closed/PPPClose.py
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/closed/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5595 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/closed/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.349263 pami-2023.4.1/PAMI/partialPeriodicPattern/maximal/
--rw-r--r--   0 likhitha   (505) staff       (20)    27900 2022-10-12 03:35:13.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/maximal/Max3PGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/maximal/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     4261 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/maximal/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.350288 pami-2023.4.1/PAMI/partialPeriodicPattern/timeSeries/
--rw-r--r--   0 likhitha   (505) staff       (20)    25314 2022-09-13 07:44:04.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/timeSeries/PPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-08-02 07:47:39.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/timeSeries/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     5550 2022-09-13 07:44:04.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/timeSeries/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.351329 pami-2023.4.1/PAMI/partialPeriodicPattern/topk/
--rw-r--r--   0 likhitha   (505) staff       (20)    16925 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/topk/Topk_PPPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/topk/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     7837 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/partialPeriodicPattern/topk/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.351644 pami-2023.4.1/PAMI/partialPeriodicSpatialPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-06-28 05:26:47.000000 pami-2023.4.1/PAMI/partialPeriodicSpatialPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.352555 pami-2023.4.1/PAMI/partialPeriodicSpatialPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    18201 2022-09-16 08:22:43.000000 pami-2023.4.1/PAMI/partialPeriodicSpatialPattern/basic/STEclat.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-16 08:22:43.000000 pami-2023.4.1/PAMI/partialPeriodicSpatialPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6165 2022-09-16 08:22:40.000000 pami-2023.4.1/PAMI/partialPeriodicSpatialPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.352871 pami-2023.4.1/PAMI/periodicCorrelatedPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/periodicCorrelatedPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.353844 pami-2023.4.1/PAMI/periodicCorrelatedPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    26674 2022-09-16 08:22:43.000000 pami-2023.4.1/PAMI/periodicCorrelatedPattern/basic/EPCPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-16 08:22:43.000000 pami-2023.4.1/PAMI/periodicCorrelatedPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6652 2022-09-16 08:22:40.000000 pami-2023.4.1/PAMI/periodicCorrelatedPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.354118 pami-2023.4.1/PAMI/periodicFrequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.356172 pami-2023.4.1/PAMI/periodicFrequentPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    14838 2023-05-26 00:41:32.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/basic/PFECLAT.py
--rw-r--r--   0 likhitha   (505) staff       (20)    24398 2022-09-13 07:43:58.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/basic/PFPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)    24123 2022-09-13 07:43:58.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/basic/PFPGrowthPlus.py
--rw-r--r--   0 likhitha   (505) staff       (20)    15529 2022-09-13 07:43:58.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/basic/PFPMC.py
--rw-r--r--   0 likhitha   (505) staff       (20)    32465 2022-09-13 07:43:58.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/basic/PSGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)      726 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6525 2022-09-15 07:15:16.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.357204 pami-2023.4.1/PAMI/periodicFrequentPattern/closed/
--rw-r--r--   0 likhitha   (505) staff       (20)    19782 2022-09-13 07:43:58.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/closed/CPFPMiner.py
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/closed/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6538 2022-09-13 03:26:08.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/closed/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.357928 pami-2023.4.1/PAMI/periodicFrequentPattern/cuda/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2023-02-11 00:26:28.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/cuda/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)    16537 2023-02-11 00:26:28.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/cuda/gPFMinerBit.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.359064 pami-2023.4.1/PAMI/periodicFrequentPattern/maximal/
--rw-r--r--   0 likhitha   (505) staff       (20)    27844 2023-02-07 05:06:18.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/maximal/MaxPFGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/maximal/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     7873 2022-09-13 03:26:08.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/maximal/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.359338 pami-2023.4.1/PAMI/periodicFrequentPattern/topk/
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.360259 pami-2023.4.1/PAMI/periodicFrequentPattern/topk/TopkPFP/
--rw-r--r--   0 likhitha   (505) staff       (20)    17228 2023-02-07 01:47:35.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/topk/TopkPFP/TopkPFP.py
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2023-02-07 01:47:35.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/topk/TopkPFP/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6898 2023-02-07 01:47:35.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/topk/TopkPFP/abstract.py
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/topk/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.361335 pami-2023.4.1/PAMI/periodicFrequentPattern/topk/kPFPMiner/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2023-02-07 01:52:08.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/topk/kPFPMiner/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     4583 2023-02-07 01:49:30.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/topk/kPFPMiner/abstract.py
--rw-r--r--   0 likhitha   (505) staff       (20)    16401 2023-02-07 01:56:38.000000 pami-2023.4.1/PAMI/periodicFrequentPattern/topk/kPFPMiner/kPFPMiner.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.361736 pami-2023.4.1/PAMI/recurringPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/recurringPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.362916 pami-2023.4.1/PAMI/recurringPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    25551 2023-02-11 00:45:20.000000 pami-2023.4.1/PAMI/recurringPattern/basic/RPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/recurringPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6632 2022-09-13 07:44:04.000000 pami-2023.4.1/PAMI/recurringPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.363432 pami-2023.4.1/PAMI/relativeFrequentPatterns/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/relativeFrequentPatterns/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.365410 pami-2023.4.1/PAMI/relativeFrequentPatterns/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    25500 2022-09-20 08:51:48.000000 pami-2023.4.1/PAMI/relativeFrequentPatterns/basic/RSFPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/relativeFrequentPatterns/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     4261 2022-09-20 08:51:48.000000 pami-2023.4.1/PAMI/relativeFrequentPatterns/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.365869 pami-2023.4.1/PAMI/relativeHighUtilityPatterns/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/relativeHighUtilityPatterns/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.366849 pami-2023.4.1/PAMI/relativeHighUtilityPatterns/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    32789 2023-02-09 04:36:40.000000 pami-2023.4.1/PAMI/relativeHighUtilityPatterns/basic/RHUIM.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/relativeHighUtilityPatterns/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     7391 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/relativeHighUtilityPatterns/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.367252 pami-2023.4.1/PAMI/sequentialPatternMining/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/sequentialPatternMining/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.368744 pami-2023.4.1/PAMI/sequentialPatternMining/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    40559 2023-02-28 05:51:58.000000 pami-2023.4.1/PAMI/sequentialPatternMining/basic/SPADE.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-21 04:49:06.000000 pami-2023.4.1/PAMI/sequentialPatternMining/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6554 2023-01-08 10:45:15.000000 pami-2023.4.1/PAMI/sequentialPatternMining/basic/abstract.py
--rw-r--r--   0 likhitha   (505) staff       (20)    22030 2023-02-11 00:26:28.000000 pami-2023.4.1/PAMI/sequentialPatternMining/basic/prefixSpan.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.369520 pami-2023.4.1/PAMI/sequentialPatternMining/closed/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-21 04:50:02.000000 pami-2023.4.1/PAMI/sequentialPatternMining/closed/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6279 2022-09-13 03:26:07.000000 pami-2023.4.1/PAMI/sequentialPatternMining/closed/abstract.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-21 04:50:31.000000 pami-2023.4.1/PAMI/sequentialPatternMining/closed/bide.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.369621 pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.373000 pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    15381 2023-05-26 00:41:32.000000 pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/basic/SPPEclat.py
--rw-r--r--   0 likhitha   (505) staff       (20)    24073 2023-05-26 00:41:32.000000 pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/basic/SPPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)    17918 2022-09-13 03:26:06.000000 pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/basic/SPPGrowthDump.py
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-06-30 05:09:24.000000 pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     7258 2022-09-13 03:26:06.000000 pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.373884 pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/topK/
--rw-r--r--   0 likhitha   (505) staff       (20)    25615 2023-02-10 03:23:27.000000 pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/topK/TSPIN.py
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/topK/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     7177 2022-09-13 03:26:07.000000 pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/topK/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.374238 pami-2023.4.1/PAMI/uncertainFrequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/uncertainFrequentPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.377617 pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    24906 2022-09-13 07:44:04.000000 pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/CUFPTree.py
--rw-r--r--   0 likhitha   (505) staff       (20)    25115 2023-02-28 09:14:04.000000 pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/PUFGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)    17825 2022-09-13 03:26:05.000000 pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/TUFP.py
--rw-r--r--   0 likhitha   (505) staff       (20)    26168 2023-03-31 03:36:16.000000 pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/TubeP.py
--rw-r--r--   0 likhitha   (505) staff       (20)    26931 2023-03-31 03:36:16.000000 pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/TubeS.py
--rw-r--r--   0 likhitha   (505) staff       (20)    24582 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/UFGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)    18153 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/UVECLAT.py
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     4962 2022-09-13 07:44:04.000000 pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.377910 pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)      727 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.380190 pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    30266 2023-02-07 01:21:17.000000 pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/basic/UPFPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)    30696 2023-02-07 01:21:54.000000 pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/basic/UPFPGrowthPlus.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6551 2022-09-13 07:44:04.000000 pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/basic/abstract.py
--rw-r--r--   0 likhitha   (505) staff       (20)    30905 2022-10-03 07:07:51.000000 pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/basic/upfp.py
--rw-r--r--   0 likhitha   (505) staff       (20)    33359 2022-10-06 01:25:48.000000 pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/basic/upfpplus.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.380738 pami-2023.4.1/PAMI/uncertainProbablisticFrequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-27 07:43:30.000000 pami-2023.4.1/PAMI/uncertainProbablisticFrequentPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.380994 pami-2023.4.1/PAMI/uncertainProbablisticFrequentPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-27 07:43:44.000000 pami-2023.4.1/PAMI/uncertainProbablisticFrequentPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     4962 2022-09-27 07:44:21.000000 pami-2023.4.1/PAMI/uncertainProbablisticFrequentPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.381355 pami-2023.4.1/PAMI/weightedFrequentNeighbourhoodPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-06-28 05:36:22.000000 pami-2023.4.1/PAMI/weightedFrequentNeighbourhoodPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.382244 pami-2023.4.1/PAMI/weightedFrequentNeighbourhoodPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    26149 2023-02-06 08:15:48.000000 pami-2023.4.1/PAMI/weightedFrequentNeighbourhoodPattern/basic/SWFPGrowth.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/weightedFrequentNeighbourhoodPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6693 2023-02-06 08:50:12.000000 pami-2023.4.1/PAMI/weightedFrequentNeighbourhoodPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.382571 pami-2023.4.1/PAMI/weightedFrequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/weightedFrequentPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.383488 pami-2023.4.1/PAMI/weightedFrequentPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    23009 2022-09-20 06:22:27.000000 pami-2023.4.1/PAMI/weightedFrequentPattern/basic/WFIM.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/weightedFrequentPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     6737 2022-09-13 07:44:04.000000 pami-2023.4.1/PAMI/weightedFrequentPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.386093 pami-2023.4.1/PAMI/weightedFrequentRegularPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/weightedFrequentRegularPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.386885 pami-2023.4.1/PAMI/weightedFrequentRegularPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    26702 2023-02-10 03:46:01.000000 pami-2023.4.1/PAMI/weightedFrequentRegularPattern/basic/WFRIMiner.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/weightedFrequentRegularPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     7555 2022-09-13 07:44:04.000000 pami-2023.4.1/PAMI/weightedFrequentRegularPattern/basic/abstract.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.387191 pami-2023.4.1/PAMI/weightedUncertainFrequentPattern/
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2022-05-26 01:58:44.000000 pami-2023.4.1/PAMI/weightedUncertainFrequentPattern/__init__.py
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.388200 pami-2023.4.1/PAMI/weightedUncertainFrequentPattern/basic/
--rw-r--r--   0 likhitha   (505) staff       (20)    28437 2023-02-28 09:14:04.000000 pami-2023.4.1/PAMI/weightedUncertainFrequentPattern/basic/WUFIM.py
--rw-r--r--   0 likhitha   (505) staff       (20)        0 2022-09-13 07:44:03.000000 pami-2023.4.1/PAMI/weightedUncertainFrequentPattern/basic/__init__.py
--rw-r--r--   0 likhitha   (505) staff       (20)     4782 2023-02-10 23:22:45.000000 pami-2023.4.1/PAMI/weightedUncertainFrequentPattern/basic/abstract.py
--rw-r--r--   0 likhitha   (505) staff       (20)    34613 2023-06-01 12:58:36.389650 pami-2023.4.1/PKG-INFO
--rw-r--r--   0 likhitha   (505) staff       (20)    34029 2023-06-01 12:40:35.000000 pami-2023.4.1/README.md
-drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-01 12:58:36.389355 pami-2023.4.1/pami.egg-info/
--rw-r--r--   0 likhitha   (505) staff       (20)    34613 2023-06-01 12:58:36.000000 pami-2023.4.1/pami.egg-info/PKG-INFO
--rw-r--r--   0 likhitha   (505) staff       (20)    13726 2023-06-01 12:58:36.000000 pami-2023.4.1/pami.egg-info/SOURCES.txt
--rw-r--r--   0 likhitha   (505) staff       (20)        1 2023-06-01 12:58:36.000000 pami-2023.4.1/pami.egg-info/dependency_links.txt
--rw-r--r--   0 likhitha   (505) staff       (20)       75 2023-06-01 12:58:36.000000 pami-2023.4.1/pami.egg-info/requires.txt
--rw-r--r--   0 likhitha   (505) staff       (20)        5 2023-06-01 12:58:36.000000 pami-2023.4.1/pami.egg-info/top_level.txt
--rw-r--r--   0 likhitha   (505) staff       (20)       38 2023-06-01 12:58:36.390008 pami-2023.4.1/setup.cfg
--rw-r--r--   0 likhitha   (505) staff       (20)     1205 2023-06-01 12:56:05.000000 pami-2023.4.1/setup.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.046296 pami-2023.5.1/
+-rw-r--r--   0 likhitha   (505) staff       (20)    35149 2022-05-26 01:58:44.000000 pami-2023.5.1/LICENSE
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.920263 pami-2023.5.1/PAMI/
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.920842 pami-2023.5.1/PAMI/AssociationRules/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/AssociationRules/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.931237 pami-2023.5.1/PAMI/AssociationRules/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)     8001 2023-05-29 07:58:16.000000 pami-2023.5.1/PAMI/AssociationRules/basic/ARWithConfidence.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     8038 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/AssociationRules/basic/ARWithLeverage.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     8085 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/AssociationRules/basic/ARWithLift.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    12384 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/AssociationRules/basic/RuleMiner.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/AssociationRules/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6547 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/AssociationRules/basic/abstract.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)      139 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.931460 pami-2023.5.1/PAMI/correlatedPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/correlatedPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.934720 pami-2023.5.1/PAMI/correlatedPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    24412 2023-06-11 11:25:22.000000 pami-2023.5.1/PAMI/correlatedPattern/basic/CPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    25824 2023-06-10 21:46:38.000000 pami-2023.5.1/PAMI/correlatedPattern/basic/CPGrowthPlus.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/correlatedPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6055 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/correlatedPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.935102 pami-2023.5.1/PAMI/coveragePatterns/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/coveragePatterns/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.937867 pami-2023.5.1/PAMI/coveragePatterns/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    13995 2023-06-10 21:46:38.000000 pami-2023.5.1/PAMI/coveragePatterns/basic/CMine.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    16075 2023-06-10 21:46:38.000000 pami-2023.5.1/PAMI/coveragePatterns/basic/CPPG.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/coveragePatterns/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6938 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/coveragePatterns/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.946364 pami-2023.5.1/PAMI/extras/
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.948771 pami-2023.5.1/PAMI/extras/DF2DB/
+-rw-rw-r--   0 likhitha   (505) staff       (20)     2178 2023-05-30 02:42:12.000000 pami-2023.5.1/PAMI/extras/DF2DB/DF2DB.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     2243 2023-05-30 02:42:12.000000 pami-2023.5.1/PAMI/extras/DF2DB/DF2DBPlus.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/DF2DB/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     1607 2023-05-30 02:42:12.000000 pami-2023.5.1/PAMI/extras/DF2DB/createTDB.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     9942 2023-05-30 02:42:12.000000 pami-2023.5.1/PAMI/extras/DF2DB/denseDF2DB.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     4917 2023-05-30 02:42:12.000000 pami-2023.5.1/PAMI/extras/DF2DB/denseDF2DBPlus.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     3607 2023-05-30 02:42:12.000000 pami-2023.5.1/PAMI/extras/DF2DB/sparseDF2DB.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     3359 2023-05-30 02:42:12.000000 pami-2023.5.1/PAMI/extras/DF2DB/sparseDF2DBPlus.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.949258 pami-2023.5.1/PAMI/extras/calculateMISValues/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/calculateMISValues/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     3741 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/calculateMISValues/usingBeta.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     3794 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/calculateMISValues/usingSD.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.951441 pami-2023.5.1/PAMI/extras/dbStats/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/dbStats/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    13043 2023-05-30 02:42:12.000000 pami-2023.5.1/PAMI/extras/dbStats/fuzzyDatabaseStats.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    14661 2023-05-30 02:46:24.000000 pami-2023.5.1/PAMI/extras/dbStats/temporalDatabaseStats.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     9364 2023-05-30 02:42:12.000000 pami-2023.5.1/PAMI/extras/dbStats/transactionalDatabaseStats.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    13229 2023-05-30 02:42:12.000000 pami-2023.5.1/PAMI/extras/dbStats/uncertainTemporalDatabaseStats.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    10040 2023-05-30 02:47:08.000000 pami-2023.5.1/PAMI/extras/dbStats/uncertainTransactionalDatabaseStats.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    11775 2023-05-30 02:42:12.000000 pami-2023.5.1/PAMI/extras/dbStats/utilityDatabaseStats.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.952885 pami-2023.5.1/PAMI/extras/fuzzyTransformation/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/fuzzyTransformation/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5195 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/fuzzyTransformation/abstract.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5925 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/fuzzyTransformation/temporalToFuzzy.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5919 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/fuzzyTransformation/transactionalToFuzzyTimeSeries.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5803 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/fuzzyTransformation/utilityToFuzzy.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.953660 pami-2023.5.1/PAMI/extras/generateDatabase/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/generateDatabase/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     2877 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/generateDatabase/generateSpatioTemporalDatabase.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     7092 2023-05-31 04:57:18.000000 pami-2023.5.1/PAMI/extras/generateDatabase/generateTemporalDatabase.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     3444 2023-05-31 04:55:28.000000 pami-2023.5.1/PAMI/extras/generateDatabase/generateTransactionalDatabase.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     3593 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/generateLatexGraphFile.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.956822 pami-2023.5.1/PAMI/extras/graph/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/graph/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     1656 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/graph/dataFrameInToFigures.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     2954 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/graph/generateLatexFileFromDataFrame.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     1167 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/graph/plotLineGraphFromDictionary.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     1753 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/graph/plotLineGraphsFromDataFrame.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     2203 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/graph/visualizePatterns.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.956995 pami-2023.5.1/PAMI/extras/image2Database/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/image2Database/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.957307 pami-2023.5.1/PAMI/extras/imageProcessing/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/imageProcessing/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     4582 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/imageProcessing/imagery2Databases.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.957618 pami-2023.5.1/PAMI/extras/neighbours/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/neighbours/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     2834 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/neighbours/findNeighboursUsingEuclidean.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     3031 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/plotPointOnMap.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     3214 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/plotPointOnMap_dump.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     2178 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/scatterPlotSpatialPoints.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     1827 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/topKPatterns.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)      473 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/extras/uncertaindb_convert.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.958040 pami-2023.5.1/PAMI/faultTolerantFrequentPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/faultTolerantFrequentPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.960676 pami-2023.5.1/PAMI/faultTolerantFrequentPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    14656 2023-06-10 21:46:38.000000 pami-2023.5.1/PAMI/faultTolerantFrequentPattern/basic/FTApriori.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    21185 2023-06-10 21:48:34.000000 pami-2023.5.1/PAMI/faultTolerantFrequentPattern/basic/FTFPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    14992 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/faultTolerantFrequentPattern/basic/VBFTMine.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/faultTolerantFrequentPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6691 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/faultTolerantFrequentPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.961090 pami-2023.5.1/PAMI/frequentPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/frequentPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.968579 pami-2023.5.1/PAMI/frequentPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    13124 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/frequentPattern/basic/Apriori.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    12531 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/frequentPattern/basic/ECLAT.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    13188 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/frequentPattern/basic/ECLATDiffset.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    13480 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/frequentPattern/basic/ECLATbitset.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    20324 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/frequentPattern/basic/FPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/frequentPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     7733 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/frequentPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.969168 pami-2023.5.1/PAMI/frequentPattern/closed/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    19874 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/frequentPattern/closed/CHARM.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/frequentPattern/closed/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6445 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/frequentPattern/closed/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.969968 pami-2023.5.1/PAMI/frequentPattern/cuda/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/frequentPattern/cuda/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5744 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/frequentPattern/cuda/cudaAprioriGCT.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     8703 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/frequentPattern/cuda/cudaAprioriTID.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5582 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/frequentPattern/cuda/cudaEclatGCT.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.970668 pami-2023.5.1/PAMI/frequentPattern/maximal/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    25097 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/frequentPattern/maximal/MaxFPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/frequentPattern/maximal/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6436 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/frequentPattern/maximal/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.971678 pami-2023.5.1/PAMI/frequentPattern/pyspark/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/frequentPattern/pyspark/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5605 2023-05-30 02:18:50.000000 pami-2023.5.1/PAMI/frequentPattern/pyspark/abstract.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    13209 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/frequentPattern/pyspark/parallelApriori.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    11487 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/frequentPattern/pyspark/parallelECLAT.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    16147 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/frequentPattern/pyspark/parallelFPGrowth.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.972124 pami-2023.5.1/PAMI/frequentPattern/topk/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    14674 2023-06-10 22:08:34.000000 pami-2023.5.1/PAMI/frequentPattern/topk/FAE.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/frequentPattern/topk/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     4575 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/frequentPattern/topk/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.976188 pami-2023.5.1/PAMI/frequentSpatialPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/frequentSpatialPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.978033 pami-2023.5.1/PAMI/frequentSpatialPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    20041 2023-06-11 10:36:52.000000 pami-2023.5.1/PAMI/frequentSpatialPattern/basic/FSPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    19099 2023-06-11 10:36:52.000000 pami-2023.5.1/PAMI/frequentSpatialPattern/basic/SpatialECLAT.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/frequentSpatialPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6680 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/frequentSpatialPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.978188 pami-2023.5.1/PAMI/fuzzyCorrelatedPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzyCorrelatedPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.979130 pami-2023.5.1/PAMI/fuzzyCorrelatedPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    25239 2023-06-11 10:36:52.000000 pami-2023.5.1/PAMI/fuzzyCorrelatedPattern/basic/FCPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzyCorrelatedPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6635 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzyCorrelatedPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.979277 pami-2023.5.1/PAMI/fuzzyFrequentPatterns/
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzyFrequentPatterns/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.980247 pami-2023.5.1/PAMI/fuzzyFrequentPatterns/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    20750 2023-06-11 10:45:26.000000 pami-2023.5.1/PAMI/fuzzyFrequentPatterns/basic/FFIMiner.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    24624 2023-06-11 10:38:46.000000 pami-2023.5.1/PAMI/fuzzyFrequentPatterns/basic/FFIMiner_old.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzyFrequentPatterns/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6450 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzyFrequentPatterns/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.980396 pami-2023.5.1/PAMI/fuzzyFrequentSpatialPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzyFrequentSpatialPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.981732 pami-2023.5.1/PAMI/fuzzyFrequentSpatialPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    23992 2023-06-11 10:45:26.000000 pami-2023.5.1/PAMI/fuzzyFrequentSpatialPattern/basic/FFSPMiner.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    26791 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzyFrequentSpatialPattern/basic/FFSPMiner_old.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzyFrequentSpatialPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6580 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzyFrequentSpatialPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.982038 pami-2023.5.1/PAMI/fuzzyPeriodicFrequentPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzyPeriodicFrequentPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.983003 pami-2023.5.1/PAMI/fuzzyPeriodicFrequentPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    23521 2023-06-10 01:56:22.000000 pami-2023.5.1/PAMI/fuzzyPeriodicFrequentPattern/basic/FPFPMiner.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    25345 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzyPeriodicFrequentPattern/basic/FPFPMiner_old.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzyPeriodicFrequentPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6668 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzyPeriodicFrequentPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.983216 pami-2023.5.1/PAMI/fuzzySpatialPeriodicFrequentPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzySpatialPeriodicFrequentPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.984629 pami-2023.5.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    26817 2023-06-11 10:45:26.000000 pami-2023.5.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/FGPFPMiner.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    32216 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/FGPFPMiner_old.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6618 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.985526 pami-2023.5.1/PAMI/geoReferencedFrequentPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    28518 2023-06-11 10:45:26.000000 pami-2023.5.1/PAMI/geoReferencedFrequentPattern/GFPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/geoReferencedFrequentPattern/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5007 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/geoReferencedFrequentPattern/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.985724 pami-2023.5.1/PAMI/geoReferencedPeriodicFrequentPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/geoReferencedPeriodicFrequentPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.989745 pami-2023.5.1/PAMI/geoReferencedPeriodicFrequentPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    19950 2023-06-11 10:45:26.000000 pami-2023.5.1/PAMI/geoReferencedPeriodicFrequentPattern/basic/GPFPMiner.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/geoReferencedPeriodicFrequentPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6774 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/geoReferencedPeriodicFrequentPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.989955 pami-2023.5.1/PAMI/highUtilityFrequentPatterns/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilityFrequentPatterns/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.991582 pami-2023.5.1/PAMI/highUtilityFrequentPatterns/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    35401 2023-06-11 10:45:26.000000 pami-2023.5.1/PAMI/highUtilityFrequentPatterns/basic/HUFIM.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilityFrequentPatterns/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6081 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilityFrequentPatterns/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.991746 pami-2023.5.1/PAMI/highUtilityFrequentSpatialPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilityFrequentSpatialPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.993436 pami-2023.5.1/PAMI/highUtilityFrequentSpatialPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    39910 2023-06-11 10:45:26.000000 pami-2023.5.1/PAMI/highUtilityFrequentSpatialPattern/basic/SHUFIM.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilityFrequentSpatialPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6181 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilityFrequentSpatialPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.993734 pami-2023.5.1/PAMI/highUtilityPatterns/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilityPatterns/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.995366 pami-2023.5.1/PAMI/highUtilityPatterns/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    32747 2023-06-11 10:49:44.000000 pami-2023.5.1/PAMI/highUtilityPatterns/basic/EFIM.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    24847 2023-06-11 10:49:44.000000 pami-2023.5.1/PAMI/highUtilityPatterns/basic/HMiner.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    26567 2023-06-11 10:51:32.000000 pami-2023.5.1/PAMI/highUtilityPatterns/basic/UPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilityPatterns/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5053 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilityPatterns/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.995876 pami-2023.5.1/PAMI/highUtilitySpatialPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilitySpatialPattern/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6718 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilitySpatialPattern/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.996836 pami-2023.5.1/PAMI/highUtilitySpatialPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    27632 2023-06-11 10:51:32.000000 pami-2023.5.1/PAMI/highUtilitySpatialPattern/basic/HDSHUIM.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    34623 2023-06-11 10:53:12.000000 pami-2023.5.1/PAMI/highUtilitySpatialPattern/basic/SHUIM.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilitySpatialPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5955 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilitySpatialPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.997809 pami-2023.5.1/PAMI/highUtilitySpatialPattern/topk/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    35216 2023-06-11 10:53:12.000000 pami-2023.5.1/PAMI/highUtilitySpatialPattern/topk/TKSHUIM.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilitySpatialPattern/topk/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6625 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/highUtilitySpatialPattern/topk/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:47.997994 pami-2023.5.1/PAMI/localPeriodicPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/localPeriodicPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.004956 pami-2023.5.1/PAMI/localPeriodicPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    32664 2023-06-11 10:55:48.000000 pami-2023.5.1/PAMI/localPeriodicPattern/basic/LPPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    21999 2023-06-11 10:55:48.000000 pami-2023.5.1/PAMI/localPeriodicPattern/basic/LPPMBreadth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    21120 2023-06-11 10:55:48.000000 pami-2023.5.1/PAMI/localPeriodicPattern/basic/LPPMDepth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/localPeriodicPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     8378 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/localPeriodicPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.005227 pami-2023.5.1/PAMI/multipleMinimumSupportBasedFrequentPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/multipleMinimumSupportBasedFrequentPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.006542 pami-2023.5.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    23034 2023-06-11 10:58:52.000000 pami-2023.5.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/CFPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    22318 2023-06-11 10:58:52.000000 pami-2023.5.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/CFPGrowthPlus.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5913 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.006704 pami-2023.5.1/PAMI/partialPeriodicFrequentPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicFrequentPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.007734 pami-2023.5.1/PAMI/partialPeriodicFrequentPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    27316 2023-06-11 10:58:52.000000 pami-2023.5.1/PAMI/partialPeriodicFrequentPattern/basic/GPFgrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    21102 2023-06-11 10:58:52.000000 pami-2023.5.1/PAMI/partialPeriodicFrequentPattern/basic/PPF_DFS.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicFrequentPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5392 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicFrequentPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.007907 pami-2023.5.1/PAMI/partialPeriodicPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.009539 pami-2023.5.1/PAMI/partialPeriodicPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    50844 2023-06-11 11:03:52.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/basic/GThreePGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     4195 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/basic/Gabstract.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    24330 2023-06-11 11:03:52.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/basic/PPPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    17878 2023-06-11 11:03:52.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/basic/PPP_ECLAT.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5572 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.010128 pami-2023.5.1/PAMI/partialPeriodicPattern/closed/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    21069 2023-06-11 11:03:52.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/closed/PPPClose.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/closed/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5595 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/closed/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.010937 pami-2023.5.1/PAMI/partialPeriodicPattern/maximal/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    28482 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/maximal/Max3PGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/maximal/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     4261 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/maximal/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.011630 pami-2023.5.1/PAMI/partialPeriodicPattern/timeSeries/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    26058 2023-06-11 11:25:04.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/timeSeries/PPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/timeSeries/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     5550 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/timeSeries/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.012207 pami-2023.5.1/PAMI/partialPeriodicPattern/topk/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/topk/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     7837 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/topk/abstract.py
+-rw-r--r--   0 likhitha   (505) staff       (20)    17705 2023-06-16 10:18:07.000000 pami-2023.5.1/PAMI/partialPeriodicPattern/topk/k3PMiner.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.012744 pami-2023.5.1/PAMI/partialPeriodicSpatialPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicSpatialPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.013689 pami-2023.5.1/PAMI/partialPeriodicSpatialPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    19876 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/partialPeriodicSpatialPattern/basic/STEclat.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicSpatialPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6165 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/partialPeriodicSpatialPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.013975 pami-2023.5.1/PAMI/periodicCorrelatedPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicCorrelatedPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.014887 pami-2023.5.1/PAMI/periodicCorrelatedPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    27518 2023-06-11 11:25:04.000000 pami-2023.5.1/PAMI/periodicCorrelatedPattern/basic/EPCPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicCorrelatedPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6652 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicCorrelatedPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.015074 pami-2023.5.1/PAMI/periodicFrequentPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.017991 pami-2023.5.1/PAMI/periodicFrequentPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    15591 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/basic/PFECLAT.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    25146 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/basic/PFPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    24942 2023-06-11 11:25:04.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/basic/PFPGrowthPlus.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    16311 2023-06-11 11:25:04.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/basic/PFPMC.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    33244 2023-06-11 11:25:04.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/basic/PSGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)      726 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6525 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.018935 pami-2023.5.1/PAMI/periodicFrequentPattern/closed/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    21540 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/closed/CPFPMiner.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/closed/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6538 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/closed/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.019460 pami-2023.5.1/PAMI/periodicFrequentPattern/cuda/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/cuda/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    17618 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/cuda/gPFMinerBit.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.020534 pami-2023.5.1/PAMI/periodicFrequentPattern/maximal/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    28740 2023-06-11 11:25:04.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/maximal/MaxPFGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/maximal/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     7873 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/maximal/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.020845 pami-2023.5.1/PAMI/periodicFrequentPattern/topk/
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.021826 pami-2023.5.1/PAMI/periodicFrequentPattern/topk/TopkPFP/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    18066 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/topk/TopkPFP/TopkPFP.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/topk/TopkPFP/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6898 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/topk/TopkPFP/abstract.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/topk/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.022675 pami-2023.5.1/PAMI/periodicFrequentPattern/topk/kPFPMiner/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/topk/kPFPMiner/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     4583 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/topk/kPFPMiner/abstract.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    17235 2023-06-11 11:25:04.000000 pami-2023.5.1/PAMI/periodicFrequentPattern/topk/kPFPMiner/kPFPMiner.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.023210 pami-2023.5.1/PAMI/recurringPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/recurringPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.024500 pami-2023.5.1/PAMI/recurringPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    26300 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/recurringPattern/basic/RPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/recurringPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6632 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/recurringPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.024709 pami-2023.5.1/PAMI/relativeFrequentPatterns/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/relativeFrequentPatterns/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.025570 pami-2023.5.1/PAMI/relativeFrequentPatterns/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    26260 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/relativeFrequentPatterns/basic/RSFPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/relativeFrequentPatterns/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     4261 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/relativeFrequentPatterns/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.025755 pami-2023.5.1/PAMI/relativeHighUtilityPatterns/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/relativeHighUtilityPatterns/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.027810 pami-2023.5.1/PAMI/relativeHighUtilityPatterns/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    33573 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/relativeHighUtilityPatterns/basic/RHUIM.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/relativeHighUtilityPatterns/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     7391 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/relativeHighUtilityPatterns/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.028159 pami-2023.5.1/PAMI/sequentialPatternMining/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/sequentialPatternMining/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.029217 pami-2023.5.1/PAMI/sequentialPatternMining/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    41062 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/sequentialPatternMining/basic/SPADE.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/sequentialPatternMining/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6554 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/sequentialPatternMining/basic/abstract.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    22592 2023-06-11 11:25:04.000000 pami-2023.5.1/PAMI/sequentialPatternMining/basic/prefixSpan.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.029850 pami-2023.5.1/PAMI/sequentialPatternMining/closed/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/sequentialPatternMining/closed/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6279 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/sequentialPatternMining/closed/abstract.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/sequentialPatternMining/closed/bide.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.029969 pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.033474 pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    16341 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/basic/SPPEclat.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    25169 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/basic/SPPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    17918 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/basic/SPPGrowthDump.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     7258 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.034218 pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/topK/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    26386 2023-06-11 11:25:04.000000 pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/topK/TSPIN.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/topK/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     7177 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/topK/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.034415 pami-2023.5.1/PAMI/uncertainFrequentPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/uncertainFrequentPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.038724 pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    25974 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/CUFPTree.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    26009 2023-06-11 11:25:04.000000 pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/PUFGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    18710 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/TUFP.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    27060 2023-06-11 11:25:04.000000 pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/TubeP.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    27823 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/TubeS.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    25507 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/UFGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    19046 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/UVECLAT.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     4962 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.039005 pami-2023.5.1/PAMI/uncertainPeriodicFrequentPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)      727 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/uncertainPeriodicFrequentPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.040408 pami-2023.5.1/PAMI/uncertainPeriodicFrequentPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    31127 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/uncertainPeriodicFrequentPattern/basic/UPFPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)    31329 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/uncertainPeriodicFrequentPattern/basic/UPFPGrowthPlus.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/uncertainPeriodicFrequentPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6551 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/uncertainPeriodicFrequentPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.040587 pami-2023.5.1/PAMI/weightedFrequentNeighbourhoodPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/weightedFrequentNeighbourhoodPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.041630 pami-2023.5.1/PAMI/weightedFrequentNeighbourhoodPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    27481 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/weightedFrequentNeighbourhoodPattern/basic/SWFPGrowth.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/weightedFrequentNeighbourhoodPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6693 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/weightedFrequentNeighbourhoodPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.041819 pami-2023.5.1/PAMI/weightedFrequentPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/weightedFrequentPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.042749 pami-2023.5.1/PAMI/weightedFrequentPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    23852 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/weightedFrequentPattern/basic/WFIM.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/weightedFrequentPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     6737 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/weightedFrequentPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.042929 pami-2023.5.1/PAMI/weightedFrequentRegularPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/weightedFrequentRegularPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.043376 pami-2023.5.1/PAMI/weightedFrequentRegularPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    27228 2023-06-11 11:25:06.000000 pami-2023.5.1/PAMI/weightedFrequentRegularPattern/basic/WFRIMiner.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/weightedFrequentRegularPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     7555 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/weightedFrequentRegularPattern/basic/abstract.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.043532 pami-2023.5.1/PAMI/weightedUncertainFrequentPattern/
+-rw-rw-r--   0 likhitha   (505) staff       (20)        1 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/weightedUncertainFrequentPattern/__init__.py
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.044615 pami-2023.5.1/PAMI/weightedUncertainFrequentPattern/basic/
+-rw-rw-r--   0 likhitha   (505) staff       (20)    29070 2023-06-11 11:25:04.000000 pami-2023.5.1/PAMI/weightedUncertainFrequentPattern/basic/WUFIM.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)        0 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/weightedUncertainFrequentPattern/basic/__init__.py
+-rw-rw-r--   0 likhitha   (505) staff       (20)     4782 2023-05-05 14:19:32.000000 pami-2023.5.1/PAMI/weightedUncertainFrequentPattern/basic/abstract.py
+-rw-r--r--   0 likhitha   (505) staff       (20)    34708 2023-06-20 07:29:48.045957 pami-2023.5.1/PKG-INFO
+-rw-r--r--   0 likhitha   (505) staff       (20)    34124 2023-06-20 07:27:40.000000 pami-2023.5.1/README.md
+drwxr-xr-x   0 likhitha   (505) staff       (20)        0 2023-06-20 07:29:48.045538 pami-2023.5.1/pami.egg-info/
+-rw-r--r--   0 likhitha   (505) staff       (20)    34708 2023-06-20 07:29:47.000000 pami-2023.5.1/pami.egg-info/PKG-INFO
+-rw-r--r--   0 likhitha   (505) staff       (20)    13278 2023-06-20 07:29:47.000000 pami-2023.5.1/pami.egg-info/SOURCES.txt
+-rw-r--r--   0 likhitha   (505) staff       (20)        1 2023-06-20 07:29:47.000000 pami-2023.5.1/pami.egg-info/dependency_links.txt
+-rw-r--r--   0 likhitha   (505) staff       (20)       75 2023-06-20 07:29:47.000000 pami-2023.5.1/pami.egg-info/requires.txt
+-rw-r--r--   0 likhitha   (505) staff       (20)        5 2023-06-20 07:29:47.000000 pami-2023.5.1/pami.egg-info/top_level.txt
+-rw-r--r--   0 likhitha   (505) staff       (20)       38 2023-06-20 07:29:48.046393 pami-2023.5.1/setup.cfg
+-rw-r--r--   0 likhitha   (505) staff       (20)     1205 2023-06-20 07:28:11.000000 pami-2023.5.1/setup.py
```

### Comparing `pami-2023.4.1/LICENSE` & `pami-2023.5.1/LICENSE`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/AssociationRules/basic/ARWithConfidence.py` & `pami-2023.5.1/PAMI/AssociationRules/basic/ARWithConfidence.py`

 * *Files 0% similar despite different names*

```diff
@@ -46,23 +46,25 @@
             for j in range(i + 1, len(self._singleItems)):
                 self._generaeWithConfidence(self._singleItems[i], self._singleItems[j])
             self._generation(prefix, suffix)
 
 
 class ARWithConfidence:
     """
-    temporalDatabaseStats is class to get stats of database.
+        temporalDatabaseStats is class to get stats of database.
+        
         Attributes:
         ----------
         frequentPattern : list or dict
             list
         measure: condition to calculate the strength of rule
             str
         threshold: condition to satisfy
             int
+            
         Methods:
         -------
         startMine()
     """
 
     def __init__(self, iFile, threshold, sep):
         """
```

### Comparing `pami-2023.4.1/PAMI/AssociationRules/basic/ARWithLeverage.py` & `pami-2023.5.1/PAMI/AssociationRules/basic/ARWithLeverage.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/AssociationRules/basic/ARWithLift.py` & `pami-2023.5.1/PAMI/AssociationRules/basic/ARWithLift.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/AssociationRules/basic/RuleMiner.py` & `pami-2023.5.1/PAMI/AssociationRules/basic/RuleMiner.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/AssociationRules/basic/abstract.py` & `pami-2023.5.1/PAMI/AssociationRules/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/correlatedPattern/__init__.py` & `pami-2023.5.1/PAMI/correlatedPattern/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/correlatedPattern/basic/CPGrowth.py` & `pami-2023.5.1/PAMI/correlatedPattern/basic/CPGrowth.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,37 +1,62 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# CPGrowth is one of the fundamental algorithm to discover correlated frequent patterns in a transactional database.
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-#      Copyright (C)  2021 Rage Uday Kiran
-
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#
+#             from PAMI.correlatedSpatialPattern.basic import CSPGrowth as alg
+#
+#             obj = alg.CSPGrowth(iFile, frequentPatternsFile, measure, threshold)
+#
+#             obj.startMine()
+#
+#             Rules = obj.getPatterns()
+#
+#             print("Total number of  Patterns:", len(Patterns))
+#
+#             obj.savePatterns(oFile)
+#
+#             Df = obj.getPatternsAsDataFrame()
+#
+#             memUSS = obj.getMemoryUSS()
+#
+#             print("Total Memory in USS:", memUSS)
+#
+#             memRSS = obj.getMemoryRSS()
+#
+#             print("Total Memory in RSS", memRSS)
+#
+#             run = obj.getRuntime()
+#
+#             print("Total ExecutionTime in seconds:", run)
+
+
+
 
 
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 from PAMI.correlatedPattern.basic import abstract as _ab
 
 class _Node:
     """
     A class used to represent the node of frequentPatternTree
 
 
@@ -207,28 +232,33 @@
                 else:
                     child.counter += pathCount
                     current = child
 
 
 class CPGrowth(_ab._correlatedPatterns):
     """
-        CPGrowth is one of the fundamental algorithm to discover correlated frequent patterns in a transactional database.
-        it is based on traditional FPGrowth Algorithm,This algorithm uses breadth-first search technique to find the
-        correlated Frequent patterns in transactional database.
+    :Description: CPGrowth is one of the fundamental algorithm to discover correlated frequent patterns in a transactional database. It is based on traditional Fpgrowth Algorithm,This algorithm uses breadth-first search technique to find the correlated Frequent patterns in transactional database.
+
+    :Reference: Lee, Y.K., Kim, W.Y., Cao, D., Han, J. (2003). CoMine: efficient mining of correlated patterns. In ICDM (pp. 581584).
+    :param  iFile: str :
+                   Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  minSup: int or float or str :
+                   The user can specify minSup either in count or proportion of database size. If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+    :param minAllConf: str : Name of Neighbourhood file name
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
+
+
+
+
+
+    :Attributes:
 
-    Reference :
-    ----------
-        Lee, Y.K., Kim, W.Y., Cao, D., Han, J. (2003). CoMine: efficient mining of correlated patterns. In ICDM (pp. 581584).
-    
-    Attributes :
-    ----------
-        iFile : file
-            Name of the Input file to mine complete set of frequent patterns
-        oFile : file
-            Name of the output file to store complete set of frequent patterns
         memoryUSS : float
             To store the total amount of USS memory consumed by the program
         memoryRSS : float
             To store the total amount of RSS memory consumed by the program
         startTime:float
             To record the start time of the mining process
         endTime:float
@@ -250,87 +280,58 @@
         finalPatterns : dict
             it represents to store the patterns
         itemSetBuffer : list
             it represents the store the items in mining
         maxPatternLength : int
            it represents the constraint for pattern length
 
-    Methods :
-    -------
-        startMine()
-            Mining process will start from here
-        getPatterns()
-            Complete set of patterns will be retrieved with this function
-        save(oFile)
-            Complete set of frequent patterns will be loaded in to a output file
-        getPatternsAsDataFrame()
-            Complete set of frequent patterns will be loaded in to a dataframe
-        getMemoryUSS()
-            Total amount of USS memory consumed by the mining process will be retrieved from this function
-        getMemoryRSS()
-            Total amount of RSS memory consumed by the mining process will be retrieved from this function
-        getRuntime()
-            Total amount of runtime taken by the mining process will be retrieved from this function
-        creatingItemSets(fileName)
-            Scans the dataset or dataframes and stores in list format
-        saveAllCombination(tempBuffer,s,position,prefix,prefixLength)
-            Forms all the combinations between prefix and tempBuffer lists with support(s)
-        frequentPatternGrowthGenerate(frequentPatternTree,prefix,port)
-            Mining the frequent patterns by forming conditional frequentPatternTrees to particular prefix item.
-            mapSupport represents the 1-length items with their respective support
-        creatingItemSets(iFileName)
-            Method to Storing the complete transactions of the database file in a database variable
-        saveItemSet(prefix, prefixLength, support)
-            To save the frequent patterns mined form frequentPatternTree
 
-    Executing the code on terminal :
-    ------------------------------
-        Format:
-                python3 CPGrowth.py <inputFile> <outputFile> <minSup> <minAllConf> <sep>
-        Examples:
-                python3 CPGrowth.py inp.txt output.txt 4.0 0.3   (minSup will be considered in percentage of database transactions)
+    **Methods to execute code on terminal**
+    ----------------------------------------
 
-                python3 CPGrowth.py  patterns.txt 4  0.3   (minSup will be considered in support count or frequency)
-                                                                (it will consider '\t' as separator)
+            Format:
+                      >>> python3 CSPGrowth.py <inputFile> <outputFile> <neighbourFile> <minSup> <minAllConf> <sep>
+            Example:
+                      >>>  python3 CSPGrowth.py sampleTDB.txt output.txt sampleN.txt 0.25 0.2
 
-                python3 CPGrowth.py sampleDB.txt patterns.txt 0.23 0.2  ,
-                                                                (it will consider ',' as separator)
+                     .. note:: minSup will be considered in percentage of database transactions
 
-    Sample run of the importing code :
-    ---------------------------------
+    **Importing this algorithm into a python program**
+    --------------------------------------------------------------------------------
+    .. code-block:: python
 
-        from PAMI.correlatedPattern.basic import CPGrowth as alg
+            from PAMI.correlatedSpatialPattern.basic import CSPGrowth as alg
 
-        obj = alg.CPGrowth(iFile, minSup, minAllConf)
+            obj = alg.CSPGrowth(iFile, frequentPatternsFile, measure, threshold)
 
-        obj.startMine()
+            obj.startMine()
 
-        correlatedPatterns = obj.getPatterns()
+            Rules = obj.getPatterns()
 
-        print("Total number of correlated frequent Patterns:", len(correlatedPatterns))
+            print("Total number of  Patterns:", len(Patterns))
 
-        obj.save(oFile)
+            obj.savePatterns(oFile)
 
-        Df = obj.getPatternInDf()
+            Df = obj.getPatternsAsDataFrame()
 
-        memUSS = obj.getMemoryUSS()
+            memUSS = obj.getMemoryUSS()
 
-        print("Total Memory in USS:", memUSS)
+            print("Total Memory in USS:", memUSS)
 
-        memRSS = obj.getMemoryRSS()
+            memRSS = obj.getMemoryRSS()
 
-        print("Total Memory in RSS", memRSS)
+            print("Total Memory in RSS", memRSS)
 
-        run = obj.getRuntime()
+            run = obj.getRuntime()
 
-        print("Total ExecutionTime in seconds:", run)
+            print("Total ExecutionTime in seconds:", run)
 
-    Credits:
-    --------
-        The complete program was written by B.Sai Chitra  under the supervision of Professor Rage Uday Kiran.
+    **Credits:**
+    ----------------------------------------
+             The complete program was written by B.Sai Chitra under the supervision of Professor Rage Uday Kiran.
 
         """
 
     _startTime = float()
     _endTime = float()
     _minSup = float()
     _finalPatterns = {}
```

### Comparing `pami-2023.4.1/PAMI/correlatedPattern/basic/CPGrowthPlus.py` & `pami-2023.5.1/PAMI/relativeFrequentPatterns/basic/RSFPGrowth.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,104 +1,123 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     from PAMI.frequentPatternUsingOtherMeasures import RSFPGrowth as alg
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-#      Copyright (C)  2021 Rage Uday Kiran
-
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
+#     obj = alg.RSFPGrowth(iFile, minSup, __minRatio)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getmemoryUSS()
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     print("Total Memory in USS:", memUSS)
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
 
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
 
-from PAMI.correlatedPattern.basic import abstract as _ab
+"""
 
+from PAMI.relativeFrequentPatterns.basic import abstract as _ab
 
 
 class _Node:
     """
-        A class used to represent the node of frequentPatternTree
+        A class used to represent the node of frequentPatterntree
 
-    Attributes :
+    Attributes:
     ----------
         itemId: int
             storing item of a node
         counter: int
             To maintain the support of node
         parent: node
             To maintain the parent of every node
         child: list
             To maintain the children of node
         nodeLink : node
             Points to the node with same itemId
 
-    Methods :
+    Methods:
     -------
 
         getChild(itemName)
-            returns the node with same itemName from frequentPatternTree
+            returns the node with same itemName from frequentPatterntree
     """
 
     def __init__(self):
         self.itemId = -1
         self.counter = 1
         self.parent = None
         self.child = []
         self.nodeLink = None
 
     def getChild(self, itemName):
-        """
-        Retrieving the child from the tree
+        """ Retrieving the child from the tree
 
             :param itemName: name of the child
             :type itemName: list
             :return: returns the node with same itemName from frequentPatternTree
-            :rtype: list
+            :rtype: None or Node
 
         """
         for i in self.child:
             if i.itemId == itemName:
                 return i
         return None
 
 
 class _Tree:
     """
         A class used to represent the frequentPatternGrowth tree structure
 
-    Attributes :
+    Attributes:
     ----------
         headerList : list
             storing the list of items in tree sorted in ascending of their supports
         mapItemNodes : dictionary
             storing the nodes with same item name
         mapItemLastNodes : dictionary
             representing the map that indicates the last node for each item
         root : Node
             representing the root Node in a tree
 
-    Methods :
+    Methods:
     -------
         createHeaderList(items,minSup)
             takes items only which are greater than minSup and sort the items in ascending order
         addTransaction(transaction)
             creating transaction as a branch in frequentPatternTree
         fixNodeLinks(item,newNode)
             To create the link for nodes with same item
@@ -111,16 +130,15 @@
     def __init__(self):
         self.headerList = []
         self.mapItemNodes = {}
         self.mapItemLastNodes = {}
         self.root = _Node()
 
     def addTransaction(self, transaction):
-        """
-        Adding a transaction into a tree
+        """adding transaction into tree
 
         :param transaction: it represents the one transactions in database
         :type transaction: list
         """
 
         # This method taken a transaction as input and returns the tree
         current = self.root
@@ -134,16 +152,15 @@
                 self.fixNodeLinks(i, newNode)
                 current = newNode
             else:
                 child.counter += 1
                 current = child
 
     def fixNodeLinks(self, item, newNode):
-        """
-        Fixing node link for the newNode that inserted into frequentPatternTree
+        """Fixing node link for the newNode that inserted into frequentPatternTree
 
         :param item: it represents the item of newNode
         :type item: int
         :param newNode: it represents the newNode that inserted in frequentPatternTree
         :type newNode: Node
 
         """
@@ -151,115 +168,106 @@
             lastNode = self.mapItemLastNodes[item]
             lastNode.nodeLink = newNode
         self.mapItemLastNodes[item] = newNode
         if item not in self.mapItemNodes.keys():
             self.mapItemNodes[item] = newNode
 
     def printTree(self, root):
-        """
-
-        Print the details of Node in frequentPatternTree
+        """Print the details of Node in frequentPatternTree
 
         :param root: it represents the Node in frequentPatternTree
         :type root: Node
 
         """
 
         # this method is used print the details of tree
         if not root.child:
             return
         else:
             for i in root.child:
                 print(i.itemId, i.counter, i.parent.itemId)
                 self.printTree(i)
 
-    def createHeaderList(self, mapSupport, minSup):
-        """
-
-        To create the headerList
+    def createHeaderList(self, __mapSupport, minSup):
+        """To create the headerList
 
-        :param mapSupport: it represents the items with their supports
-        :type mapSupport: dictionary
+        :param __mapSupport: it represents the items with their supports
+        :type __mapSupport: dictionary
         :param minSup: it represents the minSup
         :param minSup: float
-
         """
         # the frequentPatternTree always maintains the header table to start the mining from leaf nodes
         t1 = []
-        for x, y in mapSupport.items():
+        for x, y in __mapSupport.items():
             if y >= minSup:
                 t1.append(x)
-        itemSetBuffer = [k for k, v in sorted(mapSupport.items(), key=lambda x: x[1], reverse=True)]
-        self.headerList = [i for i in t1 if i in itemSetBuffer]
+        __itemSetBuffer = [k for k, v in sorted(__mapSupport.items(), key=lambda x: x[1], reverse=True)]
+        self.headerList = [i for i in t1 if i in __itemSetBuffer]
 
-    def addPrefixPath(self, prefix, mapSupportBeta, minSup):
-        """
-
-        To construct the conditional tree with prefix paths of a node in frequentPatternTree
+    def addPrefixPath(self, prefix, __mapSupportBeta, minSup):
+        """To construct the conditional tree with prefix paths of a node in frequentPatternTree
 
         :param prefix: it represents the prefix items of a Node
         :type prefix: list
-        :param mapSupportBeta: it represents the items with their supports
-        :param mapSupportBeta: dictionary
+        :param __mapSupportBeta: it represents the items with their supports
+        :param __mapSupportBeta: dictionary
         :param minSup: to check the item meets with minSup
         :param minSup: float
-
         """
         # this method is used to add prefix paths in conditional trees of frequentPatternTree
         pathCount = prefix[0].counter
         current = self.root
         prefix.reverse()
         for i in range(0, len(prefix) - 1):
             pathItem = prefix[i]
-            if mapSupportBeta.get(pathItem.itemId) >= minSup:
+            if __mapSupportBeta.get(pathItem.itemId) >= minSup:
                 child = current.getChild(pathItem.itemId)
                 if not child:
                     newNode = _Node()
                     newNode.itemId = pathItem.itemId
                     newNode.parent = current
                     newNode.counter = pathCount
                     current.child.append(newNode)
                     current = newNode
                     self.fixNodeLinks(pathItem.itemId, newNode)
                 else:
                     child.counter += pathCount
                     current = child
 
 
-class CPGrowthPlus(_ab._correlatedPatterns):
-    """ 
-         CPGrowthPlus is one of the efficient algorithm to discover Correlated frequent patterns in a transactional database.
-         Using Item Support Intervals technique which is generating correlated patterns of higher order by combining only with items that
-         have support within specified interval.
-
-    Reference :
-    ---------
-        Uday Kiran R., Kitsuregawa M. (2012) Efficient Discovery of Correlated Patterns in Transactional Databases Using Items Support Intervals. 
-        In: Liddle S.W., Schewe KD., Tjoa A.M., Zhou X. (eds) Database and Expert Systems Applications. DEXA 2012. Lecture Notes in Computer Science, vol 7446. Springer, Berlin, Heidelberg. 
-        https://doi.org/10.1007/978-3-642-32600-4_18
-        
-    Attributes :
-    ----------
+class RSFPGrowth(_ab._frequentPatterns):
+    """
+    Description:
+    -------------
+
+        Algorithm to find all items with relative support from given dataset
+
+    Reference:
+    -----------
+        'Towards Efficient Discovery of Frequent Patterns with Relative Support' R. Uday Kiran and
+               Masaru Kitsuregawa, http://comad.in/comad2012/pdf/kiran.pdf
 
+    Attributes:
+    -------------
         iFile : file
             Name of the Input file to mine complete set of frequent patterns
         oFile : file
             Name of the output file to store complete set of frequent patterns
         memoryUSS : float
             To store the total amount of USS memory consumed by the program
         memoryRSS : float
             To store the total amount of RSS memory consumed by the program
         startTime:float
             To record the start time of the mining process
         endTime:float
             To record the completion time of the mining process
         minSup : float
             The user given minSup
-        minAllConf: float
-            The user given minimum all confidence Ratio (should be in range of 0 to 1) 
+        minRS : float
+            The user given minRS
         Database : list
             To store the transactions of a database in list
         mapSupport : Dictionary
             To maintain the information of item and their frequency
         lno : int
             it represents the total no of transactions
         tree : class
@@ -269,435 +277,433 @@
         finalPatterns : dict
             it represents to store the patterns
         itemSetBuffer : list
             it represents the store the items in mining
         maxPatternLength : int
            it represents the constraint for pattern length
 
-    Methods :
-    -------
+    Methods:
+    --------
         startMine()
             Mining process will start from here
-        getPatterns()
+        getFrequentPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
             Complete set of frequent patterns will be loaded in to a dataframe
-        getMemoryUSS()
+        getmemoryUSS()
             Total amount of USS memory consumed by the mining process will be retrieved from this function
         getMemoryRSS()
             Total amount of RSS memory consumed by the mining process will be retrieved from this function
         getRuntime()
             Total amount of runtime taken by the mining process will be retrieved from this function
+        check(line)
+            To check the delimiter used in the user input file
         creatingItemSets(fileName)
             Scans the dataset or dataframes and stores in list format
         frequentOneItem()
             Extracts the one-frequent patterns from transactions
         saveAllCombination(tempBuffer,s,position,prefix,prefixLength)
             Forms all the combinations between prefix and tempBuffer lists with support(s)
         saveItemSet(pattern,support)
             Stores all the frequent patterns with their respective support
         frequentPatternGrowthGenerate(frequentPatternTree,prefix,port)
             Mining the frequent patterns by forming conditional frequentPatternTrees to particular prefix item.
-            mapSupport represents the 1-length items with their respective support
-            
-    Executing the code on terminal:
-    -------
+            __mapSupport represents the 1-length items with their respective support
 
-        Format:
-        -------
-            python3 CPGrowthPlus.py <inputFile> <outputFile> <minSup> <minAllConf> <sep>
 
-        Examples:
-        ---------
-            python3 CPGrowthPlus.py sampleDB.txt patterns.txt 0.23 0.2  (minSup will be considered in percentage of database transactions)
-        
-            python3 CPGrowthPlus.py sampleDB.txt patterns.txt 3   0.2  (minSup will be considered in support count or frequency)
-                                                      (it will consider '\t' as separator)
-        
-            python3 CPGrowthPlus.py sampleDB.txt patterns.txt 0.23 0.2  ,
-                                                       (it will consider ',' as separator)
+    **Methods to execute code on terminal**
 
-    Sample run of the importing code:
-    ---------------------------------
+            Format:
+                      >>>  python3 RSFPGrowth.py <inputFile> <outputFile> <minSup> <__minRatio>
+            Example:
+                      >>>  python3 RSFPGrowth.py sampleDB.txt patterns.txt 0.23 0.2
 
-        from PAMI.correlatedPattern.basic import CPGrowthPlus as alg
+            .. note:: maxPer and minPS will be considered in percentage of database transactions
 
-        obj = alg.CPGrowthPlus(iFile, minSup,minAllConf)
 
-        obj.startMine()
+    **Importing this algorithm into a python program**
 
-        correlatedPatterns = obj.getPatterns()
+    .. code-block:: python
 
-        print("Total number of correlated frequent Patterns:", len(correlatedPatterns))
+            from PAMI.frequentPatternUsingOtherMeasures import RSFPGrowth as alg
 
-        obj.save(oFile)
+            obj = alg.RSFPGrowth(iFile, minSup, __minRatio)
 
-        Df = obj.getPatternInDf()
+            obj.startMine()
 
-        memUSS = obj.getMemoryUSS()
+            frequentPatterns = obj.getPatterns()
 
-        print("Total Memory in USS:", memUSS)
+            print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-        memRSS = obj.getMemoryRSS()
+            obj.savePatterns(oFile)
 
-        print("Total Memory in RSS", memRSS)
+            Df = obj.getPatternsAsDataFrame()
 
-        run = obj.getRuntime()
+            memUSS = obj.getmemoryUSS()
 
-        print("Total ExecutionTime in seconds:", run)
+            print("Total Memory in USS:", memUSS)
 
-    Credits:
-    --------
-        The complete program was written by B.Sai Chitra  under the supervision of Professor Rage Uday Kiran.
+            memRSS = obj.getMemoryRSS()
+
+            print("Total Memory in RSS", memRSS)
+
+            run = obj.getRuntime()
+
+            print("Total ExecutionTime in seconds:", run)
+
+    **Credits:**
+
+             The complete program was written by   Sai Chitra.B   under the supervision of Professor Rage Uday Kiran.
 
         """
 
-    _startTime = float()
-    _endTime = float()
+    __startTime = float()
+    __endTime = float()
     _minSup = str()
-    _finalPatterns = {}
+    _minRS = float()
+    __finalPatterns = {}
     _iFile = " "
     _oFile = " "
-    _minAllConf = 0.0
-    _memoryUSS = float()
-    _memoryRSS = float()
-    _Database = []
-    _mapSupport = {}
-    _lno = 0
-    _tree = str()
-    _itemSetBuffer = None
-    _fpNodeTempBuffer = []
-    _itemSetCount = 0
-    _maxPatternLength = 1000
-    _sep = "\t"
-
-    def __init__(self, iFile, minSup, minAllConf, sep="\t"):
-        super().__init__(iFile, minSup, minAllConf, sep)
+    _sep = " "
+    __memoryUSS = float()
+    __memoryRSS = float()
+    __Database = []
+    __mapSupport = {}
+    __lno = 0
+    __tree = _Tree()
+    __itemSetBuffer = None
+    __fpNodeTempBuffer = []
+    __itemSetCount = 0
+    __maxPatternLength = 1000
+
+    def __init__(self, iFile, __minSup, __minRS, sep='\t'):
+        super().__init__(iFile, __minSup, __minRS, sep)
+        self.__finalPatterns = {}
 
-    def _creatingItemSets(self):
+    def __creatingItemSets(self):
         """
-            Storing the complete transactions of the database/input file in a database variable
+            Storing the complete transactions of the __Database/input file in a __Database variable
 
 
             """
-        self._Database = []
+        self.__Database = []
         if isinstance(self._iFile, _ab._pd.DataFrame):
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
-                self._Database = self._iFile['Transactions'].tolist()
+                self.__Database = self._iFile['Transactions'].tolist()
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
-                    self._Database.append(temp)
+                    self.__Database.append(temp)
             else:
                 try:
                     with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
                             line.strip()
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
-                            self._Database.append(temp)
+                            self.__Database.append(temp)
                 except IOError:
                     print("File Not Found")
                     quit()
 
-    def _frequentOneItem(self):
-        """
-        Generating One frequent items sets
+    def __frequentOneItem(self):
+        """Generating One frequent items sets
 
         """
-        self._mapSupport = {}
-        for i in self._Database:
+        self.__mapSupport = {}
+        for i in self.__Database:
             for j in i:
-                if j not in self._mapSupport:
-                    self._mapSupport[j] = 1
+                if j not in self.__mapSupport:
+                    self.__mapSupport[j] = 1
                 else:
-                    self._mapSupport[j] += 1
+                    self.__mapSupport[j] += 1
 
-    def _saveItemSet(self, prefix, prefixLength, support, ratio):
-        """
-        To save the frequent patterns mined form frequentPatternTree
+    def __saveItemSet(self, prefix, prefixLength, support, ratio):
+        """To save the frequent patterns mined form frequentPatternTree
 
         :param prefix: the frequent pattern
         :type prefix: list
         :param prefixLength: the length of a frequent pattern
         :type prefixLength: int
         :param support: the support of a pattern
         :type support:  int
         """
 
         sample = []
         for i in range(prefixLength):
             sample.append(prefix[i])
-        self._itemSetCount += 1
-        self._finalPatterns[tuple(sample)] = [support, ratio]
+        self.__itemSetCount += 1
+        self.__finalPatterns[tuple(sample)] = str(support) + " : " + str(ratio)
 
-    def _saveAllCombinations(self, tempBuffer, s, position, prefix, prefixLength):
-        """
-        Generating all the combinations for items in single branch in frequentPatternTree
+    def __saveAllCombinations(self, tempBuffer, s, position, prefix, prefixLength):
+        """Generating all the combinations for items in single branch in frequentPatternTree
 
         :param tempBuffer: items in a list
         :type tempBuffer: list
         :param s: support at leaf node of a branch
         :param position: the length of a tempBuffer
         :type position: int
         :param prefix: it represents the list of leaf node
         :type prefix: list
         :param prefixLength: the length of prefix
         :type prefixLength: int
-        
+
         """
         max1 = 1 << position
         for i in range(1, max1):
             newPrefixLength = prefixLength
             for j in range(position):
                 isSet = i & (1 << j)
                 if isSet > 0:
                     prefix.insert(newPrefixLength, tempBuffer[j].itemId)
                     newPrefixLength += 1
-            ratio = s/self._mapSupport[self._getMaxItem(prefix, newPrefixLength)]
-            if ratio >= self._minAllConf:
-                self._saveItemSet(prefix, newPrefixLength, s, ratio)
+            ratio = s / self.__mapSupport[self.__getMinItem(prefix, newPrefixLength)]
+            if ratio >= self._minRS:
+                self.__saveItemSet(prefix, newPrefixLength, s, ratio)
 
-    def _frequentPatternGrowthGenerate(self, frequentPatternTree, prefix, prefixLength, mapSupport, minConf):
-        """
-        Mining the fp tree
+    def __frequentPatternGrowthGenerate(self, frequentPatternTree, prefix, prefixLength, __mapSupport, minConf):
+        """Mining the fp tree
 
         :param frequentPatternTree: it represents the frequentPatternTree
         :type frequentPatternTree: class Tree
         :param prefix: it represents a empty list and store the patterns that are mined
         :type prefix: list
         :param param prefixLength: the length of prefix
         :type prefixLength: int
-        :param mapSupport : it represents the support of item
-        :type mapSupport : dictionary
+        :param __mapSupport : it represents the support of item
+        :type __mapSupport : dictionary
         """
         singlePath = True
         position = 0
         s = 0
         if len(frequentPatternTree.root.child) > 1:
             singlePath = False
         else:
             currentNode = frequentPatternTree.root.child[0]
             while True:
                 if len(currentNode.child) > 1:
                     singlePath = False
                     break
-                self._fpNodeTempBuffer.insert(position, currentNode)
+                self.__fpNodeTempBuffer.insert(position, currentNode)
                 s = currentNode.counter
                 position += 1
                 if len(currentNode.child) == 0:
                     break
                 currentNode = currentNode.child[0]
         if singlePath is True:
-            self._saveAllCombinations(self._fpNodeTempBuffer, s, position, prefix, prefixLength)
+            self.__saveAllCombinations(self.__fpNodeTempBuffer, s, position, prefix, prefixLength)
         else:
             for i in reversed(frequentPatternTree.headerList):
                 item = i
-                support = mapSupport[i]
-                low = max(int(_ab._math.floor(mapSupport[i]*self._minAllConf)), self._minSup)
-                high = max(int(_ab._math.floor(mapSupport[i]/minConf)), self._minSup)
-                betaSupport = support              
+                support = __mapSupport[i]
+                CminSup = max(self._minSup, support * self._minRS)
+                betaSupport = support
                 prefix.insert(prefixLength, item)
-                max1 = self._getMaxItem(prefix, prefixLength)
-                if self._mapSupport[max1] < self._mapSupport[item]:
+                max1 = self.__getMinItem(prefix, prefixLength)
+                if self.__mapSupport[max1] > self.__mapSupport[item]:
                     max1 = item
-                ratio = support / self._mapSupport[max1]
-                if ratio >= self._minAllConf:
-                    self._saveItemSet(prefix, prefixLength + 1, betaSupport, ratio)
-                if prefixLength + 1 < self._maxPatternLength:
+                ratio = support / self.__mapSupport[max1]
+                if ratio >= self._minRS:
+                    self.__saveItemSet(prefix, prefixLength + 1, betaSupport, ratio)
+                if prefixLength + 1 < self.__maxPatternLength:
                     prefixPaths = []
                     path = frequentPatternTree.mapItemNodes.get(item)
-                    mapSupportBeta = {}
+                    __mapSupportBeta = {}
                     while path is not None:
                         if path.parent.itemId != -1:
                             prefixPath = [path]
                             pathCount = path.counter
                             parent1 = path.parent
-                            if mapSupport.get(parent1.itemId) >= low and mapSupport.get(parent1.itemId) <= high:
+                            if __mapSupport.get(parent1.itemId) >= CminSup:
                                 while parent1.itemId != -1:
-                                    allconf = int(support/max(mapSupport.get(parent1.itemId), support))
-                                    if mapSupport.get(parent1.itemId) >= allconf:
+                                    mins = CminSup
+                                    if __mapSupport.get(parent1.itemId) >= mins:
                                         prefixPath.append(parent1)
-                                        if mapSupportBeta.get(parent1.itemId) is None:
-                                            mapSupportBeta[parent1.itemId] = pathCount
+                                        if __mapSupportBeta.get(parent1.itemId) is None:
+                                            __mapSupportBeta[parent1.itemId] = pathCount
                                         else:
-                                            mapSupportBeta[parent1.itemId] = mapSupportBeta[parent1.itemId] + pathCount
+                                            __mapSupportBeta[parent1.itemId] = __mapSupportBeta[
+                                                                                   parent1.itemId] + pathCount
                                         parent1 = parent1.parent
                                     else:
                                         break
                                 prefixPaths.append(prefixPath)
                         path = path.nodeLink
-                    treeBeta = _Tree()
+                    __treeBeta = _Tree()
                     for k in prefixPaths:
-                        treeBeta.addPrefixPath(k, mapSupportBeta, self._minSup)
-                    if len(treeBeta.root.child) > 0:
-                        treeBeta.createHeaderList(mapSupportBeta, self._minSup)
-                        self._frequentPatternGrowthGenerate(treeBeta, prefix, prefixLength + 1, mapSupportBeta, minConf)
+                        __treeBeta.addPrefixPath(k, __mapSupportBeta, self._minSup)
+                    if len(__treeBeta.root.child) > 0:
+                        __treeBeta.createHeaderList(__mapSupportBeta, self._minSup)
+                        self.__frequentPatternGrowthGenerate(__treeBeta, prefix, prefixLength + 1, __mapSupportBeta,
+                                                           minConf)
 
-    def _convert(self, value):
+    def __convert(self, value):
         """
-        to convert the type of user specified minSup value
-        :param value: user specified minSup value
+        to convert the type of user specified __minSup value
+        :param value: user specified __minSup value
         :return: converted type
         """
         if type(value) is int:
             value = int(value)
         if type(value) is float:
-            value = (len(self._Database) * value)
+            value = (len(self.__Database) * value)
         if type(value) is str:
             if '.' in value:
-                value = (len(self._Database) * value)
+                value = float(value)
+                value = (len(self.__Database) * value)
             else:
                 value = int(value)
         return value
 
     def startMine(self):
         """
-        main program to start the operation
-
+            main program to start the operation
         """
 
-        self._startTime = _ab._time.time()
+        self.__startTime = _ab._time.time()
         if self._iFile is None:
             raise Exception("Please enter the file path or file name:")
         if self._minSup is None:
             raise Exception("Please enter the Minimum Support")
-        self._creatingItemSets()
-        self._finalPatterns = {}
-        self._tree = _Tree()
-        self._minSup = self._convert(self._minSup)
-        self._frequentOneItem()
-        self._mapSupport = {k: v for k, v in self._mapSupport.items() if v >= self._minSup}
-        _itemSetBuffer = [k for k, v in sorted(self._mapSupport.items(), key=lambda x: x[1], reverse=True)]
-        for i in self._Database:
-            _transaction = []
+        self.__creatingItemSets()
+        self._minSup = self.__convert(self._minSup)
+        self._minRS = float(self._minRS)
+        self.__frequentOneItem()
+        self.__finalPatterns = {}
+        self.__mapSupport = {k: v for k, v in self.__mapSupport.items() if v >= self._minSup}
+        __itemSetBuffer = [k for k, v in sorted(self.__mapSupport.items(), key=lambda x: x[1], reverse=True)]
+        for i in self.__Database:
+            transaction = []
             for j in i:
-                if j in _itemSetBuffer:
-                    _transaction.append(j)
-            _transaction.sort(key=lambda val: self._mapSupport[val], reverse=True)
-            self._tree.addTransaction(_transaction)
-        self._tree.createHeaderList(self._mapSupport, self._minSup)
-        if len(self._tree.headerList) > 0:
-            self._itemSetBuffer = []
-            self._frequentPatternGrowthGenerate(self._tree, self._itemSetBuffer, 0, self._mapSupport, self._minAllConf)
-        print("Correlated Frequent patterns were generated successfully using CorrelatedPatternGrowth algorithm")
-        self._endTime = _ab._time.time()
+                if j in __itemSetBuffer:
+                    transaction.append(j)
+            transaction.sort(key=lambda val: self.__mapSupport[val], reverse=True)
+            self.__tree.addTransaction(transaction)
+        self.__tree.createHeaderList(self.__mapSupport, self._minSup)
+        if len(self.__tree.headerList) > 0:
+            self.__itemSetBuffer = []
+            self.__frequentPatternGrowthGenerate(self.__tree, self.__itemSetBuffer, 0, self.__mapSupport, self._minRS)
+        print("Relative support frequent patterns were generated successfully using RSFPGrowth algorithm")
+        self.__endTime = _ab._time.time()
         process = _ab._psutil.Process(_ab._os.getpid())
-        self._memoryRSS = float()
-        self._memoryUSS = float()
-        self._memoryUSS = process.memory_full_info().uss
-        self._memoryRSS = process.memory_info().rss
+        self.__memoryRSS = float()
+        self.__memoryUSS = float()
+        self.__memoryUSS = process.memory_full_info().uss
+        self.__memoryRSS = process.memory_info().rss
 
     def getMemoryUSS(self):
-        """
-        Total amount of USS memory consumed by the mining process will be retrieved from this function
+        """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
         :return: returning USS memory consumed by the mining process
         :rtype: float
         """
 
-        return self._memoryUSS
+        return self.__memoryUSS
 
     def getMemoryRSS(self):
-        """
-        Total amount of RSS memory consumed by the mining process will be retrieved from this function
+        """Total amount of RSS memory consumed by the mining process will be retrieved from this function
 
         :return: returning RSS memory consumed by the mining process
         :rtype: float
         """
 
-        return self._memoryRSS
+        return self.__memoryRSS
 
-    def _getMaxItem(self, prefix, prefixLength):
-        maxItem = prefix[0]
+    def __getMinItem(self, prefix, prefixLength):
+        """
+            returns the minItem from prefix
+        """
+        minItem = prefix[0]
         for i in range(prefixLength):
-            if self._mapSupport[maxItem] < self._mapSupport[prefix[i]]:
-                maxItem = prefix[i]
-        return maxItem
-    
+            if self.__mapSupport[minItem] > self.__mapSupport[prefix[i]]:
+                minItem = prefix[i]
+        return minItem
+
     def getRuntime(self):
-        """
-        Calculating the total amount of runtime taken by the mining process
+        """Calculating the total amount of runtime taken by the mining process
 
 
         :return: returning total amount of runtime taken by the mining process
         :rtype: float
         """
 
-        return self._endTime - self._startTime
+        return self.__endTime - self.__startTime
 
     def getPatternsAsDataFrame(self):
-        """
-        Storing final frequent patterns in a dataframe
+        """Storing final frequent patterns in a dataframe
 
         :return: returning frequent patterns in a dataframe
         :rtype: pd.DataFrame
         """
 
         dataframe = {}
         data = []
-        for a, b in self._finalPatterns.items():
-            pat = " "
+        for a, b in self.__finalPatterns.items():
+            pattern = str()
             for i in a:
-                pat += str(i) + " "
-            data.append([pat, b[0], b[1]])
-            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Confidence'])
+                pattern = pattern + i + " "
+            data.append([pattern, b])
+            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
         return dataframe
 
     def save(self, outFile):
-        """
-        Complete set of frequent patterns will be loaded in to a output file
+        """Complete set of frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
         :type outFile: file
         """
-        self._oFile = outFile
-        writer = open(self._oFile, 'w+')
-        for x, y in self._finalPatterns.items():
+        self.__oFile = outFile
+        writer = open(self.__oFile, 'w+')
+        for x, y in self.__finalPatterns.items():
             pattern = str()
             for i in x:
                 pattern = pattern + i + "\t"
-            s1 = str(pattern.strip()) + ":" + str(y[0]) + ":" + str(y[1])
+            s1 = pattern.strip() + ": " + str(y)
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
-        """
-        Function to send the set of frequent patterns after completion of the mining process
+        """ Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
         :rtype: dict
         """
-        return self._finalPatterns
+        res = dict()
+        for x, y in self.__finalPatterns.items():
+            pattern = str()
+            for i in x:
+                pattern = pattern + i + "\t"
+            s1 = str(y)
+            res[pattern] = s1
+        return res
 
     def printResults(self):
-        print("Total number of Correlated Patterns:", len(self.getPatterns()))
+        print("Total number of Relative Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
     if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
         if len(_ab._sys.argv) == 6:
-            _ap = CPGrowthPlus(_ab._sys.argv[1], _ab._sys.argv[3], float(_ab._sys.argv[4]), _ab._sys.argv[5])
+            _ap = RSFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
         if len(_ab._sys.argv) == 5:
-            _ap = CPGrowthPlus(_ab._sys.argv[1], _ab._sys.argv[3], float(_ab._sys.argv[4]))
+            _ap = RSFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
         _ap.startMine()
-        _correlatedPatterns = _ap.getPatterns()
-        print("Total number of Correlated-Frequent Patterns:", len(_ap.getPatterns()))
+        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
-        print("Total ExecutionTime in seconds:", _ap.getRuntime())
+        print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `pami-2023.4.1/PAMI/correlatedPattern/basic/__init__.py` & `pami-2023.5.1/PAMI/correlatedPattern/basic/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/correlatedPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/correlatedPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/coveragePatterns/basic/CMine.py` & `pami-2023.5.1/PAMI/coveragePatterns/basic/CMine.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,112 +1,149 @@
+# CMine algorithms aims to discover the coverage patterns in transactional databases.
+#
+# **Importing this algorithm into a python program**
+# ----------------------------------------------------
+#     .. code-block:: python
+#
+#                 from PAMI.coveragePattern.basic import CMine as alg
+#
+#                 obj = alg.CMine(iFile, minRF, minCS, maxOR, seperator)
+#
+#                 obj.startMine()
+#
+#                 coveragePatterns = obj.getPatterns()
+#
+#                 print("Total number of coverage Patterns:", len(coveragePatterns))
+#
+#                 obj.save(oFile)
+#
+#                 Df = obj.getPatternsAsDataFrame()
+#
+#                 memUSS = obj.getMemoryUSS()
+#
+#                 print("Total Memory in USS:", memUSS)
+#
+#                 memRSS = obj.getMemoryRSS()
+#
+#                 print("Total Memory in RSS", memRSS)
+#
+#                 run = obj.getRuntime()
+#
+#                 print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
+
+
+
+
 from PAMI.coveragePatterns.basic import abstract as _ab
 
 class CMine(_ab._coveragePatterns):
     """
-        CMine algorithms aims to discover the coverage patterns in transactional databases.
 
-    Reference:
-    ---------
-        Bhargav Sripada, Polepalli Krishna Reddy, Rage Uday Kiran:
-        Coverage patterns for efficient banner advertisement placement. WWW (Companion Volume) 2011: 131-132
-        https://dl.acm.org/doi/10.1145/1963192.1963259
-    
-    Attributes:
-    -----------
-        self.iFile : str
-            Input file name or path of the input file
-        minSup: float or int or str
-            The user can specify minSup either in count or proportion of database size.
-            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-        sep : str
-            This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
-            However, the users can override their default separator.
-        self.oFile : str
-            Name of the output file or path of the output file
-        self.startTime:float
-            To record the start time of the mining process
-        self.endTime:float
-            To record the completion time of the mining process
-        self.finalPatterns: dict
-            Storing the complete set of patterns in a dictionary variable
-        self.memoryUSS : float
-            To store the total amount of USS memory consumed by the program
-        self.memoryRSS : float
-            To store the total amount of RSS memory consumed by the program
-        self.Database : list
-            To store the complete set of transactions available in the input database/file
-    Methods:
-    -------
-        startMine()
-            Mining process will start from here
-        getPatterns()
-            Complete set of patterns will be retrieved with this function
-        save(oFile)
-            Complete set of coverage patterns will be loaded in to a output file
-        getPatternsAsDataFrame()
-            Complete set of coverage patterns will be loaded in to a dataframe
-        getMemoryUSS()
-            Total amount of USS memory consumed by the mining process will be retrieved from this function
-        getMemoryRSS()
-            Total amount of RSS memory consumed by the mining process will be retrieved from this function
-        getRuntime()
-            Total amount of runtime taken by the mining process will be retrieved from this function
-        createCoverageItems()
-            Generate coverage items
-        tidToBitset(itemset)
-            Convert tid list to bit set
-        genPatterns(prefix, tidData)
-            Generate coverage patterns
-        generateAllPatterns(coverageItems)
-            Generate all coverage patterns
-
-    Executing the code on terminal:
-    -------
-        Format:
-        ------
-            python3 CMine.py <inputFile> <outputFile> <minRF> <minCS> <maxOR> <'\t'>
-
-        Examples:
-        --------
-            python3 CMine.py sampleTDB.txt patterns.txt 0.4 0.7 0.5 ','
-
-        Sample run of importing the code:
-        -------------------
-
-            from PAMI.coveragePattern.basic import CMine as alg
-
-            obj = alg.CMine(iFile, minRF, minCS, maxOR, seperator)
-
-            obj.startMine()
-
-            coveragePatterns = obj.getPatterns()
-
-            print("Total number of coverage Patterns:", len(coveragePatterns))
-
-            obj.save(oFile)
-
-            Df = obj.getPatternsAsDataFrame()
-
-            memUSS = obj.getMemoryUSS()
-
-            print("Total Memory in USS:", memUSS)
-
-            memRSS = obj.getMemoryRSS()
-
-            print("Total Memory in RSS", memRSS)
-
-            run = obj.getRuntime()
-
-            print("Total ExecutionTime in seconds:", run)
-
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+    :Description:  CMine algorithms aims to discover the coverage patterns in transactional databases.
+
+    :Reference:    Bhargav Sripada, Polepalli Krishna Reddy, Rage Uday Kiran:
+                   Coverage patterns for efficient banner advertisement placement. WWW (Companion Volume) 2011: 131-132
+                   https://dl.acm.org/doi/10.1145/1963192.1963259
+    :param  iFile: str :
+                   Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  minRF: float:
+                   Controls the minimum number of transactions in which every item must appear in a database.
+    :param  minCS: float:
+                   Controls the minimum number of transactions in which at least one time within a pattern must appear in a database.
+    :param  maxOR: float:
+                   Controls the maximum number of transactions in which any two items within a pattern can reappear.
+
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
+
+    :Attributes:
+
+        startTime : float
+          To record the start time of the mining process
+
+        endTime : float
+          To record the completion time of the mining process
+
+        finalPatterns : dict
+          Storing the complete set of patterns in a dictionary variable
+
+        memoryUSS : float
+          To store the total amount of USS memory consumed by the program
+
+        memoryRSS : float
+          To store the total amount of RSS memory consumed by the program
+
+        Database : list
+          To store the transactions of a database in list
+
+
+    **Methods to execute code on terminal**
+    ----------------------------------------------------
+            Format:
+                      >>>  python3 CMine.py <inputFile> <outputFile> <minRF> <minCS> <maxOR> <'\t'>
+
+            Example:
+                      >>>  python3 CMine.py sampleTDB.txt patterns.txt 0.4 0.7 0.5 ','
+
+
+
+    **Importing this algorithm into a python program**
+    ----------------------------------------------------
+    .. code-block:: python
+
+                from PAMI.coveragePattern.basic import CMine as alg
+
+                obj = alg.CMine(iFile, minRF, minCS, maxOR, seperator)
+
+                obj.startMine()
+
+                coveragePatterns = obj.getPatterns()
+
+                print("Total number of coverage Patterns:", len(coveragePatterns))
+
+                obj.save(oFile)
+
+                Df = obj.getPatternsAsDataFrame()
+
+                memUSS = obj.getMemoryUSS()
+
+                print("Total Memory in USS:", memUSS)
+
+                memRSS = obj.getMemoryRSS()
+
+                print("Total Memory in RSS", memRSS)
+
+                run = obj.getRuntime()
+
+                print("Total ExecutionTime in seconds:", run)
+
+
+    **Credits:**
+    --------------------------
+             The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+
     """
 
     _startTime = float()
     _endTime = float()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
```

### Comparing `pami-2023.4.1/PAMI/coveragePatterns/basic/CPPG.py` & `pami-2023.5.1/PAMI/coveragePatterns/basic/CPPG.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,148 +1,158 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# CPPG  algorithm discovers coverage patterns in a transactional database.
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+# **Importing this algorithm into a python program**
+# --------------------------------------------------
+#
+#             from PAMI.coveragePattern.basic import CPPG as alg
+#
+#             obj = alg.CPPG(iFile, minRF, minCS, maxOR)
+#
+#             obj.startMine()
+#
+#             coveragePatterns = obj.getPatterns()
+#
+#             print("Total number of coverage Patterns:", len(coveragePatterns))
+#
+#             obj.save(oFile)
+#
+#             Df = obj.getPatternsAsDataFrame()
+#
+#             memUSS = obj.getMemoryUSS()
+#
+#             print("Total Memory in USS:", memUSS)
+#
+#             memRSS = obj.getMemoryRSS()
+#
+#             print("Total Memory in RSS", memRSS)
+#
+#             run = obj.getRuntime()
+#
+#             print("Total ExecutionTime in seconds:", run)
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
 
 from PAMI.coveragePatterns.basic import abstract as _ab
 
 
 _maxPer = float()
 _minSup = float()
 _lno = int()
 
 
 class CPPG(_ab._coveragePatterns):
-    """ CPPG  algorithm discovers coverage patterns in a transactional database.
+    """
+
+    :Description:  CPPG  algorithm discovers coverage patterns in a transactional database.
+
+    :Reference:     Gowtham Srinivas, P.; Krishna Reddy, P.; Trinath, A. V.; Bhargav, S.; Uday Kiran, R. (2015).
+                    Mining coverage patterns from transactional databases. Journal of Intelligent Information Systems, 45(3), 423439.
+                    https://link.springer.com/article/10.1007/s10844-014-0318-3
+
+    :param  iFile: str :
+           Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  minRF: float:
+                   Controls the minimum number of transactions in which every item must appear in a database.
+    :param  minCS: float:
+                   Controls the minimum number of transactions in which at least one time within a pattern must appear in a database.
+    :param  maxOR: float:
+                   Controls the maximum number of transactions in which any two items within a pattern can reappear.
+
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
+
+
+    :Attributes:
+
+        startTime : float
+          To record the start time of the mining process
+
+        endTime : float
+          To record the completion time of the mining process
+
+        finalPatterns : dict
+          Storing the complete set of patterns in a dictionary variable
 
-    Reference:
-    --------
-        Gowtham Srinivas, P.; Krishna Reddy, P.; Trinath, A. V.; Bhargav, S.; Uday Kiran, R. (2015).
-        Mining coverage patterns from transactional databases. Journal of Intelligent Information Systems, 45(3), 423439.
-        https://link.springer.com/article/10.1007/s10844-014-0318-3
-
-    Attributes:
-    ----------
-        iFile : file
-            Name of the Input file or path of the input file
-        oFile : file
-            Name of the output file or path of the output file
-        minSup: int or float or str
-            The user can specify minSup either in count or proportion of database size.
-            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-        maxPer: int or float or str
-            The user can specify maxPer either in count or proportion of database size.
-            If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
-        sep : str
-            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-            However, the users can override their default separator.
         memoryUSS : float
-            To store the total amount of USS memory consumed by the program
+          To store the total amount of USS memory consumed by the program
+
         memoryRSS : float
-            To store the total amount of RSS memory consumed by the program
-        startTime:float
-            To record the start time of the mining process
-        endTime:float
-            To record the completion time of the mining process
+          To store the total amount of RSS memory consumed by the program
+
         Database : list
-            To store the transactions of a database in list
-        mapSupport : Dictionary
-            To maintain the information of item and their frequency
-        lno : int
-            To represent the total no of transaction
-        tree : class
-            To represents the Tree class
-        itemSetCount : int
-            To represents the total no of patterns
-        finalPatterns : dict
-            To store the complete patterns
+          To store the transactions of a database in list
+
+
+    **Methods to execute code on terminal**
+    ---------------------------------------
+
+            Format:
+                      >>>  python3 CPPG.py <inputFile> <outputFile> <minRF> <minCS> <maxOR> <'\t'>
+
+            Example:
+                      >>>   python3 CPPG.py sampleTDB.txt patterns.txt 0.4 0.7 0.5 ','
+
+
 
-    Methods:
-    -------
-        startMine()
-            Mining process will start from here
-        getPatterns()
-            Complete set of patterns will be retrieved with this function
-        save(oFile)
-            Complete set of periodic-frequent patterns will be loaded in to a output file
-        getPatternsAsDataFrame()
-            Complete set of periodic-frequent patterns will be loaded in to a dataframe
-        getMemoryUSS()
-            Total amount of USS memory consumed by the mining process will be retrieved from this function
-        getMemoryRSS()
-            Total amount of RSS memory consumed by the mining process will be retrieved from this function
-        getRuntime()
-            Total amount of runtime taken by the mining process will be retrieved from this function
-        creatingItemSets(fileName)
-            Scans the dataset and stores in a list format
-        coverageOneItem()
-            Extracts the one-coverage patterns from database
-        updateDatabases()
-            Update the database by removing aperiodic items and sort the Database by item decreased support
-        buildTree()
-            After updating the Database, remaining items will be added into the tree by setting root node as null
-        convert()
-            to convert the user specified value
+    **Importing this algorithm into a python program**
+    --------------------------------------------------
 
-    Executing the code on terminal:
-    -------
-        Format:
-        ------
-            python3 CPPG.py <inputFile> <outputFile> <minRF> <minCS> <maxOR> <'\t'>
+    .. code-block:: python
 
-        Examples:
-        --------
-            python3 CPPG.py sampleTDB.txt patterns.txt 0.4 0.7 0.5 ','
+                from PAMI.coveragePattern.basic import CPPG as alg
 
-        Sample run of importing the code:
-        -------------------
+                obj = alg.CPPG(iFile, minRF, minCS, maxOR)
 
-            from PAMI.coveragePattern.basic import CPPG as alg
+                obj.startMine()
 
-            obj = alg.CPPG(iFile, minRF, minCS, maxOR)
+                coveragePatterns = obj.getPatterns()
 
-            obj.startMine()
+                print("Total number of coverage Patterns:", len(coveragePatterns))
 
-            coveragePatterns = obj.getPatterns()
+                obj.save(oFile)
 
-            print("Total number of coverage Patterns:", len(coveragePatterns))
+                Df = obj.getPatternsAsDataFrame()
 
-            obj.save(oFile)
+                memUSS = obj.getMemoryUSS()
 
-            Df = obj.getPatternsAsDataFrame()
+                print("Total Memory in USS:", memUSS)
 
-            memUSS = obj.getMemoryUSS()
+                memRSS = obj.getMemoryRSS()
 
-            print("Total Memory in USS:", memUSS)
+                print("Total Memory in RSS", memRSS)
 
-            memRSS = obj.getMemoryRSS()
+                run = obj.getRuntime()
 
-            print("Total Memory in RSS", memRSS)
+                print("Total ExecutionTime in seconds:", run)
 
-            run = obj.getRuntime()
 
-            print("Total ExecutionTime in seconds:", run)
+    **Credits:**
+    -------------------------
 
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+             The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
 
     """
     _startTime = float()
     _endTime = float()
     _minRF = str()
     _maxOR = str()
     _minCS = str()
```

### Comparing `pami-2023.4.1/PAMI/coveragePatterns/basic/abstract.py` & `pami-2023.5.1/PAMI/coveragePatterns/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/DF2DB/DF2DB.py` & `pami-2023.5.1/PAMI/extras/DF2DB/DF2DB.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,33 +1,25 @@
 from PAMI.extras.DF2DB.denseDF2DB import *
 from PAMI.extras.DF2DB.sparseDF2DB import *
 
 class DF2DB:
     """
-        This class create database from DataFrame. Threshold values and conditions are defined to all item.
+        :Description: This class create database from DataFrame. Threshold values and conditions are defined to all item.
+
+
+        :param inputDF: DataFrame :
+             It is sparse or dense DataFrame
+        :param thresholdValue: int or float :
+             It is threshold value of all item
+        :param condition: str :
+             It is condition of all item
+        :param DFtype: str :
+             It is DataFrame type. It should be sparse or dense. Default DF is sparse.
+
 
-        Attribute:
-        ----------
-        inputDF : pandas.DataFrame
-            It is sparse or dense DataFrame
-        thresholdValue : int or float
-            It is threshold value of all item
-        condition : str
-            It is condition of all item
-        DFtype : str
-            It is DataFrame type. It should be sparse or dense. Default DF is sparse.
-
-        Nethods:
-        --------
-        getDB(outputFile)
-            Create transactional database from DataFrame and store into outputFile
-        getTDB(outputFile)
-            Create temporal database from DataFrame and store into outputFile
-        getUDB(outputFile)
-            Create utility database from DataFrame and store into outputFile
         """
     def __init__(self, inputDF, thresholdValue, condition, DFtype='sparse'):
         self.inputDF = inputDF
         self.thresholdValue = thresholdValue
         self.condition = condition
         self.DFtype = DFtype.lower()
         if DFtype == 'sparse':
@@ -36,33 +28,39 @@
             self.DF2DB = denseDF2DB(self.inputDF, self.condition, self.thresholdValue)
         else:
             raise Exception('DF type should be sparse or dense')
 
     def getTransactional(self, outputFile):
         """
         create transactional database and return outputFileName
+
         :param outputFile: file name or path to store database
         :type outputFile: str
+
         :return: outputFile name
         """
         self.DF2DB.createTransactional(outputFile)
         return self.DF2DB.getFileName()
 
     def getTemporal(self, outputFile):
         """
         create temporal database and return outputFile name
+
         :param outputFile: file name or path to store database
         :type outputFile: str
+
         :return: outputFile name
         """
         self.DF2DB.createTemporal(outputFile)
         return self.DF2DB.getFileName()
 
     def getUtility(self, outputFile):
         """
         create utility database and return outputFile name
+
         :param outputFile:  file name or path to store database
         :type outputFile: str
+
         :return: outputFile name
         """
         self.DF2DB.createUtility(outputFile)
         return self.DF2DB.getFileName()
```

### Comparing `pami-2023.4.1/PAMI/extras/DF2DB/DF2DBPlus.py` & `pami-2023.5.1/PAMI/extras/DF2DB/DF2DBPlus.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,68 +1,67 @@
 from PAMI.extras.DF2DB.denseDF2DBPlus import *
 from PAMI.extras.DF2DB.sparseDF2DBPlus import *
 
 
 class DF2DBPlus:
     """
-    This class create database from DataFrame. Threshold values and conditions are defined to each item
-    by thresholdConditonDF.
+            :Description:  This class create database from DataFrame. Threshold values and conditions are defined to each item by thresholdConditonDF.
+
+            :param inputDF: DataFrame :
+                 It is sparse or dense DataFrame
+            :param thresholdConditionDF: pandas.DataFrame :
+                It is DataFrame to contain threshold values and condition each item
+            :param condition: str :
+                 It is condition of all item
+            :param DFtype: str :
+                 It is DataFrame type. It should be sparse or dense. Default DF is sparse.
+
 
-    Attribute:
-    ----------
-    inputDF : pandas.DataFrame
-        It is sparse or dense DataFrame
-    thresholdConditionDF : pandas.DataFrame
-        It is DataFrame to contain threshold values and condition each item
-    DFtype : str
-        It is DataFrame type. It should be sparse or dense. Default DF is sparse.
-
-    Nethods:
-    --------
-    getDB(outputFile)
-        Create transactional database from DataFrame and store into outputFile
-    getTDB(outputFile)
-        Create temporal database from DataFrame and store into outputFile
-    getUDB(outputFile)
-        Create utility database from DataFrame and store into outputFile
     """
 
+
     def __init__(self, inputDF, thresholdConditionDF, DFtype='sparse'):
         self.inputDF = inputDF
         self.thresholdConditionDF = thresholdConditionDF
         self.DFtype = DFtype.lower()
         if DFtype == 'sparse':
             self.DF2DB = sparseDF2DBPlus(self.inputDF, self.thresholdConditionDF)
         elif DFtype == 'dense':
             self.DF2DB = denseDF2DBPlus(self.inputDF, self.thresholdConditionDF)
         else:
             raise Exception('DF type should be sparse or dense')
 
     def getTransactional(self, outputFile):
         """
         create transactional database and return outputFileName
+
         :param outputFile: file name or path to store database
         :type outputFile: str
+
         :return: outputFile name
         """
         self.DF2DB.createTransactional(outputFile)
         return self.DF2DB.getFileName()
 
     def getTDB(self, outputFile):
         """
         create temporal database and return outputFile name
+
         :param outputFile: file name or path to store database
         :type outputFile: str
+
         :return: outputFile name
         """
         self.DF2DB.createTemporal(outputFile)
         return self.DF2DB.getFileName()
 
     def getUDB(self, outputFile):
         """
         create utility database and return outputFile name
+
         :param outputFile:  file name or path to store database
         :type outputFile: str
+
         :return: outputFile name
         """
         self.DF2DB.createUtility(outputFile)
         return self.DF2DB.getFileName()
```

### Comparing `pami-2023.4.1/PAMI/extras/DF2DB/createTDB.py` & `pami-2023.5.1/PAMI/extras/DF2DB/createTDB.py`

 * *Files 16% similar despite different names*

```diff
@@ -8,26 +8,26 @@
         self._df = df
         self._threshold = int(threshold)
         self._items = []
         self._updatedItems = []
 
     def createTDB(self):
         """
-            Create transactional data base
+            :Description: Create transactional data base
+
 
-            :returning a transactional database as DataFrame
         """
         i = self._df.columns.values.tolist()
         if 'sid' in i:
             self._items = self._df['sid'].tolist()
         for i in self._items:
             i = i.split()
             self._updatedItems.append([j for j in i if int(j) > self._threshold])
 
-    def save(self, outFile):
+    def savePatterns(self, outFile):
         """
             Complete set of frequent patterns will be loaded in to a output file
 
             :param outFile: name of the output file
 
             :type outFile: file
         """
@@ -39,20 +39,20 @@
                 s = s + j + " "
             writer.write("%s \n" % s)
 
 
 if __name__ == '__main__':
     a = createTDB('DataFrame', "1204150")
     a.createTDB()
-    a.save('output.txt')
+    a.savePatterns('output.txt')
     ap = fp.FPGrowth('output.txt', 500, ' ')
     ap.startMine()
     Patterns = ap.getPatterns()
     print("Total number of Frequent Patterns:", len(Patterns))
-    ap.save('fpoutput.txt')
+    ap.savePatterns('fpoutput.txt')
     memUSS = ap.getMemoryUSS()
     print("Total Memory in USS:", memUSS)
     memRSS = ap.getMemoryRSS()
     print("Total Memory in RSS", memRSS)
     run = ap.getRuntime()
     print("Total ExecutionTime in ms:", run)
```

### Comparing `pami-2023.4.1/PAMI/extras/DF2DB/denseDF2DB.py` & `pami-2023.5.1/PAMI/extras/DF2DB/denseDF2DB.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,242 +1,233 @@
+import pandas as pd
+
 class denseDF2DB:
     """
-        This class create Data Base from DataFrame.
+        :Description: This class create Data Base from DataFrame.
 
-        Attribute:
-        ----------
-        inputDF : pandas.DataFrame
+        :param inputDF: dataframe :
             It is dense DataFrame
-        condition : str
+        :param condition: str :
             It is condition to judge the value in dataframe
-        thresholdValue : int or float:
+        :param thresholdValue: int or float :
             User defined value.
-        tids : list
+        :param tids: list :
             It is tids list.
-        items : list
+        :param items: list :
             Store the items list
-        outputFile : str
+        :param outputFile: str  :
             Creation data base output to this outputFile.
-
-        Methods:
-        --------
-        createDB(outputFile)
-            Create transactional data base from dataFrame
-        createTDB(outputFile)
-            Create temporal dataBase from dataFrame
-        createUDB(outputFile)
-            Create utility database from dataFrame
-        getFileName()
-            Return outputFileName.
-        """
+    """
 
     def __init__(self, inputDF, condition, thresholdValue):
         self.inputDF = inputDF
         self.condition = condition
         self.thresholdValue = thresholdValue
         self.tids = []
         self.items = []
         self.outputFile = ' '
-        self.inputDF = self.inputDF.set_index('tid', drop=True)
-        self.items = list(self.inputDF.columns.values)
-
+        self.items = list(self.inputDF.columns.values)[1:]
+        self.inputDF = self.inputDF.set_index('tid')
         self.tids = list(self.inputDF.index)
 
 
     def createTransactional(self, outputFile):
         """
-        Create transactional data base
+         :Description: Create transactional data base
+
+         :param outputFile: str :
+              Write transactional data base into outputFile
 
-        :param outputFile: Write transactional data base into outputFile
-        :type outputFile: str
         """
 
         self.outputFile = outputFile
         with open(outputFile, 'w') as f:
             if self.condition == '>':
                 for tid in self.tids:
                     transaction = [item for item in self.items if self.inputDF.at[tid, item] > self.thresholdValue]
                     if len(transaction) > 1:
                         f.write(f'{transaction[0]}')
                         for item in transaction[1:]:
-                            f.write(f'\t{item}')
+                            f.write(f',{item}')
                     elif len(transaction) == 1:
                         f.write(f'{transaction}')
                     else:
                         continue
                     f.write('\n')
 
             elif self.condition == '>=':
                 for tid in self.tids:
                     transaction = [item for item in self.items if self.inputDF.at[tid, item] >= self.thresholdValue]
                     if len(transaction) > 1:
                         f.write(f'{transaction[0]}')
                         for item in transaction[1:]:
-                            f.write(f'\t{item}')
+                            f.write(f',{item}')
                     elif len(transaction) == 1:
                         f.write(f'{transaction}')
                     else:
                         continue
                     f.write('\n')
 
             elif self.condition == '<=':
                 for tid in self.tids:
                     transaction = [item for item in self.items if self.inputDF.at[tid, item] <= self.thresholdValue]
                     if len(transaction) > 1:
                         f.write(f'{transaction[0]}')
                         for item in transaction[1:]:
-                            f.write(f'\t{item}')
+                            f.write(f',{item}')
                     elif len(transaction) == 1:
                         f.write(f'{transaction}')
                     else:
                         continue
                     f.write('\n')
 
             elif self.condition == '<':
                 for tid in self.tids:
                     transaction = [item for item in self.items if self.inputDF.at[tid, item] < self.thresholdValue]
                     if len(transaction) > 1:
                         f.write(f'{transaction[0]}')
                         for item in transaction[1:]:
-                            f.write(f'\t{item}')
+                            f.write(f',{item}')
                     elif len(transaction) == 1:
                         f.write(f'{transaction}')
                     else:
                         continue
                     f.write('\n')
             elif self.condition == '==':
                 for tid in self.tids:
                     transaction = [item for item in self.items if self.inputDF.at[tid, item] == self.thresholdValue]
                     if len(transaction) > 1:
                         f.write(f'{transaction[0]}')
                         for item in transaction[1:]:
-                            f.write(f'\t{item}')
+                            f.write(f',{item}')
                     elif len(transaction) == 1:
                         f.write(f'{transaction}')
                     else:
                         continue
                     f.write('\n')
             elif self.condition == '!=':
                 for tid in self.tids:
                     transaction = [item for item in self.items if self.inputDF.at[tid, item] != self.thresholdValue]
                     if len(transaction) > 1:
                         f.write(f'{transaction[0]}')
                         for item in transaction[1:]:
-                            f.write(f'\t{item}')
+                            f.write(f',{item}')
                     elif len(transaction) == 1:
                         f.write(f'{transaction}')
                     else:
                         continue
                     f.write('\n')
             else:
                 print('Condition error')
 
 
 
     def createTemporal(self, outputFile):
         """
-        Create temporal data base
+         :Description: Create temporal data base
+
+         :param outputFile: str :
+                 Write temporal data base into outputFile
 
-        :param outputFile: Write temporal data base into outputFile
-        :type outputFile: str
         """
 
         self.outputFile = outputFile
         with open(outputFile, 'w') as f:
             if self.condition == '>':
                 for tid in self.tids:
                     transaction = [item for item in self.items if self.inputDF.at[tid, item] > self.thresholdValue]
                     if len(transaction) > 1:
                         f.write(f'{tid}')
                         for item in transaction:
-                            f.write(f'\t{item}')
+                            f.write(f',{item}')
                     elif len(transaction) == 1:
                         f.write(f'{tid}')
-                        f.write(f'\t{transaction}')
+                        f.write(f',{transaction}')
                     else:
                         continue
                     f.write('\n')
 
             elif self.condition == '>=':
                 for tid in self.tids:
                     transaction = [item for item in self.items if self.inputDF.at[tid, item] >= self.thresholdValue]
                     if len(transaction) > 1:
                         f.write(f'{tid}')
                         for item in transaction:
-                            f.write(f'\t{item}')
+                            f.write(f',{item}')
                     elif len(transaction) == 1:
                         f.write(f'{tid}')
-                        f.write(f'\t{transaction}')
+                        f.write(f',{transaction}')
                     else:
                         continue
                     f.write('\n')
 
             elif self.condition == '<=':
                 for tid in self.tids:
                     transaction = [item for item in self.items if self.inputDF.at[tid, item] <= self.thresholdValue]
                     if len(transaction) > 1:
                         f.write(f'{tid}')
                         for item in transaction:
-                            f.write(f'\t{item}')
+                            f.write(f',{item}')
                     elif len(transaction) == 1:
                         f.write(f'{tid}')
-                        f.write(f'\t{transaction}')
+                        f.write(f',{transaction}')
                     else:
                         continue
                     f.write('\n')
 
             elif self.condition == '<':
                 for tid in self.tids:
                     transaction = [item for item in self.items if self.inputDF.at[tid, item] < self.thresholdValue]
                     if len(transaction) > 1:
                         f.write(f'{tid}')
                         for item in transaction:
-                            f.write(f'\t{item}')
+                            f.write(f',{item}')
                     elif len(transaction) == 1:
                         f.write(f'{tid}')
-                        f.write(f'\t{transaction}')
+                        f.write(f',{transaction}')
                     else:
                         continue
                     f.write('\n')
             elif self.condition == '==':
                 for tid in self.tids:
                     transaction = [item for item in self.items if self.inputDF.at[tid, item] == self.thresholdValue]
                     if len(transaction) > 1:
                         f.write(f'{tid}')
                         for item in transaction:
-                            f.write(f'\t{item}')
+                            f.write(f',{item}')
                     elif len(transaction) == 1:
                         f.write(f'{tid}')
-                        f.write(f'\t{transaction}')
+                        f.write(f',{transaction}')
                     else:
                         continue
                     f.write('\n')
             elif self.condition == '!=':
                 for tid in self.tids:
                     transaction = [item for item in self.items if self.inputDF.at[tid, item] != self.thresholdValue]
                     if len(transaction) > 1:
                         f.write(f'{tid}')
                         for item in transaction:
-                            f.write(f'\t{item}')
+                            f.write(f',{item}')
                     elif len(transaction) == 1:
                         f.write(f'{tid}')
-                        f.write(f'\t{transaction}')
+                        f.write(f',{transaction}')
                     else:
                         continue
                     f.write('\n')
 
             else:
                 print('Condition error')
 
     def createUtility(self, outputFile):
         """
-        Create the utility data base.
+         :Description: Create the utility data base.
+
+         :param outputFile:  str :
+                     Write utility data base into outputFile
 
-        :param outputFile: Write utility data base into outputFile
-        :type outputFile: str
         """
 
         self.outputFile = outputFile
         with open(self.outputFile, 'w') as f:
             for tid in self.tids:
                 df = self.inputDF.loc[tid].dropna()
                 f.write(f'{df.index[0]}')
@@ -246,18 +237,19 @@
                 f.write(f'{df.at[df.index[0]]}')
                 for item in df.index[1:]:
                     f.write(f'\t{df.at[item]}')
                 f.write('\n')
 
     def getFileName(self):
         """
-        return outputFile name
-
         :return: outputFile name
         """
 
         return self.outputFile
 
 
-    
-#obj = denseDF2DB(dataset, '>=', 5)
-#obj.createDB('soramame_transactional.txt')
+if __name__ == '__main__':
+    DF = createDenseDF('denseDF.csv')
+    obj = denseDF2DB(DF.getDF(), '>=', 2)
+    obj.createDB('testTransactional.csv')
+    transactionalDB = obj.getFileName()
+    print(transactionalDB)
```

### Comparing `pami-2023.4.1/PAMI/extras/DF2DB/denseDF2DBPlus.py` & `pami-2023.5.1/PAMI/extras/DF2DB/denseDF2DBPlus.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,38 +1,27 @@
 import pandas as pd
 
 class denseDF2DBPlus:
     """
-        This class create Data Base from DataFrame.
+        :Description: This class create Data Base from DataFrame.
 
-        Attribute:
-        ----------
-        inputDF : pandas.DataFrame
-            It is dense DataFrame which was transposed.
-        thresholdConditionDF : pandas.DataFrame
-            It has threshold value and condition each item.
-        tids : list
+        :param inputDF: dataframe :
+            It is dense DataFrame
+        :param condition: str :
+            It is condition to judge the value in dataframe
+        :param thresholdValue: int or float :
+            User defined value.
+        :param tids: list :
             It is tids list.
-        items : list
+        :param items: list :
             Store the items list
-        df : pandas.DataFrame
-            It is data frame which is merged inputDF and thresholdConditionDF.
-        outputFile : str
+        :param outputFile: str  :
             Creation data base output to this outputFile.
 
-        Methods:
-        --------
-        createDB(outputFile)
-            Create transactional data base from dataFrame
-        createTDB(outputFile)
-            Create temporal dataBase from dataFrame
-        createUDB(outputFile)
-            Create utility database from dataFrame
-        getFileName()
-            Return outputFileName.
+
         """
 
     def __init__(self, inputDF, thresholdConditionDF):
         self.inputDF = inputDF.T
         self.thresholdConditionDF = thresholdConditionDF
         self.tids = []
         self.items = []
@@ -120,13 +109,13 @@
                 f.write(f'{df.at[df.index[0]]}')
                 for item in df.index[1:]:
                     f.write(f'\t{df.at[item]}')
                 f.write('\n')
 
     def getFileName(self):
         """
-        return outputFile name
+
 
         :return: outputFile name
         """
 
         return self.outputFile
```

### Comparing `pami-2023.4.1/PAMI/extras/DF2DB/sparseDF2DB.py` & `pami-2023.5.1/PAMI/extras/DF2DB/sparseDF2DB.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,35 +1,29 @@
 import pandas as pd
 
 class sparseDF2DB:
     """
-    This class create Data Base from DataFrame.
-    Attribute:
-    ----------
-    inputDF : pandas.DataFrame
-        It is sparse DataFrame
-    condition : str
-        It is condition to judge the value in dataframe
-    thresholdValue : int or float:
-        User defined value.
-    df : pandas.DataFrame
-        It is data frame to create data base.
-    outputFile : str
-        Creation data base output to this outputFile.
-    Methods:
-    --------
-    createDB(outputFile)
-        Create transactional data base from dataFrame
-    createTDB(outputFile)
-        Create temporal dataBase from dataFrame
-    createUDB(outputFile)
-        Create utility data base from dataFrame
-    getFileName()
-        Return outputFileName.
-    """
+            :Description:  This class create Data Base from DataFrame.
+
+            :param inputDF: dataframe :
+                It is dense DataFrame
+            :param condition: str :
+                It is condition to judge the value in dataframe
+            :param thresholdValue: int or float :
+                User defined value.
+            :param tids: list :
+                It is tids list.
+            :param items: list :
+                Store the items list
+            :param outputFile: str  :
+                Creation data base output to this outputFile.
+
+
+            """
+
 
     def __init__(self, inputDF, condition, thresholdValue):
         self.inputDF = inputDF
         self.condition = condition
         self.thresholdValue = thresholdValue
         self.outputFile = ''
         if self.condition == '>':
@@ -39,34 +33,36 @@
         elif self.condition == '<=':
             self.df = self.inputDF.query(f'value <= {self.thresholdValue}')
         elif self.condition == '<':
             self.df = self.inputDF.query(f'value < {self.thresholdValue}')
         else:
             print('Condition error')
         self.df = self.df.drop(columns='value')
-        self.df = self.df.groupby('tid')['transaction'].apply(list)
-        #print(self.df)
+        self.df = self.df.groupby('tid')['item'].apply(list)
 
     def createTransactional(self, outputFile):
         """
         Create transactional data base
+
         :param outputFile: Write transactional data base into outputFile
         :type outputFile: str
+
         """
         self.outputFile = outputFile
         with open(self.outputFile, 'w') as f:
             for line in self.df:
                 f.write(f'{line[0]}')
                 for item in line[1:]:
-                    f.write(f'\t{item}')
+                    f.write(f',{item}')
                 f.write('\n')
 
     def createTemporal(self, outputFile):
         """
         Create temporal data base
+
         :param outputFile: Write temporal data base into outputFile
         :type outputFile: str
         """
 
         self.outputFile = outputFile
         with open(self.outputFile, 'w') as f:
             for tid in self.df.index:
@@ -74,14 +70,15 @@
                 for item in self.df[tid]:
                     f.write(f',{item}')
                 f.write('\n')
 
     def createUtility(self, outputFile):
         """
         Create the utility data base.
+
         :param outputFile: Write utility data base into outputFile
         :type outputFile: str
         """
 
         self.outputFile = outputFile
         items = self.inputDF.groupby(level=0)['item'].apply(list)
         values = self.inputDF.groupby(level=0)['value'].apply(list)
@@ -96,18 +93,19 @@
                 f.write(f'{values[tid][0]}')
                 for value in values[tid][1:]:
                     f.write(f'\t{value}')
                 f.write('\n')
 
     def getFileName(self):
         """
-        return outputFile name
+
         :return: outputFile name
         """
         return self.outputFile
 
-# if __name__ == '__main__':
-#     DF = createSparseDF('sparseDF.csv')
-#     obj = sparseDF2DB(DF.getDF(), '>=', 2)
-#     obj.createDB('testTransactional.csv')
-#     transactionalDB = obj.getFileName()
-#     print(transactionalDB)
+if __name__ == '__main__':
+    DF = createSparseDF('sparseDF.csv')
+    obj = sparseDF2DB(DF.getDF(), '>=', 2)
+    obj.createDB('testTransactional.csv')
+    transactionalDB = obj.getFileName()
+    print(transactionalDB)
+
```

### Comparing `pami-2023.4.1/PAMI/extras/DF2DB/sparseDF2DBPlus.py` & `pami-2023.5.1/PAMI/extras/DF2DB/sparseDF2DBPlus.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,35 +1,29 @@
 import pandas as pd
 
 class sparseDF2DBPlus:
     """
-    This class create Data Base from DataFrame.
+            :Description: This class create Data Base from DataFrame.
+
+            :param inputDF: dataframe :
+                It is dense DataFrame
+            :param condition: str :
+                It is condition to judge the value in dataframe
+            :param thresholdValue: int or float :
+                User defined value.
+            :param tids: list :
+                It is tids list.
+            :param items: list :
+                Store the items list
+            :param outputFile: str  :
+                Creation data base output to this outputFile.
+
+
+            """
 
-    Attribute:
-    ----------
-    inputDF : pandas.DataFrame
-        It is sparse DataFrame
-    thresholdConditionDF : pandas.DataFrame
-            It has threshold value and condition each item.
-    df : pandas.DataFrame
-        It is data frame to create data base.
-    outputFile : str
-        Creation data base output to this outputFile.
-
-    Methods:
-    --------
-    createDB(outputFile)
-        Create transactional data base from dataFrame
-    createTDB(outputFile)
-        Create temporal dataBase from dataFrame
-    createUDB(outputFile)
-        Create utility data base from dataFrame
-    getFileName()
-        Return outputFileName.
-    """
 
     def __init__(self, inputDF, thresholdConditionDF):
         self.inputDF = inputDF
         self.thresholdConditionDF = thresholdConditionDF
         self.outputFile = ''
         self.df = pd.merge(self.inputDF, self.thresholdConditionDF, left_on='item', right_index=True)
         self.df.query('(condition == ">" & value > threshold) | (condition == ">=" & value >= threshold) |'
@@ -94,13 +88,13 @@
                 for value in values[tid][1:]:
                     f.write(f'\t{value}')
                 f.write('\n')
 
 
     def getFileName(self):
         """
-        return outputFile name
+
 
         :return: outputFile name
         """
 
         return self.outputFile
```

### Comparing `pami-2023.4.1/PAMI/extras/calculateMISValues/usingBeta.py` & `pami-2023.5.1/PAMI/extras/calculateMISValues/usingBeta.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/calculateMISValues/usingSD.py` & `pami-2023.5.1/PAMI/extras/calculateMISValues/usingSD.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/dbStats/fuzzyDatabaseStats.py` & `pami-2023.5.1/PAMI/extras/dbStats/fuzzyDatabaseStats.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,29 +2,31 @@
 import validators
 from urllib.request import urlopen
 import pandas as pd
 import PAMI.extras.graph.plotLineGraphFromDictionary as plt
 
 class fuzzyDatabaseStats:
     """
-    utilityDatabaseStats is class to get stats of database.
+        :Description: UtilityDatabaseStats is class to get stats of database.
+        
         Attributes:
-        ----------
+        -----------
         inputFile : file
             input file path
         database : dict
             store time stamp and its transaction
         lengthList : list
             store length of all transaction
         utility : dict
             store utility each item
         sep : str
             separator in file. Default is tab space.
+            
         Methods:
-        -------
+        ---------
         run()
             execute readDatabase function
         readDatabase()
             read database from input file
         getDatabaseSize()
             get the size of database
         getMinimumTransactionLength()
```

### Comparing `pami-2023.4.1/PAMI/extras/dbStats/temporalDatabaseStats.py` & `pami-2023.5.1/PAMI/extras/dbStats/temporalDatabaseStats.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,15 +4,17 @@
 import numpy as np
 from urllib.request import urlopen
 import PAMI.extras.graph.plotLineGraphFromDictionary as plt
 
 
 class temporalDatabaseStats:
     """
-    temporalDatabaseStats is class to get stats of database.
+        Description:
+        -------------
+            temporalDatabaseStats is class to get stats of database.
 
         Attributes:
         ----------
         inputFile : file
             input file path
         database : dict
             store time stamp and its transaction
```

### Comparing `pami-2023.4.1/PAMI/extras/dbStats/transactionalDatabaseStats.py` & `pami-2023.5.1/PAMI/extras/dbStats/uncertainTransactionalDatabaseStats.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,30 +1,30 @@
 import statistics
 import pandas as pd
 import validators
 import numpy as np
 from urllib.request import urlopen
 import PAMI.extras.graph.plotLineGraphFromDictionary as plt
 
-
-class transactionalDatabaseStats:
+class uncertainTransactionalDatabaseStats:
     """
-    transactionalDatabaseStats is class to get stats of database.
-
+        :Description:
+         ------------
+         uncertainTransactionalDatabaseStats is class to get stats of database.
+        
         Attributes:
         ----------
         inputFile : file
             input file path
         database : dict
             store time stamp and its transaction
         lengthList : list
             store length of all transaction
         sep : str
             separator in file. Default is tab space.
-
         Methods:
         -------
         run()
             execute readDatabase function
         readDatabase()
             read database from input file
         getDatabaseSize()
@@ -77,28 +77,29 @@
             if 'tid' in i and 'Patterns' in i:
                 self.database = self.inputFile.set_index('tid').T.to_dict(orient='records')[0]
         if isinstance(self.inputFile, str):
             if validators.url(self.inputFile):
                 data = urlopen(self.inputFile)
                 for line in data:
                     numberOfTransaction += 1
-                    line.strip()
+                    line = line.strip()
                     line = line.decode("utf-8")
-                    temp = [i.rstrip() for i in line.split(self.sep)]
-                    temp = [x for x in temp if x]
-                    self.database[numberOfTransaction] = temp
+                    temp = line.split(':')
+                    temp1 = [i.rstrip() for i in temp[0].split(self.sep)]
+                    temp1 = [x for x in temp if x]
+                    self.database[numberOfTransaction] = temp1
             else:
                 try:
                     with open(self.inputFile, 'r', encoding='utf-8') as f:
                         for line in f:
                             numberOfTransaction += 1
-                            line.strip()
-                            temp = [i.rstrip() for i in line.split(self.sep)]
-                            temp = [x for x in temp if x]
-                            self.database[numberOfTransaction] = temp
+                            line = line.strip()
+                            temp = line.split(':')
+                            temp1 = [i for i in temp[0].split(self.sep)]
+                            self.database[numberOfTransaction] = temp1
                 except IOError:
                     print("File Not Found")
                     quit()
         self.lengthList = [len(s) for s in self.database.values()]
 
     def getDatabaseSize(self):
         """
@@ -203,24 +204,24 @@
         """
         itemFrequencies = {}
         for tid in self.database:
             for item in self.database[tid]:
                 itemFrequencies[item] = itemFrequencies.get(item, 0)
                 itemFrequencies[item] += 1
         return {k: v for k, v in sorted(itemFrequencies.items(), key=lambda x: x[1], reverse=True)}
-    
+
     def getFrequenciesInRange(self):
         fre = self.getSortedListOfItemFrequencies()
         rangeFrequencies = {}
         maximum = max([i for i in fre.values()])
-        values = [int(i*maximum/6) for i in range(1,6)]
+        values = [int(i * maximum / 6) for i in range(1, 6)]
         va = len({key: val for key, val in fre.items() if val > 0 and val < values[0]})
         rangeFrequencies[va] = values[0]
-        for i in range(1,len(values)):
-            va = len({key: val for key, val in fre.items() if val < values[i] and val > values[i-1]})
+        for i in range(1, len(values)):
+            va = len({key: val for key, val in fre.items() if val < values[i] and val > values[i - 1]})
             rangeFrequencies[va] = values[i]
         return rangeFrequencies
 
     def getTransanctionalLengthDistribution(self):
         """
         get transaction length
         :return: transaction length
@@ -238,44 +239,31 @@
         :type data: dict
         :param outputFile: output file name or path to store
         :type outputFile: str
         """
         with open(outputFile, 'w') as f:
             for key, value in data.items():
                 f.write(f'{key}\t{value}\n')
-                   
+
     def printStats(self):
         print(f'Database size (total no of transactions) : {self.getDatabaseSize()}')
         print(f'Number of items : {self.getNumberOfItems()}')
         print(f'Minimum Transaction Size : {self.getMinimumTransactionLength()}')
         print(f'Average Transaction Size : {self.getAverageTransactionLength()}')
         print(f'Maximum Transaction Size : {self.getMaximumTransactionLength()}')
         print(f'Standard Deviation Transaction Size : {self.getStandardDeviationTransactionLength()}')
         print(f'Variance in Transaction Sizes : {self.getVarianceTransactionLength()}')
         print(f'Sparsity : {self.getSparsity()}')
-  
+
     def plotGraphs(self):
         itemFrequencies = self.getFrequenciesInRange()
         transactionLength = self.getTransanctionalLengthDistribution()
         plt.plotLineGraphFromDictionary(itemFrequencies, 100, 'Frequency', 'No of items', 'frequency')
         plt.plotLineGraphFromDictionary(transactionLength, 100, 'transaction length', 'transaction length', 'frequency')
 
 
 if __name__ == '__main__':
-    data = {'tid': [1, 2, 3, 4, 5, 6, 7],
 
-            'Transactions': [['a', 'd', 'e'], ['b', 'a', 'f', 'g', 'h'], ['b', 'a', 'd', 'f'], ['b', 'a', 'c'],
-                             ['a', 'd', 'g', 'k'],
-
-                             ['b', 'd', 'g', 'c', 'i'], ['b', 'd', 'g', 'e', 'j']]}
-
-    # data = pd.DataFrame.from_dict('transactional_T10I4D100K.csv')
-    import PAMI.extras.graph.plotLineGraphFromDictionary as plt
-
-    # obj = transactionalDatabaseStats(data)
-    obj = transactionalDatabaseStats('transactional_BMS1.txt', ',')
+    obj = uncertainTransactionalDatabaseStats('Uncertain_T10.csv', '\t')
     obj.run()
     obj.printStats()
     obj.plotGraphs()
-
-
-
```

### Comparing `pami-2023.4.1/PAMI/extras/dbStats/uncertainTemporalDatabaseStats.py` & `pami-2023.5.1/PAMI/extras/dbStats/uncertainTemporalDatabaseStats.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,33 +4,33 @@
 import numpy as np
 from urllib.request import urlopen
 import PAMI.extras.graph.plotLineGraphFromDictionary as plt
 
 
 class uncertainTemporalDatabaseStats:
     """
-    temporalDatabaseStats is class to get stats of database.
+        :Description: temporalDatabaseStats is class to get stats of database.
 
         Attributes:
-        ----------
+        -----------
         inputFile : file
             input file path
         database : dict
             store time stamp and its transaction
         lengthList : list
             store size of all transaction
         timeStampCount : dict
             number of transactions per time stamp
         periodList : list
             all period list in the database
         sep : str
             separator in file. Default is tab space.
 
         Methods:
-        -------
+        --------
         run()
             execute readDatabase function
         readDatabase()
             read database from input file
         getDatabaseSize()
             get the size of database
         getMinimumTransactionLength()
```

### Comparing `pami-2023.4.1/PAMI/extras/dbStats/uncertainTransactionalDatabaseStats.py` & `pami-2023.5.1/PAMI/extras/dbStats/transactionalDatabaseStats.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,54 +1,30 @@
 import statistics
 import pandas as pd
 import validators
 import numpy as np
 from urllib.request import urlopen
 import PAMI.extras.graph.plotLineGraphFromDictionary as plt
 
-class uncertainTransactionalDatabaseStats:
+
+class transactionalDatabaseStats:
     """
-    uncertainTransactionalDatabaseStats is class to get stats of database.
-        Attributes:
-        ----------
-        inputFile : file
+        :Description:  transactionalDatabaseStats is class to get stats of database.
+
+
+        :param inputFile: file :
             input file path
-        database : dict
+        :param database: dict :
             store time stamp and its transaction
-        lengthList : list
-            store length of all transaction
-        sep : str
+        :param lengthList: list :
+            store size of all transaction
+        :param sep: str
             separator in file. Default is tab space.
-        Methods:
-        -------
-        run()
-            execute readDatabase function
-        readDatabase()
-            read database from input file
-        getDatabaseSize()
-            get the size of database
-        getMinimumTransactionLength()
-            get the minimum transaction length
-        getAverageTransactionLength()
-            get the average transaction length. It is sum of all transaction length divided by database length.
-        getMaximumTransactionLength()
-            get the maximum transaction length
-        getStandardDeviationTransactionLength()
-            get the standard deviation of transaction length
-        getVarianceTransactionLength()
-            get the variance of transaction length
-        getSparsity()
-            get the sparsity of database
-        getSortedListOfItemFrequencies()
-            get sorted list of item frequencies
-        getSortedListOfTransactionLength()
-            get sorted list of transaction length
-        save(data, outputFile)
-            store data into outputFile
-    """
+
+           """
 
     def __init__(self, inputFile, sep='\t'):
         """
         :param inputFile: input file name or path
         :type inputFile: str
         """
         self.inputFile = inputFile
@@ -74,29 +50,28 @@
             if 'tid' in i and 'Patterns' in i:
                 self.database = self.inputFile.set_index('tid').T.to_dict(orient='records')[0]
         if isinstance(self.inputFile, str):
             if validators.url(self.inputFile):
                 data = urlopen(self.inputFile)
                 for line in data:
                     numberOfTransaction += 1
-                    line = line.strip()
+                    line.strip()
                     line = line.decode("utf-8")
-                    temp = line.split(':')
-                    temp1 = [i.rstrip() for i in temp[0].split(self.sep)]
-                    temp1 = [x for x in temp if x]
-                    self.database[numberOfTransaction] = temp1
+                    temp = [i.rstrip() for i in line.split(self.sep)]
+                    temp = [x for x in temp if x]
+                    self.database[numberOfTransaction] = temp
             else:
                 try:
                     with open(self.inputFile, 'r', encoding='utf-8') as f:
                         for line in f:
                             numberOfTransaction += 1
-                            line = line.strip()
-                            temp = line.split(':')
-                            temp1 = [i for i in temp[0].split(self.sep)]
-                            self.database[numberOfTransaction] = temp1
+                            line.strip()
+                            temp = [i.rstrip() for i in line.split(self.sep)]
+                            temp = [x for x in temp if x]
+                            self.database[numberOfTransaction] = temp
                 except IOError:
                     print("File Not Found")
                     quit()
         self.lengthList = [len(s) for s in self.database.values()]
 
     def getDatabaseSize(self):
         """
@@ -201,24 +176,24 @@
         """
         itemFrequencies = {}
         for tid in self.database:
             for item in self.database[tid]:
                 itemFrequencies[item] = itemFrequencies.get(item, 0)
                 itemFrequencies[item] += 1
         return {k: v for k, v in sorted(itemFrequencies.items(), key=lambda x: x[1], reverse=True)}
-
+    
     def getFrequenciesInRange(self):
         fre = self.getSortedListOfItemFrequencies()
         rangeFrequencies = {}
         maximum = max([i for i in fre.values()])
-        values = [int(i * maximum / 6) for i in range(1, 6)]
+        values = [int(i*maximum/6) for i in range(1,6)]
         va = len({key: val for key, val in fre.items() if val > 0 and val < values[0]})
         rangeFrequencies[va] = values[0]
-        for i in range(1, len(values)):
-            va = len({key: val for key, val in fre.items() if val < values[i] and val > values[i - 1]})
+        for i in range(1,len(values)):
+            va = len({key: val for key, val in fre.items() if val < values[i] and val > values[i-1]})
             rangeFrequencies[va] = values[i]
         return rangeFrequencies
 
     def getTransanctionalLengthDistribution(self):
         """
         get transaction length
         :return: transaction length
@@ -236,31 +211,44 @@
         :type data: dict
         :param outputFile: output file name or path to store
         :type outputFile: str
         """
         with open(outputFile, 'w') as f:
             for key, value in data.items():
                 f.write(f'{key}\t{value}\n')
-
+                   
     def printStats(self):
         print(f'Database size (total no of transactions) : {self.getDatabaseSize()}')
         print(f'Number of items : {self.getNumberOfItems()}')
         print(f'Minimum Transaction Size : {self.getMinimumTransactionLength()}')
         print(f'Average Transaction Size : {self.getAverageTransactionLength()}')
         print(f'Maximum Transaction Size : {self.getMaximumTransactionLength()}')
         print(f'Standard Deviation Transaction Size : {self.getStandardDeviationTransactionLength()}')
         print(f'Variance in Transaction Sizes : {self.getVarianceTransactionLength()}')
         print(f'Sparsity : {self.getSparsity()}')
-
+  
     def plotGraphs(self):
         itemFrequencies = self.getFrequenciesInRange()
         transactionLength = self.getTransanctionalLengthDistribution()
         plt.plotLineGraphFromDictionary(itemFrequencies, 100, 'Frequency', 'No of items', 'frequency')
         plt.plotLineGraphFromDictionary(transactionLength, 100, 'transaction length', 'transaction length', 'frequency')
 
 
 if __name__ == '__main__':
+    data = {'tid': [1, 2, 3, 4, 5, 6, 7],
+
+            'Transactions': [['a', 'd', 'e'], ['b', 'a', 'f', 'g', 'h'], ['b', 'a', 'd', 'f'], ['b', 'a', 'c'],
+                             ['a', 'd', 'g', 'k'],
+
+                             ['b', 'd', 'g', 'c', 'i'], ['b', 'd', 'g', 'e', 'j']]}
+
+    # data = pd.DataFrame.from_dict('transactional_T10I4D100K.csv')
+    import PAMI.extras.graph.plotLineGraphFromDictionary as plt
 
-    obj = uncertainTransactionalDatabaseStats('Uncertain_T10.csv', '\t')
+    # obj = transactionalDatabaseStats(data)
+    obj = transactionalDatabaseStats('transactional_BMS1.txt', ',')
     obj.run()
     obj.printStats()
     obj.plotGraphs()
+
+
+
```

### Comparing `pami-2023.4.1/PAMI/extras/dbStats/utilityDatabaseStats.py` & `pami-2023.5.1/PAMI/extras/dbStats/utilityDatabaseStats.py`

 * *Files 12% similar despite different names*

```diff
@@ -2,59 +2,27 @@
 import validators
 from urllib.request import urlopen
 import pandas as pd
 import PAMI.extras.graph.plotLineGraphFromDictionary as plt
 
 class utilityDatabaseStats:
     """
-    utilityDatabaseStats is class to get stats of database.
+           :Description:  utilityDatabaseStats is class to get stats of database.
 
-        Attributes:
-        ----------
-        inputFile : file
-            input file path
-        database : dict
-            store time stamp and its transaction
-        lengthList : list
-            store length of all transaction
-        utility : dict
-            store utility each item
-        sep : str
-            separator in file. Default is tab space.
 
-        Methods:
-        -------
-        run()
-            execute readDatabase function
-        readDatabase()
-            read database from input file
-        getDatabaseSize()
-            get the size of database
-        getMinimumTransactionLength()
-            get the minimum transaction length
-        getAverageTransactionLength()
-            get the average transaction length. It is sum of all transaction length divided by database length.
-        getMaximumTransactionLength()
-            get the maximum transaction length
-        getStandardDeviationTransactionLength()
-            get the standard deviation of transaction length
-        getSortedListOfItemFrequencies()
-            get sorted list of item frequencies
-        getSortedListOfTransactionLength()
-            get sorted list of transaction length
-        save(data, outputFile)
-            store data into outputFile
-        getMinimumUtility()
-            get the minimum utility
-        getAverageUtility()
-            get the average utility
-        getMaximumUtility()
-            get the maximum utility
-        getSortedUtilityValuesOfItem()
-            get sorted utility values each item
+           :param inputFile: file :
+               input file path
+           :param database: dict :
+               store time stamp and its transaction
+           :param lengthList: list :
+               store size of all transaction
+           :param  utility : dict
+               store utility each item
+           :param sep: str
+               separator in file. Default is tab space.
     """
     def __init__(self, inputFile, sep='\t'):
         """
         :param inputFile: input file name or path
         :type inputFile: str
         """
         self.inputFile = inputFile
```

### Comparing `pami-2023.4.1/PAMI/extras/fuzzyTransformation/abstract.py` & `pami-2023.5.1/PAMI/extras/fuzzyTransformation/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/fuzzyTransformation/temporalToFuzzy.py` & `pami-2023.5.1/PAMI/extras/fuzzyTransformation/temporalToFuzzy.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/fuzzyTransformation/transactionalToFuzzyTimeSeries.py` & `pami-2023.5.1/PAMI/extras/fuzzyTransformation/transactionalToFuzzyTimeSeries.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/fuzzyTransformation/utilityToFuzzy.py` & `pami-2023.5.1/PAMI/extras/fuzzyTransformation/utilityToFuzzy.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/generateDatabase/generateSpatioTemporalDatabase.py` & `pami-2023.5.1/PAMI/extras/generateDatabase/generateSpatioTemporalDatabase.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/generateDatabase/generateTemporalDatabase.py` & `pami-2023.5.1/PAMI/extras/generateDatabase/generateTemporalDatabase.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,19 @@
 import random
 import pandas as pd
 import os
 
 class generateTemporalDatabase:
     """
-    generateTemporalDatabase creates a temporal database and outputs a database or a frame depending on input
+    Description:
+    -------------
+        generateTemporalDatabase creates a temporal database and outputs a database or a frame depending on input
 
-        Attributes:
-        -----------
+    Attributes:
+    -----------
         numOfTransactions: int
             number of transactions
         maxNumOfItem: int
             highest value an item can be
         maxNumOfItemsPerTransaction: int
             maximum number of items a transaction can be
         outputFile: str
@@ -19,16 +21,16 @@
         percentage: int
             percentage of coinToss for TID of temporalDatabase
         sep: str
             seperator for database output file
         typeOfFile: str
             specify database or dataframe to get corresponding output
 
-        Methods:
-        ---------
+    Methods:
+    ---------
         getFileName():
             returns filename
         createTemporalFile():
             creates temporal database file or dataframe
         getDatabaseAsDataFrame:
             returns dataframe
     """
```

### Comparing `pami-2023.4.1/PAMI/extras/generateDatabase/generateTransactionalDatabase.py` & `pami-2023.5.1/PAMI/extras/generateDatabase/generateTransactionalDatabase.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,18 @@
 import random
 
 
 class generateTransactionalDatabase:
     """
-    generateTransactionalDatabase generates a transactional database
+       Description:
+       -------------
+          generateTransactionalDatabase generates a transactional database
 
-        Attributes:
-        -----------
+       Attributes:
+       -----------
         numOfTransactions: int
             number of transactions
         maxNumOfDistinctItems: int
             maximum number of distinct items
         numOfItemsPerTransaction: int
             number of items per transaction
         outFileName: str
```

### Comparing `pami-2023.4.1/PAMI/extras/generateLatexGraphFile.py` & `pami-2023.5.1/PAMI/extras/generateLatexGraphFile.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/graph/dataFrameInToFigures.py` & `pami-2023.5.1/PAMI/extras/graph/dataFrameInToFigures.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/graph/generateLatexFileFromDataFrame.py` & `pami-2023.5.1/PAMI/extras/graph/generateLatexFileFromDataFrame.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/graph/plotLineGraphFromDictionary.py` & `pami-2023.5.1/PAMI/extras/graph/plotLineGraphFromDictionary.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/graph/plotLineGraphsFromDataFrame.py` & `pami-2023.5.1/PAMI/extras/graph/plotLineGraphsFromDataFrame.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/graph/visualizePatterns.py` & `pami-2023.5.1/PAMI/extras/graph/visualizePatterns.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/imageProcessing/imagery2Databases.py` & `pami-2023.5.1/PAMI/extras/imageProcessing/imagery2Databases.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/neighbours/findNeighboursUsingEuclidean.py` & `pami-2023.5.1/PAMI/extras/neighbours/findNeighboursUsingEuclidean.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/plotPointOnMap.py` & `pami-2023.5.1/PAMI/extras/plotPointOnMap.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/plotPointOnMap_dump.py` & `pami-2023.5.1/PAMI/extras/plotPointOnMap_dump.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/scatterPlotSpatialPoints.py` & `pami-2023.5.1/PAMI/extras/scatterPlotSpatialPoints.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/extras/topKPatterns.py` & `pami-2023.5.1/PAMI/extras/topKPatterns.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/faultTolerantFrequentPattern/basic/FTApriori.py` & `pami-2023.5.1/PAMI/faultTolerantFrequentPattern/basic/FTApriori.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,123 +1,146 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# FT-Apriori is one of the fundamental algorithm to discover fault tolerant frequent patterns in a transactional database.
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+# **Importing this algorithm into a python program**
+# ----------------------------------------------------------------
+#
+#     from PAMI.uncertainCorrelatedPattern.basic import CFFI as alg
+#
+#     obj = alg.CFFI("input.txt", 2, 0.4)
+#
+#     obj.startMine()
+#
+#     Patterns = obj.getPatterns()
+#
+#     print("Total number of Correlated Fuzzy Frequent Patterns:", len(Patterns))
+#
+#     obj.savePatterns("outputFile")
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime
+#
+#     print("Total ExecutionTime in seconds:", run)
 
-from PAMI.faultTolerantFrequentPattern.basic import abstract as _ab
 
-class FTApriori(_ab._faultTolerantFrequentPatterns):
-    """
-        FT-Apriori is one of the fundamental algorithm to discover fault tolerant frequent patterns in a transactional database.
-        This program employs apriori property (or downward closure property) to  reduce the search space effectively.
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
 
-        Reference:
-        ----------
-            Pei, Jian & Tung, Anthony & Han, Jiawei. (2001). Fault-Tolerant Frequent Pattern Mining: Problems and Challenges.
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
 
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
 
-        Attributes:
-        ----------
-                iFile : str
-                    Input file name or path of the input file
-                oFile : str
-                    Name of the output file or the path of output file
-                minSup: float or int or str
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
+
+from PAMI.faultTolerantFrequentPattern.basic import abstract as _ab
+
+class FTApriori(_ab._faultTolerantFrequentPatterns):
+    """
+    
+    :Description:   FT-Apriori is one of the fundamental algorithm to discover fault tolerant frequent patterns in a transactional database.
+                    This program employs apriori property (or downward closure property) to  reduce the search space effectively.
+
+    :Reference:       Pei, Jian & Tung, Anthony & Han, Jiawei. (2001). Fault-Tolerant Frequent Pattern Mining: Problems and Challenges.
+
+    :param  iFile: str :
+           Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  minSup: float or int or str :
                     The user can specify minSup either in count or proportion of database size.
                     If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
                     Otherwise, it will be treated as float.
                     Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-                sep : str
-                    This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                    However, the users can override their default separator.
-                startTime:float
-                    To record the start time of the mining process
-                endTime:float
-                    To record the completion time of the mining process
-                finalPatterns: dict
-                    Storing the complete set of patterns in a dictionary variable
-                memoryUSS : float
-                    To store the total amount of USS memory consumed by the program
-                memoryRSS : float
-                    To store the total amount of RSS memory consumed by the program
-                Database : list
-                    To store the transactions of a database in list
-
-            Methods:
-            -------
-                startMine()
-                    Mining process will start from here
-                getPatterns()
-                    Complete set of patterns will be retrieved with this function
-                save(oFile)
-                    Complete set of frequent patterns will be loaded in to a output file
-                getPatternsAsDataFrame()
-                    Complete set of frequent patterns will be loaded in to a dataframe
-                getMemoryUSS()
-                    Total amount of USS memory consumed by the mining process will be retrieved from this function
-                getMemoryRSS()
-                    Total amount of RSS memory consumed by the mining process will be retrieved from this function
-                getRuntime()
-                    Total amount of runtime taken by the mining process will be retrieved from this function
-                candidateToFrequent(candidateList)
-                    Generates frequent patterns from the candidate patterns
-                frequentToCandidate(frequentList, length)
-                    Generates candidate patterns from the frequent patterns
-
-
-            Executing the code on terminal:
-            -------------------------------
-
-                Format:
-                ------
-                    python3 FTApriori.py <inputFile> <outputFile> <minSup> <itemSup> <minLength> <faultTolerance>
-
-                Examples:
-                ---------
-                    python3 FTApriori.py sampleDB.txt patterns.txt 10.0 3.0 3 1  (minSup will be considered in times of minSup and count of database transactions)
-
-                    python3 FTApriori.py sampleDB.txt patterns.txt 10  3 2 1    (minSup will be considered in support count or frequency)
-
-
-            Sample run of the importing code:
-            ---------------------------------
-
-                import PAMI.faultTolerantFrequentPattern.basic.FTApriori as alg
-
-                obj = alg.FTApriori(iFile, minSup, itemSup, minLength, faultTolerance)
-
-                obj.startMine()
-
-                faultTolerantFrequentPatterns = obj.getPatterns()
-
-                print("Total number of Fault Tolerant Frequent Patterns:", len(faultTolerantFrequentPatterns))
-
-                obj.save(oFile)
-
-                Df = obj.getPatternInDataFrame()
-
-                print("Total Memory in USS:", obj.getMemoryUSS())
-
-                print("Total Memory in RSS", obj.getMemoryRSS())
-
-                print("Total ExecutionTime in seconds:", obj.getRuntime())
-
-            Credits:
-            --------
-                The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+    :param  itemSup: int or float :
+                    Frequency of an item
+    :param minLength: int :
+                    minimum length of a pattern
+    :param faultTolerance: int
+
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
+
+
+    :Attributes:
+
+        startTime : float
+          To record the start time of the mining process
+
+        endTime : float
+          To record the completion time of the mining process
+
+        finalPatterns : dict
+          Storing the complete set of patterns in a dictionary variable
+
+        memoryUSS : float
+          To store the total amount of USS memory consumed by the program
+
+        memoryRSS : float
+          To store the total amount of RSS memory consumed by the program
+
+        Database : list
+          To store the transactions of a database in list
+    
+        
+    **Methods to execute code on terminal**
+    ---------------------------------------
+    
+            Format:
+                      >>>    python3 FTApriori.py <inputFile> <outputFile> <minSup> <itemSup> <minLength> <faultTolerance>
+            Example:
+                      >>>    python3 FTApriori.py sampleDB.txt patterns.txt 10.0 3.0 3 1
+    
+            .. note:: minSup will be considered in times of minSup and count of database transactions
+    
+    **Importing this algorithm into a python program**
+    ----------------------------------------------------------------
+    .. code-block:: python
+    
+            from PAMI.uncertainCorrelatedPattern.basic import CFFI as alg
+    
+            obj = alg.CFFI("input.txt", 2, 0.4)
+    
+            obj.startMine()
+    
+            Patterns = obj.getPatterns()
+    
+            print("Total number of Correlated Fuzzy Frequent Patterns:",  len(Patterns))
+    
+            obj.savePatterns("outputFile")
+    
+            memUSS = obj.getMemoryUSS()
+    
+            print("Total Memory in USS:",  memUSS)
+    
+            memRSS = obj.getMemoryRSS()
+    
+            print("Total Memory in RSS",  memRSS)
+    
+            run = obj.getRuntime
+    
+            print("Total ExecutionTime in seconds:",  run)
+    
+    **Credits:**
+    ----------------
+             The complete program was written by  P.Likhitha under the supervision of Professor Rage Uday Kiran.
 
         """
 
     _minSup = float()
     _itemSup = float()
     _minLength = int()
     _faultTolerance = int()
```

### Comparing `pami-2023.4.1/PAMI/faultTolerantFrequentPattern/basic/FTFPGrowth.py` & `pami-2023.5.1/PAMI/frequentPattern/basic/FPGrowth.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,25 +1,64 @@
-from PAMI.faultTolerantFrequentPattern.basic import abstract as _ab
-
-#  Copyright (C)  2021 Rage Uday Kiran
+# FPGrowth is one of the fundamental algorithm to discover frequent patterns in a transactional database. It stores the database in compressed fp-tree decreasing the memory usage and extracts the patterns from tree.It employs employs downward closure property to  reduce the search space effectively.
+#
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#     from PAMI.frequentPattern.basic import FPGrowth as alg
+#
+#     obj = alg.FPGrowth(iFile, minSup)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
+#     memRSS = obj.getMemoryRSS()
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     print("Total Memory in RSS", memRSS)
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+#
+#
+#
+
+
+
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
 
-from PAMI.faultTolerantFrequentPattern.basic import abstract as _fp
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
+
+from PAMI.frequentPattern.basic import abstract as _fp
 
 _minSup = str()
 _fp._sys.setrecursionlimit(20000)
 
 
 class _Node:
     """
@@ -85,15 +124,14 @@
         getConditionalPatterns(patterns, frequencies)
             sort the patterns by removing the items with lower minSup
         generatePatterns(prefix)
             generating the patterns from fp-tree
     """
 
     def __init__(self):
-        self.headerList = []
         self.root = _Node(None, {})
         self.summaries = {}
         self.info = {}
 
     def addTransaction(self, transaction, count):
         """adding transaction into tree
 
@@ -206,127 +244,108 @@
             for pat in range(len(patterns)):
                 conditionalTree.addTransaction(patterns[pat], freq[pat])
             if len(patterns) > 0:
                 for q in conditionalTree.generatePatterns(pattern):
                     yield q
 
 
-class FTFPGrowth(_fp._faultTolerantFrequentPatterns):
+class FPGrowth(_fp._frequentPatterns):
     """
-       FPGrowth is one of the fundamental algorithm to discover frequent patterns in a transactional database.
-       It stores the database in compressed fp-tree decreasing the memory usage and extracts the
-       patterns from tree.It employs employs downward closure property to  reduce the search space effectively.
-
-    Reference :
-    ---------
-           Han, J., Pei, J., Yin, Y. et al. Mining Frequent Patterns without Candidate Generation: A Frequent-Pattern
+
+    :Description:   FPGrowth is one of the fundamental algorithm to discover frequent patterns in a transactional database. It stores the database in compressed fp-tree decreasing the memory usage and extracts the patterns from tree.It employs employs downward closure property to  reduce the search space effectively.
+
+    :Reference:  Han, J., Pei, J., Yin, Y. et al. Mining Frequent Patterns without Candidate Generation: A Frequent-Pattern
            Tree Approach. Data  Mining and Knowledge Discovery 8, 5387 (2004). https://doi.org/10.1023
 
-    Attributes :
-    ----------
-        iFile : file
-            Input file name or path of the input file
-        minSup: float or int or str
-            The user can specify minSup either in count or proportion of database size.
-            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-        sep : str
-            This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
-            However, the users can override their default separator.
-        oFile : file
-            Name of the output file or the path of the output file
-        startTime:float
-            To record the start time of the mining process
-        endTime:float
-            To record the completion time of the mining process
+    :param  iFile: str :
+                   Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  minSup: int or float or str :
+                   The user can specify minSup either in count or proportion of database size. If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
+
+
+
+    :Attributes:
+
+        startTime : float
+          To record the start time of the mining process
+
+        endTime : float
+          To record the completion time of the mining process
+
+        finalPatterns : dict
+          Storing the complete set of patterns in a dictionary variable
+
         memoryUSS : float
-            To store the total amount of USS memory consumed by the program
+          To store the total amount of USS memory consumed by the program
+
         memoryRSS : float
-            To store the total amount of RSS memory consumed by the program
+          To store the total amount of RSS memory consumed by the program
+
         Database : list
-            To store the transactions of a database in list
+          To store the transactions of a database in list
+
         mapSupport : Dictionary
             To maintain the information of item and their frequency
         lno : int
             it represents the total no of transactions
         tree : class
             it represents the Tree class
         finalPatterns : dict
             it represents to store the patterns
 
-    Methods :
-    -------
-        startMine()
-            Mining process will start from here
-        getPatterns()
-            Complete set of patterns will be retrieved with this function
-        save(oFile)
-            Complete set of frequent patterns will be loaded in to a output file
-        getPatternsAsDataFrame()
-            Complete set of frequent patterns will be loaded in to a dataframe
-        getMemoryUSS()
-            Total amount of USS memory consumed by the mining process will be retrieved from this function
-        getMemoryRSS()
-            Total amount of RSS memory consumed by the mining process will be retrieved from this function
-        getRuntime()
-            Total amount of runtime taken by the mining process will be retrieved from this function
-        creatingItemSets()
-            Scans the dataset or dataframes and stores in list format
-        frequentOneItem()
-            Extracts the one-frequent patterns from transactions
 
-    Executing the code on terminal:
-    -------
+    **Methods to execute code on terminal**
+    --------------------------------------------------------
         Format:
-        -------
-            python3 FPGrowth.py <inputFile> <outputFile> <minSup>
+                  >>> python3 FPGrowth.py <inputFile> <outputFile> <minSup>
 
-        Examples:
-        ---------
-            python3 FPGrowth.py sampleDB.txt patterns.txt 10.0   (minSup will be considered in times of minSup and count of database transactions)
+        Example:
+                  >>> python3 FPGrowth.py sampleDB.txt patterns.txt 10.0
 
-            python3 FPGrowth.py sampleDB.txt patterns.txt 10     (minSup will be considered in support count or frequency) (it will consider "\t" as a separator)
+        .. note:: minSup will be considered in percentage of database transactions
 
-            python3 FPGrowth.py sampleTDB.txt output.txt sampleN.txt 3 ',' (it will consider "," as a separator)
 
+    **Importing this algorithm into a python program**
+    --------------------------------------------------------
+    .. code-block:: python
 
-    Sample run of the importing code:
-    -----------
+                from PAMI.frequentPattern.basic import FPGrowth as alg
 
+                obj = alg.FPGrowth(iFile, minSup)
 
-        from PAMI.frequentPattern.basic import FPGrowth as alg
+                obj.startMine()
 
-        obj = alg.FPGrowth(iFile, minSup)
+                frequentPatterns = obj.getPatterns()
 
-        obj.startMine()
+                print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-        frequentPatterns = obj.getPatterns()
+                obj.savePatterns(oFile)
 
-        print("Total number of Frequent Patterns:", len(frequentPatterns))
+                Df = obj.getPatternInDataFrame()
 
-        obj.save(oFile)
+                memUSS = obj.getMemoryUSS()
 
-        Df = obj.getPatternInDataFrame()
+                print("Total Memory in USS:", memUSS)
 
-        memUSS = obj.getMemoryUSS()
+                memRSS = obj.getMemoryRSS()
 
-        print("Total Memory in USS:", memUSS)
+                print("Total Memory in RSS", memRSS)
 
-        memRSS = obj.getMemoryRSS()
+                run = obj.getRuntime()
 
-        print("Total Memory in RSS", memRSS)
+                print("Total ExecutionTime in seconds:", run)
 
-        run = obj.getRuntime()
 
-        print("Total ExecutionTime in seconds:", run)
-
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+    **Credits:**
+    ----------------------------
+               The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
 
         """
 
     __startTime = float()
     __endTime = float()
     _minSup = str()
     __finalPatterns = {}
@@ -338,16 +357,16 @@
     __Database = []
     __mapSupport = {}
     __lno = 0
     __tree = _Tree()
     __rank = {}
     __rankDup = {}
 
-    def __init__(self, iFile, minSup, itemSup, minLength, faultTolerance, sep='\t'):
-        super().__init__(iFile, minSup, itemSup, minLength, faultTolerance, sep)
+    def __init__(self, iFile, minSup, sep='\t'):
+        super().__init__(iFile, minSup, sep)
 
     def __creatingItemSets(self):
         """
             Storing the complete transactions of the database/input file in a database variable
 
 
         """
@@ -355,15 +374,15 @@
         if isinstance(self._iFile, _fp._pd.DataFrame):
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
                 self.__Database = self._iFile['Transactions'].tolist()
 
-            # print(self.Database)
+            #print(self.Database)
         if isinstance(self._iFile, str):
             if _fp._validators.url(self._iFile):
                 data = _fp._urlopen(self._iFile)
                 for line in data:
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
@@ -576,31 +595,30 @@
         """ Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
 
         :rtype: dict
         """
         return self.__finalPatterns
-
+    
     def printResults(self):
         print("Total number of Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:", self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_fp._sys.argv) == 7 or len(_fp._sys.argv) == 8:
-        if len(_fp._sys.argv) == 8:
-            _ap = FTFPGrowth(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4],
-                             _fp._sys.argv[5], _fp._sys.argv[6], _fp._sys.argv[7])
-        if len(_fp._sys.argv) == 7:
-            _ap = FTFPGrowth(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4], _fp._sys.argv[5], _fp._sys.argv[6])
+    if len(_fp._sys.argv) == 4 or len(_fp._sys.argv) == 5:
+        if len(_fp._sys.argv) == 5:
+            _ap = FPGrowth(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4])
+        if len(_fp._sys.argv) == 4:
+            _ap = FPGrowth(_fp._sys.argv[1], _fp._sys.argv[3])
         _ap.startMine()
-        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
+        print("Total number of Frequent Patterns:", len( _ap.getPatterns()))
         _ap.save(_fp._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/faultTolerantFrequentPattern/basic/VBFTMine.py` & `pami-2023.5.1/PAMI/faultTolerantFrequentPattern/basic/VBFTMine.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,127 +1,142 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# VBFTMine is one of the fundamental algorithm to discover fault tolerant frequent patterns in a uncertain transactional database based on bitset representation.
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+# **Importing this algorithm into a python program**
+# ---------------------------------------------------
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+# import PAMI.faultTolerantFrequentPattern.basic.VBFTMine as alg
+#
+# obj = alg.VBFTMine(iFile, minSup, itemSup, minLength, faultTolerance)
+#
+# obj.startMine()
+#
+# faultTolerantFrequentPatterns = obj.getPatterns()
+#
+# print("Total number of Fault Tolerant Frequent Patterns:", len(faultTolerantFrequentPatterns))
+#
+# obj.save(oFile)
+#
+# Df = obj.getPatternInDataFrame()
+#
+# print("Total Memory in USS:", obj.getMemoryUSS())
+#
+# print("Total Memory in RSS", obj.getMemoryRSS())
+#
+# print("Total ExecutionTime in seconds:", obj.getRuntime())
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
 
 import numpy as _np
 from PAMI.faultTolerantFrequentPattern.basic import abstract as _ab
 
 class VBFTMine(_ab._faultTolerantFrequentPatterns):
     """
-        VBFTMine is one of the fundamental algorithm to discover fault tolerant frequent patterns in a uncertain transactional database based on
-        bitset representation.
-        This program employs apriori property (or downward closure property) to  reduce the search space effectively.
-
-        Reference:
-        ----------
-            Koh, JL., Yo, PW. (2005). An Efficient Approach for Mining Fault-Tolerant Frequent Patterns Based on Bit Vector Representations.
-            In: Zhou, L., Ooi, B.C., Meng, X. (eds) Database Systems for Advanced Applications. DASFAA 2005. Lecture Notes in Computer Science,
-            vol 3453. Springer, Berlin, Heidelberg. https://doi.org/10.1007/11408079_51
-
-
-        Attributes:
-        ----------
-                iFile : str
-                    Input file name or path of the input file
-                oFile : str
-                    Name of the output file or the path of output file
-                minSup: float or int or str
+    
+    :Description:  VBFTMine is one of the fundamental algorithm to discover fault tolerant frequent patterns in a uncertain transactional database based on
+                   bitset representation.
+                   This program employs apriori property (or downward closure property) to  reduce the search space effectively.
+
+    :Reference:         Koh, JL., Yo, PW. (2005). An Efficient Approach for Mining Fault-Tolerant Frequent Patterns Based on Bit Vector Representations.
+                        In: Zhou, L., Ooi, B.C., Meng, X. (eds) Database Systems for Advanced Applications. DASFAA 2005. Lecture Notes in Computer Science,
+                        vol 3453. Springer, Berlin, Heidelberg. https://doi.org/10.1007/11408079_51
+    :param  iFile: str :
+           Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  minSup: float or int or str :
                     The user can specify minSup either in count or proportion of database size.
                     If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
                     Otherwise, it will be treated as float.
                     Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-                sep : str
-                    This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                    However, the users can override their default separator.
-                startTime:float
-                    To record the start time of the mining process
-                endTime:float
-                    To record the completion time of the mining process
-                finalPatterns: dict
-                    Storing the complete set of patterns in a dictionary variable
-                memoryUSS : float
-                    To store the total amount of USS memory consumed by the program
-                memoryRSS : float
-                    To store the total amount of RSS memory consumed by the program
-                Database : list
-                    To store the transactions of a database in list
-
-            Methods:
-            -------
-                startMine()
-                    Mining process will start from here
-                getPatterns()
-                    Complete set of patterns will be retrieved with this function
-                save(oFile)
-                    Complete set of frequent patterns will be loaded in to a output file
-                getPatternsAsDataFrame()
-                    Complete set of frequent patterns will be loaded in to a dataframe
-                getMemoryUSS()
-                    Total amount of USS memory consumed by the mining process will be retrieved from this function
-                getMemoryRSS()
-                    Total amount of RSS memory consumed by the mining process will be retrieved from this function
-                getRuntime()
-                    Total amount of runtime taken by the mining process will be retrieved from this function
-                candidateToFrequent(candidateList)
-                    Generates frequent patterns from the candidate patterns
-                frequentToCandidate(frequentList, length)
-                    Generates candidate patterns from the frequent patterns
-
-
-            Executing the code on terminal:
-            -------------------------------
-
-                Format:
-                ------
-                    python3 VBFTMine.py <inputFile> <outputFile> <minSup> <itemSup> <minLength> <faultTolerance>
-
-                Examples:
-                ---------
-                    python3 VBFTMine.py sampleDB.txt patterns.txt 10.0 3.0 3 1  (minSup will be considered in times of minSup and count of database transactions)
-
-                    python3 VBFTMine.py sampleDB.txt patterns.txt 10  3 2 1    (minSup will be considered in support count or frequency)
-
-
-            Sample run of the importing code:
-            ---------------------------------
-
-                import PAMI.faultTolerantFrequentPattern.basic.VBFTMine as alg
-
-                obj = alg.VBFTMine(iFile, minSup, itemSup, minLength, faultTolerance)
-
-                obj.startMine()
-
-                faultTolerantFrequentPatterns = obj.getPatterns()
-
-                print("Total number of Fault Tolerant Frequent Patterns:", len(faultTolerantFrequentPatterns))
-
-                obj.save(oFile)
-
-                Df = obj.getPatternInDataFrame()
-
-                print("Total Memory in USS:", obj.getMemoryUSS())
-
-                print("Total Memory in RSS", obj.getMemoryRSS())
-
-                print("Total ExecutionTime in seconds:", obj.getRuntime())
-
-            Credits:
-            --------
-                The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+    :param  itemSup: int or float :
+                    Frequency of an item
+    :param minLength: int
+                    minimum length of a pattern
+    :param faultTolerance: int
+
+
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
+
+
+    :Attributes:
+
+        startTime : float
+          To record the start time of the mining process
+
+        endTime : float
+          To record the completion time of the mining process
+
+        finalPatterns : dict
+          Storing the complete set of patterns in a dictionary variable
+
+        memoryUSS : float
+          To store the total amount of USS memory consumed by the program
+
+        memoryRSS : float
+          To store the total amount of RSS memory consumed by the program
+
+        Database : list
+          To store the transactions of a database in list
+
+
+    Executing the code on terminal:
+    -------------------------------
+
+        Format:
+        --------
+            >>> python3 VBFTMine.py <inputFile> <outputFile> <minSup> <itemSup> <minLength> <faultTolerance>
+
+        Examples:
+        ---------
+            >>> python3 VBFTMine.py sampleDB.txt patterns.txt 10.0 3.0 3 1  (minSup will be considered in times of minSup and count of database transactions)
+
+
+    Sample run of the importing code:
+    ---------------------------------
+    .. code-block:: python
+    
+        import PAMI.faultTolerantFrequentPattern.basic.VBFTMine as alg
+
+        obj = alg.VBFTMine(iFile, minSup, itemSup, minLength, faultTolerance)
+
+        obj.startMine()
+
+        faultTolerantFrequentPatterns = obj.getPatterns()
+
+        print("Total number of Fault Tolerant Frequent Patterns:", len(faultTolerantFrequentPatterns))
+
+        obj.save(oFile)
+
+        Df = obj.getPatternInDataFrame()
+
+        print("Total Memory in USS:", obj.getMemoryUSS())
+
+        print("Total Memory in RSS", obj.getMemoryRSS())
+
+        print("Total ExecutionTime in seconds:", obj.getRuntime())
+
+    Credits:
+    --------
+        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
 
         """
 
     _minSup = float()
     _itemSup = float()
     _minLength = int()
     _faultTolerance = int()
```

### Comparing `pami-2023.4.1/PAMI/faultTolerantFrequentPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/faultTolerantFrequentPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/faultTolerantFrequentPattern/maximal/abstract.py` & `pami-2023.5.1/PAMI/fuzzyPeriodicFrequentPattern/basic/abstract.py`

 * *Files 3% similar despite different names*

```diff
@@ -22,45 +22,45 @@
 #      but WITHOUT ANY WARRANTY; without even the implied warranty of
 #      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 #      GNU General Public License for more details.
 #
 #      You should have received a copy of the GNU General Public License
 #      along with this program.  If not, see <https://www.gnu.org/licenses/>.
 
-# from abc import ABC as _ABC, abstractmethod as _abstractmethod
 from abc import ABC as _ABC, abstractmethod as _abstractmethod
 import time as _time
 import csv as _csv
 import pandas as _pd
 from collections import defaultdict as _defaultdict
 from itertools import combinations as _c
 import os as _os
 import os.path as _ospath
 import psutil as _psutil
 import sys as _sys
 import validators as _validators
 from urllib.request import urlopen as _urlopen
 import functools as _functools
-import itertools as _itertools
 
 
-class _faultTolerantFrequentPatterns(_ABC):
+class _fuzzyPeriodicFrequentPatterns(_ABC):
     """ This abstract base class defines the variables and methods that every frequent pattern mining algorithm must
         employ in PAMI
 
 
-       Attributes:
-       ----------
+    Attributes :
+    ----------
         iFile : str
             Input file name or path of the input file
         minSup: integer or float or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
             Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+            Example: minSup=10 will be treated as integer, while minSup=0.1 will be treated as float
+        maxPer: int
+            The user specified Maximum periodicity
         sep : str
             This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
             However, the users can override their default separator
         startTime:float
             To record the start time of the algorithm
         endTime:float
             To record the completion time of the algorithm
@@ -69,16 +69,16 @@
         oFile : str
             Name of the output file to store complete set of frequent patterns
         memoryUSS : float
             To store the total amount of USS memory consumed by the program
         memoryRSS : float
             To store the total amount of RSS memory consumed by the program
 
-       Methods:
-       -------
+    Methods :
+    -------
         startMine()
             Calling this function will start the actual mining process
         getPatterns()
             This function will output all interesting patterns discovered by an algorithm
         save(oFile)
             This function will store the discovered patterns in an output file specified by the user
         getPatternsAsDataFrame()
@@ -88,42 +88,39 @@
         getMemoryRSS()
             This function outputs the total amount of RSS memory consumed by a mining algorithm
         getRuntime()
             This function outputs the total runtime of a mining algorithm
 
     """
 
-    def __init__(self, iFile, minSup, itemSup,  faultTolerance, sep="\t"):
+    def __init__(self, iFile, minSup, maxPer, sep="\t"):
         """
         :param iFile: Input file name or path of the input file
-        :type iFile: str or DataFrame
+        :type iFile: str
         :param minSup: The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
             Otherwise, it will be treated as float.
             Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
         :type minSup: int or float or str
+        :param maxPer: The user can specify maximum Periodicity
+        :type maxPer: int
         :param sep: separator used to distinguish items from each other. The default separator is tab space. However, users can override the default separator
         :type sep: str
         """
 
         self._iFile = iFile
         self._sep = sep
         self._minSup = minSup
-        self._itemSup = itemSup
-        self._faultTolerance = faultTolerance
+        self._maxPer = maxPer
+        self._startTime = float()
+        self._endTime = float()
         self._finalPatterns = {}
         self._oFile = str()
         self._memoryUSS = float()
         self._memoryRSS = float()
-        self._startTime = float()
-        self._endTime = float()
-
-        """Variable to store USS memory consumed by the program"""
-
-
 
     @_abstractmethod
     def startMine(self):
         """Code for the mining process will start from this function"""
 
         pass
 
@@ -157,12 +154,19 @@
 
     @_abstractmethod
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the program will be retrieved from this function"""
 
         pass
 
+
     @_abstractmethod
     def getRuntime(self):
         """Total amount of runtime taken by the program will be retrieved from this function"""
 
         pass
+
+    @_abstractmethod
+    def printResults(self):
+        """ To print all the results of execution"""
+
+        pass
```

### Comparing `pami-2023.4.1/PAMI/faultTolerantFrequentPattern/maximal/maxFTP.py` & `pami-2023.5.1/PAMI/frequentPattern/basic/ECLATDiffset.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,157 +1,194 @@
-import numpy as np
-from PAMI.faultTolerantFrequentPattern.maximal import abstract as _ab
+# ECLATDiffest uses diffset to extract the frequent patterns in a transactional database.
+
+# **Importing this algorithm into a python program**
+# ---------------------------------------------------------
+#
+#                 import PAMI.frequentPattern.basic.ECLATDiffset as alg
+#
+#                 obj = alg.ECLATDiffset(iFile, minSup)
+#
+#                 obj.startMine()
+#
+#                 frequentPatterns = obj.getPatterns()
+#
+#                 print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#                 obj.savePatterns(oFile)
+#
+#                 Df = obj.getPatternInDataFrame()
+#
+#                 memUSS = obj.getMemoryUSS()
+#
+#                 print("Total Memory in USS:", memUSS)
+#
+#                 memRSS = obj.getMemoryRSS()
+#
+#                 print("Total Memory in RSS", memRSS)
+#
+#                 run = obj.getRuntime()
+#
+#                 print("Total ExecutionTime in seconds:", run)
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
 
-class maxFTP(_ab._faultTolerantFrequentPatterns):
-    """
-        FT-Apriori is one of the fundamental algorithm to discover fault tolerant frequent patterns in a transactional database.
-        This program employs apriori property (or downward closure property) to  reduce the search space effectively.
 
-        Reference:
-        ----------
-            Pei, Jian & Tung, Anthony & Han, Jiawei. (2001). Fault-Tolerant Frequent Pattern Mining: Problems and Challenges.
-
-
-        Attributes:
-        ----------
-            iFile : str
-                Input file name or path of the input file
-            oFile : str
-                Name of the output file or the path of output file
-            minSup: float or int or str
-                The user can specify minSup either in count or proportion of database size.
-                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-            sep : str
-                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                    However, the users can override their default separator.
-            startTime:float
-                To record the start time of the mining process
-            endTime:float
-                To record the completion time of the mining process
-            finalPatterns: dict
-                Storing the complete set of patterns in a dictionary variable
-            memoryUSS : float
-                To store the total amount of USS memory consumed by the program
-            memoryRSS : float
-                To store the total amount of RSS memory consumed by the program
-            Database : list
-                To store the transactions of a database in list
-
-        Methods:
-        -------
-            startMine()
-                Mining process will start from here
-            getPatterns()
-                Complete set of patterns will be retrieved with this function
-            save(oFile)
-                Complete set of frequent patterns will be loaded in to a output file
-            getPatternsAsDataFrame()
-                Complete set of frequent patterns will be loaded in to a dataframe
-            getMemoryUSS()
-                Total amount of USS memory consumed by the mining process will be retrieved from this function
-            getMemoryRSS()
-                Total amount of RSS memory consumed by the mining process will be retrieved from this function
-            getRuntime()
-                Total amount of runtime taken by the mining process will be retrieved from this function
+# from abstract import *
 
+from PAMI.frequentPattern.basic import abstract as _ab
 
-        Executing the code on terminal:
-        -------------------------------
 
+class ECLATDiffset(_ab._frequentPatterns):
+    """
+    :Description:   ECLATDiffset uses diffset to extract the frequent patterns in a transactional database.
+
+    :Reference:  KDD '03: Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining
+            August 2003 Pages 326335 https://doi.org/10.1145/956750.956788
+            
+    :param  iFile: str :
+                   Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  minSup: int or float or str :
+                   The user can specify minSup either in count or proportion of database size. If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
+     
+ 
+    
+    :Attributes:
+    
+        startTime : float
+          To record the start time of the mining process
+
+        endTime : float
+          To record the completion time of the mining process
+
+        finalPatterns : dict
+          Storing the complete set of patterns in a dictionary variable
+
+        memoryUSS : float
+          To store the total amount of USS memory consumed by the program
+
+        memoryRSS : float
+          To store the total amount of RSS memory consumed by the program
+        
+        Database : list
+          To store the transactions of a database in list
+          
+        
+    **Methods to execute code on terminal**
+    ----------------------------------------
+    
             Format:
-            ------
-                python3 FTApriori.py <inputFile> <outputFile> <minSup> <itemSup> <minLength> <faultTolerance>
+                      >>> python3 ECLATbitset.py <inputFile> <outputFile> <minSup>
+    
+            Example:
+                      >>> python3 ECLATbitset.py sampleDB.txt patterns.txt 10.0
+    
+            .. note:: minSup will be considered in percentage of database transactions
+    
+    
+    **Importing this algorithm into a python program**
+    ---------------------------------------------------------
+    .. code-block:: python
 
-            Examples:
-            ---------
-                python3 FTApriori.py sampleDB.txt patterns.txt 10.0 3.0 3 1  (minSup will be considered in times of minSup and count of database transactions)
+                import PAMI.frequentPattern.basic.ECLATDiffset as alg
 
-                python3 FTApriori.py sampleDB.txt patterns.txt 10  3 2 1    (minSup will be considered in support count or frequency)
+                obj = alg.ECLATDiffset(iFile, minSup)
 
+                obj.startMine()
 
-        Sample run of the importing code:
-        ---------------------------------
+                frequentPatterns = obj.getPatterns()
 
-            import PAMI.faultTolerantFrequentPattern.maximal.maxFTP as alg
+                print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-            obj = alg.maxFTP(iFile, minSup, itemSup, minLength, faultTolerance)
+                obj.savePatterns(oFile)
 
-            obj.startMine()
+                Df = obj.getPatternInDataFrame()
 
-            faultTolerantFrequentPatterns = obj.getPatterns()
+                memUSS = obj.getMemoryUSS()
 
-            print("Total number of Fault Tolerant Frequent Patterns:", len(faultTolerantFrequentPatterns))
+                print("Total Memory in USS:", memUSS)
 
-            obj.save(oFile)
+                memRSS = obj.getMemoryRSS()
 
-            Df = obj.getPatternInDataFrame()
+                print("Total Memory in RSS", memRSS)
 
-            print("Total Memory in USS:", obj.getMemoryUSS())
+                run = obj.getRuntime()
 
-            print("Total Memory in RSS", obj.getMemoryRSS())
+                print("Total ExecutionTime in seconds:", run)
 
-            print("Total ExecutionTime in seconds:", obj.getRuntime())
 
-        Credits:
-        --------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+    **Credits:**
+    -------------------
+
+               The complete program was written by Kundai under the supervision of Professor Rage Uday Kiran.
 
     """
 
     _minSup = float()
-    _itemSup = float()
-    _minLength = int()
-    _faultTolerance = int()
     _startTime = float()
     _endTime = float()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
-    _mapSupport = {}
+    _diffSets = {}
+    _trans_set = set()
 
     def _creatingItemSets(self):
         """
             Storing the complete transactions of the database/input file in a database variable
 
-
         """
         self._Database = []
         if isinstance(self._iFile, _ab._pd.DataFrame):
-            temp = []
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
-                temp = self._iFile['Transactions'].tolist()
-
-            for k in temp:
-                self._Database.append(set(k))
+                self._Database = self._iFile['Transactions'].tolist()
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
-                    self._Database.append(set(temp))
+                    self._Database.append(temp)
             else:
                 try:
                     with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
                             line.strip()
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
-                            self._Database.append(set(temp))
+                            self._Database.append(temp)
                 except IOError:
                     print("File Not Found")
                     quit()
 
     def _convert(self, value):
         """
         To convert the user specified minSup value
@@ -168,88 +205,115 @@
             if '.' in value:
                 value = float(value)
                 value = (len(self._Database) * value)
             else:
                 value = int(value)
         return value
 
-    def _oneLengthItems(self):
-        self._mapSupport = {}
-        self._bits = {}
-        for i in self._Database:
-            for j in i:
-                if j not in self._mapSupport:
-                    self._mapSupport[j] = 1
-                else:
-                    self._mapSupport[j] += 1
-        self._mapSupport = {k: v for k, v in self._mapSupport.items() if v >= self._minSup}
-        genList = [k for k, v in sorted(self._mapSupport.items(), key=lambda x: x[1], reverse=True)]
-        for i in genList:
-            for j in self._Database:
-                if i in j:
-                    if i not in self._bits:
-                        self._bits[i] = np.array(1)
-                    else:
-                        self._bits[i].append(1)
-                else:
-                    if i not in self._bits:
-                        self._bits[i] = np.array(0)
-                    else:
-                        self._bits[i].append(0)
-        print(self._bits)
-        return genList
-
-    def _checkMaximal(self, itemset):
-        s = [0] * len(self._Database)
-        for i in itemset:
-            s = list(np.array(s) & np.array(self._bits[i]))
-        print(s)
+    def _getUniqueItemList(self):
 
+        # tidSets will store all the initial tids
+        tidSets = {}
+        # uniqueItem will store all frequent 1 items
+        uniqueItem = []
+        for line in self._Database:
+                transNum = 0
+                # Database = [set([i.rstrip() for i in transaction.split('\t')]) for transaction in f]
+                for transaction in self._Database:
+                    transNum += 1
+                    self._trans_set.add(transNum)
+                    for item in transaction:
+                        if item in tidSets:
+                            tidSets[item].add(transNum)
+                        else:
+                            tidSets[item] = {transNum}
+        for key, value in tidSets.items():
+            supp = len(value)
+            if supp >= self._minSup:
+                self._diffSets[key] = [supp, self._trans_set.difference(value)]
+                uniqueItem.append(key)
+        # for x, y in self._diffSets.items():
+        #     print(x, y)
+        uniqueItem.sort()
+        # print()
+        return uniqueItem
+
+    def _runDeclat(self, candidateList):
+
+        newList = []
+        for i in range(0, len(candidateList)):
+            item1 = candidateList[i]
+            iList = item1.split()
+            for j in range(i + 1, len(candidateList)):
+                item2 = candidateList[j]
+                jList = item2.split()
+                if iList[:-1] == jList[:-1]:
+                    unionDiffSet = self._diffSets[item2][1].difference(self._diffSets[item1][1])
+                    unionSup = self._diffSets[item1][0] - len(unionDiffSet)
+                    if unionSup >= self._minSup:
+                        newKey = item1 + "\t" + jList[-1]
+                        self._diffSets[newKey] = [unionSup, unionDiffSet]
+                        newList.append(newKey)
+                    else: 
+                        break
 
+        if len(newList) > 0:
+            self._runDeclat(newList)
 
     def startMine(self):
-        self._startTime =  _ab._time.time()
+        """Frequent pattern mining process will start from here"""
+
+        self._startTime = _ab._time.time()
+        self._Database = []
+        self._finalPatterns = {}
+        self._diffSets = {}
+        self._trans_set = set()
+        if self._iFile is None:
+            raise Exception("Please enter the file path or file name:")
+        if self._minSup is None:
+            raise Exception("Please enter the Minimum Support")
         self._creatingItemSets()
+        #print(len(self._Database))
         self._minSup = self._convert(self._minSup)
-        self._itemSup = self._convert(self._itemSup)
-        self._faultTolerance = int(self._faultTolerance)
-        sortedList = self._oneLengthItems()
-        self._checkMaximal(sortedList)
-        self._maxFTP(sortedList)
-        self.__endTime = _ab._time.time()
-        self.__memoryUSS = float()
-        self.__memoryRSS = float()
+        uniqueItemList = []
+        uniqueItemList = self._getUniqueItemList()
+        self._runDeclat(uniqueItemList)
+        self._finalPatterns = self._diffSets
+        #print(len(self._finalPatterns), len(uniqueItemList))
+        self._endTime = _ab._time.time()
         process = _ab._psutil.Process(_ab._os.getpid())
-        self.__memoryUSS = process.memory_full_info().uss
-        self.__memoryRSS = process.memory_info().rss
+        self._memoryUSS = float()
+        self._memoryRSS = float()
+        self._memoryUSS = process.memory_full_info().uss
+        self._memoryRSS = process.memory_info().rss
+        print("Frequent patterns were generated successfully using ECLAT Diffset algorithm")
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
         :return: returning USS memory consumed by the mining process
 
         :rtype: float
         """
 
-        return self.__memoryUSS
+        return self._memoryUSS
 
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the mining process will be retrieved from this function
 
         :return: returning RSS memory consumed by the mining process
 
         :rtype: float
         """
 
-        return self.__memoryRSS
+        return self._memoryRSS
 
     def getRuntime(self):
         """Calculating the total amount of runtime taken by the mining process
 
-
         :return: returning total amount of runtime taken by the mining process
 
         :rtype: float
         """
 
         return self._endTime - self._startTime
 
@@ -257,66 +321,60 @@
         """Storing final frequent patterns in a dataframe
 
         :return: returning frequent patterns in a dataframe
 
         :rtype: pd.DataFrame
         """
 
-        dataframe = {}
+        dataFrame = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a.replace('\t', ' '), b])
-            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
-        return dataframe
+            data.append([a.replace('\t', ' '), b[0]])
+            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
+        return dataFrame
 
     def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
 
         :type outFile: file
         """
         self._oFile = outFile
         writer = open(self._oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            s1 = x.strip() + ":" + str(y)
-            writer.write("%s \n" % s1)
+            patternsAndSupport = x.strip() + ":" + str(y[0])
+            writer.write("%s \n" % patternsAndSupport)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
 
         :rtype: dict
         """
         return self._finalPatterns
 
     def printResults(self):
         print("Total number of Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
-        print("Total ExecutionTime in ms:", self.getRuntime())
+        print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_ab._sys.argv) == 7 or len(_ab._sys.argv) == 8:
-        if len(_ab._sys.argv) == 8:
-            _ap = maxFTP(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5], _ab._sys.argv[6], _ab._sys.argv[7])
-        if len(_ab._sys.argv) == 7:
-            _ap = maxFTP(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[6], _ab._sys.argv[6])
+    if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:
+        if len(_ab._sys.argv) == 5:
+            _ap = ECLATDiffset(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+        if len(_ab._sys.argv) == 4:
+            _ap = ECLATDiffset(_ab._sys.argv[1], _ab._sys.argv[3])
         _ap.startMine()
-        print("Total number of maximal Fault-Tolerant Frequent Patterns:", len(_ap.getPatterns()))
+        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
+        print(_ap.getPatternsAsDataFrame())
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
-        _ap = maxFTP('sample.txt', 3, 2, 1, ' ')
-        _ap.startMine()
-        print("Total number of maximal Fault-Tolerant Frequent Patterns:", len(_ap.getPatterns()))
-        _ap.save('output.txt')
-        print("Total Memory in USS:", _ap.getMemoryUSS())
-        print("Total Memory in RSS", _ap.getMemoryRSS())
-        print("Total ExecutionTime in ms:", _ap.getRuntime())
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `pami-2023.4.1/PAMI/frequentPattern/__init__.py` & `pami-2023.5.1/PAMI/frequentPattern/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/frequentPattern/basic/Apriori.py` & `pami-2023.5.1/PAMI/frequentPattern/basic/Apriori.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,133 +1,148 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# Apriori is one of the fundamental algorithm to discover frequent patterns in a transactional database. This program employs apriori property (or downward closure property) to  reduce the search space effectively. This algorithm employs breadth-first search technique to find the complete set of frequent patterns in a transactional database.
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+# **Importing this algorithm into a python program**
+# ----------------------------------------------------
+#
+#     import PAMI.frequentPattern.basic.Apriori as alg
+#
+#     obj = alg.Apriori(iFile, minSup)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
 
 from PAMI.frequentPattern.basic import abstract as _ab
 
 
 class Apriori(_ab._frequentPatterns):
     """
-        Apriori is one of the fundamental algorithm to discover frequent patterns in a transactional database.
-        This program employs apriori property (or downward closure property) to  reduce the search space effectively.
-        This algorithm employs breadth-first search technique to find the complete set of frequent patterns in a
-        transactional database.
-
-        Reference:
-        ----------
-            Agrawal, R., Imieli nski, T., Swami, A.: Mining association rules between sets of items in large databases.
+    :Description: Apriori is one of the fundamental algorithm to discover frequent patterns in a transactional database. This program employs apriori property (or downward closure property) to  reduce the search space effectively. This algorithm employs breadth-first search technique to find the complete set of frequent patterns in a transactional database.
+
+    :Reference:  Agrawal, R., Imieli nski, T., Swami, A.: Mining association rules between sets of items in large databases.
             In: SIGMOD. pp. 207216 (1993), https://doi.org/10.1145/170035.170072
 
+    :param  iFile: str :
+                   Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  minSup: int :
+                   The user can specify minSup either in count or proportion of database size. If the program detects the data type of minSup is integer, then it treats minSup is expressed in count. Otherwise, it will be treated as float.
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
+
+
+
+    :Attributes:
+
+        startTime : float
+          To record the start time of the mining process
+
+        endTime : float
+          To record the completion time of the mining process
 
-        Attributes:
-        ----------
-            iFile : str
-                Input file name or path of the input file
-            oFile : str
-                Name of the output file or the path of output file
-            minSup: float or int or str
-                The user can specify minSup either in count or proportion of database size.
-                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-            sep : str
-                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                However, the users can override their default separator.
-            startTime:float
-                To record the start time of the mining process
-            endTime:float
-                To record the completion time of the mining process
-            finalPatterns: dict
-                Storing the complete set of patterns in a dictionary variable
-            memoryUSS : float
-                To store the total amount of USS memory consumed by the program
-            memoryRSS : float
-                To store the total amount of RSS memory consumed by the program
-            Database : list
-                To store the transactions of a database in list
-
-        Methods:
-        -------
-            startMine()
-                Mining process will start from here
-            getPatterns()
-                Complete set of patterns will be retrieved with this function
-            save(oFile)
-                Complete set of frequent patterns will be loaded in to a output file
-            getPatternsAsDataFrame()
-                Complete set of frequent patterns will be loaded in to a dataframe
-            getMemoryUSS()
-                Total amount of USS memory consumed by the mining process will be retrieved from this function
-            getMemoryRSS()
-                Total amount of RSS memory consumed by the mining process will be retrieved from this function
-            getRuntime()
-                Total amount of runtime taken by the mining process will be retrieved from this function
-            candidateToFrequent(candidateList)
-                Generates frequent patterns from the candidate patterns
-            frequentToCandidate(frequentList, length)
-                Generates candidate patterns from the frequent patterns
+        finalPatterns : dict
+          Storing the complete set of patterns in a dictionary variable
 
+        memoryUSS : float
+          To store the total amount of USS memory consumed by the program
 
-        Executing the code on terminal:
-        -------------------------------
+        memoryRSS : float
+          To store the total amount of RSS memory consumed by the program
+
+        Database : list
+          To store the transactions of a database in list
+
+
+
+    **Methods to execute code on terminal**
+    ----------------------------------------------------
 
             Format:
-            ------
-                python3 Apriori.py <inputFile> <outputFile> <minSup>
+                      >>> python3 Apriori.py <inputFile> <outputFile> <minSup>
+
+            Example:
+                      >>>  python3 Apriori.py sampleDB.txt patterns.txt 10.0
+
+            .. note:: minSup will be considered in percentage of database transactions
+
 
-            Examples:
-            ---------
-                python3 Apriori.py sampleDB.txt patterns.txt 10.0   (minSup will be considered in times of minSup and count of database transactions)
+    **Importing this algorithm into a python program**
+    ----------------------------------------------------
 
-                python3 Apriori.py sampleDB.txt patterns.txt 10     (minSup will be considered in support count or frequency)
+    .. code-block:: python
 
+             import PAMI.frequentPattern.basic.Apriori as alg
 
-        Sample run of the importing code:
-        ---------------------------------
+             obj = alg.Apriori(iFile, minSup)
 
-            import PAMI.frequentPattern.basic.Apriori as alg
+             obj.startMine()
 
-            obj = alg.Apriori(iFile, minSup)
+             frequentPatterns = obj.getPatterns()
 
-            obj.startMine()
+             print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-            frequentPatterns = obj.getPatterns()
+             obj.savePatterns(oFile)
 
-            print("Total number of Frequent Patterns:", len(frequentPatterns))
+             Df = obj.getPatternInDataFrame()
 
-            obj.save(oFile)
+             memUSS = obj.getMemoryUSS()
 
-            Df = obj.getPatternInDataFrame()
+             print("Total Memory in USS:", memUSS)
 
-            memUSS = obj.getMemoryUSS()
+             memRSS = obj.getMemoryRSS()
 
-            print("Total Memory in USS:", memUSS)
+             print("Total Memory in RSS", memRSS)
 
-            memRSS = obj.getMemoryRSS()
+             run = obj.getRuntime()
 
-            print("Total Memory in RSS", memRSS)
+             print("Total ExecutionTime in seconds:", run)
 
-            run = obj.getRuntime()
 
-            print("Total ExecutionTime in seconds:", run)
+    **Credits:**
+    -------------
 
-        Credits:
-        --------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+             The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
 
     """
 
     _minSup = float()
     _startTime = float()
     _endTime = float()
     _finalPatterns = {}
```

### Comparing `pami-2023.4.1/PAMI/frequentPattern/basic/ECLAT.py` & `pami-2023.5.1/PAMI/frequentPattern/basic/ECLAT.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,115 +1,125 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# ECLAT is one of the fundamental algorithm to discover frequent patterns in a transactional database.
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+# **Importing this algorithm into a python program**
+# ------------------------------------------------------------------
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     import PAMI.frequentPattern.basic.ECLAT as alg
+#
+#     obj = alg.ECLAT(iFile, minSup)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
 
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
 
 from PAMI.frequentPattern.basic import abstract as _ab
 
 
 class ECLAT(_ab._frequentPatterns):
-    """ ECLAT is one of the fundamental algorithm to discover frequent patterns in a transactional database.
-        This program employs downward closure property to  reduce the search space effectively.
-        This algorithm employs depth-first search technique to find the complete set of frequent patterns in a
-        transactional database.
-
-        Reference:
-        ----------
-            Mohammed Javeed Zaki: Scalable Algorithms for Association Mining. IEEE Trans. Knowl. Data Eng. 12(3):
+    """
+
+    :Description: ECLAT is one of the fundamental algorithm to discover frequent patterns in a transactional database.
+
+    :Reference:  Mohammed Javeed Zaki: Scalable Algorithms for Association Mining. IEEE Trans. Knowl. Data Eng. 12(3):
             372-390 (2000), https://ieeexplore.ieee.org/document/846291
 
-        Attributes:
-        ----------
-            iFile : str
-                Input file name or path of the input file
-            minSup: float or int or str
-                The user can specify minSup either in count or proportion of database size.
-                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-            sep : str
-                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                However, the users can override their default separator.
-            oFile : str
-                Name of the output file or the path of the output file
-            startTime:float
-                To record the start time of the mining process
-            endTime:float
-                To record the completion time of the mining process
-            finalPatterns: dict
-                Storing the complete set of patterns in a dictionary variable
-            memoryUSS : float
-                To store the total amount of USS memory consumed by the program
-            memoryRSS : float
-                To store the total amount of RSS memory consumed by the program
-
-        Methods:
-        -------
-            startMine()
-                Mining process will start from here
-            getPatterns()
-                Complete set of patterns will be retrieved with this function
-            save(oFile)
-                Complete set of frequent patterns will be loaded in to a output file
-            getPatternsAsDataFrame()
-                Complete set of frequent patterns will be loaded in to a dataframe
-            getMemoryUSS()
-                Total amount of USS memory consumed by the mining process will be retrieved from this function
-            getMemoryRSS()
-                Total amount of RSS memory consumed by the mining process will be retrieved from this function
-            getRuntime()
-                Total amount of runtime taken by the mining process will be retrieved from this function
-            creatingItemSets()
-                Scans the dataset or dataframes and stores in list format
-            frequentOneItem()
-                Generates one frequent patterns
-            ECLATGeneration(candidateList)
-                It will generate the combinations of frequent items
-            generateFrequentPatterns(tidList)
-                It will generate the combinations of frequent items from a list of items
+    :param  iFile: str :
+                   Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  minSup: int or float or str :
+                   The user can specify minSup either in count or proportion of database size. If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
+
+
+
+    :Attributes:
+
+        startTime : float
+          To record the start time of the mining process
+
+        endTime : float
+          To record the completion time of the mining process
 
-        Executing the code on terminal:
-        -------------------------------
+        finalPatterns : dict
+          Storing the complete set of patterns in a dictionary variable
+
+        memoryUSS : float
+          To store the total amount of USS memory consumed by the program
+
+        memoryRSS : float
+          To store the total amount of RSS memory consumed by the program
+
+        Database : list
+          To store the transactions of a database in list
+
+
+    **Methods to execute code on terminal**
+    ------------------------------------------
 
             Format:
-            ------
-                python3 ECLAT.py <inputFile> <outputFile> <minSup>
+                      >>> python3 ECLAT.py <inputFile> <outputFile> <minSup>
 
-            Examples:
-            ---------
-                python3 ECLAT.py sampleDB.txt patterns.txt 10.0   (minSup will be considered in times of minSup and count of database transactions)
+            Example:
+                      >>>  python3 ECLAT.py sampleDB.txt patterns.txt 10.0
 
-                python3 ECLAT.py sampleDB.txt patterns.txt 10     (minSup will be considered in support count or frequency)
+            .. note:: minSup will be considered in percentage of database transactions
 
 
-        Sample run of the importing code:
-        ---------------------------------
+    **Importing this algorithm into a python program**
+    ------------------------------------------------------------------
+    .. code-block:: python
 
             import PAMI.frequentPattern.basic.ECLAT as alg
 
             obj = alg.ECLAT(iFile, minSup)
 
             obj.startMine()
 
             frequentPatterns = obj.getPatterns()
 
             print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-            obj.save(oFile)
+            obj.savePatterns(oFile)
 
             Df = obj.getPatternInDataFrame()
 
             memUSS = obj.getMemoryUSS()
 
             print("Total Memory in USS:", memUSS)
 
@@ -117,17 +127,19 @@
 
             print("Total Memory in RSS", memRSS)
 
             run = obj.getRuntime()
 
             print("Total ExecutionTime in seconds:", run)
 
-        Credits:
-        --------
-            The complete program was written by Kundai  under the supervision of Professor Rage Uday Kiran.
+
+    **Credits:**
+    ----------------------
+
+             The complete program was written by Kundai  under the supervision of Professor Rage Uday Kiran.
 
     """
 
     _minSup = float()
     _startTime = float()
     _endTime = float()
     _finalPatterns = {}
```

### Comparing `pami-2023.4.1/PAMI/frequentPattern/basic/ECLATDiffset.py` & `pami-2023.5.1/PAMI/frequentPattern/basic/ECLATbitset.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,362 +1,380 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+#  ECLATbitset is one of the fundamental algorithm to discover frequent patterns in a transactional database.
+#
+#  **Importing this algorithm into a python program**
+#  ---------------------------------------------------------
+#
+#     import PAMI.frequentPattern.basic.ECLATbitset as alg
+#
+#     obj = alg.ECLATbitset(iFile, minSup)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+#
+#
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-# from abstract import *
 
-from PAMI.frequentPattern.basic import abstract as _ab
 
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
 
-class ECLATDiffset(_ab._frequentPatterns):
+
+from PAMI.frequentPattern.basic import abstract as _ab
+
+class ECLATbitset(_ab._frequentPatterns):
     """
-        It uses diffset to extract the frequent patterns.
+    :Description:  ECLATbitset is one of the fundamental algorithm to discover frequent patterns in a transactional database.
+
+    :Reference:  Mohammed Javeed Zaki: Scalable Algorithms for Association Mining. IEEE Trans. Knowl. Data Eng. 12(3):
+            372-390 (2000), https://ieeexplore.ieee.org/document/846291
+
+    :param  iFile: str :
+                   Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  minSup: int or float or str :
+                   The user can specify minSup either in count or proportion of database size. If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
+
 
-        Reference:
-        ----------
-            KDD '03: Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining
-            August 2003 Pages 326335 https://doi.org/10.1145/956750.956788
-
-        Attributes:
-        ----------
-            iFile : str
-                Input file name or path of the input file
-            minSup: float or int or str
-                The user can specify minSup either in count or proportion of database size.
-                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-            sep : str
-                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                However, the users can override their default separator.
-            oFile : str
-                Name of the output file or the path of the output file
-            startTime:float
-                To record the start time of the mining process
-            endTime:float
-                To record the completion time of the mining process
-            finalPatterns: dict
-                Storing the complete set of patterns in a dictionary variable
-            memoryUSS : float
-                To store the total amount of USS memory consumed by the program
-            memoryRSS : float
-                To store the total amount of RSS memory consumed by the program
-
-        Methods:
-        -------
-            startMine()
-                Mining process will start from here
-            getPatterns()
-                Complete set of patterns will be retrieved with this function
-            save(oFile)
-                Complete set of frequent patterns will be loaded in to a output file
-            getPatternsAsDataFrame()
-                Complete set of frequent patterns will be loaded in to a dataframe
-            getMemoryUSS()
-                Total amount of USS memory consumed by the mining process will be retrieved from this function
-            getMemoryRSS()
-                Total amount of RSS memory consumed by the mining process will be retrieved from this function
-            getRuntime()
-                Total amount of runtime taken by the mining process will be retrieved from this function
-            creatingItemSets()
-                Scans the dataset or dataframes and stores in list format
-            frequentOneItem()
-                Generates one frequent patterns
-            ECLATGeneration(candidateList)
-                It will generate the combinations of frequent items
-            generateFrequentPatterns(tidList)
-                It will generate the combinations of frequent items from a list of items
 
-        Executing the code on terminal:
-        -------------------------------
+    :Attributes:
+
+        startTime : float
+          To record the start time of the mining process
+
+        endTime : float
+          To record the completion time of the mining process
+
+        finalPatterns : dict
+          Storing the complete set of patterns in a dictionary variable
+
+        memoryUSS : float
+          To store the total amount of USS memory consumed by the program
+
+        memoryRSS : float
+          To store the total amount of RSS memory consumed by the program
+
+        Database : list
+          To store the transactions of a database in list
+
+
+    **Methods to execute code on terminal**
+    ----------------------------------------
 
             Format:
-            ------
-            python3 ECLATDiffset.py <inputFile> <outputFile> <minSup>
+                      >>> python3 ECLATDiffset.py <inputFile> <outputFile> <minSup>
+
+            Example:
+                      >>> python3 ECLATDiffset.py sampleDB.txt patterns.txt 10.0
 
-            Examples:
-            ---------
-            python3 ECLATDiffset.py sampleDB.txt patterns.txt 10.0   (minSup will be considered in times of minSup and count of database transactions)
+            .. note:: minSup will be considered in percentage of database transactions
 
-            python3 ECLATDiffset.py sampleDB.txt patterns.txt 10     (minSup will be considered in support count or frequency)
 
+    **Importing this algorithm into a python program**
+    ---------------------------------------------------------
+    .. code-block:: python
 
-        Sample run of the importing code:
-        ---------------------------------
+                import PAMI.frequentPattern.basic.ECLATbitset as alg
 
-            import PAMI.frequentPattern.basic.ECLATDiffset as alg
+                obj = alg.ECLATbitset(iFile, minSup)
 
-            obj = alg.ECLAT(iFile, minSup)
+                obj.startMine()
 
-            obj.startMine()
+                frequentPatterns = obj.getPatterns()
 
-            frequentPatterns = obj.getPatterns()
+                print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-            print("Total number of Frequent Patterns:", len(frequentPatterns))
+                obj.savePatterns(oFile)
 
-            obj.save(oFile)
+                Df = obj.getPatternInDataFrame()
 
-            Df = obj.getPatternInDataFrame()
+                memUSS = obj.getMemoryUSS()
 
-            memUSS = obj.getMemoryUSS()
+                print("Total Memory in USS:", memUSS)
 
-            print("Total Memory in USS:", memUSS)
+                memRSS = obj.getMemoryRSS()
 
-            memRSS = obj.getMemoryRSS()
+                print("Total Memory in RSS", memRSS)
 
-            print("Total Memory in RSS", memRSS)
+                run = obj.getRuntime()
 
-            run = obj.getRuntime()
+                print("Total ExecutionTime in seconds:", run)
 
-            print("Total ExecutionTime in seconds:", run)
+    **Credits:**
+    -------------------
 
-        Credits:
-        --------
-            The complete program was written by Kundai under the supervision of Professor Rage Uday Kiran.
+               The complete program was written by Yudai Masu under the supervision of Professor Rage Uday Kiran.
 
     """
 
-    _minSup = float()
     _startTime = float()
     _endTime = float()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
+    _minSup = str()
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
-    _diffSets = {}
-    _trans_set = set()
+    _mapSupport = {}
+    _lno = 0
+
+
+    def _convert(self, value):
+        """
+        To convert the user specified minSup value
+        :param value: user specified minSup value
+        :return: converted type
+        """
+        if type(value) is int:
+            value = int(value)
+        if type(value) is float:
+            value = (len(self._Database) * value)
+        if type(value) is str:
+            if '.' in value:
+                value = float(value)
+                value = (len(self._Database) * value)
+            else:
+                value = int(value)
+        return value
 
     def _creatingItemSets(self):
         """
             Storing the complete transactions of the database/input file in a database variable
-
         """
         self._Database = []
+        self._mapSupport = {}
         if isinstance(self._iFile, _ab._pd.DataFrame):
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
                 self._Database = self._iFile['Transactions'].tolist()
+
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
                     self._Database.append(temp)
             else:
                 try:
-                    with open(self._iFile, 'r', encoding='utf-8') as f:
+                    with open(self._iFile, 'r') as f:
                         for line in f:
-                            line.strip()
-                            temp = [i.rstrip() for i in line.split(self._sep)]
-                            temp = [x for x in temp if x]
-                            self._Database.append(temp)
+                            self._lno += 1
+                            splitter = [i.rstrip() for i in line.split(self._sep)]
+                            splitter = [x for x in splitter if x]
+                            self._Database.append(splitter)
                 except IOError:
                     print("File Not Found")
-                    quit()
+        self._minSup = self._convert(self._minSup)
 
-    def _convert(self, value):
+    def creatingFrequentItems(self):
         """
-        To convert the user specified minSup value
+        This function creates frequent items from _database.
+        :return: frequentTidData that stores frequent items and their tid list.
+        """
+        tidData = {}
+        self._lno = 0
+        for transaction in self._Database:
+            self._lno = self._lno + 1
+            for item in transaction:
+                if item not in tidData:
+                    tidData[item] = [self._lno]
+                else:
+                    tidData[item].append(self._lno)
+        frequentTidData = {k: v for k, v in tidData.items() if len(v) >= self._minSup}
+        frequentTidData = dict(sorted(frequentTidData.items(), reverse=True, key=lambda x: len(x[1])))
+        return frequentTidData
 
-        :param value: user specified minSup value
+    def tidToBitset(self,itemset):
+        """
+        This function converts tid list to bitset.
+        :param itemset:
+        :return:
+        """
+        bitset = {}
 
-        :return: converted type
+        for k,v in itemset.items():
+            bitset[k] = 0b1
+            bitset[k] = (bitset[k] << int(v[0])) | 0b1
+            for i in range(1,len(v)):
+                diff = int(v[i]) - int(v[i-1])
+                bitset[k] = (bitset[k] << diff) | 0b1
+            bitset[k] = (bitset[k] << (self._lno - int(v[i])))
+        return bitset
+
+    def genPatterns(self,prefix,tidData):
         """
-        if type(value) is int:
-            value = int(value)
-        if type(value) is float:
-            value = (len(self._Database) * value)
-        if type(value) is str:
-            if '.' in value:
-                value = float(value)
-                value = (len(self._Database) * value)
-            else:
-                value = int(value)
-        return value
+        This function generate frequent pattern about prefix.
+        :param prefix: String
+        :param tidData: list
+        :return:
+        """
+        # variables to store frequent item set and
+        itemset = prefix[0]
 
-    def _getUniqueItemList(self):
+        # Get the length of tidData
+        length = len(tidData)
 
-        # tidSets will store all the initial tids
-        tidSets = {}
-        # uniqueItem will store all frequent 1 items
-        uniqueItem = []
-        for line in self._Database:
-                transNum = 0
-                # Database = [set([i.rstrip() for i in transaction.split('\t')]) for transaction in f]
-                for transaction in self._Database:
-                    transNum += 1
-                    self._trans_set.add(transNum)
-                    for item in transaction:
-                        if item in tidSets:
-                            tidSets[item].add(transNum)
-                        else:
-                            tidSets[item] = {transNum}
-        for key, value in tidSets.items():
-            supp = len(value)
-            if supp >= self._minSup:
-                self._diffSets[key] = [supp, self._trans_set.difference(value)]
-                uniqueItem.append(key)
-        # for x, y in self._diffSets.items():
-        #     print(x, y)
-        uniqueItem.sort()
-        # print()
-        return uniqueItem
-
-    def _runDeclat(self, candidateList):
-
-        newList = []
-        for i in range(0, len(candidateList)):
-            item1 = candidateList[i]
-            iList = item1.split()
-            for j in range(i + 1, len(candidateList)):
-                item2 = candidateList[j]
-                jList = item2.split()
-                if iList[:-1] == jList[:-1]:
-                    unionDiffSet = self._diffSets[item2][1].difference(self._diffSets[item1][1])
-                    unionSup = self._diffSets[item1][0] - len(unionDiffSet)
-                    if unionSup >= self._minSup:
-                        newKey = item1 + "\t" + jList[-1]
-                        self._diffSets[newKey] = [unionSup, unionDiffSet]
-                        newList.append(newKey)
-                    else: 
-                        break
+        for i in range(length):
+            #tid = prefix[1].intersection(tidData[i][1])
+            tid = prefix[1] & tidData[i][1]
+            count = bin(tid).count("1") - 1
+            #tidLength = len(tid)
+            if count >= self._minSup:
+                frequentItemset = itemset + '\t' + tidData[i][0]
+                self._finalPatterns[frequentItemset] = count
+                self.genPatterns((frequentItemset,tid),tidData[i+1:length])
 
-        if len(newList) > 0:
-            self._runDeclat(newList)
+    def genAllFrequentPatterns(self,frequentItems):
+        """
+        This function generates all frequent patterns.
+        :param frequentItems: frequent items
+        :return:
+        """
+        tidData = list(frequentItems.items())
+        length = len(tidData)
+        for i in range(length):
+            #print(i,tidData[i][0])
+            self.genPatterns(tidData[i],tidData[i+1:length])
 
     def startMine(self):
-        """Frequent pattern mining process will start from here"""
+        """Frequent pattern mining process will start from here
+                We start with the scanning the itemSets and store the bitsets respectively.
+                We form the combinations of single items and  check with minSup condition to check the frequency of patterns
+                """
 
         self._startTime = _ab._time.time()
-        self._Database = []
-        self._finalPatterns = {}
-        self._diffSets = {}
-        self._trans_set = set()
         if self._iFile is None:
             raise Exception("Please enter the file path or file name:")
         if self._minSup is None:
             raise Exception("Please enter the Minimum Support")
+
         self._creatingItemSets()
-        #print(len(self._Database))
-        self._minSup = self._convert(self._minSup)
-        uniqueItemList = []
-        uniqueItemList = self._getUniqueItemList()
-        self._runDeclat(uniqueItemList)
-        self._finalPatterns = self._diffSets
-        #print(len(self._finalPatterns), len(uniqueItemList))
+        frequentItems = self.creatingFrequentItems()
+        self._finalPatterns = {k: len(v) for k, v in frequentItems.items()}
+        frequentItemsBitset = self.tidToBitset(frequentItems)
+        self.genAllFrequentPatterns(frequentItemsBitset)
         self._endTime = _ab._time.time()
         process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryUSS = float()
         self._memoryRSS = float()
         self._memoryUSS = process.memory_full_info().uss
         self._memoryRSS = process.memory_info().rss
-        print("Frequent patterns were generated successfully using ECLAT Diffset algorithm")
+        print("Frequent patterns were generated successfully using Eclat_bitset algorithm")
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
-
         :return: returning USS memory consumed by the mining process
-
         :rtype: float
         """
 
         return self._memoryUSS
 
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the mining process will be retrieved from this function
-
         :return: returning RSS memory consumed by the mining process
-
         :rtype: float
         """
 
         return self._memoryRSS
 
     def getRuntime(self):
         """Calculating the total amount of runtime taken by the mining process
-
         :return: returning total amount of runtime taken by the mining process
-
         :rtype: float
         """
 
         return self._endTime - self._startTime
 
     def getPatternsAsDataFrame(self):
         """Storing final frequent patterns in a dataframe
-
         :return: returning frequent patterns in a dataframe
-
         :rtype: pd.DataFrame
         """
 
         dataFrame = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a.replace('\t', ' '), b[0]])
+            data.append([a.replace('\t', ' '), b])
             dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
         return dataFrame
 
     def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
-
         :param outFile: name of the output file
-
         :type outFile: file
         """
         self._oFile = outFile
         writer = open(self._oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            patternsAndSupport = x.strip() + ":" + str(y[0])
+            patternsAndSupport = x.strip() + ":" + str(y)
             writer.write("%s \n" % patternsAndSupport)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
-
         :return: returning frequent patterns
-
         :rtype: dict
         """
         return self._finalPatterns
 
     def printResults(self):
         print("Total number of Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
-
-if __name__ == "__main__":
+if __name__=="__main__":
     _ap = str()
     if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:
         if len(_ab._sys.argv) == 5:
-            _ap = ECLATDiffset(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+            _ap = ECLATbitset(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
         if len(_ab._sys.argv) == 4:
-            _ap = ECLATDiffset(_ab._sys.argv[1], _ab._sys.argv[3])
+            _ap = ECLATbitset(_ab._sys.argv[1], _ab._sys.argv[3])
         _ap.startMine()
         print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
-        print(_ap.getPatternsAsDataFrame())
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
         print("Error! The number of input parameters do not match the total number of parameters provided")
-
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `pami-2023.4.1/PAMI/frequentPattern/basic/ECLATbitset.py` & `pami-2023.5.1/PAMI/frequentPattern/pyspark/parallelECLAT.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,245 +1,169 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# Parallel Eclat is an algorithm to discover frequent patterns in a transactional database. This program employs parallel apriori property (or downward closure property) to  reduce the search space effectively.
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
+# **Importing this algorithm into a python program**
+#  ----------------------------------------------------
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     import PAMI.frequentPattern.pyspark.parallelECLAT as alg
+#
+#     obj = alg.parallelECLAT(iFile, minSup, numWorkers)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+#
+#
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
+
+
+
+
 
+# from pyspark import SparkConf, SparkContext
+# import abstract as _ab
+from PAMI.frequentPattern.pyspark import abstract as _ab
 
-from PAMI.frequentPattern.basic import abstract as _ab
 
-class ECLATbitset(_ab._frequentPatterns):
+class parallelECLAT(_ab._frequentPatterns):
     """
-        ECLATbitset is one of the fundamental algorithm to discover frequent patterns in a transactional database.
 
-    Reference:
-    ----------
+    :Description: Parallel Eclat is an algorithm to discover frequent patterns in a transactional database. This program employs parallel apriori property (or downward closure property) to  reduce the search space effectively.
 
+    :Reference:
+
+    :param  iFile: str :
+                   Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  minSup: int :
+                   The user can specify minSup either in count or proportion of database size. If the program detects the data type of minSup is integer, then it treats minSup is expressed in count. Otherwise, it will be treated as float.
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
+    :param  numPartitions: int :
+                   The number of partitions. On each worker node, an executor process is started and this process performs processing.The processing unit of worker node is partition
+
+
+    :Attributes:
+
+        startTime : float
+          To record the start time of the mining process
+
+        endTime : float
+          To record the completion time of the mining process
+
+        finalPatterns : dict
+          Storing the complete set of patterns in a dictionary variable
+
+        memoryUSS : float
+          To store the total amount of USS memory consumed by the program
+
+        memoryRSS : float
+          To store the total amount of RSS memory consumed by the program
+
+        lno : int
+                the number of transactions
+
+    
+    **Methods to execute code on terminal**
+    ----------------------------------------------------
+    
+            Format:
+                      >>> python3 parallelECLAT.py <inputFile> <outputFile> <minSup> <numWorkers>
+    
+            Example:
+                      >>> python3 parallelECLAT.py sampleDB.txt patterns.txt 10.0 3
+    
+            .. note:: minSup will be considered in percentage of database transactions
+    
+    
+    **Importing this algorithm into a python program**
+    ----------------------------------------------------
+    .. code-block:: python
+    
+                import PAMI.frequentPattern.pyspark.parallelECLAT as alg
+    
+                obj = alg.parallelECLAT(iFile, minSup, numWorkers)
+    
+                obj.startMine()
+    
+                frequentPatterns = obj.getPatterns()
+    
+                print("Total number of Frequent Patterns:", len(frequentPatterns))
+    
+                obj.savePatterns(oFile)
+    
+                Df = obj.getPatternInDataFrame()
+    
+                memUSS = obj.getMemoryUSS()
+    
+                print("Total Memory in USS:", memUSS)
+    
+                memRSS = obj.getMemoryRSS()
+    
+                print("Total Memory in RSS", memRSS)
+    
+                run = obj.getRuntime()
+    
+                print("Total ExecutionTime in seconds:", run)
+    
+    
+    **Credits:**
+    ----------------------------------------------------
+             The complete program was written by Yudai Masu under the supervision of Professor Rage Uday Kiran.
 
-    Attributes:
-    -----------
-        self.iFile : str
-            Input file name or path of the input file
-        minSup: float or int or str
-            The user can specify minSup either in count or proportion of database size.
-            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-        sep : str
-            This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
-            However, the users can override their default separator.
-        self.oFile : str
-            Name of the output file or path of the output file
-        self.startTime:float
-            To record the start time of the mining process
-        self.endTime:float
-            To record the completion time of the mining process
-        self.finalPatterns: dict
-            Storing the complete set of patterns in a dictionary variable
-        self.memoryUSS : float
-            To store the total amount of USS memory consumed by the program
-        self.memoryRSS : float
-            To store the total amount of RSS memory consumed by the program
-        self.Database : list
-            To store the complete set of transactions available in the input database/file
-    Methods:
-    -------
-        startMine()
-            Mining process will start from here
-        getPatterns()
-            Complete set of patterns will be retrieved with this function
-        save(oFile)
-            Complete set of frequent patterns will be loaded in to a output file
-        getPatternsAsDataFrame()
-            Complete set of frequent patterns will be loaded in to a dataframe
-        getMemoryUSS()
-            Total amount of USS memory consumed by the mining process will be retrieved from this function
-        getMemoryRSS()
-            Total amount of RSS memory consumed by the mining process will be retrieved from this function
-        getRuntime()
-            Total amount of runtime taken by the mining process will be retrieved from this function
-        createFrequentItems()
-            Generate frequent items
-        tidToBitset(itemset)
-            Convert tid list to bit set
-        genPatterns(prefix, tidData)
-            Generate frequent patterns
-        genAllFrequentPatterns(frequentItems)
-            Generate all frequent patterns
     """
 
+    _minSup = float()
+    _numPartitions = int()
     _startTime = float()
     _endTime = float()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
-    _minSup = str()
     _memoryUSS = float()
     _memoryRSS = float()
-    _Database = []
-    _mapSupport = {}
-    _lno = 0
+    _lno = int()
 
-
-    def _convert(self, value):
-        """
-        To convert the user specified minSup value
-        :param value: user specified minSup value
-        :return: converted type
-        """
-        if type(value) is int:
-            value = int(value)
-        if type(value) is float:
-            value = (len(self._Database) * value)
-        if type(value) is str:
-            if '.' in value:
-                value = float(value)
-                value = (len(self._Database) * value)
-            else:
-                value = int(value)
-        return value
-
-    def _creatingItemSets(self):
-        """
-            Storing the complete transactions of the database/input file in a database variable
-        """
-        self._Database = []
-        self._mapSupport = {}
-        if isinstance(self._iFile, _ab._pd.DataFrame):
-            if self._iFile.empty:
-                print("its empty..")
-            i = self._iFile.columns.values.tolist()
-            if 'Transactions' in i:
-                self._Database = self._iFile['Transactions'].tolist()
-
-        if isinstance(self._iFile, str):
-            if _ab._validators.url(self._iFile):
-                data = _ab._urlopen(self._iFile)
-                for line in data:
-                    line.strip()
-                    line = line.decode("utf-8")
-                    temp = [i.rstrip() for i in line.split(self._sep)]
-                    temp = [x for x in temp if x]
-                    self._Database.append(temp)
-            else:
-                try:
-                    with open(self._iFile, 'r') as f:
-                        for line in f:
-                            self._lno += 1
-                            splitter = [i.rstrip() for i in line.split(self._sep)]
-                            splitter = [x for x in splitter if x]
-                            self._Database.append(splitter)
-                except IOError:
-                    print("File Not Found")
-        self._minSup = self._convert(self._minSup)
-
-    def creatingFrequentItems(self):
-        """
-        This function creates frequent items from _database.
-        :return: frequentTidData that stores frequent items and their tid list.
-        """
-        tidData = {}
-        self._lno = 0
-        for transaction in self._Database:
-            self._lno = self._lno + 1
-            for item in transaction:
-                if item not in tidData:
-                    tidData[item] = [self._lno]
-                else:
-                    tidData[item].append(self._lno)
-        frequentTidData = {k: v for k, v in tidData.items() if len(v) >= self._minSup}
-        frequentTidData = dict(sorted(frequentTidData.items(), reverse=True, key=lambda x: len(x[1])))
-        return frequentTidData
-
-    def tidToBitset(self,itemset):
-        """
-        This function converts tid list to bitset.
-        :param itemset:
-        :return:
-        """
-        bitset = {}
-
-        for k,v in itemset.items():
-            bitset[k] = 0b1
-            bitset[k] = (bitset[k] << int(v[0])) | 0b1
-            for i in range(1,len(v)):
-                diff = int(v[i]) - int(v[i-1])
-                bitset[k] = (bitset[k] << diff) | 0b1
-            bitset[k] = (bitset[k] << (self._lno - int(v[i])))
-        return bitset
-
-    def genPatterns(self,prefix,tidData):
-        """
-        This function generate frequent pattern about prefix.
-        :param prefix: String
-        :param tidData: list
-        :return:
-        """
-        # variables to store frequent item set and
-        itemset = prefix[0]
-
-        # Get the length of tidData
-        length = len(tidData)
-
-        for i in range(length):
-            #tid = prefix[1].intersection(tidData[i][1])
-            tid = prefix[1] & tidData[i][1]
-            count = bin(tid).count("1") - 1
-            #tidLength = len(tid)
-            if count >= self._minSup:
-                frequentItemset = itemset + '\t' + tidData[i][0]
-                self._finalPatterns[frequentItemset] = count
-                self.genPatterns((frequentItemset,tid),tidData[i+1:length])
-
-    def genAllFrequentPatterns(self,frequentItems):
-        """
-        This function generates all frequent patterns.
-        :param frequentItems: frequent items
-        :return:
-        """
-        tidData = list(frequentItems.items())
-        length = len(tidData)
-        for i in range(length):
-            #print(i,tidData[i][0])
-            self.genPatterns(tidData[i],tidData[i+1:length])
-
-    def startMine(self):
-        """Frequent pattern mining process will start from here
-                We start with the scanning the itemSets and store the bitsets respectively.
-                We form the combinations of single items and  check with minSup condition to check the frequency of patterns
-                """
-
-        self._startTime = _ab._time.time()
-        if self._iFile is None:
-            raise Exception("Please enter the file path or file name:")
-        if self._minSup is None:
-            raise Exception("Please enter the Minimum Support")
-
-        self._creatingItemSets()
-        frequentItems = self.creatingFrequentItems()
-        self._finalPatterns = {k: len(v) for k, v in frequentItems.items()}
-        frequentItemsBitset = self.tidToBitset(frequentItems)
-        self.genAllFrequentPatterns(frequentItemsBitset)
-        self._endTime = _ab._time.time()
-        process = _ab._psutil.Process(_ab._os.getpid())
-        self._memoryUSS = float()
-        self._memoryRSS = float()
-        self._memoryUSS = process.memory_full_info().uss
-        self._memoryRSS = process.memory_info().rss
-        print("Frequent patterns were generated successfully using Eclat_bitset algorithm")
+    def __init__(self, iFile, minSup, numWorkers, sep='\t'):
+        super().__init__(iFile, minSup, int(numWorkers), sep)
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
         :return: returning USS memory consumed by the mining process
         :rtype: float
         """
 
@@ -266,50 +190,135 @@
         :return: returning frequent patterns in a dataframe
         :rtype: pd.DataFrame
         """
 
         dataFrame = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a.replace('\t', ' '), b])
+            data.append([a, b])
             dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
         return dataFrame
 
-    def save(self, outFile):
-        """Complete set of frequent patterns will be loaded in to a output file
+    def savePatterns(self, outFile):
+        """
+        Complete set of frequent patterns will be loaded in to a output file
         :param outFile: name of the output file
         :type outFile: file
         """
         self._oFile = outFile
         writer = open(self._oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            patternsAndSupport = x.strip() + ":" + str(y)
-            writer.write("%s \n" % patternsAndSupport)
+            s1 = x + ":" + str(y)
+            writer.write("%s \n" % s1)
 
     def getPatterns(self):
-        """ Function to send the set of frequent patterns after completion of the mining process
+        """
+        Function to send the set of frequent patterns after completion of the mining process
         :return: returning frequent patterns
         :rtype: dict
         """
         return self._finalPatterns
 
-    def printResults(self):
-        print("Total number of Frequent Patterns:", len(self.getPatterns()))
-        print("Total Memory in USS:", self.getMemoryUSS())
-        print("Total Memory in RSS", self.getMemoryRSS())
-        print("Total ExecutionTime in ms:",  self.getRuntime())
+    def _genPatterns(self, suffix, pattern, data):
+        freqPatterns = {}
+        index = data.index(suffix)
+        for i in range(index + 1, len(data)):
+            tid = pattern[1].intersection(data[i][1])
+            if len(tid) >= self._minSup:
+                freqPattern = pattern[0] + ' ' + data[i][0]
+                freqPatterns[freqPattern] = len(tid)
+                freqPatterns.update(self._genPatterns(data[i], (freqPattern, tid), data))
+        return freqPatterns
+
+    def _convert(self, value):
+        """
+        To convert the user specified minSup value
+        :param value: user specified minSup value
+        :return: converted type
+        """
+        print(value, type(value))
+        if type(value) is int:
+            value = int(value)
+        elif type(value) is float:
+            value = (self._lno * value)
+        elif type(value) is str:
+            if '.' in value:
+                value = float(value)
+                value = (self._lno * value)
+            else:
+                value = int(value)
+        else:
+            print("None")
+        print(type(value), value)
+        return value
+
+    def startMine(self):
+        """
+        Frequent pattern mining process will start from here
+        """
+
+        self._startTime = _ab._time.time()
+        conf = SparkConf().setAppName("Parallel ECLAT").setMaster("local[*]")
+        sc = SparkContext(conf=conf)
+
+        data = sc.textFile(self._iFile, self._numPartitions) \
+            .map(lambda line: [int(y) for y in line.rstrip().split(self._sep)]).persist()
+        self._lno = data.count()
+        self._minSup = self._convert(self._minSup)
+
+        frequentItems = None
+        if 'transactional' in self._iFile:
+            frequentItems = data.zipWithIndex() \
+                .flatMap(lambda x: [(str(item), x[1]) for item in x[0]]) \
+                .groupByKey() \
+                .filter(lambda x: len(x[1]) >= self._minSup) \
+                .sortBy(lambda x: len(x[1])) \
+                .mapValues(set) \
+                .persist()
+            data.unpersist()
+        elif 'temporal' in self._iFile:
+            frequentItems = data.flatMap(lambda trans: [(str(item), trans[0]) for item in trans[1:]]) \
+                .groupByKey() \
+                .filter(lambda x: len(x[1]) >= self._minSup) \
+                .mapValues(set) \
+                .persist()
+            data.unpersist()
+        else:
+            pass
+            # print("may be not able to process the input file")
+
+        freqItems = dict(frequentItems.collect())
+        # print(len(freqItems))
+        self._finalPatterns = {k: len(v) for k, v in freqItems.items()}
+
+        freqPatterns = list(frequentItems.map(lambda x: self._genPatterns(x, x, list(freqItems.items())))
+                            .filter(lambda x: len(x) != 0).collect())
+        for value in freqPatterns:
+            self._finalPatterns.update(value)
+
+        self._endTime = _ab._time.time()
+        process = _ab._psutil.Process(_ab._os.getpid())
+        self._memoryUSS = process.memory_full_info().uss
+        self._memoryRSS = process.memory_info().rss
+        print("Frequent patterns were generated successfully using Parallel ECLAT algorithm")
+        sc.stop()
+
 
-if __name__=="__main__":
+if __name__ == "__main__":
     _ap = str()
-    if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:
+    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
+        if len(_ab._sys.argv) == 6:
+            _ap = parallelECLAT(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
         if len(_ab._sys.argv) == 5:
-            _ap = ECLATbitset(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
-        if len(_ab._sys.argv) == 4:
-            _ap = ECLATbitset(_ab._sys.argv[1], _ab._sys.argv[3])
+            _ap = parallelECLAT(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
         _ap.startMine()
-        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
-        _ap.save(_ab._sys.argv[2])
-        print("Total Memory in USS:", _ap.getMemoryUSS())
-        print("Total Memory in RSS", _ap.getMemoryRSS())
-        print("Total ExecutionTime in ms:", _ap.getRuntime())
+        _finalPatterns = _ap.getPatterns()
+        print("Total number of Frequent Patterns:", len(_finalPatterns))
+        # _ap.savePatterns(_ab._sys.argv[2])
+        _memUSS = _ap.getMemoryUSS()
+        print("Total Memory in USS:", _memUSS)
+        _memRSS = _ap.getMemoryRSS()
+        print("Total Memory in RSS", _memRSS)
+        _run = _ap.getRuntime()
+        print("Total ExecutionTime in ms:", _run)
     else:
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/frequentPattern/basic/FPGrowth.py` & `pami-2023.5.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/CFPGrowth.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,27 +1,62 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     from PAMI.multipleMinimumSupportBasedFrequentPattern.basic import CFPGrowth as alg
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     obj = alg.CFPGrowth(iFile, mIS)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
 
-from PAMI.frequentPattern.basic import abstract as _fp
 
-_minSup = str()
-_fp._sys.setrecursionlimit(20000)
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
 
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+
+from PAMI.multipleMinimumSupportBasedFrequentPattern.basic import abstract as _fp
+
+_fp._sys.setrecursionlimit(20000)
+_MIS = {}
 
 class _Node:
     """
         A class used to represent the node of frequentPatternTree
 
     Attributes:
     ----------
@@ -166,15 +201,16 @@
         data1 = {}
         for i in range(len(ConditionalPatterns)):
             for j in ConditionalPatterns[i]:
                 if j in data1:
                     data1[j] += conditionalFreq[i]
                 else:
                     data1[j] = conditionalFreq[i]
-        up_dict = {k: v for k, v in data1.items() if v >= _minSup}
+        #up_dict = {k: v for k, v in data1.items() if v >= _minSup}
+        up_dict = data1.copy()
         count = 0
         for p in ConditionalPatterns:
             p1 = [v for v in p if v in up_dict]
             trans = sorted(p1, key=lambda x: (up_dict.get(x), -x), reverse=True)
             if len(trans) > 0:
                 pat.append(trans)
                 freq.append(conditionalFreq[count])
@@ -189,48 +225,52 @@
         prefix: an empty list
 
         Returns
         -------
         Frequent patterns that are extracted from fp-tree
 
         """
+        global _MIS
         for i in sorted(self.summaries, key=lambda x: (self.info.get(x), -x)):
             pattern = prefix[:]
             pattern.append(i)
-            yield pattern, self.info[i]
+            sup = []
+            for j in pattern:
+                sup.append(_MIS[j])
+            if self.info[i] >= min(sup):
+                yield pattern, self.info[i]
             patterns, freq, info = self.getFinalConditionalPatterns(i)
             conditionalTree = _Tree()
             conditionalTree.info = info.copy()
             for pat in range(len(patterns)):
                 conditionalTree.addTransaction(patterns[pat], freq[pat])
             if len(patterns) > 0:
                 for q in conditionalTree.generatePatterns(pattern):
                     yield q
 
 
-class FPGrowth(_fp._frequentPatterns):
+class CFPGrowth(_fp._frequentPatterns):
     """
-       FPGrowth is one of the fundamental algorithm to discover frequent patterns in a transactional database.
-       It stores the database in compressed fp-tree decreasing the memory usage and extracts the
-       patterns from tree.It employs employs downward closure property to  reduce the search space effectively.
+    Description:
+    ------------------
+
+       CFPGrowth is one of the fundamental algorithm to discover frequent patterns based on multiple minimum support in a transactional database.
 
     Reference :
     ---------
-           Han, J., Pei, J., Yin, Y. et al. Mining Frequent Patterns without Candidate Generation: A Frequent-Pattern
-           Tree Approach. Data  Mining and Knowledge Discovery 8, 5387 (2004). https://doi.org/10.1023
+        Ya-Han Hu and Yen-Liang Chen. 2006. Mining association rules with multiple minimum supports: a new mining algorithm and a support tuning mechanism.
+        Decis. Support Syst. 42, 1 (October 2006), 124. https://doi.org/10.1016/j.dss.2004.09.007
+
 
     Attributes :
     ----------
         iFile : file
             Input file name or path of the input file
-        minSup: float or int or str
-            The user can specify minSup either in count or proportion of database size.
-            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+        MIS: file or dictionary
+            Multiple minimum supports of all items in the database
         sep : str
             This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
             However, the users can override their default separator.
         oFile : file
             Name of the output file or the path of the output file
         startTime:float
             To record the start time of the mining process
@@ -248,15 +288,15 @@
             it represents the total no of transactions
         tree : class
             it represents the Tree class
         finalPatterns : dict
             it represents to store the patterns
 
     Methods :
-    -------
+    ----------------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -267,37 +307,37 @@
             Total amount of RSS memory consumed by the mining process will be retrieved from this function
         getRuntime()
             Total amount of runtime taken by the mining process will be retrieved from this function
         creatingItemSets()
             Scans the dataset or dataframes and stores in list format
         frequentOneItem()
             Extracts the one-frequent patterns from transactions
-            
+
     Executing the code on terminal:
-    -------
+    ----------------------------------
         Format:
         -------
-            python3 FPGrowth.py <inputFile> <outputFile> <minSup>
+            >>> python3 CFPGrowth.py <inputFile> <outputFile>
 
         Examples:
         ---------
-            python3 FPGrowth.py sampleDB.txt patterns.txt 10.0   (minSup will be considered in times of minSup and count of database transactions)
+            >>> python3 CFPGrowth.py sampleDB.txt patterns.txt MISFile.txt
 
-            python3 FPGrowth.py sampleDB.txt patterns.txt 10     (minSup will be considered in support count or frequency) (it will consider "\t" as a separator)
+            >>> python3 CFPGrowth.py sampleDB.txt patterns.txt MISFile.txt
 
-            python3 FPGrowth.py sampleTDB.txt output.txt sampleN.txt 3 ',' (it will consider "," as a separator)
+            >>> python3 CFPGrowth.py sampleTDB.txt output.txt sampleN.txt MIS ',' (it will consider "," as a separator)
 
 
     Sample run of the importing code:
-    -----------
+    --------------------------------------
 
 
-        from PAMI.frequentPattern.basic import FPGrowth as alg
+        from PAMI.multipleMinimumSupportBasedFrequentPattern.basic import CFPGrowth as alg
 
-        obj = alg.FPGrowth(iFile, minSup)
+        obj = alg.CFPGrowth(iFile, mIS)
 
         obj.startMine()
 
         frequentPatterns = obj.getPatterns()
 
         print("Total number of Frequent Patterns:", len(frequentPatterns))
 
@@ -317,34 +357,34 @@
 
         print("Total ExecutionTime in seconds:", run)
 
     Credits:
     -------
         The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
 
-        """
+    """
 
     __startTime = float()
     __endTime = float()
-    _minSup = str()
+    _MIS = str
     __finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
     __memoryUSS = float()
     __memoryRSS = float()
     __Database = []
     __mapSupport = {}
     __lno = 0
     __tree = _Tree()
     __rank = {}
     __rankDup = {}
 
-    def __init__(self, iFile, minSup, sep='\t'):
-        super().__init__(iFile, minSup, sep)
+    def __init__(self, iFile, MIS, sep='\t'):
+        super().__init__(iFile, MIS, sep)
 
     def __creatingItemSets(self):
         """
             Storing the complete transactions of the database/input file in a database variable
 
 
         """
@@ -352,36 +392,78 @@
         if isinstance(self._iFile, _fp._pd.DataFrame):
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
                 self.__Database = self._iFile['Transactions'].tolist()
 
-            #print(self.Database)
+            # print(self.Database)
         if isinstance(self._iFile, str):
             if _fp._validators.url(self._iFile):
                 data = _fp._urlopen(self._iFile)
                 for line in data:
-                    line.strip()
+                    line = line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
                     self.__Database.append(temp)
             else:
                 try:
                     with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
-                            line.strip()
-                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            line = line.strip()
+                            temp = [i.rstrip() for i in line.split('\t')]
                             temp = [x for x in temp if x]
+                            # print(temp)
                             self.__Database.append(temp)
                 except IOError:
                     print("File Not Found")
                     quit()
 
+    def _getMISValues(self):
+        """
+            Storing the Minimum supports given by the user for each item in the database
+
+
+        """
+        self._MISValues = {}
+        if isinstance(self._MIS, _fp._pd.DataFrame):
+            items, MIS = [], []
+            if self._MIS.empty:
+                print("its empty..")
+            i = self._MIS.columns.values.tolist()
+            if 'items' in i:
+                items = self._MIS['items'].tolist()
+            if 'MIS' in i:
+                MIS = self._MIS['MIS'].tolist()
+            for i in range(len(items)):
+                self._MISValues[items[i]] = MIS[i]
+
+        if isinstance(self._MIS, str):
+            if _fp._validators.url(self._MIS):
+                data = _fp._urlopen(self._MIS)
+                for line in data:
+                    line = line.strip()
+                    line = line.decode("utf-8")
+                    temp = [i.rstrip() for i in line.split(self._sep)]
+                    temp = [x for x in temp if x]
+                    self._MISValues[temp[0]] = int(temp[1])
+            else:
+                try:
+                    with open(self._MIS, 'r', encoding='utf-8') as f:
+                        for line in f:
+                            line = line.strip()
+                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            temp = [x for x in temp if x]
+                            self._MISValues[temp[0]] = int(temp[1])
+                    print(len(self._MISValues))
+                except IOError:
+                    print("File Not Found")
+                    quit()
+
     def __convert(self, value):
         """
         to convert the type of user specified minSup value
 
         :param value: user specified minSup value
 
         :return: converted type
@@ -401,20 +483,24 @@
     def __frequentOneItem(self):
         """
         Generating One frequent items sets
 
         """
         self.__mapSupport = {}
         for tr in self.__Database:
-            for i in range(0, len(tr)):
+            for i in range(len(tr)):
                 if tr[i] not in self.__mapSupport:
                     self.__mapSupport[tr[i]] = 1
                 else:
                     self.__mapSupport[tr[i]] += 1
-        self.__mapSupport = {k: v for k, v in self.__mapSupport.items() if v >= self._minSup}
+        # for x, y in self.__mapSupport.items():
+        #     print(x, y)
+        self.__mapSupport = {k: v for k, v in self.__mapSupport.items() if v >= min(self._MISValues.values())}
+        # for x, y in self.__mapSupport.items():
+        #     print(x, y)
         genList = [k for k, v in sorted(self.__mapSupport.items(), key=lambda x: x[1], reverse=True)]
         self.__rank = dict([(index, item) for (item, index) in enumerate(genList)])
         return genList
 
     def __updateTransactions(self, itemSet):
         """
         Updates the items in transactions with rank of items according to their support
@@ -478,35 +564,34 @@
         return temp
 
     def startMine(self):
         """
             main program to start the operation
 
         """
-        global _minSup
+        global _MIS
         self.__startTime = _fp._time.time()
         if self._iFile is None:
             raise Exception("Please enter the file path or file name:")
-        if self._minSup is None:
-            raise Exception("Please enter the Minimum Support")
         self.__creatingItemSets()
-        self._minSup = self.__convert(self._minSup)
-        _minSup = self._minSup
+        self._getMISValues()
+        #MIS = self._MISValues
         itemSet = self.__frequentOneItem()
         updatedTransactions = self.__updateTransactions(itemSet)
         for x, y in self.__rank.items():
+            _MIS[y] = self._MISValues[x]
             self.__rankDup[y] = x
         info = {self.__rank[k]: v for k, v in self.__mapSupport.items()}
         __Tree = self.__buildTree(updatedTransactions, info)
         patterns = __Tree.generatePatterns([])
         self.__finalPatterns = {}
         for k in patterns:
             s = self.__savePeriodic(k[0])
             self.__finalPatterns[str(s)] = k[1]
-        print("Frequent patterns were generated successfully using frequentPatternGrowth algorithm")
+        print("Frequent patterns were generated successfully using CFPGrowth algorithm")
         self.__endTime = _fp._time.time()
         self.__memoryUSS = float()
         self.__memoryRSS = float()
         process = _fp._psutil.Process(_fp._os.getpid())
         self.__memoryUSS = process.memory_full_info().uss
         self.__memoryRSS = process.memory_info().rss
 
@@ -573,30 +658,37 @@
         """ Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
 
         :rtype: dict
         """
         return self.__finalPatterns
-    
+
     def printResults(self):
-        print("Total number of Frequent Patterns:", len(self.getPatterns()))
+        print("Total number of  Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
-        print("Total ExecutionTime in ms:", self.getRuntime())
+        print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
     if len(_fp._sys.argv) == 4 or len(_fp._sys.argv) == 5:
         if len(_fp._sys.argv) == 5:
-            _ap = FPGrowth(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4])
+            _ap = CFPGrowth(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4])
         if len(_fp._sys.argv) == 4:
-            _ap = FPGrowth(_fp._sys.argv[1], _fp._sys.argv[3])
+            _ap = CFPGrowth(_fp._sys.argv[1], _fp._sys.argv[3])
         _ap.startMine()
-        print("Total number of Frequent Patterns:", len( _ap.getPatterns()))
+        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
         _ap.save(_fp._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
+        _ap = CFPGrowth('/Users/Likhitha/Downloads/Transactional_T10I4D100K-3.csv', '/Users/Likhitha/Downloads/MIS_T10I4D100K_.csv', '\t')
+        _ap.startMine()
+        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
+        _ap.save('/Users/Likhitha/Downloads/CFPGrowth_output.txt')
+        print("Total Memory in USS:", _ap.getMemoryUSS())
+        print("Total Memory in RSS", _ap.getMemoryRSS())
+        print("Total ExecutionTime in ms:", _ap.getRuntime())
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/frequentPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/frequentPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/frequentPattern/closed/CHARM.py` & `pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/UVECLAT.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,52 +1,96 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-#
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-
-
-from PAMI.frequentPattern.closed import abstract as _ab
-
-
-class CHARM(_ab._frequentPatterns):
-    """ CHARM is an algorithm to discover closed frequent patterns in a transactional database.
-        Closed frequent patterns are patterns if there exists no superset that has the same support count as this original itemset.
-        This algorithm employs depth-first search technique to find the complete set of closed frequent patterns in a
-        transactional database.
-        
-        Reference:
-        ----------
-            Mohammed J. Zaki and Ching-Jui Hsiao, CHARM: An Efficient Algorithm for Closed Itemset Mining,
-            Proceedings of the 2002 SIAM, SDM. 2002, 457-473, https://doi.org/10.1137/1.9781611972726.27
+#
+#     from PAMI.uncertainFrequentPattern.basic import UVECLAT as alg
+#
+#     obj = alg.UVEclat(iFile, minSup)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getmemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
 
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+import operator as _operator
+from PAMI.uncertainFrequentPattern.basic import abstract as _ab
+
+
+_minSup = float()
+_finalPatterns = {}
+
+
+class _Item:
+    """
+    A class used to represent the item with probability in transaction of dataset
+    ...
     Attributes:
+    __________
+        item : int or word
+            Represents the name of the item
+        probability : float
+            Represent the existential probability(likelihood presence) of an item
+    """
+
+    def __init__(self, item, probability):
+        self.item = item
+        self.probability = probability
+
+
+class UVEclat(_ab._frequentPatterns):
+    """
+    Description:
+    -------------
+        It is one of the fundamental algorithm to discover frequent patterns in a uncertain transactional database
+        using PUF-Tree.
+    Reference:
     ----------
+    Carson Kai-Sang Leung, Lijing Sun: "Equivalence class transformation based mining of frequent itemsets from uncertain data",
+    SAC '11: Proceedings of the 2011 ACM Symposium on Applied ComputingMarch, 2011, Pages 983984,
+    https://doi.org/10.1145/1982185.1982399
+
+    Attributes:
+    ------------
         iFile : file
             Name of the Input file or path of the input file
         oFile : file
             Name of the output file or path of the output file
         minSup: float or int or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
@@ -55,485 +99,425 @@
         sep : str
             This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
             However, the users can override their default separator.
         memoryUSS : float
             To store the total amount of USS memory consumed by the program
         memoryRSS : float
             To store the total amount of RSS memory consumed by the program
-        startTime: float
+        startTime:float
             To record the start time of the mining process
-        endTime: float
+        endTime:float
             To record the completion time of the mining process
         Database : list
             To store the transactions of a database in list
         mapSupport : Dictionary
             To maintain the information of item and their frequency
         lno : int
-            it represents the total no of transactions
+            To represent the total no of transaction
         tree : class
-            it represents the Tree class
+            To represents the Tree class
         itemSetCount : int
-            it represents the total no of patterns
+            To represents the total no of patterns
         finalPatterns : dict
-            it represents to store the patterns
-        tidList : dict
-            stores the timestamps of an item
-        hashing : dict
-            stores the patterns with their support to check for the closed property
-
+            To store the complete patterns
     Methods:
-    -------
+    ---------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
-        save(oFile)
+        storePatternsInFile(oFile)
             Complete set of frequent patterns will be loaded in to a output file
-        getPatternsAsDataFrame()
+        getPatternsInDataFrame()
             Complete set of frequent patterns will be loaded in to a dataframe
         getMemoryUSS()
             Total amount of USS memory consumed by the mining process will be retrieved from this function
         getMemoryRSS()
             Total amount of RSS memory consumed by the mining process will be retrieved from this function
         getRuntime()
             Total amount of runtime taken by the mining process will be retrieved from this function
-        creatingItemsets()
-            Stores the frequent patterns with their timestamps from the dataset
-        
-        
-    Executing the code on terminal:
-    -------
-        Format: python3 CHARM.py <inputFile> <outputFile> <minSup>
+        creatingItemSets(fileName)
+            Scans the dataset and stores in a list format
+        frequentOneItem()
+            Extracts the one-length frequent patterns from database
 
-        Examples:
 
-        python3 CHARM.py sampleDB.txt patterns.txt 10.0   (minSup will be considered in times of minSup and count of database transactions)
+    **Methods to execute code on terminal**
 
-        python3 CHARM.py sampleDB.txt patterns.txt 10     (minSup will be considered in support count or frequency)
+            Format:
+                      >>> python3 uveclat.py <inputFile> <outputFile> <minSup>
+            Example:
+                      >>>  python3 uveclat.py sampleTDB.txt patterns.txt 3
 
-    Sample run of the importing code:
-    --------------
+            .. note:: minSup  will be considered in support count or frequency
 
-        from PAMI.frequentPattern.closed import closed as alg
+    **Importing this algorithm into a python program**
 
-        obj = alg.Closed(iFile, minSup)
+    .. code-block:: python
 
-        obj.startMine()
+            from PAMI.uncertainFrequentPattern.basic import UVECLAT as alg
 
-        frequentPatterns = obj.getPatterns()
+            obj = alg.UVEclat(iFile, minSup)
 
-        print("Total number of Closed Frequent Patterns:", len(frequentPatterns))
 
-        obj.save(oFile)
+            obj.startMine()
 
-        Df = obj.getPatternsAsDataFrame()
+            frequentPatterns = obj.getPatterns()
 
-        memUSS = obj.getMemoryUSS()
+            print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-        print("Total Memory in USS:", memUSS)
+            obj.savePatterns(oFile)
 
-        memRSS = obj.getMemoryRSS()
+            Df = obj.getPatternsAsDataFrame()
 
-        print("Total Memory in RSS", memRSS)
+            memUSS = obj.getmemoryUSS()
 
-        run = obj.getRuntime()
+            print("Total Memory in USS:", memUSS)
 
-        print("Total ExecutionTime in seconds:", run)
+            memRSS = obj.getMemoryRSS()
 
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+            print("Total Memory in RSS", memRSS)
 
-        """
+            run = obj.getRuntime()
+
+            print("Total ExecutionTime in seconds:", run)
 
+    **Credits:**
+
+         The complete program was written by   P.Likhitha    under the supervision of Professor Rage Uday Kiran.
+
+    """
     _startTime = float()
     _endTime = float()
-    _minSup = float()
+    _minSup = str()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
     _tidList = {}
-    _lno = 0
-    _mapSupport = {}
-    _hashing = {}
-    _itemSetCount = 0
-    _maxItemId = 0
-    _tableSize = 10000
-    _writer = None
-
-    def _convert(self, value):
-        """
-        to convert the type of user specified minSup value
-
-        :param value: user specified minSup value
-
-        :return: converted type
-        """
-        if type(value) is int:
-            value = int(value)
-        if type(value) is float:
-            value = (self._lno * value)
-        if type(value) is str:
-            if '.' in value:
-                value = float(value)
-                value = (self._lno * value)
-            else:
-                value = int(value)
-        return value
+    _rank = {}
 
-    def _creatingItemsets(self):
+    def _creatingItemSets(self):
         """
-        Storing the complete frequent patterns of the database/input file in a database variable
+            Scans the dataset
         """
-        self._mapSupport = {}
-        self._tidList = {}
-        self._lno = 0
+        self._Database = []
         if isinstance(self._iFile, _ab._pd.DataFrame):
+            uncertain, data = [], []
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
                 self._Database = self._iFile['Transactions'].tolist()
-            for i in self._Database:
-                self._lno += 1
-                for j in i:
-                    if j not in self._mapSupport:
-                        self._mapSupport[j] = 1
-                        self._tidList[j] = [self._lno]
-                    else:
-                        self._mapSupport[j] += 1
-                        self._tidList[j].append(self._lno)
+            if 'uncertain' in i:
+                uncertain = self._iFile['uncertain'].tolist()
+            for k in range(len(data)):
+                tr = []
+                for j in range(len(data[k])):
+                    product = _Item(data[k][j], uncertain[k][j])
+                    tr.append(product)
+                self._Database.append(tr)
+
+            # print(self.Database)
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
                     line.strip()
-                    self._lno += 1
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
-                    for j in temp:
-                        if j not in self._mapSupport:
-                            self._mapSupport[j] = 1
-                            self._tidList[j] = [self._lno]
-                        else:
-                            self._mapSupport[j] += 1
-                            self._tidList[j].append(self._lno)
+                    tr = []
+                    for i in temp:
+                        i1 = i.index('(')
+                        i2 = i.index(')')
+                        item = i[0:i1]
+                        probability = float(i[i1 + 1:i2])
+                        product = _Item(item, probability)
+                        tr.append(product)
+                    self._Database.append(temp)
             else:
                 try:
                     with open(self._iFile, 'r') as f:
                         for line in f:
-                            i = [i.rstrip() for i in line.split(self._sep)]
-                            i = [x for x in i if x]
-                            self._lno += 1
-                            for j in i:
-                                if j not in self._mapSupport:
-                                    self._mapSupport[j] = 1
-                                    self._tidList[j] = [self._lno]
-                                else:
-                                    self._mapSupport[j] += 1
-                                    self._tidList[j].append(self._lno)
+                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            temp = [x for x in temp if x]
+                            tr = []
+                            for i in temp:
+                                i1 = i.index('(')
+                                i2 = i.index(')')
+                                item = i[0:i1]
+                                probability = float(i[i1 + 1:i2])
+                                product = _Item(item, probability)
+                                tr.append(product)
+                            self._Database.append(tr)
                 except IOError:
                     print("File Not Found")
-        self._minSup = self._convert(self._minSup)
-        self._mapSupport = {k: v for k, v in self._mapSupport.items() if v >= self._minSup}
-        _flist = {}
-        self._tidList = {k: v for k, v in self._tidList.items() if k in self._mapSupport}
-        for x, y in self._tidList.items():
-            t1 = 0
-            for i in y:
-                t1 += i
-            _flist[x] = t1
-        _flist = [key for key, value in sorted(_flist.items(), key=lambda x: x[1])]
-        return _flist
-
-    def _calculate(self, tidSet):
-        """To calculate the hashcode of pattern
-
-            :param tidSet: the timestamps of a pattern
 
-            :type tidSet: list
-
-            :rtype: int
+    def _frequentOneItem(self):
+        """takes the self.Database and calculates the support of each item in the dataset and assign the
+            ranks to the items by decreasing support and returns the frequent items list
         """
 
-        hashcode = 0
-        for i in tidSet:
-            hashcode += i
-        if hashcode < 0:
-            hashcode = abs(0 - hashcode)
-        return hashcode % self._tableSize
-
-    def _contains(self, itemSet, value, hashcode):
-        """ Check for the closed property(patterns with same support) by checking the hashcode(sum of timestamps),
-            if hashcode key in hashing dict is none then returns a false, else returns with true.
-
-            :param itemSet: frequent pattern
-
-            :type itemSet: list
-
-            :param value: support of the pattern
-
-            :type value: int
+        mapSupport = {}
+        k = 0
+        for i in self._Database:
+            k += 1
+            for j in i:
+                if j.item not in mapSupport:
+                    mapSupport[str(j.item)] = j.probability
+                    self._tidList[str(j.item)] = {k: j.probability}
+                else:
+                    mapSupport[str(j.item)] += j.probability
+                    self._tidList[str(j.item)].update({k: j.probability})
+        mapSupport = {k: v for k, v in mapSupport.items() if v >= self._minSup}
+        plist = dict( sorted(mapSupport.items(), key=_operator.itemgetter(1),reverse=True))
+        return list(plist.keys())
+
+    @staticmethod
+    def _check(i, x):
+        """To check the presence of item or pattern in transaction
+                :param x: it represents the pattern
+                :type x : list
+                :param i : represents the uncertain self.Database
+                :type i : list
+        """
+
+        # This method taken a transaction as input and returns the tree
+        for m in x:
+            k = 0
+            for n in i:
+                if m == n.item:
+                    k += 1
+            if k == 0:
+                return 0
+        return 1
+
+    @staticmethod
+    def _convert(value):
+        """
+        To convert the type of user specified minSup value
+            :param value: user specified minSup value
+            :return: converted type minSup value
+        """
+        if type(value) is int:
+            value = int(value)
+        if type(value) is float:
+            value = float(value)
+        if type(value) is str:
+            if '.' in value:
+                value = float(value)
+            else:
+                value = int(value)
+        return value
 
-            :param hashcode: calculated from the timestamps of pattern
+    def _removeFalsePositives(self):
+        """
+            To remove the false positive patterns generated in frequent patterns
+            :return: patterns with accurate probability
+        """
+        global _finalPatterns
+        periods = {}
+        for i in self._Database:
+            for x, y in _finalPatterns.items():
+                if len(x) == 1:
+                    periods[x] = y
+                else:
+                    s = 1
+                    check = self._check(i, x)
+                    if check == 1:
+                        for j in i:
+                            if j.item in x:
+                                s *= j.probability
+                        if x in periods:
+                            periods[x] += s
+                        else:
+                            periods[x] = s
+        for x, y in periods.items():
+            if y >= self._minSup:
+                sample = str()
+                for i in x:
+                    sample = sample + i + "\t"
+                self._finalPatterns[sample] = y
 
-            :type hashcode: int
-            """
-        if self._hashing.get(hashcode) is None:
-            return False
-        for i in self._hashing[hashcode]:
-            itemSetx = i
-            if value == self._hashing[hashcode][itemSetx] and set(itemSetx).issuperset(itemSet):
-                return True
-        return False
+    @staticmethod
+    def _Intersection(tidSetx, tidSetY):
+        tids = []
+        support = []
+        tidDict = {}
+        for x, y in tidSetx.items():
+            for x1, y1 in tidSetY.items():
+                if x == x1:
+                    tids.append(x)
+                    support.append(y * y1)
+                    tidDict.update({x: y * y1})
+        return tidDict
 
-    def _save(self, prefix, suffix, tidSetx):
-        """ Check for the closed property (patterns with same support), if found deletes the subsets and stores
-            supersets and also saves the patterns that satisfy the closed property
+    def _calculateExpSup(self, tidList):
+        return sum(tidList.values())
 
+    def _save(self, prefix, suffix, tidSetI):
+        """Saves the patterns that satisfy the periodic frequent property.
             :param prefix: the prefix of a pattern
-
+            :type prefix: list
             :param suffix: the suffix of a patterns
-
             :type suffix: list
-
-            :param tidSetx: the timestamp of a patterns
-
-            :type tidSetx: list
+            :param tidSetI: the timestamp of a patterns
+            :type tidSetI: dict
         """
+
+        global _finalPatterns
         if prefix is None:
             prefix = suffix
         else:
             prefix = prefix + suffix
-        prefix = list(set(prefix))
-        prefix.sort()
-        val = len(tidSetx)
-        if val >= self._minSup:
-            hashcode = self._calculate(tidSetx)
-            if self._contains(prefix, val, hashcode) is False:
-                sample = str()
-                for i in prefix:
-                    sample = sample + i + "\t"
-                self._itemSetCount += 1
-                self._finalPatterns[sample] = val
-            if hashcode not in self._hashing:
-                self._hashing[hashcode] = {tuple(prefix): val}
-            else:
-                self._hashing[hashcode][tuple(prefix)] = val
-
-    def _processEquivalenceClass(self, prefix, itemSets, tidSets):
-        """ Equivalence class is followed  and check for the patterns which satisfies frequent properties.
+        val = self._calculateExpSup(tidSetI)
+        _finalPatterns[tuple(prefix)] = val
 
+    def _Generation(self, prefix, itemSets, tidSets):
+        """Equivalence class is followed  and checks for the patterns generated for periodic-frequent patterns.
             :param prefix:  main equivalence prefix
-
-            :type prefix: frequent item or pattern
-
-            :param itemSets: patterns which are items combined with prefix and satisfying the minSup
-
+            :type prefix: periodic-frequent item or pattern
+            :param itemSets: patterns which are items combined with prefix and satisfying the periodicity
+                            and frequent with their timestamps
             :type itemSets: list
-
             :param tidSets: timestamps of the items in the argument itemSets
-
             :type tidSets: list
-
-
-        """
+                    """
         if len(itemSets) == 1:
             i = itemSets[0]
             tidI = tidSets[0]
             self._save(prefix, [i], tidI)
             return
-        if len(itemSets) == 2:
-            itemX = itemSets[0]
-            tidSetX = tidSets[0]
-            itemY = itemSets[1]
-            tidSetY = tidSets[1]
-            y1 = list(set(tidSetX).intersection(tidSetY))
-            if len(y1) >= self._minSup:
-                suffix = []
-                suffix += [itemX, itemY]
-                suffix = list(set(suffix))
-                self._save(prefix, suffix, y1)
-            if len(y1) != len(tidSetX):
-                self._save(prefix, [itemX], tidSetX)
-            if len(y1) != len(tidSetY):
-                self._save(prefix, [itemX], tidSetY)
-            return
         for i in range(len(itemSets)):
-            itemX = itemSets[i]
-            if itemX is None:
+            itemI = itemSets[i]
+            if itemI is None:
                 continue
-            tidSetX = tidSets[i]
+            tidSetI = tidSets[i]
             classItemSets = []
             classTidSets = []
-            itemSetx = [itemX]
+            itemSetX = [itemI]
             for j in range(i + 1, len(itemSets)):
-                itemY = itemSets[j]
-                if itemY is None:
-                    continue
-                tidSetY = tidSets[j]
-                y = list(set(tidSetX).intersection(tidSetY))
-                if len(y) < self._minSup:
-                    continue
-                if len(tidSetX) == len(tidSetY) and len(y) == len(tidSetX):
-                    itemSets.insert(j, None)
-                    tidSets.insert(j, None)
-                    itemSetx.append(itemY)
-                elif len(tidSetX) < len(tidSetY) and len(y) == len(tidSetX):
-                    itemSetx.append(itemY)
-                elif len(tidSetX) > len(tidSetY) and len(y) == len(tidSetY):
-                    itemSets.insert(j, None)
-                    tidSets.insert(j, None)
-                    classItemSets.append(itemY)
-                    classTidSets.append(y)
-                else:
-                    classItemSets.append(itemY)
+                itemJ = itemSets[j]
+                tidSetJ = tidSets[j]
+                y = self._Intersection(tidSetI, tidSetJ)
+                if self._calculateExpSup(y) >= self._minSup:
+                    classItemSets.append(itemJ)
                     classTidSets.append(y)
-            if len(classItemSets) > 0:
-                newPrefix = list(set(itemSetx)) + prefix
-                self._processEquivalenceClass(newPrefix, classItemSets, classTidSets)
-                self._save(prefix, list(set(itemSetx)), tidSetX)
+            newPrefix = list(set(itemSetX)) + prefix
+            self._Generation(newPrefix, classItemSets, classTidSets)
+            self._save(prefix, list(set(itemSetX)), tidSetI)
 
     def startMine(self):
+        """Main method where the patterns are mined by constructing tree and remove the remove the false patterns
+            by counting the original support of a patterns
         """
-        Mining process will start from here by extracting the frequent patterns from the database. It performs prefix
-        equivalence to generate the combinations and closed frequent patterns.
-        """
+        global _minSup
         self._startTime = _ab._time.time()
-        _plist = self._creatingItemsets()
-        self._finalPatterns = {}
-        self._hashing = {}
-        for i in range(len(_plist)):
-            itemX = _plist[i]
-            if itemX is None:
-                continue
-            tidSetx = self._tidList[itemX]
-            itemSetx = [itemX]
+        self._creatingItemSets()
+        self._minSup = self._convert(self._minSup)
+        _minSup = self._minSup
+        plist = self._frequentOneItem()
+        for i in range(len(plist)):
+            itemI = plist[i]
+            tidSetI = self._tidList[itemI]
+            itemSetX = [itemI]
             itemSets = []
             tidSets = []
-            for j in range(i + 1, len(_plist)):
-                itemY = _plist[j]
-                if itemY is None:
-                    continue
-                tidSetY = self._tidList[itemY]
-                y1 = list(set(tidSetx).intersection(tidSetY))
-                if len(y1) < self._minSup:
-                    continue
-                if len(tidSetx) == len(tidSetY) and len(y1) == len(tidSetx):
-                    _plist.insert(j, None)
-                    itemSetx.append(itemY)
-                elif len(tidSetx) < len(tidSetY) and len(y1) == len(tidSetx):
-                    itemSetx.append(itemY)
-                elif len(tidSetx) > len(tidSetY) and len(y1) == len(tidSetY):
-                    _plist.insert(j, None)
-                    itemSets.append(itemY)
+            for j in range(i+1, len(plist)):
+                itemJ = plist[j]
+                tidSetJ = self._tidList[itemJ]
+                y1 = self._Intersection(tidSetI, tidSetJ)
+                if self._calculateExpSup(y1) >= self._minSup:
+                    itemSets.append(itemJ)
                     tidSets.append(y1)
-                else:
-                    itemSets.append(itemY)
-                    tidSets.append(y1)
-            if len(itemSets) > 0:
-                self._processEquivalenceClass(itemSetx, itemSets, tidSets)
-            self._save(None, itemSetx, tidSetx)
-        print("Closed Frequent patterns were generated successfully using CHARM algorithm")
+            self._Generation(itemSetX, itemSets, tidSets)
+            self._save(None, itemSetX, tidSetI)
+        self._removeFalsePositives()
+        print("Frequent patterns were generated from uncertain databases successfully using PUF algorithm")
         self._endTime = _ab._time.time()
-        _process = _ab._psutil.Process(_ab._os.getpid())
-        self._memoryUSS = float()
+        process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryRSS = float()
-        self._memoryUSS = _process.memory_full_info().uss
-        self._memoryRSS = _process.memory_info().rss
+        self._memoryUSS = float()
+        self._memoryUSS = process.memory_full_info().uss
+        self._memoryRSS = process.memory_info().rss
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
-
         :return: returning USS memory consumed by the mining process
-
         :rtype: float
         """
 
         return self._memoryUSS
 
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the mining process will be retrieved from this function
-
         :return: returning RSS memory consumed by the mining process
-
         :rtype: float
         """
 
         return self._memoryRSS
 
     def getRuntime(self):
         """Calculating the total amount of runtime taken by the mining process
-
         :return: returning total amount of runtime taken by the mining process
-
         :rtype: float
         """
 
         return self._endTime - self._startTime
 
     def getPatternsAsDataFrame(self):
         """Storing final frequent patterns in a dataframe
-
         :return: returning frequent patterns in a dataframe
-
         :rtype: pd.DataFrame
         """
 
         dataframe = {}
         data = []
         for a, b in self._finalPatterns.items():
             data.append([a.replace('\t', ' '), b])
             dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
         return dataframe
 
-    def save(self, outFile):
+    def save(self, oFile):
         """Complete set of frequent patterns will be loaded in to a output file
-
-        :param outFile: name of the output file
-
-        :type outFile: file
+        :param oFile: name of the output file
+        :type oFile: file
         """
-        self._oFile = outFile
-        writer = open(self._oFile, 'w+')
+        self.oFile = oFile
+        writer = open(self.oFile, 'w+')
         for x, y in self._finalPatterns.items():
             s1 = x.strip() + ":" + str(y)
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
-
         :return: returning frequent patterns
-
         :rtype: dict
         """
-
         return self._finalPatterns
 
     def printResults(self):
-        print("Total number of Closed Frequent Patterns:", len(self.getPatterns()))
+        print("Total number of  Uncertain Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
     if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:
         if len(_ab._sys.argv) == 5:
-            _ap = CHARM(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+            _ap = UVEclat(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
         if len(_ab._sys.argv) == 4:
-            _ap = CHARM(_ab._sys.argv[1], _ab._sys.argv[3])
+            _ap = UVEclat(_ab._sys.argv[1], _ab._sys.argv[3])
         _ap.startMine()
-        print("Total number of Closed Frequent Patterns:", len(_ap.getPatterns()))
+        print("Total number of Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
-        _memRSS = _ap.getMemoryRSS()
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
-        print("Error! The number of input parameters do not match the total number of parameters provided")
+        print("Error! The number of input parameters do not match the total number of parameters provided")
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `pami-2023.4.1/PAMI/frequentPattern/closed/abstract.py` & `pami-2023.5.1/PAMI/frequentPattern/closed/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/frequentPattern/cuda/cudaAprioriGCT.py` & `pami-2023.5.1/PAMI/frequentPattern/cuda/cudaAprioriGCT.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,14 +1,37 @@
+#
+#
+#
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
+
+
+
+
 import os
 import csv
 import time
 import numpy as np
-import pycuda.gpuarray as gpuarray
-import pycuda.autoinit
-import psutil
+# import pycuda.gpuarray as gpuarray
+# import pycuda.autoinit
+# import psutil
 
 
 class cudaAprioriGCT:
     __time = 0
     __memRSS = 0
     __memUSS = 0
     __GPU_MEM = 0
```

### Comparing `pami-2023.4.1/PAMI/frequentPattern/cuda/cudaAprioriTID.py` & `pami-2023.5.1/PAMI/frequentPattern/cuda/cudaAprioriTID.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,42 +1,66 @@
+#
+#
+#
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
+
+
+
+
+
 import os
 import csv
 import time
 import numpy as np
-import pycuda.gpuarray as gpuarray
-import pycuda.autoinit
-import psutil
-import pycuda.driver as cuda
-from pycuda.compiler import SourceModule
-import pycuda
-
-deviceIntersection = SourceModule("""
-    __global__ void intersection(int *compareThis, int *compareThat, int *resultStart,
-                                 int *values, int *result, int resultX, int resultY){
-        const int tidX = blockIdx.x * blockDim.x + threadIdx.x;
-        const int tidY = blockIdx.y * blockDim.y + threadIdx.y; 
-        int resultIndex = resultStart[tidX] + tidY;
-        
-        // ignore if tidX or tidY is out of bounds or if the value comparing with is 0
-        if (tidX > resultX-1 || tidY > resultY-1 || values[compareThis[tidX] + tidY] == 0) return;
-
-        for (int i = 0; i < resultY; i++){
-            if ( values[compareThat[tidX] + i] == 0) return;
-            if ( values[compareThis[tidX] + tidY] == values[compareThat[tidX] + i]){
-                result[resultIndex] = values[compareThis[tidX] + tidY];
-                return;
-            }
-        }
-
-        //result[resultIndex] = values[compareThis[tidX] + tidY];
-
-    }
-
-"""
-                                  )
+# import pycuda.gpuarray as gpuarray
+# import pycuda.autoinit
+# import psutil
+# import pycuda.driver as cuda
+# from pycuda.compiler import SourceModule
+# import pycuda
+
+# deviceIntersection = SourceModule("""
+#     __global__ void intersection(int *compareThis, int *compareThat, int *resultStart,
+#                                  int *values, int *result, int resultX, int resultY){
+#         const int tidX = blockIdx.x * blockDim.x + threadIdx.x;
+#         const int tidY = blockIdx.y * blockDim.y + threadIdx.y;
+#         int resultIndex = resultStart[tidX] + tidY;
+#
+#         // ignore if tidX or tidY is out of bounds or if the value comparing with is 0
+#         if (tidX > resultX-1 || tidY > resultY-1 || values[compareThis[tidX] + tidY] == 0) return;
+#
+#         for (int i = 0; i < resultY; i++){
+#             if ( values[compareThat[tidX] + i] == 0) return;
+#             if ( values[compareThis[tidX] + tidY] == values[compareThat[tidX] + i]){
+#                 result[resultIndex] = values[compareThis[tidX] + tidY];
+#                 return;
+#             }
+#         }
+#
+#         //result[resultIndex] = values[compareThis[tidX] + tidY];
+#
+#     }
+#
+# """
+#                                   )
 
 
 class cudaAprioriTID:
     __time = 0
     __memRSS = 0
     __memUSS = 0
     __GPU_MEM = 0
```

### Comparing `pami-2023.4.1/PAMI/frequentPattern/cuda/cudaEclatGCT.py` & `pami-2023.5.1/PAMI/frequentPattern/cuda/cudaEclatGCT.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,17 +1,38 @@
+#
+#
+#
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
+
 import os
 import csv
 import time
 import numpy as np
-import pycuda.gpuarray as gpuarray
-import pycuda.autoinit
-import psutil
+# import pycuda.gpuarray as gpuarray
+# import pycuda.autoinit
+# import psutil
 
 
 class cudaEclatGCT:
+    
     __time = 0
     __memRSS = 0
     __memUSS = 0
     __GPU_MEM = 0
     filePath = ""
     sep = ""
     minSup = 0
```

### Comparing `pami-2023.4.1/PAMI/frequentPattern/maximal/MaxFPGrowth.py` & `pami-2023.5.1/PAMI/frequentPattern/maximal/MaxFPGrowth.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,21 +1,60 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# MaxFP-Growth is one of the fundamental algorithm to discover maximal frequent patterns in a transactional database.
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+# **Importing this algorithm into a python program**
+# ---------------------------------------------------------
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     from PAMI.frequentPattern.maximal import MaxFPGrowth as alg
+#
+#     obj = alg.MaxFPGrowth("../basic/sampleTDB.txt", "2")
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns("patterns")
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+#
+#
+
+
+#
+#
+#
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
 
 
 from PAMI.frequentPattern.maximal import abstract as _ab
 
 
 _minSup = str()
 global maximalTree
@@ -362,124 +401,109 @@
 
 # Initialising the  variable for maximal tree
 #maximalTree = _MPTree()
 
 
 class MaxFPGrowth(_ab._frequentPatterns):
     """
-    MaxFP-Growth is one of the fundamental algorithm to discover maximal frequent patterns in a transactional database.
+    :Description: MaxFP-Growth is one of the fundamental algorithm to discover maximal frequent patterns in a transactional database.
 
-    Reference:
-    ---------
-        Grahne, G. and Zhu, J., "High Performance Mining of Maximal Frequent itemSets",
+    :Reference:   Grahne, G. and Zhu, J., "High Performance Mining of Maximal Frequent itemSets",
         http://users.encs.concordia.ca/~grahne/papers/hpdm03.pdf
 
-    Attributes:
-    ----------
-        iFile : file
-            Name of the Input file to mine complete set of frequent patterns
-        oFile : file
-            Name of the output file to store complete set of frequent patterns
-        minSup: float or int or str
-            The user can specify minSup either in count or proportion of database size.
-            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-        sep : str
-            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-            However, the users can override their default separator.
+    :param  iFile: str :
+                   Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  minSup: int or float or str :
+                   The user can specify minSup either in count or proportion of database size. If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
+
+
+
+    :Attributes:
+
+        startTime : float
+          To record the start time of the mining process
+
+        endTime : float
+          To record the completion time of the mining process
+
+        finalPatterns : dict
+          Storing the complete set of patterns in a dictionary variable
+
         memoryUSS : float
-            To store the total amount of USS memory consumed by the program
+          To store the total amount of USS memory consumed by the program
+
         memoryRSS : float
-            To store the total amount of RSS memory consumed by the program
-        startTime:float
-            To record the start time of the mining process
-        endTime:float
-            To record the completion time of the mining process
+          To store the total amount of RSS memory consumed by the program
+
         Database : list
-            To store the transactions of a database in list
+          To store the transactions of a database in list
+
         mapSupport : Dictionary
             To maintain the information of item and their frequency
         lno : int
-            it represents the total no of transaction
+            it represents the total no of transactions
         tree : class
             it represents the Tree class
+        itemSetCount : int
+            it represents the total no of patterns
         finalPatterns : dict
             it represents to store the patterns
 
-    Methods:
-    -------
-        startMine()
-            Mining process will start from here
-        getPatterns()
-            Complete set of patterns will be retrieved with this function
-        save(oFile)
-            Complete set of frequent patterns will be loaded in to a output file
-        getPatternsAsDataFrame()
-            Complete set of frequent patterns will be loaded in to a dataframe
-        getMemoryUSS()
-            Total amount of USS memory consumed by the mining process will be retrieved from this function
-        getMemoryRSS()
-            Total amount of RSS memory consumed by the mining process will be retrieved from this function
-        getRuntime()
-            Total amount of runtime taken by the mining process will be retrieved from this function
-        creatingItemSets()
-            Scans the dataset or dataframes and stores in list format
-        frequentOneItem()
-            Extracts the one-frequent patterns from Databases
-        updateTransactions()
-            update the Databases by removing aperiodic items and sort the Database by item decreased support
-        buildTree()
-            after updating the Databases ar added into the tree by setting root node as null
-        startMine()
-            the main method to run the program
-
-    Executing the code on terminal:
-    -------
-        Format:
-        ------
-            python3 MaxFPGrowth.py <inputFile> <outputFile> <minSup>
 
-        Examples:
-        -------
-            python3 MaxFPGrowth.py sampleDB.txt patterns.txt 0.3   (minSup will be considered in percentage of database transactions)
+    **Methods to execute code on terminal**
+    ---------------------------------------------------------
+
+            Format:
+                      >>> python3 MaxFPGrowth.py <inputFile> <outputFile> <minSup>
+
+            Example:
+                      >>> python3 MaxFPGrowth.py sampleDB.txt patterns.txt 0.3
+
+            .. note:: minSup will be considered in percentage of database transactions
+
+
+    **Importing this algorithm into a python program**
+    ---------------------------------------------------------
+
+    .. code-block:: python
 
-            python3 MaxFPGrowth.py sampleDB.txt patterns.txt 3     (minSup will be considered in support count or frequency)
+            from PAMI.frequentPattern.maximal import MaxFPGrowth as alg
 
-    Sample run of the imported code:
-    --------------
-        from PAMI.frequentPattern.maximal import MaxFPGrowth as alg
+            obj = alg.MaxFPGrowth("../basic/sampleTDB.txt", "2")
 
-        obj = alg.MaxFPGrowth("../basic/sampleTDB.txt", "2")
+            obj.startMine()
 
-        obj.startMine()
+            frequentPatterns = obj.getPatterns()
 
-        frequentPatterns = obj.getPatterns()
+            print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-        print("Total number of Frequent Patterns:", len(frequentPatterns))
+            obj.savePatterns("patterns")
 
-        obj.save("patterns")
+            Df = obj.getPatternsAsDataFrame()
 
-        Df = obj.getPatternsAsDataFrame()
+            memUSS = obj.getMemoryUSS()
 
-        memUSS = obj.getMemoryUSS()
+            print("Total Memory in USS:", memUSS)
 
-        print("Total Memory in USS:", memUSS)
+            memRSS = obj.getMemoryRSS()
 
-        memRSS = obj.getMemoryRSS()
+            print("Total Memory in RSS", memRSS)
 
-        print("Total Memory in RSS", memRSS)
+            run = obj.getRuntime()
 
-        run = obj.getRuntime()
+            print("Total ExecutionTime in seconds:", run)
 
-        print("Total ExecutionTime in seconds:", run)
 
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+    **Credits:**
+    -------------------
+                The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
 
     """
     _startTime = float()
     _endTime = float()
     _minSup = str()
     _maxPer = float()
     _finalPatterns = {}
```

### Comparing `pami-2023.4.1/PAMI/frequentPattern/maximal/__init__.py` & `pami-2023.5.1/PAMI/frequentPattern/maximal/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/frequentPattern/maximal/abstract.py` & `pami-2023.5.1/PAMI/frequentPattern/maximal/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/frequentPattern/pyspark/abstract.py` & `pami-2023.5.1/PAMI/frequentPattern/pyspark/abstract.py`

 * *Files 0% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 import os as _os
 import os.path as _ospath
 import psutil as _psutil
 import sys as _sys
 import validators as _validators
 from urllib.request import urlopen as _urlopen
 import functools as _functools
-from pyspark import SparkConf as _SparkConf, SparkContext as _SparkContext
+# from pyspark import SparkConf as _SparkConf, SparkContext as _SparkContext
 
 class _frequentPatterns(_ABC):
     """ This abstract base class defines the variables and methods that every frequent pattern mining algorithm must
             employ in PAMI
            Attributes:
            ----------
             iFile : str
```

### Comparing `pami-2023.4.1/PAMI/frequentPattern/pyspark/parallelFPGrowth.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/basic/PFECLAT.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,415 +1,416 @@
-from pyspark import SparkConf, SparkContext
-from collections import defaultdict
-from PAMI.frequentPattern.pyspark import abstract as _ab
-from operator import add
 
 
-class _Node:
-    """
-        Attribute
-        ---------
-            item : int
-                Storing item of a node
-            count : int
-                To maintain the support count of node
-            children : dict
-                To maintain the children of node
-            prefix : list
-                To maintain the prefix of node
-    """
 
-    def __init__(self, item, prefix):
-        self.item = item
-        self.count = 0
-        self.children = {}
-        self.prefix = prefix
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#     from PAMI.periodicFrequentPattern.basic import PFECLAT as alg
+#
+#     obj = alg.PFECLAT("../basic/sampleTDB.txt", "2", "5")
+#
+#     obj.startMine()
+#
+#     periodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+#
+#     obj.savePatterns("patterns")
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+#
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
 
+"""
 
-class _Tree:
-    """
-        Attribute
-        ---------
-            root : Node
-                The first node of the tree set to Null
-            nodeLink : dict
-                Store nodes that have the same item
-        Methods
-        -------
-            addTransaction(transaction, count)
-                Create tree from transaction and count
-            addNodeToNodeLink(node)
-                Add nodes that have the same item to self.nodeLink
-            generateConditionalTree(item)
-                Create conditional pattern base of item
+from PAMI.periodicFrequentPattern.basic import abstract as _ab
+
+
+class PFECLAT(_ab._periodicFrequentPatterns):
     """
+    Description:
+    -------------
+        EclatPFP is the fundamental approach to mine the periodic-frequent patterns.
+
+    Reference:
+    -----------
+        P. Ravikumar, P.Likhitha, R. Uday kiran, Y. Watanobe, and Koji Zettsu, "Towards efficient discovery of
+        periodic-frequent patterns in columnar temporal databases", 2021 IEA/AIE.
+
+    Attributes:
+    -----------
+        iFile : file
+            Name of the Input file or path of the input file
+        oFile : file
+            Name of the output file or path of the output file
+        minSup: int or float or str
+            The user can specify minSup either in count or proportion of database size.
+            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+        maxPer: int or float or str
+            The user can specify maxPer either in count or proportion of database size.
+            If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
+        sep : str
+            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+            However, the users can override their default separator.
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
+        startTime:float
+            To record the start time of the mining process
+        endTime:float
+            To record the completion time of the mining process
+        Database : list
+            To store the transactions of a database in list
+        mapSupport : Dictionary
+            To maintain the information of item and their frequency
+        lno : int
+            it represents the total no of transactions
+        tree : class
+            it represents the Tree class
+        itemSetCount : int
+            it represents the total no of patterns
+        finalPatterns : dict
+            it represents to store the patterns
+        tidList : dict
+            stores the timestamps of an item
+        hashing : dict
+            stores the patterns with their support to check for the closed property
+
+    Methods:
+    ---------
+        startMine()
+            Mining process will start from here
+        getPatterns()
+            Complete set of patterns will be retrieved with this function
+        save(oFile)
+            Complete set of periodic-frequent patterns will be loaded in to a output file
+        getPatternsAsDataFrame()
+            Complete set of periodic-frequent patterns will be loaded in to a dataframe
+        getMemoryUSS()
+            Total amount of USS memory consumed by the mining process will be retrieved from this function
+        getMemoryRSS()
+            Total amount of RSS memory consumed by the mining process will be retrieved from this function
+        getRuntime()
+            Total amount of runtime taken by the mining process will be retrieved from this function
+        creatingOneItemSets()
+            Scan the database and store the items with their timestamps which are periodic frequent 
+        getPeriodAndSupport()
+            Calculates the support and period for a list of timestamps.
+        Generation()
+            Used to implement prefix class equivalence method to generate the periodic patterns recursively
+            
 
-    def __init__(self):
-        self.root = _Node(None, [])
-        self.nodeLink = {}
-        self.itemCount = defaultdict(int)
+    **Methods to execute code on terminal**
 
-    def addTransaction(self, transaction, count):
-        """
-        Add transaction to tree
-        :param transaction: list
-        :param count: int
-        :return:
-        """
-        current = self.root
-        for item in transaction:
-            if item not in current.children:
-                current.children[item] = _Node(item, transaction[0:transaction.index(item)])
-                current.children[item].count += count
-                self.addNodeToNodeLink(current.children[item])
-            else:
-                current.children[item].count += count
-            self.itemCount[item] += count
-            current = current.children[item]
+            Format:
+                      >>>  python3 PFECLAT.py <inputFile> <outputFile> <minSup>
+            Example:
+                      >>>   python3 PFECLAT.py sampleDB.txt patterns.txt 10.0
 
-    def addNodeToNodeLink(self, node):
-        """
-        Add node to self.nodeLink
-        :param node: Node
-        :return:
-        """
-        if node.item not in self.nodeLink:
-            self.nodeLink[node.item] = [node]
-        else:
-            self.nodeLink[node.item].append(node)
+            .. note:: minSup will be considered in percentage of database transactions
 
-    def generateConditionalTree(self, item):
-        """
-        Generate conditional tree based on item
-        :param item: str or int
-        :return: Tree
-        """
-        tree = _Tree()
-        for node in self.nodeLink[item]:
-            tree.addTransaction(node.prefix, node.count)
-        return tree
 
+    **Importing this algorithm into a python program**
 
-class parallelFPGrowth(_ab._frequentPatterns):
-    """
-        Attributes:
-        ----------
-                minSup : float
-                    The user can specify minSup either in count or proportion of database size.
-                iFile : file
-                    Input file name or path of the input file.
-                oFile : file
-                    Name of the output file or the path of the output file.
-                sep : str
-                    This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                    However, the users can override their default separator.
-                startTime:float
-                    To record the start time of the mining process
-                endTime:float
-                    To record the completion time of the mining process
-                memoryUSS : float
-                    To store the total amount of USS memory consumed by the program
-                memoryRSS : float
-                    To store the total amount of RSS memory consumed by the program
-                finalPatterns : dict
-                    it represents to store the all frequent patterns
-                FPList : list
-                    frequent pattern list
-                numWorkers: int
-                    The number of workers
-                    On each worker node, an executor process is started and this process performs processing.
-                    The processing unit of worker node is partition
-                lno : int
-                    the number of transactions
-            Methods
-            -------
-                startMine()
-                    Mining process will start from this function
-                getPatterns()
-                    Complete set of patterns will be retrieved with this function
-                save(outFile)
-                    Complete set of frequent patterns will be loaded in to a output file
-                getPatternsAsDataFrame()
-                    Complete set of frequent patterns will be loaded in to a dataframe
-                getMemoryUSS()
-                    Total amount of USS memory consumed by the mining process will be retrieved from this function
-                getMemoryRSS()
-                    Total amount of RSS memory consumed by the mining process will be retrieved from this function
-                getRuntime()
-                    Total amount of runtime taken by the mining process will be retrieved from this function
-                genCondTransaction(data, rank)
-                    Generating conditional transactions for distributed pattern mining
-                getPartitionId(item)
-                    Get partition id of item
-                    FPTree is created on each workers based on partition id.
-                genAllFrequentPatterns(tree_tuple)
-                    Get all frequent patterns
-                genFreqPatterns(item, prefix, tree)
-                    Generate frequent patterns based on item and prefix
-        Executing the code on terminal:
-        -------------------------------
-            Format:
-            ------
-                python3 parallelFPGrowth.py <inputFile> <outputFile> <minSup> <numWorkers>
-            Examples:
-            ---------
-                python3 parallelFPGrowth.py sampleDB.txt patterns.txt 10.0 3   (minSup will be considered in times of minSup and count of database transactions)
-                python3 parallelFPGrowth.py sampleDB.txt patterns.txt 10 3    (minSup will be considered in support count or frequency)
-        Sample run of the importing code:
-        ---------------------------------
-            import PAMI.frequentPattern.pyspark.parallelFPGrowth as alg
-            obj = alg.parallelFPGrowth(iFile, minSup, numWorkers)
-            obj.startMine()
-            frequentPatterns = obj.getPatterns()
-            print("Total number of Frequent Patterns:", len(frequentPatterns))
-            obj.save(oFile)
-            Df = obj.getPatternInDataFrame()
-            memUSS = obj.getMemoryUSS()
-            print("Total Memory in USS:", memUSS)
-            memRSS = obj.getMemoryRSS()
-            print("Total Memory in RSS", memRSS)
-            run = obj.getRuntime()
-            print("Total ExecutionTime in seconds:", run)
-        Credits:
-        --------
-            The complete program was written by Yudai Masu under the supervision of Professor Rage Uday Kiran.
-        """
-    _minSup = float()
-    _numPartitions = int()
-    _startTime = float()
-    _endTime = float()
-    _finalPatterns = dict()
-    _FPList = list()
-    _iFile = " "
-    _oFile = " "
-    _sep = " "
-    _memoryUSS = float()
-    _memoryRSS = float()
-    _lno = int()
+    .. code-block:: python
 
-    def __init__(self, iFile, minSup, numWorkers, sep='\t'):
-        super().__init__(iFile, minSup, int(numWorkers), sep)
+             from PAMI.periodicFrequentPattern.basic import PFECLAT as alg
 
-    def startMine(self):
-        """Frequent pattern mining process will start from here"""
+                obj = alg.PFECLAT("../basic/sampleTDB.txt", "2", "5")
 
-        self._startTime = _ab._time.time()
+                obj.startMine()
 
-        conf = SparkConf().setAppName("Parallel FPGrowth").setMaster("local[*]")
-        sc = SparkContext(conf=conf)
+                periodicFrequentPatterns = obj.getPatterns()
 
-        rdd = sc.textFile(self._iFile, self._numPartitions) \
-            .map(lambda x: x.rstrip().split('\t')) \
-            .persist()
+                print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
 
-        self._lno = rdd.count()
-        self._minSup = self._convert(self._minSup)
+                obj.savePatterns("patterns")
 
-        freqItems = rdd.flatMap(lambda trans: [(item, 1) for item in trans]) \
-            .reduceByKey(add) \
-            .filter(lambda x: x[1] >= self._minSup) \
-            .sortBy(lambda x: x[1], ascending=False) \
-            .collect()
-        self._finalPatterns = dict(freqItems)
-        self._FPList = [x[0] for x in freqItems]
-        rank = dict([(item, index) for (index, item) in enumerate(self._FPList)])
-
-        workByPartition = rdd.flatMap(lambda x: self.genCondTransaction(x, rank)).groupByKey()
-
-        trees = workByPartition.foldByKey(_Tree(), lambda tree, data: self.buildTree(tree, data))
-        freqPatterns = trees.flatMap(lambda tree_tuple: self.genAllFrequentPatterns(tree_tuple))
-        result = freqPatterns.map(
-            lambda ranks_count: (tuple([self._FPList[z] for z in ranks_count[0]]), ranks_count[1])) \
-            .collect()
-
-        self._finalPatterns.update(dict(result))
-
-        temp = {}
-        for pattern, v in self._finalPatterns.items():
-            s = ""
-            if isinstance(pattern, str):
-                s += pattern + '\t'
-            else:
-                for item in pattern:
-                    s += item + '\t'
-            temp[s] = v
-        self._finalPatterns = temp
+                Df = obj.getPatternsAsDataFrame()
 
-        self._endTime = _ab._time.time()
-        process = _ab._psutil.Process(_ab._os.getpid())
-        self._memoryUSS = process.memory_full_info().uss
-        self._memoryRSS = process.memory_info().rss
-        sc.stop()
+                memUSS = obj.getMemoryUSS()
 
-        print("Frequent patterns were generated successfully using Parallel FPGrowth algorithm")
+                print("Total Memory in USS:", memUSS)
 
-    def getPartitionId(self, value):
-        """
-            Get partition id of item
-            :param value: int
-            :return: int
-        """
-        return value % self._numPartitions
+                memRSS = obj.getMemoryRSS()
 
-    def genCondTransaction(self, transaction, rank):
-        """
-            Generate conditional transactions from transaction
-            :param transaction : list
-            :param rank: dict
-            :return: list
-        """
-        newTrans = [rank[item] for item in transaction if item in rank.keys()]
-        newTrans = sorted(newTrans)
-        condTrans = {}
-        for i in reversed(newTrans):
-            partition = self.getPartitionId(i)
-            if partition not in condTrans:
-                condTrans[partition] = newTrans[:newTrans.index(i) + 1]
-        return [x for x in condTrans.items()]
+                print("Total Memory in RSS", memRSS)
+
+                run = obj.getRuntime()
+
+                print("Total ExecutionTime in seconds:", run)
+
+    **Credits:**
+
+             The complete program was written by  P.Likhitha   under the supervision of Professor Rage Uday Kiran.
 
-    @staticmethod
-    def buildTree(tree, data):
-        """
-            Build tree from data
-            :param tree: Tree
-            :param data: list
-            :return: tree
-        """
-        for trans in data:
-            tree.addTransaction(trans, 1)
-        return tree
 
-    def genAllFrequentPatterns(self, tree_tuple):
         """
-            Generate all frequent patterns
-            :param tree_tuple: (partition id, tree)
-            :return: dict
+    
+    _iFile = " "
+    _oFile = " "
+    _sep = " "
+    _dbSize = None
+    _Database = None
+    _minSup = str()
+    _maxPer = str()
+    _tidSet = set()
+    _finalPatterns = {}
+    _startTime = None
+    _endTime = None
+    _memoryUSS = float()
+    _memoryRSS = float()
+
+    def _getPeriodic(self, tids: set):
+        tidList = list(tids)
+        tidList.sort()
+        tidList.append(self._dbSize)
+        cur = 0
+        per = 0
+        for tid in tidList:
+            per = max(per, tid - cur)
+            if per > self._maxPer:  # early stopping
+                break
+            cur = tid
+        return per
+
+    def _convert(self, value):
         """
-        itemList = sorted(tree_tuple[1].itemCount.items(), key=lambda x: x[1])
-        itemList = [x[0] for x in itemList]
-        freqPatterns = {}
-        for item in itemList:
-            if self.getPartitionId(item) == tree_tuple[0]:
-                freqPatterns.update(self.genFreqPatterns(item, [item], tree_tuple[1]))
-        return freqPatterns.items()
+        To convert the given user specified value
 
-    def genFreqPatterns(self, item, prefix, tree):
+        :param value: user specified value
+        :return: converted value
         """
-            Generate new frequent patterns based on item
-            :param item: item
-            :param prefix: prefix frequent pattern
-            :param tree: tree
-            :return:
+        if type(value) is int:
+            value = int(value)
+        if type(value) is float:
+            value = (self._dbSize * value)
+        if type(value) is str:
+            if '.' in value:
+                value = float(value)
+                value = (self._dbSize * value)
+            else:
+                value = int(value)
+        return value
+
+    def _creatingOneItemSets(self):
+        """Storing the complete transactions of the database/input file in a database variable
         """
-        condTree = tree.generateConditionalTree(item)
-        freqPatterns = {}
-        freqItems = {}
-        for i in condTree.nodeLink.keys():
-            freqItems[i] = 0
-            for node in condTree.nodeLink[i]:
-                freqItems[i] += node.count
-        freqItems = {key: value for key, value in freqItems.items() if value >= self._minSup}
-
-        for i in freqItems:
-            pattern = prefix + [i]
-            freqPatterns[tuple(pattern)] = freqItems[i]
-            freqPatterns.update(self.genFreqPatterns(i, pattern, condTree))
-        return freqPatterns
+        plist = []
+        Database = []
+        if isinstance(self._iFile, _ab._pd.DataFrame):
+            ts, data = [], []
+            if self._iFile.empty:
+                print("its empty..")
+            i = self._iFile.columns.values.tolist()
+            if 'TS' in i:
+                ts = self._iFile['TS'].tolist()
+            if 'Transactions' in i:
+                data = self._iFile['Transactions'].tolist()
+            for i in range(len(data)):
+                tr = [ts[i][0]]
+                tr = tr + data[i]
+                Database.append(tr)
+        if isinstance(self._iFile, str):
+            if _ab._validators.url(self._iFile):
+                data = _ab._urlopen(self._iFile)
+                for line in data:
+                    line.strip()
+                    line = line.decode("utf-8")
+                    temp = [i.rstrip() for i in line.split(self._sep)]
+                    temp = [x for x in temp if x]
+                    Database.append(temp)
+            else:
+                try:
+                    with open(self._iFile, 'r', encoding='utf-8') as f:
+                        for line in f:
+                            line.strip()
+                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            temp = [x for x in temp if x]
+                            Database.append(temp)
+                except IOError:
+                    print("File Not Found")
+                    quit()
+        tid = 0
+        itemsets = {}  # {key: item, value: list of tids}
+        periodicHelper = {}  # {key: item, value: [period, last_tid]}
+        for line in Database:
+            tid = int(line[0])
+            self._tidSet.add(tid)
+            for item in line[1:]:
+                if item in itemsets:
+                    itemsets[item].add(tid)
+                    periodicHelper[item][0] = max(periodicHelper[item][0],
+                                                  abs(tid - periodicHelper[item][1]))  # update current max period
+                    periodicHelper[item][1] = tid  # update the last tid
+                else:
+                    itemsets[item] = {tid}
+                    periodicHelper[item] = [abs(0 - tid), tid]  # initialize helper
+
+        # finish all items' period
+        self._dbSize = len(Database)
+        self._minSup = self._convert(self._minSup)
+        self._maxPer = self._convert(self._maxPer)
+        del Database
+        for item, _ in periodicHelper.items():
+            periodicHelper[item][0] = max(periodicHelper[item][0],
+                                          abs(self._dbSize - periodicHelper[item][1]))  # tid of the last transaction
+        candidates = []
+        for item, tids in itemsets.items():
+            per = periodicHelper[item][0]
+            sup = len(tids)
+            if sup >= self._minSup and per <= self._maxPer:
+                candidates.append(item)
+                self._finalPatterns[item] = [sup, per, tids]
+        return candidates
+    
+    def _generateEclat(self, candidates):
+        newCandidates = []
+        for i in range(0, len(candidates)):
+            prefixItem = candidates[i]
+            prefixItemSet = prefixItem.split()
+            for j in range(i + 1, len(candidates)):
+                item = candidates[j]
+                itemSet = item.split()
+                if prefixItemSet[:-1] == itemSet[:-1] and prefixItemSet[-1] != itemSet[-1]:
+                    _value = self._finalPatterns[item][2].intersection(self._finalPatterns[prefixItem][2])
+                    sup = len(_value)
+                    per = self._getPeriodic(_value)
+                    if sup >= self._minSup and per <= self._maxPer:
+                        newItem = prefixItem + " " + itemSet[-1]
+                        self._finalPatterns[newItem] = [sup, per, _value]
+                        newCandidates.append(newItem)
+
+        if len(newCandidates) > 0:
+            self._generateEclat(newCandidates)
+    
+    def startMine(self):
+        self._startTime = _ab._time.time()
+        self._finalPatterns = {}
+        frequentSets = self._creatingOneItemSets()
+        self._generateEclat(frequentSets)
+        self._endTime = _ab._time.time()
+        process = _ab._psutil.Process(_ab._os.getpid())
+        self._memoryRSS = float()
+        self._memoryUSS = float()
+        self._memoryUSS = process.memory_full_info().uss
+        self._memoryRSS = process.memory_info().rss
+        print("Periodic-Frequent patterns were generated successfully using PFECLAT algorithm ")
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
+
         :return: returning USS memory consumed by the mining process
         :rtype: float
         """
 
         return self._memoryUSS
 
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the mining process will be retrieved from this function
+
         :return: returning RSS memory consumed by the mining process
         :rtype: float
         """
 
         return self._memoryRSS
 
     def getRuntime(self):
         """Calculating the total amount of runtime taken by the mining process
+
+
         :return: returning total amount of runtime taken by the mining process
         :rtype: float
         """
 
         return self._endTime - self._startTime
 
     def getPatternsAsDataFrame(self):
-        """Storing final frequent patterns in a dataframe
-        :return: returning frequent patterns in a dataframe
+        """Storing final periodic-frequent patterns in a dataframe
+
+        :return: returning periodic-frequent patterns in a dataframe
         :rtype: pd.DataFrame
         """
 
-        dataFrame = {}
+        dataframe = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a.replace('\t', ' '), b])
-            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
-        return dataFrame
+            data.append([a, b[0], b[1]])
+            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Periodicity'])
+        return dataframe
 
     def save(self, outFile):
-        """Complete set of frequent patterns will be loaded in to a output file
+        """Complete set of periodic-frequent patterns will be loaded in to a output file
+
         :param outFile: name of the output file
         :type outFile: file
         """
         self._oFile = outFile
         writer = open(self._oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            s1 = x.strip() + ":" + str(y)
+            s1 = x.replace(' ', '\t') + ":" + str(y[0]) + ":" + str(y[1])
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
-        """
-        Function to send the set of frequent patterns after completion of the mining process
-        :return: returning frequent patterns
+        """ Function to send the set of periodic-frequent patterns after completion of the mining process
+
+        :return: returning periodic-frequent patterns
         :rtype: dict
         """
         return self._finalPatterns
 
-    def _convert(self, value):
-        """
-        To convert the user specified minSup value
-        :param value: user specified minSup value
-        :return: converted type
-        """
-        if type(value) is int:
-            value = int(value)
-        elif type(value) is float:
-            value = (self._lno * value)
-        elif type(value) is str:
-            if '.' in value:
-                value = float(value)
-                value = (self._lno * value)
-            else:
-                value = int(value)
-        else:
-            print("minSup is not correct")
-        return value
-
     def printResults(self):
-        print("Total number of Frequent Patterns:", len(self.getPatterns()))
+        print("Total number of Periodic Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
-        print("Total ExecutionTime in ms:", self.getRuntime())
-
+        print("Total ExecutionTime in ms:",  self.getRuntime())
+                    
 
 if __name__ == "__main__":
     _ap = str()
     if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
         if len(_ab._sys.argv) == 6:
-            _ap = parallelFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
+            _ap = PFECLAT(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
         if len(_ab._sys.argv) == 5:
-            _ap = parallelFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+            _ap = PFECLAT(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
         _ap.startMine()
-        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
+        print("Total number of Periodic-Frequent Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
-        print("Total Memory in RSS",  _ap.getMemoryRSS())
+        print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/frequentPattern/topk/FAE.py` & `pami-2023.5.1/PAMI/frequentPattern/topk/FAE.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,125 +1,147 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+
+# Top - K is and algorithm to discover top frequent patterns in a transactional database.
+#
+# **Importing this algorithm into a python program**
+# ---------------------------------------------------------
+#
+#         import PAMI.frequentPattern.topK.FAE as alg
+#
+#         obj = alg.FAE(iFile, K)
+#
+#         obj.startMine()
+#
+#         topKFrequentPatterns = obj.getPatterns()
+#
+#         print("Total number of Frequent Patterns:", len(topKFrequentPatterns))
+#
+#         obj.save(oFile)
+#
+#         Df = obj.getPatternInDataFrame()
+#
+#         memUSS = obj.getMemoryUSS()
+#
+#         print("Total Memory in USS:", memUSS)
+#
+#         memRSS = obj.getMemoryRSS()
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#         print("Total Memory in RSS", memRSS)
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#         run = obj.getRuntime()
+#
+#         print("Total ExecutionTime in seconds:", run)
+
+#
+#
+#
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
 
 from PAMI.frequentPattern.topk import abstract as _ab
 
 
 class FAE(_ab._frequentPatterns):
     """
-        Top - K is and algorithm to discover top frequent patterns in a transactional database.
+    :Description: Top - K is and algorithm to discover top frequent patterns in a transactional database.
+
+
+    :Reference:   Zhi-Hong Deng, Guo-Dong Fang: Mining Top-Rank-K Frequent Patterns: DOI: 10.1109/ICMLC.2007.4370261  Source: IEEE Xplore
+                  https://ieeexplore.ieee.org/document/4370261
+    :param  iFile: str :
+                   Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  k: int :
+                    User specified count of top frequent patterns
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
+
+
+
+    :Attributes:
+
+        startTime : float
+          To record the start time of the mining process
+
+        endTime : float
+          To record the completion time of the mining process
+
+        finalPatterns : dict
+          Storing the complete set of patterns in a dictionary variable
+
+        memoryUSS : float
+          To store the total amount of USS memory consumed by the program
+
+        memoryRSS : float
+          To store the total amount of RSS memory consumed by the program
+
+        finalPatterns : dict
+            it represents to store the patterns
+
+
+    **Methods to execute code on terminal**
+    ----------------------------------------
+
+        Format:
+
+           >>> python3 FAE.py <inputFile> <outputFile> <K>
+
+        Examples:
+
+           >>> python3 FAE.py sampleDB.txt patterns.txt 10
+
+
+    **Importing this algorithm into a python program**
+    ---------------------------------------------------------
+    .. code-block:: python
+
+        import PAMI.frequentPattern.topK.FAE as alg
+
+        obj = alg.FAE(iFile, K)
+
+        obj.startMine()
+
+        topKFrequentPatterns = obj.getPatterns()
+
+        print("Total number of Frequent Patterns:", len(topKFrequentPatterns))
+
+        obj.save(oFile)
+
+        Df = obj.getPatternInDataFrame()
+
+        memUSS = obj.getMemoryUSS()
+
+        print("Total Memory in USS:", memUSS)
+
+        memRSS = obj.getMemoryRSS()
+
+        print("Total Memory in RSS", memRSS)
+
+        run = obj.getRuntime()
+
+        print("Total ExecutionTime in seconds:", run)
 
-        Reference:
-        ----------
-            Zhi-Hong Deng, Guo-Dong Fang: Mining Top-Rank-K Frequent Patterns: DOI: 10.1109/ICMLC.2007.4370261  Source: IEEE Xplore
-            https://ieeexplore.ieee.org/document/4370261
-
-        Attributes:
-        ----------
-            iFile : str
-                Input file name or path of the input file
-            k: int
-                User specified counte of top frequent patterns
-            sep : str
-                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                However, the users can override their default separator.
-            oFile : str
-                Name of the output file or the path of the output file
-            startTime:float
-                To record the start time of the mining process
-            endTime:float
-                To record the completion time of the mining process
-            finalPatterns: dict
-                Storing the complete set of patterns in a dictionary variable
-            memoryUSS : float
-                To store the total amount of USS memory consumed by the program
-            memoryRSS : float
-                To store the total amount of RSS memory consumed by the program
-
-        Methods:
-        -------
-            startMine()
-                Mining process will start from here
-            getPatterns()
-                Complete set of patterns will be retrieved with this function
-            save(oFile)
-                Complete set of frequent patterns will be loaded in to a output file
-            getPatternsAsDataFrame()
-                Complete set of frequent patterns will be loaded in to a dataframe
-            getMemoryUSS()
-                Total amount of USS memory consumed by the mining process will be retrieved from this function
-            getMemoryRSS()
-                Total amount of RSS memory consumed by the mining process will be retrieved from this function
-            getRuntime()
-                Total amount of runtime taken by the mining process will be retrieved from this function
-            creatingItemSets()
-                Scans the dataset or dataframes and stores in list format
-            frequentOneItem()
-                Generates one frequent patterns
-            eclatGeneration(candidateList)
-                It will generate the combinations of frequent items
-            generateFrequentPatterns(tidList)
-                It will generate the combinations of frequent items from a list of items
-
-        Executing the code on terminal:
-        -------------------------------
-
-            Format:
-            ------
-                python3 FAE.py <inputFile> <outputFile> <K>
-
-            Examples:
-            ---------
-                python3 FAE.py sampleDB.txt patterns.txt 10
-
-
-        Sample run of the importing code:
-        ---------------------------------
-
-            import PAMI.frequentPattern.topK.FAE as alg
-
-            obj = alg.FAE(iFile, K)
-
-            obj.startMine()
-
-            topKFrequentPatterns = obj.getPatterns()
-
-            print("Total number of Frequent Patterns:", len(topKFrequentPatterns))
-
-            obj.save(oFile)
-
-            Df = obj.getPatternInDataFrame()
-
-            memUSS = obj.getMemoryUSS()
-
-            print("Total Memory in USS:", memUSS)
-
-            memRSS = obj.getMemoryRSS()
-
-            print("Total Memory in RSS", memRSS)
-
-            run = obj.getRuntime()
-
-            print("Total ExecutionTime in seconds:", run)
-
-        Credits:
-        --------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+    Credits:
+    --------
+        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
 
     """
 
     _startTime = float()
     _endTime = float()
     _k = int()
     _finalPatterns = {}
```

### Comparing `pami-2023.4.1/PAMI/frequentPattern/topk/abstract.py` & `pami-2023.5.1/PAMI/frequentPattern/topk/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/frequentSpatialPattern/__init__.py` & `pami-2023.5.1/PAMI/frequentSpatialPattern/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/frequentSpatialPattern/basic/FSPGrowth.py` & `pami-2023.5.1/PAMI/frequentSpatialPattern/basic/FSPGrowth.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,7 +1,55 @@
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#         from PAMI.frequentSpatialPattern.basic import FSPGrowth as alg
+#
+#         obj = alg.FSPGrowth("sampleTDB.txt", "sampleN.txt", 5)
+#
+#         obj.startMine()
+#
+#         spatialFrequentPatterns = obj.getPatterns()
+#
+#         print("Total number of Spatial Frequent Patterns:", len(spatialFrequentPatterns))
+#
+#         obj.save("outFile")
+#
+#         memUSS = obj.getMemoryUSS()
+#
+#         print("Total Memory in USS:", memUSS)
+#
+#         memRSS = obj.getMemoryRSS()
+#
+#         print("Total Memory in RSS", memRSS)
+#
+#         run = obj.getRuntime()
+#
+#         print("Total ExecutionTime in seconds:", run)
+#
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+
 from PAMI.frequentSpatialPattern.basic import abstract as _ab
 
 
 class _Node:
     """
     A class used to represent the node of frequentPatternTree
     Attributes
@@ -167,16 +215,25 @@
         for item in reversed(flist):
             frequentPatterns.extend(self.getPattern(item, item, minSup, neighbourhood))
         return frequentPatterns
 
 
 class FSPGrowth(_ab._spatialFrequentPatterns):
     """
+    Description:
+    -------------
+        Given a transactional database and a spatial (or neighborhood) file, FSPM aims to discover all of those patterns
+        that satisfy the user-specified minimum support (minSup) and maximum distance (maxDist) constraints
+    Reference:
+    -----------
+        Rage, Uday & Fournier Viger, Philippe & Zettsu, Koji & Toyoda, Masashi & Kitsuregawa, Masaru. (2020).
+        Discovering Frequent Spatial Patterns in Very Large Spatiotemporal Databases.
+
     Attributes:
-    ----------
+    ------------
         iFile : file
             Input file name or path of the input file
         nFile : file
             Neighbourhood file name or path of the neighbourhood file
         oFile : file
             Name of the output file or the path of output file
         minSup : float
@@ -187,16 +244,17 @@
             To record the start time of the mining process
         endTime:float
             To record the completion time of the mining process
         memoryUSS : float
             To store the total amount of USS memory consumed by the program
         memoryRSS : float
             To store the total amount of RSS memory consumed by the program
-    Methods
-    -------
+
+    Methods:
+    --------
         startMine()
             This function starts pattern mining.
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsInDataFrame()
@@ -219,39 +277,54 @@
             This function maps neighbourhood to number.
             Because in this program, each item is mapped to number based on fpList so that it can be distributed.
             So the contents of neighbourhood must also be mapped to a number.
         createFPTree()
             This function creates FPTree.
         getAllFrequentPatterns(data, fpList, ndata)
             This function generates all frequent patterns
+
     Executing the code on terminal :
-    ------------------------------
+    ---------------------------------
         Format:
-            python3 FSPGrowth.py <inputFile> <outputFile> <neighbourFile> <minSup>
+
+            >>> python3 FSPGrowth.py <inputFile> <outputFile> <neighbourFile> <minSup>
         Examples:
-            python3 FSPGrowth.py sampleTDB.txt output.txt sampleN.txt 0.5 (minSup will be considered in percentage of database transactions)
-            python3 FSPGrowth.py sampleTDB.txt output.txt sampleN.txt 3 (minSup will be considered in support count or frequency)
-                                                                (it considers "\t" as separator)
-            python3 FSPGrowth.py sampleTDB.txt output.txt sampleN.txt 3 ','  (it will consider "," as a separator)
+
+            >>> python3 FSPGrowth.py sampleTDB.txt output.txt sampleN.txt 0.5 (minSup will be considered in percentage of database transactions)
+
     Sample run of importing the code :
-    -------------------------------
+    -----------------------------------
+    .. code-block:: python
+
         from PAMI.frequentSpatialPattern.basic import FSPGrowth as alg
+
         obj = alg.FSPGrowth("sampleTDB.txt", "sampleN.txt", 5)
+
         obj.startMine()
+
         spatialFrequentPatterns = obj.getPatterns()
+
         print("Total number of Spatial Frequent Patterns:", len(spatialFrequentPatterns))
+
         obj.save("outFile")
+
         memUSS = obj.getMemoryUSS()
+
         print("Total Memory in USS:", memUSS)
+
         memRSS = obj.getMemoryRSS()
+
         print("Total Memory in RSS", memRSS)
+
         run = obj.getRuntime()
+
         print("Total ExecutionTime in seconds:", run)
+
     Credits:
-    -------
+    ----------
         The complete program was written by Yudai Masu under the supervision of Professor Rage Uday Kiran.
     """
 
     _minSup = float()
     _startTime = float()
     _endTime = float()
     _finalPatterns = {}
```

### Comparing `pami-2023.4.1/PAMI/frequentSpatialPattern/basic/SpatialECLAT.py` & `pami-2023.5.1/PAMI/frequentSpatialPattern/basic/SpatialECLAT.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,20 +1,72 @@
+#  **Importing this algorithm into a python program**
+#  ---------------------------------------------------
+#
+#     from PAMI.frequentSpatialPattern.basic import SpatialECLAT as alg
+#
+#     obj = alg.SpatialECLAT("sampleTDB.txt", "sampleN.txt", 5)
+#
+#     obj.startMine()
+#
+#     spatialFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Spatial Frequent Patterns:", len(spatialFrequentPatterns))
+#
+#     obj.save("outFile")
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 from PAMI.frequentSpatialPattern.basic import abstract as _ab
 
 
 class SpatialECLAT(_ab._spatialFrequentPatterns):
-    """ 
+    """
+    Description:
+    --------------
         Spatial Eclat is a Extension of ECLAT algorithm,which  stands for Equivalence Class Clustering and bottom-up
         Lattice Traversal.It is one of the popular methods of Association Rule mining. It is a more efficient and
         scalable version of the Apriori algorithm.
 
-            ...
+    Reference:
+    -----------
+        Rage, Uday & Fournier Viger, Philippe & Zettsu, Koji & Toyoda, Masashi & Kitsuregawa, Masaru. (2020).
+        Discovering Frequent Spatial Patterns in Very Large Spatiotemporal Databases.
 
     Attributes :
-    ----------
+    ---------------
         iFile : str
             Input file name or path of the input file
         nFile: str
             Name of Neighbourhood file name
         minSup: int or float or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
@@ -32,15 +84,15 @@
             To store the total amount of USS memory consumed by the program
         memoryRSS : float
             To store the total amount of RSS memory consumed by the program
         Database : list
             To store the complete set of transactions available in the input database/file
 
     Methods :
-    -------
+    ------------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -65,29 +117,27 @@
             To convert the given user specified value    
         getNeighbourItems(keySet):
             A function to get common neighbours of a itemSet
         mapNeighbours(file):
             A function to map items to their neighbours
 
     Executing the code on terminal :
-    ------------------------------
-        Format: 
-            python3 SpatialECLAT.py <inputFile> <outputFile> <neighbourFile> <minSup>
+    ----------------------------------
+        Format:
+
+            >>> python3 SpatialECLAT.py <inputFile> <outputFile> <neighbourFile> <minSup>
             
         Examples:
-            python3 SpatialECLAT.py sampleTDB.txt output.txt sampleN.txt 0.5 (minSup will be considered in percentage of database transactions)
-            
-            python3 SpatialECLAT.py sampleTDB.txt output.txt sampleN.txt 3 (minSup will be considered in support count or frequency)
-                                                                (it considers "\t" as separator)
-                    
-            python3 SpatialECLAT.py sampleTDB.txt output.txt sampleN.txt 3 ','  (it will consider "," as a separator)
 
+            >>> python3 SpatialECLAT.py sampleTDB.txt output.txt sampleN.txt 0.5 (minSup will be considered in percentage of database transactions)
+            
     Sample run of importing the code :
-    -------------------------------
-        
+    -----------------------------------
+    .. code-block:: python
+
         from PAMI.frequentSpatialPattern.basic import SpatialECLAT as alg
         
         obj = alg.SpatialECLAT("sampleTDB.txt", "sampleN.txt", 5)
 
         obj.startMine()
 
         spatialFrequentPatterns = obj.getPatterns()
@@ -106,15 +156,15 @@
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
 
 
     Credits:
-    -------
+    ---------
         The complete program was written by B.Sai Chitra under the supervision of Professor Rage Uday Kiran.
     """
 
     _minSup = float()
     _startTime = float()
     _endTime = float()
     _finalPatterns = {}
```

### Comparing `pami-2023.4.1/PAMI/frequentSpatialPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/frequentSpatialPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/fuzzyCorrelatedPattern/__init__.py` & `pami-2023.5.1/PAMI/fuzzyCorrelatedPattern/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/fuzzyCorrelatedPattern/basic/FCPGrowth.py` & `pami-2023.5.1/PAMI/fuzzyCorrelatedPattern/basic/FCPGrowth.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,35 +1,34 @@
-#  Copyright (C)  2021 Rage Uday Kiran
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-#
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+# **Importing this algorithm into a python program**
+# -----------------------------------
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-
+#     from PAMI.fuzzyCorrelatedPattern.basic import FCPGrowth as alg
+#
+#     obj = alg.FCPGrowth("input.txt",2,0.4)
+#
+#     obj.startTimeMine()
+#
+#     correlatedFuzzyFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Correlated Fuzzy Frequent Patterns:", len(correlatedFuzzyFrequentPatterns))
+#
+#     obj.save("output")
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime
+#
+#     print("Total ExecutionTime in seconds:", run)
 from PAMI.fuzzyCorrelatedPattern.basic import abstract as _ab
 
 
 class _FFList:
     """
      A class represent a Fuzzy List of an element
 
@@ -174,19 +173,26 @@
         self.item = 0
         self.quantity = 0
         self.region = 'N'
 
 
 class FCPGrowth(_ab._corelatedFuzzyFrequentPatterns):
     """
+    Description:
+    -------------
         FCPGrowth is the algorithm to discover Correlated Fuzzy-frequent patterns in a transactional database.
         it is based on traditional fuzzy frequent pattern mining.
 
+    Reference:
+    ---------------
+        Lin, N.P., & Chueh, H. (2007). Fuzzy correlation rules mining.
+        https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.416.6053&rep=rep1&type=pdf
+
     Attributes :
-    ----------
+    -------------
         iFile : file
             Name of the input file to mine complete set of fuzzy spatial frequent patterns
         oFile : file
                Name of the oFile file to store complete set of fuzzy spatial frequent patterns
         minSup : int
                 The user given support
         minAllConf: float
@@ -212,15 +218,15 @@
         jointCnt: int
             To keep track of the number of FFI-list that was constructed
         BufferSize: int
             represent the size of Buffer
         itemBuffer list
             to keep track of items in buffer
     Methods :
-    -------
+    ------------
         startTimeMine()
             Mining process will startTime from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -241,28 +247,27 @@
             A function to construct Fuzzy itemSet from 2 fuzzy itemSets
         findElementWithTID(uList, tid)
             To find element with same tid as given
         WriteOut(prefix, prefixLen, item, sumIUtil,ratio)
             To Store the patten      
 
     Executing the code on terminal :
-    -------
-            Format: 
-                python3 FCPGrowth.py <inputFile> <outputFile> <minSup> <minAllConf> <sep>
-            Examples: 
-                    python3 FCPGrowth.py sampleTDB.txt output.txt 2 0.2 (minSup will be considered in support count or frequency)
-                    
-                    python3 FCPGrowth.py sampleTDB.txt output.txt 0.25 0.2 (minSup and maxPer will be considered in percentage of database)
-                                                                     (it will consider separator as "\t")
+    -------------------------------------
+            Format:
+
+                >>> python3 FCPGrowth.py <inputFile> <outputFile> <minSup> <minAllConf> <sep>
+            Examples:
+
+                >>> python3 FCPGrowth.py sampleTDB.txt output.txt 2 0.2 (minSup will be considered in support count or frequency)
                     
-                    python3 FCPGrowth.py sampleTDB.txt output.txt 2 0.2 ,
-                                                                      (it will consider separator as ',')
+
     Sample run of importing the code:
-    -------------------------------
-        
+    -----------------------------------
+    .. code-block:: python
+
         from PAMI.fuzzyCorrelatedPattern.basic import FCPGrowth as alg
 
         obj = alg.FCPGrowth("input.txt",2,0.4)
 
         obj.startTimeMine()
 
         correlatedFuzzyFrequentPatterns = obj.getPatterns()
@@ -280,15 +285,15 @@
         print("Total Memory in RSS", memRSS)
 
         run = obj.getRuntime
 
         print("Total ExecutionTime in seconds:", run)
 
     Credits:
-    -------
+    ---------
             The complete program was written by B.Sai Chitra under the supervision of Professor Rage Uday Kiran.
 
     """
     _startTime = float()
     _endTime = float()
     _minSup = str()
     _maxPer = float()
```

### Comparing `pami-2023.4.1/PAMI/fuzzyCorrelatedPattern/basic/__init__.py` & `pami-2023.5.1/PAMI/fuzzyCorrelatedPattern/basic/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/fuzzyCorrelatedPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/fuzzyCorrelatedPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/fuzzyFrequentPatterns/__init__.py` & `pami-2023.5.1/PAMI/fuzzyFrequentPatterns/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/fuzzyFrequentPatterns/basic/FFIMiner.py` & `pami-2023.5.1/PAMI/fuzzyFrequentPatterns/basic/FFIMiner.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,34 +1,54 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-#
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     from PAMI.fuzzyFrequentPatterns import FFIMiner as alg
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     obj = alg.FFIMiner("input.txt", 2)
+#
+#     obj.startMine()
+#
+#     fuzzyFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Fuzzy Frequent Patterns:", len(fuzzyFrequentPatterns))
+#
+#     obj.save("outputFile")
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 from PAMI.fuzzyFrequentPatterns.basic import abstract as _ab
 
 
 class _FFList:
     """
      A class represent a Fuzzy List of an element
@@ -106,25 +126,29 @@
     def __init__(self):
         self.item = 0
         self.quantity = 0
 
 
 class FFIMiner(_ab._fuzzyFrequentPattenrs):
     """
+    Description:
+    -------------
         Fuzzy Frequent  Pattern-Miner is desired to find all  frequent fuzzy patterns which is on-trivial and challenging problem
         to its huge search space.we are using efficient pruning techniques to reduce the search space.
+
     Reference :
-    ---------
+    --------------
         Lin, Chun-Wei & Li, Ting & Fournier Viger, Philippe & Hong, Tzung-Pei. (2015).
         A fast Algorithm for mining fuzzy frequent itemsets. Journal of Intelligent & Fuzzy Systems. 29.
         2373-2379. 10.3233/IFS-151936.
         https://www.researchgate.net/publication/286510908_A_fast_Algorithm_for_mining_fuzzy_frequent_itemSets
 
     Attributes :
-    ----------
+    ---------------
+    
         iFile : string
             Name of the input file to mine complete set of fuzzy  frequent patterns
         fmFile : string
             Name of the fuzzy membership file to mine complete set of fuzzy  frequent patterns
         oFile : string
                Name of the oFile file to store complete set of fuzzy  frequent patterns
         minSup : float
@@ -149,16 +173,17 @@
             To Keep track of fuzzy regions of item
         jointCnt: int
             To keep track of the number of ffi-list that was constructed
         BufferSize: int
             represent the size of Buffer
         itemBuffer list
             to keep track of items in buffer
+
     Methods :
-    -------
+    ------------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -179,27 +204,26 @@
             A function to construct Fuzzy itemSet from 2 fuzzy itemSets
         findElementWithTID(uList, tid)
             To find element with same tid as given
         WriteOut(prefix, prefixLen, item, sumIUtil)
             To Store the patten
 
     Executing the code on terminal :
-    -------
+    --------------------------------
         Format:
-            python3 FFIMinerMiner.py <inputFile> <outputFile> <minSup> <separator>
+
+            >>> python3 FFIMinerMiner.py <inputFile> <outputFile> <minSup> <separator>
         Examples:
-            python3  FFIMinerMiner.py sampleTDB.txt output.txt 6  (minSup will be considered in support count or frequency)
 
-            python3  FFIMinerMiner.py sampleTDB.txt output.txt 0.3 (minSup and maxPer will be considered in percentage of database)
-                                                      (it will consider '\t' as a separator)
+            >>> python3  FFIMinerMiner.py sampleTDB.txt output.txt 6  (minSup will be considered in support count or frequency)
 
-            python3  FFIMinerMiner.py sampleTDB.txt output.txt 6 , (it consider ',' as a separator)
 
     Sample run of importing the code:
-    -------------------------------
+    ----------------------------------
+    .. code-block:: python
 
         from PAMI.fuzzyFrequentPatterns import FFIMiner as alg
 
         obj = alg.FFIMiner("input.txt", 2)
 
         obj.startMine()
 
@@ -219,17 +243,19 @@
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
 
 
     Credits:
-    -------
+    -----------
         The complete program was written by B.Sai Chitra under the supervision of Professor Rage Uday Kiran.
+    
     """
+    
     _startTime = float()
     _endTime = float()
     _minSup = str()
     _maxPer = float()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
```

### Comparing `pami-2023.4.1/PAMI/fuzzyFrequentPatterns/basic/FFIMiner_old.py` & `pami-2023.5.1/PAMI/fuzzyFrequentPatterns/basic/FFIMiner_old.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,34 +1,7 @@
-#  Copyright (C)  2021 Rage Uday Kiran
-#
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-#
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
 
 from PAMI.fuzzyFrequentPatterns.basic import abstract as _ab
 
 
 class _FFList:
     """
      A class represent a Fuzzy List of an element
```

### Comparing `pami-2023.4.1/PAMI/fuzzyFrequentPatterns/basic/abstract.py` & `pami-2023.5.1/PAMI/fuzzyFrequentPatterns/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/fuzzyFrequentSpatialPattern/__init__.py` & `pami-2023.5.1/PAMI/fuzzyFrequentSpatialPattern/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/fuzzyFrequentSpatialPattern/basic/FFSPMiner.py` & `pami-2023.5.1/PAMI/fuzzyPeriodicFrequentPattern/basic/FPFPMiner.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,139 +1,180 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+# Sample run of importing the code:
+#     -------------------------------
+#
+#         from PAMI.fuzzyPeriodicFrequentPattern.basic import FPFPMiner as alg
+#
+#         obj =alg.FPFPMiner("input.txt",2,3)
+#
+#         obj.startMine()
+#
+#         periodicFrequentPatterns = obj.getPatterns()
+#
+#         print("Total number of Fuzzy Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+#
+#         obj.save("output.txt")
+#
+#         memUSS = obj.getMemoryUSS()
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-#
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#         print("Total Memory in USS:", memUSS)
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#         memRSS = obj.getMemoryRSS()
+#
+#         print("Total Memory in RSS", memRSS)
+#
+#         run = obj.getRuntime()
+#
+#         print("Total ExecutionTime in seconds:", run)
+
+
+__copyright__ = """(Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
 
-from PAMI.fuzzyFrequentSpatialPattern.basic import abstract as _ab
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+)"""
+
+
+from PAMI.fuzzyPeriodicFrequentPattern.basic import abstract as _ab
 
 
 class _FFList:
     """
-     A class represent a Fuzzy List of an element
+        A class represent a Fuzzy List of an element
 
-    Attributes :
+    Attributes:
     ----------
-         item: int
-             the item name
-         sumIUtil: float
-             the sum of utilities of an fuzzy item in database
-         sumRUtil: float
-             the sum of resting values of a fuzzy item in database
-         elements: list
-             a list of elements contain tid,Utility and resting values of element in each transaction
-    Methods :
+        item: int
+            the item name
+        sumLUtil: float
+            the sum of utilities of an fuzzy item in database
+        sumRUtil: float
+            the sum of resting values of a fuzzy item in database
+        elements: list
+            list of elements contain tid,Utility and resting values of element in each transaction
+        maxPeriod: int
+            it represent the max period of a item
+
+    Methods:
     -------
         addElement(element)
             Method to add an element to this fuzzy list and update the sums at the same time.
 
         printElement(e)
             Method to print elements
 
     """
 
     def __init__(self, itemName):
         self.item = itemName
-        self.sumIUtil = 0.0
+        self.sumLUtil = 0.0
         self.sumRUtil = 0.0
         self.elements = []
+        self.maxPeriod = 0
 
     def addElement(self, element):
         """
             A Method that add a new element to FFList
 
             :param element: an element to be add to FFList
             :pram type: Element
         """
-        self.sumIUtil += element.iUtils
+        self.sumLUtil += element.lUtils
         self.sumRUtil += element.rUtils
         self.elements.append(element)
+        self.maxPeriod = max(self.maxPeriod, element.period)
 
     def printElement(self):
         """
             A Method to Print elements in the FFList
         """
         for ele in self.elements:
-            print(ele.tid, ele.iUtils, ele.rUtils)
+            print(ele.tid, ele.lUtils, ele.rUtils, ele.period)
 
 
 class _Element:
     """
         A class represents an Element of a fuzzy list
 
-    Attributes :
-    ----------
+        Attributes:
+        ----------
         tid : int
             keep tact of transaction id
-        iUtils: float
+        lUtils: float
             the utility of an fuzzy item in the transaction
         rUtils : float
-            the neighbourhood resting value of an fuzzy item in the transaction
+            the resting value of an fuzzy item in the transaction
+        period: int
+            represent the period of the element
     """
 
-    def __init__(self, tid, iUtil, rUtil):
+    def __init__(self, tid, iUtil, rUtil, period):
         self.tid = tid
-        self.iUtils = iUtil
+        self.lUtils = iUtil
         self.rUtils = rUtil
+        self.period = period
 
 
 class _Pair:
     """
-        A class to store item and it's quantity together
+        A class to store item name and quantity together.
     """
 
     def __init__(self):
         self.item = 0
         self.quantity = 0
 
 
-class FFSPMiner(_ab._fuzzySpatialFrequentPatterns):
+class FPFPMiner(_ab._fuzzyPeriodicFrequentPatterns):
     """
-        Fuzzy Frequent Spatial Pattern-Miner is desired to find all Spatially frequent fuzzy patterns
-        which is on-trivial and challenging problem to its huge search space.we are using efficient pruning
-         techniques to reduce the search space.
+    Description:
+    -------------
+
+        Fuzzy Periodic Frequent Pattern Miner is desired to find all fuzzy periodic frequent patterns which is
+        on-trivial and challenging problem to its huge search space.we are using efficient pruning
+        techniques to reduce the search space.
 
     Reference:
-    ---------
-        Reference: P. Veena, B. S. Chithra, R. U. Kiran, S. Agarwal and K. Zettsu, "Discovering Fuzzy Frequent
-        Spatial Patterns in Large Quantitative Spatiotemporal databases," 2021 IEEE International Conference on Fuzzy Systems
-        (FUZZ-IEEE), 2021, pp. 1-8, doi: 10.1109/FUZZ45933.2021.9494594.
+    -----------
+        Lin, N.P., & Chueh, H. (2007). Fuzzy correlation rules mining.
+        https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.416.6053&rep=rep1&type=pdf
 
-    Attributes :
+    Attributes:
     ----------
         iFile : file
             Name of the input file to mine complete set of fuzzy spatial frequent patterns
         oFile : file
                Name of the oFile file to store complete set of fuzzy spatial frequent patterns
         minSup : float
-            The user given minimum support
-        neighbors: map
-            keep track of neighbours of elements
+            The user given support
+        period: int
+            periodicity of an element
         memoryRSS : float
                 To store the total amount of RSS memory consumed by the program
         startTime:float
                To record the start time of the mining process
         endTime:float
             To record the completion time of the mining process
         itemsCnt: int
@@ -150,15 +191,21 @@
             To Keep track of fuzzy regions of item
         jointCnt: int
             To keep track of the number of FFI-list that was constructed
         BufferSize: int
             represent the size of Buffer
         itemBuffer list
             to keep track of items in buffer
-    Methods :
+        maxTID: int
+            represent the maximum tid of the database
+        lastTIDs: map
+            represent the last tid of fuzzy items
+        itemsToRegion: map
+            represent items with respective regions
+    Methods:
     -------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
@@ -172,47 +219,49 @@
             Total amount of runtime taken by the mining process will be retrieved from this function
         convert(value):
             To convert the given user specified value
         FSFIMining( prefix, prefixLen, fsFim, minSup)
             Method generate FFI from prefix
         construct(px, py)
             A function to construct Fuzzy itemSet from 2 fuzzy itemSets
-        Intersection(neighbourX,neighbourY)
-            Return common neighbours of 2 itemSet Neighbours
-        findElementWithTID(uList, tid)
+        findElementWithTID(UList, tid)
             To find element with same tid as given
         WriteOut(prefix, prefixLen, item, sumIUtil,period)
             To Store the patten
 
     Executing the code on terminal :
     -------
         Format:
-            python3 FFSPMiner_old.py <inputFile> <outputFile> <neighbours> <minSup> <sep>
+        ------
+            python3 FPFPMiner_old.py <inputFile> <outputFile> <minSup> <maxPer> <sep>
+
         Examples:
-            python3  FFSPMiner_old.py sampleTDB.txt output.txt sampleN.txt 3  (minSup will be considered in support count or frequency)
+        ------
+            python3  FPFPMiner_old.py sampleTDB.txt output.txt 2 3 (minSup and maxPer will be considered in support count or frequency)
+
+            python3  FPFPMiner_old.py sampleTDB.txt output.txt 0.25 0.3 (minSup and maxPer will be considered in percentage of database)
+                                        (will consider "\t" as separator)
+
+            python3  FPFPMiner_old.py sampleTDB.txt output.txt 2 3  ,(will consider ',' as separator)
 
-            python3  FFSPMiner_old.py sampleTDB.txt output.txt sampleN.txt 0.3 (minSup and maxPer will be considered in percentage of database)
-                                                            (will consider "\t" as separator in both input and neighbourhood files)
 
-            python3  FFSPMiner_old.py sampleTDB.txt output.txt sampleN.txt 3 ,
-                                                              (will consider "," as separator in both input and neighbourhood files)
     Sample run of importing the code:
     -------------------------------
 
-        from PAMI.fuzzyFrequentSpatialPattern import FFSPMiner as alg
+        from PAMI.fuzzyPeriodicFrequentPattern.basic import FPFPMiner as alg
 
-        obj = alg.FFSPMiner("input.txt", "neighbours.txt", 2)
+        obj =alg.FPFPMiner("input.txt",2,3)
 
         obj.startMine()
 
-        fuzzySpatialFrequentPatterns = obj.getPatterns()
+        periodicFrequentPatterns = obj.getPatterns()
 
-        print("Total number of fuzzy frequent spatial patterns:", len(fuzzySpatialFrequentPatterns))
+        print("Total number of Fuzzy Periodic Frequent Patterns:", len(periodicFrequentPatterns))
 
-        obj.save("outputFile")
+        obj.save("output.txt")
 
         memUSS = obj.getMemoryUSS()
 
         print("Total Memory in USS:", memUSS)
 
         memRSS = obj.getMemoryRSS()
 
@@ -220,43 +269,46 @@
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
 
     Credits:
     -------
-            The complete program was written by B.Sai Chitra under the supervision of Professor Rage Uday Kiran.
-    """
+            The complete program was written by Sai Chitra.B under the supervision of Professor Rage Uday Kiran.
 
+    """
     _startTime = float()
     _endTime = float()
     _minSup = str()
     _maxPer = float()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
-    _nFile = " "
     _memoryUSS = float()
     _memoryRSS = float()
-    _sep = "\t"
+    _sep = " "
+    _Database = []
     _transactions = []
     _fuzzyValues = []
+    _ts = []
 
-    def __init__(self, iFile, nFile, minSup, sep="\t"):
-        super().__init__(iFile, nFile, minSup, sep)
-        self._mapItemNeighbours = {}
-        self._startTime = 0
-        self._endTime = 0
-        self._mapItemSum = {}
-        self._joinsCnt = 0
+    def __init__(self, iFile, minSup, period, sep="\t"):
+        super().__init__(iFile, minSup, period, sep)
+        self._oFile = ""
         self._BufferSize = 200
         self._itemSetBuffer = []
+        self._mapItemSum = {}
         self._finalPatterns = {}
-        self._dbLen = 0
+        self._joinsCnt = 0
         self._itemsCnt = 0
+        self._startTime = float()
+        self._endTime = float()
+        self._memoryUSS = float()
+        self._memoryRSS = float()
+        self._dbLen = 0
 
     def _compareItems(self, o1, o2):
         """
             A Function that sort all FFI-list in ascending order of Support
         """
         compare = self._mapItemSum[o1.item] - self._mapItemSum[o2.item]
         if compare == 0:
@@ -278,206 +330,164 @@
             if '.' in value:
                 value = (self._dbLen * value)
             else:
                 value = int(value)
         return value
 
     def _creatingItemSets(self):
-        self._transactions, self._fuzzyValues = [], []
+        data, self._transactions, self._fuzzyValues, ts = [], [], [], []
         if isinstance(self._iFile, _ab._pd.DataFrame):
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
+            if 'TS' in i:
+                self._ts = self._iFile['TS'].tolist()
             if 'Transactions' in i:
-                self.transactions = self._iFile['Transactions'].tolist()
+                self._transactions = self._iFile['Transactions'].tolist()
             if 'fuzzyValues' in i:
-                self.fuzzyValues = self._iFile['Utilities'].tolist()
-
+                self._fuzzyValues = self._iFile['fuzzyValues'].tolist()
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
+                count = 0
                 for line in data:
                     line = line.decode("utf-8")
                     line = line.split("\n")[0]
                     parts = line.split(":")
                     parts[0] = parts[0].strip()
                     parts[1] = parts[1].strip()
                     items = parts[0].split(self._sep)
                     quantities = parts[1].split(self._sep)
-                    self.transactions.append([x for x in items])
-                    self.fuzzyValues.append([float(x) for x in quantities])
+                    self._ts.append(int(items[0]))
+                    self._transactions.append([x for x in items[1:]])
+                    self._fuzzyValues.append([float(x) for x in quantities])
+                    count += 1
             else:
                 try:
                     with open(self._iFile, 'r', encoding='utf-8') as f:
+                        count = 0
                         for line in f:
                             line = line.split("\n")[0]
                             parts = line.split(":")
                             parts[0] = parts[0].strip()
                             parts[1] = parts[1].strip()
                             items = parts[0].split(self._sep)
                             quantities = parts[1].split(self._sep)
-                            self._transactions.append([x for x in items])
+                            self._ts.append(int(items[0]))
+                            self._transactions.append([x for x in items[1:]])
                             self._fuzzyValues.append([float(x) for x in quantities])
-                except IOError:
-                    print("File Not Found")
-                    quit()
-
-    def _mapNeighbours(self):
-        self._mapItemNeighbours = {}
-        if isinstance(self._nFile, _ab._pd.DataFrame):
-            data, items = [], []
-            if self._nFile.empty:
-                print("its empty..")
-            i = self._nFile.columns.values.tolist()
-            if 'items' in i:
-                items = self._nFile['items'].tolist()
-            if 'Neighbours' in i:
-                data = self._nFile['Neighbours'].tolist()
-            for k in range(len(items)):
-                self._mapItemNeighbours[items[k]] = data[k]
-
-        if isinstance(self._nFile, str):
-            if _ab._validators.url(self._nFile):
-                data = _ab._urlopen(self._nFile)
-                for line in data:
-                    line = line.decode("utf-8")
-                    line = line.split("\n")[0]
-                    parts = [i.rstrip() for i in line.split(self._sep)]
-                    parts = [x for x in parts]
-                    item = parts[0]
-                    neigh1 = []
-                    for i in range(1, len(parts)):
-                        neigh1.append(parts[i])
-                    self._mapItemNeighbours[item] = neigh1
-            else:
-                try:
-                    with open(self._nFile, 'r', encoding='utf-8') as f:
-                        for line in f:
-                            line = line.split("\n")[0]
-                            parts = [i.rstrip() for i in line.split(self._sep)]
-                            parts = [x for x in parts]
-                            item = parts[0]
-                            neigh1 = []
-                            for i in range(1, len(parts)):
-                                neigh1.append(parts[i])
-                            self._mapItemNeighbours[item] = neigh1
+                            count += 1
                 except IOError:
                     print("File Not Found")
                     quit()
 
     def startMine(self):
-        """ Frequent pattern mining process will start from here
         """
+            Fuzzy periodic Frequent pattern mining process will start from here
+        """
+        maxTID = 0
+        lastTIDs = {}
         self._startTime = _ab._time.time()
         self._creatingItemSets()
         self._finalPatterns = {}
-        self._mapNeighbours()
+        tid = int()
         for line in range(len(self._transactions)):
+            tid = int(self._ts[line])
+            self._dbLen += 1
             items = self._transactions[line]
             quantities = self._fuzzyValues[line]
-            self._dbLen += 1
+            if tid < maxTID:
+                maxTID = tid
             for i in range(0, len(items)):
                 item = items[i]
                 if item in self._mapItemSum:
                     self._mapItemSum[item] += quantities[i]
                 else:
                     self._mapItemSum[item] = quantities[i]
-        listOfFFList = []
+        listOfFFIList = []
         mapItemsToFFLIST = {}
-        #self._minSup = self._convert(self._minSup)
+        # self._minSup = self._convert(self._minSup)
+        self._maxPer = self._convert(self._maxPer)
         for item1 in self._mapItemSum.keys():
             item = item1
             if self._mapItemSum[item] >= self._minSup:
-                fuList = _FFList(item)
-                mapItemsToFFLIST[item] = fuList
-                listOfFFList.append(fuList)
-        listOfFFList.sort(key=_ab._functools.cmp_to_key(self._compareItems))
-        tid = 0
+                fUList = _FFList(item)
+                k = tuple([item])
+                mapItemsToFFLIST[k] = fUList
+                listOfFFIList.append(fUList)
+                lastTIDs[item] = tid
+        listOfFFIList.sort(key=_ab._functools.cmp_to_key(self._compareItems))
         for line in range(len(self._transactions)):
+            tid = int(self._ts[line])
             items = self._transactions[line]
             quantities = self._fuzzyValues[line]
             revisedTransaction = []
             for i in range(0, len(items)):
                 pair = _Pair()
                 pair.item = items[i]
-                pair.quantity = quantities[i]
                 item = pair.item
+                pair.quantity = quantities[i]
                 if self._mapItemSum[item] >= self._minSup:
                     if pair.quantity > 0:
                         revisedTransaction.append(pair)
             revisedTransaction.sort(key=_ab._functools.cmp_to_key(self._compareItems))
             for i in range(len(revisedTransaction) - 1, -1, -1):
                 pair = revisedTransaction[i]
                 remainUtil = 0
-                for j in range(len(revisedTransaction) - 1, i, -1):
-                    if self._mapItemNeighbours.get(pair.item[0]) is None:
-                        continue
-                    if revisedTransaction[j].item[0] in self._mapItemNeighbours[pair.item[0]]:
-                        remainUtil += revisedTransaction[j].quantity
-                remainingUtility = remainUtil
-                if mapItemsToFFLIST.get(pair.item) is not None:
-                    FFListOfItem = mapItemsToFFLIST[pair.item]
-                    element = _Element(tid, pair.quantity, remainingUtility)
+                for j in range(len(revisedTransaction) - 1, i - 1, -1):
+                    remainUtil += revisedTransaction[j].quantity
+                if pair.quantity > remainUtil:
+                    remainingUtility = pair.quantity
+                else:
+                    remainingUtility = remainUtil
+                if mapItemsToFFLIST.get(tuple([pair.item])) is not None:
+                    FFListOfItem = mapItemsToFFLIST[tuple([pair.item])]
+                    if len(FFListOfItem.elements) == 0:
+                        element = _Element(tid, pair.quantity, remainingUtility, 0)
+                    else:
+                        if lastTIDs[pair.item] == tid:
+                            element = _Element(tid, pair.quantity, remainingUtility, maxTID - tid)
+                        else:
+                            lastTid = FFListOfItem.elements[-1].tid
+                            curPer = tid - lastTid
+                            element = _Element(tid, pair.quantity, remainingUtility, curPer)
                     FFListOfItem.addElement(element)
-            tid += 1
-        itemNeighbours = list(self._mapItemNeighbours.keys())
-        self._FSFIMining(self._itemSetBuffer, 0, listOfFFList, self._minSup, itemNeighbours)
+        self._FSFIMining(self._itemSetBuffer, 0, listOfFFIList, self._minSup)
         self._endTime = _ab._time.time()
         process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryUSS = float()
         self._memoryRSS = float()
         self._memoryUSS = process.memory_full_info().uss
         self._memoryRSS = process.memory_info().rss
 
-    def _FSFIMining(self, prefix, prefixLen, FSFIM, minSup, itemNeighbours):
-        """Generates FFSPMiner from prefix
+    def _FSFIMining(self, prefix, prefixLen, fsFim, minSup):
 
-        :param prefix: the prefix patterns of FFSPMiner
+        """Generates FPFP from prefix
+
+        :param prefix: the prefix patterns of FPFP
         :type prefix: len
         :param prefixLen: the length of prefix
         :type prefixLen: int
-           :param FSFIM: the Fuzzy list of prefix itemSets
-           :type FSFIM: list
-           :param minSup: the minimum support of
-           :type minSup:int
-           :param itemNeighbours: the set of common neighbours of prefix
-           :type itemNeighbours: list or set
-        """
-        for i in range(0, len(FSFIM)):
-            X = FSFIM[i]
-            if X.sumIUtil >= minSup:
-                self._WriteOut(prefix, prefixLen, X.item, X.sumIUtil)
-            newNeighbours = self._Intersection(self._mapItemNeighbours.get(X.item[0]), itemNeighbours)
+        :param fsFim: the Fuzzy list of prefix itemSets
+        :type fsFim: list
+        :param minSup: the minimum support of
+        :type minSup:int
+        """
+        for i in range(0, len(fsFim)):
+            X = fsFim[i]
+            if X.sumLUtil >= minSup and X.maxPeriod <= self._maxPer:
+                self._WriteOut(prefix, prefixLen, X.item, X.sumLUtil, X.maxPeriod)
             if X.sumRUtil >= minSup:
                 exULs = []
-                for j in range(i + 1, len(FSFIM)):
-                    Y = FSFIM[j]
-                    if Y.item[0] in newNeighbours:
-                        exULs.append(self._construct(X, Y))
-                        self._joinsCnt += 1
+                for j in range(i + 1, len(fsFim)):
+                    Y = fsFim[j]
+                    exULs.append(self._construct(X, Y))
+                    self._joinsCnt += 1
                 self._itemSetBuffer.insert(prefixLen, X.item)
-                self._FSFIMining(self._itemSetBuffer, prefixLen + 1, exULs, minSup, newNeighbours)
-
-    def _Intersection(self, neighbourX, neighbourY):
-        """
-            A function to get common neighbours from 2 itemSets
-            :param neighbourX: the set of neighbours of itemSet 1
-            :type neighbourX: set or list
-            :param neighbourY: the set of neighbours of itemSet 2
-            :type neighbourY: set or list
-            :return : set of common neighbours of 2 itemSets
-            :rtype :set
-        """
-        result = []
-        if neighbourX is None or neighbourY is None:
-            return result
-        for i in range(0, len(neighbourX)):
-            if neighbourX[i] in neighbourY:
-                result.append(neighbourX[i])
-        return result
+                self._FSFIMining(self._itemSetBuffer, prefixLen + 1, exULs, minSup, )
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
         :return: returning USS memory consumed by the mining process
         :rtype: float
         """
@@ -499,88 +509,91 @@
         :return: returning total amount of runtime taken by the mining process
         :rtype: float
        """
         return self._endTime - self._startTime
 
     def _construct(self, px, py):
         """
-            A function to construct a new Fuzzy itemSet from 2 fuzzy itemSets
+            A function to construct a new Fuzzy item set from 2 fuzzy itemSets
 
-            :param px:the itemSet px
+            :param px:the item set px
             :type px:FFI-List
-            :param py:itemSet py
+            :param py:item set py
             :type py:FFI-List
-            :return :the itemSet of pxy(px and py)
+            :return :the item set of pxy(px and py)
             :rtype :FFI-List
         """
         pxyUL = _FFList(py.item)
+        prev = 0
         for ex in px.elements:
             ey = self._findElementWithTID(py, ex.tid)
             if ey is None:
                 continue
-            eXY = _Element(ex.tid, min([ex.iUtils, ey.iUtils], key=lambda x: float(x)), ey.rUtils)
+            eXY = _Element(ex.tid, min([ex.lUtils, ey.lUtils], key=lambda x: float(x)), ey.rUtils, ex.tid - prev)
             pxyUL.addElement(eXY)
+            prev = ex.tid
         return pxyUL
 
-    def _findElementWithTID(self, uList, tid):
+    def _findElementWithTID(self, UList, tid):
         """
             To find element with same tid as given
-            :param uList:fuzzyList
-            :type uList:FFI-List
+            :param UList: fuzzy list
+            :type UList:FFI-List
             :param tid:transaction id
             :type tid:int
-            :return:element tid as given
+            :return:element eith tid as given
             :rtype: element if exist or None
         """
-        List = uList.elements
+        List = UList.elements
         first = 0
         last = len(List) - 1
         while first <= last:
             mid = (first + last) >> 1
             if List[mid].tid < tid:
                 first = mid + 1
             elif List[mid].tid > tid:
                 last = mid - 1
             else:
                 return List[mid]
         return None
 
-    def _WriteOut(self, prefix, prefixLen, item, sumIUtil):
+    def _WriteOut(self, prefix, prefixLen, item, sumLUtil, period):
         """
             To Store the patten
             :param prefix: prefix of itemSet
             :type prefix: list
             :param prefixLen: length of prefix
             :type prefixLen: int
             :param item: the last item
             :type item: int
-            :param sumIUtil: sum of utility of itemSet
-            :type sumIUtil: float
-
+            :param sumLUtil: sum of utility of itemSet
+            :type sumLUtil: float
+            :param period: represent the period of itemSet
+            :type period: int
         """
         self._itemsCnt += 1
         res = ""
         for i in range(0, prefixLen):
-            res += str(prefix[i]) + "\t"
+            res += str(prefix[i]) +  "\t"
         res += str(item)
-        res1 = str(sumIUtil)
-        self._finalPatterns[res] = res1
+        #res1 = str(sumLUtil) + " : " + str(period)
+        self._finalPatterns[res] = [sumLUtil, period]
 
     def getPatternsAsDataFrame(self):
         """Storing final frequent patterns in a dataframe
 
         :return: returning frequent patterns in a dataframe
         :rtype: pd.DataFrame
         """
 
         dataFrame = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a.replace('\t', ' '), b])
-            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
+            data.append([a.replace('\t', ' '), b[0], b[1]])
+            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Periodicity'])
         return dataFrame
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
         :rtype: dict
@@ -589,42 +602,43 @@
 
     def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
         :type outFile: file
         """
-        self.oFile = outFile
-        writer = open(self.oFile, 'w+')
+        self._oFile = outFile
+        writer = open(self._oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            patternsAndSupport = x.strip() + " : " + str(y)
+            patternsAndSupport = x.strip() + ":" + str(y[0]) + ":" + str(y[1])
             writer.write("%s \n" % patternsAndSupport)
 
     def printResults(self):
-        print("Total number of Spatial Fuzzy Frequent Patterns:", len(self.getPatterns()))
+        print("Total number of Fuzzy Periodic-Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in seconds:", self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
     if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
-        if len(_ab._sys.argv) == 6:
-            _ap = FFSPMiner(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
-        if len(_ab._sys.argv) == 5:
-            _ap = FFSPMiner(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+        if len(_ab._sys.argv) == 6:  # to  include a user specified separator
+            _ap = FPFPMiner(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
+        if len(_ab._sys.argv) == 5:  # to consider "\t" as a separator
+            _ap = FPFPMiner(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
         _ap.startMine()
-        print("Total number of Spatial Fuzzy Frequent  Patterns:", len(_ap.getPatterns()))
+        print("Total number of Fuzzy Periodic-Frequent Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in seconds:", _ap.getRuntime())
     else:
-        _ap = FFSPMiner('sample.txt', 'nei.txt', 1, ' ')
+        _ap = FPFPMiner('sample.txt', 1, 10, ' ')
         _ap.startMine()
-        print("Total number of Fuzzy-Frequent Patterns:", len(_ap.getPatterns()))
+        print("Total number of Fuzzy Periodic-Frequent Patterns:", len(_ap.getPatterns()))
         _ap.save('output.txt')
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in seconds:", _ap.getRuntime())
         print("Error! The number of input parameters do not match the total number of parameters provided")
+
```

### Comparing `pami-2023.4.1/PAMI/fuzzyFrequentSpatialPattern/basic/FFSPMiner_old.py` & `pami-2023.5.1/PAMI/fuzzyFrequentSpatialPattern/basic/FFSPMiner_old.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/fuzzyFrequentSpatialPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/fuzzyFrequentSpatialPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/fuzzyPeriodicFrequentPattern/__init__.py` & `pami-2023.5.1/PAMI/fuzzyPeriodicFrequentPattern/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/fuzzyPeriodicFrequentPattern/basic/FPFPMiner.py` & `pami-2023.5.1/PAMI/fuzzyFrequentSpatialPattern/basic/FFSPMiner.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,142 +1,163 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+#
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#     .. code-block:: python
+#
+#         from PAMI.fuzzyFrequentSpatialPattern import FFSPMiner as alg
+#
+#         obj = alg.FFSPMiner("input.txt", "neighbours.txt", 2)
+#
+#         obj.startMine()
+#
+#         fuzzySpatialFrequentPatterns = obj.getPatterns()
+#
+#         print("Total number of fuzzy frequent spatial patterns:", len(fuzzySpatialFrequentPatterns))
+#
+#         obj.save("outputFile")
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-#
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#         memUSS = obj.getMemoryUSS()
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#         print("Total Memory in USS:", memUSS)
+#
+#         memRSS = obj.getMemoryRSS()
+#
+#         print("Total Memory in RSS", memRSS)
+#
+#         run = obj.getRuntime()
+#
+#         print("Total ExecutionTime in seconds:", run)
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
 
-from PAMI.fuzzyPeriodicFrequentPattern.basic import abstract as _ab
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+from PAMI.fuzzyFrequentSpatialPattern.basic import abstract as _ab
 
 
 class _FFList:
     """
-        A class represent a Fuzzy List of an element
+     A class represent a Fuzzy List of an element
 
-    Attributes:
+    Attributes :
     ----------
-        item: int
-            the item name
-        sumLUtil: float
-            the sum of utilities of an fuzzy item in database
-        sumRUtil: float
-            the sum of resting values of a fuzzy item in database
-        elements: list
-            list of elements contain tid,Utility and resting values of element in each transaction
-        maxPeriod: int
-            it represent the max period of a item
-
-    Methods:
+         item: int
+             the item name
+         sumIUtil: float
+             the sum of utilities of an fuzzy item in database
+         sumRUtil: float
+             the sum of resting values of a fuzzy item in database
+         elements: list
+             a list of elements contain tid,Utility and resting values of element in each transaction
+    Methods :
     -------
         addElement(element)
             Method to add an element to this fuzzy list and update the sums at the same time.
 
         printElement(e)
             Method to print elements
 
     """
 
     def __init__(self, itemName):
         self.item = itemName
-        self.sumLUtil = 0.0
+        self.sumIUtil = 0.0
         self.sumRUtil = 0.0
         self.elements = []
-        self.maxPeriod = 0
 
     def addElement(self, element):
         """
             A Method that add a new element to FFList
 
             :param element: an element to be add to FFList
             :pram type: Element
         """
-        self.sumLUtil += element.lUtils
+        self.sumIUtil += element.iUtils
         self.sumRUtil += element.rUtils
         self.elements.append(element)
-        self.maxPeriod = max(self.maxPeriod, element.period)
 
     def printElement(self):
         """
             A Method to Print elements in the FFList
         """
         for ele in self.elements:
-            print(ele.tid, ele.lUtils, ele.rUtils, ele.period)
+            print(ele.tid, ele.iUtils, ele.rUtils)
 
 
 class _Element:
     """
         A class represents an Element of a fuzzy list
 
-        Attributes:
-        ----------
+    Attributes :
+    ----------
         tid : int
             keep tact of transaction id
-        lUtils: float
+        iUtils: float
             the utility of an fuzzy item in the transaction
         rUtils : float
-            the resting value of an fuzzy item in the transaction
-        period: int
-            represent the period of the element
+            the neighbourhood resting value of an fuzzy item in the transaction
     """
 
-    def __init__(self, tid, iUtil, rUtil, period):
+    def __init__(self, tid, iUtil, rUtil):
         self.tid = tid
-        self.lUtils = iUtil
+        self.iUtils = iUtil
         self.rUtils = rUtil
-        self.period = period
 
 
 class _Pair:
     """
-        A class to store item name and quantity together.
+        A class to store item and it's quantity together
     """
 
     def __init__(self):
         self.item = 0
         self.quantity = 0
 
 
-class FPFPMiner(_ab._fuzzyPeriodicFrequentPatterns):
+class FFSPMiner(_ab._fuzzySpatialFrequentPatterns):
     """
-        Fuzzy Periodic Frequent Pattern Miner is desired to find all fuzzy periodic frequent patterns which is
-        on-trivial and challenging problem to its huge search space.we are using efficient pruning
+    Description:
+    -------------
+        Fuzzy Frequent Spatial Pattern-Miner is desired to find all Spatially frequent fuzzy patterns
+        which is on-trivial and challenging problem to its huge search space.we are using efficient pruning
         techniques to reduce the search space.
 
+    Reference:
+    -------------
+        Reference: P. Veena, B. S. Chithra, R. U. Kiran, S. Agarwal and K. Zettsu, "Discovering Fuzzy Frequent
+        Spatial Patterns in Large Quantitative Spatiotemporal databases," 2021 IEEE International Conference on Fuzzy Systems
+        (FUZZ-IEEE), 2021, pp. 1-8, doi: 10.1109/FUZZ45933.2021.9494594.
 
-    Attributes:
-    ----------
+    Attributes :
+    --------------
         iFile : file
             Name of the input file to mine complete set of fuzzy spatial frequent patterns
         oFile : file
                Name of the oFile file to store complete set of fuzzy spatial frequent patterns
         minSup : float
-            The user given support
-        period: int
-            periodicity of an element
+            The user given minimum support
+        neighbors: map
+            keep track of neighbours of elements
         memoryRSS : float
                 To store the total amount of RSS memory consumed by the program
         startTime:float
                To record the start time of the mining process
         endTime:float
             To record the completion time of the mining process
         itemsCnt: int
@@ -153,22 +174,16 @@
             To Keep track of fuzzy regions of item
         jointCnt: int
             To keep track of the number of FFI-list that was constructed
         BufferSize: int
             represent the size of Buffer
         itemBuffer list
             to keep track of items in buffer
-        maxTID: int
-            represent the maximum tid of the database
-        lastTIDs: map
-            represent the last tid of fuzzy items
-        itemsToRegion: map
-            represent items with respective regions
-    Methods:
-    -------
+    Methods :
+    -----------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -181,96 +196,90 @@
             Total amount of runtime taken by the mining process will be retrieved from this function
         convert(value):
             To convert the given user specified value
         FSFIMining( prefix, prefixLen, fsFim, minSup)
             Method generate FFI from prefix
         construct(px, py)
             A function to construct Fuzzy itemSet from 2 fuzzy itemSets
-        findElementWithTID(UList, tid)
+        Intersection(neighbourX,neighbourY)
+            Return common neighbours of 2 itemSet Neighbours
+        findElementWithTID(uList, tid)
             To find element with same tid as given
         WriteOut(prefix, prefixLen, item, sumIUtil,period)
             To Store the patten
 
     Executing the code on terminal :
-    -------
+    -----------------------------------
         Format:
-        ------
-            python3 FPFPMiner_old.py <inputFile> <outputFile> <minSup> <maxPer> <sep>
 
+            >>> python3 FFSPMiner_old.py <inputFile> <outputFile> <neighbours> <minSup> <sep>
         Examples:
-        ------
-            python3  FPFPMiner_old.py sampleTDB.txt output.txt 2 3 (minSup and maxPer will be considered in support count or frequency)
 
-            python3  FPFPMiner_old.py sampleTDB.txt output.txt 0.25 0.3 (minSup and maxPer will be considered in percentage of database)
-                                        (will consider "\t" as separator)
-
-            python3  FPFPMiner_old.py sampleTDB.txt output.txt 2 3  ,(will consider ',' as separator)
+            >>> python3  FFSPMiner_old.py sampleTDB.txt output.txt sampleN.txt 3  (minSup will be considered in support count or frequency)
 
 
     Sample run of importing the code:
-    -------------------------------
+    -----------------------------------
+    .. code-block:: python
 
-        from PAMI.fuzzyPeriodicFrequentPattern.basic import FPFPMiner as alg
+        from PAMI.fuzzyFrequentSpatialPattern import FFSPMiner as alg
 
-        obj =alg.FPFPMiner("input.txt",2,3)
+        obj = alg.FFSPMiner("input.txt", "neighbours.txt", 2)
 
         obj.startMine()
 
-        periodicFrequentPatterns = obj.getPatterns()
+        fuzzySpatialFrequentPatterns = obj.getPatterns()
 
-        print("Total number of Fuzzy Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+        print("Total number of fuzzy frequent spatial patterns:", len(fuzzySpatialFrequentPatterns))
 
-        obj.save("output.txt")
+        obj.save("outputFile")
 
         memUSS = obj.getMemoryUSS()
 
         print("Total Memory in USS:", memUSS)
 
         memRSS = obj.getMemoryRSS()
 
         print("Total Memory in RSS", memRSS)
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
 
     Credits:
-    -------
-            The complete program was written by Sai Chitra.B under the supervision of Professor Rage Uday Kiran.
-
+    ---------
+            The complete program was written by B.Sai Chitra under the supervision of Professor Rage Uday Kiran.
     """
+
     _startTime = float()
     _endTime = float()
     _minSup = str()
     _maxPer = float()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
+    _nFile = " "
     _memoryUSS = float()
     _memoryRSS = float()
-    _sep = " "
-    _Database = []
+    _sep = "\t"
     _transactions = []
     _fuzzyValues = []
-    _ts = []
 
-    def __init__(self, iFile, minSup, period, sep="\t"):
-        super().__init__(iFile, minSup, period, sep)
-        self._oFile = ""
+    def __init__(self, iFile, nFile, minSup, sep="\t"):
+        super().__init__(iFile, nFile, minSup, sep)
+        self._mapItemNeighbours = {}
+        self._startTime = 0
+        self._endTime = 0
+        self._mapItemSum = {}
+        self._joinsCnt = 0
         self._BufferSize = 200
         self._itemSetBuffer = []
-        self._mapItemSum = {}
         self._finalPatterns = {}
-        self._joinsCnt = 0
-        self._itemsCnt = 0
-        self._startTime = float()
-        self._endTime = float()
-        self._memoryUSS = float()
-        self._memoryRSS = float()
         self._dbLen = 0
+        self._itemsCnt = 0
 
     def _compareItems(self, o1, o2):
         """
             A Function that sort all FFI-list in ascending order of Support
         """
         compare = self._mapItemSum[o1.item] - self._mapItemSum[o2.item]
         if compare == 0:
@@ -292,164 +301,206 @@
             if '.' in value:
                 value = (self._dbLen * value)
             else:
                 value = int(value)
         return value
 
     def _creatingItemSets(self):
-        data, self._transactions, self._fuzzyValues, ts = [], [], [], []
+        self._transactions, self._fuzzyValues = [], []
         if isinstance(self._iFile, _ab._pd.DataFrame):
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
-            if 'TS' in i:
-                self._ts = self._iFile['TS'].tolist()
             if 'Transactions' in i:
-                self._transactions = self._iFile['Transactions'].tolist()
+                self.transactions = self._iFile['Transactions'].tolist()
             if 'fuzzyValues' in i:
-                self._fuzzyValues = self._iFile['fuzzyValues'].tolist()
+                self.fuzzyValues = self._iFile['Utilities'].tolist()
+
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
-                count = 0
                 for line in data:
                     line = line.decode("utf-8")
                     line = line.split("\n")[0]
                     parts = line.split(":")
                     parts[0] = parts[0].strip()
                     parts[1] = parts[1].strip()
                     items = parts[0].split(self._sep)
                     quantities = parts[1].split(self._sep)
-                    self._ts.append(int(items[0]))
-                    self._transactions.append([x for x in items[1:]])
-                    self._fuzzyValues.append([float(x) for x in quantities])
-                    count += 1
+                    self.transactions.append([x for x in items])
+                    self.fuzzyValues.append([float(x) for x in quantities])
             else:
                 try:
                     with open(self._iFile, 'r', encoding='utf-8') as f:
-                        count = 0
                         for line in f:
                             line = line.split("\n")[0]
                             parts = line.split(":")
                             parts[0] = parts[0].strip()
                             parts[1] = parts[1].strip()
                             items = parts[0].split(self._sep)
                             quantities = parts[1].split(self._sep)
-                            self._ts.append(int(items[0]))
-                            self._transactions.append([x for x in items[1:]])
+                            self._transactions.append([x for x in items])
                             self._fuzzyValues.append([float(x) for x in quantities])
-                            count += 1
+                except IOError:
+                    print("File Not Found")
+                    quit()
+
+    def _mapNeighbours(self):
+        self._mapItemNeighbours = {}
+        if isinstance(self._nFile, _ab._pd.DataFrame):
+            data, items = [], []
+            if self._nFile.empty:
+                print("its empty..")
+            i = self._nFile.columns.values.tolist()
+            if 'items' in i:
+                items = self._nFile['items'].tolist()
+            if 'Neighbours' in i:
+                data = self._nFile['Neighbours'].tolist()
+            for k in range(len(items)):
+                self._mapItemNeighbours[items[k]] = data[k]
+
+        if isinstance(self._nFile, str):
+            if _ab._validators.url(self._nFile):
+                data = _ab._urlopen(self._nFile)
+                for line in data:
+                    line = line.decode("utf-8")
+                    line = line.split("\n")[0]
+                    parts = [i.rstrip() for i in line.split(self._sep)]
+                    parts = [x for x in parts]
+                    item = parts[0]
+                    neigh1 = []
+                    for i in range(1, len(parts)):
+                        neigh1.append(parts[i])
+                    self._mapItemNeighbours[item] = neigh1
+            else:
+                try:
+                    with open(self._nFile, 'r', encoding='utf-8') as f:
+                        for line in f:
+                            line = line.split("\n")[0]
+                            parts = [i.rstrip() for i in line.split(self._sep)]
+                            parts = [x for x in parts]
+                            item = parts[0]
+                            neigh1 = []
+                            for i in range(1, len(parts)):
+                                neigh1.append(parts[i])
+                            self._mapItemNeighbours[item] = neigh1
                 except IOError:
                     print("File Not Found")
                     quit()
 
     def startMine(self):
+        """ Frequent pattern mining process will start from here
         """
-            Fuzzy periodic Frequent pattern mining process will start from here
-        """
-        maxTID = 0
-        lastTIDs = {}
         self._startTime = _ab._time.time()
         self._creatingItemSets()
         self._finalPatterns = {}
-        tid = int()
+        self._mapNeighbours()
         for line in range(len(self._transactions)):
-            tid = int(self._ts[line])
-            self._dbLen += 1
             items = self._transactions[line]
             quantities = self._fuzzyValues[line]
-            if tid < maxTID:
-                maxTID = tid
+            self._dbLen += 1
             for i in range(0, len(items)):
                 item = items[i]
                 if item in self._mapItemSum:
                     self._mapItemSum[item] += quantities[i]
                 else:
                     self._mapItemSum[item] = quantities[i]
-        listOfFFIList = []
+        listOfFFList = []
         mapItemsToFFLIST = {}
-        # self._minSup = self._convert(self._minSup)
-        self._maxPer = self._convert(self._maxPer)
+        #self._minSup = self._convert(self._minSup)
         for item1 in self._mapItemSum.keys():
             item = item1
             if self._mapItemSum[item] >= self._minSup:
-                fUList = _FFList(item)
-                k = tuple([item])
-                mapItemsToFFLIST[k] = fUList
-                listOfFFIList.append(fUList)
-                lastTIDs[item] = tid
-        listOfFFIList.sort(key=_ab._functools.cmp_to_key(self._compareItems))
+                fuList = _FFList(item)
+                mapItemsToFFLIST[item] = fuList
+                listOfFFList.append(fuList)
+        listOfFFList.sort(key=_ab._functools.cmp_to_key(self._compareItems))
+        tid = 0
         for line in range(len(self._transactions)):
-            tid = int(self._ts[line])
             items = self._transactions[line]
             quantities = self._fuzzyValues[line]
             revisedTransaction = []
             for i in range(0, len(items)):
                 pair = _Pair()
                 pair.item = items[i]
-                item = pair.item
                 pair.quantity = quantities[i]
+                item = pair.item
                 if self._mapItemSum[item] >= self._minSup:
                     if pair.quantity > 0:
                         revisedTransaction.append(pair)
             revisedTransaction.sort(key=_ab._functools.cmp_to_key(self._compareItems))
             for i in range(len(revisedTransaction) - 1, -1, -1):
                 pair = revisedTransaction[i]
                 remainUtil = 0
-                for j in range(len(revisedTransaction) - 1, i - 1, -1):
-                    remainUtil += revisedTransaction[j].quantity
-                if pair.quantity > remainUtil:
-                    remainingUtility = pair.quantity
-                else:
-                    remainingUtility = remainUtil
-                if mapItemsToFFLIST.get(tuple([pair.item])) is not None:
-                    FFListOfItem = mapItemsToFFLIST[tuple([pair.item])]
-                    if len(FFListOfItem.elements) == 0:
-                        element = _Element(tid, pair.quantity, remainingUtility, 0)
-                    else:
-                        if lastTIDs[pair.item] == tid:
-                            element = _Element(tid, pair.quantity, remainingUtility, maxTID - tid)
-                        else:
-                            lastTid = FFListOfItem.elements[-1].tid
-                            curPer = tid - lastTid
-                            element = _Element(tid, pair.quantity, remainingUtility, curPer)
+                for j in range(len(revisedTransaction) - 1, i, -1):
+                    if self._mapItemNeighbours.get(pair.item[0]) is None:
+                        continue
+                    if revisedTransaction[j].item[0] in self._mapItemNeighbours[pair.item[0]]:
+                        remainUtil += revisedTransaction[j].quantity
+                remainingUtility = remainUtil
+                if mapItemsToFFLIST.get(pair.item) is not None:
+                    FFListOfItem = mapItemsToFFLIST[pair.item]
+                    element = _Element(tid, pair.quantity, remainingUtility)
                     FFListOfItem.addElement(element)
-        self._FSFIMining(self._itemSetBuffer, 0, listOfFFIList, self._minSup)
+            tid += 1
+        itemNeighbours = list(self._mapItemNeighbours.keys())
+        self._FSFIMining(self._itemSetBuffer, 0, listOfFFList, self._minSup, itemNeighbours)
         self._endTime = _ab._time.time()
         process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryUSS = float()
         self._memoryRSS = float()
         self._memoryUSS = process.memory_full_info().uss
         self._memoryRSS = process.memory_info().rss
 
-    def _FSFIMining(self, prefix, prefixLen, fsFim, minSup):
+    def _FSFIMining(self, prefix, prefixLen, FSFIM, minSup, itemNeighbours):
+        """Generates FFSPMiner from prefix
 
-        """Generates FPFP from prefix
-
-        :param prefix: the prefix patterns of FPFP
+        :param prefix: the prefix patterns of FFSPMiner
         :type prefix: len
         :param prefixLen: the length of prefix
         :type prefixLen: int
-        :param fsFim: the Fuzzy list of prefix itemSets
-        :type fsFim: list
-        :param minSup: the minimum support of
-        :type minSup:int
-        """
-        for i in range(0, len(fsFim)):
-            X = fsFim[i]
-            if X.sumLUtil >= minSup and X.maxPeriod <= self._maxPer:
-                self._WriteOut(prefix, prefixLen, X.item, X.sumLUtil, X.maxPeriod)
+           :param FSFIM: the Fuzzy list of prefix itemSets
+           :type FSFIM: list
+           :param minSup: the minimum support of
+           :type minSup:int
+           :param itemNeighbours: the set of common neighbours of prefix
+           :type itemNeighbours: list or set
+        """
+        for i in range(0, len(FSFIM)):
+            X = FSFIM[i]
+            if X.sumIUtil >= minSup:
+                self._WriteOut(prefix, prefixLen, X.item, X.sumIUtil)
+            newNeighbours = self._Intersection(self._mapItemNeighbours.get(X.item[0]), itemNeighbours)
             if X.sumRUtil >= minSup:
                 exULs = []
-                for j in range(i + 1, len(fsFim)):
-                    Y = fsFim[j]
-                    exULs.append(self._construct(X, Y))
-                    self._joinsCnt += 1
+                for j in range(i + 1, len(FSFIM)):
+                    Y = FSFIM[j]
+                    if Y.item[0] in newNeighbours:
+                        exULs.append(self._construct(X, Y))
+                        self._joinsCnt += 1
                 self._itemSetBuffer.insert(prefixLen, X.item)
-                self._FSFIMining(self._itemSetBuffer, prefixLen + 1, exULs, minSup, )
+                self._FSFIMining(self._itemSetBuffer, prefixLen + 1, exULs, minSup, newNeighbours)
+
+    def _Intersection(self, neighbourX, neighbourY):
+        """
+            A function to get common neighbours from 2 itemSets
+            :param neighbourX: the set of neighbours of itemSet 1
+            :type neighbourX: set or list
+            :param neighbourY: the set of neighbours of itemSet 2
+            :type neighbourY: set or list
+            :return : set of common neighbours of 2 itemSets
+            :rtype :set
+        """
+        result = []
+        if neighbourX is None or neighbourY is None:
+            return result
+        for i in range(0, len(neighbourX)):
+            if neighbourX[i] in neighbourY:
+                result.append(neighbourX[i])
+        return result
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
         :return: returning USS memory consumed by the mining process
         :rtype: float
         """
@@ -471,91 +522,88 @@
         :return: returning total amount of runtime taken by the mining process
         :rtype: float
        """
         return self._endTime - self._startTime
 
     def _construct(self, px, py):
         """
-            A function to construct a new Fuzzy item set from 2 fuzzy itemSets
+            A function to construct a new Fuzzy itemSet from 2 fuzzy itemSets
 
-            :param px:the item set px
+            :param px:the itemSet px
             :type px:FFI-List
-            :param py:item set py
+            :param py:itemSet py
             :type py:FFI-List
-            :return :the item set of pxy(px and py)
+            :return :the itemSet of pxy(px and py)
             :rtype :FFI-List
         """
         pxyUL = _FFList(py.item)
-        prev = 0
         for ex in px.elements:
             ey = self._findElementWithTID(py, ex.tid)
             if ey is None:
                 continue
-            eXY = _Element(ex.tid, min([ex.lUtils, ey.lUtils], key=lambda x: float(x)), ey.rUtils, ex.tid - prev)
+            eXY = _Element(ex.tid, min([ex.iUtils, ey.iUtils], key=lambda x: float(x)), ey.rUtils)
             pxyUL.addElement(eXY)
-            prev = ex.tid
         return pxyUL
 
-    def _findElementWithTID(self, UList, tid):
+    def _findElementWithTID(self, uList, tid):
         """
             To find element with same tid as given
-            :param UList: fuzzy list
-            :type UList:FFI-List
+            :param uList:fuzzyList
+            :type uList:FFI-List
             :param tid:transaction id
             :type tid:int
-            :return:element eith tid as given
+            :return:element tid as given
             :rtype: element if exist or None
         """
-        List = UList.elements
+        List = uList.elements
         first = 0
         last = len(List) - 1
         while first <= last:
             mid = (first + last) >> 1
             if List[mid].tid < tid:
                 first = mid + 1
             elif List[mid].tid > tid:
                 last = mid - 1
             else:
                 return List[mid]
         return None
 
-    def _WriteOut(self, prefix, prefixLen, item, sumLUtil, period):
+    def _WriteOut(self, prefix, prefixLen, item, sumIUtil):
         """
             To Store the patten
             :param prefix: prefix of itemSet
             :type prefix: list
             :param prefixLen: length of prefix
             :type prefixLen: int
             :param item: the last item
             :type item: int
-            :param sumLUtil: sum of utility of itemSet
-            :type sumLUtil: float
-            :param period: represent the period of itemSet
-            :type period: int
+            :param sumIUtil: sum of utility of itemSet
+            :type sumIUtil: float
+
         """
         self._itemsCnt += 1
         res = ""
         for i in range(0, prefixLen):
-            res += str(prefix[i]) +  "\t"
+            res += str(prefix[i]) + "\t"
         res += str(item)
-        #res1 = str(sumLUtil) + " : " + str(period)
-        self._finalPatterns[res] = [sumLUtil, period]
+        res1 = str(sumIUtil)
+        self._finalPatterns[res] = res1
 
     def getPatternsAsDataFrame(self):
         """Storing final frequent patterns in a dataframe
 
         :return: returning frequent patterns in a dataframe
         :rtype: pd.DataFrame
         """
 
         dataFrame = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a.replace('\t', ' '), b[0], b[1]])
-            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Periodicity'])
+            data.append([a.replace('\t', ' '), b])
+            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
         return dataFrame
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
         :rtype: dict
@@ -564,43 +612,42 @@
 
     def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
         :type outFile: file
         """
-        self._oFile = outFile
-        writer = open(self._oFile, 'w+')
+        self.oFile = outFile
+        writer = open(self.oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            patternsAndSupport = x.strip() + ":" + str(y[0]) + ":" + str(y[1])
+            patternsAndSupport = x.strip() + " : " + str(y)
             writer.write("%s \n" % patternsAndSupport)
 
     def printResults(self):
-        print("Total number of Fuzzy Periodic-Frequent Patterns:", len(self.getPatterns()))
+        print("Total number of Spatial Fuzzy Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in seconds:", self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
     if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
-        if len(_ab._sys.argv) == 6:  # to  include a user specified separator
-            _ap = FPFPMiner(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
-        if len(_ab._sys.argv) == 5:  # to consider "\t" as a separator
-            _ap = FPFPMiner(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+        if len(_ab._sys.argv) == 6:
+            _ap = FFSPMiner(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
+        if len(_ab._sys.argv) == 5:
+            _ap = FFSPMiner(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
         _ap.startMine()
-        print("Total number of Fuzzy Periodic-Frequent Patterns:", len(_ap.getPatterns()))
+        print("Total number of Spatial Fuzzy Frequent  Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in seconds:", _ap.getRuntime())
     else:
-        _ap = FPFPMiner('sample.txt', 1, 10, ' ')
+        _ap = FFSPMiner('sample.txt', 'nei.txt', 1, ' ')
         _ap.startMine()
-        print("Total number of Fuzzy Periodic-Frequent Patterns:", len(_ap.getPatterns()))
+        print("Total number of Fuzzy-Frequent Patterns:", len(_ap.getPatterns()))
         _ap.save('output.txt')
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in seconds:", _ap.getRuntime())
         print("Error! The number of input parameters do not match the total number of parameters provided")
-
```

### Comparing `pami-2023.4.1/PAMI/fuzzyPeriodicFrequentPattern/basic/FPFPMiner_old.py` & `pami-2023.5.1/PAMI/fuzzyPeriodicFrequentPattern/basic/FPFPMiner_old.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/fuzzyPeriodicFrequentPattern/basic/__init__.py` & `pami-2023.5.1/PAMI/fuzzyPeriodicFrequentPattern/basic/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/fuzzyPeriodicFrequentPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/abstract.py`

 * *Files 4% similar despite different names*

```diff
@@ -36,31 +36,28 @@
 import os.path as _ospath
 import psutil as _psutil
 import sys as _sys
 import validators as _validators
 from urllib.request import urlopen as _urlopen
 import functools as _functools
 
-
-class _fuzzyPeriodicFrequentPatterns(_ABC):
+class _fuzzySpatialFrequentPatterns(_ABC):
     """ This abstract base class defines the variables and methods that every frequent pattern mining algorithm must
         employ in PAMI
 
 
     Attributes :
     ----------
         iFile : str
             Input file name or path of the input file
         minSup: integer or float or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
             Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=0.1 will be treated as float
-        maxPer: int
-            The user specified Maximum periodicity
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
         sep : str
             This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
             However, the users can override their default separator
         startTime:float
             To record the start time of the algorithm
         endTime:float
             To record the completion time of the algorithm
@@ -88,31 +85,32 @@
         getMemoryRSS()
             This function outputs the total amount of RSS memory consumed by a mining algorithm
         getRuntime()
             This function outputs the total runtime of a mining algorithm
 
     """
 
-    def __init__(self, iFile, minSup, maxPer, sep="\t"):
+    def __init__(self, iFile, nFile, minSup, maxPer, sep="\t"):
         """
         :param iFile: Input file name or path of the input file
         :type iFile: str
+        :param nFile: neighbourhood file name or path
+        :type nFile: str
         :param minSup: The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
             Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+            Example: minSup=10 will be treated as integer, while minSup=0.3 will be treated as float
         :type minSup: int or float or str
-        :param maxPer: The user can specify maximum Periodicity
-        :type maxPer: int
         :param sep: separator used to distinguish items from each other. The default separator is tab space. However, users can override the default separator
         :type sep: str
         """
 
         self._iFile = iFile
         self._sep = sep
+        self._nFile = nFile
         self._minSup = minSup
         self._maxPer = maxPer
         self._startTime = float()
         self._endTime = float()
         self._finalPatterns = {}
         self._oFile = str()
         self._memoryUSS = float()
@@ -163,10 +161,10 @@
     def getRuntime(self):
         """Total amount of runtime taken by the program will be retrieved from this function"""
 
         pass
 
     @_abstractmethod
     def printResults(self):
-        """ To print all the results of execution"""
+        """ TO print all the results of execution"""
 
-        pass
+        pass
```

### Comparing `pami-2023.4.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/FGPFPMiner.py` & `pami-2023.5.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/FGPFPMiner_old.py`

 * *Files 12% similar despite different names*

```diff
@@ -21,14 +21,16 @@
 #      This program is distributed in the hope that it will be useful,
 #      but WITHOUT ANY WARRANTY; without even the implied warranty of
 #      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 #      GNU General Public License for more details.
 #
 #      You should have received a copy of the GNU General Public License
 #      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+import pandas as pd
+import plotly.express as px
 import PAMI.fuzzySpatialPeriodicFrequentPattern.basic.abstract as _ab
 
 
 class _FFList:
     """
      A class represent a Fuzzy List of an element
     Attributes :
@@ -205,31 +207,37 @@
     _nFile = " "
     _FuzFile = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _sep = "\t"
     _transactionsDB = []
     _fuzzyValuesDB = []
-    _ts = []
 
-    def __init__(self, iFile, nFile, minSup, maxPer, sep):
-        super().__init__(iFile, nFile, minSup, maxPer, sep)
+    def __init__(self, iFile, nFile, FuzFile, minSup, maxPer, sep):
+        super().__init__(iFile, nFile, FuzFile, minSup, maxPer, sep)
         self._mapItemNeighbours = {}
         self._startTime = 0
         self._endTime = 0
         self._itemsCnt = 0
         self._itemSupData = {}
         self._mapItemSum = {}
+        self._finalClosedPeriodicPatterns = {}
+        self._mapItemRegions = {}
+        self._fuzzyRegionReferenceMap = {}
         self._joinsCnt = 0
         self._BufferSize = 200
         self._itemSetBuffer = []
         self._finalPatterns = {}
         self._finalPeriodicPatterns = {}
         self._tidList = {}
         self._dbLen = 0
+        self._regionsNumber = 0
+        self._RegionsCal = []
+        self._RegionsLabel = []
+        self._LabelKey = {}
 
     def _compareItems(self, o1, o2):
         """
             A Function that sort all FFI-list in ascending order of Support
         """
         compare = self._mapItemSum[o1.item] - self._mapItemSum[o2.item]
         if compare == 0:
@@ -250,16 +258,41 @@
         if type(value) is str:
             if '.' in value:
                 value = float(value)
             else:
                 value = int(value)
         return value
 
+    def _fuzzyMembershipFunc(self):
+
+        try:
+            with open(self._FuzFile, 'r', encoding='utf-8') as f:
+                count = 0
+                for line in f:
+                    line = line.split("\n")[0]
+                    parts = line.split(" ")
+                    lowerBound = parts[0].strip()
+                    upperBound = parts[1].strip()
+                    lb_Label = parts[2].strip()
+                    ub_Label = parts[3].strip()
+                    self._RegionsCal.append([int(lowerBound), int(upperBound)])
+                    self._RegionsLabel.append([lb_Label, ub_Label])
+                    for i in range(0, 2):
+                        if lb_Label.capitalize() not in self._LabelKey:
+                            self._LabelKey[lb_Label.capitalize()] = count
+                            count += 1
+                        if ub_Label.capitalize() not in self._LabelKey:
+                            self._LabelKey[ub_Label.capitalize()] = count
+                            count += 1
+        except IOError:
+            print("File Not Found")
+            quit()
+
     def _creatingItemSets(self):
-        self._transactionsDB, self._fuzzyValuesDB, self._ts = [], [], []
+        self._transactionsDB, self._fuzzyValuesDB = [], []
         if isinstance(self._iFile, _ab._pd.DataFrame):
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
                 self._transactionsDB = self._iFile['Transactions'].tolist()
             if 'fuzzyValues' in i:
@@ -269,31 +302,29 @@
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
                     line = line.decode("utf-8")
                     line = line.split("\n")[0]
                     parts = line.split(":")
                     items = parts[0].split(self._sep)
-                    quantities = parts[1].split(self._sep)
-                    self._ts.append(int(items[0]))
-                    self._transactionsDB.append([x for x in items[1:]])
-                    self._fuzzyValuesDB.append([float(x) for x in quantities])
+                    quantities = parts[2].split(self._sep)
+                    self._transactionsDB.append([x for x in items])
+                    self._fuzzyValuesDB.append([x for x in quantities])
             else:
                 try:
                     with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
                             line = line.split("\n")[0]
                             parts = line.split(":")
                             parts[0] = parts[0].strip()
-                            parts[1] = parts[1].strip()
+                            parts[2] = parts[2].strip()
                             items = parts[0].split(self._sep)
-                            quantities = parts[1].split(self._sep)
-                            self._ts.append(int(items[0]))
-                            self._transactionsDB.append([x for x in items[1:]])
-                            self._fuzzyValuesDB.append([float(x) for x in quantities])
+                            quantities = parts[2].split(self._sep)
+                            self._transactionsDB.append([x for x in items])
+                            self._fuzzyValuesDB.append([x for x in quantities])
                 except IOError:
                     print("File Not Found")
                     quit()
 
     def _mapNeighbours(self):
         self._mapItemNeighbours = {}
         if isinstance(self._nFile, _ab._pd.DataFrame):
@@ -334,92 +365,125 @@
                                 neigh1.append(parts[i])
                             self._mapItemNeighbours[item] = neigh1
                 except IOError:
                     print(self._nFile)
                     print("File Not Found")
                     quit()
 
+    def _Regions(self, quantity):
+
+        self._list = [0] * len(self._LabelKey)
+        if self._RegionsCal[0][0] < quantity <= self._RegionsCal[0][1]:
+            self._list[0] = 1
+            return
+        elif quantity >= self._RegionsCal[-1][0]:
+            self._list[-1] = 1
+            return
+        else:
+            for i in range(1, len(self._RegionsCal) - 1):
+                if self._RegionsCal[i][0] < quantity <= self._RegionsCal[i][1]:
+                    base = self._RegionsCal[i][1] - self._RegionsCal[i][0]
+                    for pos in range(0, 2):
+                        if self._RegionsLabel[i][pos].islower():
+                            self._list[self._LabelKey[self._RegionsLabel[i][pos].capitalize()]] = float(
+                                (self._RegionsCal[i][1] - quantity) / base)
+                        else:
+                            self._list[self._LabelKey[self._RegionsLabel[i][pos].capitalize()]] = float(
+                                (quantity - self._RegionsCal[i][0]) / base)
+        return
+
     def startMine(self):
         """ Frequent pattern mining process will start from here
         """
         self._startTime = _ab._time.time()
         self._mapNeighbours()
         self._creatingItemSets()
+        self._fuzzyMembershipFunc()
         self._finalPatterns = {}
         recent_occur = {}
         for line in range(len(self._transactionsDB)):
             item_list = self._transactionsDB[line]
             fuzzyValues_list = self._fuzzyValuesDB[line]
-            ts = self._ts[line]
             self._dbLen += 1
             """T
             The section below is for:
                 1.Finding the support of each item's region in the entire database
                 2.Finding the periodic patterns of the data
                 3.Trimming off the patterns whose support is less than minSupport
             """
             for i in range(0, len(item_list)):
                 item = item_list[i]
                 if item in self._tidList:
-                    self._tidList[item].append(ts - recent_occur[item][-1])
-                    recent_occur[item].append(ts)
+                    self._tidList[item].append(self._dbLen - recent_occur[item][-1])
+                    recent_occur[item].append(self._dbLen)
                 else:
-                    self._tidList[item] = [ts]
-                    recent_occur[item] = [ts]
+                    self._tidList[item] = [self._dbLen]
+                    recent_occur[item] = [self._dbLen]
                 fuzzy_ref = fuzzyValues_list[i]
-                if item[0] in self._mapItemNeighbours:
+                if item in self._mapItemNeighbours:
+                    if fuzzy_ref not in self._fuzzyRegionReferenceMap:
+                        self._Regions(int(fuzzy_ref))
+                        self._fuzzyRegionReferenceMap[fuzzy_ref] = self._list
+
                     if item in self._itemSupData.keys():
-                        self._itemSupData[item] += fuzzy_ref
+                        self._itemSupData[item] = [sum(i) for i in zip(self._itemSupData[item],
+                                                                       self._fuzzyRegionReferenceMap[fuzzy_ref])]
                     else:
-                        self._itemSupData[item] = fuzzy_ref
+                        self._itemSupData[item] = self._fuzzyRegionReferenceMap[fuzzy_ref]
+
         for item in self._tidList.keys():
             self._tidList[item].append(len(self._transactionsDB) - recent_occur[item][-1])
         del recent_occur
         """
             Using Maximum Scalar Cardinality Value strategy to narrow down search space and generate candidate fuzzy periodic-frequent items. 
             Step1. Identify the regional representative (region with max support). This is the representative that will be tested to see if its greater than given minsup
             Step2. prune out all items whose regional support is less than the given minsup
             Step3. At the end, sort the list of stored Candidate Frequent-Periodic Patterns in ascending order
         """
 
         listOfFFList = []
         mapItemsToFFLIST = {}
         region_label = []
-        #self._minSup = self._convert(self._minSup)
+        for i in range(0, len(self._RegionsLabel)):
+            if self._RegionsLabel[i][1] not in region_label:
+                region_label.append(str(self._RegionsLabel[i][1]))
+
+        self._minSup = self._convert(self._minSup)
         for item in self._itemSupData.keys():
-            if self._itemSupData[item] >= self._minSup:
-                self._mapItemSum[item] = self._itemSupData[item]
+            if max(self._itemSupData[item]) >= self._minSup:
+                self._mapItemSum[item] = max(self._itemSupData[item])
+                self._mapItemRegions[item] = region_label[self._itemSupData[item].index(self._mapItemSum[item])]
                 fuList = _FFList(item)
                 if int(self._maxPer) >= max(self._tidList[item]):
                     fuList.isPeriodic = True
                 mapItemsToFFLIST[item] = fuList
                 listOfFFList.append(fuList)
+
         del self._itemSupData
         del self._tidList
         listOfFFList.sort(key=_ab._functools.cmp_to_key(self._compareItems))
         tid = 0
         for j in range(len(self._transactionsDB)):
             item_list = list(set(self._transactionsDB[j]).intersection(set(self._mapItemSum.keys())))
-            fuzzy_list = [self._fuzzyValuesDB[j][i] for i in range(len(self._fuzzyValuesDB[j])) if self._transactionsDB[j][i] in self._mapItemSum.keys()]
             revisedTransaction = []
             for i in range(0, len(item_list)):
                 pair = _Pair()
                 pair.item = item_list[i]
-                fuzzy_ref = fuzzy_list[i]
-                pair.quantity = fuzzy_ref
+                fuzzy_ref = str(self._fuzzyValuesDB[j][self._transactionsDB[j].index(pair.item)])
+                pair.quantity = self._fuzzyRegionReferenceMap[fuzzy_ref][
+                    region_label.index(self._mapItemRegions[pair.item])]
                 if pair.quantity > 0:
                     revisedTransaction.append(pair)
             revisedTransaction.sort(key=_ab._functools.cmp_to_key(self._compareItems))
             qaunt = {}
             for i in range(len(revisedTransaction) - 1, -1, -1):
                 pair = revisedTransaction[i]
-                qaunt[pair.item[0]] = pair.quantity
+                qaunt[pair.item] = pair.quantity
                 remainUtil = 0
-                temp = list(set(self._mapItemNeighbours[pair.item[0]]).intersection(set(qaunt.keys())))
-                # print(temp, self._mapItemNeighbours[pair.item[0]], qaunt)
+                temp = list(set(self._mapItemNeighbours[pair.item]).intersection(set(qaunt.keys())))
                 for j in temp:
                     remainUtil += float(qaunt[j])
                 del temp
                 remainingUtility = remainUtil
                 FFListObject = mapItemsToFFLIST[pair.item]
                 element = _Element(tid, pair.quantity, remainingUtility)
                 FFListObject.addElement(element)
@@ -447,15 +511,15 @@
            :param itemNeighbours: the set of common neighbours of prefix
            :type itemNeighbours: list or set
         """
         for i in range(0, len(FSFIM)):
             _FFListObject1 = FSFIM[i]
             if _FFListObject1.sumIUtil >= minSup:
                 self._WriteOut(prefix, prefixLen, _FFListObject1, _FFListObject1.sumIUtil)
-            newNeighbourList = self._Intersection(self._mapItemNeighbours.get(_FFListObject1.item[0]), itemNeighbours)
+            newNeighbourList = self._Intersection(self._mapItemNeighbours.get(_FFListObject1.item), itemNeighbours)
             if _FFListObject1.sumRUtil >= minSup:
                 exULs = []
                 for j in range(i + 1, len(FSFIM)):
                     _FFListObject2 = FSFIM[j]
                     if _FFListObject2.item in newNeighbourList:
                         exULs.append(self._construct(_FFListObject1, _FFListObject2))
                         self._joinsCnt += 1
@@ -571,16 +635,16 @@
             :param sumIUtil: sum of utility of itemSet
             :type sumIUtil: float
         """
         item = _FFListObject.item
         self._itemsCnt += 1
         res = ""
         for i in range(0, prefixLen):
-            res += str(prefix[i]) + "\t"
-        res += str(item)
+            res += str(prefix[i]) + "." + str(self._mapItemRegions[prefix[i]]) + "\t"
+        res += str(item) + "." + str(self._mapItemRegions.get(item))
         res1 = str(sumIUtil)
         self._finalPatterns[res] = res1
 
         if _FFListObject.isPeriodic:
             self._finalPeriodicPatterns[res] = res1
 
     def getPatternsAsDataFrame(self):
@@ -617,34 +681,81 @@
 
     def printResults(self):
         print("Total number of Spatial Fuzzy Periodic-Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
+    '''def getPatternsAsDataframe(self):
+
+        """
+        :return: returning periodic frequent patterns in a dataframe
+        :rtype: pd.DataFrame
+        """
+
+        data = []
+        dataFrame = _ab._pd.DataFrame()
+        for a, b in self._finalPeriodicPatterns.items():
+            data.append([a, b])
+            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
+        return dataFrame'''
+
+    def generateLatexCode(self, result):
+
+        titles = result.columns.tolist()
+        titles.remove("minsup")
+        titles.remove("algorithm")
+        for i in range(0, len(titles)):
+            legendary = pd.unique(result[['algorithm']].values.ravel())
+            color = ['red', 'blue', 'green', 'black', 'yellow']
+            xaxis = result["minsup"].values.tolist()
+            yaxis = result[titles[i]].values.tolist()
+            algo = result["algorithm"].values.tolist()
+            x_label = "minsup"
+            filename = titles[i]
+            latexwriter = open(filename + "Latexfile.tex", "w")
+            latexwriter.write("")
+            latexwriter.write("\\begin{axis}[\n\txlabel={\\Huge{" + x_label + "}},")
+            latexwriter.write("\n\tylabel={\\Huge{" + titles[i] + "}},")
+            latexwriter.write("\n\txmin=" + str(min(xaxis)) + ", xmax=" + str(max(xaxis)) + ",")
+
+            for num in range(0, len(legendary)):
+                latexwriter.write("\n\\addplot+  [" + color[num] + "]\n\tcoordinates {\n")
+                for num2 in range(0, len(xaxis)):
+                    if (legendary[num] == algo[num2]):
+                        latexwriter.write("(" + str(xaxis[num2]) + "," + str(yaxis[num2]) + ")\n")
+                latexwriter.write("\t};   \\addlegendentry{" + legendary[num] + "}\n")
+                if (num + 1 == len(legendary)):
+                    latexwriter.write("\\end{axis}")
+        print("Latex file generated successfully")
+
+    def generateGraphs(result):
+
+        fig = px.line(result, x='minsup', y='patterns', color='algorithm', title='Patterns)', markers=True)
+        fig.show()
+        fig = px.line(result, x='minsup', y='runtime', color='algorithm', title='Runtime)', markers=True)
+        fig.show()
+        fig = px.line(result, x='minsup', y='memoryUSS', color='algorithm', title='MemoryUSS)', markers=True)
+        fig.show()
+        fig = px.line(result, x='minsup', y='memoryRSS', color='algorithm', title='MemoryRSS)', markers=True)
+        fig.show()
+
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
+    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 7:
         if len(_ab._sys.argv) == 6:
             _ap = FGPFPMiner(_ab._sys.argv[1], _ab._sys.argv[2], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5],
                              _ab._sys.argv[6])
         if len(_ab._sys.argv) == 5:
             _ap = FGPFPMiner(_ab._sys.argv[1], _ab._sys.argv[2], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
         _ap.startMine()
         print("Total number of Spatial Fuzzy Periodic Frequent  Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS",  _ap.getMemoryRSS())
         print("Total ExecutionTime in seconds:", _ap.getRuntime())
         _ap.save("outputfile.txt")
     else:
-        _ap = FGPFPMiner('sample.txt','nei.txt', 1, 10, ' ')
-        _ap.startMine()
-        print("Total number of Fuzzy Periodic-Frequent Patterns:", len(_ap.getPatterns()))
-        _ap.save('output.txt')
-        print("Total Memory in USS:", _ap.getMemoryUSS())
-        print("Total Memory in RSS", _ap.getMemoryRSS())
-        print("Total ExecutionTime in seconds:", _ap.getRuntime())
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/FGPFPMiner_old.py` & `pami-2023.5.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/FGPFPMiner.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,36 +1,48 @@
-#  Copyright (C)  2021 Rage Uday Kiran
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     from PAMI.fuzzySpatialPeriodicFrequentPattern import FGPFPMiner as alg
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     obj = alg.FFSPMiner("input.txt", "neighbours.txt", 3, 4)
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
+#     obj.startMine()
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     print("Total number of fuzzy frequent spatial patterns:", len(obj.getPatterns()))
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-import pandas as pd
-import plotly.express as px
+#     obj.save("outputFile")
+#
+#     print("Total Memory in USS:", obj.getMemoryUSS())
+#
+#     print("Total Memory in RSS", obj.getMemoryRSS())
+#
+#     print("Total ExecutionTime in seconds:", obj.getRuntime())
+#
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+
 import PAMI.fuzzySpatialPeriodicFrequentPattern.basic.abstract as _ab
 
 
 class _FFList:
     """
      A class represent a Fuzzy List of an element
     Attributes :
@@ -103,17 +115,24 @@
     def __init__(self):
         self.item = 0
         self.quantity = 0
 
 
 class FGPFPMiner(_ab._fuzzySpatialFrequentPatterns):
     """
+    Description:
+    -------------
+    
         Fuzzy Frequent Spatial Pattern-Miner is desired to find all Spatially frequent fuzzy patterns
         which is on-trivial and challenging problem to its huge search space.we are using efficient pruning
          techniques to reduce the search space.
+         
+    Reference:
+    -----------
+    
     Attributes :
     ----------
         iFile : file
             Name of the input file to mine complete set of fuzzy spatial frequent patterns
         oFile : file
                Name of the oFile file to store complete set of fuzzy spatial frequent patterns
         minSup : float
@@ -169,35 +188,43 @@
         Intersection(neighbourX,neighbourY)
             Return common neighbours of 2 itemSet Neighbours
         findElementWithTID(uList, tid)
             To find element with same tid as given
         WriteOut(prefix, prefixLen, item, sumIUtil,period)
             To Store the patten
     Executing the code on terminal :
-    -------
+    -----------------------------------
         Format:
-            python3 FGPFPMiner_old.py <inputFile> <outputFile> <neighbours> <minSup> <maxPer> <sep>
+        -------
+            >>> python3 FGPFPMiner_old.py <inputFile> <outputFile> <neighbours> <minSup> <maxPer> <sep>
         Examples:
-            python3  FGPFPMiner_old.py sampleTDB.txt output.txt sampleN.txt 3 4  (minSup will be considered in support count or frequency)
-            python3  FGPFPMiner_old.py sampleTDB.txt output.txt sampleN.txt 0.3 0.4 (minSup and maxPer will be considered in percentage of database)
-                                                            (will consider "\t" as separator in both input and neighbourhood files)
-            python3  FGPFPMiner_old.py sampleTDB.txt output.txt sampleN.txt 3 4 ','
-                                                              (will consider "," as separator in both input and neighbourhood files)
+            >>> python3  FGPFPMiner_old.py sampleTDB.txt output.txt sampleN.txt 3 4  (minSup will be considered in support count or frequency)
+           
     Sample run of importing the code:
-    -------------------------------
+    --------------------------------------
+    .. code-block:: python
+    
         from PAMI.fuzzySpatialPeriodicFrequentPattern import FGPFPMiner as alg
+        
         obj = alg.FFSPMiner("input.txt", "neighbours.txt", 3, 4)
+        
         obj.startMine()
+        
         print("Total number of fuzzy frequent spatial patterns:", len(obj.getPatterns()))
+        
         obj.save("outputFile")
+        
         print("Total Memory in USS:", obj.getMemoryUSS())
+        
         print("Total Memory in RSS", obj.getMemoryRSS())
+        
         print("Total ExecutionTime in seconds:", obj.getRuntime())
+    
     Credits:
-    -------
+    ---------
             The complete program was written by B.Sai Chitra and Kundai Kwangwari under the supervision of Professor Rage Uday Kiran.
     """
 
     _startTime = float()
     _endTime = float()
     _minSup = str()
     _maxPer = float()
@@ -207,37 +234,31 @@
     _nFile = " "
     _FuzFile = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _sep = "\t"
     _transactionsDB = []
     _fuzzyValuesDB = []
+    _ts = []
 
-    def __init__(self, iFile, nFile, FuzFile, minSup, maxPer, sep):
-        super().__init__(iFile, nFile, FuzFile, minSup, maxPer, sep)
+    def __init__(self, iFile, nFile, minSup, maxPer, sep):
+        super().__init__(iFile, nFile, minSup, maxPer, sep)
         self._mapItemNeighbours = {}
         self._startTime = 0
         self._endTime = 0
         self._itemsCnt = 0
         self._itemSupData = {}
         self._mapItemSum = {}
-        self._finalClosedPeriodicPatterns = {}
-        self._mapItemRegions = {}
-        self._fuzzyRegionReferenceMap = {}
         self._joinsCnt = 0
         self._BufferSize = 200
         self._itemSetBuffer = []
         self._finalPatterns = {}
         self._finalPeriodicPatterns = {}
         self._tidList = {}
         self._dbLen = 0
-        self._regionsNumber = 0
-        self._RegionsCal = []
-        self._RegionsLabel = []
-        self._LabelKey = {}
 
     def _compareItems(self, o1, o2):
         """
             A Function that sort all FFI-list in ascending order of Support
         """
         compare = self._mapItemSum[o1.item] - self._mapItemSum[o2.item]
         if compare == 0:
@@ -258,41 +279,16 @@
         if type(value) is str:
             if '.' in value:
                 value = float(value)
             else:
                 value = int(value)
         return value
 
-    def _fuzzyMembershipFunc(self):
-
-        try:
-            with open(self._FuzFile, 'r', encoding='utf-8') as f:
-                count = 0
-                for line in f:
-                    line = line.split("\n")[0]
-                    parts = line.split(" ")
-                    lowerBound = parts[0].strip()
-                    upperBound = parts[1].strip()
-                    lb_Label = parts[2].strip()
-                    ub_Label = parts[3].strip()
-                    self._RegionsCal.append([int(lowerBound), int(upperBound)])
-                    self._RegionsLabel.append([lb_Label, ub_Label])
-                    for i in range(0, 2):
-                        if lb_Label.capitalize() not in self._LabelKey:
-                            self._LabelKey[lb_Label.capitalize()] = count
-                            count += 1
-                        if ub_Label.capitalize() not in self._LabelKey:
-                            self._LabelKey[ub_Label.capitalize()] = count
-                            count += 1
-        except IOError:
-            print("File Not Found")
-            quit()
-
     def _creatingItemSets(self):
-        self._transactionsDB, self._fuzzyValuesDB = [], []
+        self._transactionsDB, self._fuzzyValuesDB, self._ts = [], [], []
         if isinstance(self._iFile, _ab._pd.DataFrame):
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
                 self._transactionsDB = self._iFile['Transactions'].tolist()
             if 'fuzzyValues' in i:
@@ -302,29 +298,31 @@
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
                     line = line.decode("utf-8")
                     line = line.split("\n")[0]
                     parts = line.split(":")
                     items = parts[0].split(self._sep)
-                    quantities = parts[2].split(self._sep)
-                    self._transactionsDB.append([x for x in items])
-                    self._fuzzyValuesDB.append([x for x in quantities])
+                    quantities = parts[1].split(self._sep)
+                    self._ts.append(int(items[0]))
+                    self._transactionsDB.append([x for x in items[1:]])
+                    self._fuzzyValuesDB.append([float(x) for x in quantities])
             else:
                 try:
                     with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
                             line = line.split("\n")[0]
                             parts = line.split(":")
                             parts[0] = parts[0].strip()
-                            parts[2] = parts[2].strip()
+                            parts[1] = parts[1].strip()
                             items = parts[0].split(self._sep)
-                            quantities = parts[2].split(self._sep)
-                            self._transactionsDB.append([x for x in items])
-                            self._fuzzyValuesDB.append([x for x in quantities])
+                            quantities = parts[1].split(self._sep)
+                            self._ts.append(int(items[0]))
+                            self._transactionsDB.append([x for x in items[1:]])
+                            self._fuzzyValuesDB.append([float(x) for x in quantities])
                 except IOError:
                     print("File Not Found")
                     quit()
 
     def _mapNeighbours(self):
         self._mapItemNeighbours = {}
         if isinstance(self._nFile, _ab._pd.DataFrame):
@@ -365,125 +363,92 @@
                                 neigh1.append(parts[i])
                             self._mapItemNeighbours[item] = neigh1
                 except IOError:
                     print(self._nFile)
                     print("File Not Found")
                     quit()
 
-    def _Regions(self, quantity):
-
-        self._list = [0] * len(self._LabelKey)
-        if self._RegionsCal[0][0] < quantity <= self._RegionsCal[0][1]:
-            self._list[0] = 1
-            return
-        elif quantity >= self._RegionsCal[-1][0]:
-            self._list[-1] = 1
-            return
-        else:
-            for i in range(1, len(self._RegionsCal) - 1):
-                if self._RegionsCal[i][0] < quantity <= self._RegionsCal[i][1]:
-                    base = self._RegionsCal[i][1] - self._RegionsCal[i][0]
-                    for pos in range(0, 2):
-                        if self._RegionsLabel[i][pos].islower():
-                            self._list[self._LabelKey[self._RegionsLabel[i][pos].capitalize()]] = float(
-                                (self._RegionsCal[i][1] - quantity) / base)
-                        else:
-                            self._list[self._LabelKey[self._RegionsLabel[i][pos].capitalize()]] = float(
-                                (quantity - self._RegionsCal[i][0]) / base)
-        return
-
     def startMine(self):
         """ Frequent pattern mining process will start from here
         """
         self._startTime = _ab._time.time()
         self._mapNeighbours()
         self._creatingItemSets()
-        self._fuzzyMembershipFunc()
         self._finalPatterns = {}
         recent_occur = {}
         for line in range(len(self._transactionsDB)):
             item_list = self._transactionsDB[line]
             fuzzyValues_list = self._fuzzyValuesDB[line]
+            ts = self._ts[line]
             self._dbLen += 1
             """T
             The section below is for:
                 1.Finding the support of each item's region in the entire database
                 2.Finding the periodic patterns of the data
                 3.Trimming off the patterns whose support is less than minSupport
             """
             for i in range(0, len(item_list)):
                 item = item_list[i]
                 if item in self._tidList:
-                    self._tidList[item].append(self._dbLen - recent_occur[item][-1])
-                    recent_occur[item].append(self._dbLen)
+                    self._tidList[item].append(ts - recent_occur[item][-1])
+                    recent_occur[item].append(ts)
                 else:
-                    self._tidList[item] = [self._dbLen]
-                    recent_occur[item] = [self._dbLen]
+                    self._tidList[item] = [ts]
+                    recent_occur[item] = [ts]
                 fuzzy_ref = fuzzyValues_list[i]
-                if item in self._mapItemNeighbours:
-                    if fuzzy_ref not in self._fuzzyRegionReferenceMap:
-                        self._Regions(int(fuzzy_ref))
-                        self._fuzzyRegionReferenceMap[fuzzy_ref] = self._list
-
+                if item[0] in self._mapItemNeighbours:
                     if item in self._itemSupData.keys():
-                        self._itemSupData[item] = [sum(i) for i in zip(self._itemSupData[item],
-                                                                       self._fuzzyRegionReferenceMap[fuzzy_ref])]
+                        self._itemSupData[item] += fuzzy_ref
                     else:
-                        self._itemSupData[item] = self._fuzzyRegionReferenceMap[fuzzy_ref]
-
+                        self._itemSupData[item] = fuzzy_ref
         for item in self._tidList.keys():
             self._tidList[item].append(len(self._transactionsDB) - recent_occur[item][-1])
         del recent_occur
         """
             Using Maximum Scalar Cardinality Value strategy to narrow down search space and generate candidate fuzzy periodic-frequent items. 
             Step1. Identify the regional representative (region with max support). This is the representative that will be tested to see if its greater than given minsup
             Step2. prune out all items whose regional support is less than the given minsup
             Step3. At the end, sort the list of stored Candidate Frequent-Periodic Patterns in ascending order
         """
 
         listOfFFList = []
         mapItemsToFFLIST = {}
         region_label = []
-        for i in range(0, len(self._RegionsLabel)):
-            if self._RegionsLabel[i][1] not in region_label:
-                region_label.append(str(self._RegionsLabel[i][1]))
-
-        self._minSup = self._convert(self._minSup)
+        #self._minSup = self._convert(self._minSup)
         for item in self._itemSupData.keys():
-            if max(self._itemSupData[item]) >= self._minSup:
-                self._mapItemSum[item] = max(self._itemSupData[item])
-                self._mapItemRegions[item] = region_label[self._itemSupData[item].index(self._mapItemSum[item])]
+            if self._itemSupData[item] >= self._minSup:
+                self._mapItemSum[item] = self._itemSupData[item]
                 fuList = _FFList(item)
                 if int(self._maxPer) >= max(self._tidList[item]):
                     fuList.isPeriodic = True
                 mapItemsToFFLIST[item] = fuList
                 listOfFFList.append(fuList)
-
         del self._itemSupData
         del self._tidList
         listOfFFList.sort(key=_ab._functools.cmp_to_key(self._compareItems))
         tid = 0
         for j in range(len(self._transactionsDB)):
             item_list = list(set(self._transactionsDB[j]).intersection(set(self._mapItemSum.keys())))
+            fuzzy_list = [self._fuzzyValuesDB[j][i] for i in range(len(self._fuzzyValuesDB[j])) if self._transactionsDB[j][i] in self._mapItemSum.keys()]
             revisedTransaction = []
             for i in range(0, len(item_list)):
                 pair = _Pair()
                 pair.item = item_list[i]
-                fuzzy_ref = str(self._fuzzyValuesDB[j][self._transactionsDB[j].index(pair.item)])
-                pair.quantity = self._fuzzyRegionReferenceMap[fuzzy_ref][
-                    region_label.index(self._mapItemRegions[pair.item])]
+                fuzzy_ref = fuzzy_list[i]
+                pair.quantity = fuzzy_ref
                 if pair.quantity > 0:
                     revisedTransaction.append(pair)
             revisedTransaction.sort(key=_ab._functools.cmp_to_key(self._compareItems))
             qaunt = {}
             for i in range(len(revisedTransaction) - 1, -1, -1):
                 pair = revisedTransaction[i]
-                qaunt[pair.item] = pair.quantity
+                qaunt[pair.item[0]] = pair.quantity
                 remainUtil = 0
-                temp = list(set(self._mapItemNeighbours[pair.item]).intersection(set(qaunt.keys())))
+                temp = list(set(self._mapItemNeighbours[pair.item[0]]).intersection(set(qaunt.keys())))
+                # print(temp, self._mapItemNeighbours[pair.item[0]], qaunt)
                 for j in temp:
                     remainUtil += float(qaunt[j])
                 del temp
                 remainingUtility = remainUtil
                 FFListObject = mapItemsToFFLIST[pair.item]
                 element = _Element(tid, pair.quantity, remainingUtility)
                 FFListObject.addElement(element)
@@ -511,15 +476,15 @@
            :param itemNeighbours: the set of common neighbours of prefix
            :type itemNeighbours: list or set
         """
         for i in range(0, len(FSFIM)):
             _FFListObject1 = FSFIM[i]
             if _FFListObject1.sumIUtil >= minSup:
                 self._WriteOut(prefix, prefixLen, _FFListObject1, _FFListObject1.sumIUtil)
-            newNeighbourList = self._Intersection(self._mapItemNeighbours.get(_FFListObject1.item), itemNeighbours)
+            newNeighbourList = self._Intersection(self._mapItemNeighbours.get(_FFListObject1.item[0]), itemNeighbours)
             if _FFListObject1.sumRUtil >= minSup:
                 exULs = []
                 for j in range(i + 1, len(FSFIM)):
                     _FFListObject2 = FSFIM[j]
                     if _FFListObject2.item in newNeighbourList:
                         exULs.append(self._construct(_FFListObject1, _FFListObject2))
                         self._joinsCnt += 1
@@ -635,16 +600,16 @@
             :param sumIUtil: sum of utility of itemSet
             :type sumIUtil: float
         """
         item = _FFListObject.item
         self._itemsCnt += 1
         res = ""
         for i in range(0, prefixLen):
-            res += str(prefix[i]) + "." + str(self._mapItemRegions[prefix[i]]) + "\t"
-        res += str(item) + "." + str(self._mapItemRegions.get(item))
+            res += str(prefix[i]) + "\t"
+        res += str(item)
         res1 = str(sumIUtil)
         self._finalPatterns[res] = res1
 
         if _FFListObject.isPeriodic:
             self._finalPeriodicPatterns[res] = res1
 
     def getPatternsAsDataFrame(self):
@@ -681,81 +646,34 @@
 
     def printResults(self):
         print("Total number of Spatial Fuzzy Periodic-Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
-    '''def getPatternsAsDataframe(self):
-
-        """
-        :return: returning periodic frequent patterns in a dataframe
-        :rtype: pd.DataFrame
-        """
-
-        data = []
-        dataFrame = _ab._pd.DataFrame()
-        for a, b in self._finalPeriodicPatterns.items():
-            data.append([a, b])
-            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
-        return dataFrame'''
-
-    def generateLatexCode(self, result):
-
-        titles = result.columns.tolist()
-        titles.remove("minsup")
-        titles.remove("algorithm")
-        for i in range(0, len(titles)):
-            legendary = pd.unique(result[['algorithm']].values.ravel())
-            color = ['red', 'blue', 'green', 'black', 'yellow']
-            xaxis = result["minsup"].values.tolist()
-            yaxis = result[titles[i]].values.tolist()
-            algo = result["algorithm"].values.tolist()
-            x_label = "minsup"
-            filename = titles[i]
-            latexwriter = open(filename + "Latexfile.tex", "w")
-            latexwriter.write("")
-            latexwriter.write("\\begin{axis}[\n\txlabel={\\Huge{" + x_label + "}},")
-            latexwriter.write("\n\tylabel={\\Huge{" + titles[i] + "}},")
-            latexwriter.write("\n\txmin=" + str(min(xaxis)) + ", xmax=" + str(max(xaxis)) + ",")
-
-            for num in range(0, len(legendary)):
-                latexwriter.write("\n\\addplot+  [" + color[num] + "]\n\tcoordinates {\n")
-                for num2 in range(0, len(xaxis)):
-                    if (legendary[num] == algo[num2]):
-                        latexwriter.write("(" + str(xaxis[num2]) + "," + str(yaxis[num2]) + ")\n")
-                latexwriter.write("\t};   \\addlegendentry{" + legendary[num] + "}\n")
-                if (num + 1 == len(legendary)):
-                    latexwriter.write("\\end{axis}")
-        print("Latex file generated successfully")
-
-    def generateGraphs(result):
-
-        fig = px.line(result, x='minsup', y='patterns', color='algorithm', title='Patterns)', markers=True)
-        fig.show()
-        fig = px.line(result, x='minsup', y='runtime', color='algorithm', title='Runtime)', markers=True)
-        fig.show()
-        fig = px.line(result, x='minsup', y='memoryUSS', color='algorithm', title='MemoryUSS)', markers=True)
-        fig.show()
-        fig = px.line(result, x='minsup', y='memoryRSS', color='algorithm', title='MemoryRSS)', markers=True)
-        fig.show()
-
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 7:
+    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
         if len(_ab._sys.argv) == 6:
             _ap = FGPFPMiner(_ab._sys.argv[1], _ab._sys.argv[2], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5],
                              _ab._sys.argv[6])
         if len(_ab._sys.argv) == 5:
             _ap = FGPFPMiner(_ab._sys.argv[1], _ab._sys.argv[2], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
         _ap.startMine()
         print("Total number of Spatial Fuzzy Periodic Frequent  Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS",  _ap.getMemoryRSS())
         print("Total ExecutionTime in seconds:", _ap.getRuntime())
         _ap.save("outputfile.txt")
     else:
+        _ap = FGPFPMiner('sample.txt','nei.txt', 1, 10, ' ')
+        _ap.startMine()
+        print("Total number of Fuzzy Periodic-Frequent Patterns:", len(_ap.getPatterns()))
+        _ap.save('output.txt')
+        print("Total Memory in USS:", _ap.getMemoryUSS())
+        print("Total Memory in RSS", _ap.getMemoryRSS())
+        print("Total ExecutionTime in seconds:", _ap.getRuntime())
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/fuzzySpatialPeriodicFrequentPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/weightedFrequentPattern/basic/abstract.py`

 * *Files 3% similar despite different names*

```diff
@@ -22,35 +22,37 @@
 #      but WITHOUT ANY WARRANTY; without even the implied warranty of
 #      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 #      GNU General Public License for more details.
 #
 #      You should have received a copy of the GNU General Public License
 #      along with this program.  If not, see <https://www.gnu.org/licenses/>.
 
+# from abc import ABC as _ABC, abstractmethod as _abstractmethod
 from abc import ABC as _ABC, abstractmethod as _abstractmethod
 import time as _time
 import csv as _csv
 import pandas as _pd
 from collections import defaultdict as _defaultdict
 from itertools import combinations as _c
 import os as _os
 import os.path as _ospath
 import psutil as _psutil
 import sys as _sys
 import validators as _validators
 from urllib.request import urlopen as _urlopen
 import functools as _functools
 
-class _fuzzySpatialFrequentPatterns(_ABC):
+
+class _weightedFrequentPatterns(_ABC):
     """ This abstract base class defines the variables and methods that every frequent pattern mining algorithm must
         employ in PAMI
 
 
-    Attributes :
-    ----------
+       Attributes:
+       ----------
         iFile : str
             Input file name or path of the input file
         minSup: integer or float or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
             Otherwise, it will be treated as float.
             Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
@@ -66,16 +68,16 @@
         oFile : str
             Name of the output file to store complete set of frequent patterns
         memoryUSS : float
             To store the total amount of USS memory consumed by the program
         memoryRSS : float
             To store the total amount of RSS memory consumed by the program
 
-    Methods :
-    -------
+       Methods:
+       -------
         startMine()
             Calling this function will start the actual mining process
         getPatterns()
             This function will output all interesting patterns discovered by an algorithm
         save(oFile)
             This function will store the discovered patterns in an output file specified by the user
         getPatternsAsDataFrame()
@@ -85,40 +87,40 @@
         getMemoryRSS()
             This function outputs the total amount of RSS memory consumed by a mining algorithm
         getRuntime()
             This function outputs the total runtime of a mining algorithm
 
     """
 
-    def __init__(self, iFile, nFile, minSup, maxPer, sep="\t"):
+    def __init__(self, iFile, wFile, minSup, minWeight, sep="\t"):
         """
         :param iFile: Input file name or path of the input file
-        :type iFile: str
-        :param nFile: neighbourhood file name or path
-        :type nFile: str
+        :type iFile: str or DataFrame
+        :param wFile: Input file name or path of the input file
+        :type wFile: str or DataFrame
         :param minSup: The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
             Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=0.3 will be treated as float
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
         :type minSup: int or float or str
         :param sep: separator used to distinguish items from each other. The default separator is tab space. However, users can override the default separator
         :type sep: str
         """
 
         self._iFile = iFile
+        self._wFile = wFile
         self._sep = sep
-        self._nFile = nFile
         self._minSup = minSup
-        self._maxPer = maxPer
-        self._startTime = float()
-        self._endTime = float()
+        self._minWeight = minWeight
         self._finalPatterns = {}
         self._oFile = str()
         self._memoryUSS = float()
         self._memoryRSS = float()
+        self._startTime = float()
+        self._endTime = float()
 
     @_abstractmethod
     def startMine(self):
         """Code for the mining process will start from this function"""
 
         pass
 
@@ -152,19 +154,19 @@
 
     @_abstractmethod
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the program will be retrieved from this function"""
 
         pass
 
-
     @_abstractmethod
     def getRuntime(self):
         """Total amount of runtime taken by the program will be retrieved from this function"""
 
         pass
 
     @_abstractmethod
     def printResults(self):
-        """ TO print all the results of execution"""
+        """ To print all the results of execution"""
 
-        pass
+
+        pass
```

### Comparing `pami-2023.4.1/PAMI/geoReferencedFrequentPattern/GFPGrowth.py` & `pami-2023.5.1/PAMI/weightedUncertainFrequentPattern/basic/WUFIM.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,28 +1,64 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     from PAMI.weightedUncertainFrequentPattern.basic import WFIM as alg
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     obj = alg.WFIM(iFile, wFile, expSup, expWSup)
+#
+#     obj.startMine()
+#
+#     Patterns = obj.getPatterns()
+#
+#     print("Total number of  Patterns:", len(Patterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
 
-from PAMI.geoReferencedFrequentPatterns import abstract as _ab
 
-_minSup = str()
-_neighbourList = {}
-_ab._sys.setrecursionlimit(20000)
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+from PAMI.weightedUncertainFrequentPattern.basic import abstract as _ab
+
+_expSup = str()
+_expWSup = str()
+_weights = {}
 _finalPatterns = {}
+_ab._sys.setrecursionlimit(20000)
 
 
 class _Item:
     """
     A class used to represent the item with probability in transaction of dataset
     ...
     Attributes:
@@ -104,27 +140,23 @@
         self.info = {}
 
     def addTransaction(self, transaction):
         """adding transaction into tree
             :param transaction : it represents the one self.Database in database
             :type transaction : list
         """
-        global _neighbourList
+
         currentNode = self.root
         for i in range(len(transaction)):
             if transaction[i].item not in currentNode.children:
                 newNode = _Node(transaction[i].item, {})
-                nei = _neighbourList.get(transaction[i].item)
                 l1 = i - 1
                 lp = []
                 while l1 >= 0:
-                    if nei == None:
-                        break
-                    if transaction[l1].item in nei:
-                        lp.append(transaction[l1].probability)
+                    lp.append(transaction[l1].probability)
                     l1 -= 1
                 if len(lp) == 0:
                     newNode.probability = transaction[i].probability
                 else:
                     newNode.probability = max(lp) * transaction[i].probability
                 currentNode.addChild(newNode)
                 if transaction[i].item in self.summaries:
@@ -171,26 +203,21 @@
     def conditionalPatterns(self, alpha):
         """generates all the conditional patterns of respective node
             :param alpha : it represents the Node in tree
             :type alpha : _Node
         """
 
         # This method generates conditional patterns of node by traversing the tree
-        global _neighbourList
         finalPatterns = []
         sup = []
         for i in self.summaries[alpha]:
-            j = i.item
             s = i.probability
             set2 = []
             while i.parent.item is not None:
-                if _neighbourList.get(j) is not None:
-                    #print(_neighbourList.get(j))
-                    if i.parent.item in _neighbourList[j]:
-                        set2.append(i.parent.item)
+                set2.append(i.parent.item)
                 i = i.parent
             if len(set2) > 0:
                 set2.reverse()
                 finalPatterns.append(set2)
                 sup.append(s)
         finalPatterns, support, info = self.conditionalTransactions(finalPatterns, sup)
         return finalPatterns, support, info
@@ -208,26 +235,26 @@
         """ It generates the conditional patterns with frequent items
                 :param condPatterns : conditionalPatterns generated from conditionalPattern method for respective node
                 :type condPatterns : list
                 :support : the support of conditional pattern in tree
                 :support : int
         """
 
-        global minSup
+        global _expSup, _expWSup
         pat = []
         sup = []
         count = {}
         for i in range(len(condPatterns)):
             for j in condPatterns[i]:
                 if j in count:
                     count[j] += support[i]
                 else:
                     count[j] = support[i]
         updatedDict = {}
-        updatedDict = {k: v for k, v in count.items() if v >= minSup}
+        updatedDict = {k: v for k, v in count.items() if v >= _expSup}
         count = 0
         for p in condPatterns:
             p1 = [v for v in p if v in updatedDict]
             trans = sorted(p1, key=lambda x: updatedDict[x], reverse=True)
             if len(trans) > 0:
                 pat.append(trans)
                 sup.append(support[count])
@@ -236,44 +263,52 @@
 
     def generatePatterns(self, prefix):
         """generates the patterns
             :param prefix : forms the combination of items
             :type prefix : list
         """
 
-        global _finalPatterns, minSup
+        global _finalPatterns, _expSup, _expWSup, _weights
         for i in sorted(self.summaries, key=lambda x: (self.info.get(x))):
             pattern = prefix[:]
             pattern.append(i)
-            s = 0
-            for x in self.summaries[i]:
-                s += x.probability
-            _finalPatterns[tuple(pattern)] = self.info[i]
-            if s >= minSup:
+            weight = 0
+            for k in pattern:
+                weight = weight + _weights[k]
+            weight = weight/len(pattern)
+            if self.info.get(i) >= _expSup and self.info.get(i) * weight >= _expWSup:
+                _finalPatterns[tuple(pattern)] = self.info.get(i)
                 patterns, support, info = self.conditionalPatterns(i)
                 conditionalTree = _Tree()
                 conditionalTree.info = info.copy()
                 for pat in range(len(patterns)):
                     conditionalTree.addConditionalPattern(patterns[pat], support[pat])
                 if len(patterns) > 0:
                     conditionalTree.generatePatterns(pattern)
             self.removeNode(i)
 
 
-class GFPGrowth(_ab._frequentPatterns):
+class WUFIM(_ab._weightedFrequentPatterns):
     """
-        It is one of the fundamental algorithm to discover frequent patterns in a uncertain transactional database
-        using GFP-Tree.
+    Description:
+    -------------
+        It is one of the algorithm to discover weighted frequent patterns in a uncertain transactional database
+        using PUF-Tree.
+
     Reference:
-    --------
-        
+    ------------
+        Efficient Mining of Weighted Frequent Itemsets in Uncertain Databases, In book: Machine Learning and Data Mining in Pattern Recognition
+        Chun-Wei Jerry Lin, Wensheng Gan, Philippe Fournier Viger, Tzung-Pei Hong
+
     Attributes:
-    ----------
+    ------------
         iFile : file
             Name of the Input file or path of the input file
+        wFile : file
+            Name of the Input file or path of the input file
         oFile : file
             Name of the output file or path of the output file
         minSup: float or int or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
             Otherwise, it will be treated as float.
             Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
@@ -297,20 +332,20 @@
         tree : class
             To represents the Tree class
         itemSetCount : int
             To represents the total no of patterns
         finalPatterns : dict
             To store the complete patterns
     Methods:
-    -------
+    ---------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
-        savePatterns(oFile)
+        save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
             Complete set of frequent patterns will be loaded in to a dataframe
         getMemoryUSS()
             Total amount of USS memory consumed by the mining process will be retrieved from this function
         getMemoryRSS()
             Total amount of RSS memory consumed by the mining process will be retrieved from this function
@@ -324,56 +359,71 @@
             Update the transactions by removing non-frequent items and sort the Database by item decreased support
         buildTree()
             After updating the Database, remaining items will be added into the tree by setting root node as null
         convert()
             to convert the user specified value
         startMine()
             Mining process will start from this function
-    Executing the code on terminal:
-    -------
+
+    **Methods to execute code on terminal**
+
         Format:
-        ------
-        python3 GFPGrowth.py <inputFile> <neighborFile> <outputFile> <minSup>
-        Examples:
-        --------
-        python3 GFPGrowth.py sampleTDB.txt sampleNeighbor.txt patterns.txt 3    (minSup  will be considered in support count or frequency)
-    
-    Sample run of importing the code:
-    -------------------
-        from PAMI.geoReferenceFrequentPattern.basic import GFPGrowth as alg
-        obj = alg.GFPGrowth(iFile, nFile, minSup)
+                  >>>  python3 WUFIM.py <inputFile> <outputFile> <minSup>
+        Example:
+                  >>>  python3 WUFIM.py sampleTDB.txt patterns.txt 3
+
+                 .. note:: minSup  will be considered in support count or frequency
+
+    **Importing this algorithm into a python program**
+
+.. code-block:: python
+
+        from PAMI.weightedUncertainFrequentPattern.basic import WFIM as alg
+
+        obj = alg.WFIM(iFile, wFile, expSup, expWSup)
+
         obj.startMine()
+
         Patterns = obj.getPatterns()
+
         print("Total number of  Patterns:", len(Patterns))
+
         obj.savePatterns(oFile)
+
         Df = obj.getPatternsAsDataFrame()
+
         memUSS = obj.getMemoryUSS()
+
         print("Total Memory in USS:", memUSS)
+
         memRSS = obj.getMemoryRSS()
+
         print("Total Memory in RSS", memRSS)
+
         run = obj.getRuntime()
+
         print("Total ExecutionTime in seconds:", run)
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
-    """
+   """
     _startTime = float()
     _endTime = float()
     _minSup = str()
     _finalPatterns = {}
     _iFile = " "
+    _wFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
     _rank = {}
+    _expSup = float()
+    _expWSup = float()
 
-    def __init__(self, iFile, nFile, minSup, sep='\t'):
-        super().__init__(iFile, nFile, minSup, sep)
+    def __init__(self, iFile, wFile, expSup, expWSup, sep='\t'):
+        super().__init__(iFile, wFile, expSup, expWSup, sep)
 
     def _creatingItemSets(self):
         """
             Scans the uncertain transactional dataset
         """
         self._Database = []
         if isinstance(self._iFile, _ab._pd.DataFrame):
@@ -393,110 +443,101 @@
                 self._Database.append(tr)
 
             # print(self.Database)
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
-                    line.strip()
                     line = line.decode("utf-8")
-                    temp = [i.rstrip() for i in line.split(self._sep)]
-                    temp = [x for x in temp if x]
+                    line = line.strip()
+                    line = [i for i in line.split(':')]
+                    temp1 = [i.rstrip() for i in line[0].split(self._sep)]
+                    temp2 = [i.rstrip() for i in line[1].split(self._sep)]
+                    temp1 = [x for x in temp1 if x]
+                    temp2 = [x for x in temp2 if x]
                     tr = []
-                    for i in temp:
-                        i1 = i.index('(')
-                        i2 = i.index(')')
-                        item = i[0:i1]
-                        probability = float(i[i1 + 1:i2])
+                    for i in range(len(temp1)):
+                        item = temp1[i]
+                        probability = float(temp2[i])
                         product = _Item(item, probability)
                         tr.append(product)
-                    self._Database.append(temp)
+                    self._Database.append(tr)
             else:
                 try:
                     with open(self._iFile, 'r') as f:
                         for line in f:
-                            temp = [i.rstrip() for i in line.split(self._sep)]
-                            temp = [x for x in temp if x]
+                            line = line.strip()
+                            line = [i for i in line.split(':')]
+                            temp1 = [i.rstrip() for i in line[0].split(self._sep)]
+                            temp2 = [i.rstrip() for i in line[1].split(self._sep)]
+                            temp1 = [x for x in temp1 if x]
+                            temp2 = [x for x in temp2 if x]
                             tr = []
-                            for i in temp[1:]:
-                                i1 = i.index('(')
-                                i2 = i.index(')')
-                                item = i[0:i1]
-                                probability = float(i[i1 + 1:i2])
+                            for i in range(len(temp1)):
+                                item = temp1[i]
+                                probability = float(temp2[i])
                                 product = _Item(item, probability)
                                 tr.append(product)
                             self._Database.append(tr)
                 except IOError:
                     print("File Not Found")
-                    
-    def _creatingNeighbours(self):
+
+    def _scanningWeights(self):
         """
             Scans the uncertain transactional dataset
         """
-        global _neighbourList
-        _neighbourList = {}
-        if isinstance(self._nFile, _ab._pd.DataFrame):
-            uncertain, data = [], []
-            if self._iFile.empty:
+        self._weights = {}
+        if isinstance(self._wFile, _ab._pd.DataFrame):
+            weights, data = [], []
+            if self._wFile.empty:
                 print("its empty..")
-            i = self._iFile.columns.values.tolist()
-            if 'Transactions' in i:
-                self._Database = self._iFile['Transactions'].tolist()
-            if 'uncertain' in i:
-                uncertain = self._iFile['uncertain'].tolist()
+            i = self._wFile.columns.values.tolist()
+            if 'items' in i:
+                data = self._wFile['items'].tolist()
+            if 'weights' in i:
+                weights = self._wFile['weights'].tolist()
             for k in range(len(data)):
-                tr = []
-                for j in range(len(data[k])):
-                    product = _Item(data[k][j], uncertain[k][j])
-                    tr.append(product)
-                self._Database.append(tr)
+                self._weights[data[k]] = int(float(weights[k]))
 
             # print(self.Database)
-        if isinstance(self._nFile, str):
-            if _ab._validators.url(self._iFile):
-                data = _ab._urlopen(self._iFile)
+        if isinstance(self._wFile, str):
+            if _ab._validators.url(self._wFile):
+                data = _ab._urlopen(self._wFile)
                 for line in data:
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
-                    tr = []
-                    for i in temp:
-                        i1 = i.index('(')
-                        i2 = i.index(')')
-                        item = i[0:i1]
-                        probability = float(i[i1 + 1:i2])
-                        product = _Item(item, probability)
-                        tr.append(product)
-                    self._Database.append(temp)
+                    self._weights[temp[0]] = int(float(temp[1]))
             else:
                 try:
-                    with open(self._nFile, 'r') as f:
+                    with open(self._wFile, 'r') as f:
                         for line in f:
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
-                            _neighbourList[temp[0]] = temp[1:]
+                            self._weights[temp[0]] = float(temp[1])
                 except IOError:
                     print("File Not Found")
 
     def _frequentOneItem(self):
         """takes the self.Database and calculates the support of each item in the dataset and assign the
             ranks to the items by decreasing support and returns the frequent items list
                 :param self.Database : it represents the one self.Database in database
                 :type self.Database : list
         """
 
         mapSupport = {}
         for i in self._Database:
             for j in i:
                 if j.item not in mapSupport:
-                    mapSupport[j.item] = j.probability
+                    if self._weights.get(j.item) is not None:
+                        mapSupport[j.item] = [j.probability, self._weights[j.item]]
                 else:
-                    mapSupport[j.item] += j.probability
-        mapSupport = {k: v for k, v in mapSupport.items() if v >= self._minSup}
+                    mapSupport[j.item][0] += j.probability
+        mapSupport = {k: v[0] for k, v in mapSupport.items() if v[0] >= self._expSup and v[0] * v[1] >= self._expWSup}
         plist = [k for k, v in sorted(mapSupport.items(), key=lambda x: x[1], reverse=True)]
         self.rank = dict([(index, item) for (item, index) in enumerate(plist)])
         return mapSupport, plist
 
     @staticmethod
     def _buildTree(data, info):
         """it takes the self.Database and support of each item and construct the main tree with setting root
@@ -587,38 +628,46 @@
                             if j.item in x:
                                 s *= j.probability
                         if x in periods:
                             periods[x] += s
                         else:
                             periods[x] = s
         for x, y in periods.items():
-            if y >= self._minSup:
+            weight = 0
+            for i in x:
+                weight += self._weights[i]
+            weight = weight / len(x)
+            if weight * y >= self._expWSup:
                 sample = str()
                 for i in x:
-                    sample = sample + i + " "
+                    sample = sample + i + "\t"
                 self._finalPatterns[sample] = y
 
     def startMine(self):
         """Main method where the patterns are mined by constructing tree and remove the remove the false patterns
             by counting the original support of a patterns
         """
-        global minSup
+        global _expSup, _expWSup, _weights, _finalPatterns
         self._startTime = _ab._time.time()
+        self._Database, self._weights = [], {}
         self._creatingItemSets()
-        self._creatingNeighbours()
-        #self._minSup = self._convert(self._minSup)
-        minSup = self._minSup
+        self._scanningWeights()
+        _weights = self._weights
+        self._expSup = float(self._expSup)
+        self._expWSup = float(self._expWSup)
+        _expSup = self._expSup
+        _expWSup = self._expWSup
         self._finalPatterns = {}
         mapSupport, plist = self._frequentOneItem()
         self.Database1 = self._updateTransactions(mapSupport)
         info = {k: v for k, v in mapSupport.items()}
         Tree1 = self._buildTree(self.Database1, info)
         Tree1.generatePatterns([])
         self._removeFalsePositives()
-        print("Geo-Referenced Frequent patterns were generated from uncertain databases successfully using GFP algorithm")
+        print("Weighted Frequent patterns were generated  successfully using WUFIM algorithm")
         self._endTime = _ab._time.time()
         process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryUSS = float()
         self.memoryRSS = float()
         self._memoryUSS = process.memory_full_info().uss
         self.memoryRSS = process.memory_info().rss
 
@@ -651,59 +700,66 @@
         :return: returning frequent patterns in a dataframe
         :rtype: pd.DataFrame
         """
 
         dataframe = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a, b])
+            s = str()
+            for i in a:
+                s = s + i + " "
+            data.append([s, b])
             dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
         return dataframe
 
-    def savePatterns(self, outFile):
+    def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
         :param outFile: name of the output file
         :type outFile: file
         """
         self.oFile = outFile
         writer = open(self.oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            s1 = x + ":" + str(y)
+            s = str()
+            for i in x:
+                s = s + i + "\t"
+            s1 = s.strip() + ":" + str(y)
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
         :return: returning frequent patterns
         :rtype: dict
         """
         return self._finalPatterns
-    
+
     def printResults(self):
-        print("Total number of Patterns:", len(self.getPatterns()))
-        self.savePatterns("patterns.txt")
-        memUSS = self.getMemoryUSS()
-        print("Total Memory in USS:", memUSS)
-        memRSS = self.getMemoryRSS()
-        print("Total Memory in RSS", memRSS)
-        run = self.getRuntime()
-        print("Total ExecutionTime in ms:", run)
+        print("Total number of  Weighted Uncertain Frequent Patterns:", len(self.getPatterns()))
+        print("Total Memory in USS:", self.getMemoryUSS())
+        print("Total Memory in RSS", self.getMemoryRSS())
+        print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
+    if len(_ab._sys.argv) == 6 or len(_ab._sys.argv) == 7:
+        if len(_ab._sys.argv) == 7:
+            _ap = WUFIM(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5], _ab._sys.argv[6])
         if len(_ab._sys.argv) == 6:
-            _ap = GFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
-        if len(_ab._sys.argv) == 5:
-            _ap = GFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+            _ap = WUFIM(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
         _ap.startMine()
-        _Patterns = _ap.getPatterns()
-        print("Total number of Patterns:", len(_Patterns))
-        _ap.savePatterns(_ab._sys.argv[2])
-        _memUSS = _ap.getMemoryUSS()
-        print("Total Memory in USS:", _memUSS)
-        _memRSS = _ap.getMemoryRSS()
-        print("Total Memory in RSS", _memRSS)
-        _run = _ap.getRuntime()
-        print("Total ExecutionTime in ms:", _run)
+        print("Total number of Weighted Uncertain Frequent Patterns:", len(_ap.getPatterns()))
+        _ap.save(_ab._sys.argv[2])
+        print("Total Memory in USS:", _ap.getMemoryUSS())
+        print("Total Memory in RSS", _ap.getMemoryRSS())
+        print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
+        for k in [120, 140, 160, 180, 200]:
+            _ap = WUFIM('/Users/likhitha/Downloads/uncertainTransaction_T10I4D200K.csv', '/Users/likhitha/Downloads/T10_weights.txt',
+                        k, 500, '\t')
+            _ap.startMine()
+            print("Total number of Weighted Uncertain Frequent Patterns:", len(_ap.getPatterns()))
+            _ap.save('/Users/likhitha/Downloads/WUFIM_output.txt')
+            print("Total Memory in USS:", _ap.getMemoryUSS())
+            print("Total Memory in RSS", _ap.getMemoryRSS())
+            print("Total ExecutionTime in ms:", _ap.getRuntime())
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/geoReferencedFrequentPattern/abstract.py` & `pami-2023.5.1/PAMI/geoReferencedFrequentPattern/abstract.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,7 +1,8 @@
+
 from abc import ABC as _ABC, abstractmethod as _abstractmethod
 import time as _time
 import csv as _csv
 import pandas as _pd
 from collections import defaultdict as _defaultdict
 from itertools import combinations as _c
 import os as _os
```

### Comparing `pami-2023.4.1/PAMI/geoReferencedPeriodicFrequentPattern/basic/GPFPMiner.py` & `pami-2023.5.1/PAMI/geoReferencedPeriodicFrequentPattern/basic/GPFPMiner.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,15 +1,68 @@
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     import PAMI.geoReferencedPeridicFrequentPattern.GPFPMiner as alg
+#
+#     obj = alg.GPFPMiner("sampleTDB.txt", "sampleN.txt", 5, 3)
+#
+#     obj.startMine()
+#
+#     Patterns = obj.getPatterns()
+#
+#     print("Total number of Geo Referenced Periodic-Frequent Patterns:", len(Patterns))
+#
+#     obj.save("outFile")
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 from  PAMI.geoReferencedPeriodicFrequentPattern.basic import abstract as _ab
 
 
 class GPFPMiner(_ab._geoReferencedPeriodicFrequentPatterns):
     """ 
+    Description:
+    ------------
         GPFPMiner is a Extension of ECLAT algorithm,which  stands for Equivalence Class Clustering and bottom-up
         Lattice Traversal to mine the geo referenced peridoic frequent patterns.
-            ...
+        
+    Reference:
+    -----------
+    
+          
     Attributes :
     ----------
             iFile : str
                 Input file name or path of the input file
             nFile: str:
                Name of Neighbourhood file name
             minSup: float or int or str
@@ -36,15 +89,15 @@
             memoryUSS : float
                 To store the total amount of USS memory consumed by the program
             memoryRSS : float
                 To store the total amount of RSS memory consumed by the program
             Database : list
                 To store the complete set of transactions available in the input database/file
     Methods :
-    -------
+    ---------
             startMine()
                 Mining process will start from here
             getPatterns()
                 Complete set of patterns will be retrieved with this function
             save(oFile)
                 Complete set of frequent patterns will be loaded in to a output file
             getPatternsAsDataFrames()
@@ -62,28 +115,27 @@
             convert(value):
                 To convert the given user specified value    
             getNeighbourItems(keySet):
                 A function to get common neighbours of a itemSet
              mapNeighbours(file):
                 A function to map items to their neighbours
     Executing the code on terminal :
-    ------------------------------
+    ---------------------------------
         Format:
-            python3 GPFPMiner.py <inputFile> <outputFile> <neighbourFile> <minSup> <maxPer>
+        --------
+            >>> python3 GPFPMiner.py <inputFile> <outputFile> <neighbourFile> <minSup> <maxPer>
         Examples:
-            python3 GPFPMiner.py sampleTDB.txt output.txt sampleN.txt 0.5 0.3 (minSup & maxPer will be considered in percentage of database transactions)
-
-            python3 GPFPMiner.py sampleTDB.txt output.txt sampleN.txt 5 3 (minSup & maxPer will be considered in support count or frequency)
-                                                                (it considers "\t" as separator)
-
-            python3 GPFPMiner.py sampleTDB.txt output.txt sampleN.txt 5 3 ',' (it will consider "," as a separator)
+        ---------
+            >>> python3 GPFPMiner.py sampleTDB.txt output.txt sampleN.txt 0.5 0.3 (minSup & maxPer will be considered in percentage of database transactions)
 
+           
     Sample run of importing the code :
-    -------------------------------
-
+    ------------------------------------
+    .. code-block:: python
+    
         import PAMI.geoReferencedPeridicFrequentPattern.GPFPMiner as alg
 
         obj = alg.GPFPMiner("sampleTDB.txt", "sampleN.txt", 5, 3)
 
         obj.startMine()
 
         Patterns = obj.getPatterns()
```

### Comparing `pami-2023.4.1/PAMI/geoReferencedPeriodicFrequentPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/geoReferencedPeriodicFrequentPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/highUtilityFrequentPatterns/basic/HUFIM.py` & `pami-2023.5.1/PAMI/highUtilityFrequentPatterns/basic/HUFIM.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,34 +1,57 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.highUtilityFrequentPatterns.basic import HUFIM as alg
+#
+#     ob j =alg.HUFIM("input.txt", 35, 20)
+#
+#     obj.startMine()
+#
+#     Patterns = obj.getPatterns()
+#
+#     print("Total number of high utility frequent Patterns:", len(Patterns))
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-#
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     obj.save("output")
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 
 from PAMI.highUtilityFrequentPatterns.basic import abstract as _ab
 
 
 class _Transaction:
     """
         A class to store Transaction of a database
@@ -273,19 +296,21 @@
             A method to return transactions from database
         """
         return self.transactions
 
 
 class HUFIM(_ab._utilityPatterns):
     """
-    HUFIM (High Utility Frequent Itemset Miner) algorithm helps us to mine High Utility Frequent ItemSets (HUFIs) from transactional databases.
+    Description:
+    -------------
+        HUFIM (High Utility Frequent Itemset Miner) algorithm helps us to mine High Utility Frequent ItemSets (HUFIs) from transactional databases.
 
 
     Reference:
-    ---------
+    -----------
         Kiran, R.U., Reddy, T.Y., Fournier-Viger, P., Toyoda, M., Reddy, P.K., & Kitsuregawa, M. (2019).
         Efficiently Finding High Utility-Frequent Itemsets Using Cutoff and Suffix Utility. PAKDD 2019.
         DOI: 10.1007/978-3-030-16145-3_15
     
     Attributes:
     -----------
         iFile : file
@@ -324,15 +349,15 @@
             Number of RHUI's
         itemsToKeep: list
             keep only the promising items i.e items that can extend other items to form RHUIs
         itemsToExplore: list
             list of items that needs to be explored
 
     Methods :
-    -------
+    ----------
         startMine()
                 Mining process will start from here
         getPatterns()
                 Complete set of patterns will be retrieved with this function
         save(oFile)
                 Complete set of patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -357,25 +382,28 @@
               A Method to sort transaction
         sortTransaction(self, trans1, trans2)
               A Method to sort transaction
         useUtilityBinArrayToCalculateLocalUtilityFirstTime(self, dataset)
              A method to calculate local utility values for single itemSets
 
     Executing the code on terminal :
-    -------
+    ---------------------------------
         Format:
-            python3 HUFIM.py <inputFile> <outputFile> <minUtil> <sep>
+        ---------
+             >>>  python3 HUFIM.py <inputFile> <outputFile> <minUtil> <sep>
         Examples:
-            python3 HUFIM.py sampleTDB.txt output.txt 35 20 (it will consider "\t" as separator)
+        ---------
+            >>>  python3 HUFIM.py sampleTDB.txt output.txt 35 20 (it will consider "\t" as separator)
 
-            python3 HUFIM.py sampleTDB.txt output.txt 35 20 , (it will consider "," as separator)
+            >>>  python3 HUFIM.py sampleTDB.txt output.txt 35 20 , (it will consider "," as separator)
 
     Sample run of importing the code:
     -------------------------------
-        
+    .. code-block:: python
+
         from PAMI.highUtilityFrequentPatterns.basic import HUFIM as alg
 
         obj=alg.HUFIM("input.txt", 35, 20)
 
         obj.startMine()
 
         Patterns = obj.getPatterns()
@@ -393,15 +421,15 @@
         print("Total Memory in RSS", memRSS)
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
    
     Credits:
-    -------
+    ---------
         The complete program was written by pradeep pallikila under the supervision of Professor Rage Uday Kiran.
      
     """
 
     _highUtilityFrequentItemSets = []
     _candidateCount = 0
     _utilityBinArrayLU = {}
```

### Comparing `pami-2023.4.1/PAMI/highUtilityFrequentPatterns/basic/abstract.py` & `pami-2023.5.1/PAMI/highUtilityFrequentPatterns/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/highUtilityFrequentSpatialPattern/__init__.py` & `pami-2023.5.1/PAMI/highUtilityFrequentSpatialPattern/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/highUtilityFrequentSpatialPattern/basic/SHUFIM.py` & `pami-2023.5.1/PAMI/highUtilityFrequentSpatialPattern/basic/SHUFIM.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,57 @@
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#
+#         from PAMI.highUtilityFrequentSpatialPattern.basic import SHUFIM as alg
+#
+#         obj=alg.SHUFIM("input.txt","Neighbours.txt",35,20)
+#
+#         obj.startMine()
+#
+#         patterns = obj.getPatterns()
+#
+#         print("Total number of Spatial high utility frequent Patterns:", len(patterns))
+#
+#         obj.save("output")
+#
+#         memUSS = obj.getMemoryUSS()
+#
+#         print("Total Memory in USS:", memUSS)
+#
+#         memRSS = obj.getMemoryRSS()
+#
+#         print("Total Memory in RSS", memRSS)
+#
+#         run = obj.getRuntime()
+#
+#         print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+
 from PAMI.highUtilityFrequentSpatialPattern.basic import abstract as _ab
 from functools import cmp_to_key as _comToKey
 
 class _Transaction:
     """
         A class to store Transaction of a database
 
@@ -262,18 +312,20 @@
             A method to return transactions from database
         """
         return self.transactions
 
 
 class SHUFIM(_ab._utilityPatterns):
     """
-      Spatial High Utility Frequent ItemSet Mining (SHUFIM) aims to discover all itemSets in a spatioTemporal database
+    Description:
+    -------------
+       Spatial High Utility Frequent ItemSet Mining (SHUFIM) aims to discover all itemSets in a spatioTemporal database
        that satisfy the user-specified minimum utility, minimum support and maximum distance constraints
     Reference:
-    ---------
+    -----------
         10.1007/978-3-030-37188-3_17
 
     Attributes:
     -----------
         iFile : file
             Name of the input file to mine complete set of frequent patterns
         nFile : file
@@ -310,15 +362,15 @@
             Number of SHUFI's (Spatial High Utility Frequent Itemsets)
         itemsToKeep: list
             keep only the promising items ie items whose supersets can be required patterns
         itemsToExplore: list
             keep items that subtreeUtility grater than minUtil
 
     Methods :
-    -------
+    ---------
         startMine()
                 Mining process will start from here
         getPatterns()
                 Complete set of patterns will be retrieved with this function
         save(oFile)
                 Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -347,22 +399,26 @@
               A Method to sort transaction in the order of PMU
         sortTransaction(self, trans1, trans2)
               A Method to sort transaction in the order of PMU
         useUtilityBinArrayToCalculateLocalUtilityFirstTime(self, dataset)
              A method to scan the database using utility bin array to calculate the pmus
 
     Executing the code on terminal :
-    -------
-        Format: python3 SHUFIM.py <inputFile> <outputFile> <Neighbours> <minUtil> <minSup> <sep>
-        Examples: python3 SHUFIM.py sampleTDB.txt output.txt sampleN.txt 35 20 (it will consider "\t" as separator)
-                  python3 SHUFIM.py sampleTDB.txt output.txt sampleN.txt 35 20 , (it will consider "," as separator)
+    -------------------------------------
+        Format:
+        ------
+          >>> python3 SHUFIM.py <inputFile> <outputFile> <Neighbours> <minUtil> <minSup> <sep>
+        Examples:
+        ------
+          >>> python3 SHUFIM.py sampleTDB.txt output.txt sampleN.txt 35 20 (it will consider "\t" as separator)
 
     Sample run of importing the code:
-    -------------------------------
-        
+    -------------------------------------
+    .. code-block:: python
+
         from PAMI.highUtilityFrequentSpatialPattern.basic import SHUFIM as alg
 
         obj=alg.SHUFIM("input.txt","Neighbours.txt",35,20)
 
         obj.startMine()
 
         patterns = obj.getPatterns()
@@ -380,16 +436,18 @@
         print("Total Memory in RSS", memRSS)
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
 
     Credits:
-    -------
+    ---------
+
             The complete program was written by Pradeep Pallikila under the supervision of Professor Rage Uday Kiran.
+
     """
     _candidateCount = 0
     _utilityBinArrayLU = {}
     _utilityBinArraySU = {}
     _oldNamesToNewNames = {}
     _newNamesToOldNames = {}
     _singleItemSetsSupport = {}
```

### Comparing `pami-2023.4.1/PAMI/highUtilityFrequentSpatialPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/highUtilityFrequentSpatialPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/highUtilityPatterns/basic/EFIM.py` & `pami-2023.5.1/PAMI/highUtilityPatterns/basic/EFIM.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,56 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#         from PAMI.highUtilityPatterns.basic import EFIM as alg
+#
+#         obj=alg.EFIM("input.txt",35)
+#
+#         obj.startMine()
+#
+#         Patterns = obj.getPatterns()
+#
+#         print("Total number of high utility Patterns:", len(Patterns))
+#
+#         obj.save("output")
+#
+#         memUSS = obj.getMemoryUSS()
+#
+#         print("Total Memory in USS:", memUSS)
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#         memRSS = obj.getMemoryRSS()
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#         print("Total Memory in RSS", memRSS)
+#
+#         run = obj.getRuntime()
+#
+#         print("Total ExecutionTime in seconds:", run)
+
+
+
 
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
 
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 from PAMI.highUtilityPatterns.basic import abstract as _ab
 
 
 class _Transaction:
     """
         A class to store Transaction of a database
@@ -249,15 +282,17 @@
             A method to return transactions from database
         """
         return self.transactions
 
 
 class EFIM(_ab._utilityPatterns):
     """
-    EFIM is one of the fastest algorithm to mine High Utility ItemSets from transactional databases.
+    Description:
+    ------------
+        EFIM is one of the fastest algorithm to mine High Utility ItemSets from transactional databases.
     
     Reference:
     ---------
         Zida, S., Fournier-Viger, P., Lin, J.CW. et al. EFIM: a fast and memory efficient algorithm for
         high-utility itemset mining. Knowl Inf Syst 51, 595625 (2017). https://doi.org/10.1007/s10115-016-0986-0
     
     Attributes:
@@ -325,21 +360,26 @@
               A Method to sort transaction
         sort_transaction(self, trans1, trans2)
               A Method to sort transaction
         useUtilityBinArrayToCalculateLocalUtilityFirstTime(self, dataset)
              A method to calculate local utility values for single itemsets
 
     Executing the code on terminal :
-    -------
-        Format: python3 EFIM.py <inputFile> <outputFile> <minUtil> <sep>
-        Examples: python3 EFIM sampleTDB.txt output.txt 35  (it will consider "\t" as separator)
-                  python3 EFIM sampleTDB.txt output.txt 35 , (it will consider "," as separator)
+    -------------------------------------
+        Format:
+        ------
+           >>> python3 EFIM.py <inputFile> <outputFile> <minUtil> <sep>
+        Examples:
+        ---------
+           >>> python3 EFIM sampleTDB.txt output.txt 35  (it will consider "\t" as separator)
+           >>> python3 EFIM sampleTDB.txt output.txt 35 , (it will consider "," as separator)
 
     Sample run of importing the code:
-    -------------------------------
+    -------------------------------------
+    .. code-block:: python
         
         from PAMI.highUtilityPatterns.basic import EFIM as alg
 
         obj=alg.EFIM("input.txt",35)
 
         obj.startMine()
```

### Comparing `pami-2023.4.1/PAMI/highUtilityPatterns/basic/HMiner.py` & `pami-2023.5.1/PAMI/highUtilityPatterns/basic/HMiner.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,55 @@
 
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.highUtilityPatterns.basic import HMiner as alg
+#
+#     obj = alg.HMiner("input.txt", 35)
+#
+#     obj.startMine()
+#
+#     Patterns = obj.getPatterns()
+#
+#     print("Total number of high utility Patterns:", len(Patterns))
+#
+#     obj.save("output")
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 from PAMI.highUtilityPatterns.basic import abstract as _ab
 
 
 class _Element:
     """
     A class represents an Element of a utility list .
     Attributes :
@@ -80,15 +127,22 @@
     def __init__(self):
         self.item = 0
         self.utility = 0
 
 
 class HMiner(_ab._utilityPatterns):
     """
+    Description:
+    -------------
+
         High Utility itemSet Mining (HMIER) is an importent algorithm to miner High utility items from the database.
+
+    Reference:
+    ------------
+
     Attributes:
     ----------
         iFile : file
             Name of the input file to mine complete set of frequent patterns
         oFile : file
             Name of the output file to store complete set of frequent patterns
         memoryRSS : float
@@ -129,24 +183,29 @@
             A method to update closed values
         saveitemSet(prefix, prefixLen, item, utility)
             A method to save itemSets
         updateElement(z, culs, st, excul, newT, ex, duppos, ey_ts)
             A method to updates vales for duplicates
         construcCUL(x, culs, st, minUtil, length, exnighbors)
             A method to construct CUL's database
+
     Executing the code on terminal :
-    -------
+    -----------------------------------
         Format:
-            python3 HMiner.py <inputFile> <outputFile> <minUtil>
-            python3 HMiner.py <inputFile> <outputFile> <minUtil> <separator>
+        -------
+            >>> python3 HMiner.py <inputFile> <outputFile> <minUtil>
+
         Examples:
-            python3 HMiner.py sampleTDB.txt output.txt 35 (separator will be "\t")
-            python3 HMiner.py sampleTDB.txt output.txt 35 ,  (separator will be "," in input file)
+        -------
+
+            >>> python3 HMiner.py sampleTDB.txt output.txt 35 (separator will be "\t")
+
     Sample run of importing the code:
-    -------------------------------
+    --------------------------------------
+    .. code-block:: python
 
         from PAMI.highUtilityPatterns.basic import HMiner as alg
         
         obj = alg.HMiner("input.txt",35)
         
         obj.startMine()
```

### Comparing `pami-2023.4.1/PAMI/highUtilityPatterns/basic/UPGrowth.py` & `pami-2023.5.1/PAMI/highUtilityPatterns/basic/UPGrowth.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,22 +1,54 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.highUtilityPatterns.basic import UPGrowth as alg
+#
+#     obj=alg.UPGrowth("input.txt",35)
+#
+#     obj.startMine()
+#
+#     highUtilityPatterns = obj.getPatterns()
+#
+#     print("Total number of Spatial Frequent Patterns:", len(highUtilityPatterns))
+#
+#     obj.save("output")
+#
+#     memUSS = obj.getMemoryUSS()
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     print("Total Memory in USS:", memUSS)
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
 
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 from PAMI.highUtilityPatterns.basic import abstract as _ab
 
 
 class _UPItem:
     """
     A class to represent the UPItem
@@ -277,15 +309,17 @@
         """
         self.headerList = list(self.mapItemNodes.keys())
         self.headerList = sorted(self.headerList, key=lambda x: mapItemToTwu[x], reverse=True)
 
 
 class UPGrowth(_ab._utilityPatterns):
     """
-    UP-Growth is two-phase algorithm to mine High Utility Itemsets from transactional databases.
+    Description:
+    ------------
+        UP-Growth is two-phase algorithm to mine High Utility Itemsets from transactional databases.
 
     Reference:
     ---------
         Vincent S. Tseng, Cheng-Wei Wu, Bai-En Shie, and Philip S. Yu. 2010. UP-Growth: an efficient algorithm for high utility itemset mining.
         In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD '10).
         Association for Computing Machinery, New York, NY, USA, 253262. DOI:https://doi.org/10.1145/1835804.1835839
 
@@ -333,21 +367,26 @@
         getMemoryUSS()
                 Total amount of USS memory consumed by the mining process will be retrieved from this function
         getMemoryRSS()
                 Total amount of RSS memory consumed by the mining process will be retrieved from this function
         getRuntime()
                Total amount of runtime taken by the mining process will be retrieved from this function
     Executing the code on terminal :
-    -------
-        Format: python3 UPGrowth <inputFile> <outputFile> <Neighbours> <minUtil> <sep>
-        Examples: python3 UPGrowth sampleTDB.txt output.txt sampleN.txt 35  (it will consider "\t" as separator)
-                  python3 UPGrowth sampleTDB.txt output.txt sampleN.txt 35 , (it will consider "," as separator)
-    Sample run of importing the code:
-    -------------------------------
+    -------------------------------------
+        Format:
+        ------------
+          >>> python3 UPGrowth <inputFile> <outputFile> <Neighbours> <minUtil> <sep>
+        Examples:
+        ------------
+          >>> python3 UPGrowth sampleTDB.txt output.txt sampleN.txt 35  (it will consider "\t" as separator)
 
+    Sample run of importing the code:
+    -------------------------------------
+    .. code-block:: python
+    
         from PAMI.highUtilityPatterns.basic import UPGrowth as alg
 
         obj=alg.UPGrowth("input.txt",35)
 
         obj.startMine()
 
         highUtilityPatterns = obj.getPatterns()
```

### Comparing `pami-2023.4.1/PAMI/highUtilityPatterns/basic/abstract.py` & `pami-2023.5.1/PAMI/highUtilityPatterns/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/highUtilitySpatialPattern/__init__.py` & `pami-2023.5.1/PAMI/highUtilitySpatialPattern/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/highUtilitySpatialPattern/abstract.py` & `pami-2023.5.1/PAMI/highUtilitySpatialPattern/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/highUtilitySpatialPattern/basic/HDSHUIM.py` & `pami-2023.5.1/PAMI/highUtilitySpatialPattern/basic/HDSHUIM.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,7 +1,55 @@
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.highUtilityFrequentSpatialPattern.basic import HDSHUIM as alg
+#
+#     obj=alg.HDSHUIM("input.txt","Neighbours.txt",35)
+#
+#     obj.startMine()
+#
+#     Patterns = obj.getPatterns()
+#
+#     print("Total number of Spatial High-Utility Patterns:", len(Patterns))
+#
+#     obj.save("output")
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 from PAMI.highUtilitySpatialPattern.basic import abstract as _ab
 
 
 class _Element:
     """
     A class represents an Element of a utility list as used by the HDSHUIM algorithm.
 
@@ -83,20 +131,27 @@
     def __init__(self):
         self.item = 0
         self.utility = 0
 
 
 class HDSHUIM(_ab._utilityPatterns):
     """
+    Description:
+    ------------
         Spatial High Utility ItemSet Mining (SHUIM) [3] is an important model in data
         mining with many real-world applications. It involves finding all spatially interesting itemSets having high value 
         in a quantitative spatio temporal database.
+    Reference:
+    ----------
+        P. Pallikila et al., "Discovering Top-k Spatial High Utility Itemsets in Very Large Quantitative Spatiotemporal 
+        databases," 2021 IEEE International Conference on Big Data (Big Data), Orlando, FL, USA, 2021, pp. 4925-4935,
+        doi: 10.1109/BigData52589.2021.9671912.
 
     Attributes :
-    ----------
+    --------------
         iFile : str
             Name of the input file to mine complete set of frequent patterns
         oFile : str
             Name of the output file to store complete set of frequent patterns
         nFile: str
            Name of Neighbourhood items file
         memoryRSS : float
@@ -114,15 +169,15 @@
         huiCnt: int
             huis created
         neighbors: map
             keep track of neighbours of elements
         mapOfPMU: map
             a map to keep track of Probable Maximum utility(PMU) of each item
     Methods :
-    -------
+    ----------
             startMine()
                 Mining process will start from here
             getPatterns()
                 Complete set of patterns will be retrieved with this function
             save(oFile)
                 Complete set of frequent patterns will be loaded in to a output file
             constructCUL(x, compactUList, st, minUtil, length, exNeighbours)
@@ -142,26 +197,29 @@
             saveItemSet(prefix, prefixLen, item, utility)
                A method to save itemSets
             updateElement(z, compactUList, st, exCul, newT, ex, duPrevPos, eyTs)
                A method to updates vales for duplicates
 
 
     Executing the code on terminal :
-    -------
+    --------------------------------
         Format:
-            python3 HDSHUIM.py <inputFile> <outputFile> <Neighbours> <minUtil>
+        -------
+            >>> python3 HDSHUIM.py <inputFile> <outputFile> <Neighbours> <minUtil>
 
-            python3 HDSHUIM.py <inputFile> <outputFile> <Neighbours> <minUtil> <separator>
+            >>> python3 HDSHUIM.py <inputFile> <outputFile> <Neighbours> <minUtil> <separator>
         Examples:
-            python3 HDSHUIM.py sampleTDB.txt output.txt sampleN.txt 35 (separator will be "\t" in both input and neighbourhood file)
+        ---------
+            >>> python3 HDSHUIM.py sampleTDB.txt output.txt sampleN.txt 35 (separator will be "\t" in both input and neighbourhood file)
 
-            python3 HDSHUIM.py sampleTDB.txt output.txt sampleN.txt 35 , (separator will be "," in both input and neighbourhood file)
+            >>> python3 HDSHUIM.py sampleTDB.txt output.txt sampleN.txt 35 , (separator will be "," in both input and neighbourhood file)
 
     Sample run of importing the code:
-    -------------------------------
+    -----------------------------------
+    .. code-block:: python
         
         from PAMI.highUtilityFrequentSpatialPattern.basic import HDSHUIM as alg
 
         obj=alg.HDSHUIM("input.txt","Neighbours.txt",35)
 
         obj.startMine()
 
@@ -180,15 +238,15 @@
         print("Total Memory in RSS", memRSS)
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
 
     Credits:
-    -------
+    ----------
         The complete program was written by B.Sai Chitra under the supervision of Professor Rage Uday Kiran.
             
     """
 
     _startTime = float()
     _endTime = float()
     _minSup = str()
```

### Comparing `pami-2023.4.1/PAMI/highUtilitySpatialPattern/basic/SHUIM.py` & `pami-2023.5.1/PAMI/highUtilitySpatialPattern/basic/SHUIM.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,7 +1,53 @@
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#     from PAMI.highUtilitySpatialPattern.basic import SHUIM as alg
+#
+#     obj=alg.SHUIM("input.txt","Neighbours.txt",35)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Spatial high utility Patterns:", len(frequentPatterns))
+#
+#     obj.save("output")
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 from PAMI.highUtilitySpatialPattern.basic import abstract as _ab
 from functools import cmp_to_key as _cmpToKey
 
 
 class _Transaction:
     """
         A class to store Transaction of a database
@@ -203,19 +249,23 @@
             A method to return transactions from database
         """
         return self.transactions
 
 
 class SHUIM(_ab._utilityPatterns):
     """
-      Spatial High Utility itemSet Mining (SHUIM) aims to discover all itemSets in a spatioTemporal database
+    Description:
+    -------------
+       Spatial High Utility itemSet Mining (SHUIM) aims to discover all itemSets in a spatioTemporal database
        that satisfy the user-specified minimum utility and maximum distance constraints
     Reference:
-    ---------
-        https://doi.org/10.1007/978-3-030-37188-3_17
+    ----------
+        Rage, Uday & Veena, Pamalla & Penugonda, Ravikumar & Raj, Bathala & Dao, Minh & Zettsu, Koji & Bommisetti, Sai. 
+        (2023). HDSHUI-miner: a novel algorithm for discovering spatial high-utility itemsets in high-dimensional 
+        spatiotemporal databases. Applied Intelligence. 53. 1-26. 10.1007/s10489-022-04436-w.
 
     Attributes:
     -----------
         iFile : file
             Name of the input file to mine complete set of frequent patterns
         nFile : file
             Name of the Neighbours file that contain neighbours of items
@@ -248,15 +298,15 @@
             Number of SHUI's
         itemsToKeep: list
             keep only the promising items ie items having twu >= minUtil
         itemsToExplore: list
             keep items that subtreeUtility grater than minUtil
 
     Methods :
-    -------
+    ----------
         startMine()
                 Mining process will start from here
         getPatterns()
                 Complete set of patterns will be retrieved with this function
         save(oFile)
                 Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -285,22 +335,27 @@
               A Method to sort transaction in the order of PMU
         sort_transaction(self, trans1, trans2)
               A Method to sort transaction in the order of PMU
         useUtilityBinArrayToCalculateLocalUtilityFirstTime(self, dataset)
              A method to scan the database using utility bin array to calculate the pmus                   
 
     Executing the code on terminal :
-    -------
-        Format: python3 SHUIM.py <inputFile> <outputFile> <Neighbours> <minUtil> <sep>
-        Examples: python3 SHUIM.py sampleTDB.txt output.txt sampleN.txt 35  (it will consider "\t" as separator)
-                  python3 SHUIM.py sampleTDB.txt output.txt sampleN.txt 35 , (it will consider "," as separator)
+    ---------------------------------
+        Format:
+        --------
+             >>> python3 SHUIM.py <inputFile> <outputFile> <Neighbours> <minUtil> <sep>
+        Examples:
+        ---------
+             >>> python3 SHUIM.py sampleTDB.txt output.txt sampleN.txt 35  (it will consider "\t" as separator)
+             >>> python3 SHUIM.py sampleTDB.txt output.txt sampleN.txt 35 , (it will consider "," as separator)
 
     Sample run of importing the code:
-    -------------------------------
-        
+    ----------------------------------
+    .. code-block:: python
+         
         from PAMI.highUtilitySpatialPattern.basic import SHUIM as alg
 
         obj=alg.SHUIM("input.txt","Neighbours.txt",35)
 
         obj.startMine()
 
         frequentPatterns = obj.getPatterns()
@@ -319,15 +374,15 @@
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
 
     Credits:
     -------
-            The complete program was written by Pradeep Pallikila under the supervision of Professor Rage Uday Kiran.
+         The complete program was written by Pradeep Pallikila under the supervision of Professor Rage Uday Kiran.
     """
     _highUtilityItemSets = []
     _candidateCount = 0
     _utilityBinArrayLU = {}
     _utilityBinArraySU = {}
     _oldNamesToNewNames = {}
     _newNamesToOldNames = {}
```

### Comparing `pami-2023.4.1/PAMI/highUtilitySpatialPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/highUtilitySpatialPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/highUtilitySpatialPattern/topk/TKSHUIM.py` & `pami-2023.5.1/PAMI/highUtilitySpatialPattern/topk/TKSHUIM.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,54 @@
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#    from PAMI.highUtilitySpatialPattern.topk import TKSHUIM as alg
+#
+#     obj=alg.TKSHUIM("input.txt","Neighbours.txt",35)
+#
+#     obj.startMine()
+#
+#     Patterns = obj.getPatterns()
+#
+#     obj.save("output")
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+#
+#
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 from PAMI.highUtilitySpatialPattern.topk.abstract import *
 from functools import cmp_to_key
 import heapq
 
 class Transaction:
     """
         A class to store Transaction of a database
@@ -202,19 +249,23 @@
             A method to return transactions from database
         """
         return self.transactions
 
 
 class TKSHUIM(utilityPatterns):
     """
-      Top K Spatial High Utility ItemSet Mining (TKSHUIM) aims to discover Top-K Spatial High Utility Itemsets
-      (TKSHUIs) in a spatioTemporal database
+    Description:
+    ------------
+       Top K Spatial High Utility ItemSet Mining (TKSHUIM) aims to discover Top-K Spatial High Utility Itemsets
+       (TKSHUIs) in a spatioTemporal database
     Reference:
     ---------
-
+       P. Pallikila et al., "Discovering Top-k Spatial High Utility Itemsets in Very Large Quantitative Spatiotemporal 
+       databases," 2021 IEEE International Conference on Big Data (Big Data), Orlando, FL, USA, 2021, pp. 4925-4935, 
+       doi: 10.1109/BigData52589.2021.9671912.
 
     Attributes:
     -----------
         iFile : file
             Name of the input file to mine complete set of frequent patterns
         nFile : file
             Name of the Neighbours file that contain neighbours of items
@@ -244,15 +295,15 @@
             Maximum memory used by this program for running
         itemsToKeep: list
             keep only the promising items ie items having twu >= minUtil
         itemsToExplore: list
             keep items that subtreeUtility grater than minUtil
 
     Methods :
-    -------
+    ------------
         startMine()
                 Mining process will start from here
         getPatterns()
                 Complete set of patterns will be retrieved with this function
         save(oFile)
                 Complete set of patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -288,14 +339,15 @@
     -------
         Format: python3 TKSHUIM.py <inputFile> <outputFile> <Neighbours> <k> <sep>
         Examples: python3 TKSHUIM.py sampleTDB.txt output.txt sampleN.txt 35  (it will consider "\t" as separator)
                   python3 TKSHUIM.py sampleTDB.txt output.txt sampleN.txt 35 , (it will consider "," as separator)
 
     Sample run of importing the code:
     -------------------------------
+    .. code-block:: python
         
         from PAMI.highUtilitySpatialPattern.topk import TKSHUIM as alg
 
         obj=alg.TKSHUIM("input.txt","Neighbours.txt",35)
 
         obj.startMine()
 
@@ -312,15 +364,15 @@
         print("Total Memory in RSS", memRSS)
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
 
     Credits:
-    -------
+    ----------
             The complete program was written by Pradeep Pallikila under the supervision of Professor Rage Uday Kiran.
     """
     candidateCount = 0
     utilityBinArrayLU = {}
     utilityBinArraySU = {}
     oldNamesToNewNames = {}
     newNamesToOldNames = {}
```

### Comparing `pami-2023.4.1/PAMI/highUtilitySpatialPattern/topk/abstract.py` & `pami-2023.5.1/PAMI/highUtilitySpatialPattern/topk/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/localPeriodicPattern/basic/LPPGrowth.py` & `pami-2023.5.1/PAMI/localPeriodicPattern/basic/LPPGrowth.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,58 @@
 
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#     from PAMI.localPeriodicPattern.basic import LPPGrowth as alg
+#
+#     obj = alg.LPPGrowth(iFile, maxPer, maxSoPer, minDur)
+#
+#     obj.startMine()
+#
+#     localPeriodicPatterns = obj.getPatterns()
+#
+#     print(f'Total number of local periodic patterns: {len(localPeriodicPatterns)}')
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print(f'Total memory in USS: {memUSS}')
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print(f'Total memory in RSS: {memRSS}')
+#
+#     runtime = obj.getRuntime()
+#
+#     print(f'Total execution time in seconds: {runtime})
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+
 from PAMI.localPeriodicPattern.basic import abstract as _ab
 
 
 class Node:
     """
     A class used to represent the node of localPeriodicPatternTree
     ...
@@ -154,17 +204,30 @@
             else:
                 currentNode = child
             currentNode.tidList |= tidList
 
 
 class LPPGrowth(_ab._localPeriodicPatterns):
     """
+    Description:
+    ------------
+        Local Periodic Patterns, which are patterns (sets of events) that have a periodic behavior in some non predefined
+        time-intervals. A pattern is said to be a local periodic pattern if it appears regularly and continuously in some
+        time-intervals. The maxSoPer (maximal period of spillovers) measure allows detecting time-intervals of variable
+        lengths where a pattern is continuously periodic, while the minDur (minimal duration) measure ensures that those
+        time-intervals have a minimum duration.
 
-        Attributes:
-        -----------
+    Reference:
+    ----------
+        Fournier-Viger, P., Yang, P., Kiran, R. U., Ventura, S., Luna, J. M.. (2020). Mining Local Periodic Patterns in
+        a Discrete Sequence. Information Sciences, Elsevier, to appear. [ppt] DOI: 10.1016/j.ins.2020.09.044
+
+
+    Attributes:
+    -----------
             iFile : str
                 Input file name or path of the input file
             oFile : str
                 Output file name or path of the output file
             maxPer : float
                 User defined maxPer value.
             maxSoPer : float
@@ -189,16 +252,16 @@
                 Storing the item and its PTL.
             items : list
                 Storing local periodic item list.
             sep: str
                 separator used to distinguish items from each other. The default separator is tab space.
 
 
-        Methods:
-        -------
+    Methods:
+    -------
             findSeparator(line)
                 Find the separator of the line which split strings.
             creteLPPlist()
                 Create the local periodic patterns list from input data.
             createTSList()
                 Create the tsList as bit vector from input data.
             generateLPP()
@@ -222,56 +285,59 @@
             getLocalPeriodicPatterns()
                 return local periodic patterns and its PTL
             save(oFile)
                 Complete set of local periodic patterns will be loaded in to a output file.
             getPatternsAsDataFrame()
                 Complete set of local periodic patterns will be loaded in to a dataframe.
 
-        Executing the code on terminal:
-        ------------------------------
-            Format:
-                python3 LPPMGrowth.py <inputFile> <outputFile> <maxPer> <minSoPer> <minDur>
-            Examples:
-                python3 LPPMGrowth.py sampleDB.txt patterns.txt 0.3 0.4 0.5
+    Executing the code on terminal:
+    ------------------------------
+        Format:
+        -------
+            >>> python3 LPPMGrowth.py <inputFile> <outputFile> <maxPer> <minSoPer> <minDur>
+        Examples:
+        ---------
+            >>> python3 LPPMGrowth.py sampleDB.txt patterns.txt 0.3 0.4 0.5
 
-                python3 LPPMGrowth.py sampleDB.txt patterns.txt 3 4 5
+            >>> python3 LPPMGrowth.py sampleDB.txt patterns.txt 3 4 5
 
-        Sample run of importing the code:
-        --------------------------------
+    Sample run of importing the code:
+    ----------------------------------
+    .. code-block:: python
 
-            from PAMI.localPeriodicPattern.basic import LPPGrowth as alg
+        from PAMI.localPeriodicPattern.basic import LPPGrowth as alg
 
-            obj = alg.LPPGrowth(iFile, maxPer, maxSoPer, minDur)
+        obj = alg.LPPGrowth(iFile, maxPer, maxSoPer, minDur)
 
-            obj.startMine()
+        obj.startMine()
 
-            localPeriodicPatterns = obj.getPatterns()
+        localPeriodicPatterns = obj.getPatterns()
 
-            print(f'Total number of local periodic patterns: {len(localPeriodicPatterns)}')
+        print(f'Total number of local periodic patterns: {len(localPeriodicPatterns)}')
 
-            obj.save(oFile)
+        obj.save(oFile)
 
-            Df = obj.getPatternsAsDataFrame()
+        Df = obj.getPatternsAsDataFrame()
 
-            memUSS = obj.getMemoryUSS()
+        memUSS = obj.getMemoryUSS()
 
-            print(f'Total memory in USS: {memUSS}')
+        print(f'Total memory in USS: {memUSS}')
 
-            memRSS = obj.getMemoryRSS()
+        memRSS = obj.getMemoryRSS()
 
-            print(f'Total memory in RSS: {memRSS}')
+        print(f'Total memory in RSS: {memRSS}')
 
-            runtime = obj.getRuntime()
+        runtime = obj.getRuntime()
 
-            print(f'Total execution time in seconds: {runtime})
+        print(f'Total execution time in seconds: {runtime})
 
-        Credits:
-        -------
-            The complete program was written by So Nakamura under the supervision of Professor Rage Uday Kiran.
-        """
+    Credits:
+    -------
+        The complete program was written by So Nakamura under the supervision of Professor Rage Uday Kiran.
+    """
     _localPeriodicPatterns__iFile = ' '
     _localPeriodicPatterns__oFile = ' '
     _localPeriodicPatterns__maxPer = str()
     _localPeriodicPatterns__maxSoPer = str()
     _localPeriodicPatterns__minDur = str()
     __tsMin = 0
     __tsMax = 0
```

### Comparing `pami-2023.4.1/PAMI/localPeriodicPattern/basic/LPPMBreadth.py` & `pami-2023.5.1/PAMI/localPeriodicPattern/basic/LPPMBreadth.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,14 +1,78 @@
 
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.localPeriodicPattern.basic import LPPMBreadth as alg
+#
+#     obj = alg.LPPMBreadth(iFile, maxPer, maxSoPer, minDur)
+#
+#     obj.startMine()
+#
+#     localPeriodicPatterns = obj.getPatterns()
+#
+#     print(f'Total number of local periodic patterns: {len(localPeriodicPatterns)}')
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print(f'Total memory in USS: {memUSS}')
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print(f'Total memory in RSS: {memRSS}')
+#
+#     runtime = obj.getRuntime()
+#
+#     print(f'Total execution time in seconds: {runtime})
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 from PAMI.localPeriodicPattern.basic import abstract as _ab
 
 
 class LPPMBreadth(_ab._localPeriodicPatterns):
 
     """
+    Description:
+    ------------
+        Local Periodic Patterns, which are patterns (sets of events) that have a periodic behavior in some non predefined
+        time-intervals. A pattern is said to be a local periodic pattern if it appears regularly and continuously in some 
+        time-intervals. The maxSoPer (maximal period of spillovers) measure allows detecting time-intervals of variable 
+        lengths where a pattern is continuously periodic, while the minDur (minimal duration) measure ensures that those 
+        time-intervals have a minimum duration.
+
+    Reference:
+    ----------
+        Fournier-Viger, P., Yang, P., Kiran, R. U., Ventura, S., Luna, J. M.. (2020). Mining Local Periodic Patterns in
+        a Discrete Sequence. Information Sciences, Elsevier, to appear. [ppt] DOI: 10.1016/j.ins.2020.09.044
+
 
     Attributes:
     -----------
         iFile : str
             Input file name or path of the input file
         oFile : str
             Output file name or path of the output file
@@ -63,14 +127,16 @@
         Format:
             python3 LPPBreadth.py <inputFile> <outputFile> <maxPer> <minSoPer> <minDur>
         Examples:
             python3 LPPMBreadth.py sampleDB.txt patterns.txt 0.3 0.4 0.5
 
     Sample run of importing the code:
     --------------------------------
+    .. code-block:: python
+    
         from PAMI.localPeriodicPattern.basic import LPPMBreadth as alg
 
         obj = alg.LPPMBreadth(iFile, maxPer, maxSoPer, minDur)
 
         obj.startMine()
 
         localPeriodicPatterns = obj.getPatterns()
```

### Comparing `pami-2023.4.1/PAMI/localPeriodicPattern/basic/LPPMDepth.py` & `pami-2023.5.1/PAMI/localPeriodicPattern/basic/LPPMDepth.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,14 +1,77 @@
 
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.localPeriodicPattern.basic import LPPMDepth as alg
+#
+#     obj = alg.LPPMDepth(iFile, maxPer, maxSoPer, minDur)
+#
+#     obj.startMine()
+#
+#     localPeriodicPatterns = obj.getPatterns()
+#
+#     print(f'Total number of local periodic patterns: {len(localPeriodicPatterns)}')
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print(f'Total memory in USS: {memUSS}')
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print(f'Total memory in RSS: {memRSS}')
+#
+#     runtime = obj.getRuntime()
+#
+#     print(f'Total execution time in seconds: {runtime})
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 from PAMI.localPeriodicPattern.basic import abstract as _ab
 
 
 class LPPMDepth(_ab._localPeriodicPatterns):
 
     """
+    Description:
+    ------------
+        Local Periodic Patterns, which are patterns (sets of events) that have a periodic behavior in some non predefined
+        time-intervals. A pattern is said to be a local periodic pattern if it appears regularly and continuously in some
+        time-intervals. The maxSoPer (maximal period of spillovers) measure allows detecting time-intervals of variable
+        lengths where a pattern is continuously periodic, while the minDur (minimal duration) measure ensures that those
+        time-intervals have a minimum duration.
+
+    Reference:
+    ------------
+        Fournier-Viger, P., Yang, P., Kiran, R. U., Ventura, S., Luna, J. M.. (2020). Mining Local Periodic Patterns in
+        a Discrete Sequence. Information Sciences, Elsevier, to appear. [ppt] DOI: 10.1016/j.ins.2020.09.044
+
     Attributes:
     -----------
         iFile : str
             Input file name or path of the input file
         oFile : str
             Output file name or path of the output file
         maxPer : float
@@ -29,15 +92,15 @@
             To store local periodic patterns and its PTL.
         tsList : dict
             To store items and its time stamp as bit vector.
         sep : str
             separator used to distinguish items from each other. The default separator is tab space.
 
     Methods:
-    -------
+    ---------
         createTSlist()
             Create the TSlist as bit vector from input data.
         generateLPP()
             Generate 1 length local periodic pattens by TSlist and execute depth first search.
         calculatePTL(tsList)
             Calculate PTL from input tsList as bit vector
         LPPMDepthSearch(extensionOfP)
@@ -56,22 +119,26 @@
             Complete set of local periodic patterns will be loaded in to a output file.
         getPatternsAsDataFrame()
             Complete set of local periodic patterns will be loaded in to a dataframe.
 
     Executing the code on terminal:
     ------------------------------
         Format:
-            python3 LPPMDepth.py <inputFile> <outputFile> <maxPer> <minSoPer> <minDur> <sep>
+        -------
+           >>> python3 LPPMDepth.py <inputFile> <outputFile> <maxPer> <minSoPer> <minDur> <sep>
         Examples:
-            python3 LPPMDepth.py sampleDB.txt patterns.txt 0.3 0.4 0.5
+        ---------
+           >>> python3 LPPMDepth.py sampleDB.txt patterns.txt 0.3 0.4 0.5
 
-            python3 LPPMDepth.py sampleDB.txt patterns.txt 3 4 5
+           >>> python3 LPPMDepth.py sampleDB.txt patterns.txt 3 4 5
 
     Sample run of importing the code:
     --------------------------------
+    .. code-block:: python
+
         from PAMI.localPeriodicPattern.basic import LPPMDepth as alg
 
         obj = alg.LPPMDepth(iFile, maxPer, maxSoPer, minDur)
 
         obj.startMine()
 
         localPeriodicPatterns = obj.getPatterns()
@@ -91,15 +158,15 @@
         print(f'Total memory in RSS: {memRSS}')
 
         runtime = obj.getRuntime()
 
         print(f'Total execution time in seconds: {runtime})
 
     Credits:
-    -------
+    --------
         The complete program was written by So Nakamura under the supervision of Professor Rage Uday Kiran.
     """
     
     _localPeriodicPatterns__iFile = ''
     _localPeriodicPatterns__oFile = ''
     _localPeriodicPatterns__maxPer = str()
     _localPeriodicPatterns__maxSoPer = str()
```

### Comparing `pami-2023.4.1/PAMI/localPeriodicPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/localPeriodicPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/CFPGrowth.py` & `pami-2023.5.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/CFPGrowthPlus.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,26 +1,63 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#     from PAMI.multipleMinimumSupportBasedFrequentPattern.basic import CFPGrowthPlus as alg
+#
+#     obj = alg.CFPGrowthPlus(iFile, mIS)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     memUSS = obj.getMemoryUSS()
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 from PAMI.multipleMinimumSupportBasedFrequentPattern.basic import abstract as _fp
 
 _fp._sys.setrecursionlimit(20000)
-_MIS = {}
+MIS = {}
 
 class _Node:
     """
         A class used to represent the node of frequentPatternTree
 
     Attributes:
     ----------
@@ -189,45 +226,48 @@
         prefix: an empty list
 
         Returns
         -------
         Frequent patterns that are extracted from fp-tree
 
         """
-        global _MIS
+        global MIS
         for i in sorted(self.summaries, key=lambda x: (self.info.get(x), -x)):
             pattern = prefix[:]
             pattern.append(i)
             sup = []
             for j in pattern:
-                sup.append(_MIS[j])
+                sup.append(MIS[j])
             if self.info[i] >= min(sup):
                 yield pattern, self.info[i]
             patterns, freq, info = self.getFinalConditionalPatterns(i)
             conditionalTree = _Tree()
             conditionalTree.info = info.copy()
             for pat in range(len(patterns)):
                 conditionalTree.addTransaction(patterns[pat], freq[pat])
             if len(patterns) > 0:
                 for q in conditionalTree.generatePatterns(pattern):
                     yield q
 
 
-class CFPGrowth(_fp._frequentPatterns):
+class CFPGrowthPlus(_fp._frequentPatterns):
     """
-       CFPGrowth is one of the fundamental algorithm to discover frequent patterns based on multiple minimum support in a transactional database.
 
-    Reference :
-    ---------
-        Ya-Han Hu and Yen-Liang Chen. 2006. Mining association rules with multiple minimum supports: a new mining algorithm and a support tuning mechanism.
-        Decis. Support Syst. 42, 1 (October 2006), 124. https://doi.org/10.1016/j.dss.2004.09.007
+    Description:
+    ------------
+       CFPGrowthPlus is one of the fundamental algorithm to discover frequent patterns based on multiple minimum support in a transactional database.
+
+    Reference:
+    ---------------
+        R. Uday Kiran P. Krishna Reddy Novel techniques to reduce search space in multiple minimum supports-based frequent
+        pattern mining algorithms. 11-20 2011 EDBT https://doi.org/10.1145/1951365.1951370
 
 
-    Attributes :
-    ----------
+    Attributes:
+    -------------
         iFile : file
             Input file name or path of the input file
         MIS: file or dictionary
             Multiple minimum supports of all items in the database
         sep : str
             This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
             However, the users can override their default separator.
@@ -249,15 +289,15 @@
             it represents the total no of transactions
         tree : class
             it represents the Tree class
         finalPatterns : dict
             it represents to store the patterns
 
     Methods :
-    -------
+    ----------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -270,35 +310,35 @@
             Total amount of runtime taken by the mining process will be retrieved from this function
         creatingItemSets()
             Scans the dataset or dataframes and stores in list format
         frequentOneItem()
             Extracts the one-frequent patterns from transactions
 
     Executing the code on terminal:
-    -------
+    -------------------------------
         Format:
         -------
-            python3 CFPGrowth.py <inputFile> <outputFile>
+            >>> python3 CFPGrowthPlus.py <inputFile> <outputFile> <minSup>
 
         Examples:
         ---------
-            python3 CFPGrowth.py sampleDB.txt patterns.txt MISFile.txt
+            >>> python3 CFPGrowthPlus.py sampleDB.txt patterns.txt MIS
 
-            python3 CFPGrowth.py sampleDB.txt patterns.txt MISFile.txt
+            >>> python3 CFPGrowthPlus.py sampleDB.txt patterns.txt MIS
 
-            python3 CFPGrowth.py sampleTDB.txt output.txt sampleN.txt MIS ',' (it will consider "," as a separator)
+            >>> python3 CFPGrowthPlus.py sampleTDB.txt output.txt sampleN.txt MIS ',' (it will consider "," as a separator)
 
 
     Sample run of the importing code:
-    -----------
+    --------------------------------------
+    .. code-block:: python
 
+        from PAMI.multipleMinimumSupportBasedFrequentPattern.basic import CFPGrowthPlus as alg
 
-        from PAMI.multipleMinimumSupportBasedFrequentPattern.basic import CFPGrowth as alg
-
-        obj = alg.CFPGrowth(iFile, mIS)
+        obj = alg.CFPGrowthPlus(iFile, mIS)
 
         obj.startMine()
 
         frequentPatterns = obj.getPatterns()
 
         print("Total number of Frequent Patterns:", len(frequentPatterns))
 
@@ -315,15 +355,15 @@
         print("Total Memory in RSS", memRSS)
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
 
     Credits:
-    -------
+    ---------
         The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
 
         """
 
     __startTime = float()
     __endTime = float()
     _MIS = str
@@ -368,17 +408,16 @@
                     temp = [x for x in temp if x]
                     self.__Database.append(temp)
             else:
                 try:
                     with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
                             line = line.strip()
-                            temp = [i.rstrip() for i in line.split('\t')]
+                            temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
-                            # print(temp)
                             self.__Database.append(temp)
                 except IOError:
                     print("File Not Found")
                     quit()
 
     def _getMISValues(self):
         """
@@ -412,15 +451,14 @@
                 try:
                     with open(self._MIS, 'r', encoding='utf-8') as f:
                         for line in f:
                             line = line.strip()
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
                             self._MISValues[temp[0]] = int(temp[1])
-                    print(len(self._MISValues))
                 except IOError:
                     print("File Not Found")
                     quit()
 
     def __convert(self, value):
         """
         to convert the type of user specified minSup value
@@ -444,24 +482,20 @@
     def __frequentOneItem(self):
         """
         Generating One frequent items sets
 
         """
         self.__mapSupport = {}
         for tr in self.__Database:
-            for i in range(len(tr)):
+            for i in range(1, len(tr)):
                 if tr[i] not in self.__mapSupport:
                     self.__mapSupport[tr[i]] = 1
                 else:
                     self.__mapSupport[tr[i]] += 1
-        # for x, y in self.__mapSupport.items():
-        #     print(x, y)
         self.__mapSupport = {k: v for k, v in self.__mapSupport.items() if v >= min(self._MISValues.values())}
-        # for x, y in self.__mapSupport.items():
-        #     print(x, y)
         genList = [k for k, v in sorted(self.__mapSupport.items(), key=lambda x: x[1], reverse=True)]
         self.__rank = dict([(index, item) for (item, index) in enumerate(genList)])
         return genList
 
     def __updateTransactions(self, itemSet):
         """
         Updates the items in transactions with rank of items according to their support
@@ -525,34 +559,33 @@
         return temp
 
     def startMine(self):
         """
             main program to start the operation
 
         """
-        global _MIS
+        global MIS
         self.__startTime = _fp._time.time()
         if self._iFile is None:
             raise Exception("Please enter the file path or file name:")
         self.__creatingItemSets()
         self._getMISValues()
-        #MIS = self._MISValues
         itemSet = self.__frequentOneItem()
         updatedTransactions = self.__updateTransactions(itemSet)
         for x, y in self.__rank.items():
-            _MIS[y] = self._MISValues[x]
+            MIS[y] = self._MISValues[x]
             self.__rankDup[y] = x
         info = {self.__rank[k]: v for k, v in self.__mapSupport.items()}
         __Tree = self.__buildTree(updatedTransactions, info)
         patterns = __Tree.generatePatterns([])
         self.__finalPatterns = {}
         for k in patterns:
             s = self.__savePeriodic(k[0])
             self.__finalPatterns[str(s)] = k[1]
-        print("Frequent patterns were generated successfully using CFPGrowth algorithm")
+        print("Frequent patterns were generated successfully using frequentPatternGrowth algorithm")
         self.__endTime = _fp._time.time()
         self.__memoryUSS = float()
         self.__memoryRSS = float()
         process = _fp._psutil.Process(_fp._os.getpid())
         self.__memoryUSS = process.memory_full_info().uss
         self.__memoryRSS = process.memory_info().rss
 
@@ -627,29 +660,23 @@
     def printResults(self):
         print("Total number of  Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
+
 if __name__ == "__main__":
     _ap = str()
     if len(_fp._sys.argv) == 4 or len(_fp._sys.argv) == 5:
         if len(_fp._sys.argv) == 5:
-            _ap = CFPGrowth(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4])
+            _ap = CFPGrowthPlus(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4])
         if len(_fp._sys.argv) == 4:
-            _ap = CFPGrowth(_fp._sys.argv[1], _fp._sys.argv[3])
+            _ap = CFPGrowthPlus(_fp._sys.argv[1], _fp._sys.argv[3])
         _ap.startMine()
         print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
         _ap.save(_fp._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
-        _ap = CFPGrowth('/Users/Likhitha/Downloads/Transactional_T10I4D100K-3.csv', '/Users/Likhitha/Downloads/MIS_T10I4D100K_.csv', '\t')
-        _ap.startMine()
-        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
-        _ap.save('/Users/Likhitha/Downloads/CFPGrowth_output.txt')
-        print("Total Memory in USS:", _ap.getMemoryUSS())
-        print("Total Memory in RSS", _ap.getMemoryRSS())
-        print("Total ExecutionTime in ms:", _ap.getRuntime())
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `pami-2023.4.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/CFPGrowthPlus.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/basic/PPPGrowth.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,263 +1,344 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#         from PAMI.periodicFrequentPattern.basic import PPPGrowth as alg
+#
+#         obj = alg.PPPGrowth(iFile, periodicSupport, period)
+#
+#         obj.startMine()
+#
+#         partialPeriodicPatterns = obj.getPatterns()
+#
+#         print("Total number of partial periodic Patterns:", len(partialPeriodicPatterns))
+#
+#         obj.save(oFile)
+#
+#         Df = obj.getPatternInDf()
+#
+#         memUSS = obj.getMemoryUSS()
+#
+#         print("Total Memory in USS:", memUSS)
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
+#         memRSS = obj.getMemoryRSS()
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#         print("Total Memory in RSS", memRSS)
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#         run = obj.getRuntime()
+#
+#         print("Total ExecutionTime in seconds:", run)
+
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
 
-from PAMI.multipleMinimumSupportBasedFrequentPattern.basic import abstract as _fp
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
 
-_fp._sys.setrecursionlimit(20000)
-MIS = {}
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
 
-class _Node:
+"""
+
+
+from PAMI.partialPeriodicPattern.basic import abstract as _abstract
+import validators as _validators
+from urllib.request import urlopen as _urlopen
+import sys as _sys
+
+_periodicSupport = float()
+_period = float()
+_lno = int()
+
+class _Node(object):
     """
         A class used to represent the node of frequentPatternTree
-
-    Attributes:
-    ----------
-        itemId: int
+        ...
+        Attributes
+        ----------
+        item : int
             storing item of a node
-        counter: int
-            To maintain the support of node
-        parent: node
-            To maintain the parent of node
-        children: list
+        timeStamps : list
+            To maintain the timestamps of transaction at the end of the branch
+        parent : node
+            To maintain the parent of every node
+        children : list
             To maintain the children of node
 
-    Methods:
-    -------
-
-        addChild(node)
-            Updates the nodes children list and parent for the given node
-
+        Methods
+        -------
+        addChild(itemName)
+        storing the children to their respective parent nodes
     """
 
     def __init__(self, item, children):
-        self.itemId = item
-        self.counter = 1
-        self.parent = None
+        self.item = item
         self.children = children
+        self.parent = None
+        self.timeStamps = []
 
     def addChild(self, node):
-        """
-            Retrieving the child from the tree
-
-            :param node: Children node
-            :type node: Node
-            :return: Updates the children nodes and parent nodes
-
-        """
-        self.children[node.itemId] = node
+        self.children[node.item] = node
         node.parent = self
 
 
-class _Tree:
+class _Tree(object):
     """
-    A class used to represent the frequentPatternGrowth tree structure
+        A class used to represent the frequentPatternGrowth tree structure
 
-    Attributes:
-    ----------
+        ...
+
+        Attributes
+        ----------
         root : Node
-            The first node of the tree set to Null.
+            Represents the root node of the tree
         summaries : dictionary
-            Stores the nodes itemId which shares same itemId
+            storing the nodes with same item name
         info : dictionary
-            frequency of items in the transactions
+            stores the support of items
 
-    Methods:
-    -------
-        addTransaction(transaction, freq)
-            adding items of  transactions into the tree as nodes and freq is the count of nodes
-        getFinalConditionalPatterns(node)
-            getting the conditional patterns from fp-tree for a node
-        getConditionalPatterns(patterns, frequencies)
-            sort the patterns by removing the items with lower minSup
-        generatePatterns(prefix)
-            generating the patterns from fp-tree
-    """
+
+        Methods
+        -------
+        addTransaction(transaction)
+            creating transaction as a branch in frequentPatternTree
+        getConditionalPatterns(Node)
+            generates the conditional patterns from tree for specific node
+        conditionalTransactions(prefixPaths,Support)
+            takes the prefixPath of a node and support at child of the path and extract the frequent items from
+            prefixPaths and generates prefixPaths with items which are frequent
+        remove(Node)
+            removes the node from tree once after generating all the patterns respective to the node
+        generatePatterns(Node)
+            starts from the root node of the tree and mines the frequent patterns
+
+            """
 
     def __init__(self):
         self.root = _Node(None, {})
         self.summaries = {}
         self.info = {}
 
-    def addTransaction(self, transaction, count):
-        """adding transaction into tree
-
-        :param transaction: it represents the one transactions in database
-
-        :type transaction: list
-
-        :param count: frequency of item
-
-        :type count: int
+    def _addTransaction(self, transaction, tid):
         """
+                adding transaction into tree
 
-        # This method takes transaction as input and returns the tree
+                :param transaction : it represents the one transactions in database
+                :type transaction : list
+                :param tid : represents the timestamp of transaction
+                :type tid : list
+        """
         currentNode = self.root
         for i in range(len(transaction)):
             if transaction[i] not in currentNode.children:
                 newNode = _Node(transaction[i], {})
-                newNode.freq = count
                 currentNode.addChild(newNode)
                 if transaction[i] in self.summaries:
                     self.summaries[transaction[i]].append(newNode)
                 else:
                     self.summaries[transaction[i]] = [newNode]
                 currentNode = newNode
             else:
                 currentNode = currentNode.children[transaction[i]]
-                currentNode.freq += count
+        currentNode.timeStamps = currentNode.timeStamps + tid
 
-    def getFinalConditionalPatterns(self, alpha):
+    def _getConditionalPatterns(self, alpha):
         """
-        generates the conditional patterns for a node
-
-        Parameters:
-        ----------
-            alpha: node to generate conditional patterns
-
-        Returns
-        -------
-            returns conditional patterns, frequency of each item in conditional patterns
+            generates all the conditional patterns of respective node
 
+            :param alpha : it represents the Node in tree
+            :type alpha : Node
         """
         finalPatterns = []
-        finalFreq = []
+        finalSets = []
         for i in self.summaries[alpha]:
-            set1 = i.freq
+            set1 = i.timeStamps
             set2 = []
-            while i.parent.itemId is not None:
-                set2.append(i.parent.itemId)
+            while i.parent.item is not None:
+                set2.append(i.parent.item)
                 i = i.parent
             if len(set2) > 0:
                 set2.reverse()
                 finalPatterns.append(set2)
-                finalFreq.append(set1)
-        finalPatterns, finalFreq, info = self.getConditionalTransactions(finalPatterns, finalFreq)
-        return finalPatterns, finalFreq, info
+                finalSets.append(set1)
+        finalPatterns, finalSets, info = self._conditionalTransactions(finalPatterns, finalSets)
+        return finalPatterns, finalSets, info
+
+    def _generateTimeStamps(self, node):
+        finalTs = node.timeStamps
+        return finalTs
+
+    def _removeNode(self, nodeValue):
+        """
+            removing the node from tree
 
-    @staticmethod
-    def getConditionalTransactions(ConditionalPatterns, conditionalFreq):
+            :param nodeValue : it represents the node in tree
+            :type nodeValue : node
         """
-        To calculate the frequency of items in conditional patterns and sorting the patterns
+        for i in self.summaries[nodeValue]:
+            i.parent.timeStamps = i.parent.timeStamps + i.timeStamps
+            del i.parent.children[nodeValue]
+
+    def _getTimeStamps(self, alpha):
+        """
+        Returns the timeStamps of a node
+
         Parameters
         ----------
-        ConditionalPatterns: paths of a node
-        conditionalFreq: frequency of each item in the path
+        alpha: node of tree
 
         Returns
         -------
-            conditional patterns and frequency of each item in transactions
+        timeStamps of a node
+
+        """
+        temporary = []
+        for i in self.summaries[alpha]:
+            temporary += i.timeStamps
+        return temporary
+
+    def _getPeriodicSupport(self, timeStamps):
+        """
+            calculates the support and periodicity with list of timestamps
+
+            :param timeStamps : timestamps of a pattern
+
+            :type timeStamps : list
+
+
+        """
+        timeStamps.sort()
+        per = 0
+        sup = 0
+        for i in range(len(timeStamps) - 1):
+            j = i + 1
+            if abs(timeStamps[j] - timeStamps[i]) <= _period:
+                per += 1
+            sup += 1
+        return per
+
+    def _conditionalTransactions(self, conditionalPatterns, conditionalTimeStamps):
+        """ It generates the conditional patterns with periodic frequent items
+
+                :param conditionalPatterns : conditional_patterns generated from condition_pattern method for
+                                        respective node
+                :type conditionalPatterns : list
+                :param conditionalTimeStamps : represents the timestamps of conditional patterns of a node
+                :type conditionalTimeStamps : list
         """
-        global _minSup
-        pat = []
-        freq = []
+        global _periodicSupport, _period
+        patterns = []
+        timeStamps = []
         data1 = {}
-        for i in range(len(ConditionalPatterns)):
-            for j in ConditionalPatterns[i]:
+        for i in range(len(conditionalPatterns)):
+            for j in conditionalPatterns[i]:
                 if j in data1:
-                    data1[j] += conditionalFreq[i]
+                    data1[j] = data1[j] + conditionalTimeStamps[i]
                 else:
-                    data1[j] = conditionalFreq[i]
-        #up_dict = {k: v for k, v in data1.items() if v >= _minSup}
-        up_dict = data1.copy()
+                    data1[j] = conditionalTimeStamps[i]
+        updatedDictionary = {}
+        for m in data1:
+            updatedDictionary[m] = self._getPeriodicSupport(data1[m])
+        updatedDictionary = {k: v for k, v in updatedDictionary.items() if v >= _periodicSupport}
         count = 0
-        for p in ConditionalPatterns:
-            p1 = [v for v in p if v in up_dict]
-            trans = sorted(p1, key=lambda x: (up_dict.get(x), -x), reverse=True)
+        for p in conditionalPatterns:
+            p1 = [v for v in p if v in updatedDictionary]
+            trans = sorted(p1, key=lambda x: (updatedDictionary.get(x), -x), reverse=True)
             if len(trans) > 0:
-                pat.append(trans)
-                freq.append(conditionalFreq[count])
+                patterns.append(trans)
+                timeStamps.append(conditionalTimeStamps[count])
             count += 1
-        return pat, freq, up_dict
-
-    def generatePatterns(self, prefix):
-        """
-        To generate the frequent patterns
-        Parameters
-        ----------
-        prefix: an empty list
+        return patterns, timeStamps, updatedDictionary
 
-        Returns
-        -------
-        Frequent patterns that are extracted from fp-tree
+    def _generatePatterns(self, prefix):
+        """generates the patterns
 
-        """
-        global MIS
+                :param prefix : forms the combination of items
+                :type prefix : list
+                        """
         for i in sorted(self.summaries, key=lambda x: (self.info.get(x), -x)):
             pattern = prefix[:]
             pattern.append(i)
-            sup = []
-            for j in pattern:
-                sup.append(MIS[j])
-            if self.info[i] >= min(sup):
-                yield pattern, self.info[i]
-            patterns, freq, info = self.getFinalConditionalPatterns(i)
+            yield pattern, self.info[i]
+            patterns, timeStamps, info = self._getConditionalPatterns(i)
             conditionalTree = _Tree()
             conditionalTree.info = info.copy()
             for pat in range(len(patterns)):
-                conditionalTree.addTransaction(patterns[pat], freq[pat])
+                conditionalTree._addTransaction(patterns[pat], timeStamps[pat])
             if len(patterns) > 0:
-                for q in conditionalTree.generatePatterns(pattern):
+                for q in conditionalTree._generatePatterns(pattern):
                     yield q
+            self._removeNode(i)
 
 
-class CFPGrowthPlus(_fp._frequentPatterns):
+class PPPGrowth(_abstract._partialPeriodicPatterns):
     """
+    Description:
+    ----------------------
+        3pgrowth is fundamental approach to mine the partial periodic patterns in temporal database.
 
+    Reference:
+    -----------
+        Discovering Partial Periodic Itemsets in Temporal Databases,SSDBM '17: Proceedings of the 29th International Conference on Scientific and Statistical Database ManagementJune 2017
+        Article No.: 30 Pages 16https://doi.org/10.1145/3085504.3085535
 
-    Reference :
-    ---------
-        R. Uday Kiran P. Krishna Reddy Novel techniques to reduce search space in multiple minimum supports-based frequent
-        pattern mining algorithms. 11-20 2011 EDBT https://doi.org/10.1145/1951365.1951370
-
-
-    Attributes :
+    Parameters:
     ----------
         iFile : file
-            Input file name or path of the input file
-        MIS: file or dictionary
-            Multiple minimum supports of all items in the database
+            Name of the Input file or path of the input file
+        oFile : file
+            Name of the output file or path of the output file
+        periodicSupport: float or int or str
+            The user can specify periodicSupport either in count or proportion of database size.
+            If the program detects the data type of periodicSupport is integer, then it treats periodicSupport is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: periodicSupport=10 will be treated as integer, while periodicSupport=10.0 will be treated as float
+        period: float or int or str
+            The user can specify period either in count or proportion of database size.
+            If the program detects the data type of period is integer, then it treats period is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: period=10 will be treated as integer, while period=10.0 will be treated as float
         sep : str
-            This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
+            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
             However, the users can override their default separator.
-        oFile : file
-            Name of the output file or the path of the output file
-        startTime:float
-            To record the start time of the mining process
-        endTime:float
-            To record the completion time of the mining process
         memoryUSS : float
             To store the total amount of USS memory consumed by the program
         memoryRSS : float
             To store the total amount of RSS memory consumed by the program
+        startTime:float
+            To record the start time of the mining process
+        endTime:float
+            To record the completion time of the mining process
         Database : list
             To store the transactions of a database in list
         mapSupport : Dictionary
             To maintain the information of item and their frequency
         lno : int
             it represents the total no of transactions
         tree : class
             it represents the Tree class
         finalPatterns : dict
             it represents to store the patterns
 
-    Methods :
+    Methods:
     -------
+
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -266,377 +347,329 @@
             Total amount of USS memory consumed by the mining process will be retrieved from this function
         getMemoryRSS()
             Total amount of RSS memory consumed by the mining process will be retrieved from this function
         getRuntime()
             Total amount of runtime taken by the mining process will be retrieved from this function
         creatingItemSets()
             Scans the dataset or dataframes and stores in list format
-        frequentOneItem()
+        partialPeriodicOneItem()
             Extracts the one-frequent patterns from transactions
+        updateTransactions()
+            updates the transactions by removing the aperiodic items and sort the transactions with items
+            by decreasing support
+        buildTree()
+            constrcuts the main tree by setting the root node as null
+        startMine()
+            main program to mine the partial periodic patterns
 
     Executing the code on terminal:
-    -------
+    -----------------------------------
         Format:
-        -------
-            python3 CFPGrowthPlus.py <inputFile> <outputFile> <minSup>
-
+        --------
+           >>> python3 PPPGrowth.py <inputFile> <outputFile> <periodicSupport> <period>
+    
         Examples:
-        ---------
-            python3 CFPGrowthPlus.py sampleDB.txt patterns.txt MIS
-
-            python3 CFPGrowthPlus.py sampleDB.txt patterns.txt MIS
-
-            python3 CFPGrowthPlus.py sampleTDB.txt output.txt sampleN.txt MIS ',' (it will consider "," as a separator)
+        --------
+           >>> python3 PPPGrowth.py sampleDB.txt patterns.txt 10.0 2.0   (periodicSupport and period will be considered in percentage of database transactions)
 
+           >>> python3 PPPGrowth.py sampleDB.txt patterns.txt 10 2     (periodicSupprot and period will be considered in count)
 
     Sample run of the importing code:
-    -----------
-
+    -----------------------------------------
+    .. code-block:: python
 
-        from PAMI.multipleMinimumSupportBasedFrequentPattern.basic import CFPGrowthPlus as alg
+        from PAMI.periodicFrequentPattern.basic import PPPGrowth as alg
 
-        obj = alg.CFPGrowthPlus(iFile, mIS)
+        obj = alg.PPPGrowth(iFile, periodicSupport, period)
 
         obj.startMine()
 
-        frequentPatterns = obj.getPatterns()
+        partialPeriodicPatterns = obj.getPatterns()
 
-        print("Total number of Frequent Patterns:", len(frequentPatterns))
+        print("Total number of partial periodic Patterns:", len(partialPeriodicPatterns))
 
         obj.save(oFile)
 
-        Df = obj.getPatternInDataFrame()
+        Df = obj.getPatternInDf()
 
         memUSS = obj.getMemoryUSS()
 
         print("Total Memory in USS:", memUSS)
 
         memRSS = obj.getMemoryRSS()
 
         print("Total Memory in RSS", memRSS)
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
 
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
 
-        """
+    Credits:
+    -----------------
+    The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
 
-    __startTime = float()
-    __endTime = float()
-    _MIS = str
-    __finalPatterns = {}
+    """
+    _periodicSupport = float()
+    _period = float()
+    _startTime = float()
+    _endTime = float()
+    _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
-    __memoryUSS = float()
-    __memoryRSS = float()
-    __Database = []
-    __mapSupport = {}
-    __lno = 0
-    __tree = _Tree()
-    __rank = {}
-    __rankDup = {}
-
-    def __init__(self, iFile, MIS, sep='\t'):
-        super().__init__(iFile, MIS, sep)
+    _memoryUSS = float()
+    _memoryRSS = float()
+    _Database = []
+    _rank = {}
+    _rankdup = {}
+    _lno = 0
 
-    def __creatingItemSets(self):
+    def _creatingItemSets(self):
         """
             Storing the complete transactions of the database/input file in a database variable
 
 
-        """
-        self.__Database = []
-        if isinstance(self._iFile, _fp._pd.DataFrame):
+            """
+        self._Database = []
+        if isinstance(self._iFile, _abstract._pd.DataFrame):
+            data, tids = [], []
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
+            if 'TS' in i:
+                tids = self._iFile['TS'].tolist()
             if 'Transactions' in i:
-                self.__Database = self._iFile['Transactions'].tolist()
-
+                data = self._iFile['Transactions'].tolist()
+            for i in range(len(data)):
+                tr = [tids[i][0]]
+                tr = tr + data[i]
+                self._Database.append(tr)
+            self._lno = len(self._Database)
             # print(self.Database)
         if isinstance(self._iFile, str):
-            if _fp._validators.url(self._iFile):
-                data = _fp._urlopen(self._iFile)
+            if _validators.url(self._iFile):
+                data = _urlopen(self._iFile)
                 for line in data:
-                    line = line.strip()
+                    line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
-                    self.__Database.append(temp)
+                    self._Database.append(temp)
             else:
                 try:
                     with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
-                            line = line.strip()
+                            line.strip()
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
-                            self.__Database.append(temp)
+                            self._Database.append(temp)
                 except IOError:
                     print("File Not Found")
                     quit()
 
-    def _getMISValues(self):
+    def _partialPeriodicOneItem(self):
         """
-            Storing the Minimum supports given by the user for each item in the database
+                    calculates the support of each item in the dataset and assign the ranks to the items
+                    by decreasing support and returns the frequent items list
 
+                    """
+        data = {}
+        self._period = self._convert(self._period)
+        self._periodicSupport = self._convert(self._periodicSupport)
+        for tr in self._Database:
+            for i in range(1, len(tr)):
+                if tr[i] not in data:
+                    data[tr[i]] = [0, int(tr[0]), 1]
+                else:
+                    lp = int(tr[0]) - data[tr[i]][1]
+                    if lp <= self._period:
+                        data[tr[i]][0] += 1
+                    data[tr[i]][1] = int(tr[0])
+                    data[tr[i]][2] += 1
+        data = {k: v[0] for k, v in data.items() if v[0] >= self._periodicSupport}
+        pfList = [k for k, v in sorted(data.items(), key=lambda x: x[1], reverse=True)]
+        self._rank = dict([(index, item) for (item, index) in enumerate(pfList)])
+        return data, pfList
+
+    def _updateTransactions(self, dict1):
+        """remove the items which are not frequent from transactions and updates the transactions with rank of items
+
+                    :param dict1 : frequent items with support
+                    :type dict1 : dictionary
+                    """
+        list1 = []
+        for tr in self._Database:
+            list2 = [int(tr[0])]
+            for i in range(1, len(tr)):
+                if tr[i] in dict1:
+                    list2.append(self._rank[tr[i]])
+            if len(list2) >= 2:
+                basket = list2[1:]
+                basket.sort()
+                list2[1:] = basket[0:]
+                list1.append(list2)
+        return list1
 
+    def _buildTree(self, data, info):
+        """it takes the transactions and support of each item and construct the main tree with setting root
+                            node as null
+
+                :param data : it represents the one transactions in database
+                :type data : list
+                :param info : it represents the support of each item
+                :type info : dictionary
         """
-        self._MISValues = {}
-        if isinstance(self._MIS, _fp._pd.DataFrame):
-            items, MIS = [], []
-            if self._MIS.empty:
-                print("its empty..")
-            i = self._MIS.columns.values.tolist()
-            if 'items' in i:
-                items = self._MIS['items'].tolist()
-            if 'MIS' in i:
-                MIS = self._MIS['MIS'].tolist()
-            for i in range(len(items)):
-                self._MISValues[items[i]] = MIS[i]
-
-        if isinstance(self._MIS, str):
-            if _fp._validators.url(self._MIS):
-                data = _fp._urlopen(self._MIS)
-                for line in data:
-                    line = line.strip()
-                    line = line.decode("utf-8")
-                    temp = [i.rstrip() for i in line.split(self._sep)]
-                    temp = [x for x in temp if x]
-                    self._MISValues[temp[0]] = int(temp[1])
-            else:
-                try:
-                    with open(self._MIS, 'r', encoding='utf-8') as f:
-                        for line in f:
-                            line = line.strip()
-                            temp = [i.rstrip() for i in line.split(self._sep)]
-                            temp = [x for x in temp if x]
-                            self._MISValues[temp[0]] = int(temp[1])
-                except IOError:
-                    print("File Not Found")
-                    quit()
+        rootNode = _Tree()
+        rootNode.info = info.copy()
+        for i in range(len(data)):
+            set1 = []
+            set1.append(data[i][0])
+            rootNode._addTransaction(data[i][1:], set1)
+        return rootNode
 
-    def __convert(self, value):
+    def _savePeriodic(self, itemset):
         """
-        to convert the type of user specified minSup value
+        To convert the pattern with its original item name
+        :param itemset: partial periodic pattern
+        :return: pattern with original item name
+        """
+        temp = str()
+        for i in itemset:
+            temp = temp + self._rankdup[i] + "\t"
+        return temp
 
-        :param value: user specified minSup value
+    def _convert(self, value):
+        """
+        To convert the given user specified value
 
-        :return: converted type
+        :param value: user specified value
+        :return: converted value
         """
         if type(value) is int:
             value = int(value)
         if type(value) is float:
-            value = (len(self.__Database) * value)
+            value = (len(self._Database) * value)
         if type(value) is str:
             if '.' in value:
                 value = float(value)
-                value = (len(self.__Database) * value)
+                value = (len(self._Database) * value)
             else:
                 value = int(value)
         return value
 
-    def __frequentOneItem(self):
-        """
-        Generating One frequent items sets
-
-        """
-        self.__mapSupport = {}
-        for tr in self.__Database:
-            for i in range(1, len(tr)):
-                if tr[i] not in self.__mapSupport:
-                    self.__mapSupport[tr[i]] = 1
-                else:
-                    self.__mapSupport[tr[i]] += 1
-        self.__mapSupport = {k: v for k, v in self.__mapSupport.items() if v >= min(self._MISValues.values())}
-        genList = [k for k, v in sorted(self.__mapSupport.items(), key=lambda x: x[1], reverse=True)]
-        self.__rank = dict([(index, item) for (item, index) in enumerate(genList)])
-        return genList
-
-    def __updateTransactions(self, itemSet):
-        """
-        Updates the items in transactions with rank of items according to their support
-
-        :Example: oneLength = {'a':7, 'b': 5, 'c':'4', 'd':3}
-                    rank = {'a':0, 'b':1, 'c':2, 'd':3}
-
-        Parameters
-        ----------
-        itemSet: list of one-frequent items
-
-        -------
-
-        """
-        list1 = []
-        for tr in self.__Database:
-            list2 = []
-            for i in range(len(tr)):
-                if tr[i] in itemSet:
-                    list2.append(self.__rank[tr[i]])
-            if len(list2) >= 1:
-                list2.sort()
-                list1.append(list2)
-        return list1
-
-    @staticmethod
-    def __buildTree(transactions, info):
-        """
-        Builds the tree with updated transactions
-        Parameters:
-        ----------
-            transactions: updated transactions
-            info: support details of each item in transactions
-
-        Returns:
-        -------
-            transactions compressed in fp-tree
-
-        """
-        rootNode = _Tree()
-        rootNode.info = info.copy()
-        for i in range(len(transactions)):
-            rootNode.addTransaction(transactions[i], 1)
-        return rootNode
-
-    def __savePeriodic(self, itemSet):
-        """
-        The duplication items and their ranks
-        Parameters:
-        ----------
-            itemSet: frequent itemSet that generated
-
-        Returns:
-        -------
-            patterns with original item names.
-
-        """
-        temp = str()
-        for i in itemSet:
-            temp = temp + self.__rankDup[i] + "\t"
-        return temp
-
     def startMine(self):
         """
-            main program to start the operation
+                   Main method where the patterns are mined by constructing tree.
 
-        """
-        global MIS
-        self.__startTime = _fp._time.time()
+               """
+        global _periodicSupport, _period, _lno
+        self._startTime = _abstract._time.time()
         if self._iFile is None:
             raise Exception("Please enter the file path or file name:")
-        self.__creatingItemSets()
-        self._getMISValues()
-        itemSet = self.__frequentOneItem()
-        updatedTransactions = self.__updateTransactions(itemSet)
-        for x, y in self.__rank.items():
-            MIS[y] = self._MISValues[x]
-            self.__rankDup[y] = x
-        info = {self.__rank[k]: v for k, v in self.__mapSupport.items()}
-        __Tree = self.__buildTree(updatedTransactions, info)
-        patterns = __Tree.generatePatterns([])
-        self.__finalPatterns = {}
-        for k in patterns:
-            s = self.__savePeriodic(k[0])
-            self.__finalPatterns[str(s)] = k[1]
-        print("Frequent patterns were generated successfully using frequentPatternGrowth algorithm")
-        self.__endTime = _fp._time.time()
-        self.__memoryUSS = float()
-        self.__memoryRSS = float()
-        process = _fp._psutil.Process(_fp._os.getpid())
-        self.__memoryUSS = process.memory_full_info().uss
-        self.__memoryRSS = process.memory_info().rss
+        if self._periodicSupport is None:
+            raise Exception("Please enter the Minimum Support")
+        self._creatingItemSets()
+        generatedItems, pfList = self._partialPeriodicOneItem()
+        _periodicSupport, _period, _lno = self._periodicSupport, self._period, len(self._Database)
+        updatedTransactions = self._updateTransactions(generatedItems)
+        for x, y in self._rank.items():
+            self._rankdup[y] = x
+        info = {self._rank[k]: v for k, v in generatedItems.items()}
+        Tree = self._buildTree(updatedTransactions, info)
+        patterns = Tree._generatePatterns([])
+        self._finalPatterns = {}
+        for i in patterns:
+            s = self._savePeriodic(i[0])
+            self._finalPatterns[s] = i[1]
+        self._endTime = _abstract._time.time()
+        process = _abstract._psutil.Process(_abstract._os.getpid())
+        self._memoryUSS = float()
+        self._memoryRSS = float()
+        self._memoryUSS = process.memory_full_info().uss
+        self._memoryRSS = process.memory_info().rss
+        print("Partial Periodic Patterns were generated successfully using 3PGrowth algorithm ")
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
         :return: returning USS memory consumed by the mining process
-
         :rtype: float
         """
 
-        return self.__memoryUSS
+        return self._memoryUSS
 
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the mining process will be retrieved from this function
 
         :return: returning RSS memory consumed by the mining process
-
         :rtype: float
         """
 
-        return self.__memoryRSS
+        return self._memoryRSS
 
     def getRuntime(self):
         """Calculating the total amount of runtime taken by the mining process
 
 
         :return: returning total amount of runtime taken by the mining process
-
         :rtype: float
         """
 
-        return self.__endTime - self.__startTime
+        return self._endTime - self._startTime
 
     def getPatternsAsDataFrame(self):
         """Storing final frequent patterns in a dataframe
 
         :return: returning frequent patterns in a dataframe
-
         :rtype: pd.DataFrame
         """
 
-        dataframe = {}
+        dataFrame = {}
         data = []
-        for a, b in self.__finalPatterns.items():
+        for a, b in self._finalPatterns.items():
             data.append([a.replace('\t', ' '), b])
-            dataframe = _fp._pd.DataFrame(data, columns=['Patterns', 'Support'])
-        return dataframe
+            dataFrame = _abstract._pd.DataFrame(data, columns=['Patterns', 'periodicSupport'])
+        return dataFrame
 
     def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
-
         :type outFile: file
         """
         self._oFile = outFile
         writer = open(self._oFile, 'w+')
-        for x, y in self.__finalPatterns.items():
+        for x, y in self._finalPatterns.items():
             s1 = x.strip() + ":" + str(y)
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
-
         :rtype: dict
         """
-        return self.__finalPatterns
+        return self._finalPatterns
 
     def printResults(self):
-        print("Total number of  Frequent Patterns:", len(self.getPatterns()))
+        print("Total number of Partial Periodic Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
-
 if __name__ == "__main__":
     _ap = str()
-    if len(_fp._sys.argv) == 4 or len(_fp._sys.argv) == 5:
-        if len(_fp._sys.argv) == 5:
-            _ap = CFPGrowthPlus(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4])
-        if len(_fp._sys.argv) == 4:
-            _ap = CFPGrowthPlus(_fp._sys.argv[1], _fp._sys.argv[3])
+    if len(_sys.argv) == 5 or len(_sys.argv) == 6:
+        if len(_sys.argv) == 6:
+            _ap = PPPGrowth(_sys.argv[1], _sys.argv[3], _sys.argv[4], _sys.argv[5])
+        if len(_sys.argv) == 5:
+            _ap = PPPGrowth(_sys.argv[1], _sys.argv[3], _sys.argv[4])
         _ap.startMine()
-        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
-        _ap.save(_fp._sys.argv[2])
+        print("Total number of Partial Periodic Patterns:", len(_ap.getPatterns()))
+        _ap.save(_sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
-        print("Total ExecutionTime in ms:", _ap.getRuntime())
+        print("Total ExecutionTime in ms:",  _ap.getRuntime())
     else:
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `pami-2023.4.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/multipleMinimumSupportBasedFrequentPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/partialPeriodicFrequentPattern/basic/GPFgrowth.py` & `pami-2023.5.1/PAMI/partialPeriodicFrequentPattern/basic/GPFgrowth.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,59 @@
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#     from PAMI.partialPeriodicFrequentPattern.basic import GPFgrowth as alg
+#
+#     obj = alg.GPFgrowth(inputFile, outputFile, minSup, maxPer, minPR)
+#
+#     obj.startMine()
+#
+#     partialPeriodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of partial periodic Patterns:", len(partialPeriodicFrequentPatterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternInDf()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 import sys
 from PAMI.partialPeriodicFrequentPattern.basic.abstract import *
 
 orderOfItem = {}
 
 class Node:
     """
@@ -440,23 +492,25 @@
                 obj = PFgrowth(prefixTree, prefix, PFList, self.minSup, self.maxPer, self.minPR, self.last)
                 result1 = obj.run()
                 result = {**result, **result1}
         return result
 
 class GPFgrowth(partialPeriodicPatterns):
     """
-    GPFgrowth is algorithm to mine the partial periodic frequent pattern in temporal database.
+    Description:
+    ------------
+        GPFgrowth is algorithm to mine the partial periodic frequent pattern in temporal database.
     
     Reference:
-    ---------
-    R. Uday Kiran, J.N. Venkatesh, Masashi Toyoda, Masaru Kitsuregawa, P. Krishna Reddy, Discovering partial periodic-frequent patterns in a transactional database,
-    Journal of Systems and Software, Volume 125, 2017, Pages 170-182, ISSN 0164-1212, https://doi.org/10.1016/j.jss.2016.11.035.
-    ...
+    -----------
+        R. Uday Kiran, J.N. Venkatesh, Masashi Toyoda, Masaru Kitsuregawa, P. Krishna Reddy, Discovering partial periodic-frequent patterns in a transactional database,
+        Journal of Systems and Software, Volume 125, 2017, Pages 170-182, ISSN 0164-1212, https://doi.org/10.1016/j.jss.2016.11.035.
+
     Attributes:
-    ----------
+    ------------
         inputFile : file
             Name of the input file to mine complete set of frequent pattern
         minSup : float
             The user defined minSup
         maxPer : float
             The user defined maxPer
         minPR : float
@@ -467,15 +521,15 @@
             storing the total runtime of the mining process
         memoryUSS : float
             storing the total amount of USS memory consumed by the program
         memoryRSS : float
             storing the total amount of RSS memory consumed by the program
 
     Methods:
-    -------
+    ---------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         storePatternsInFile(ouputFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -483,23 +537,27 @@
         getMemoryUSS()
             Total amount of USS memory consumed by the mining process will be retrieved from this function
         getMemoryRSS()
             Total amount of RSS memory consumed by the mining process will be retrieved from this function
         getRuntime()
             Total amount of runtime taken by the mining process will be retrieved from this function
 
-    Format:
-    ------
-        python3 GPFgrowth.py <inputFile> <outputFile> <minSup> <maxPer> <minPR>
+    Executing code on Terminal:
+    ------------------------------
+        Format:
+        --------
+            >>> python3 GPFgrowth.py <inputFile> <outputFile> <minSup> <maxPer> <minPR>
 
         Examples:
-            python3 GPFgrowth.py sampleDB.txt patterns.txt 10 10 0.5
+        ---------
+            >>> python3 GPFgrowth.py sampleDB.txt patterns.txt 10 10 0.5
 
     Sample run of the importing code:
-    ------------
+    ---------------------------------
+    .. code-block:: python
 
         from PAMI.partialPeriodicFrequentPattern.basic import GPFgrowth as alg
 
         obj = alg.GPFgrowth(inputFile, outputFile, minSup, maxPer, minPR)
 
         obj.startMine()
 
@@ -518,14 +576,20 @@
         memRSS = obj.getMemoryRSS()
 
         print("Total Memory in RSS", memRSS)
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
+
+    Credits:
+    ---------
+            The complete program was written by Nakamura  under the supervision of Professor Rage Uday Kiran.
+
+
     """
     _partialPeriodicPatterns__iFile = ' '
     _partialPeriodicPatterns__oFile = ' '
     _partialPeriodicPatterns__sep = str()
     _partialPeriodicPatterns__startTime = float()
     _partialPeriodicPatterns__endTime = float()
     _partialPeriodicPatterns__minSup = str()
```

### Comparing `pami-2023.4.1/PAMI/partialPeriodicFrequentPattern/basic/PPF_DFS.py` & `pami-2023.5.1/PAMI/partialPeriodicFrequentPattern/basic/PPF_DFS.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,16 +1,71 @@
+
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#     from PAMI.partialPeriodicFrequentpattern.basic import PPF_DFS as alg
+#
+#     obj = alg.PPF_DFS(iFile, minSup)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+#
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 import sys
 import validators
 from urllib.request import urlopen
 from PAMI.partialPeriodicFrequentPattern.basic.abstract import *
 
 
 class PPF_DFS(partialPeriodicPatterns):
     """
-    PPF_DFS is algorithm to mine the partial periodic frequent patterns.
+    Description:
+    -------------
+        PPF_DFS is algorithm to mine the partial periodic frequent patterns.
 
     Attributes:
     ----------
 
         iFile : file
             input file path
         oFile : file
@@ -35,15 +90,15 @@
             storing the total runtime of the mining process
         memoryUSS : float
             storing the total amount of USS memory consumed by the program
         memoryRSS : float
             storing the total amount of RSS memory consumed by the program
 
     Methods:
-    -------
+    --------
         getPer_Sup(tids)
             caluclate ip / (sup+1)
         getPerSup(tids)
             caluclate ip
         oneItems(path)
             scan all lines in database
         save(prefix,suffix,tidsetx)
@@ -61,24 +116,27 @@
         getMemoryUSS()
             Total amount of USS memory consumed by the mining process will be retrieved from this function
         getMemoryRSS()
             Total amount of RSS memory consumed by the mining process will be retrieved from this function
         getRuntime()
             Total amount of runtime taken by the mining process will be retrieved from this function
 
-    Format:
-    -------
-        python3 PPF_DFS.py <inputFile> <outputFile> <minSup> <maxPer> <minPR>
-
-    Examples:
-
-        python3 PPF_DFS.py sampleDB.txt patterns.txt 10 10 0.5
+    Executing code on Terminal:
+    ------------------------------
+        Format:
+        --------
+            >>> python3 PPF_DFS.py <inputFile> <outputFile> <minSup> <maxPer> <minPR>
+
+        Examples:
+        ---------
+            >>> python3 PPF_DFS.py sampleDB.txt patterns.txt 10 10 0.5
 
     Sample run of the importing code:
-    -----------
+    ---------------------------------------
+    .. code-block:: python
 
         from PAMI.partialPeriodicFrequentpattern.basic import PPF_DFS as alg
 
         obj = alg.PPF_DFS(iFile, minSup)
 
         obj.startMine()
 
@@ -99,15 +157,15 @@
         print("Total Memory in RSS", memRSS)
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
 
     Credits:
-    -------
+    --------
         The complete program was written by S. Nakamura  under the supervision of Professor Rage Uday Kiran.\n
 
     """
 
     __path = ' '
     _partialPeriodicPatterns__iFile = ' '
     _partialPeriodicPatterns__oFile = ' '
```

### Comparing `pami-2023.4.1/PAMI/partialPeriodicFrequentPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/partialPeriodicFrequentPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/__init__.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/basic/GThreePGrowth.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/basic/GThreePGrowth.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,21 +1,57 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#     from PAMI.periodicFrequentPattern.basic import PPPGrowth as alg
+#
+#     obj = alg.PPPGrowth(iFile, periodicSupport, period)
+#
+#     obj.startMine()
+#
+#     partialPeriodicPatterns = obj.getPatterns()
+#
+#     print("Total number of partial periodic Patterns:", len(partialPeriodicPatterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternInDf()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     run = obj.getRuntime()
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 
 from PAMI.partialPeriodicPattern.basic import Gabstract as _abstract
 import validators as _validators
 from urllib.request import urlopen as _urlopen
 import sys as _sys
 
 _periodicSupport = float()
@@ -249,21 +285,26 @@
                 if len(patterns) > 0:
                     for q in conditionalTree._generatePatterns(pattern):
                         yield q
             self._removeNode(i)
 
 
 class GThreePGrowth(_abstract._partialPeriodicPatterns):
-    """ 3pgrowth is fundamental approach to mine the partial periodic patterns in temporal database.
+    """
+    Description:
+    ------------
+        3pgrowth is fundamental approach to mine the partial periodic patterns in temporal database.
 
+    Reference:
+    ----------
         Reference : Discovering Partial Periodic Itemsets in Temporal Databases,SSDBM '17: Proceedings of the 29th International Conference on Scientific and Statistical Database ManagementJune 2017
         Article No.: 30 Pages 16https://doi.org/10.1145/3085504.3085535
 
     Parameters:
-    ----------
+    ------------
         self.iFile : file
             Name of the Input file or path of the input file
         self. oFile : file
             Name of the output file or path of the output file
         periodicSupport: float or int or str
             The user can specify periodicSupport either in count or proportion of database size.
             If the program detects the data type of periodicSupport is integer, then it treats periodicSupport is expressed in count.
@@ -293,15 +334,15 @@
             it represents the total no of transactions
         tree : class
             it represents the Tree class
         finalPatterns : dict
             it represents to store the patterns
 
     Methods:
-    -------
+    ---------
 
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
@@ -321,22 +362,31 @@
             updates the transactions by removing the aperiodic items and sort the transactions with items
             by decreasing support
         buildTree()
             constrcuts the main tree by setting the root node as null
         startMine()
             main program to mine the partial periodic patterns
 
-        Format: python3 PPPGrowth.py <inputFile> <outputFile> <periodicSupport> <period>
+    Executing the code on terminal:
+    -----------------------------------
 
-        Examples: python3 PPPGrowth.py sampleDB.txt patterns.txt 10.0 2.0   (periodicSupport and period will be considered in percentage of database transactions)
-
-                  python3 PPPGrowth.py sampleDB.txt patterns.txt 10 2     (periodicSupprot and period will be considered in count)
+        Format:
+        -----------
+          >>> python3 PPPGrowth.py <inputFile> <outputFile> <periodicSupport> <period>
 
-        Sample run of the importing code:
+        Examples:
         -----------
+          >>> python3 PPPGrowth.py sampleDB.txt patterns.txt 10.0 2.0   (periodicSupport and period will be considered in percentage of database transactions)
+
+          >>> python3 PPPGrowth.py sampleDB.txt patterns.txt 10 2     (periodicSupprot and period will be considered in count)
+
+    Sample run of the importing code:
+    --------------------------------------------
+    .. code-block:: python
+
         from PAMI.periodicFrequentPattern.basic import PPPGrowth as alg
 
         obj = alg.PPPGrowth(iFile, periodicSupport, period)
 
         obj.startMine()
 
         partialPeriodicPatterns = obj.getPatterns()
@@ -356,17 +406,17 @@
         print("Total Memory in RSS", memRSS)
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
 
 
-        Credits:
-        -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+    Credits:
+    ------------------
+    The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
 
         """
     _periodicSupport = float()
     _period = float()
     _relativePS = {}
     _startTime = float()
     _endTime = float()
```

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/basic/Gabstract.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/basic/Gabstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/basic/PPPGrowth.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/basic/PFPGrowthPlus.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,103 +1,140 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.periodicFrequentPattern.basic import PFPGorwthPlus as alg
+#
+#     obj = alg.PFPGrowthPlus("../basic/sampleTDB.txt", "2", "6")
+#
+#     obj.startMine()
+#
+#     periodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+#
+#     obj.savePatterns("patterns")
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-
-from PAMI.partialPeriodicPattern.basic import abstract as _abstract
-import validators as _validators
-from urllib.request import urlopen as _urlopen
-import sys as _sys
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
 
-_periodicSupport = float()
-_period = float()
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+from PAMI.periodicFrequentPattern.basic import abstract as _ab
+
+_maxPer = float()
+_minSup = float()
 _lno = int()
 
+
 class _Node(object):
     """
-        A class used to represent the node of frequentPatternTree
-        ...
-        Attributes
-        ----------
+    A class used to represent the node of frequentPatternTree
+
+    ...
+    Attributes:
+    ----------
         item : int
             storing item of a node
         timeStamps : list
             To maintain the timestamps of transaction at the end of the branch
         parent : node
             To maintain the parent of every node
         children : list
             To maintain the children of node
 
-        Methods
-        -------
+    Methods:
+    -------
         addChild(itemName)
-        storing the children to their respective parent nodes
-    """
+            storing the children to their respective parent nodes
+        """
 
     def __init__(self, item, children):
         self.item = item
         self.children = children
         self.parent = None
         self.timeStamps = []
 
     def addChild(self, node):
         self.children[node.item] = node
         node.parent = self
 
 
 class _Tree(object):
     """
-        A class used to represent the frequentPatternGrowth tree structure
+    A class used to represent the frequentPatternGrowth tree structure
 
-        ...
+    ...
 
-        Attributes
+        Attributes:
         ----------
-        root : Node
-            Represents the root node of the tree
-        summaries : dictionary
-            storing the nodes with same item name
-        info : dictionary
-            stores the support of items
+            root : Node
+                Represents the root node of the tree
+            summaries : dictionary
+                storing the nodes with same item name
+            info : dictionary
+                stores the support of items
 
 
-        Methods
+        Methods:
         -------
-        addTransaction(transaction)
-            creating transaction as a branch in frequentPatternTree
-        getConditionalPatterns(Node)
-            generates the conditional patterns from tree for specific node
-        conditionalTransactions(prefixPaths,Support)
-            takes the prefixPath of a node and support at child of the path and extract the frequent items from
-            prefixPaths and generates prefixPaths with items which are frequent
-        remove(Node)
-            removes the node from tree once after generating all the patterns respective to the node
-        generatePatterns(Node)
-            starts from the root node of the tree and mines the frequent patterns
+            addTransaction(transaction)
+                creating transaction as a branch in frequentPatternTree
+            getConditionalPatterns(Node)
+                generates the conditional patterns from tree for specific node
+            conditionalTransactions(prefixPaths,Support)
+                takes the prefixPath of a node and support at child of the path and extract the frequent items from
+                prefixPaths and generates prefixPaths with items which are frequent
+            remove(Node)
+                removes the node from tree once after generating all the patterns respective to the node
+            generatePatterns(Node)
+                starts from the root node of the tree and mines the periodic-frequent patterns
 
-            """
+        """
 
     def __init__(self):
         self.root = _Node(None, {})
         self.summaries = {}
         self.info = {}
 
-    def _addTransaction(self, transaction, tid):
+    def addTransaction(self, transaction, tid):
         """
-                adding transaction into tree
+        adding transaction into tree
 
                 :param transaction : it represents the one transactions in database
                 :type transaction : list
                 :param tid : represents the timestamp of transaction
                 :type tid : list
         """
         currentNode = self.root
@@ -110,296 +147,300 @@
                 else:
                     self.summaries[transaction[i]] = [newNode]
                 currentNode = newNode
             else:
                 currentNode = currentNode.children[transaction[i]]
         currentNode.timeStamps = currentNode.timeStamps + tid
 
-    def _getConditionalPatterns(self, alpha):
-        """
-            generates all the conditional patterns of respective node
+    def getConditionalPatterns(self, alpha):
+        """generates all the conditional patterns of respective node
 
-            :param alpha : it represents the Node in tree
-            :type alpha : Node
+                    :param alpha : it represents the Node in tree
+                    :type alpha : Node
         """
         finalPatterns = []
         finalSets = []
         for i in self.summaries[alpha]:
             set1 = i.timeStamps
             set2 = []
             while i.parent.item is not None:
                 set2.append(i.parent.item)
                 i = i.parent
             if len(set2) > 0:
                 set2.reverse()
                 finalPatterns.append(set2)
                 finalSets.append(set1)
-        finalPatterns, finalSets, info = self._conditionalTransactions(finalPatterns, finalSets)
+        finalPatterns, finalSets, info = self.conditionalTransactions(finalPatterns, finalSets)
         return finalPatterns, finalSets, info
 
-    def _generateTimeStamps(self, node):
-        finalTs = node.timeStamps
-        return finalTs
+    @staticmethod
+    def generateTimeStamps(node):
+        finalTimeStamps = node.timeStamps
+        return finalTimeStamps
 
-    def _removeNode(self, nodeValue):
-        """
-            removing the node from tree
+    def removeNode(self, nodeValue):
+        """removing the node from tree
 
-            :param nodeValue : it represents the node in tree
-            :type nodeValue : node
-        """
+                        :param nodeValue : it represents the node in tree
+                        :type nodeValue : node
+                        """
         for i in self.summaries[nodeValue]:
             i.parent.timeStamps = i.parent.timeStamps + i.timeStamps
             del i.parent.children[nodeValue]
 
-    def _getTimeStamps(self, alpha):
-        """
-        Returns the timeStamps of a node
-
-        Parameters
-        ----------
-        alpha: node of tree
-
-        Returns
-        -------
-        timeStamps of a node
-
-        """
+    def getTimeStamps(self, alpha):
         temporary = []
         for i in self.summaries[alpha]:
             temporary += i.timeStamps
         return temporary
 
-    def _getPeriodicSupport(self, timeStamps):
+    @staticmethod
+    def getSupportAndPeriod(timeStamps):
         """
-            calculates the support and periodicity with list of timestamps
+                   calculates the support and periodicity with list of timestamps
 
-            :param timeStamps : timestamps of a pattern
+                   :param timeStamps : timestamps of a pattern
+                   :type timeStamps : list
 
-            :type timeStamps : list
 
-
-        """
+                           """
+        global _maxPer, _lno
         timeStamps.sort()
+        cur = 0
         per = 0
         sup = 0
-        for i in range(len(timeStamps) - 1):
-            j = i + 1
-            if abs(timeStamps[j] - timeStamps[i]) <= _period:
-                per += 1
+        for j in range(len(timeStamps)):
+            per = max(per, timeStamps[j] - cur)
+            if per > _maxPer:
+                return [0, 0]
+            cur = timeStamps[j]
             sup += 1
-        return per
+        per = max(per, _lno - cur)
+        return [sup, per]
 
-    def _conditionalTransactions(self, conditionalPatterns, conditionalTimeStamps):
+    def conditionalTransactions(self, conditionalPatterns, conditionalTimeStamps):
         """ It generates the conditional patterns with periodic frequent items
 
-                :param conditionalPatterns : conditional_patterns generated from condition_pattern method for
-                                        respective node
+                :param conditionalPatterns : conditionalPatterns generated from conditionalPattern method for
+                                    respective node
                 :type conditionalPatterns : list
                 :param conditionalTimeStamps : represents the timestamps of conditional patterns of a node
                 :type conditionalTimeStamps : list
-        """
-        global _periodicSupport, _period
-        patterns = []
+                """
+        global _maxPer, _minSup
+        pat = []
         timeStamps = []
         data1 = {}
         for i in range(len(conditionalPatterns)):
             for j in conditionalPatterns[i]:
                 if j in data1:
                     data1[j] = data1[j] + conditionalTimeStamps[i]
                 else:
                     data1[j] = conditionalTimeStamps[i]
         updatedDictionary = {}
         for m in data1:
-            updatedDictionary[m] = self._getPeriodicSupport(data1[m])
-        updatedDictionary = {k: v for k, v in updatedDictionary.items() if v >= _periodicSupport}
+            updatedDictionary[m] = self.getSupportAndPeriod(data1[m])
+        updatedDictionary = {k: v for k, v in updatedDictionary.items() if v[0] >= _minSup and v[1] <= _maxPer}
         count = 0
         for p in conditionalPatterns:
             p1 = [v for v in p if v in updatedDictionary]
-            trans = sorted(p1, key=lambda x: (updatedDictionary.get(x), -x), reverse=True)
+            trans = sorted(p1, key=lambda x: (updatedDictionary.get(x)[0], -x), reverse=True)
             if len(trans) > 0:
-                patterns.append(trans)
+                pat.append(trans)
                 timeStamps.append(conditionalTimeStamps[count])
             count += 1
-        return patterns, timeStamps, updatedDictionary
+        return pat, timeStamps, updatedDictionary
 
-    def _generatePatterns(self, prefix):
+    def generatePatterns(self, prefix):
         """generates the patterns
 
                 :param prefix : forms the combination of items
                 :type prefix : list
-                        """
-        for i in sorted(self.summaries, key=lambda x: (self.info.get(x), -x)):
+                """
+        for i in sorted(self.summaries, key=lambda x: (self.info.get(x)[0], -x)):
             pattern = prefix[:]
             pattern.append(i)
             yield pattern, self.info[i]
-            patterns, timeStamps, info = self._getConditionalPatterns(i)
+            patterns, timeStamps, info = self.getConditionalPatterns(i)
             conditionalTree = _Tree()
             conditionalTree.info = info.copy()
             for pat in range(len(patterns)):
-                conditionalTree._addTransaction(patterns[pat], timeStamps[pat])
+                conditionalTree.addTransaction(patterns[pat], timeStamps[pat])
             if len(patterns) > 0:
-                for q in conditionalTree._generatePatterns(pattern):
+                for q in conditionalTree.generatePatterns(pattern):
                     yield q
-            self._removeNode(i)
-
+            self.removeNode(i)
 
-class PPPGrowth(_abstract._partialPeriodicPatterns):
-    """ 3pgrowth is fundamental approach to mine the partial periodic patterns in temporal database.
 
-        Reference : Discovering Partial Periodic Itemsets in Temporal Databases,SSDBM '17: Proceedings of the 29th International Conference on Scientific and Statistical Database ManagementJune 2017
-        Article No.: 30 Pages 16https://doi.org/10.1145/3085504.3085535
-
-    Parameters:
-    ----------
-        self.iFile : file
+class PFPGrowthPlus(_ab._periodicFrequentPatterns):
+    """
+    Description:
+    -------------
+        PFPGrowthPlus is fundamental and improved version of PFPGrowth algorithm to discover periodic-frequent patterns in temporal database.
+        It uses greedy approach to discover effectively
+
+    Reference :
+    ------------
+        R. UdayKiran, MasaruKitsuregawa, and P. KrishnaReddyd, "Efficient discovery of periodic-frequent patterns in
+        very large databases," Journal of Systems and Software February 2016 https://doi.org/10.1016/j.jss.2015.10.035
+
+    Attributes:
+    ------------
+        iFile : file
             Name of the Input file or path of the input file
-        self. oFile : file
+        oFile : file
             Name of the output file or path of the output file
-        periodicSupport: float or int or str
-            The user can specify periodicSupport either in count or proportion of database size.
-            If the program detects the data type of periodicSupport is integer, then it treats periodicSupport is expressed in count.
+        minSup: int or float or str
+            The user can specify minSup either in count or proportion of database size.
+            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
             Otherwise, it will be treated as float.
-            Example: periodicSupport=10 will be treated as integer, while periodicSupport=10.0 will be treated as float
-        period: float or int or str
-            The user can specify period either in count or proportion of database size.
-            If the program detects the data type of period is integer, then it treats period is expressed in count.
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+        maxPer: int or float or str
+            The user can specify maxPer either in count or proportion of database size.
+            If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
             Otherwise, it will be treated as float.
-            Example: period=10 will be treated as integer, while period=10.0 will be treated as float
+            Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
         sep : str
             This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
             However, the users can override their default separator.
-        self.memoryUSS : float
+        memoryUSS : float
             To store the total amount of USS memory consumed by the program
-        self.memoryRSS : float
+        memoryRSS : float
             To store the total amount of RSS memory consumed by the program
-        self.startTime:float
+        startTime:float
             To record the start time of the mining process
-        self.endTime:float
+        endTime:float
             To record the completion time of the mining process
         Database : list
             To store the transactions of a database in list
         mapSupport : Dictionary
             To maintain the information of item and their frequency
         lno : int
-            it represents the total no of transactions
+            it represents the total no of transaction
         tree : class
             it represents the Tree class
+        itemSetCount : int
+            it represents the total no of patterns
         finalPatterns : dict
             it represents to store the patterns
 
     Methods:
-    -------
-
+    ---------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
-            Complete set of frequent patterns will be loaded in to a output file
+            Complete set of periodic-frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
-            Complete set of frequent patterns will be loaded in to a dataframe
+            Complete set of periodic-frequent patterns will be loaded in to a dataframe
         getMemoryUSS()
             Total amount of USS memory consumed by the mining process will be retrieved from this function
         getMemoryRSS()
             Total amount of RSS memory consumed by the mining process will be retrieved from this function
         getRuntime()
             Total amount of runtime taken by the mining process will be retrieved from this function
-        creatingItemSets()
+        check(line)
+            To check the delimiter used in the user input file
+        creatingItemSets(fileName)
             Scans the dataset or dataframes and stores in list format
-        partialPeriodicOneItem()
-            Extracts the one-frequent patterns from transactions
-        updateTransactions()
-            updates the transactions by removing the aperiodic items and sort the transactions with items
-            by decreasing support
+        PeriodicFrequentOneItem()
+            Extracts the one-periodic-frequent patterns from Databases
+        updateDatabases()
+            update the Databases by removing aperiodic items and sort the Database by item decreased support
         buildTree()
-            constrcuts the main tree by setting the root node as null
+            after updating the Databases ar added into the tree by setting root node as null
         startMine()
-            main program to mine the partial periodic patterns
+            the main method to run the program
 
-        Format: python3 PPPGrowth.py <inputFile> <outputFile> <periodicSupport> <period>
 
-        Examples: python3 PPPGrowth.py sampleDB.txt patterns.txt 10.0 2.0   (periodicSupport and period will be considered in percentage of database transactions)
+    **Methods to execute code on terminal**
 
-                  python3 PPPGrowth.py sampleDB.txt patterns.txt 10 2     (periodicSupprot and period will be considered in count)
+            Format:
+                      >>>  python3 PFPGrowthPlus.py <inputFile> <outputFile> <minSup> <maxPer>
+            Example:
+                      >>>  python3 PFPGrowthPlus.py sampleTDB.txt patterns.txt 0.3 0.4
 
-        Sample run of the importing code:
-        -----------
-        from PAMI.periodicFrequentPattern.basic import PPPGrowth as alg
+            .. note:: minSup will be considered in percentage of database transactions
 
-        obj = alg.PPPGrowth(iFile, periodicSupport, period)
 
-        obj.startMine()
+    **Importing this algorithm into a python program**
 
-        partialPeriodicPatterns = obj.getPatterns()
+    .. code-block:: python
 
-        print("Total number of partial periodic Patterns:", len(partialPeriodicPatterns))
+                from PAMI.periodicFrequentPattern.basic import PFPGorwthPlus as alg
 
-        obj.save(oFile)
+                obj = alg.PFPGrowthPlus("../basic/sampleTDB.txt", "2", "6")
 
-        Df = obj.getPatternInDf()
+                obj.startMine()
 
-        memUSS = obj.getMemoryUSS()
+                periodicFrequentPatterns = obj.getPatterns()
 
-        print("Total Memory in USS:", memUSS)
+                print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
 
-        memRSS = obj.getMemoryRSS()
+                obj.savePatterns("patterns")
 
-        print("Total Memory in RSS", memRSS)
+                Df = obj.getPatternsAsDataFrame()
 
-        run = obj.getRuntime()
+                memUSS = obj.getMemoryUSS()
 
-        print("Total ExecutionTime in seconds:", run)
+                print("Total Memory in USS:", memUSS)
 
+                memRSS = obj.getMemoryRSS()
 
-        Credits:
-        -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+                print("Total Memory in RSS", memRSS)
 
-        """
-    _periodicSupport = float()
-    _period = float()
+                run = obj.getRuntime()
+
+                print("Total ExecutionTime in seconds:", run)
+
+    **Credits:**
+
+             The complete program was written by  P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+
+    """
+
+    _minSup = str()
+    _maxPer = str()
     _startTime = float()
     _endTime = float()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
     _rank = {}
-    _rankdup = {}
+    _rankedUp = {}
     _lno = 0
 
     def _creatingItemSets(self):
         """
             Storing the complete transactions of the database/input file in a database variable
 
 
-            """
+        """
         self._Database = []
-        if isinstance(self._iFile, _abstract._pd.DataFrame):
-            data, tids = [], []
+        if isinstance(self._iFile, _ab._pd.DataFrame):
+            data, ts = [], []
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'TS' in i:
-                tids = self._iFile['TS'].tolist()
+                ts = self._iFile['TS'].tolist()
             if 'Transactions' in i:
                 data = self._iFile['Transactions'].tolist()
             for i in range(len(data)):
-                tr = [tids[i][0]]
+                tr = [ts[i][0]]
                 tr = tr + data[i]
                 self._Database.append(tr)
-            self._lno = len(self._Database)
-            # print(self.Database)
         if isinstance(self._iFile, str):
-            if _validators.url(self._iFile):
-                data = _urlopen(self._iFile)
+            if _ab._validators.url(self._iFile):
+                data = _ab._urlopen(self._iFile)
                 for line in data:
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
                     self._Database.append(temp)
             else:
@@ -410,84 +451,94 @@
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
                             self._Database.append(temp)
                 except IOError:
                     print("File Not Found")
                     quit()
 
-    def _partialPeriodicOneItem(self):
+    def _periodicFrequentOneItem(self):
         """
-                    calculates the support of each item in the dataset and assign the ranks to the items
-                    by decreasing support and returns the frequent items list
+            calculates the support of each item in the dataset and assign the ranks to the items
+            by decreasing support and returns the frequent items list
 
-                    """
+            """
         data = {}
-        self._period = self._convert(self._period)
-        self._periodicSupport = self._convert(self._periodicSupport)
         for tr in self._Database:
+            n = int(tr[0])
             for i in range(1, len(tr)):
-                if tr[i] not in data:
-                    data[tr[i]] = [0, int(tr[0]), 1]
+                if n <= self._maxPer:
+                    if tr[i] not in data:
+                        data[tr[i]] = [int(tr[0]), int(tr[0]), 1]
+                    else:
+                        data[tr[i]][0] = max(data[tr[i]][0], (int(tr[0]) - data[tr[i]][1]))
+                        data[tr[i]][1] = int(tr[0])
+                        data[tr[i]][2] += 1
                 else:
-                    lp = int(tr[0]) - data[tr[i]][1]
-                    if lp <= self._period:
-                        data[tr[i]][0] += 1
-                    data[tr[i]][1] = int(tr[0])
-                    data[tr[i]][2] += 1
-        data = {k: v[0] for k, v in data.items() if v[0] >= self._periodicSupport}
-        pfList = [k for k, v in sorted(data.items(), key=lambda x: x[1], reverse=True)]
-        self._rank = dict([(index, item) for (item, index) in enumerate(pfList)])
-        return data, pfList
+                    if tr[i] in data:
+                        lp = abs(n - data[tr[i]][1])
+                        if lp > self._maxPer:
+                            del data[tr[i]]
+                        else:
+                            data[tr[i]][0] = max(data[tr[i]][0], lp)
+                            data[tr[i]][1] = int(tr[0])
+                            data[tr[i]][2] += 1
+        for key in data:
+            data[key][0] = max(data[key][0], _lno - data[key][1])
+        data = {k: [v[2], v[0]] for k, v in data.items() if v[0] <= self._maxPer and v[2] >= self._minSup}
+        genList = [k for k, v in sorted(data.items(), key=lambda x: (x[1][0], x[0]), reverse=True)]
+        self._rank = dict([(index, item) for (item, index) in enumerate(genList)])
+        # genList=[k for k,v in sorted(data.items(),key=lambda x: (x[1][0],x[0]),reverse=True)]
+        return data, genList
 
     def _updateTransactions(self, dict1):
         """remove the items which are not frequent from transactions and updates the transactions with rank of items
 
-                    :param dict1 : frequent items with support
-                    :type dict1 : dictionary
-                    """
+            :param dict1 : frequent items with support
+            :type dict1 : dictionary
+            """
         list1 = []
         for tr in self._Database:
             list2 = [int(tr[0])]
             for i in range(1, len(tr)):
                 if tr[i] in dict1:
                     list2.append(self._rank[tr[i]])
             if len(list2) >= 2:
                 basket = list2[1:]
                 basket.sort()
                 list2[1:] = basket[0:]
                 list1.append(list2)
         return list1
 
-    def _buildTree(self, data, info):
+    @staticmethod
+    def _buildTree(data, info):
         """it takes the transactions and support of each item and construct the main tree with setting root
-                            node as null
+                    node as null
 
-                :param data : it represents the one transactions in database
-                :type data : list
-                :param info : it represents the support of each item
-                :type info : dictionary
-        """
+                        :param data : it represents the one transactions in database
+                        :type data : list
+                        :param info : it represents the support of each item
+                        :type info : dictionary
+                        """
         rootNode = _Tree()
         rootNode.info = info.copy()
         for i in range(len(data)):
-            set1 = []
-            set1.append(data[i][0])
-            rootNode._addTransaction(data[i][1:], set1)
+            set1 = [data[i][0]]
+            rootNode.addTransaction(data[i][1:], set1)
         return rootNode
 
-    def _savePeriodic(self, itemset):
+    def _savePeriodic(self, itemSet):
         """
-        To convert the pattern with its original item name
-        :param itemset: partial periodic pattern
-        :return: pattern with original item name
-        """
-        temp = str()
-        for i in itemset:
-            temp = temp + self._rankdup[i] + "\t"
-        return temp
+        To convert item ranks into original item names
+        :param itemSet: periodic-frequent pattern
+        :return: original itemSet
+        """
+        t1 = str()
+        for i in itemSet:
+            t1 = t1 + self._rankedUp[i] + " "
+        return t1
 
     def _convert(self, value):
         """
         To convert the given user specified value
 
         :param value: user specified value
         :return: converted value
@@ -502,43 +553,45 @@
                 value = (len(self._Database) * value)
             else:
                 value = int(value)
         return value
 
     def startMine(self):
         """
-                   Main method where the patterns are mined by constructing tree.
+            Main method where the patterns are mined by constructing tree.
 
-               """
-        global _periodicSupport, _period, _lno
-        self._startTime = _abstract._time.time()
+        """
+        global _minSup, _maxPer, _lno
+        self._startTime = _ab._time.time()
         if self._iFile is None:
             raise Exception("Please enter the file path or file name:")
-        if self._periodicSupport is None:
+        if self._minSup is None:
             raise Exception("Please enter the Minimum Support")
         self._creatingItemSets()
-        generatedItems, pfList = self._partialPeriodicOneItem()
-        _periodicSupport, _period, _lno = self._periodicSupport, self._period, len(self._Database)
+        self._minSup = self._convert(self._minSup)
+        self._maxPer = self._convert(self._maxPer)
+        _minSup, _maxPer, _lno = self._minSup, self._maxPer, len(self._Database)
+        generatedItems, pfList = self._periodicFrequentOneItem()
         updatedTransactions = self._updateTransactions(generatedItems)
         for x, y in self._rank.items():
-            self._rankdup[y] = x
+            self._rankedUp[y] = x
         info = {self._rank[k]: v for k, v in generatedItems.items()}
         Tree = self._buildTree(updatedTransactions, info)
-        patterns = Tree._generatePatterns([])
+        patterns = Tree.generatePatterns([])
         self._finalPatterns = {}
         for i in patterns:
-            s = self._savePeriodic(i[0])
-            self._finalPatterns[s] = i[1]
-        self._endTime = _abstract._time.time()
-        process = _abstract._psutil.Process(_abstract._os.getpid())
-        self._memoryUSS = float()
+            x = self._savePeriodic(i[0])
+            self._finalPatterns[x] = i[1]
+        self._endTime = _ab._time.time()
+        process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryRSS = float()
+        self._memoryUSS = float()
         self._memoryUSS = process.memory_full_info().uss
         self._memoryRSS = process.memory_info().rss
-        print("Partial Periodic Patterns were generated successfully using 3PGrowth algorithm ")
+        print("periodic-frequent patterns were generated successfully using PFPGrowth++ algorithm ")
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
         :return: returning USS memory consumed by the mining process
         :rtype: float
         """
@@ -561,62 +614,62 @@
         :return: returning total amount of runtime taken by the mining process
         :rtype: float
         """
 
         return self._endTime - self._startTime
 
     def getPatternsAsDataFrame(self):
-        """Storing final frequent patterns in a dataframe
+        """Storing final periodic-frequent patterns in a dataframe
 
-        :return: returning frequent patterns in a dataframe
+        :return: returning periodic-frequent patterns in a dataframe
         :rtype: pd.DataFrame
         """
 
-        dataFrame = {}
+        dataframe = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a.replace('\t', ' '), b])
-            dataFrame = _abstract._pd.DataFrame(data, columns=['Patterns', 'periodicSupport'])
-        return dataFrame
+            data.append([a, b[0], b[1]])
+            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Periodicity'])
+        return dataframe
 
     def save(self, outFile):
-        """Complete set of frequent patterns will be loaded in to a output file
+        """Complete set of periodic-frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
         :type outFile: file
         """
         self._oFile = outFile
         writer = open(self._oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            s1 = x.strip() + ":" + str(y)
+            s1 = x.replace(' ','\t').strip() + ":" + str(y[0]) + ":" + str(y[1])
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
-        """ Function to send the set of frequent patterns after completion of the mining process
+        """ Function to send the set of periodic-frequent patterns after completion of the mining process
 
-        :return: returning frequent patterns
+        :return: returning periodic-frequent patterns
         :rtype: dict
         """
         return self._finalPatterns
 
     def printResults(self):
-        print("Total number of Partial Periodic Patterns:", len(self.getPatterns()))
+        print("Total number of Periodic Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_sys.argv) == 5 or len(_sys.argv) == 6:
-        if len(_sys.argv) == 6:
-            _ap = PPPGrowth(_sys.argv[1], _sys.argv[3], _sys.argv[4], _sys.argv[5])
-        if len(_sys.argv) == 5:
-            _ap = PPPGrowth(_sys.argv[1], _sys.argv[3], _sys.argv[4])
+    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
+        if len(_ab._sys.argv) == 6:
+            _ap = PFPGrowthPlus(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
+        if len(_ab._sys.argv) == 5:
+            _ap = PFPGrowthPlus(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
         _ap.startMine()
-        print("Total number of Partial Periodic Patterns:", len(_ap.getPatterns()))
-        _ap.save(_sys.argv[2])
+        print("Total number of Periodic-Frequent Patterns:", len(_ap.getPatterns()))
+        _ap.save(_ab._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
-        print("Total ExecutionTime in ms:",  _ap.getRuntime())
+        print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/basic/PPP_ECLAT.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/topk/k3PMiner.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,376 +1,427 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+
+#
+#     import PAMI.partialPeriodicPattern.topk.Topk_PPPGrowth as alg
+#
+#     obj = alg.Topk_PPPGrowth(iFile, k, periodicity)
+#
+#     obj.startMine()
+#
+#     partialPeriodicPatterns = obj.getPatterns()
+#
+#     print("Total number of top partial periodic Patterns:", len(partialPeriodicPatterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
+#     memRSS = obj.getMemoryRSS()
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     print("Total Memory in RSS", memRSS)
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
 
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
 
-from PAMI.partialPeriodicPattern.basic import abstract as _ab
+"""
 
 
-class PPP_ECLAT(_ab._partialPeriodicPatterns):
+from PAMI.partialPeriodicPattern.topk import abstract as _abstract
+import validators as _validators
+from urllib.request import urlopen as _urlopen
+import sys as _sys
+
+
+class Topk_PPPGrowth(_abstract.partialPeriodicPatterns):
     """
-    3pEclat is the fundamental approach to mine the partial periodic frequent patterns.
+    Description:
+    -------------
+        Top - K is and algorithm to discover top partial periodic patterns in a temporal  database.
 
     Reference:
-
-    Parameters:
     ----------
-        self.iFile : file
-            Name of the Input file or path of the input file
-        self. oFile : file
-            Name of the output file or path of the output file
-        periodicSupport: float or int or str
-            The user can specify periodicSupport either in count or proportion of database size.
-            If the program detects the data type of periodicSupport is integer, then it treats periodicSupport is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: periodicSupport=10 will be treated as integer, while periodicSupport=10.0 will be treated as float
-        period: float or int or str
-            The user can specify period either in count or proportion of database size.
-            If the program detects the data type of period is integer, then it treats period is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: period=10 will be treated as integer, while period=10.0 will be treated as float
-        sep : str
-            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-            However, the users can override their default separator.
-        memoryUSS : float
-            To store the total amount of USS memory consumed by the program
-        memoryRSS : float
-            To store the total amount of RSS memory consumed by the program
-        startTime:float
-            To record the start time of the mining process
-        endTime:float
-            To record the completion time of the mining process
-        Database : list
-            To store the transactions of a database in list
-        mapSupport : Dictionary
-            To maintain the information of item and their frequency
-        lno : int
-            it represents the total no of transactions
-        tree : class
-            it represents the Tree class
-        finalPatterns : dict
-            it represents to store the patterns
-        tidList : dict
-            stores the timestamps of an item
 
-    Methods:
-    -------
-        startMine()
-            Mining process will start from here
-        getPatterns()
-            Complete set of patterns will be retrieved with this function
-        save(oFile)
-            Complete set of frequent patterns will be loaded in to a output file
-        getPatternsAsDataFrame()
-            Complete set of frequent patterns will be loaded in to a dataframe
-        getMemoryUSS()
-            Total amount of USS memory consumed by the mining process will be retrieved from this function
-        getMemoryRSS()
-            Total amount of RSS memory consumed by the mining process will be retrieved from this function
-        getRuntime()
-            Total amount of runtime taken by the mining process will be retrieved from this function
-        creatingOneitemSets()
-            Scan the database and store the items with their timestamps which are periodic frequent
-        getPeriodAndSupport()
-            Calculates the support and period for a list of timestamps.
-        Generation()
-            Used to implement prefix class equivalence method to generate the periodic patterns recursively
-
-    Executing the code on terminal:
-    -------
 
-        Format: python3 PPP_ECLAT.py <inputFile> <outputFile> <periodicSupport> <period>
+    Attributes:
+    ------------
+            iFile : str
+                Input file name or path of the input file
+            k: int
+                User specified count of top partial periodic patterns
+            sep : str
+                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+                However, the users can override their default separator.
+            oFile : str
+                Name of the output file or the path of the output file
+            startTime:float
+                To record the start time of the mining process
+            endTime:float
+                To record the completion time of the mining process
+            finalPatterns: dict
+                Storing the complete set of patterns in a dictionary variable
+            memoryUSS : float
+                To store the total amount of USS memory consumed by the program
+            memoryRSS : float
+                To store the total amount of RSS memory consumed by the program
 
-        Examples: python3 PPP_ECLAT.py sampleDB.txt patterns.txt 0.3 0.4   (periodicSupport and period will be considered in percentage of database transactions)
+    Methods:
+    --------
+            startMine()
+                Mining process will start from here
+            getPatterns()
+                Complete set of patterns will be retrieved with this function
+            save(oFile)
+                Complete set of frequent patterns will be loaded in to a output file
+            getPatternsAsDataFrame()
+                Complete set of frequent patterns will be loaded in to a dataframe
+            getMemoryUSS()
+                Total amount of USS memory consumed by the mining process will be retrieved from this function
+            getMemoryRSS()
+                Total amount of RSS memory consumed by the mining process will be retrieved from this function
+            getRuntime()
+                Total amount of runtime taken by the mining process will be retrieved from this function
+            creatingItemSets()
+                Scans the dataset or dataframes and stores in list format
+            frequentOneItem()
+                Generates one frequent patterns
+            eclatGeneration(candidateList)
+                It will generate the combinations of frequent items
+            generateFrequentPatterns(tidList)
+                It will generate the combinations of frequent items from a list of items
 
-                  python3 threePEeclat.py sampleDB.txt patterns.txt 3 4     (periodicSupport and period will be considered in support count or frequency)
+    Executing the code on terminal:
+    -------------------------------
 
+        Format:
+        ------
+            >>> python3 FAE.py <inputFile> <outputFile> <k> <periodicity>
 
-    Sample run of importing the code:
-    -------------------
+        Examples:
+        ---------
+            >>> python3 FAE.py sampleDB.txt patterns.txt 10 3
 
-        from PAMI.periodicFrequentPattern.basic import PPP_ECLAT as alg
 
-        obj = alg.PPP_ECLAT(iFile, periodicSupport,period)
+    Sample run of the importing code:
+    ---------------------------------
+    .. code-block:: python
 
-        obj.startMine()
+            import PAMI.partialPeriodicPattern.topk.Topk_PPPGrowth as alg
 
-        Patterns = obj.getPatterns()
+            obj = alg.Topk_PPPGrowth(iFile, k, periodicity)
 
-        print("Total number of partial periodic patterns:", len(Patterns))
+            obj.startMine()
 
-        obj.save(oFile)
+            partialPeriodicPatterns = obj.getPatterns()
 
-        Df = obj.getPatternsAsDataFrame()
+            print("Total number of top partial periodic Patterns:", len(partialPeriodicPatterns))
 
-        memUSS = obj.getMemoryUSS()
+            obj.save(oFile)
 
-        print("Total Memory in USS:", memUSS)
+            Df = obj.getPatternInDataFrame()
 
-        memRSS = obj.getMemoryRSS()
+            memUSS = obj.getMemoryUSS()
 
-        print("Total Memory in RSS", memRSS)
+            print("Total Memory in USS:", memUSS)
 
-        run = obj.getRuntime()
+            memRSS = obj.getMemoryRSS()
 
-        print("Total ExecutionTime in seconds:", run)
+            print("Total Memory in RSS", memRSS)
 
-        Credits:
-        -------
+            run = obj.getRuntime()
 
-        The complete program was written by P.RaviKumar  under the supervision of Professor Rage Uday Kiran.\n
+            print("Total ExecutionTime in seconds:", run)
 
+    Credits:
+    ---------
+            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
 
+    """
 
-        """
     _startTime = float()
     _endTime = float()
+    _k = int()
+    _periodicity = " "
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
-    _mapSupport = {}
-    _itemsetCount = 0
-    _writer = None
-    _periodicSupport = str()
-    _period = str()
-    _tidList = {}
-    _lno = 0
     _Database = []
+    _tidList = {}
+    _lno = int()
+    _minimum = int()
+    _mapSupport = {}
 
-    def _convert(self, value):
-        """
-        To convert the given user specified value
-
-        :param value: user specified value
-
-        :return: converted value
-        """
-        if type(value) is int:
-            value = int(value)
-        if type(value) is float:
-            value = (len(self._Database) * value)
-        if type(value) is str:
-            if '.' in value:
-                value = float(value)
-                value = (len(self._Database) * value)
-            else:
-                value = int(value)
-        return value
-
-    def _getPeriodicSupport(self, timeStamps):
+    def _creatingItemSets(self):
         """
-            calculates the support and periodicity with list of timestamps
+            Storing the complete transactions of the database/input file in a database variable
 
-            :param timeStamps : timestamps of a pattern
-
-            :type timeStamps : list
         """
-        timeStamps.sort()
-        per = 0
-        for i in range(len(timeStamps) - 1):
-            j = i + 1
-            if abs(timeStamps[j] - timeStamps[i]) <= self._period:
-                per += 1
-        return per
-
-    def _creatingItemSets(self):
         self._Database = []
-        if isinstance(self._iFile, _ab._pd.DataFrame):
-            data, tids = [], []
+        if isinstance(self._iFile, _abstract._pd.DataFrame):
+            timeStamp, data = [], []
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'TS' in i:
-                tids = self._iFile['TS'].tolist()
+                timeStamp = self._iFile['TS'].tolist()
             if 'Transactions' in i:
                 data = self._iFile['Transactions'].tolist()
             for i in range(len(data)):
-                tr = [tids[i][0]]
+                tr = [timeStamp[i]]
                 tr = tr + data[i]
                 self._Database.append(tr)
             self._lno = len(self._Database)
-
+            # print(self.Database)
         if isinstance(self._iFile, str):
-            if _ab._validators.url(self._iFile):
-                data = _ab._urlopen(self._iFile)
+            if _validators.url(self._iFile):
+                data = _urlopen(self._iFile)
                 for line in data:
-                    line.strip()
                     self._lno += 1
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
                     self._Database.append(temp)
             else:
                 try:
                     with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
                             self._lno += 1
-                            line.strip()
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
                             self._Database.append(temp)
                 except IOError:
                     print("File Not Found")
                     quit()
 
-    def _creatingOneitemSets(self):
+    def _convert(self, value):
         """
-           Scans the Temporal database / Input file and stores the 1-length partial-periodic patterns.
+        To convert the given user specified value
+        :param value: user specified value
+        :return: converted value
         """
-        plist = []
-        self._tidList = {}
+        if type(value) is int:
+            value = int(value)
+        if type(value) is float:
+            value = (len(self._Database) * value)
+        if type(value) is str:
+            if '.' in value:
+                value = float(value)
+                value = (len(self._Database) * value)
+            else:
+                value = int(value)
+        return value
+
+    def _frequentOneItem(self):
+        """
+        Generating one frequent patterns
+        """
+
         self._mapSupport = {}
-        self._period = self._convert(self._period)
+        self._tidList = {}
+        self._periodicity = self._convert(self._periodicity)
+        self._k = int(self._convert(self._k))
         for line in self._Database:
-            s = line
-            n = int(s[0])
-            for i in range(1, len(s)):
-                si = s[i]
+            n = int(line[0])
+            for i in range(1, len(line)):
+                si = line[i]
                 if self._mapSupport.get(si) is None:
-                    self._mapSupport[si] = [0, n]
+                    self._mapSupport[si] = [1, 0, n]
                     self._tidList[si] = [n]
                 else:
-                    lp = n - self._mapSupport[si][1]
-                    if lp <= self._period:
-                        self._mapSupport[si][0] += 1
-                    self._mapSupport[si][1] = n
+                    self._mapSupport[si][0] += 1
+                    period = abs(n - self._mapSupport[si][2])
+                    if period <= self._periodicity:
+                        self._mapSupport[si][1] += 1
+                    self._mapSupport[si][2] = n
                     self._tidList[si].append(n)
-        self._periodicSupport = self._convert(self._periodicSupport)
-        self._mapSupport = {k: v[0] for k, v in self._mapSupport.items() if v[0] >= self._periodicSupport}
-        plist = [key for key, value in sorted(self._mapSupport.items(), key=lambda x: x[1], reverse=True)]
+        for x, y in self._mapSupport.items():
+            period = abs(self._lno - self._mapSupport[x][2])
+            if period <= self._periodicity:
+                self._mapSupport[x][1] += 1
+        self._mapSupport = {k: v[1] for k, v in self._mapSupport.items()}
+        plist = [key for key, value in sorted(self._mapSupport.items(), key=lambda x: x[0], reverse=True)]
+        self._finalPatterns = {}
+        for i in plist:
+            if self._mapSupport[i] == 0:
+                continue
+            if len(self._finalPatterns) >= self._k:
+                break
+            else:
+                self._finalPatterns[i] = self._mapSupport[i]
+        print(len(self._finalPatterns),  self._k, self._periodicity)
+        self._minimum = min([self._finalPatterns[i] for i in self._finalPatterns.keys()])
+        plist = list(self._finalPatterns.keys())
         return plist
 
-    def _save(self, prefix, suffix, tidSetX):
+    def _getSupportAndPeriod(self, timeStamps):
+        """To calculate the periodicity and support
+        :param timeStamps: Timestamps of an item set
+        :return: support, periodicity
         """
-            saves the patterns that satisfy the partial periodic property.
 
-            :param prefix: the prefix of a pattern
+        timeStamps.sort()
+        sup = 0
+        for j in range(len(timeStamps) - 1):
+            per = abs(timeStamps[j + 1] - timeStamps[j])
+            if per <= self._periodicity:
+                sup += 1
+        return sup
 
-            :type prefix: list
+    def _save(self, prefix, suffix, tidSetI):
+        """Saves the patterns that satisfy the periodic frequent property.
 
-            :param suffix : the suffix of a patterns
+            :param prefix: the prefix of a pattern
 
-            :type suffix : list
+            :type prefix: list
 
-            :param tidSetX : the timestamp of a patterns
+            :param suffix: the suffix of a patterns
 
-            :type tidSetX : list
+            :type suffix: list
 
+            :param tidSetI: the timestamp of a patterns
 
+            :type tidSetI: list
         """
+
         if prefix is None:
             prefix = suffix
         else:
             prefix = prefix + suffix
-        val = self._getPeriodicSupport(tidSetX)
-        if val >= self._periodicSupport:
-            sample = str()
-            for i in prefix:
-                sample = sample + i + "\t"
-            self._finalPatterns[sample] = val
+        val = self._getSupportAndPeriod(tidSetI)
+        sample = str()
+        for i in prefix:
+            sample = sample + i + "\t"
+        if len(self._finalPatterns) < self._k:
+            if val >= self._minimum:
+                self._finalPatterns[sample] = val
+                self._finalPatterns = {k: v for k, v in
+                                       sorted(self._finalPatterns.items(), key=lambda item: item[1], reverse=True)}
+                self._minimum = min([self._finalPatterns[i] for i in self._finalPatterns.keys()])
+        else:
+            for x, y in sorted(self._finalPatterns.items(), key=lambda x: x[1]):
+                if val > y:
+                    del self._finalPatterns[x]
+                    self._finalPatterns[x] = y
+                    self._finalPatterns = {k: v for k, v in
+                                           sorted(self._finalPatterns.items(), key=lambda item: item[1], reverse=True)}
+                    self._minimum = min([self._finalPatterns[i] for i in self._finalPatterns.keys()])
+                    return
 
     def _Generation(self, prefix, itemSets, tidSets):
-        """
-            Generates the patterns following Equivalence-class methods
+        """Equivalence class is followed  and checks for the patterns generated for periodic-frequent patterns.
 
-            :param prefix :  main equivalence prefix
+            :param prefix:  main equivalence prefix
 
-            :type prefix : partial-periodic item or pattern
+            :type prefix: periodic-frequent item or pattern
 
-            :param itemSets : patterns which are items combined with prefix and satisfying the periodicity
-                            and partial property with their timestamps
+            :param itemSets: patterns which are items combined with prefix and satisfying the periodicity
+                            and frequent with their timestamps
 
-            :type itemSets : list
+            :type itemSets: list
 
-            :param tidSets : timestamps of the items in the argument itemSets
+            :param tidSets: timestamps of the items in the argument itemSets
 
-            :type tidSets : list
-
-
-                    """
+            :type tidSets: list
+        """
         if len(itemSets) == 1:
             i = itemSets[0]
-            tidi = tidSets[0]
-            self._save(prefix, [i], tidi)
+            tidI = tidSets[0]
+            self._save(prefix, [i], tidI)
             return
         for i in range(len(itemSets)):
             itemI = itemSets[i]
             if itemI is None:
                 continue
-            tidSetX = tidSets[i]
+            tidSetI = tidSets[i]
             classItemSets = []
             classTidSets = []
             itemSetX = [itemI]
             for j in range(i + 1, len(itemSets)):
                 itemJ = itemSets[j]
                 tidSetJ = tidSets[j]
-                y = list(set(tidSetX).intersection(tidSetJ))
-                val = self._getPeriodicSupport(y)
-                if val >= self._periodicSupport:
+                y = list(set(tidSetI).intersection(tidSetJ))
+                val = self._getSupportAndPeriod(y)
+                if val >= self._minimum:
                     classItemSets.append(itemJ)
                     classTidSets.append(y)
-            newprefix = list(set(itemSetX)) + prefix
-            self._Generation(newprefix, classItemSets, classTidSets)
-            self._save(prefix, list(set(itemSetX)), tidSetX)
+            newPrefix = list(set(itemSetX)) + prefix
+            self._Generation(newPrefix, classItemSets, classTidSets)
+            self._save(prefix, list(set(itemSetX)), tidSetI)
 
     def startMine(self):
         """
-            Main program start with extracting the periodic frequent items from the database and
-            performs prefix equivalence to form the combinations and generates partial-periodic patterns.
+            Main function of the program
 
         """
-        self._startTime = _ab._time.time()
+        self._startTime = _abstract._time.time()
+        if self._iFile is None:
+            raise Exception("Please enter the file path or file name:")
+        if self._k is None:
+            raise Exception("Please enter the Minimum Support")
         self._creatingItemSets()
-        plist = self._creatingOneitemSets()
-        self._finalPatterns = {}
+        plist = self._frequentOneItem()
         for i in range(len(plist)):
             itemI = plist[i]
-            tidSetX = self._tidList[itemI]
+            tidSetI = self._tidList[itemI]
             itemSetX = [itemI]
             itemSets = []
             tidSets = []
             for j in range(i + 1, len(plist)):
                 itemJ = plist[j]
                 tidSetJ = self._tidList[itemJ]
-                y1 = list(set(tidSetX).intersection(tidSetJ))
-                val = self._getPeriodicSupport(y1)
-                if val >= self._periodicSupport:
+                y1 = list(set(tidSetI).intersection(tidSetJ))
+                val = self._getSupportAndPeriod(y1)
+                if val >= self._minimum:
                     itemSets.append(itemJ)
                     tidSets.append(y1)
             self._Generation(itemSetX, itemSets, tidSets)
-            self._save(None, itemSetX, tidSetX)
-        print("Partial Periodic Patterns were generated successfully using 3PEclat algorithm")
-        self._endTime = _ab._time.time()
-        process = _ab._psutil.Process(_ab._os.getpid())
-        self._memoryRSS = float()
+        print("TopK partial periodic patterns were generated successfully")
+        self._endTime = _abstract._time.time()
+        process = _abstract._psutil.Process(_abstract._os.getpid())
         self._memoryUSS = float()
+        self._memoryRSS = float()
         self._memoryUSS = process.memory_full_info().uss
         self._memoryRSS = process.memory_info().rss
 
     def getMemoryUSS(self):
-        """
-        Total amount of USS memory consumed by the mining process will be retrieved from this function
+        """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
-        :return: returning USS memory consumed by the mining process
+                    :return: returning USS memory consumed by the mining process
 
-        :rtype: float
+                    :rtype: float
         """
 
         return self._memoryUSS
 
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the mining process will be retrieved from this function
 
@@ -378,16 +429,15 @@
 
         :rtype: float
         """
 
         return self._memoryRSS
 
     def getRuntime(self):
-        """
-        Calculating the total amount of runtime taken by the mining process
+        """Calculating the total amount of runtime taken by the mining process
 
         :return: returning total amount of runtime taken by the mining process
 
         :rtype: float
         """
 
         return self._endTime - self._startTime
@@ -396,66 +446,58 @@
         """Storing final frequent patterns in a dataframe
 
         :return: returning frequent patterns in a dataframe
 
         :rtype: pd.DataFrame
         """
 
-        dataframe = {}
+        dataFrame = {}
         data = []
         for a, b in self._finalPatterns.items():
             data.append([a.replace('\t', ' '), b])
-            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'periodicSupport'])
-        return dataframe
+            dataFrame = _abstract._pd.DataFrame(data, columns=['Patterns', 'Support'])
+        return dataFrame
 
     def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
 
         :type outFile: file
         """
         self._oFile = outFile
         writer = open(self._oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            s1 = x.strip() + ":" + str(y)
-            writer.write("%s \n" % s1)
+            patternsAndSupport = x.strip() + ":" + str(y)
+            writer.write("%s \n" % patternsAndSupport)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
 
         :rtype: dict
         """
         return self._finalPatterns
 
     def printResults(self):
-        print("Total number of Partial Periodic Patterns:", len(self.getPatterns()))
+        print("Top K Partial Periodic Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
-        if len(_ab._sys.argv) == 6:
-            _ap = PPP_ECLAT(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
-        if len(_ab._sys.argv) == 5:
-            _ap = PPP_ECLAT(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+    if len(_sys.argv) == 5 or len(_sys.argv) == 6:
+        if len(_sys.argv) == 6:
+            _ap = Topk_PPPGrowth(_sys.argv[1], _sys.argv[3], _sys.argv[4], _sys.argv[5])
+        if len(_sys.argv) == 5:
+            _ap = Topk_PPPGrowth(_sys.argv[1], _sys.argv[3], _sys.argv[4])
         _ap.startMine()
-        print("Total number of Partial Periodic Patterns:", len(_ap.getPatterns()))
-        _ap.save(_ab._sys.argv[2])
+        print("Top K Partial Periodic Patterns:", len(_ap.getPatterns()))
+        _ap.save(_sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
-        for i in [100, 200, 300, 400, 500]:
-            _ap = PPP_ECLAT('/Users/Likhitha/Downloads/temporal_T10I4D100K.csv', i, 5000, '\t')
-            _ap.startMine()
-            print("Total number of Maximal Partial Periodic Patterns:", len(_ap.getPatterns()))
-            _ap.save('/Users/Likhitha/Downloads/output.txt')
-            print("Total Memory in USS:", _ap.getMemoryUSS())
-            print("Total Memory in RSS", _ap.getMemoryRSS())
-            print("Total ExecutionTime in ms:", _ap.getRuntime())
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/basic/__init__.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/basic/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/closed/PPPClose.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/closed/PPPClose.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,115 +1,174 @@
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#    from PAMI.partialPeriodicPattern.closed import PPPClose as alg
+#
+#     obj = alg.PPPClose("../basic/sampleTDB.txt", "2", "6")
+#
+#     obj.startMine()
+#
+#     periodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(periodicFrequentPatterns))
+#
+#     obj.save("patterns")
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+#
+#
+#
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+
+
 import sys as _sys
 import validators as _validators
 from urllib.request import urlopen as _urlopen
 from PAMI.partialPeriodicPattern.closed import abstract as _abstract
 
 
 class PPPClose(_abstract._partialPeriodicPatterns):
-    """ PPPClose algorithm is used to discover the closed partial periodic patterns in temporal databases.
+    """
+    Description:
+    ------------
+        PPPClose algorithm is used to discover the closed partial periodic patterns in temporal databases.
         It uses depth-first search.
 
-        Reference:
-        -------
-        ...
-
-        Attributes:
-        ----------
-            iFile : str
-                Input file name or path of the input file
-            oFile : str
-                Name of the output file or path of the input file
-            periodicSupport: int or float or str
-                The user can specify periodicSupport either in count or proportion of database size.
-                If the program detects the data type of periodicSupport is integer, then it treats periodicSupport is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: periodicSupport=10 will be treated as integer, while periodicSupport=10.0 will be treated as float
-            period: int or float or str
-                The user can specify period either in count or proportion of database size.
-                If the program detects the data type of period is integer, then it treats period is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: period=10 will be treated as integer, while period=10.0 will be treated as float
-            sep : str
-                This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
-                However, the users can override their default separator.
-            startTime:float
-                To record the start time of the mining process
-            endTime:float
-                To record the completion time of the mining process
-            finalPatterns: dict
-                Storing the complete set of patterns in a dictionary variable
-            memoryUSS : float
-                To store the total amount of USS memory consumed by the program
-            memoryRSS : float
-                To store the total amount of RSS memory consumed by the program
-
-        Methods:
-        -------
-
-            startMine()
-                Mining process will start from here
-            getPatterns()
-                Complete set of patterns will be retrieved with this function
-            save(oFile)
-                Complete set of frequent patterns will be loaded in to a output file
-            getPatternsAsDataFrame()
-                Complete set of frequent patterns will be loaded in to a dataframe
-            getMemoryUSS()
-                Total amount of USS memory consumed by the mining process will be retrieved from this function
-            getMemoryRSS()
-                Total amount of RSS memory consumed by the mining process will be retrieved from this function
-            getRuntime()
-                Total amount of runtime taken by the mining process will be retrieved from this function
+    Reference:
+    -------------
+        
+
+    Attributes:
+    ----------
+        iFile : str
+            Input file name or path of the input file
+        oFile : str
+            Name of the output file or path of the input file
+        periodicSupport: int or float or str
+            The user can specify periodicSupport either in count or proportion of database size.
+            If the program detects the data type of periodicSupport is integer, then it treats periodicSupport is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: periodicSupport=10 will be treated as integer, while periodicSupport=10.0 will be treated as float
+        period: int or float or str
+            The user can specify period either in count or proportion of database size.
+            If the program detects the data type of period is integer, then it treats period is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: period=10 will be treated as integer, while period=10.0 will be treated as float
+        sep : str
+            This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
+            However, the users can override their default separator.
+        startTime:float
+            To record the start time of the mining process
+        endTime:float
+            To record the completion time of the mining process
+        finalPatterns: dict
+            Storing the complete set of patterns in a dictionary variable
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
+
+    Methods:
+    ---------
+
+        startMine()
+            Mining process will start from here
+        getPatterns()
+            Complete set of patterns will be retrieved with this function
+        save(oFile)
+            Complete set of frequent patterns will be loaded in to a output file
+        getPatternsAsDataFrame()
+            Complete set of frequent patterns will be loaded in to a dataframe
+        getMemoryUSS()
+            Total amount of USS memory consumed by the mining process will be retrieved from this function
+        getMemoryRSS()
+            Total amount of RSS memory consumed by the mining process will be retrieved from this function
+        getRuntime()
+            Total amount of runtime taken by the mining process will be retrieved from this function
 
-        Executing the code on terminal:
-        -------
+    Executing the code on terminal:
+    -------------------------------
         Format:
-        ------
-            python3 PPPClose.py <inputFile> <outputFile> <periodicSupport> <period>
+        ------------
+           >>> python3 PPPClose.py <inputFile> <outputFile> <periodicSupport> <period>
 
         Examples:
         --------
-            python3 PPPClose.py sampleTDB.txt patterns.txt 0.3 0.4   (periodicSupport and period will be considered in percentage of database
+            >>> python3 PPPClose.py sampleTDB.txt patterns.txt 0.3 0.4   (periodicSupport and period will be considered in percentage of database
         transactions)
 
-            python3 PPPClose.py sampleTDB.txt patterns.txt 3 4     (periodicSupport and period will be considered in support count or frequency)
+            >>> python3 PPPClose.py sampleTDB.txt patterns.txt 3 4     (periodicSupport and period will be considered in support count or frequency)
 
 
-        Sample run of the imported code:
-        --------------
+    Sample run of the imported code:
+    --------------------------------------
+    .. code-block:: python
 
-            from PAMI.partialPeriodicPattern.closed import PPPClose as alg
+        from PAMI.partialPeriodicPattern.closed import PPPClose as alg
 
-            obj = alg.PPPClose("../basic/sampleTDB.txt", "2", "6")
+        obj = alg.PPPClose("../basic/sampleTDB.txt", "2", "6")
 
-            obj.startMine()
+        obj.startMine()
 
-            periodicFrequentPatterns = obj.getPatterns()
+        periodicFrequentPatterns = obj.getPatterns()
 
-            print("Total number of Frequent Patterns:", len(periodicFrequentPatterns))
+        print("Total number of Frequent Patterns:", len(periodicFrequentPatterns))
 
-            obj.save("patterns")
+        obj.save("patterns")
 
-            Df = obj.getPatternsAsDataFrame()
+        Df = obj.getPatternsAsDataFrame()
 
-            memUSS = obj.getMemoryUSS()
+        memUSS = obj.getMemoryUSS()
 
-            print("Total Memory in USS:", memUSS)
+        print("Total Memory in USS:", memUSS)
 
-            memRSS = obj.getMemoryRSS()
+        memRSS = obj.getMemoryRSS()
 
-            print("Total Memory in RSS", memRSS)
+        print("Total Memory in RSS", memRSS)
 
-            run = obj.getRuntime()
+        run = obj.getRuntime()
 
-            print("Total ExecutionTime in seconds:", run)
+        print("Total ExecutionTime in seconds:", run)
 
-        Credits:
-        -------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+    Credits:
+    -------
+        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
 
         """
 
     _periodicSupport = float()
     _period = float()
     _startTime = float()
     _endTime = float()
```

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/closed/abstract.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/closed/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/maximal/Max3PGrowth.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/maximal/Max3PGrowth.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,21 +1,58 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.periodicFrequentPattern.maximal import ThreePGrowth as alg
+#
+#     obj = alg.ThreePGrowth(iFile, periodicSupport, period)
+#
+#     obj.startMine()
+#
+#     partialPeriodicPatterns = obj.partialPeriodicPatterns()
+#
+#     print("Total number of partial periodic Patterns:", len(partialPeriodicPatterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternInDf()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     run = obj.getRuntime()
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 import sys as _sys
 import validators as _validators
 from urllib.request import urlopen as _urlopen
 from PAMI.partialPeriodicPattern.maximal import abstract as _abstract
 
 global maximalTree
@@ -367,110 +404,116 @@
             pat.append(trans)
             timeStamps.append(condTimeStamps[count])
         count += 1
     return pat, timeStamps, updatedDict
 
 
 class Max3PGrowth(_abstract._partialPeriodicPatterns):
-    """ Max3p-Growth algorithm IS to discover maximal periodic-frequent patterns in a temporal database.
+    """
+    Description:
+    ------------
+        Max3p-Growth algorithm IS to discover maximal periodic-frequent patterns in a temporal database.
         It extract the partial periodic patterns from 3p-tree and checks for the maximal property and stores
         all the maximal patterns in max3p-tree and extracts the maximal periodic patterns.
 
-        Reference:
-        --------
+    Reference:
+    -----------
         R. Uday Kiran, Yutaka Watanobe, Bhaskar Chaudhury, Koji Zettsu, Masashi Toyoda, Masaru Kitsuregawa,
         "Discovering Maximal Periodic-Frequent Patterns in Very Large Temporal Databases",
         IEEE 2020, https://ieeexplore.ieee.org/document/9260063
 
-        Attributes:
-        ----------
-            iFile : file
-                Name of the Input file or path of the input file
-            oFile : file
-                Name of the output file or path of the output file
-            periodicSupport: float or int or str
-                The user can specify periodicSupport either in count or proportion of database size.
-                If the program detects the data type of periodicSupport is integer, then it treats periodicSupport is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: periodicSupport=10 will be treated as integer, while periodicSupport=10.0 will be treated as float
-            period: float or int or str
-                The user can specify period either in count or proportion of database size.
-                If the program detects the data type of period is integer, then it treats period is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: period=10 will be treated as integer, while period=10.0 will be treated as float
-            sep : str
-                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                However, the users can override their default separator.
-            memoryUSS : float
-                To store the total amount of USS memory consumed by the program
-            memoryRSS : float
-                To store the total amount of RSS memory consumed by the program
-            startTime:float
-                To record the start time of the mining process
-            endTime:float
-                To record the completion time of the mining process
-            periodicSupport : int/float
-                The user given minimum support
-            period : int/float
-                The user given maximum period
-            Database : list
-                To store the transactions of a database in list
-            mapSupport : Dictionary
-                To maintain the information of item and their frequency
-            lno : int
-                it represents the total no of transaction
-            tree : class
-                it represents the Tree class
-            itemSetCount : int
-                it represents the total no of patterns
-            finalPatterns : dict
-                it represents to store the patterns
-
-        Methods:
-        -------
-            startMine()
-                Mining process will start from here
-            getFrequentPatterns()
-                Complete set of patterns will be retrieved with this function
-            save(oFile)
-                Complete set of periodic-frequent patterns will be loaded in to a output file
-            getPatternsAsDataFrame()
-                Complete set of periodic-frequent patterns will be loaded in to a dataframe
-            getMemoryUSS()
-                Total amount of USS memory consumed by the mining process will be retrieved from this function
-            getMemoryRSS()
-                Total amount of RSS memory consumed by the mining process will be retrieved from this function
-            getRuntime()
-                Total amount of runtime taken by the mining process will be retrieved from this function
-            creatingitemSets(fileName)
-                Scans the dataset or dataframes and stores in list format
-            PeriodicFrequentOneItem()
-                Extracts the one-periodic-frequent patterns from Databases
-            updateDatabases()
-                update the Databases by removing aperiodic items and sort the Database by item decreased support
-            buildTree()
-                after updating the Databases ar added into the tree by setting root node as null
-            startMine()
-                the main method to run the program
-
-        Executing the code on terminal:
-        -------
-            Format:
-            ------
-                python3 max3prowth.py <inputFile> <outputFile> <periodicSupport> <period>
-
-            Examples:
-            --------
-                python3 Max3PGrowth.py sampleTDB.txt patterns.txt 0.3 0.4  (periodicSupport will be considered in percentage of database
+    Attributes:
+    -----------
+
+        iFile : file
+            Name of the Input file or path of the input file
+        oFile : file
+            Name of the output file or path of the output file
+        periodicSupport: float or int or str
+            The user can specify periodicSupport either in count or proportion of database size.
+            If the program detects the data type of periodicSupport is integer, then it treats periodicSupport is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: periodicSupport=10 will be treated as integer, while periodicSupport=10.0 will be treated as float
+        period: float or int or str
+            The user can specify period either in count or proportion of database size.
+            If the program detects the data type of period is integer, then it treats period is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: period=10 will be treated as integer, while period=10.0 will be treated as float
+        sep : str
+            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+            However, the users can override their default separator.
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
+        startTime:float
+            To record the start time of the mining process
+        endTime:float
+            To record the completion time of the mining process
+        periodicSupport : int/float
+            The user given minimum support
+        period : int/float
+            The user given maximum period
+        Database : list
+            To store the transactions of a database in list
+        mapSupport : Dictionary
+            To maintain the information of item and their frequency
+        lno : int
+            it represents the total no of transaction
+        tree : class
+            it represents the Tree class
+        itemSetCount : int
+            it represents the total no of patterns
+        finalPatterns : dict
+            it represents to store the patterns
+
+    Methods:
+    ---------
+        startMine()
+            Mining process will start from here
+        getFrequentPatterns()
+            Complete set of patterns will be retrieved with this function
+        save(oFile)
+            Complete set of periodic-frequent patterns will be loaded in to a output file
+        getPatternsAsDataFrame()
+            Complete set of periodic-frequent patterns will be loaded in to a dataframe
+        getMemoryUSS()
+            Total amount of USS memory consumed by the mining process will be retrieved from this function
+        getMemoryRSS()
+            Total amount of RSS memory consumed by the mining process will be retrieved from this function
+        getRuntime()
+            Total amount of runtime taken by the mining process will be retrieved from this function
+        creatingitemSets(fileName)
+            Scans the dataset or dataframes and stores in list format
+        PeriodicFrequentOneItem()
+            Extracts the one-periodic-frequent patterns from Databases
+        updateDatabases()
+            update the Databases by removing aperiodic items and sort the Database by item decreased support
+        buildTree()
+            after updating the Databases ar added into the tree by setting root node as null
+        startMine()
+            the main method to run the program
+
+    Executing the code on terminal:
+    -------------------------------
+        Format:
+        --------
+            >>> python3 max3prowth.py <inputFile> <outputFile> <periodicSupport> <period>
+
+        Examples:
+        ---------
+            >>>  python3 Max3PGrowth.py sampleTDB.txt patterns.txt 0.3 0.4  (periodicSupport will be considered in percentage of database
                 transactions)
 
-                python3 Max3PGrowth.py sampleTDB.txt patterns.txt 3 4  (periodicSupport will be considered in count)
+            >>>  python3 Max3PGrowth.py sampleTDB.txt patterns.txt 3 4  (periodicSupport will be considered in count)
+
+    Sample run of the importing code:
+    ----------------------------------
+    .. code-block:: python
 
-        Sample run of the importing code:
-        -----------
             from PAMI.periodicFrequentPattern.maximal import ThreePGrowth as alg
 
             obj = alg.ThreePGrowth(iFile, periodicSupport, period)
 
             obj.startMine()
 
             partialPeriodicPatterns = obj.partialPeriodicPatterns()
@@ -490,19 +533,19 @@
             print("Total Memory in RSS", memRSS)
 
             run = obj.getRuntime()
 
             print("Total ExecutionTime in seconds:", run)
 
 
-        Credits:
-        -------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+    Credits:
+    ---------
+        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
 
-        """
+    """
     _startTime = float()
     _endTime = float()
     _periodicSupport = str()
     _period = float()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
```

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/maximal/__init__.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/maximal/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/maximal/abstract.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/maximal/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/timeSeries/PPGrowth.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/timeSeries/PPGrowth.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,21 +1,55 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.periodicFrequentPattern.basic import PPGrowth as alg
+#
+#     obj = alg.PPGrowth(iFile, minSup, maxPer)
+#
+#     obj.startMine()
+#
+#     periodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     print("Total Memory in USS:", memUSS)
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 from PAMI.partialPeriodicPattern.timeSeries import abstract as _ab
 
 
 
 _lno = int()
 _periodicSupport = float()
@@ -259,24 +293,27 @@
             if len(patterns) > 0:
                 for q in conditionalTree.generatePatterns(pattern):
                     yield q
             self.removeNode(i)
 
 
 class PPGrowth(_ab._partialPeriodicPatterns):
-    """ PPGrowth is one of the fundamental algorithm to discover periodic-frequent patterns in a transactional database.
+    """
+    Description:
+    ------------
+        PPGrowth is one of the fundamental algorithm to discover periodic-frequent patterns in a transactional database.
 
     Reference:
-    --------
+    -----------
         C. Saideep, R. Uday Kiran, K. Zettsu, P. Fournier-Viger, M. Kitsuregawa and P. Krishna Reddy,
         "Discovering Periodic Patterns in Irregular Time Series," 2019 International Conference on Data Mining Workshops (ICDMW), 2019,
         pp. 1020-1028, doi: 10.1109/ICDMW.2019.00147.
 
     Attributes:
-    ----------
+    -----------
         iFile : file
             Name of the Input file or path of the input file
         oFile : file
             Name of the output file or path of the output file
         minSup: int or float or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
@@ -308,15 +345,15 @@
             To represents the Tree class
         itemSetCount : int
             To represents the total no of patterns
         finalPatterns : dict
             To store the complete patterns
 
     Methods:
-    -------
+    ---------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of periodic-frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -334,59 +371,59 @@
         updateDatabases()
             Update the database by removing aperiodic items and sort the Database by item decreased support
         buildTree()
             After updating the Database, remaining items will be added into the tree by setting root node as null
         convert()
             to convert the user specified value
 
-        Executing the code on terminal:
-        -------
+    Executing the code on terminal:
+    --------------------------------
         Format:
-        ------
-        python3 PPGrowth.py <inputFile> <outputFile> <minSup> <maxPer>
+        -----------
+           >>> python3 PPGrowth.py <inputFile> <outputFile> <minSup> <maxPer>
 
         Examples:
-        --------
-        python3 PPGrowth.py sampleTDB.txt patterns.txt 0.3 0.4   (minSup and maxPer will be considered in percentage of database
+        ----------
+           >>> python3 PPGrowth.py sampleTDB.txt patterns.txt 0.3 0.4   (minSup and maxPer will be considered in percentage of database
         transactions)
 
-        python3 PPGrowth.py sampleTDB.txt patterns.txt 3 4     (minSup and maxPer will be considered in support count or frequency)
+           >>> python3 PPGrowth.py sampleTDB.txt patterns.txt 3 4     (minSup and maxPer will be considered in support count or frequency)
 
-        Sample run of importing the code:
-        -------------------
+    Sample run of importing the code:
+    ----------------------------------
 
-            from PAMI.periodicFrequentPattern.basic import PPGrowth as alg
+        from PAMI.periodicFrequentPattern.basic import PPGrowth as alg
 
-            obj = alg.PPGrowth(iFile, minSup, maxPer)
+        obj = alg.PPGrowth(iFile, minSup, maxPer)
 
-            obj.startMine()
+        obj.startMine()
 
-            periodicFrequentPatterns = obj.getPatterns()
+        periodicFrequentPatterns = obj.getPatterns()
 
-            print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+        print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
 
-            obj.save(oFile)
+        obj.save(oFile)
 
-            Df = obj.getPatternsAsDataFrame()
+        Df = obj.getPatternsAsDataFrame()
 
-            memUSS = obj.getMemoryUSS()
+        memUSS = obj.getMemoryUSS()
 
-            print("Total Memory in USS:", memUSS)
+        print("Total Memory in USS:", memUSS)
 
-            memRSS = obj.getMemoryRSS()
+        memRSS = obj.getMemoryRSS()
 
-            print("Total Memory in RSS", memRSS)
+        print("Total Memory in RSS", memRSS)
 
-            run = obj.getRuntime()
+        run = obj.getRuntime()
 
-            print("Total ExecutionTime in seconds:", run)
+        print("Total ExecutionTime in seconds:", run)
 
-        Credits:
-        -------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+    Credits:
+    -------
+        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
 
     """
     _startTime = float()
     _endTime = float()
     _periodicSupport = str()
     _period = float()
     _finalPatterns = {}
```

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/timeSeries/abstract.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/timeSeries/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/topk/Topk_PPPGrowth.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/topk/kPFPMiner/kPFPMiner.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,42 +1,79 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     import PAMI.periodicFrequentPattern.kPFPMiner as alg
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     obj = alg.kPFPMiner(iFile, k)
+#
+#     obj.startMine()
+#
+#     periodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of top-k Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 
-from PAMI.partialPeriodicPattern.topk import abstract as _abstract
-import validators as _validators
-from urllib.request import urlopen as _urlopen
-import sys as _sys
+from PAMI.periodicFrequentPattern.topk.kPFPMiner import abstract as _ab
 
 
-class Topk_PPPGrowth(_abstract.partialPeriodicPatterns):
+class kPFPMiner(_ab._periodicFrequentPatterns):
     """
-        Top - K is and algorithm to discover top partial periodic patterns in a temporal  database.
+        Description:
+        ------------
 
-        Reference:
-        ----------
+            Top - K is and algorithm to discover top periodic-frequent patterns in a temporal database.
 
+        Reference:
+        -----------
+            Likhitha, P., Ravikumar, P., Kiran, R.U., Watanobe, Y. (2022).
+            Discovering Top-k Periodic-Frequent Patterns in Very Large Temporal Databases. Big Data Analytics.
+            BDA 2022. Lecture Notes in Computer Science, vol 13773. Springer, Cham. https://doi.org/10.1007/978-3-031-24094-2_14
 
         Attributes:
-        ----------
+        -----------
             iFile : str
                 Input file name or path of the input file
             k: int
-                User specified count of top partial periodic patterns
+                User specified counte of top-k periodic frequent patterns
             sep : str
                 This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
                 However, the users can override their default separator.
             oFile : str
                 Name of the output file or the path of the output file
             startTime:float
                 To record the start time of the mining process
@@ -46,20 +83,20 @@
                 Storing the complete set of patterns in a dictionary variable
             memoryUSS : float
                 To store the total amount of USS memory consumed by the program
             memoryRSS : float
                 To store the total amount of RSS memory consumed by the program
 
         Methods:
-        -------
+        ---------
             startMine()
                 Mining process will start from here
             getPatterns()
                 Complete set of patterns will be retrieved with this function
-            save(oFile)
+            savePatterns(oFile)
                 Complete set of frequent patterns will be loaded in to a output file
             getPatternsAsDataFrame()
                 Complete set of frequent patterns will be loaded in to a dataframe
             getMemoryUSS()
                 Total amount of USS memory consumed by the mining process will be retrieved from this function
             getMemoryRSS()
                 Total amount of RSS memory consumed by the mining process will be retrieved from this function
@@ -75,33 +112,34 @@
                 It will generate the combinations of frequent items from a list of items
 
         Executing the code on terminal:
         -------------------------------
 
             Format:
             ------
-            python3 FAE.py <inputFile> <outputFile> <k> <periodicity>
+            >>> python3 kPFPMiner.py <inputFile> <outputFile> <k>
 
             Examples:
             ---------
-            python3 FAE.py sampleDB.txt patterns.txt 10 3
+            >>> python3 kPFPMiner.py sampleDB.txt patterns.txt 10
 
 
         Sample run of the importing code:
         ---------------------------------
+        .. code-block:: python
 
-            import PAMI.partialPeriodicPattern.topk.Topk_PPPGrowth as alg
+            import PAMI.periodicFrequentPattern.kPFPMiner as alg
 
-            obj = alg.Topk_PPPGrowth(iFile, k, periodicity)
+            obj = alg.kPFPMiner(iFile, k)
 
             obj.startMine()
 
-            partialPeriodicPatterns = obj.getPatterns()
+            periodicFrequentPatterns = obj.getPatterns()
 
-            print("Total number of top partial periodic Patterns:", len(partialPeriodicPatterns))
+            print("Total number of top-k Periodic Frequent Patterns:", len(periodicFrequentPatterns))
 
             obj.save(oFile)
 
             Df = obj.getPatternInDataFrame()
 
             memUSS = obj.getMemoryUSS()
 
@@ -120,199 +158,157 @@
             The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
 
     """
 
     _startTime = float()
     _endTime = float()
     _k = int()
-    _periodicity = " "
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
     _tidList = {}
-    _lno = int()
-    _minimum = int()
-    _mapSupport = {}
+    lno = int()
+    _maximum = int()
 
     def _creatingItemSets(self):
         """
             Storing the complete transactions of the database/input file in a database variable
 
         """
+
         self._Database = []
-        if isinstance(self._iFile, _abstract._pd.DataFrame):
-            timeStamp, data = [], []
+        if isinstance(self._iFile, _ab._pd.DataFrame):
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
-            if 'TS' in i:
-                timeStamp = self._iFile['TS'].tolist()
             if 'Transactions' in i:
-                data = self._iFile['Transactions'].tolist()
-            for i in range(len(data)):
-                tr = [timeStamp[i]]
-                tr = tr + data[i]
-                self._Database.append(tr)
-            self._lno = len(self._Database)
+                self._Database = self._iFile['Transactions'].tolist()
+
             # print(self.Database)
         if isinstance(self._iFile, str):
-            if _validators.url(self._iFile):
-                data = _urlopen(self._iFile)
+            if _ab._validators.url(self._iFile):
+                data = _ab._urlopen(self._iFile)
                 for line in data:
-                    self._lno += 1
+                    line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
                     self._Database.append(temp)
             else:
                 try:
                     with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
-                            self._lno += 1
+                            line.strip()
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
                             self._Database.append(temp)
                 except IOError:
                     print("File Not Found")
                     quit()
-
-    def _convert(self, value):
-        """
-        To convert the given user specified value
-        :param value: user specified value
-        :return: converted value
-        """
-        if type(value) is int:
-            value = int(value)
-        if type(value) is float:
-            value = (len(self._Database) * value)
-        if type(value) is str:
-            if '.' in value:
-                value = float(value)
-                value = (len(self._Database) * value)
-            else:
-                value = int(value)
-        return value
+                    
+    def getPer_Sup(self, tids):
+        tids.sort()
+        cur=0
+        per=list()
+        sup=0
+        #print(tids)
+        for i in range(len(tids)-1):
+            j = i + 1
+            #if tids[j] - cur <= periodicity:
+                #return [0,0]
+            per.append(tids[j] - cur)
+            cur = tids[j]
+        per.append(self.lno - cur)
+        return max(per)
 
     def _frequentOneItem(self):
         """
         Generating one frequent patterns
         """
-
         self._mapSupport = {}
         self._tidList = {}
-        self._periodicity = self._convert(self._periodicity)
-        self._k = int(self._convert(self._k))
+        n = 0
         for line in self._Database:
+            self.lno += 1
             n = int(line[0])
             for i in range(1, len(line)):
                 si = line[i]
                 if self._mapSupport.get(si) is None:
-                    self._mapSupport[si] = [1, 0, n]
+                    self._mapSupport[si] = [1, abs(0 - n), n]
                     self._tidList[si] = [n]
                 else:
                     self._mapSupport[si][0] += 1
-                    period = abs(n - self._mapSupport[si][2])
-                    if period <= self._periodicity:
-                        self._mapSupport[si][1] += 1
+                    self._mapSupport[si][1] = max(self._mapSupport[si][1], abs(n - self._mapSupport[si][2]))
                     self._mapSupport[si][2] = n
                     self._tidList[si].append(n)
         for x, y in self._mapSupport.items():
-            period = abs(self._lno - self._mapSupport[x][2])
-            if period <= self._periodicity:
-                self._mapSupport[x][1] += 1
-        self._mapSupport = {k: v[1] for k, v in self._mapSupport.items()}
-        plist = [key for key, value in sorted(self._mapSupport.items(), key=lambda x: x[0], reverse=True)]
-        self._finalPatterns = {}
+            self._mapSupport[x][1] = max(self._mapSupport[x][1], abs(n - self._mapSupport[x][2]))
+        plist = [key for key, value in sorted(self._mapSupport.items(), key=lambda x: x[1], reverse=True)]
         for i in plist:
-            if self._mapSupport[i] == 0:
-                continue
             if len(self._finalPatterns) >= self._k:
                 break
             else:
-                self._finalPatterns[i] = self._mapSupport[i]
-        print(len(self._finalPatterns),  self._k, self._periodicity)
-        self._minimum = min([self._finalPatterns[i] for i in self._finalPatterns.keys()])
+                self._finalPatterns[i] = self._mapSupport[i][1]
+        self._maximum = max([self._finalPatterns[i] for i in self._finalPatterns.keys()])
         plist = list(self._finalPatterns.keys())
         return plist
 
-    def _getSupportAndPeriod(self, timeStamps):
-        """To calculate the periodicity and support
-        :param timeStamps: Timestamps of an item set
-        :return: support, periodicity
-        """
-
-        timeStamps.sort()
-        sup = 0
-        for j in range(len(timeStamps) - 1):
-            per = abs(timeStamps[j + 1] - timeStamps[j])
-            if per <= self._periodicity:
-                sup += 1
-        return sup
 
     def _save(self, prefix, suffix, tidSetI):
         """Saves the patterns that satisfy the periodic frequent property.
 
             :param prefix: the prefix of a pattern
-
             :type prefix: list
-
             :param suffix: the suffix of a patterns
-
             :type suffix: list
-
             :param tidSetI: the timestamp of a patterns
-
             :type tidSetI: list
         """
 
         if prefix is None:
             prefix = suffix
         else:
             prefix = prefix + suffix
-        val = self._getSupportAndPeriod(tidSetI)
+        val = self.getPer_Sup(tidSetI)
         sample = str()
         for i in prefix:
-            sample = sample + i + "\t"
+            sample = sample + i + " "
         if len(self._finalPatterns) < self._k:
-            if val >= self._minimum:
+            if val < self._maximum:
                 self._finalPatterns[sample] = val
-                self._finalPatterns = {k: v for k, v in
-                                       sorted(self._finalPatterns.items(), key=lambda item: item[1], reverse=True)}
-                self._minimum = min([self._finalPatterns[i] for i in self._finalPatterns.keys()])
+                self._finalPatterns = {k: v for k, v in sorted(self._finalPatterns.items(), key=lambda item: item[1], reverse=True)}
+                self._maximum = max([i for i in self._finalPatterns.values()])
         else:
-            for x, y in sorted(self._finalPatterns.items(), key=lambda x: x[1]):
-                if val > y:
+            for x, y in sorted(self._finalPatterns.items(), key=lambda x: x[1], reverse=True):
+                if val < y:
                     del self._finalPatterns[x]
-                    self._finalPatterns[x] = y
+                    self._finalPatterns[sample] = val
                     self._finalPatterns = {k: v for k, v in
-                                           sorted(self._finalPatterns.items(), key=lambda item: item[1], reverse=True)}
-                    self._minimum = min([self._finalPatterns[i] for i in self._finalPatterns.keys()])
+                                              sorted(self._finalPatterns.items(), key=lambda item: item[1],
+                                                     reverse=True)}
+                    self._maximum = max([i for i in self._finalPatterns.values()])
                     return
 
     def _Generation(self, prefix, itemSets, tidSets):
         """Equivalence class is followed  and checks for the patterns generated for periodic-frequent patterns.
 
             :param prefix:  main equivalence prefix
-
             :type prefix: periodic-frequent item or pattern
-
             :param itemSets: patterns which are items combined with prefix and satisfying the periodicity
                             and frequent with their timestamps
-
             :type itemSets: list
-
             :param tidSets: timestamps of the items in the argument itemSets
-
             :type tidSets: list
-        """
+
+
+                    """
         if len(itemSets) == 1:
             i = itemSets[0]
             tidI = tidSets[0]
             self._save(prefix, [i], tidI)
             return
         for i in range(len(itemSets)):
             itemI = itemSets[i]
@@ -322,54 +318,71 @@
             classItemSets = []
             classTidSets = []
             itemSetX = [itemI]
             for j in range(i + 1, len(itemSets)):
                 itemJ = itemSets[j]
                 tidSetJ = tidSets[j]
                 y = list(set(tidSetI).intersection(tidSetJ))
-                val = self._getSupportAndPeriod(y)
-                if val >= self._minimum:
+                if self.getPer_Sup(y) <= self._maximum:
                     classItemSets.append(itemJ)
                     classTidSets.append(y)
             newPrefix = list(set(itemSetX)) + prefix
             self._Generation(newPrefix, classItemSets, classTidSets)
             self._save(prefix, list(set(itemSetX)), tidSetI)
 
+    def _convert(self, value):
+        """
+        to convert the type of user specified minSup value
+        :param value: user specified minSup value
+        :return: converted type
+        """
+        if type(value) is int:
+            value = int(value)
+        if type(value) is float:
+            value = (len(self._Database) * value)
+        if type(value) is str:
+            if '.' in value:
+                value = float(value)
+                value = ((len(self._Database)) * value)
+            else:
+                value = int(value)
+        return value
+
     def startMine(self):
         """
             Main function of the program
 
         """
-        self._startTime = _abstract._time.time()
+        self._startTime = _ab._time.time()
         if self._iFile is None:
             raise Exception("Please enter the file path or file name:")
         if self._k is None:
             raise Exception("Please enter the Minimum Support")
         self._creatingItemSets()
+        self._k = self._convert(self._k)
         plist = self._frequentOneItem()
         for i in range(len(plist)):
             itemI = plist[i]
             tidSetI = self._tidList[itemI]
             itemSetX = [itemI]
             itemSets = []
             tidSets = []
             for j in range(i + 1, len(plist)):
                 itemJ = plist[j]
                 tidSetJ = self._tidList[itemJ]
                 y1 = list(set(tidSetI).intersection(tidSetJ))
-                val = self._getSupportAndPeriod(y1)
-                if val >= self._minimum:
+                if self.getPer_Sup(y1) <= self._maximum:
                     itemSets.append(itemJ)
                     tidSets.append(y1)
             self._Generation(itemSetX, itemSets, tidSets)
-        print("TopK partial periodic patterns were generated successfully")
-        self._endTime = _abstract._time.time()
-        process = _abstract._psutil.Process(_abstract._os.getpid())
+        print("kPFPMiner has successfully generated top-k frequent patterns")
+        self._endTime = _ab._time.time()
         self._memoryUSS = float()
         self._memoryRSS = float()
+        process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryUSS = process.memory_full_info().uss
         self._memoryRSS = process.memory_info().rss
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
                     :return: returning USS memory consumed by the mining process
@@ -406,55 +419,61 @@
 
         :rtype: pd.DataFrame
         """
 
         dataFrame = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a.replace('\t', ' '), b])
-            dataFrame = _abstract._pd.DataFrame(data, columns=['Patterns', 'Support'])
+            data.append([a, b])
+            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'periodicity'])
         return dataFrame
 
     def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
 
         :type outFile: file
         """
         self._oFile = outFile
         writer = open(self._oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            patternsAndSupport = x.strip() + ":" + str(y)
+            patternsAndSupport = x + ":" + str(y)
             writer.write("%s \n" % patternsAndSupport)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
 
         :rtype: dict
         """
         return self._finalPatterns
 
     def printResults(self):
-        print("Top K Partial Periodic Patterns:", len(self.getPatterns()))
+        print("Total number of  Top-k Periodic Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_sys.argv) == 5 or len(_sys.argv) == 6:
-        if len(_sys.argv) == 6:
-            _ap = Topk_PPPGrowth(_sys.argv[1], _sys.argv[3], _sys.argv[4], _sys.argv[5])
-        if len(_sys.argv) == 5:
-            _ap = Topk_PPPGrowth(_sys.argv[1], _sys.argv[3], _sys.argv[4])
+    if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:
+        if len(_ab._sys.argv) == 5:
+            _ap = kPFPMiner(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+        if len(_ab._sys.argv) == 4:
+            _ap = kPFPMiner(_ab._sys.argv[1], _ab._sys.argv[3])
         _ap.startMine()
-        print("Top K Partial Periodic Patterns:", len(_ap.getPatterns()))
-        _ap.save(_sys.argv[2])
-        print("Total Memory in USS:", _ap.getMemoryUSS())
-        print("Total Memory in RSS", _ap.getMemoryRSS())
-        print("Total ExecutionTime in ms:", _ap.getRuntime())
+        _Patterns = _ap.getPatterns()
+        print("Total number of top-k periodic frequent patterns:", len(_Patterns))
+        _ap.save(_ab._sys.argv[2])
+        _memUSS = _ap.getMemoryUSS()
+        print("Total Memory in USS:", _memUSS)
+        _memRSS = _ap.getMemoryRSS()
+        print("Total Memory in RSS", _memRSS)
+        _run = _ap.getRuntime()
+        print("Total ExecutionTime in ms:", _run)
     else:
         print("Error! The number of input parameters do not match the total number of parameters provided")
+
+
```

### Comparing `pami-2023.4.1/PAMI/partialPeriodicPattern/topk/abstract.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/topk/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/partialPeriodicSpatialPattern/basic/STEclat.py` & `pami-2023.5.1/PAMI/partialPeriodicSpatialPattern/basic/STEclat.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,23 +1,75 @@
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#     import PAMI.partialPeriodicSpatialPattern.STEclat as alg
+#
+#     obj = alg.STEclat("sampleTDB.txt", "sampleN.txt", 3, 4)
+#
+#     obj.startMine()
+#
+#     partialPeriodicSpatialPatterns = obj.getPatterns()
+#
+#     print("Total number of Periodic Spatial Frequent Patterns:", len(partialPeriodicSpatialPatterns))
+#
+#     obj.save("outFile")
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+
 from PAMI.partialPeriodicSpatialPattern.basic import abstract as _ab
 
 
 class STEclat(_ab._partialPeriodicSpatialPatterns):
     """
+    Description:
+    ------------
+       PPGrowth is one of the fundamental algorithm to discover periodic-frequent patterns in a transactional database.
+
 
-    ...
 
     Reference:
-    ---------
+    -----------
         R. Uday Kiran, C. Saideep, K. Zettsu, M. Toyoda, M. Kitsuregawa and P. Krishna Reddy,
         "Discovering Partial Periodic Spatial Patterns in Spatiotemporal Databases," 2019 IEEE International
         Conference on Big Data (Big Data), 2019, pp. 233-238, doi: 10.1109/BigData47090.2019.9005693.
 
-    Attributes :
-    ----------
+    Attributes:
+    ------------
             iFile : str
                 Input file name or path of the input file
             nFile: str:
                Name of Neighbourhood file name
             maxIAT: float or int or str
                 The user can specify maxIAT either in count or proportion of database size.
                 If the program detects the data type of maxIAT is integer, then it treats maxIAT is expressed in count.
@@ -41,16 +93,16 @@
                 Name of the output file to store complete set of frequent patterns
             memoryUSS : float
                 To store the total amount of USS memory consumed by the program
             memoryRSS : float
                 To store the total amount of RSS memory consumed by the program
             Database : list
                 To store the complete set of transactions available in the input database/file
-    Methods :
-    -------
+    Methods:
+    ---------
             startMine()
                 Mining process will start from here
             getPatterns()
                 Complete set of patterns will be retrieved with this function
             save(oFile)
                 Complete set of frequent patterns will be loaded in to a output file
             getPatternsAsDataFrames()
@@ -71,26 +123,27 @@
                 A function to get common neighbours of a itemSet
              mapNeighbours(file):
                 A function to map items to their neighbours
 
     Executing the code on terminal :
     ------------------------------
         Format:
-            python3 STEclat.py <inputFile> <outputFile> <neighbourFile>  <minPS>  <maxIAT> 
+            >>> python3 STEclat.py <inputFile> <outputFile> <neighbourFile>  <minPS>  <maxIAT>
         Examples:
-            python3 STEclat.py sampleTDB.txt output.txt sampleN.txt 0.2 0.5 (maxIAT & minPS will be considered in percentage of database transactions)
+            >>> python3 STEclat.py sampleTDB.txt output.txt sampleN.txt 0.2 0.5 (maxIAT & minPS will be considered in percentage of database transactions)
 
-            python3 STEclat.py sampleTDB.txt output.txt sampleN.txt  5 3 ( maxIAT & minPS will be considered in support count or frequency)
+            >>> python3 STEclat.py sampleTDB.txt output.txt sampleN.txt  5 3 ( maxIAT & minPS will be considered in support count or frequency)
                                                                 (it considers "\t" as separator)
 
-            python3 STEclat.py sampleTDB.txt output.txt sampleN.txt 3 2 ',' (it will consider "," as a separator)
+            >>> python3 STEclat.py sampleTDB.txt output.txt sampleN.txt 3 2 ',' (it will consider "," as a separator)
 
     Sample run of importing the code :
     -------------------------------
-
+    .. code-block:: python
+    
         import PAMI.partialPeriodicSpatialPattern.STEclat as alg
 
         obj = alg.STEclat("sampleTDB.txt", "sampleN.txt", 3, 4)
 
         obj.startMine()
 
         partialPeriodicSpatialPatterns = obj.getPatterns()
```

### Comparing `pami-2023.4.1/PAMI/partialPeriodicSpatialPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/partialPeriodicSpatialPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/periodicCorrelatedPattern/basic/EPCPGrowth.py` & `pami-2023.5.1/PAMI/periodicCorrelatedPattern/basic/EPCPGrowth.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,62 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.periodicCorrelatedPattern.basic import EPCPGrowth as alg
+#
+#     obj = alg.EPCPGrowth(iFile, minSup, minAllCOnf, maxPer, maxPerAllConf)
+#
+#     obj.startMine()
+#
+#     periodicCorrelatedPatterns = obj.getPatterns()
+#
+#     print("Total number of Periodic Frequent Patterns:", len(periodicCorrelatedPatterns))
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     obj.save(oFile)
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+
 import sys
 
 from PAMI.periodicCorrelatedPattern.basic import abstract as _ab
 
 _maxPer = float()
 _minAllConf = float()
 _minSup = float()
@@ -272,22 +313,25 @@
                 if len(patterns) > 0:
                     for q in conditionalTree.generatePatterns(pattern):
                         yield q
             self.removeNode(i)
 
 
 class EPCPGrowth(_ab._periodicCorrelatedPatterns):
-    """ EPCPGrowth is an algorithm to discover periodic-Correlaterd patterns in a temporal database.
+    """
+    Description:
+    ------------
+        EPCPGrowth is an algorithm to discover periodic-Correlaterd patterns in a temporal database.
 
     Reference:
-    --------
+    ----------
         http://www.tkl.iis.u-tokyo.ac.jp/new/uploads/publication_file/file/897/Venkatesh2018_Chapter_DiscoveringPeriodic-Correlated.pdf
 
     Attributes:
-    ----------
+    ------------
         iFile : file
             Name of the Input file or path of the input file
         oFile : file
             Name of the output file or path of the output file
         minSup: int or float or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
@@ -329,15 +373,15 @@
             To represents the Tree class
         itemSetCount : int
             To represents the total no of patterns
         finalPatterns : dict
             To store the complete patterns
 
     Methods:
-    -------
+    ---------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of periodic-frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -355,59 +399,61 @@
         updateDatabases()
             Update the database by removing aperiodic items and sort the Database by item decreased support
         buildTree()
             After updating the Database, remaining items will be added into the tree by setting root node as null
         convert()
             to convert the user specified value
 
-        Executing the code on terminal:
-        -------
+    Executing the code on terminal:
+    -----------------------------------
         Format:
-        ------
-        python3 PFPGrowth.py <inputFile> <outputFile> <minSup> <maxPer>
+        -------
+
+        >>> python3 PFPGrowth.py <inputFile> <outputFile> <minSup> <maxPer>
 
         Examples:
-        --------
-        python3 PFPGrowth.py sampleTDB.txt patterns.txt 0.3 0.4   (minSup and maxPer will be considered in percentage of database
+        ---------
+        >>> python3 PFPGrowth.py sampleTDB.txt patterns.txt 0.3 0.4   (minSup and maxPer will be considered in percentage of database
         transactions)
 
-        python3 PFPGrowth.py sampleTDB.txt patterns.txt 3 4     (minSup and maxPer will be considered in support count or frequency)
+        >>> python3 PFPGrowth.py sampleTDB.txt patterns.txt 3 4     (minSup and maxPer will be considered in support count or frequency)
 
-        Sample run of importing the code:
-        -------------------
+    Sample run of importing the code:
+    -------------------
+    .. code-block:: python
 
-            from PAMI.periodicCorrelatedPattern.basic import EPCPGrowth as alg
+        from PAMI.periodicCorrelatedPattern.basic import EPCPGrowth as alg
 
-            obj = alg.EPCPGrowth(iFile, minSup, minAllCOnf, maxPer, maxPerAllConf)
+        obj = alg.EPCPGrowth(iFile, minSup, minAllCOnf, maxPer, maxPerAllConf)
 
-            obj.startMine()
+        obj.startMine()
 
-            periodicCorrelatedPatterns = obj.getPatterns()
+        periodicCorrelatedPatterns = obj.getPatterns()
 
-            print("Total number of Periodic Frequent Patterns:", len(periodicCorrelatedPatterns))
+        print("Total number of Periodic Frequent Patterns:", len(periodicCorrelatedPatterns))
 
-            obj.save(oFile)
+        obj.save(oFile)
 
-            Df = obj.getPatternsAsDataFrame()
+        Df = obj.getPatternsAsDataFrame()
 
-            memUSS = obj.getMemoryUSS()
+        memUSS = obj.getMemoryUSS()
 
-            print("Total Memory in USS:", memUSS)
+        print("Total Memory in USS:", memUSS)
 
-            memRSS = obj.getMemoryRSS()
+        memRSS = obj.getMemoryRSS()
 
-            print("Total Memory in RSS", memRSS)
+        print("Total Memory in RSS", memRSS)
 
-            run = obj.getRuntime()
+        run = obj.getRuntime()
 
-            print("Total ExecutionTime in seconds:", run)
+        print("Total ExecutionTime in seconds:", run)
 
-        Credits:
-        -------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+    Credits:
+    ---------
+        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
 
     """
     _startTime = float()
     _endTime = float()
     _minSup = str()
     _minAllCOnf = float()
     _maxPer = float()
```

### Comparing `pami-2023.4.1/PAMI/periodicCorrelatedPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/periodicCorrelatedPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/__init__.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/basic/PFECLAT.py` & `pami-2023.5.1/PAMI/partialPeriodicPattern/basic/PPP_ECLAT.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,49 +1,89 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#     from PAMI.periodicFrequentPattern.basic import PPP_ECLAT as alg
+#
+#     obj = alg.PPP_ECLAT(iFile, periodicSupport, period)
+#
+#     obj.startMine()
+#
+#     Patterns = obj.getPatterns()
+#
+#     print("Total number of partial periodic patterns:", len(Patterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
+#     memRSS = obj.getMemoryRSS()
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     print("Total Memory in RSS", memRSS)
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+
 
-from PAMI.periodicFrequentPattern.basic import abstract as _ab
+from PAMI.partialPeriodicPattern.basic import abstract as _ab
 
 
-class PFECLAT(_ab._periodicFrequentPatterns):
-    """ EclatPFP is the fundamental approach to mine the periodic-frequent patterns.
+class PPP_ECLAT(_ab._partialPeriodicPatterns):
+    """
+    Descripition:
+    ----------------------
+        3pEclat is the fundamental approach to mine the partial periodic frequent patterns.
 
-        Reference:
-        --------
-            P. Ravikumar, P.Likhitha, R. Uday kiran, Y. Watanobe, and Koji Zettsu, "Towards efficient discovery of 
-            periodic-frequent patterns in columnar temporal databases", 2021 IEA/AIE.
+    Reference:
+    -----------
+        To be published
 
-    Attributes:
+
+    Parameters:
     ----------
-        iFile : file
+        self.iFile : file
             Name of the Input file or path of the input file
-        oFile : file
+        self. oFile : file
             Name of the output file or path of the output file
-        minSup: int or float or str
-            The user can specify minSup either in count or proportion of database size.
-            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+        periodicSupport: float or int or str
+            The user can specify periodicSupport either in count or proportion of database size.
+            If the program detects the data type of periodicSupport is integer, then it treats periodicSupport is expressed in count.
             Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-        maxPer: int or float or str
-            The user can specify maxPer either in count or proportion of database size.
-            If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
+            Example: periodicSupport=10 will be treated as integer, while periodicSupport=10.0 will be treated as float
+        period: float or int or str
+            The user can specify period either in count or proportion of database size.
+            If the program detects the data type of period is integer, then it treats period is expressed in count.
             Otherwise, it will be treated as float.
-            Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
+            Example: period=10 will be treated as integer, while period=10.0 will be treated as float
         sep : str
             This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
             However, the users can override their default separator.
         memoryUSS : float
             To store the total amount of USS memory consumed by the program
         memoryRSS : float
             To store the total amount of RSS memory consumed by the program
@@ -55,320 +95,413 @@
             To store the transactions of a database in list
         mapSupport : Dictionary
             To maintain the information of item and their frequency
         lno : int
             it represents the total no of transactions
         tree : class
             it represents the Tree class
-        itemSetCount : int
-            it represents the total no of patterns
         finalPatterns : dict
             it represents to store the patterns
         tidList : dict
             stores the timestamps of an item
-        hashing : dict
-            stores the patterns with their support to check for the closed property
 
     Methods:
     -------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
-            Complete set of periodic-frequent patterns will be loaded in to a output file
+            Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
-            Complete set of periodic-frequent patterns will be loaded in to a dataframe
+            Complete set of frequent patterns will be loaded in to a dataframe
         getMemoryUSS()
             Total amount of USS memory consumed by the mining process will be retrieved from this function
         getMemoryRSS()
             Total amount of RSS memory consumed by the mining process will be retrieved from this function
         getRuntime()
             Total amount of runtime taken by the mining process will be retrieved from this function
-        creatingOneItemSets()
-            Scan the database and store the items with their timestamps which are periodic frequent 
+        creatingOneitemSets()
+            Scan the database and store the items with their timestamps which are periodic frequent
         getPeriodAndSupport()
             Calculates the support and period for a list of timestamps.
         Generation()
             Used to implement prefix class equivalence method to generate the periodic patterns recursively
-            
-        Executing the code on terminal:
-        -------
+
+    Executing the code on terminal:
+    ----------------------------------------
+
         Format:
-        ------
-            python3 PFPECLAT.py <inputFile> <outputFile> <minSup>
+        -----------
+           >>> python3 PPP_ECLAT.py <inputFile> <outputFile> <periodicSupport> <period>
 
         Examples:
-        --------
-            python3 PFPECLAT.py sampleDB.txt patterns.txt 10.0   (minSup will be considered in percentage of database transactions)
+        -----------
+           >>> python3 PPP_ECLAT.py sampleDB.txt patterns.txt 0.3 0.4   (periodicSupport and period will be considered in percentage of database transactions)
+
+           >>> python3 threePEeclat.py sampleDB.txt patterns.txt 3 4     (periodicSupport and period will be considered in support count or frequency)
+
 
-            python3 PFPECLAT.py sampleDB.txt patterns.txt 10     (minSup will be considered in support count or frequency)
-        
-        Sample run of the imported code:
-        --------------
-        
-            from PAMI.periodicFrequentPattern.basic import PFPECLAT as alg
+    Sample run of importing the code:
+    -----------------------------------------
+    .. code-block:: python
 
-            obj = alg.PFPECLAT("../basic/sampleTDB.txt", "2", "5")
+        from PAMI.periodicFrequentPattern.basic import PPP_ECLAT as alg
 
-            obj.startMine()
+        obj = alg.PPP_ECLAT(iFile, periodicSupport,period)
 
-            periodicFrequentPatterns = obj.getPatterns()
+        obj.startMine()
 
-            print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+        Patterns = obj.getPatterns()
 
-            obj.save("patterns")
+        print("Total number of partial periodic patterns:", len(Patterns))
 
-            Df = obj.getPatternsAsDataFrame()
+        obj.save(oFile)
 
-            memUSS = obj.getMemoryUSS()
+        Df = obj.getPatternsAsDataFrame()
 
-            print("Total Memory in USS:", memUSS)
+        memUSS = obj.getMemoryUSS()
 
-            memRSS = obj.getMemoryRSS()
+        print("Total Memory in USS:", memUSS)
 
-            print("Total Memory in RSS", memRSS)
+        memRSS = obj.getMemoryRSS()
 
-            run = obj.getRuntime()
+        print("Total Memory in RSS", memRSS)
+
+        run = obj.getRuntime()
+
+        print("Total ExecutionTime in seconds:", run)
+
+    Credits:
+    ------------------
+
+    The complete program was written by P.RaviKumar  under the supervision of Professor Rage Uday Kiran.\n
 
-            print("Total ExecutionTime in seconds:", run)
 
-        Credits:
-        -------
-            The complete program was written by P.RaviKumar  under the supervision of Professor Rage Uday Kiran.\n
 
         """
-    
+    _startTime = float()
+    _endTime = float()
+    _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
-    _dbSize = None
-    _Database = None
-    _minSup = str()
-    _maxPer = str()
-    _tidSet = set()
-    _finalPatterns = {}
-    _startTime = None
-    _endTime = None
     _memoryUSS = float()
     _memoryRSS = float()
-
-    def _getPeriodic(self, tids: set):
-        tidList = list(tids)
-        tidList.sort()
-        tidList.append(self._dbSize)
-        cur = 0
-        per = 0
-        for tid in tidList:
-            per = max(per, tid - cur)
-            if per > self._maxPer:  # early stopping
-                break
-            cur = tid
-        return per
+    _mapSupport = {}
+    _itemsetCount = 0
+    _writer = None
+    _periodicSupport = str()
+    _period = str()
+    _tidList = {}
+    _lno = 0
+    _Database = []
 
     def _convert(self, value):
         """
         To convert the given user specified value
 
         :param value: user specified value
+
         :return: converted value
         """
         if type(value) is int:
             value = int(value)
         if type(value) is float:
-            value = (self._dbSize * value)
+            value = (len(self._Database) * value)
         if type(value) is str:
             if '.' in value:
                 value = float(value)
-                value = (self._dbSize * value)
+                value = (len(self._Database) * value)
             else:
                 value = int(value)
         return value
 
-    def _creatingOneItemSets(self):
-        """Storing the complete transactions of the database/input file in a database variable
+    def _getPeriodicSupport(self, timeStamps):
         """
-        plist = []
-        Database = []
+            calculates the support and periodicity with list of timestamps
+
+            :param timeStamps : timestamps of a pattern
+
+            :type timeStamps : list
+        """
+        timeStamps.sort()
+        per = 0
+        for i in range(len(timeStamps) - 1):
+            j = i + 1
+            if abs(timeStamps[j] - timeStamps[i]) <= self._period:
+                per += 1
+        return per
+
+    def _creatingItemSets(self):
+        self._Database = []
         if isinstance(self._iFile, _ab._pd.DataFrame):
-            ts, data = [], []
+            data, tids = [], []
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'TS' in i:
-                ts = self._iFile['TS'].tolist()
+                tids = self._iFile['TS'].tolist()
             if 'Transactions' in i:
                 data = self._iFile['Transactions'].tolist()
             for i in range(len(data)):
-                tr = [ts[i][0]]
+                tr = [tids[i][0]]
                 tr = tr + data[i]
-                Database.append(tr)
+                self._Database.append(tr)
+            self._lno = len(self._Database)
+
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
                     line.strip()
+                    self._lno += 1
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
-                    Database.append(temp)
+                    self._Database.append(temp)
             else:
                 try:
                     with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
+                            self._lno += 1
                             line.strip()
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
-                            Database.append(temp)
+                            self._Database.append(temp)
                 except IOError:
                     print("File Not Found")
                     quit()
-        tid = 0
-        itemsets = {}  # {key: item, value: list of tids}
-        periodicHelper = {}  # {key: item, value: [period, last_tid]}
-        for line in Database:
-            tid = int(line[0])
-            self._tidSet.add(tid)
-            for item in line[1:]:
-                if item in itemsets:
-                    itemsets[item].add(tid)
-                    periodicHelper[item][0] = max(periodicHelper[item][0],
-                                                  abs(tid - periodicHelper[item][1]))  # update current max period
-                    periodicHelper[item][1] = tid  # update the last tid
+
+    def _creatingOneitemSets(self):
+        """
+           Scans the Temporal database / Input file and stores the 1-length partial-periodic patterns.
+        """
+        plist = []
+        self._tidList = {}
+        self._mapSupport = {}
+        self._period = self._convert(self._period)
+        for line in self._Database:
+            s = line
+            n = int(s[0])
+            for i in range(1, len(s)):
+                si = s[i]
+                if self._mapSupport.get(si) is None:
+                    self._mapSupport[si] = [0, n]
+                    self._tidList[si] = [n]
                 else:
-                    itemsets[item] = {tid}
-                    periodicHelper[item] = [abs(0 - tid), tid]  # initialize helper
+                    lp = n - self._mapSupport[si][1]
+                    if lp <= self._period:
+                        self._mapSupport[si][0] += 1
+                    self._mapSupport[si][1] = n
+                    self._tidList[si].append(n)
+        self._periodicSupport = self._convert(self._periodicSupport)
+        self._mapSupport = {k: v[0] for k, v in self._mapSupport.items() if v[0] >= self._periodicSupport}
+        plist = [key for key, value in sorted(self._mapSupport.items(), key=lambda x: x[1], reverse=True)]
+        return plist
+
+    def _save(self, prefix, suffix, tidSetX):
+        """
+            saves the patterns that satisfy the partial periodic property.
+
+            :param prefix: the prefix of a pattern
+
+            :type prefix: list
+
+            :param suffix : the suffix of a patterns
+
+            :type suffix : list
+
+            :param tidSetX : the timestamp of a patterns
+
+            :type tidSetX : list
+
+
+        """
+        if prefix is None:
+            prefix = suffix
+        else:
+            prefix = prefix + suffix
+        val = self._getPeriodicSupport(tidSetX)
+        if val >= self._periodicSupport:
+            sample = str()
+            for i in prefix:
+                sample = sample + i + "\t"
+            self._finalPatterns[sample] = val
+
+    def _Generation(self, prefix, itemSets, tidSets):
+        """
+            Generates the patterns following Equivalence-class methods
+
+            :param prefix :  main equivalence prefix
+
+            :type prefix : partial-periodic item or pattern
+
+            :param itemSets : patterns which are items combined with prefix and satisfying the periodicity
+                            and partial property with their timestamps
+
+            :type itemSets : list
+
+            :param tidSets : timestamps of the items in the argument itemSets
+
+            :type tidSets : list
+
+
+                    """
+        if len(itemSets) == 1:
+            i = itemSets[0]
+            tidi = tidSets[0]
+            self._save(prefix, [i], tidi)
+            return
+        for i in range(len(itemSets)):
+            itemI = itemSets[i]
+            if itemI is None:
+                continue
+            tidSetX = tidSets[i]
+            classItemSets = []
+            classTidSets = []
+            itemSetX = [itemI]
+            for j in range(i + 1, len(itemSets)):
+                itemJ = itemSets[j]
+                tidSetJ = tidSets[j]
+                y = list(set(tidSetX).intersection(tidSetJ))
+                val = self._getPeriodicSupport(y)
+                if val >= self._periodicSupport:
+                    classItemSets.append(itemJ)
+                    classTidSets.append(y)
+            newprefix = list(set(itemSetX)) + prefix
+            self._Generation(newprefix, classItemSets, classTidSets)
+            self._save(prefix, list(set(itemSetX)), tidSetX)
 
-        # finish all items' period
-        self._dbSize = len(Database)
-        self._minSup = self._convert(self._minSup)
-        self._maxPer = self._convert(self._maxPer)
-        del Database
-        for item, _ in periodicHelper.items():
-            periodicHelper[item][0] = max(periodicHelper[item][0],
-                                          abs(self._dbSize - periodicHelper[item][1]))  # tid of the last transaction
-        candidates = []
-        for item, tids in itemsets.items():
-            per = periodicHelper[item][0]
-            sup = len(tids)
-            if sup >= self._minSup and per <= self._maxPer:
-                candidates.append(item)
-                self._finalPatterns[item] = [sup, per, tids]
-        return candidates
-    
-    def _generateEclat(self, candidates):
-        newCandidates = []
-        for i in range(0, len(candidates)):
-            prefixItem = candidates[i]
-            prefixItemSet = prefixItem.split()
-            for j in range(i + 1, len(candidates)):
-                item = candidates[j]
-                itemSet = item.split()
-                if prefixItemSet[:-1] == itemSet[:-1] and prefixItemSet[-1] != itemSet[-1]:
-                    _value = self._finalPatterns[item][2].intersection(self._finalPatterns[prefixItem][2])
-                    sup = len(_value)
-                    per = self._getPeriodic(_value)
-                    if sup >= self._minSup and per <= self._maxPer:
-                        newItem = prefixItem + " " + itemSet[-1]
-                        self._finalPatterns[newItem] = [sup, per, _value]
-                        newCandidates.append(newItem)
-
-        if len(newCandidates) > 0:
-            self._generateEclat(newCandidates)
-    
     def startMine(self):
+        """
+            Main program start with extracting the periodic frequent items from the database and
+            performs prefix equivalence to form the combinations and generates partial-periodic patterns.
+
+        """
         self._startTime = _ab._time.time()
+        self._creatingItemSets()
+        plist = self._creatingOneitemSets()
         self._finalPatterns = {}
-        frequentSets = self._creatingOneItemSets()
-        self._generateEclat(frequentSets)
+        for i in range(len(plist)):
+            itemI = plist[i]
+            tidSetX = self._tidList[itemI]
+            itemSetX = [itemI]
+            itemSets = []
+            tidSets = []
+            for j in range(i + 1, len(plist)):
+                itemJ = plist[j]
+                tidSetJ = self._tidList[itemJ]
+                y1 = list(set(tidSetX).intersection(tidSetJ))
+                val = self._getPeriodicSupport(y1)
+                if val >= self._periodicSupport:
+                    itemSets.append(itemJ)
+                    tidSets.append(y1)
+            self._Generation(itemSetX, itemSets, tidSets)
+            self._save(None, itemSetX, tidSetX)
+        print("Partial Periodic Patterns were generated successfully using 3PEclat algorithm")
         self._endTime = _ab._time.time()
         process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryRSS = float()
         self._memoryUSS = float()
         self._memoryUSS = process.memory_full_info().uss
         self._memoryRSS = process.memory_info().rss
-        print("Periodic-Frequent patterns were generated successfully using PFECLAT algorithm ")
 
     def getMemoryUSS(self):
-        """Total amount of USS memory consumed by the mining process will be retrieved from this function
+        """
+        Total amount of USS memory consumed by the mining process will be retrieved from this function
 
         :return: returning USS memory consumed by the mining process
+
         :rtype: float
         """
 
         return self._memoryUSS
 
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the mining process will be retrieved from this function
 
         :return: returning RSS memory consumed by the mining process
+
         :rtype: float
         """
 
         return self._memoryRSS
 
     def getRuntime(self):
-        """Calculating the total amount of runtime taken by the mining process
-
+        """
+        Calculating the total amount of runtime taken by the mining process
 
         :return: returning total amount of runtime taken by the mining process
+
         :rtype: float
         """
 
         return self._endTime - self._startTime
 
     def getPatternsAsDataFrame(self):
-        """Storing final periodic-frequent patterns in a dataframe
+        """Storing final frequent patterns in a dataframe
+
+        :return: returning frequent patterns in a dataframe
 
-        :return: returning periodic-frequent patterns in a dataframe
         :rtype: pd.DataFrame
         """
 
         dataframe = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a, b[0], b[1]])
-            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Periodicity'])
+            data.append([a.replace('\t', ' '), b])
+            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'periodicSupport'])
         return dataframe
 
     def save(self, outFile):
-        """Complete set of periodic-frequent patterns will be loaded in to a output file
+        """Complete set of frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
+
         :type outFile: file
         """
         self._oFile = outFile
         writer = open(self._oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            s1 = x.replace(' ', '\t') + ":" + str(y[0]) + ":" + str(y[1])
+            s1 = x.strip() + ":" + str(y)
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
-        """ Function to send the set of periodic-frequent patterns after completion of the mining process
+        """ Function to send the set of frequent patterns after completion of the mining process
+
+        :return: returning frequent patterns
 
-        :return: returning periodic-frequent patterns
         :rtype: dict
         """
         return self._finalPatterns
 
     def printResults(self):
-        print("Total number of Periodic Frequent Patterns:", len(self.getPatterns()))
+        print("Total number of Partial Periodic Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
-                    
+
 
 if __name__ == "__main__":
     _ap = str()
     if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
         if len(_ab._sys.argv) == 6:
-            _ap = PFECLAT(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
+            _ap = PPP_ECLAT(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
         if len(_ab._sys.argv) == 5:
-            _ap = PFECLAT(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+            _ap = PPP_ECLAT(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
         _ap.startMine()
-        print("Total number of Periodic-Frequent Patterns:", len(_ap.getPatterns()))
+        print("Total number of Partial Periodic Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
+        for i in [100, 200, 300, 400, 500]:
+            _ap = PPP_ECLAT('/Users/Likhitha/Downloads/temporal_T10I4D100K.csv', i, 5000, '\t')
+            _ap.startMine()
+            print("Total number of Maximal Partial Periodic Patterns:", len(_ap.getPatterns()))
+            _ap.save('/Users/Likhitha/Downloads/output.txt')
+            print("Total Memory in USS:", _ap.getMemoryUSS())
+            print("Total Memory in RSS", _ap.getMemoryRSS())
+            print("Total ExecutionTime in ms:", _ap.getRuntime())
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/basic/PFPGrowth.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/basic/PFPGrowth.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,21 +1,61 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.periodicFrequentPattern.basic import PFPGrowth as alg
+#
+#     obj = alg.PFPGrowth(iFile, minSup, maxPer)
+#
+#     obj.startMine()
+#
+#     periodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     obj.savePatterns(oFile)
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 from PAMI.periodicFrequentPattern.basic import abstract as _ab
 
 
 _maxPer = float()
 _minSup = float()
 _lno = int()
@@ -257,18 +297,21 @@
             if len(patterns) > 0:
                 for q in conditionalTree.generatePatterns(pattern):
                     yield q
             self.removeNode(i)
 
 
 class PFPGrowth(_ab._periodicFrequentPatterns):
-    """ PFPGrowth is one of the fundamental algorithm to discover periodic-frequent patterns in a transactional database.
+    """
+    Description:
+    -------------
+        PFPGrowth is one of the fundamental algorithm to discover periodic-frequent patterns in a transactional database.
 
     Reference:
-    --------
+    -----------
         Syed Khairuzzaman Tanbeer, Chowdhury Farhan, Byeong-Soo Jeong, and Young-Koo Lee, "Discovering Periodic-Frequent
         Patterns in Transactional Databases", PAKDD 2009, https://doi.org/10.1007/978-3-642-01307-2_24
 
     Attributes:
     ----------
         iFile : file
             Name of the Input file or path of the input file
@@ -331,60 +374,58 @@
         updateDatabases()
             Update the database by removing aperiodic items and sort the Database by item decreased support
         buildTree()
             After updating the Database, remaining items will be added into the tree by setting root node as null
         convert()
             to convert the user specified value
 
-        Executing the code on terminal:
-        -------
-        Format:
-        ------
-        python3 PFPGrowth.py <inputFile> <outputFile> <minSup> <maxPer>
 
-        Examples:
-        --------
-        python3 PFPGrowth.py sampleTDB.txt patterns.txt 0.3 0.4   (minSup and maxPer will be considered in percentage of database
-        transactions)
+    **Methods to execute code on terminal**
 
-        python3 PFPGrowth.py sampleTDB.txt patterns.txt 3 4     (minSup and maxPer will be considered in support count or frequency)
+            Format:
+                      >>>  python3 PFPGrowth.py <inputFile> <outputFile> <minSup> <maxPer>
+            Example:
+                      >>>  python3 PFPGrowth.py sampleTDB.txt patterns.txt 0.3 0.4
 
-        Sample run of importing the code:
-        -------------------
+            .. note:: minSup will be considered in percentage of database transactions
 
-            from PAMI.periodicFrequentPattern.basic import PFPGrowth as alg
 
-            obj = alg.PFPGrowth(iFile, minSup, maxPer)
+    **Importing this algorithm into a python program**
 
-            obj.startMine()
+    .. code-block:: python
 
-            periodicFrequentPatterns = obj.getPatterns()
+                from PAMI.periodicFrequentPattern.basic import PFPGrowth as alg
 
-            print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+                obj = alg.PFPGrowth(iFile, minSup, maxPer)
 
-            obj.save(oFile)
+                obj.startMine()
 
-            Df = obj.getPatternsAsDataFrame()
+                periodicFrequentPatterns = obj.getPatterns()
 
-            memUSS = obj.getMemoryUSS()
+                print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
 
-            print("Total Memory in USS:", memUSS)
+                obj.savePatterns(oFile)
 
-            memRSS = obj.getMemoryRSS()
+                Df = obj.getPatternsAsDataFrame()
 
-            print("Total Memory in RSS", memRSS)
+                memUSS = obj.getMemoryUSS()
 
-            run = obj.getRuntime()
+                print("Total Memory in USS:", memUSS)
 
-            print("Total ExecutionTime in seconds:", run)
+                memRSS = obj.getMemoryRSS()
 
-        Credits:
-        -------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+                print("Total Memory in RSS", memRSS)
+
+                run = obj.getRuntime()
+
+                print("Total ExecutionTime in seconds:", run)
+
+    **Credits:**
 
+             The complete program was written by  P.Likhitha  under the supervision of Professor Rage Uday Kiran.
     """
     _startTime = float()
     _endTime = float()
     _minSup = str()
     _maxPer = float()
     _finalPatterns = {}
     _iFile = " "
```

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/basic/PFPGrowthPlus.py` & `pami-2023.5.1/PAMI/recurringPattern/basic/RPGrowth.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,109 +1,156 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.periodicFrequentPattern.recurring import RPGrowth as alg
+#
+#     obj = alg.RPGrowth(iFile, maxPer, minPS, minRec)
+#
+#     obj.startMine()
+#
+#     periodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
+#     print("Total Memory in USS:", memUSS)
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     memRSS = obj.getMemoryRSS()
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
 
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
 
-from PAMI.periodicFrequentPattern.basic import abstract as _ab
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+from PAMI.recurringPattern.basic import abstract as _ab
 
 _maxPer = float()
-_minSup = float()
+_minPS = float()
+_minRec = float()
 _lno = int()
 
 
 class _Node(object):
     """
-    A class used to represent the node of frequentPatternTree
+        A class used to represent the node of frequentPatternTree
 
-    ...
-    Attributes:
-    ----------
-        item : int
-            storing item of a node
-        timeStamps : list
-            To maintain the timestamps of transaction at the end of the branch
-        parent : node
-            To maintain the parent of every node
-        children : list
-            To maintain the children of node
+        Attributes:
+        ----------
+            item : int or None
+                Storing item of a node
+            timeStamps : list
+                To maintain the timestamps of a database at the end of the branch
+            parent : node
+                To maintain the parent of every node
+            children : list
+                To maintain the children of a node
 
-    Methods:
-    -------
-        addChild(itemName)
-            storing the children to their respective parent nodes
+        Methods:
+        -------
+            addChild(itemName)
+                Storing the children to their respective parent nodes
         """
 
     def __init__(self, item, children):
+        """ Initializing the Node class
+
+        :param item: Storing the item of a node
+        :type item: int or None
+        :param children: To maintain the children of a node
+        :type children: dict
+        """
+
         self.item = item
         self.children = children
         self.parent = None
         self.timeStamps = []
 
     def addChild(self, node):
+        """ To add the children to a node
+
+            :param node: parent node in the tree
+        """
+
         self.children[node.item] = node
         node.parent = self
 
 
 class _Tree(object):
     """
-    A class used to represent the frequentPatternGrowth tree structure
-
-    ...
+        A class used to represent the frequentPatternGrowth tree structure
 
         Attributes:
         ----------
             root : Node
                 Represents the root node of the tree
             summaries : dictionary
-                storing the nodes with same item name
+                Storing the nodes with same item name
             info : dictionary
-                stores the support of items
+                Stores the support of the items
 
 
         Methods:
         -------
-            addTransaction(transaction)
-                creating transaction as a branch in frequentPatternTree
+            addTransactions(Database)
+                Creating transaction as a branch in Recurring PatternTree
             getConditionalPatterns(Node)
-                generates the conditional patterns from tree for specific node
-            conditionalTransactions(prefixPaths,Support)
-                takes the prefixPath of a node and support at child of the path and extract the frequent items from
+                Generates the conditional patterns from tree for specific node
+            conditionalTransaction(prefixPaths,Support)
+                Takes the prefixPath of a node and support at child of the path and extract the frequent patterns from
                 prefixPaths and generates prefixPaths with items which are frequent
             remove(Node)
-                removes the node from tree once after generating all the patterns respective to the node
+                Removes the node from tree once after generating all the patterns respective to the node
             generatePatterns(Node)
-                starts from the root node of the tree and mines the periodic-frequent patterns
+                Starts from the root node of the tree and mines the periodic-frequent patterns
 
         """
 
     def __init__(self):
         self.root = _Node(None, {})
         self.summaries = {}
         self.info = {}
 
     def addTransaction(self, transaction, tid):
-        """
-        adding transaction into tree
+        """     Adding a transaction into tree
 
-                :param transaction : it represents the one transactions in database
-                :type transaction : list
-                :param tid : represents the timestamp of transaction
-                :type tid : list
+                :param transaction: To represent the complete database
+                :type transaction: list
+                :param tid: To represent the timestamp of a database
+                :type tid: list
+                :return: rp-tree
         """
+
         currentNode = self.root
         for i in range(len(transaction)):
             if transaction[i] not in currentNode.children:
                 newNode = _Node(transaction[i], {})
                 currentNode.addChild(newNode)
                 if transaction[i] in self.summaries:
                     self.summaries[transaction[i]].append(newNode)
@@ -111,158 +158,194 @@
                     self.summaries[transaction[i]] = [newNode]
                 currentNode = newNode
             else:
                 currentNode = currentNode.children[transaction[i]]
         currentNode.timeStamps = currentNode.timeStamps + tid
 
     def getConditionalPatterns(self, alpha):
-        """generates all the conditional patterns of respective node
+        """Generates all the conditional patterns of a respective node
 
-                    :param alpha : it represents the Node in tree
-                    :type alpha : Node
+            :param alpha: To represent a Node in the tree
+            :type alpha: Node
+            :return: A tuple consisting of finalPatterns, conditional pattern base and information
         """
         finalPatterns = []
         finalSets = []
         for i in self.summaries[alpha]:
             set1 = i.timeStamps
             set2 = []
             while i.parent.item is not None:
                 set2.append(i.parent.item)
                 i = i.parent
             if len(set2) > 0:
                 set2.reverse()
                 finalPatterns.append(set2)
                 finalSets.append(set1)
-        finalPatterns, finalSets, info = self.conditionalTransactions(finalPatterns, finalSets)
+        finalPatterns, finalSets, info = self.conditionalDatabases(finalPatterns, finalSets)
         return finalPatterns, finalSets, info
 
     @staticmethod
     def generateTimeStamps(node):
+        """To get the timestamps of a node
+
+        :param node: A node in the tree
+        :return: Timestamps of a node
+        """
+
         finalTimeStamps = node.timeStamps
         return finalTimeStamps
 
     def removeNode(self, nodeValue):
-        """removing the node from tree
+        """ Removing the node from tree
+
+            :param nodeValue: To represent a node in the tree
+            :type nodeValue: node
+            :return: Tree with their nodes updated with timestamps
+        """
 
-                        :param nodeValue : it represents the node in tree
-                        :type nodeValue : node
-                        """
         for i in self.summaries[nodeValue]:
             i.parent.timeStamps = i.parent.timeStamps + i.timeStamps
             del i.parent.children[nodeValue]
 
     def getTimeStamps(self, alpha):
+        """ To get all the timestamps of the nodes which share same item name
+
+            :param alpha: Node in a tree
+            :return: Timestamps of a  node
+        """
         temporary = []
         for i in self.summaries[alpha]:
             temporary += i.timeStamps
         return temporary
 
     @staticmethod
     def getSupportAndPeriod(timeStamps):
-        """
-                   calculates the support and periodicity with list of timestamps
-
-                   :param timeStamps : timestamps of a pattern
-                   :type timeStamps : list
+        """To calculate the recurrence and support
 
+        :param timeStamps: Timestamps of an item set
+        :return: recurring intervals with corresponding periodic support, summation of support of periodic intervals, support
+        """
 
-                           """
-        global _maxPer, _lno
+        global _maxPer,_minPS
         timeStamps.sort()
-        cur = 0
-        per = 0
-        sup = 0
-        for j in range(len(timeStamps)):
-            per = max(per, timeStamps[j] - cur)
-            if per > _maxPer:
-                return [0, 0]
-            cur = timeStamps[j]
-            sup += 1
-        per = max(per, _lno - cur)
-        return [sup, per]
-
-    def conditionalTransactions(self, conditionalPatterns, conditionalTimeStamps):
-        """ It generates the conditional patterns with periodic frequent items
-
-                :param conditionalPatterns : conditionalPatterns generated from conditionalPattern method for
-                                    respective node
-                :type conditionalPatterns : list
-                :param conditionalTimeStamps : represents the timestamps of conditional patterns of a node
-                :type conditionalTimeStamps : list
-                """
-        global _maxPer, _minSup
+        cur = ' '
+        st = ' '
+        end = ' '
+        if len(timeStamps) > 0:
+            cur = timeStamps[0]
+            st = timeStamps[0]
+            end = timeStamps[0]
+        ps = 0
+        lps = 1
+        recli = []
+        for i in range(1, len(timeStamps)):
+            if abs(timeStamps[i] - cur) <= _maxPer:
+                lps += 1
+            else:
+                if lps >= _minPS:
+                    recli.append([st, end, lps])
+                    ps += lps
+                lps = 1
+                st = timeStamps[i]
+            cur = timeStamps[i]
+            end = cur
+        if lps >= _minPS:
+            recli.append([st, end, lps])
+            ps+=lps
+        # print(recli)
+        return [recli, ps, len(timeStamps)]
+
+    def conditionalDatabases(self, conditionalPatterns, conditionalTimeStamps):
+        """ It generates the conditional patterns with periodic-frequent items
+
+            :param conditionalPatterns: conditionalPatterns generated from conditionPattern method of a respective node
+            :type conditionalPatterns: list
+            :param conditionalTimeStamps: Represents the timestamps of a conditional patterns of a node
+            :type conditionalTimeStamps: list
+            :returns: Returns conditional transactions by removing non recurring items
+        """
+
+        global _maxPer, _minPS, _minRec
         pat = []
         timeStamps = []
         data1 = {}
         for i in range(len(conditionalPatterns)):
             for j in conditionalPatterns[i]:
                 if j in data1:
                     data1[j] = data1[j] + conditionalTimeStamps[i]
                 else:
                     data1[j] = conditionalTimeStamps[i]
         updatedDictionary = {}
         for m in data1:
             updatedDictionary[m] = self.getSupportAndPeriod(data1[m])
-        updatedDictionary = {k: v for k, v in updatedDictionary.items() if v[0] >= _minSup and v[1] <= _maxPer}
+        # print(updatedDictionary)
+        updatedDictionary = {k: [v[0],v[2]] for k, v in updatedDictionary.items() if v[1] >= (_minPS*_minRec)}
         count = 0
         for p in conditionalPatterns:
             p1 = [v for v in p if v in updatedDictionary]
-            trans = sorted(p1, key=lambda x: (updatedDictionary.get(x)[0], -x), reverse=True)
+            trans = sorted(p1, key=lambda x: (updatedDictionary.get(x)[1], -x), reverse=True)
             if len(trans) > 0:
                 pat.append(trans)
                 timeStamps.append(conditionalTimeStamps[count])
             count += 1
         return pat, timeStamps, updatedDictionary
 
     def generatePatterns(self, prefix):
-        """generates the patterns
+        """ Generates the patterns
 
-                :param prefix : forms the combination of items
-                :type prefix : list
-                """
-        for i in sorted(self.summaries, key=lambda x: (self.info.get(x)[0], -x)):
+            :param prefix: Forms the combination of items
+            :type prefix: list
+            :returns: yields patterns with their recurrence and support
+        """
+        global _minRec
+        for i in sorted(self.summaries, key=lambda x: (self.info.get(x)[1], -x)):
             pattern = prefix[:]
             pattern.append(i)
-            yield pattern, self.info[i]
+            if len(self.info.get(i)[0]) >= _minRec:
+                yield pattern, self.info[i]
             patterns, timeStamps, info = self.getConditionalPatterns(i)
             conditionalTree = _Tree()
             conditionalTree.info = info.copy()
             for pat in range(len(patterns)):
                 conditionalTree.addTransaction(patterns[pat], timeStamps[pat])
             if len(patterns) > 0:
                 for q in conditionalTree.generatePatterns(pattern):
                     yield q
             self.removeNode(i)
 
 
-class PFPGrowthPlus(_ab._periodicFrequentPatterns):
-    """ PFPGrowthPlus is fundamental and improved version of PFPGrowth algorithm to discover periodic-frequent patterns in temporal database.
-        It uses greedy approach to discover effectively
-
-        Reference :
-        --------
-        R. UdayKiran, MasaruKitsuregawa, and P. KrishnaReddyd, "Efficient discovery of periodic-frequent patterns in
-        very large databases," Journal of Systems and Software February 2016 https://doi.org/10.1016/j.jss.2015.10.035
+class RPGrowth(_ab._recurringPatterns):
+    """
+    Description:
+    -------------
+
+         RPGrowth is one of the fundamental algorithm to discover recurring patterns in a transactional database.
+
+    Reference:
+    ------------
+
 
     Attributes:
     ----------
         iFile : file
             Name of the Input file or path of the input file
         oFile : file
             Name of the output file or path of the output file
-        minSup: int or float or str
-            The user can specify minSup either in count or proportion of database size.
-            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
         maxPer: int or float or str
             The user can specify maxPer either in count or proportion of database size.
             If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
             Otherwise, it will be treated as float.
             Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
+        minPS: int or float or str
+            The user can specify minPS either in count or proportion of database size.
+            If the program detects the data type of minPS is integer, then it treats minPS is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minPS=10 will be treated as integer, while minPS=10.0 will be treated as float
+        minRec: int or float or str
+            The user has to specify minRec in count.
         sep : str
             This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
             However, the users can override their default separator.
         memoryUSS : float
             To store the total amount of USS memory consumed by the program
         memoryRSS : float
             To store the total amount of RSS memory consumed by the program
@@ -271,21 +354,21 @@
         endTime:float
             To record the completion time of the mining process
         Database : list
             To store the transactions of a database in list
         mapSupport : Dictionary
             To maintain the information of item and their frequency
         lno : int
-            it represents the total no of transaction
+            To represent the total no of transaction
         tree : class
-            it represents the Tree class
+            To represents the Tree class
         itemSetCount : int
-            it represents the total no of patterns
+            To represents the total no of patterns
         finalPatterns : dict
-            it represents to store the patterns
+            To store the complete patterns
 
     Methods:
     -------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
@@ -295,109 +378,97 @@
             Complete set of periodic-frequent patterns will be loaded in to a dataframe
         getMemoryUSS()
             Total amount of USS memory consumed by the mining process will be retrieved from this function
         getMemoryRSS()
             Total amount of RSS memory consumed by the mining process will be retrieved from this function
         getRuntime()
             Total amount of runtime taken by the mining process will be retrieved from this function
-        check(line)
-            To check the delimiter used in the user input file
         creatingItemSets(fileName)
-            Scans the dataset or dataframes and stores in list format
-        PeriodicFrequentOneItem()
-            Extracts the one-periodic-frequent patterns from Databases
+            Scans the dataset and stores in a list format
+        OneItems()
+            Extracts the possible recurring items of size one from database
         updateDatabases()
-            update the Databases by removing aperiodic items and sort the Database by item decreased support
+            Update the database by removing non recurring items and sort the Database by item decreased support
         buildTree()
-            after updating the Databases ar added into the tree by setting root node as null
-        startMine()
-            the main method to run the program
+            After updating the Database, remaining items will be added into the tree by setting root node as null
+        convert()
+            to convert the user specified value
 
-    Executing the code on terminal:
-    -------
-        Format:
-        ------
-        python3 PFPGrowthPlus.py <inputFile> <outputFile> <minSup> <maxPer>
 
-        Examples:
-        ------
-        python3 PFPGrowthPlus.py sampleTDB.txt patterns.txt 0.3 0.4   (minSup will be considered in percentage of database transactions)
+    **Methods to execute code on terminal**
 
-        python3 PFPGrowthPlus.py sampleTDB.txt patterns.txt 3 4     (minSup will be considered in support count or frequency)
+            Format:
+                      >>>  python3 RPGrowth.py <inputFile> <outputFile> <maxPer> <minPS> <minRec>
+            Example:
+                      >>>  python3 RPGrowth.py sampleTDB.txt patterns.txt 0.3 0.4 2
 
-    Sample run of the imported code:
-    --------------
+            .. note:: maxPer and minPS will be considered in percentage of database transactions
 
-            from PAMI.periodicFrequentPattern.basic import PFPGorwthPlus as alg
 
-            obj = alg.PFPGrowthPlus("../basic/sampleTDB.txt", "2", "6")
+    **Importing this algorithm into a python program**
 
-            obj.startMine()
+    .. code-block:: python
 
-            periodicFrequentPatterns = obj.getPatterns()
+                from PAMI.periodicFrequentPattern.recurring import RPGrowth as alg
 
-            print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+                obj = alg.RPGrowth(iFile, maxPer, minPS, minRec)
 
-            obj.save("patterns")
+                obj.startMine()
 
-            Df = obj.getPatternsAsDataFrame()
+                periodicFrequentPatterns = obj.getPatterns()
 
-            memUSS = obj.getMemoryUSS()
+                print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
 
-            print("Total Memory in USS:", memUSS)
+                obj.savePatterns(oFile)
 
-            memRSS = obj.getMemoryRSS()
+                Df = obj.getPatternsAsDataFrame()
 
-            print("Total Memory in RSS", memRSS)
+                memUSS = obj.getMemoryUSS()
 
-            run = obj.getRuntime()
+                print("Total Memory in USS:", memUSS)
 
-            print("Total ExecutionTime in seconds:", run)
+                memRSS = obj.getMemoryRSS()
 
-        Credits:
-        -------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+                print("Total Memory in RSS", memRSS)
 
-    """
+                run = obj.getRuntime()
+
+                print("Total ExecutionTime in seconds:", run)
+    **Credits:**
 
-    _minSup = str()
-    _maxPer = str()
+             The complete program was written by   C. Saideep  under the supervision of Professor Rage Uday Kiran.
+
+    """
     _startTime = float()
     _endTime = float()
+    _minPS = str()
+    _maxPer = float()
+    _minRec = str()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
     _rank = {}
     _rankedUp = {}
     _lno = 0
 
     def _creatingItemSets(self):
+        """ Storing the complete values of the database/input file in a database variable
         """
-            Storing the complete transactions of the database/input file in a database variable
-
 
-        """
         self._Database = []
         if isinstance(self._iFile, _ab._pd.DataFrame):
-            data, ts = [], []
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
-            if 'TS' in i:
-                ts = self._iFile['TS'].tolist()
             if 'Transactions' in i:
-                data = self._iFile['Transactions'].tolist()
-            for i in range(len(data)):
-                tr = [ts[i][0]]
-                tr = tr + data[i]
-                self._Database.append(tr)
+                self._Database = self._iFile['Transactions'].tolist()
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
@@ -411,93 +482,98 @@
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
                             self._Database.append(temp)
                 except IOError:
                     print("File Not Found")
                     quit()
 
-    def _periodicFrequentOneItem(self):
-        """
-            calculates the support of each item in the dataset and assign the ranks to the items
-            by decreasing support and returns the frequent items list
+    def _OneItems(self):
+        """ Calculates the maxRec and support of each item in the database and assign ranks to the items
+            by decreasing support and returns the RP-list
 
-            """
+            :returns: return the RP-list
+        """
+        #global rank
         data = {}
         for tr in self._Database:
-            n = int(tr[0])
             for i in range(1, len(tr)):
-                if n <= self._maxPer:
-                    if tr[i] not in data:
-                        data[tr[i]] = [int(tr[0]), int(tr[0]), 1]
+                if tr[i] not in data:
+                    data[tr[i]] = [[], int(tr[0]), int(tr[0]), 1, 0, 1]
+                else:
+                    lp = int(tr[0]) - data[tr[i]][2]
+                    if lp <= self._maxPer:
+                        data[tr[i]][3] += 1
+
                     else:
-                        data[tr[i]][0] = max(data[tr[i]][0], (int(tr[0]) - data[tr[i]][1]))
+                        if data[tr[i]][3] >= self._minPS:
+                            data[tr[i]][0].append([data[tr[i]][1], data[tr[i]][2], data[tr[i]][3]])
+                            data[tr[i]][4] += data[tr[i]][3]
+                        data[tr[i]][3] = 1
                         data[tr[i]][1] = int(tr[0])
-                        data[tr[i]][2] += 1
-                else:
-                    if tr[i] in data:
-                        lp = abs(n - data[tr[i]][1])
-                        if lp > self._maxPer:
-                            del data[tr[i]]
-                        else:
-                            data[tr[i]][0] = max(data[tr[i]][0], lp)
-                            data[tr[i]][1] = int(tr[0])
-                            data[tr[i]][2] += 1
-        for key in data:
-            data[key][0] = max(data[key][0], _lno - data[key][1])
-        data = {k: [v[2], v[0]] for k, v in data.items() if v[0] <= self._maxPer and v[2] >= self._minSup}
-        genList = [k for k, v in sorted(data.items(), key=lambda x: (x[1][0], x[0]), reverse=True)]
+                    data[tr[i]][2] = int(tr[0])
+                    data[tr[i]][5] += 1
+            # print(data)
+           
+        for ri in data:
+            if data[ri][3] >= self._minPS:
+                data[ri][0].append([data[ri][1], data[ri][2], data[ri][3]])
+                data[ri][4] += data[ri][3]
+        data = {k: [v[0], v[5]] for k, v in data.items() if v[4] >= (self._minPS*self._minRec)}
+        genList = [k for k, v in sorted(data.items(), key=lambda x: (x[1][1], x[0]), reverse=True)]
         self._rank = dict([(index, item) for (item, index) in enumerate(genList)])
-        # genList=[k for k,v in sorted(data.items(),key=lambda x: (x[1][0],x[0]),reverse=True)]
         return data, genList
 
-    def _updateTransactions(self, dict1):
-        """remove the items which are not frequent from transactions and updates the transactions with rank of items
+    def _updateDatabases(self, dict1):
+        """ Remove the items which does not  satisfy maxRec from database and updates the database with rank of items
 
-            :param dict1 : frequent items with support
-            :type dict1 : dictionary
+            :param dict1: Recurring items with support and recurrence
+            :type dict1: dictionary
+            :return: Sorted and updated transactions
             """
         list1 = []
         for tr in self._Database:
             list2 = [int(tr[0])]
             for i in range(1, len(tr)):
                 if tr[i] in dict1:
                     list2.append(self._rank[tr[i]])
             if len(list2) >= 2:
                 basket = list2[1:]
                 basket.sort()
                 list2[1:] = basket[0:]
                 list1.append(list2)
+                # print(list2)
         return list1
 
     @staticmethod
     def _buildTree(data, info):
-        """it takes the transactions and support of each item and construct the main tree with setting root
-                    node as null
+        """ It takes the database and construct the main tree by setting root node as a null
+
+            :param data: it represents the one items in database
+            :type data: list
+            :param info: it represents the support and recurrence of each item
+            :type info: dictionary
+            :return: returns root node of tree
+        """
 
-                        :param data : it represents the one transactions in database
-                        :type data : list
-                        :param info : it represents the support of each item
-                        :type info : dictionary
-                        """
         rootNode = _Tree()
         rootNode.info = info.copy()
         for i in range(len(data)):
             set1 = [data[i][0]]
             rootNode.addTransaction(data[i][1:], set1)
         return rootNode
 
     def _savePeriodic(self, itemSet):
-        """
-        To convert item ranks into original item names
-        :param itemSet: periodic-frequent pattern
-        :return: original itemSet
+        """ To convert the ranks of items in to their original item names
+
+            :param itemSet: recurring pattern
+            :return: recurring pattern with original item names
         """
         t1 = str()
         for i in itemSet:
-            t1 = t1 + self._rankedUp[i] + " "
+            t1 = t1 + self._rankedUp[i] + "\t"
         return t1
 
     def _convert(self, value):
         """
         To convert the given user specified value
 
         :param value: user specified value
@@ -512,46 +588,44 @@
                 value = float(value)
                 value = (len(self._Database) * value)
             else:
                 value = int(value)
         return value
 
     def startMine(self):
+        """ Mining process will start from this function
         """
-            Main method where the patterns are mined by constructing tree.
 
-        """
-        global _minSup, _maxPer, _lno
+        global _minPS, _minRec, _maxPer, _lno
         self._startTime = _ab._time.time()
         if self._iFile is None:
             raise Exception("Please enter the file path or file name:")
-        if self._minSup is None:
-            raise Exception("Please enter the Minimum Support")
         self._creatingItemSets()
-        self._minSup = self._convert(self._minSup)
+        self._minPS = self._convert(self._minPS)
         self._maxPer = self._convert(self._maxPer)
-        _minSup, _maxPer, _lno = self._minSup, self._maxPer, len(self._Database)
-        generatedItems, pfList = self._periodicFrequentOneItem()
-        updatedTransactions = self._updateTransactions(generatedItems)
+        self._minRec = int(self._minRec)
+        self._finalPatterns = {}
+        _maxPer, _minPS, _minRec, _lno = self._maxPer, self._minPS, self._minRec, len(self._Database)
+        generatedItems, pfList = self._OneItems()
+        updatedDatabases = self._updateDatabases(generatedItems)
         for x, y in self._rank.items():
             self._rankedUp[y] = x
         info = {self._rank[k]: v for k, v in generatedItems.items()}
-        Tree = self._buildTree(updatedTransactions, info)
+        Tree = self._buildTree(updatedDatabases, info)
         patterns = Tree.generatePatterns([])
-        self._finalPatterns = {}
         for i in patterns:
-            x = self._savePeriodic(i[0])
-            self._finalPatterns[x] = i[1]
+            sample = self._savePeriodic(i[0])
+            self._finalPatterns[sample] = i[1]
         self._endTime = _ab._time.time()
         process = _ab._psutil.Process(_ab._os.getpid())
-        self._memoryRSS = float()
         self._memoryUSS = float()
+        self._memoryRSS = float()
         self._memoryUSS = process.memory_full_info().uss
         self._memoryRSS = process.memory_info().rss
-        print("periodic-frequent patterns were generated successfully using PFPGrowth++ algorithm ")
+        print("Recurring patterns were generated successfully using RPGrowth algorithm ")
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
         :return: returning USS memory consumed by the mining process
         :rtype: float
         """
@@ -580,56 +654,72 @@
     def getPatternsAsDataFrame(self):
         """Storing final periodic-frequent patterns in a dataframe
 
         :return: returning periodic-frequent patterns in a dataframe
         :rtype: pd.DataFrame
         """
 
-        dataframe = {}
+        dataFrame = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a, b[0], b[1]])
-            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Periodicity'])
-        return dataframe
+            s = str()
+            for i in a:
+                s = s + i + ' '
+            z = []
+            str1 = '{'
+            for z in b[0]:
+                str1 += '{' + str([z[0], z[1]]) + ' : ' + str(z[2]) + '}'
+            str1 += '}'
+            data.append([s.replace('\t', ' '), b[1], len(b[0]), str1])
+            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Recurrance', 'intervals'])
+        return dataFrame
 
     def save(self, outFile):
         """Complete set of periodic-frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
         :type outFile: file
         """
         self._oFile = outFile
         writer = open(self._oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            s1 = x.replace(' ','\t').strip() + ":" + str(y[0]) + ":" + str(y[1])
+            s = str()
+            for i in x:
+                s = s + i + '\t'
+            str1 = '{'
+            for z in y[0]:
+                str1 += '{'+str([z[0], z[1]])+' : ' + str(z[2]) + '}'
+            str1 += '}'
+            s1 = s.strip() + ":" + str(y[1]) + ":" + str(len(y[0])) + ":" + str1
             writer.write("%s \n" % s1)
+        writer.close()
 
     def getPatterns(self):
         """ Function to send the set of periodic-frequent patterns after completion of the mining process
 
         :return: returning periodic-frequent patterns
         :rtype: dict
         """
         return self._finalPatterns
 
     def printResults(self):
-        print("Total number of Periodic Frequent Patterns:", len(self.getPatterns()))
+        print("Total number of recurrent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
+    if len(_ab._sys.argv) == 6 or len(_ab._sys.argv) == 7:
+        if len(_ab._sys.argv) == 7:
+            _ap = RPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5], _ab._sys.argv[6])
         if len(_ab._sys.argv) == 6:
-            _ap = PFPGrowthPlus(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
-        if len(_ab._sys.argv) == 5:
-            _ap = PFPGrowthPlus(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+            _ap = RPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
         _ap.startMine()
-        print("Total number of Periodic-Frequent Patterns:", len(_ap.getPatterns()))
+        print("Total number of Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/basic/PFPMC.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/basic/PFPMC.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,32 +1,73 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.periodicFrequentPattern.basic import PFPMC as alg
+#
+#     obj = alg.PFPMC("../basic/sampleTDB.txt", "2", "5")
+#
+#     obj.startMine()
+#
+#     periodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+#
+#     obj.savePatterns("patterns")
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     memRSS = obj.getMemoryRSS()
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 from itertools import groupby as _groupby
 from operator import itemgetter as _itemgetter
 from PAMI.periodicFrequentPattern.basic import abstract as _ab
 
 
 class PFPMC(_ab._periodicFrequentPatterns):
-    """ EclatDiffset PFP is the fundamental approach to mine the periodic-frequent patterns.
+    """
+    Description:
+    ------------
+
+     EclatDiffset PFP is the fundamental approach to mine the periodic-frequent patterns.
 
     Reference:
-    --------
+    --------------
 
 
     Attributes:
     ----------
         iFile : file
             Name of the Input file or path of the input file
         oFile : file
@@ -88,58 +129,58 @@
         creatingOneItemSets()
             Scan the database and store the items with their timestamps which are periodic frequent
         getPeriodAndSupport()
             Calculates the support and period for a list of timestamps.
         Generation()
             Used to implement prefix class equivalence method to generate the periodic patterns recursively
 
-        Executing the code on terminal:
-        -------
-        Format:
-        ------
-            python3 PFPMC.py <inputFile> <outputFile> <minSup> <maxPer>
 
-        Examples:
-        --------
-            python3 PFPMC.py sampleDB.txt patterns.txt 10.0 4.0   (minSup & maxPer will be considered in percentage of database transactions)
+    **Methods to execute code on terminal**
+
+            Format:
+                      >>>   python3 PFPMC.py <inputFile> <outputFile> <minSup> <maxPer>
+            Example:
+                      >>>   python3 PFPMC.py sampleDB.txt patterns.txt 10.0 4.0
+    
+            .. note:: minSup and maxPer will be considered in percentage of database transactions
+
+
+    **Importing this algorithm into a python program**
 
-            python3 PFPMC.py sampleDB.txt patterns.txt 10 4     (minSup & maxPer will be considered in support count or frequency)
+    .. code-block:: python
 
-        Sample run of the imported code:
-        --------------
+                from PAMI.periodicFrequentPattern.basic import PFPMC as alg
 
-            from PAMI.periodicFrequentPattern.basic import PFPMC as alg
+                obj = alg.PFPMC("../basic/sampleTDB.txt", "2", "5")
 
-            obj = alg.PFPMC("../basic/sampleTDB.txt", "2", "5")
+                obj.startMine()
 
-            obj.startMine()
+                periodicFrequentPatterns = obj.getPatterns()
 
-            periodicFrequentPatterns = obj.getPatterns()
+                print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
 
-            print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+                obj.savePatterns("patterns")
 
-            obj.save("patterns")
+                Df = obj.getPatternsAsDataFrame()
 
-            Df = obj.getPatternsAsDataFrame()
+                memUSS = obj.getMemoryUSS()
 
-            memUSS = obj.getMemoryUSS()
+                print("Total Memory in USS:", memUSS)
 
-            print("Total Memory in USS:", memUSS)
+                memRSS = obj.getMemoryRSS()
 
-            memRSS = obj.getMemoryRSS()
+                print("Total Memory in RSS", memRSS)
 
-            print("Total Memory in RSS", memRSS)
+                run = obj.getRuntime()
 
-            run = obj.getRuntime()
+                print("Total ExecutionTime in seconds:", run)
 
-            print("Total ExecutionTime in seconds:", run)
+    **Credits:**
 
-        Credits:
-        -------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+             The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
 
         """
 
     _iFile = " "
     _oFile = " "
     _sep = " "
     _dbSize = None
```

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/basic/PSGrowth.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/basic/PSGrowth.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,21 +1,59 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.periodicFrequentPattern.basic import PSGrowth as alg
+#
+#     obj = alg.PSGrowth("../basic/sampleTDB.txt", "2", "6")
+#
+#     obj.startMine()
+#
+#     periodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of  Patterns:", len(periodicFrequentPatterns))
+#
+#     obj.savePatterns("patterns")
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     run = obj.getRuntime()
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     print("Total ExecutionTime in seconds:", run)
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 from itertools import combinations as _combinations
 from PAMI.periodicFrequentPattern.basic import abstract as _ab
 
 _pfList = []
 _minSup = int()
 _maxPer = int()
@@ -518,15 +556,19 @@
             pat.append(trans)
             timeStamps.append(timestamp[count])
         count += 1
     return pat, timeStamps, updatedDict
 
 
 class PSGrowth(_ab._periodicFrequentPatterns):
-    """PS-Growth is one of the fundamental algorithm to discover periodic-frequent patterns in a temporal database.
+    """
+    Description:
+    ------------
+
+        PS-Growth is one of the fundamental algorithm to discover periodic-frequent patterns in a temporal database.
 
     Reference :
     ----------
         A. Anirudh, R. U. Kiran, P. K. Reddy and M. Kitsuregaway, "Memory efficient mining of periodic-frequent
         patterns in transactional databases," 2016 IEEE Symposium Series on Computational Intelligence (SSCI),
         2016, pp. 1-8, https://doi.org/10.1109/SSCI.2016.7849926
 
@@ -587,60 +629,58 @@
         getRuntime()
             Total amount of runtime taken by the mining process will be retrieved from this function
         OneLengthItems()
             Scans the dataset or dataframes and stores in list format
         buildTree()
             after updating the Databases ar added into the tree by setting root node as null
 
-    Executing the code on terminal:
-    -------
-        Format:
-        ------
-        python3 PSGrowth.py <inputFile> <outputFile> <minSup> <maxPer>
 
-        Examples:
-        --------
-        python3 PSGrowth.py sampleTDB.txt patterns.txt 0.3 0.4   (minSup and maxPer will be considered in percentage of database
-        transactions)
+    **Methods to execute code on terminal**
 
-        python3 PSGrowth.py sampleTDB.txt patterns.txt 3 4     (minSup and maxPer will be considered in support count or frequency)
+            Format:
+                      >>>  python3 PSGrowth.py <inputFile> <outputFile> <minSup> <maxPer>
+            Example:
+                      >>>  python3 PSGrowth.py sampleTDB.txt patterns.txt 0.3 0.4
 
+            .. note:: minSup will be considered in percentage of database transactions
 
-    Sample run of the imported code:
-    --------------
 
-        from PAMI.periodicFrequentPattern.basic import PSGrowth as alg
+    **Importing this algorithm into a python program**
 
-        obj = alg.PSGrowth("../basic/sampleTDB.txt", "2", "6")
+    .. code-block:: python
 
-        obj.startMine()
+            from PAMI.periodicFrequentPattern.basic import PSGrowth as alg
 
-        periodicFrequentPatterns = obj.getPatterns()
+            obj = alg.PSGrowth("../basic/sampleTDB.txt", "2", "6")
 
-        print("Total number of  Patterns:", len(periodicFrequentPatterns))
+            obj.startMine()
 
-        obj.save("patterns")
+            periodicFrequentPatterns = obj.getPatterns()
 
-        Df = obj.getPatternsAsDataFrame()
+            print("Total number of  Patterns:", len(periodicFrequentPatterns))
 
-        memUSS = obj.getMemoryUSS()
+            obj.savePatterns("patterns")
 
-        print("Total Memory in USS:", memUSS)
+            Df = obj.getPatternsAsDataFrame()
 
-        memRSS = obj.getMemoryRSS()
+            memUSS = obj.getMemoryUSS()
 
-        print("Total Memory in RSS", memRSS)
+            print("Total Memory in USS:", memUSS)
 
-        run = obj.getRuntime()
+            memRSS = obj.getMemoryRSS()
 
-        print("Total ExecutionTime in seconds:", run)
+            print("Total Memory in RSS", memRSS)
 
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+            run = obj.getRuntime()
+
+            print("Total ExecutionTime in seconds:", run)
+
+    **Credits:**
+
+             The complete program was written by  P.Likhitha   under the supervision of Professor Rage Uday Kiran.
 
     """
 
     _startTime = float()
     _endTime = float()
     _minSup = str()
     _maxPer = str()
```

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/basic/__init__.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/basic/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/closed/CPFPMiner.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/closed/CPFPMiner.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,20 +1,76 @@
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.periodicFrequentPattern.closed import CPFPMiner as alg
+#
+#     obj = alg.CPFPMiner("../basic/sampleTDB.txt", "2", "6")
+#
+#     obj.startMine()
+#
+#     periodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(periodicFrequentPatterns))
+#
+#     obj.savePatterns("patterns")
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+
 from PAMI.periodicFrequentPattern.closed import abstract as _ab
 
 
 class CPFPMiner(_ab._periodicFrequentPatterns):
-    """ CPFPMiner algorithm is used to discover the closed periodic frequent patterns in temporal databases.
-        It uses depth-first search.
+    """ 
+        Description:
+        ------------
+         
+            CPFPMiner algorithm is used to discover the closed periodic frequent patterns in temporal databases.
+            It uses depth-first search.
 
         Reference:
         -------
             P. Likhitha et al., "Discovering Closed Periodic-Frequent Patterns in Very Large Temporal Databases"
             2020 IEEE International Conference on Big Data (Big Data), 2020, https://ieeexplore.ieee.org/document/9378215
 
-        ...
+      
         Attributes:
         ----------
             iFile : str
                 Input file name or path of the input file
             oFile : str
                 Name of the output file or path of the input file
             minSup: int or float or str
@@ -55,60 +111,59 @@
             getMemoryUSS()
                 Total amount of USS memory consumed by the mining process will be retrieved from this function
             getMemoryRSS()
                 Total amount of RSS memory consumed by the mining process will be retrieved from this function
             getRuntime()
                 Total amount of runtime taken by the mining process will be retrieved from this function
 
-        Executing the code on terminal:
-        -------
-        Format:
-        ------
-        python3 CPFPMiner.py <inputFile> <outputFile> <minSup> <maxPer>
-
-        Examples:
-        --------
-        python3 CPFPMiner.py sampleTDB.txt patterns.txt 0.3 0.4   (minSup and maxPer will be considered in percentage of database
-        transactions)
-
-        python3 CPFPMiner.py sampleTDB.txt patterns.txt 3 4     (minSup and maxPer will be considered in support count or frequency)
+                
+        **Methods to execute code on terminal**
         
+                Format:
+                          >>>  python3 CPFPMiner.py <inputFile> <outputFile> <minSup> <maxPer>
+                Example:
+                          >>>  python3 CPFPMiner.py sampleTDB.txt patterns.txt 0.3 0.4
         
-        Sample run of the imported code:
-        --------------
-
-            from PAMI.periodicFrequentPattern.closed import CPFPMiner as alg
-
-            obj = alg.CPFPMiner("../basic/sampleTDB.txt", "2", "6")
-
-            obj.startMine()
-
-            periodicFrequentPatterns = obj.getPatterns()
-
-            print("Total number of Frequent Patterns:", len(periodicFrequentPatterns))
-
-            obj.save("patterns")
-
-            Df = obj.getPatternsAsDataFrame()
-
-            memUSS = obj.getMemoryUSS()
-
-            print("Total Memory in USS:", memUSS)
-
-            memRSS = obj.getMemoryRSS()
-
-            print("Total Memory in RSS", memRSS)
-
-            run = obj.getRuntime()
-
-            print("Total ExecutionTime in seconds:", run)
+                .. note:: minSup will be considered in percentage of database transactions
+        
+        
+        **Importing this algorithm into a python program**
+        
+        .. code-block:: python
+        
+                    from PAMI.periodicFrequentPattern.closed import CPFPMiner as alg
+        
+                    obj = alg.CPFPMiner("../basic/sampleTDB.txt", "2", "6")
+        
+                    obj.startMine()
+        
+                    periodicFrequentPatterns = obj.getPatterns()
+        
+                    print("Total number of Frequent Patterns:", len(periodicFrequentPatterns))
+        
+                    obj.savePatterns("patterns")
+        
+                    Df = obj.getPatternsAsDataFrame()
+        
+                    memUSS = obj.getMemoryUSS()
+        
+                    print("Total Memory in USS:", memUSS)
+        
+                    memRSS = obj.getMemoryRSS()
+        
+                    print("Total Memory in RSS", memRSS)
+        
+                    run = obj.getRuntime()
+        
+                    print("Total ExecutionTime in seconds:", run)
+        
+        **Credits:**
+        
+                 The complete program was written by  P.Likhitha under the supervision of Professor Rage Uday Kiran.
 
-        Credits:
-        -------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
 
         """
 
     _minSup = float()
     _maxPer = float()
     _startTime = float()
     _endTime = float()
```

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/closed/__init__.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/closed/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/closed/abstract.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/closed/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/cuda/gPFMinerBit.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/cuda/gPFMinerBit.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,174 +1,249 @@
 
-#  Copyright (C)  2021 Rage Uday Kiran
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from cudaAlgorithms import gPFMinerBit
+#
+#     obj = gPFMinerBit.gPFMinerBit("data.txt", 2, 3)
+#
+#     obj.run()
+#
+#     print(obj.getPatterns())
+#
+#     print(obj.getRuntime())
+#
+#     print(obj.getMemoryRSS())
+#
+#     print(obj.getMemoryUSS())
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     print(obj.getGPUMemory())
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
 
 
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 
 import os
 import sys
 import csv
 import time
 import psutil
 import numpy as np
-import pycuda.autoinit
-import pycuda.driver as cuda
-from pycuda.compiler import SourceModule
-
-supportAndPeriod = SourceModule(r"""
-    
-__global__ void supportAndPeriod(unsigned long long int *bitArray, // containing transactions
-                                unsigned long long int *support, // for support
-                                unsigned long long int *period, // for period
-                                unsigned long long int *thingsToCompare, // for things to compare
-                                unsigned long long int *thingsToCompareIndex, // for things to compare index
-                                unsigned long long int numberOfThingsToCompare, // for number of things to compare
-                                unsigned long long int numberOfBits, // for number of bits
-                                unsigned long long int numberOfElements, // for number of elements
-                                unsigned long long int maxPeriod, // for max period
-                                unsigned long long int maxTimeStamp){
-        
-        unsigned long long int threadIDX = blockIdx.x * blockDim.x + threadIdx.x;
+# import pycuda.autoinit
+# import pycuda.driver as cuda
+# from pycuda.compiler import SourceModule
+#
+# supportAndPeriod = SourceModule(r"""
+#
+# __global__ void supportAndPeriod(unsigned long long int *bitArray, // containing transactions
+#                                 unsigned long long int *support, // for support
+#                                 unsigned long long int *period, // for period
+#                                 unsigned long long int *thingsToCompare, // for things to compare
+#                                 unsigned long long int *thingsToCompareIndex, // for things to compare index
+#                                 unsigned long long int numberOfThingsToCompare, // for number of things to compare
+#                                 unsigned long long int numberOfBits, // for number of bits
+#                                 unsigned long long int numberOfElements, // for number of elements
+#                                 unsigned long long int maxPeriod, // for max period
+#                                 unsigned long long int maxTimeStamp){
+#
+#         unsigned long long int threadIDX = blockIdx.x * blockDim.x + threadIdx.x;
+#
+#         if (threadIDX > numberOfThingsToCompare-2) return;
+#
+#         unsigned long long int holder = 0;
+#         unsigned long long int supportCounter = 0;
+#         unsigned long long int periodCounter = 0;
+#         unsigned long long int numbersCounter = 0;
+#         short int bitRepresentation[64];
+#         short int index = numberOfBits - 1;
+#
+#         for(int i = 0; i < numberOfElements; i++){
+#             // intersection
+#             holder = bitArray[thingsToCompare[thingsToCompareIndex[threadIDX]] * numberOfElements + i];
+#             for (int j = thingsToCompareIndex[threadIDX]+1; j < thingsToCompareIndex[threadIDX + 1]; j++){
+#                 holder = holder & bitArray[thingsToCompare[j] * numberOfElements + i];
+#             }
+#
+#             // empty bitRepresentation
+#             for (int j = 0; j < 64; j++){
+#                 bitRepresentation[j] = 0;
+#             }
+#
+#             // conversion to bit representation
+#             index = numberOfBits - 1;
+#             while (holder > 0){
+#                 bitRepresentation[index] = holder % 2;
+#                 holder = holder / 2;
+#                 index--;
+#             }
+#
+#             // counting period
+#             for (int j = 0; j < numberOfBits; j++){
+#                 periodCounter++;
+#                 numbersCounter++;
+#                 if (periodCounter > maxPeriod){
+#                     period[threadIDX] = periodCounter;
+#                     support[threadIDX] = supportCounter;
+#                     return;
+#                 }
+#                 if (bitRepresentation[j] == 1){
+#                     supportCounter++;
+#                     if (periodCounter > period[threadIDX]) period[threadIDX] = periodCounter;
+#                     periodCounter = 0;
+#                 }
+#                 if (numbersCounter == maxTimeStamp){
+#                     support[threadIDX] = supportCounter;
+#                     period[threadIDX] = periodCounter;
+#                     return;
+#                 }
+#             }
+#
+#         }
+#         support[threadIDX] = supportCounter;
+#         period[threadIDX] = periodCounter;
+#         return;
+#
+#     }
+#
+# """
+#                                 )
 
-        if (threadIDX > numberOfThingsToCompare-2) return;
 
-        unsigned long long int holder = 0;
-        unsigned long long int supportCounter = 0;
-        unsigned long long int periodCounter = 0;
-        unsigned long long int numbersCounter = 0;
-        short int bitRepresentation[64];
-        short int index = numberOfBits - 1;
-
-        for(int i = 0; i < numberOfElements; i++){
-            // intersection
-            holder = bitArray[thingsToCompare[thingsToCompareIndex[threadIDX]] * numberOfElements + i];
-            for (int j = thingsToCompareIndex[threadIDX]+1; j < thingsToCompareIndex[threadIDX + 1]; j++){
-                holder = holder & bitArray[thingsToCompare[j] * numberOfElements + i];
-            }
-
-            // empty bitRepresentation
-            for (int j = 0; j < 64; j++){
-                bitRepresentation[j] = 0;
-            }
-
-            // conversion to bit representation
-            index = numberOfBits - 1;
-            while (holder > 0){
-                bitRepresentation[index] = holder % 2;
-                holder = holder / 2;
-                index--;
-            }
-
-            // counting period
-            for (int j = 0; j < numberOfBits; j++){
-                periodCounter++;
-                numbersCounter++;
-                if (periodCounter > maxPeriod){
-                    period[threadIDX] = periodCounter;
-                    support[threadIDX] = supportCounter;
-                    return;
-                }
-                if (bitRepresentation[j] == 1){
-                    supportCounter++;
-                    if (periodCounter > period[threadIDX]) period[threadIDX] = periodCounter;
-                    periodCounter = 0;
-                }
-                if (numbersCounter == maxTimeStamp){
-                    support[threadIDX] = supportCounter;
-                    period[threadIDX] = periodCounter;
-                    return;
-                }
-            }
-
-        }
-        support[threadIDX] = supportCounter;
-        period[threadIDX] = periodCounter;
-        return;
+class gPFMinerBit:
 
-    }
+    """
+    Description:
+    ------------
 
-"""
-                                )
+        ECLAT is one of the fundamental algorithm to discover frequent patterns in a transactional database.
+        This algorithm applies ECLAT as well as calculates periodicity to find patterns in a temporal database.
+        This program employs downward closure property to  reduce the search space effectively.
+        This algorithm employs depth-first search technique to find the complete set of frequent patterns in a
+        temporal database.
 
+    Attributes:
+    ------------
+        filePath : str
+             path of the file
 
-class gPFMinerBit:
+        minSup : int
+             minimum support
 
-    """ ECLAT is one of the fundamental algorithm to discover frequent patterns in a transactional database.
-    This algorithm applies ECLAT as well as calculates periodicity to find patterns in a temporal database.
-    This program employs downward closure property to  reduce the search space effectively.
-    This algorithm employs depth-first search technique to find the complete set of frequent patterns in a
-    temporal database.
+        maxPeriod : (int)
+             maximum period
 
-    Attributes:
-        filePath (str): path of the file
-        minSup (int): minimum support
-        maxPeriod (int): maximum period
-        sep (str, optional): separator. Defaults to "\t".
-        Patterns (dict, optional): dictionary of the patterns. Defaults to {}.
-        maxTimeStamp (int, optional): maximum timestamp. Defaults to 0.
-        __time (int, optional): time taken to execute the algorithm. Defaults to 0.
-        __memRSS (int, optional): memory used by the program. Defaults to 0.
-        __memUSS (int, optional): memory used by the program. Defaults to 0.
-        __GPU_MEM (int, optional): GPU memory used by the program. Defaults to 0.
-        __baseGPUMem (int, optional): base GPU memory used by the program. Defaults to 0.
+        sep : str, optional
+         separator
 
-    Methods:
-        __readFile(): Read the file and return the data in a dictionary
-        __getMaxPeriod(): Get the maximum period of the patterns
-        __generateBitArray(): Generate the bit array
-        getRuntime(): Get the runtime of the algorithm
-        getMemoryRSS(): Get the memory used by the program
-        getMemoryUSS(): Get the memory used by the program
-        getGPUMemory(): Get the GPU memory used by the program
-        getPatterns(): Get the patterns
+        Patterns : dict, optional
+            dictionary of the patterns. Defaults to {}.
+
+        maxTimeStamp : int, optional
+           maximum timestamp. Defaults to 0.
+
+        __time : int, optional
+           time taken to execute the algorithm. Defaults to 0.
+
+        __memRSS : int, optional
+           memory used by the program. Defaults to 0.
+
+        __memUSS : int, optional
+           memory used by the program. Defaults to 0.
+
+        __GPU_MEM : int, optional
+           GPU memory used by the program. Defaults to 0.
+
+        __baseGPUMem : int, optional
+           base GPU memory used by the program. Defaults to 0.
+
+
+
+    **Importing this algorithm into a python program**
+    ------------------------------------------------------------
+    .. code-block:: python
+
+         from cudaAlgorithms import gPFMinerBit
+
+         obj = gPFMinerBit.gPFMinerBit("data.txt", 2, 3)
+
+         obj.run()
+
+         print(obj.getPatterns())
+
+         print(obj.getRuntime())
+
+         print(obj.getMemoryRSS())
 
-    Example:
-        >>> from cudaAlgorithms import gPFMinerBit
-        >>> obj = gPFMinerBit.gPFMinerBit("data.txt", 2, 3)
-        >>> obj.run()
-        >>> print(obj.getPatterns())
-        >>> print(obj.getRuntime())
-        >>> print(obj.getMemoryRSS())
-        >>> print(obj.getMemoryUSS())
-        >>> print(obj.getGPUMemory())
+         print(obj.getMemoryUSS())
 
-        Running from the command line:
-        $ python3 gPFMinerBit.py data.txt 2 3 output.txt
+         print(obj.getGPUMemory())
+
+    Running from the command line:
+    ------------------------------------------------------------
+
+    >>> python3 gPFMinerBit.py data.txt 2 3 output.txt
         
 
-    Created by:
+    Credits:
+    ------------
         This program is created by Tarun Sreepada under the supervision of Professor Rage Uday Kiran.
         
     """
 
-    supportAndPeriod = supportAndPeriod.get_function("supportAndPeriod")
+    # supportAndPeriod = supportAndPeriod.get_function("supportAndPeriod")
 
     def __init__(self, filePath, minSup, maxPeriod, sep="\t"):
         self.filePath = filePath
         self.sep = sep
         self.minSup = minSup
         self.Patterns = {}
         self.maxPeriod = maxPeriod
         self.__time = 0
         self.__memRSS = 0
         self.__memUSS = 0
         self.__GPU_MEM = 0
         self.__baseGPUMem = 0
+        """
+         Methods:
+        ------------
+        __readFile(): Read the file and return the data in a dictionary
+
+        __getMaxPeriod(): Get the maximum period of the patterns
+
+        __generateBitArray(): Generate the bit array
+
+        getRuntime(): Get the runtime of the algorithm
+
+        getMemoryRSS(): Get the memory used by the program
+
+        getMemoryUSS(): Get the memory used by the program
+
+        getGPUMemory(): Get the GPU memory used by the program
+
+        getPatterns(): Get the patterns"""
 
     def __readFile(self):
         """
         Read the file and return the data in a dictionary
 
         Returns:
             dict: dictionary of the data
```

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/maximal/MaxPFGrowth.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/maximal/MaxPFGrowth.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,21 +1,59 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#     from PAMI.periodicFrequentPattern.maximal import MaxPFGrowth as alg
+#
+#     obj = alg.MaxPFGrowth("../basic/sampleTDB.txt", "2", "6")
+#
+#     obj.startMine()
+#
+#     Patterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(Patterns))
+#
+#     obj.save("patterns")
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     run = obj.getRuntime()
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     print("Total ExecutionTime in seconds:", run)
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 
 from PAMI.periodicFrequentPattern.maximal import abstract as _ab
 
 #global maximalTree
 _minSup = float()
 _maxPer = float()
@@ -355,16 +393,19 @@
             pat.append(trans)
             timeStamps.append(condTimeStamps[count])
         count += 1
     return pat, timeStamps, updatedDict
 
 
 class MaxPFGrowth(_ab._periodicFrequentPatterns):
-    """ MaxPF-Growth is one of the fundamental algorithm to discover maximal periodic-frequent
-        patterns in a temporal database.
+    """
+        Description:
+        ------------
+            MaxPF-Growth is one of the fundamental algorithm to discover maximal periodic-frequent
+            patterns in a temporal database.
 
         Reference:
         --------
             R. Uday Kiran, Yutaka Watanobe, Bhaskar Chaudhury, Koji Zettsu, Masashi Toyoda, Masaru Kitsuregawa,
             "Discovering Maximal Periodic-Frequent Patterns in Very Large Temporal Databases",
             IEEE 2020, https://ieeexplore.ieee.org/document/9260063
 
@@ -432,28 +473,30 @@
                 update the Databases by removing aperiodic items and sort the Database by item decreased support
             buildTree()
                 after updating the Databases ar added into the tree by setting root node as null
             startMine()
                 the main method to run the program
 
         Executing the code on terminal:
-        -------
+        -----------------------------------
             Format:
-            ------
-            python3 maxpfrowth.py <inputFile> <outputFile> <minSup> <maxPer>
+            -------
+            >>> python3 maxpfrowth.py <inputFile> <outputFile> <minSup> <maxPer>
 
             Examples:
             --------
-            python3 maxpfrowth.py sampleTDB.txt patterns.txt 0.3 0.4  (minSup will be considered in percentage of database
+            >>> python3 maxpfrowth.py sampleTDB.txt patterns.txt 0.3 0.4  (minSup will be considered in percentage of database
             transactions)
-            python3 maxpfrowth.py sampleTDB.txt patterns.txt 3 4  (minSup will be considered in support count or frequency)
+            >>> python3 maxpfrowth.py sampleTDB.txt patterns.txt 3 4  (minSup will be considered in support count or frequency)
             
             
         Sample run of the imported code:
-        --------------
+        ------------------------------------------
+         .. code-block:: python
+
             from PAMI.periodicFrequentPattern.maximal import MaxPFGrowth as alg
 
             obj = alg.MaxPFGrowth("../basic/sampleTDB.txt", "2", "6")
 
             obj.startMine()
 
             Patterns = obj.getPatterns()
@@ -472,17 +515,17 @@
 
             print("Total Memory in RSS", memRSS)
 
             run = obj.getRuntime()
 
             print("Total ExecutionTime in seconds:", run)
 
-            Credits:
-            -------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+        Credits:
+        -------
+        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
 
         """
     _startTime = float()
     _endTime = float()
     _minSup = str()
     _maxPer = float()
     _finalPatterns = {}
```

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/maximal/__init__.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/maximal/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/maximal/abstract.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/maximal/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/topk/TopkPFP/TopkPFP.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/topk/TopkPFP/TopkPFP.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,36 +1,73 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     import PAMI.periodicFrequentPattern.topk.TopkPFPGrowth as alg
+#
+#     obj = alg.TopkPFPGrowth(iFile, k, maxPer)
+#
+#     obj.startMine()
+#
+#     periodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(periodicFrequentPatterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 
 from PAMI.periodicFrequentPattern.topk import abstract as _ab
 
 
 class TopkPFPGrowth(_ab._periodicFrequentPatterns):
     """
-        Top - K is and algorithm to discover top periodic frequent patterns in a temporal database.
+        Description:
+        ------------
+            Top - K is and algorithm to discover top periodic frequent patterns in a temporal database.
 
         Reference:
         ----------
             Komate Amphawan, Philippe Lenca, Athasit Surarerks: "Mining Top-K Periodic-Frequent Pattern from Transactional Databases without Support Threshold"
             International Conference on Advances in Information Technology: https://link.springer.com/chapter/10.1007/978-3-642-10392-6_3
 
         Attributes:
-        ----------
+        -----------
             iFile : str
                 Input file name or path of the input file
             k: int
                 User specified counte of top frequent patterns
             sep : str
                 This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
                 However, the users can override their default separator.
@@ -44,15 +81,15 @@
                 Storing the complete set of patterns in a dictionary variable
             memoryUSS : float
                 To store the total amount of USS memory consumed by the program
             memoryRSS : float
                 To store the total amount of RSS memory consumed by the program
 
         Methods:
-        -------
+        --------
             startMine()
                 Mining process will start from here
             getPatterns()
                 Complete set of patterns will be retrieved with this function
             save(oFile)
                 Complete set of frequent patterns will be loaded in to a output file
             getPatternsAsDataFrame()
@@ -73,24 +110,26 @@
                 It will generate the combinations of frequent items from a list of items
 
         Executing the code on terminal:
         -------------------------------
 
             Format:
             ------
-                python3 TopkPFP.py <inputFile> <outputFile> <k> <maxPer>
+                >>> python3 TopkPFP.py <inputFile> <outputFile> <k> <maxPer>
 
             Examples:
             ---------
-                python3 TopkPFP.py sampleDB.txt patterns.txt 10 3
+                >>> python3 TopkPFP.py sampleDB.txt patterns.txt 10 3
 
 
         Sample run of the importing code:
         ---------------------------------
 
+        .. code-block:: python
+
             import PAMI.periodicFrequentPattern.topk.TopkPFPGrowth as alg
 
             obj = alg.TopkPFPGrowth(iFile, k, maxPer)
 
             obj.startMine()
 
             periodicFrequentPatterns = obj.getPatterns()
```

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/topk/TopkPFP/abstract.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/topk/TopkPFP/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/topk/kPFPMiner/abstract.py` & `pami-2023.5.1/PAMI/periodicFrequentPattern/topk/kPFPMiner/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/periodicFrequentPattern/topk/kPFPMiner/kPFPMiner.py` & `pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/TUFP.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,261 +1,357 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     from PAMI.uncertainFrequentPattern.basic import TUFP as alg
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     obj = alg.TUFP(iFile, minSup)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getmemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+
+from PAMI.uncertainFrequentPattern.basic import abstract as _ab
 
-from PAMI.periodicFrequentPattern.topk.kPFPMiner import abstract as _ab
+_minSup = float()
+_finalPatterns = {}
 
 
-class kPFPMiner(_ab._periodicFrequentPatterns):
+class _Item:
     """
-        Top - K is and algorithm to discover top periodic-frequent patterns in a temporal database.
+    A class used to represent the item with probability in transaction of dataset
 
-        Reference:
-        ----------
-            Likhitha, P., Ravikumar, P., Kiran, R.U., Watanobe, Y. (2022).
-            Discovering Top-k Periodic-Frequent Patterns in Very Large Temporal Databases. Big Data Analytics.
-            BDA 2022. Lecture Notes in Computer Science, vol 13773. Springer, Cham. https://doi.org/10.1007/978-3-031-24094-2_14
-
-        Attributes:
-        ----------
-            iFile : str
-                Input file name or path of the input file
-            k: int
-                User specified counte of top-k periodic frequent patterns
-            sep : str
-                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                However, the users can override their default separator.
-            oFile : str
-                Name of the output file or the path of the output file
-            startTime:float
-                To record the start time of the mining process
-            endTime:float
-                To record the completion time of the mining process
-            finalPatterns: dict
-                Storing the complete set of patterns in a dictionary variable
-            memoryUSS : float
-                To store the total amount of USS memory consumed by the program
-            memoryRSS : float
-                To store the total amount of RSS memory consumed by the program
-
-        Methods:
-        -------
-            startMine()
-                Mining process will start from here
-            getPatterns()
-                Complete set of patterns will be retrieved with this function
-            savePatterns(oFile)
-                Complete set of frequent patterns will be loaded in to a output file
-            getPatternsAsDataFrame()
-                Complete set of frequent patterns will be loaded in to a dataframe
-            getMemoryUSS()
-                Total amount of USS memory consumed by the mining process will be retrieved from this function
-            getMemoryRSS()
-                Total amount of RSS memory consumed by the mining process will be retrieved from this function
-            getRuntime()
-                Total amount of runtime taken by the mining process will be retrieved from this function
-            creatingItemSets()
-                Scans the dataset or dataframes and stores in list format
-            frequentOneItem()
-                Generates one frequent patterns
-            eclatGeneration(candidateList)
-                It will generate the combinations of frequent items
-            generateFrequentPatterns(tidList)
-                It will generate the combinations of frequent items from a list of items
+    ...
 
-        Executing the code on terminal:
-        -------------------------------
+    Attributes:
+    __________
+        item : int or word
+            Represents the name of the item
+        probability : float
+            Represent the existential probability(likelihood presence) of an item
+    """
+
+    def __init__(self, item, probability):
+        self.item = item
+        self.probability = probability
+
+
+class TUFP(_ab._frequentPatterns):
+    """
+    Description:
+    -------------
+        It is one of the fundamental algorithm to discover top-k frequent patterns in a uncertain transactional database
+        using CUP-Lists.
+
+    Reference:
+    ----------
+        Tuong Le, Bay Vo, Van-Nam Huynh, Ngoc Thanh Nguyen, Sung Wook Baik 5, "Mining top-k frequent patterns from uncertain databases",
+        Springer Science+Business Media, LLC, part of Springer Nature 2020, https://doi.org/10.1007/s10489-019-01622-1
+
+    Attributes:
+    ------------
+        iFile : file
+            Name of the Input file or path of the input file
+        oFile : file
+            Name of the output file or path of the output file
+        minSup: float or int or str
+            The user can specify minSup either in count or proportion of database size.
+            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+        sep : str
+            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+            However, the users can override their default separator.
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
+        startTime:float
+            To record the start time of the mining process
+        endTime:float
+            To record the completion time of the mining process
+        Database : list
+            To store the transactions of a database in list
+        mapSupport : Dictionary
+            To maintain the information of item and their frequency
+        lno : int
+            To represent the total no of transaction
+        tree : class
+            To represents the Tree class
+        itemSetCount : int
+            To represents the total no of patterns
+        finalPatterns : dict
+            To store the complete patterns
+    Methods:
+    ---------
+        startMine()
+            Mining process will start from here
+        getPatterns()
+            Complete set of patterns will be retrieved with this function
+        storePatternsInFile(oFile)
+            Complete set of frequent patterns will be loaded in to a output file
+        getPatternsInDataFrame()
+            Complete set of frequent patterns will be loaded in to a dataframe
+        getMemoryUSS()
+            Total amount of USS memory consumed by the mining process will be retrieved from this function
+        getMemoryRSS()
+            Total amount of RSS memory consumed by the mining process will be retrieved from this function
+        getRuntime()
+            Total amount of runtime taken by the mining process will be retrieved from this function
+        creatingItemSets(fileName)
+            Scans the dataset and stores in a list format
+        frequentOneItem()
+            Extracts the one-length frequent patterns from database
+        updateTransactions()
+            Update the transactions by removing non-frequent items and sort the Database by item decreased support
+        buildTree()
+            After updating the Database, remaining items will be added into the tree by setting root node as null
+        convert()
+            to convert the user specified value
+        startMine()
+            Mining process will start from this function
+
+
+    **Methods to execute code on terminal**
 
             Format:
-            ------
-            python3 kPFPMiner.py <inputFile> <outputFile> <k>
+                      >>> python3 TUFP.py <inputFile> <outputFile> <minSup>
+            Example:
+                      >>>  python3 TUFP.py sampleTDB.txt patterns.txt 0.6
 
-            Examples:
-            ---------
-            python3 kPFPMiner.py sampleDB.txt patterns.txt 10
+            .. note:: minSup  will be considered in support count or frequency
 
+    **Importing this algorithm into a python program**
 
-        Sample run of the importing code:
-        ---------------------------------
+    .. code-block:: python
 
-            import PAMI.periodicFrequentPattern.kPFPMiner as alg
+            from PAMI.uncertainFrequentPattern.basic import TUFP as alg
 
-            obj = alg.kPFPMiner(iFile, k)
+            obj = alg.TUFP(iFile, minSup)
 
             obj.startMine()
 
-            periodicFrequentPatterns = obj.getPatterns()
+            frequentPatterns = obj.getPatterns()
 
-            print("Total number of top-k Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+            print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-            obj.save(oFile)
+            obj.savePatterns(oFile)
 
-            Df = obj.getPatternInDataFrame()
+            Df = obj.getPatternsAsDataFrame()
 
-            memUSS = obj.getMemoryUSS()
+            memUSS = obj.getmemoryUSS()
 
             print("Total Memory in USS:", memUSS)
 
             memRSS = obj.getMemoryRSS()
 
             print("Total Memory in RSS", memRSS)
 
             run = obj.getRuntime()
 
             print("Total ExecutionTime in seconds:", run)
 
-        Credits:
-        --------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+    **Credits:**
+
+             The complete program was written by   P.Likhitha   under the supervision of Professor Rage Uday Kiran.
 
     """
 
     _startTime = float()
     _endTime = float()
-    _k = int()
+    _minSup = str()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
-    _tidList = {}
-    lno = int()
-    _maximum = int()
+    _cupList = {}
+    _topk = {}
+    _minimum = 9999
 
     def _creatingItemSets(self):
         """
-            Storing the complete transactions of the database/input file in a database variable
-
+            Scans the dataset
         """
-
         self._Database = []
         if isinstance(self._iFile, _ab._pd.DataFrame):
+            uncertain, data = [], []
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
                 self._Database = self._iFile['Transactions'].tolist()
+            if 'uncertain' in i:
+                uncertain = self._iFile['uncertain'].tolist()
+            for k in range(len(data)):
+                tr = []
+                for j in range(len(data[k])):
+                    product = _Item(data[k][j], uncertain[k][j])
+                    tr.append(product)
+                self._Database.append(tr)
 
             # print(self.Database)
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
+                    tr = []
+                    for i in temp:
+                        i1 = i.index('(')
+                        i2 = i.index(')')
+                        item = i[0:i1]
+                        probability = float(i[i1 + 1:i2])
+                        product = _Item(item, probability)
+                        tr.append(product)
                     self._Database.append(temp)
             else:
                 try:
-                    with open(self._iFile, 'r', encoding='utf-8') as f:
+                    with open(self._iFile, 'r') as f:
                         for line in f:
-                            line.strip()
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
-                            self._Database.append(temp)
+                            tr = []
+                            for i in temp:
+                                i1 = i.index('(')
+                                i2 = i.index(')')
+                                item = i[0:i1]
+                                probability = float(i[i1 + 1:i2])
+                                product = _Item(item, probability)
+                                tr.append(product)
+                            self._Database.append(tr)
                 except IOError:
                     print("File Not Found")
-                    quit()
-                    
-    def getPer_Sup(self, tids):
-        tids.sort()
-        cur=0
-        per=list()
-        sup=0
-        #print(tids)
-        for i in range(len(tids)-1):
-            j = i + 1
-            #if tids[j] - cur <= periodicity:
-                #return [0,0]
-            per.append(tids[j] - cur)
-            cur = tids[j]
-        per.append(self.lno - cur)
-        return max(per)
 
     def _frequentOneItem(self):
+        """takes the self.Database and calculates the support of each item in the dataset and assign the
+            ranks to the items by decreasing support and returns the frequent items list
+
+                :param self.Database : it represents the one self.Database in database
+
+                :type self.Database : list
         """
-        Generating one frequent patterns
-        """
-        self._mapSupport = {}
-        self._tidList = {}
-        n = 0
-        for line in self._Database:
-            self.lno += 1
-            n = int(line[0])
-            for i in range(1, len(line)):
-                si = line[i]
-                if self._mapSupport.get(si) is None:
-                    self._mapSupport[si] = [1, abs(0 - n), n]
-                    self._tidList[si] = [n]
+
+        mapSupport = {}
+        k = 0
+        for i in self._Database:
+            k += 1
+            for j in i:
+                if j.item not in mapSupport:
+                    mapSupport[j.item] = j.probability
+                    self._cupList[j.item] = {k:j.probability}
                 else:
-                    self._mapSupport[si][0] += 1
-                    self._mapSupport[si][1] = max(self._mapSupport[si][1], abs(n - self._mapSupport[si][2]))
-                    self._mapSupport[si][2] = n
-                    self._tidList[si].append(n)
-        for x, y in self._mapSupport.items():
-            self._mapSupport[x][1] = max(self._mapSupport[x][1], abs(n - self._mapSupport[x][2]))
-        plist = [key for key, value in sorted(self._mapSupport.items(), key=lambda x: x[1], reverse=True)]
-        for i in plist:
-            if len(self._finalPatterns) >= self._k:
+                    mapSupport[j.item] += j.probability
+                    self._cupList[j.item].update({k: j.probability})
+        plist = [k for k,v in sorted(mapSupport.items(), key=lambda x: x[1], reverse=True)]
+        k = 0
+        for x, in plist:
+            k +=1
+            if k >= self._minSup:
                 break
-            else:
-                self._finalPatterns[i] = self._mapSupport[i][1]
-        self._maximum = max([self._finalPatterns[i] for i in self._finalPatterns.keys()])
-        plist = list(self._finalPatterns.keys())
+            self._finalPatterns[x] = mapSupport[x]
+        self._minimum = min(list(self._finalPatterns.values()))
         return plist
 
+    @staticmethod
+    def _convert(value):
+        """
+        To convert the type of user specified minSup value
+
+            :param value: user specified minSup value
+
+            :return: converted type minSup value
+        """
+        if type(value) is int:
+            value = int(value)
+        if type(value) is float:
+            value = float(value)
+        if type(value) is str:
+            if '.' in value:
+                value = float(value)
+            else:
+                value = int(value)
+        return value
 
     def _save(self, prefix, suffix, tidSetI):
         """Saves the patterns that satisfy the periodic frequent property.
 
             :param prefix: the prefix of a pattern
             :type prefix: list
             :param suffix: the suffix of a patterns
             :type suffix: list
             :param tidSetI: the timestamp of a patterns
-            :type tidSetI: list
+            :type tidSetI: dict
         """
 
         if prefix is None:
             prefix = suffix
         else:
             prefix = prefix + suffix
-        val = self.getPer_Sup(tidSetI)
-        sample = str()
-        for i in prefix:
-            sample = sample + i + " "
-        if len(self._finalPatterns) < self._k:
-            if val < self._maximum:
+        val = sum(tidSetI.values())
+        #print(prefix, val)
+        if len(self._finalPatterns) <= self._minSup:
+            sample = str()
+            for i in prefix:
+                sample = sample + i + " "
+            self._finalPatterns[sample] = val
+        if len(self._finalPatterns) == self._minSup:
+            if val > self._minimum:
+                sample = str()
+                for i in prefix:
+                    sample = sample + i + " "
+                index = list(self._finalPatterns.keys())[list(self._finalPatterns.values()).index(self._minimum)]
+                del self._finalPatterns[index]
                 self._finalPatterns[sample] = val
-                self._finalPatterns = {k: v for k, v in sorted(self._finalPatterns.items(), key=lambda item: item[1], reverse=True)}
-                self._maximum = max([i for i in self._finalPatterns.values()])
-        else:
-            for x, y in sorted(self._finalPatterns.items(), key=lambda x: x[1], reverse=True):
-                if val < y:
-                    del self._finalPatterns[x]
-                    self._finalPatterns[sample] = val
-                    self._finalPatterns = {k: v for k, v in
-                                              sorted(self._finalPatterns.items(), key=lambda item: item[1],
-                                                     reverse=True)}
-                    self._maximum = max([i for i in self._finalPatterns.values()])
-                    return
+                self._minimum = min(list(self._finalPatterns.values()))
+        #print(self.finalPatterns, self.minimum, self.minSup)
+
 
     def _Generation(self, prefix, itemSets, tidSets):
         """Equivalence class is followed  and checks for the patterns generated for periodic-frequent patterns.
 
             :param prefix:  main equivalence prefix
             :type prefix: periodic-frequent item or pattern
             :param itemSets: patterns which are items combined with prefix and satisfying the periodicity
@@ -267,92 +363,77 @@
 
                     """
         if len(itemSets) == 1:
             i = itemSets[0]
             tidI = tidSets[0]
             self._save(prefix, [i], tidI)
             return
-        for i in range(len(itemSets)):
+        for i in range(0, len(itemSets)):
             itemI = itemSets[i]
             if itemI is None:
                 continue
             tidSetI = tidSets[i]
             classItemSets = []
             classTidSets = []
             itemSetX = [itemI]
-            for j in range(i + 1, len(itemSets)):
+            for j in range(i+1, len(itemSets)):
                 itemJ = itemSets[j]
                 tidSetJ = tidSets[j]
-                y = list(set(tidSetI).intersection(tidSetJ))
-                if self.getPer_Sup(y) <= self._maximum:
-                    classItemSets.append(itemJ)
-                    classTidSets.append(y)
+                y = {key: tidSetJ[key] * tidSetI.get(key, 0) for key in tidSetJ.keys()}
+                sum2 = sum(list(y.values()))
+                #print(prefix, itemJ, y, sum2)
+                #if sum2 >= self.minimum:
+                self._save(prefix, [itemJ], y)
+                classItemSets.append(itemJ)
+                classTidSets.append(y)
+            #print(itemI, tidSetI, classItemSets)
             newPrefix = list(set(itemSetX)) + prefix
             self._Generation(newPrefix, classItemSets, classTidSets)
-            self._save(prefix, list(set(itemSetX)), tidSetI)
-
-    def _convert(self, value):
-        """
-        to convert the type of user specified minSup value
-        :param value: user specified minSup value
-        :return: converted type
-        """
-        if type(value) is int:
-            value = int(value)
-        if type(value) is float:
-            value = (len(self._Database) * value)
-        if type(value) is str:
-            if '.' in value:
-                value = float(value)
-                value = ((len(self._Database)) * value)
-            else:
-                value = int(value)
-        return value
+            #self.save(prefix, list(set(itemSetX)), tidSetI)
 
     def startMine(self):
-        """
-            Main function of the program
+        """Main method where the patterns are mined by constructing tree and remove the remove the false patterns
+            by counting the original support of a patterns
+
 
         """
+        global _minSup
         self._startTime = _ab._time.time()
-        if self._iFile is None:
-            raise Exception("Please enter the file path or file name:")
-        if self._k is None:
-            raise Exception("Please enter the Minimum Support")
         self._creatingItemSets()
-        self._k = self._convert(self._k)
+        self._minSup = self._convert(self._minSup)
+        _minSup = self._minSup
         plist = self._frequentOneItem()
         for i in range(len(plist)):
             itemI = plist[i]
-            tidSetI = self._tidList[itemI]
+            tidSetI = self._cupList[itemI]
             itemSetX = [itemI]
             itemSets = []
             tidSets = []
-            for j in range(i + 1, len(plist)):
+            for j in range(i+1, len(plist)):
                 itemJ = plist[j]
-                tidSetJ = self._tidList[itemJ]
-                y1 = list(set(tidSetI).intersection(tidSetJ))
-                if self.getPer_Sup(y1) <= self._maximum:
-                    itemSets.append(itemJ)
-                    tidSets.append(y1)
+                tidSetJ = self._cupList[itemJ]
+                y1 = {key: tidSetJ[key] * tidSetI.get(key, 0)  for key in tidSetJ.keys()}
+                self._save(itemSetX, [itemJ], y1)
+                itemSets.append(itemJ)
+                tidSets.append(y1)
             self._Generation(itemSetX, itemSets, tidSets)
-        print("kPFPMiner has successfully generated top-k frequent patterns")
+        print("Top-K Frequent patterns were generated from uncertain databases successfully using TUFP algorithm")
         self._endTime = _ab._time.time()
+        process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryUSS = float()
         self._memoryRSS = float()
-        process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryUSS = process.memory_full_info().uss
         self._memoryRSS = process.memory_info().rss
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
-                    :return: returning USS memory consumed by the mining process
+        :return: returning USS memory consumed by the mining process
 
-                    :rtype: float
+        :rtype: float
         """
 
         return self._memoryUSS
 
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the mining process will be retrieved from this function
 
@@ -362,14 +443,15 @@
         """
 
         return self._memoryRSS
 
     def getRuntime(self):
         """Calculating the total amount of runtime taken by the mining process
 
+
         :return: returning total amount of runtime taken by the mining process
 
         :rtype: float
         """
 
         return self._endTime - self._startTime
 
@@ -377,64 +459,67 @@
         """Storing final frequent patterns in a dataframe
 
         :return: returning frequent patterns in a dataframe
 
         :rtype: pd.DataFrame
         """
 
-        dataFrame = {}
+        dataframe = {}
         data = []
         for a, b in self._finalPatterns.items():
             data.append([a, b])
-            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'periodicity'])
-        return dataFrame
+            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
+        return dataframe
 
     def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
 
         :type outFile: file
         """
-        self._oFile = outFile
-        writer = open(self._oFile, 'w+')
+        self.oFile = outFile
+        writer = open(self.oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            patternsAndSupport = x + ":" + str(y)
-            writer.write("%s \n" % patternsAndSupport)
+            s1 = x + ":" + str(y)
+            writer.write("%s \n" % s1)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
 
         :rtype: dict
         """
         return self._finalPatterns
 
-    def printResults(self):
-        print("Total number of  Top-k Periodic Frequent Patterns:", len(self.getPatterns()))
-        print("Total Memory in USS:", self.getMemoryUSS())
-        print("Total Memory in RSS", self.getMemoryRSS())
-        print("Total ExecutionTime in ms:",  self.getRuntime())
-
 
 if __name__ == "__main__":
     _ap = str()
     if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:
         if len(_ab._sys.argv) == 5:
-            _ap = kPFPMiner(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+            _ap = TUFP(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
         if len(_ab._sys.argv) == 4:
-            _ap = kPFPMiner(_ab._sys.argv[1], _ab._sys.argv[3])
+            _ap = TUFP(_ab._sys.argv[1], _ab._sys.argv[3])
         _ap.startMine()
         _Patterns = _ap.getPatterns()
-        print("Total number of top-k periodic frequent patterns:", len(_Patterns))
+        print("Total number of Patterns:", len(_Patterns))
         _ap.save(_ab._sys.argv[2])
         _memUSS = _ap.getMemoryUSS()
         print("Total Memory in USS:", _memUSS)
         _memRSS = _ap.getMemoryRSS()
         print("Total Memory in RSS", _memRSS)
         _run = _ap.getRuntime()
         print("Total ExecutionTime in ms:", _run)
     else:
+        '''ap = TUFP("/home/apiiit-rkv/Desktop/uncertain/tubeSample", 10, ' ')
+        ap.startMine()
+        Patterns = ap.getPatterns()
+        print("Total number of Patterns:", len(Patterns))
+        ap.save("patterns.txt")
+        memUSS = ap.getMemoryUSS()
+        print("Total Memory in USS:", memUSS)
+        memRSS = ap.getMemoryRSS()
+        print("Total Memory in RSS", memRSS)
+        run = ap.getRuntime()
+        print("Total ExecutionTime in ms:", run)'''
         print("Error! The number of input parameters do not match the total number of parameters provided")
-
-
```

### Comparing `pami-2023.4.1/PAMI/recurringPattern/basic/RPGrowth.py` & `pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/PUFGrowth.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,309 +1,315 @@
-#  Copyright (C)  2021 Rage Uday Kiran
-# 
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.PAMI.periodicFrequentPattern.recurring.
-
-from PAMI.recurringPattern.basic import abstract as _ab
-
-_maxPer = float()
-_minPS = float()
-_minRec = float()
-_lno = int()
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.uncertainFrequentPattern.basic import puf as alg
+#
+#     obj = alg.PUFGrowth(iFile, minSup)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getmemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
 
 
-class _Node(object):
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+
+from PAMI.uncertainFrequentPattern.basic import abstract as _ab
+
+_minSup = str()
+_ab._sys.setrecursionlimit(20000)
+_finalPatterns = {}
+
+
+class _Item:
+    """
+    A class used to represent the item with probability in transaction of dataset
+    ...
+    Attributes:
+    __________
+        item : int or word
+            Represents the name of the item
+        probability : float
+            Represent the existential probability(likelihood presence) of an item
     """
-        A class used to represent the node of frequentPatternTree
 
-        Attributes:
-        ----------
-            item : int or None
-                Storing item of a node
-            timeStamps : list
-                To maintain the timestamps of a database at the end of the branch
-            parent : node
-                To maintain the parent of every node
-            children : list
-                To maintain the children of a node
-
-        Methods:
-        -------
-            addChild(itemName)
-                Storing the children to their respective parent nodes
-        """
+    def __init__(self, item, probability):
+        self.item = item
+        self.probability = probability
 
-    def __init__(self, item, children):
-        """ Initializing the Node class
 
-        :param item: Storing the item of a node
-        :type item: int or None
-        :param children: To maintain the children of a node
-        :type children: dict
-        """
+class _Node(object):
+    """
+    A class used to represent the node of frequentPatternTree
+        ...
+    Attributes:
+    ----------
+        item : int
+            storing item of a node
+        probability : int
+            To maintain the expected support of node
+        parent : node
+            To maintain the parent of every node
+        children : list
+            To maintain the children of node
+    Methods:
+    -------
+        addChild(itemName)
+            storing the children to their respective parent nodes
+    """
 
+    def __init__(self, item, children):
         self.item = item
+        self.probability = 1
         self.children = children
         self.parent = None
-        self.timeStamps = []
 
     def addChild(self, node):
-        """ To add the children to a node
-
-            :param node: parent node in the tree
-        """
-
         self.children[node.item] = node
         node.parent = self
 
 
 class _Tree(object):
     """
-        A class used to represent the frequentPatternGrowth tree structure
-
-        Attributes:
-        ----------
-            root : Node
-                Represents the root node of the tree
-            summaries : dictionary
-                Storing the nodes with same item name
-            info : dictionary
-                Stores the support of the items
-
-
-        Methods:
-        -------
-            addTransactions(Database)
-                Creating transaction as a branch in Recurring PatternTree
-            getConditionalPatterns(Node)
-                Generates the conditional patterns from tree for specific node
-            conditionalTransaction(prefixPaths,Support)
-                Takes the prefixPath of a node and support at child of the path and extract the frequent patterns from
-                prefixPaths and generates prefixPaths with items which are frequent
-            remove(Node)
-                Removes the node from tree once after generating all the patterns respective to the node
-            generatePatterns(Node)
-                Starts from the root node of the tree and mines the periodic-frequent patterns
-
-        """
+    A class used to represent the frequentPatternGrowth tree structure
+    ...
+    Attributes:
+    ----------
+        root : Node
+            Represents the root node of the tree
+        summaries : dictionary
+            storing the nodes with same item name
+        info : dictionary
+            stores the support of items
+    Methods:
+    -------
+        addTransaction(transaction)
+            creating transaction as a branch in frequentPatternTree
+        addConditionalPattern(prefixPaths, supportOfItems)
+            construct the conditional tree for prefix paths
+        conditionalPatterns(Node)
+            generates the conditional patterns from tree for specific node
+        conditionalTransactions(prefixPaths,Support)
+            takes the prefixPath of a node and support at child of the path and extract the frequent items from
+            prefixPaths and generates prefixPaths with items which are frequent
+        remove(Node)
+            removes the node from tree once after generating all the patterns respective to the node
+        generatePatterns(Node)
+            starts from the root node of the tree and mines the frequent patterns
+    """
 
     def __init__(self):
         self.root = _Node(None, {})
         self.summaries = {}
         self.info = {}
 
-    def addTransaction(self, transaction, tid):
-        """     Adding a transaction into tree
+    def addTransaction(self, transaction):
+        """adding transaction into tree
+            :param transaction : it represents the one self.Database in database
+            :type transaction : list
+        """
 
-                :param transaction: To represent the complete database
-                :type transaction: list
-                :param tid: To represent the timestamp of a database
-                :type tid: list
-                :return: rp-tree
+        currentNode = self.root
+        for i in range(len(transaction)):
+            if transaction[i].item not in currentNode.children:
+                newNode = _Node(transaction[i].item, {})
+                l1 = i - 1
+                lp = []
+                while l1 >= 0:
+                    lp.append(transaction[l1].probability)
+                    l1 -= 1
+                if len(lp) == 0:
+                    newNode.probability = transaction[i].probability
+                else:
+                    newNode.probability = max(lp) * transaction[i].probability
+                currentNode.addChild(newNode)
+                if transaction[i].item in self.summaries:
+                    self.summaries[transaction[i].item].append(newNode)
+                else:
+                    self.summaries[transaction[i].item] = [newNode]
+                currentNode = newNode
+            else:
+                currentNode = currentNode.children[transaction[i].item]
+                l1 = i - 1
+                lp = []
+                while l1 >= 0:
+                    lp.append(transaction[l1].probability)
+                    l1 -= 1
+                if len(lp) == 0:
+                    currentNode.probability += transaction[i].probability
+                else:
+                    currentNode.probability += max(lp) * transaction[i].probability
+
+    def addConditionalPattern(self, transaction, sup):
+        """constructing conditional tree from prefixPaths
+            :param transaction : it represents the one self.Database in database
+            :type transaction : list
+            :param sup : support of prefixPath taken at last child of the path
+            :type sup : int
         """
 
+        # This method takes transaction, support and constructs the conditional tree
         currentNode = self.root
         for i in range(len(transaction)):
             if transaction[i] not in currentNode.children:
                 newNode = _Node(transaction[i], {})
+                newNode.probability = sup
                 currentNode.addChild(newNode)
                 if transaction[i] in self.summaries:
                     self.summaries[transaction[i]].append(newNode)
                 else:
                     self.summaries[transaction[i]] = [newNode]
                 currentNode = newNode
             else:
                 currentNode = currentNode.children[transaction[i]]
-        currentNode.timeStamps = currentNode.timeStamps + tid
-
-    def getConditionalPatterns(self, alpha):
-        """Generates all the conditional patterns of a respective node
+                currentNode.probability += sup
 
-            :param alpha: To represent a Node in the tree
-            :type alpha: Node
-            :return: A tuple consisting of finalPatterns, conditional pattern base and information
+    def conditionalPatterns(self, alpha):
+        """generates all the conditional patterns of respective node
+            :param alpha : it represents the Node in tree
+            :type alpha : _Node
         """
+
+        # This method generates conditional patterns of node by traversing the tree
         finalPatterns = []
-        finalSets = []
+        sup = []
         for i in self.summaries[alpha]:
-            set1 = i.timeStamps
+            s = i.probability
             set2 = []
             while i.parent.item is not None:
                 set2.append(i.parent.item)
                 i = i.parent
             if len(set2) > 0:
                 set2.reverse()
                 finalPatterns.append(set2)
-                finalSets.append(set1)
-        finalPatterns, finalSets, info = self.conditionalDatabases(finalPatterns, finalSets)
-        return finalPatterns, finalSets, info
-
-    @staticmethod
-    def generateTimeStamps(node):
-        """To get the timestamps of a node
-
-        :param node: A node in the tree
-        :return: Timestamps of a node
-        """
-
-        finalTimeStamps = node.timeStamps
-        return finalTimeStamps
+                sup.append(s)
+        finalPatterns, support, info = self.conditionalTransactions(finalPatterns, sup)
+        return finalPatterns, support, info
 
     def removeNode(self, nodeValue):
-        """ Removing the node from tree
-
-            :param nodeValue: To represent a node in the tree
-            :type nodeValue: node
-            :return: Tree with their nodes updated with timestamps
+        """removing the node from tree
+            :param nodeValue : it represents the node in tree
+            :type nodeValue : node
         """
 
         for i in self.summaries[nodeValue]:
-            i.parent.timeStamps = i.parent.timeStamps + i.timeStamps
             del i.parent.children[nodeValue]
 
-    def getTimeStamps(self, alpha):
-        """ To get all the timestamps of the nodes which share same item name
-
-            :param alpha: Node in a tree
-            :return: Timestamps of a  node
-        """
-        temporary = []
-        for i in self.summaries[alpha]:
-            temporary += i.timeStamps
-        return temporary
-
-    @staticmethod
-    def getSupportAndPeriod(timeStamps):
-        """To calculate the recurrence and support
-
-        :param timeStamps: Timestamps of an item set
-        :return: recurring intervals with corresponding periodic support, summation of support of periodic intervals, support
-        """
-
-        global _maxPer,_minPS
-        timeStamps.sort()
-        cur = ' '
-        st = ' '
-        end = ' '
-        if len(timeStamps) > 0:
-            cur = timeStamps[0]
-            st = timeStamps[0]
-            end = timeStamps[0]
-        ps = 0
-        lps = 1
-        recli = []
-        for i in range(1, len(timeStamps)):
-            if abs(timeStamps[i] - cur) <= _maxPer:
-                lps += 1
-            else:
-                if lps >= _minPS:
-                    recli.append([st, end, lps])
-                    ps += lps
-                lps = 1
-                st = timeStamps[i]
-            cur = timeStamps[i]
-            end = cur
-        if lps >= _minPS:
-            recli.append([st, end, lps])
-            ps+=lps
-        # print(recli)
-        return [recli, ps, len(timeStamps)]
-
-    def conditionalDatabases(self, conditionalPatterns, conditionalTimeStamps):
-        """ It generates the conditional patterns with periodic-frequent items
-
-            :param conditionalPatterns: conditionalPatterns generated from conditionPattern method of a respective node
-            :type conditionalPatterns: list
-            :param conditionalTimeStamps: Represents the timestamps of a conditional patterns of a node
-            :type conditionalTimeStamps: list
-            :returns: Returns conditional transactions by removing non recurring items
+    def conditionalTransactions(self, condPatterns, support):
+        """ It generates the conditional patterns with frequent items
+                :param condPatterns : conditionalPatterns generated from conditionalPattern method for respective node
+                :type condPatterns : list
+                :support : the support of conditional pattern in tree
+                :support : int
         """
 
-        global _maxPer, _minPS, _minRec
+        global minSup
         pat = []
-        timeStamps = []
-        data1 = {}
-        for i in range(len(conditionalPatterns)):
-            for j in conditionalPatterns[i]:
-                if j in data1:
-                    data1[j] = data1[j] + conditionalTimeStamps[i]
+        sup = []
+        count = {}
+        for i in range(len(condPatterns)):
+            for j in condPatterns[i]:
+                if j in count:
+                    count[j] += support[i]
                 else:
-                    data1[j] = conditionalTimeStamps[i]
-        updatedDictionary = {}
-        for m in data1:
-            updatedDictionary[m] = self.getSupportAndPeriod(data1[m])
-        # print(updatedDictionary)
-        updatedDictionary = {k: [v[0],v[2]] for k, v in updatedDictionary.items() if v[1] >= (_minPS*_minRec)}
+                    count[j] = support[i]
+        updatedDict = {}
+        updatedDict = {k: v for k, v in count.items() if v >= minSup}
         count = 0
-        for p in conditionalPatterns:
-            p1 = [v for v in p if v in updatedDictionary]
-            trans = sorted(p1, key=lambda x: (updatedDictionary.get(x)[1], -x), reverse=True)
+        for p in condPatterns:
+            p1 = [v for v in p if v in updatedDict]
+            trans = sorted(p1, key=lambda x: updatedDict[x], reverse=True)
             if len(trans) > 0:
                 pat.append(trans)
-                timeStamps.append(conditionalTimeStamps[count])
-            count += 1
-        return pat, timeStamps, updatedDictionary
+                sup.append(support[count])
+                count += 1
+        return pat, sup, updatedDict
 
     def generatePatterns(self, prefix):
-        """ Generates the patterns
-
-            :param prefix: Forms the combination of items
-            :type prefix: list
-            :returns: yields patterns with their recurrence and support
+        """generates the patterns
+            :param prefix : forms the combination of items
+            :type prefix : list
         """
-        global _minRec
-        for i in sorted(self.summaries, key=lambda x: (self.info.get(x)[1], -x)):
+
+        global _finalPatterns, minSup
+        for i in sorted(self.summaries, key=lambda x: (self.info.get(x))):
             pattern = prefix[:]
             pattern.append(i)
-            if len(self.info.get(i)[0]) >= _minRec:
-                yield pattern, self.info[i]
-            patterns, timeStamps, info = self.getConditionalPatterns(i)
-            conditionalTree = _Tree()
-            conditionalTree.info = info.copy()
-            for pat in range(len(patterns)):
-                conditionalTree.addTransaction(patterns[pat], timeStamps[pat])
-            if len(patterns) > 0:
-                for q in conditionalTree.generatePatterns(pattern):
-                    yield q
+            s = 0
+            for x in self.summaries[i]:
+                s += x.probability
+            _finalPatterns[tuple(pattern)] = self.info[i]
+            if s >= minSup:
+                patterns, support, info = self.conditionalPatterns(i)
+                conditionalTree = _Tree()
+                conditionalTree.info = info.copy()
+                for pat in range(len(patterns)):
+                    conditionalTree.addConditionalPattern(patterns[pat], support[pat])
+                if len(patterns) > 0:
+                    conditionalTree.generatePatterns(pattern)
             self.removeNode(i)
 
 
-class RPGrowth(_ab._recurringPatterns):
-    """ RPGrowth is one of the fundamental algorithm to discover recurring patterns in a transactional database.
-
-   
-
-    Attributes:
+class PUFGrowth(_ab._frequentPatterns):
+    """
+    Description:
+    ------------
+        It is one of the fundamental algorithm to discover frequent patterns in a uncertain transactional database
+        using PUF-Tree.
+    Reference:
     ----------
+        Carson Kai-Sang Leung, Syed Khairuzzaman Tanbeer, "PUF-Tree: A Compact Tree Structure for Frequent Pattern Mining of Uncertain Data",
+        Pacific-Asia Conference on Knowledge Discovery and Data Mining(PAKDD 2013), https://link.springer.com/chapter/10.1007/978-3-642-37453-1_2
+    Attributes:
+    -----------
         iFile : file
             Name of the Input file or path of the input file
         oFile : file
             Name of the output file or path of the output file
-        maxPer: int or float or str
-            The user can specify maxPer either in count or proportion of database size.
-            If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
+        minSup: float or int or str
+            The user can specify minSup either in count or proportion of database size.
+            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
             Otherwise, it will be treated as float.
-            Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
-        minPS: int or float or str
-            The user can specify minPS either in count or proportion of database size.
-            If the program detects the data type of minPS is integer, then it treats minPS is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: minPS=10 will be treated as integer, while minPS=10.0 will be treated as float
-        minRec: int or float or str
-            The user has to specify minRec in count.
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
         sep : str
             This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
             However, the users can override their default separator.
         memoryUSS : float
             To store the total amount of USS memory consumed by the program
         memoryRSS : float
             To store the total amount of RSS memory consumed by the program
@@ -319,367 +325,372 @@
             To represent the total no of transaction
         tree : class
             To represents the Tree class
         itemSetCount : int
             To represents the total no of patterns
         finalPatterns : dict
             To store the complete patterns
-
     Methods:
-    -------
+    ---------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
-            Complete set of periodic-frequent patterns will be loaded in to a output file
+            Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
-            Complete set of periodic-frequent patterns will be loaded in to a dataframe
+            Complete set of frequent patterns will be loaded in to a dataframe
         getMemoryUSS()
             Total amount of USS memory consumed by the mining process will be retrieved from this function
         getMemoryRSS()
             Total amount of RSS memory consumed by the mining process will be retrieved from this function
         getRuntime()
             Total amount of runtime taken by the mining process will be retrieved from this function
         creatingItemSets(fileName)
             Scans the dataset and stores in a list format
-        OneItems()
-            Extracts the possible recurring items of size one from database
-        updateDatabases()
-            Update the database by removing non recurring items and sort the Database by item decreased support
+        frequentOneItem()
+            Extracts the one-length frequent patterns from database
+        updateTransactions()
+            Update the transactions by removing non-frequent items and sort the Database by item decreased support
         buildTree()
             After updating the Database, remaining items will be added into the tree by setting root node as null
         convert()
             to convert the user specified value
+        startMine()
+            Mining process will start from this function
+    **Methods to execute code on terminal**
 
-    Executing the code on terminal:
-    -------
         Format:
-        ------
-        python3 RPGrowth.py <inputFile> <outputFile> <maxPer> <minPS> <minRec>
+                  >>> python3 PUFGrowth.py <inputFile> <outputFile> <minSup>
+        Example:
+                  >>>  python3 PUFGrowth.py sampleTDB.txt patterns.txt 3
+
+        .. note:: minSup  will be considered in support count or frequency
 
-        Examples:
-        --------
-        python3 RPGrowth.py sampleTDB.txt patterns.txt 0.3 0.4 2   (maxPer and minPS  will be considered in percentage of database
-        transactions and minRec is integer)
 
-        python3 RPGrowth.py sampleTDB.txt patterns.txt 3 4 2  (maxPer and minPS  will be considered in support count or frequency and minRec is integer)
+    **Importing this algorithm into a python program**
 
-    Sample run of importing the code:
-    -------------------
+    .. code-block:: python
 
-            from PAMI.periodicFrequentPattern.recurring import RPGrowth as alg
+            from PAMI.uncertainFrequentPattern.basic import puf as alg
 
-            obj = alg.RPGrowth(iFile, maxPer, minPS, minRec)
+            obj = alg.PUFGrowth(iFile, minSup)
 
             obj.startMine()
 
-            recurringPatterns = obj.getPatterns()
+            frequentPatterns = obj.getPatterns()
 
-            print("Total number of Recurring Patterns:", len(recurringPatterns))
+            print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-            obj.save(oFile)
+            obj.savePatterns(oFile)
 
             Df = obj.getPatternsAsDataFrame()
 
-            memUSS = obj.getMemoryUSS()
+            memUSS = obj.getmemoryUSS()
 
             print("Total Memory in USS:", memUSS)
 
             memRSS = obj.getMemoryRSS()
 
             print("Total Memory in RSS", memRSS)
 
             run = obj.getRuntime()
 
             print("Total ExecutionTime in seconds:", run)
 
-        Credits:
-        -------
-            The complete program was written by C. Saideep under the supervision of Professor Rage Uday Kiran.\n
+    **Credits:**
 
-    """
+             The complete program was written by  P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+"""
     _startTime = float()
     _endTime = float()
-    _minPS = str()
-    _maxPer = float()
-    _minRec = str()
+    _minSup = str()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
     _rank = {}
-    _rankedUp = {}
-    _lno = 0
+
+    def __init__(self, iFile, minSup, sep='\t'):
+        super().__init__(iFile, minSup, sep)
 
     def _creatingItemSets(self):
-        """ Storing the complete values of the database/input file in a database variable
         """
-
+            Scans the uncertain transactional dataset
+        """
         self._Database = []
         if isinstance(self._iFile, _ab._pd.DataFrame):
+            uncertain, data = [], []
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
                 self._Database = self._iFile['Transactions'].tolist()
+            if 'uncertain' in i:
+                uncertain = self._iFile['uncertain'].tolist()
+            for k in range(len(data)):
+                tr = []
+                for j in range(len(data[k])):
+                    product = _Item(data[k][j], uncertain[k][j])
+                    tr.append(product)
+                self._Database.append(tr)
+
+            # print(self.Database)
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
-                    line.strip()
+                    line = line.strip()
                     line = line.decode("utf-8")
-                    temp = [i.rstrip() for i in line.split(self._sep)]
+                    temp1 = line.split(':')
+                    temp = [i.rstrip() for i in temp[0].split(self._sep)]
+                    uncertain = [float(i.rstrip()) for i in temp[1].split(self._sep)]
                     temp = [x for x in temp if x]
-                    self._Database.append(temp)
+                    uncertain = [x for x in uncertain if x]
+                    tr = []
+                    for i in range(len(temp)):
+                        item = temp[i]
+                        probability = uncertain[i]
+                        product = _Item(item, probability)
+                        tr.append(product)
+                    self._Database.append(tr)
             else:
                 try:
-                    with open(self._iFile, 'r', encoding='utf-8') as f:
+                    with open(self._iFile, 'r') as f:
                         for line in f:
-                            line.strip()
-                            temp = [i.rstrip() for i in line.split(self._sep)]
-                            temp = [x for x in temp if x]
-                            self._Database.append(temp)
+                            temp1 = line.strip()
+                            temp1 = temp1.split(':')
+                            temp = [i.rstrip() for i in temp1[0].split(self._sep)]
+                            uncertain = [float(i.rstrip()) for i in temp1[1].split(self._sep)]
+                            tr = []
+                            for i in range(len(temp)):
+                                item = temp[i]
+                                probability = uncertain[i]
+                                product = _Item(item, probability)
+                                tr.append(product)
+                            self._Database.append(tr)
                 except IOError:
                     print("File Not Found")
-                    quit()
 
-    def _OneItems(self):
-        """ Calculates the maxRec and support of each item in the database and assign ranks to the items
-            by decreasing support and returns the RP-list
-
-            :returns: return the RP-list
+    def _frequentOneItem(self):
+        """takes the self.Database and calculates the support of each item in the dataset and assign the
+            ranks to the items by decreasing support and returns the frequent items list
+                :param self.Database : it represents the one self.Database in database
+                :type self.Database : list
         """
-        #global rank
-        data = {}
-        for tr in self._Database:
-            for i in range(1, len(tr)):
-                if tr[i] not in data:
-                    data[tr[i]] = [[], int(tr[0]), int(tr[0]), 1, 0, 1]
+
+        mapSupport = {}
+        for i in self._Database:
+            for j in i:
+                if j.item not in mapSupport:
+                    mapSupport[j.item] = j.probability
                 else:
-                    lp = int(tr[0]) - data[tr[i]][2]
-                    if lp <= self._maxPer:
-                        data[tr[i]][3] += 1
-
-                    else:
-                        if data[tr[i]][3] >= self._minPS:
-                            data[tr[i]][0].append([data[tr[i]][1], data[tr[i]][2], data[tr[i]][3]])
-                            data[tr[i]][4] += data[tr[i]][3]
-                        data[tr[i]][3] = 1
-                        data[tr[i]][1] = int(tr[0])
-                    data[tr[i]][2] = int(tr[0])
-                    data[tr[i]][5] += 1
-            # print(data)
-           
-        for ri in data:
-            if data[ri][3] >= self._minPS:
-                data[ri][0].append([data[ri][1], data[ri][2], data[ri][3]])
-                data[ri][4] += data[ri][3]
-        data = {k: [v[0], v[5]] for k, v in data.items() if v[4] >= (self._minPS*self._minRec)}
-        genList = [k for k, v in sorted(data.items(), key=lambda x: (x[1][1], x[0]), reverse=True)]
-        self._rank = dict([(index, item) for (item, index) in enumerate(genList)])
-        return data, genList
-
-    def _updateDatabases(self, dict1):
-        """ Remove the items which does not  satisfy maxRec from database and updates the database with rank of items
-
-            :param dict1: Recurring items with support and recurrence
-            :type dict1: dictionary
-            :return: Sorted and updated transactions
-            """
-        list1 = []
-        for tr in self._Database:
-            list2 = [int(tr[0])]
-            for i in range(1, len(tr)):
-                if tr[i] in dict1:
-                    list2.append(self._rank[tr[i]])
-            if len(list2) >= 2:
-                basket = list2[1:]
-                basket.sort()
-                list2[1:] = basket[0:]
-                list1.append(list2)
-                # print(list2)
-        return list1
+                    mapSupport[j.item] += j.probability
+        mapSupport = {k: v for k, v in mapSupport.items() if v >= self._minSup}
+        plist = [k for k, v in sorted(mapSupport.items(), key=lambda x: x[1], reverse=True)]
+        self.rank = dict([(index, item) for (item, index) in enumerate(plist)])
+        return mapSupport, plist
 
     @staticmethod
     def _buildTree(data, info):
-        """ It takes the database and construct the main tree by setting root node as a null
-
-            :param data: it represents the one items in database
-            :type data: list
-            :param info: it represents the support and recurrence of each item
-            :type info: dictionary
-            :return: returns root node of tree
+        """it takes the self.Database and support of each item and construct the main tree with setting root
+            node as null
+                :param data : it represents the one self.Database in database
+                :type data : list
+                :param info : it represents the support of each item
+                :type info : dictionary
         """
 
         rootNode = _Tree()
         rootNode.info = info.copy()
         for i in range(len(data)):
-            set1 = [data[i][0]]
-            rootNode.addTransaction(data[i][1:], set1)
+            rootNode.addTransaction(data[i])
         return rootNode
 
-    def _savePeriodic(self, itemSet):
-        """ To convert the ranks of items in to their original item names
-
-            :param itemSet: recurring pattern
-            :return: recurring pattern with original item names
+    def _updateTransactions(self, dict1):
+        """remove the items which are not frequent from self.Database and updates the self.Database with rank of items
+            :param dict1 : frequent items with support
+            :type dict1 : dictionary
         """
-        t1 = str()
-        for i in itemSet:
-            t1 = t1 + self._rankedUp[i] + "\t"
-        return t1
+
+        list1 = []
+        for tr in self._Database:
+            list2 = []
+            for i in range(0, len(tr)):
+                if tr[i].item in dict1:
+                    list2.append(tr[i])
+            if len(list2) >= 2:
+                basket = list2
+                basket.sort(key=lambda val: self.rank[val.item])
+                list2 = basket
+                list1.append(list2)
+        return list1
+
+    @staticmethod
+    def _check(i, x):
+        """To check the presence of item or pattern in transaction
+                :param x: it represents the pattern
+                :type x : list
+                :param i : represents the uncertain self.Database
+                :type i : list
+        """
+
+        # This method taken a transaction as input and returns the tree
+        for m in x:
+            k = 0
+            for n in i:
+                if m == n.item:
+                    k += 1
+            if k == 0:
+                return 0
+        return 1
 
     def _convert(self, value):
         """
-        To convert the given user specified value
-
-        :param value: user specified value
-        :return: converted value
+        To convert the type of user specified minSup value
+            :param value: user specified minSup value
+            :return: converted type minSup value
         """
         if type(value) is int:
             value = int(value)
         if type(value) is float:
             value = (len(self._Database) * value)
         if type(value) is str:
             if '.' in value:
-                value = float(value)
                 value = (len(self._Database) * value)
             else:
                 value = int(value)
         return value
 
-    def startMine(self):
-        """ Mining process will start from this function
+    def _removeFalsePositives(self):
         """
+            To remove the false positive patterns generated in frequent patterns
+            :return: patterns with accurate probability
+        """
+        global _finalPatterns
+        periods = {}
+        for i in self._Database:
+            for x, y in _finalPatterns.items():
+                if len(x) == 1:
+                    periods[x] = y
+                else:
+                    s = 1
+                    check = self._check(i, x)
+                    if check == 1:
+                        for j in i:
+                            if j.item in x:
+                                s *= j.probability
+                        if x in periods:
+                            periods[x] += s
+                        else:
+                            periods[x] = s
+        for x, y in periods.items():
+            if y >= self._minSup:
+                sample = str()
+                for i in x:
+                    sample = sample + i + "\t"
+                self._finalPatterns[sample] = y
 
-        global _minPS, _minRec, _maxPer, _lno
+    def startMine(self):
+        """Main method where the patterns are mined by constructing tree and remove the remove the false patterns
+            by counting the original support of a patterns
+        """
+        global minSup
         self._startTime = _ab._time.time()
-        if self._iFile is None:
-            raise Exception("Please enter the file path or file name:")
         self._creatingItemSets()
-        self._minPS = self._convert(self._minPS)
-        self._maxPer = self._convert(self._maxPer)
-        self._minRec = int(self._minRec)
+        self._minSup = self._convert(self._minSup)
+        minSup = self._minSup
         self._finalPatterns = {}
-        _maxPer, _minPS, _minRec, _lno = self._maxPer, self._minPS, self._minRec, len(self._Database)
-        generatedItems, pfList = self._OneItems()
-        updatedDatabases = self._updateDatabases(generatedItems)
-        for x, y in self._rank.items():
-            self._rankedUp[y] = x
-        info = {self._rank[k]: v for k, v in generatedItems.items()}
-        Tree = self._buildTree(updatedDatabases, info)
-        patterns = Tree.generatePatterns([])
-        for i in patterns:
-            sample = self._savePeriodic(i[0])
-            self._finalPatterns[sample] = i[1]
+        mapSupport, plist = self._frequentOneItem()
+        self.Database1 = self._updateTransactions(mapSupport)
+        info = {k: v for k, v in mapSupport.items()}
+        Tree1 = self._buildTree(self.Database1, info)
+        Tree1.generatePatterns([])
+        self._removeFalsePositives()
+        print("Uncertain Frequent patterns were generated successfully using PUFGrowth algorithm")
         self._endTime = _ab._time.time()
         process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryUSS = float()
-        self._memoryRSS = float()
+        self.memoryRSS = float()
         self._memoryUSS = process.memory_full_info().uss
-        self._memoryRSS = process.memory_info().rss
-        print("Recurring patterns were generated successfully using RPGrowth algorithm ")
+        self.memoryRSS = process.memory_info().rss
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
-
         :return: returning USS memory consumed by the mining process
         :rtype: float
         """
 
         return self._memoryUSS
 
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the mining process will be retrieved from this function
-
         :return: returning RSS memory consumed by the mining process
         :rtype: float
         """
 
-        return self._memoryRSS
+        return self.memoryRSS
 
     def getRuntime(self):
         """Calculating the total amount of runtime taken by the mining process
-
-
         :return: returning total amount of runtime taken by the mining process
         :rtype: float
         """
 
         return self._endTime - self._startTime
 
     def getPatternsAsDataFrame(self):
-        """Storing final periodic-frequent patterns in a dataframe
-
-        :return: returning periodic-frequent patterns in a dataframe
+        """Storing final frequent patterns in a dataframe
+        :return: returning frequent patterns in a dataframe
         :rtype: pd.DataFrame
         """
 
-        dataFrame = {}
+        dataframe = {}
         data = []
         for a, b in self._finalPatterns.items():
-            s = str()
-            for i in a:
-                s = s + i + ' '
-            z = []
-            str1 = '{'
-            for z in b[0]:
-                str1 += '{' + str([z[0], z[1]]) + ' : ' + str(z[2]) + '}'
-            str1 += '}'
-            data.append([s.replace('\t', ' '), b[1], len(b[0]), str1])
-            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Recurrance', 'intervals'])
-        return dataFrame
+            data.append([a.replace('\t', ' '), b])
+            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
+        return dataframe
 
     def save(self, outFile):
-        """Complete set of periodic-frequent patterns will be loaded in to a output file
-
+        """Complete set of frequent patterns will be loaded in to a output file
         :param outFile: name of the output file
         :type outFile: file
         """
-        self._oFile = outFile
-        writer = open(self._oFile, 'w+')
+        self.oFile = outFile
+        writer = open(self.oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            s = str()
-            for i in x:
-                s = s + i + '\t'
-            str1 = '{'
-            for z in y[0]:
-                str1 += '{'+str([z[0], z[1]])+' : ' + str(z[2]) + '}'
-            str1 += '}'
-            s1 = s.strip() + ":" + str(y[1]) + ":" + str(len(y[0])) + ":" + str1
+            s1 = x.strip() + ":" + str(y)
             writer.write("%s \n" % s1)
-        writer.close()
 
     def getPatterns(self):
-        """ Function to send the set of periodic-frequent patterns after completion of the mining process
-
-        :return: returning periodic-frequent patterns
+        """ Function to send the set of frequent patterns after completion of the mining process
+        :return: returning frequent patterns
         :rtype: dict
         """
         return self._finalPatterns
 
     def printResults(self):
-        print("Total number of recurrent Patterns:", len(self.getPatterns()))
+        print("Total number of  Uncertain Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_ab._sys.argv) == 6 or len(_ab._sys.argv) == 7:
-        if len(_ab._sys.argv) == 7:
-            _ap = RPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5], _ab._sys.argv[6])
-        if len(_ab._sys.argv) == 6:
-            _ap = RPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
+    if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:
+        if len(_ab._sys.argv) == 5:
+            _ap = PUFGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+        if len(_ab._sys.argv) == 4:
+            _ap = PUFGrowth(_ab._sys.argv[1], _ab._sys.argv[3])
         _ap.startMine()
-        print("Total number of Patterns:", len(_ap.getPatterns()))
+        print("Total number of Uncertain Frequent Patterns:", _ap.getPatterns())
         _ap.save(_ab._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/recurringPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/recurringPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/relativeFrequentPatterns/basic/RSFPGrowth.py` & `pami-2023.5.1/PAMI/correlatedPattern/basic/CPGrowthPlus.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,88 +1,126 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# CPGrowthPlus is one of the efficient algorithm to discover Correlated frequent patterns in a transactional database.
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-#      Copyright (C)  2021 Rage Uday Kiran
+#  **Importing this algorithm into a python program**
+#   -----------------------------------------------
+#
+#                 from PAMI.coveragePattern.basic import CPPG as alg
+#
+#                 obj = alg.CPPG(iFile, minRF, minCS, maxOR)
+#
+#                 obj.startMine()
+#
+#                 coveragePatterns = obj.getPatterns()
+#
+#                 print("Total number of coverage Patterns:", len(coveragePatterns))
+#
+#                 obj.save(oFile)
+#
+#                 Df = obj.getPatternsAsDataFrame()
+#
+#                 memUSS = obj.getMemoryUSS()
+#
+#                 print("Total Memory in USS:", memUSS)
+#
+#                 memRSS = obj.getMemoryRSS()
+#
+#                 print("Total Memory in RSS", memRSS)
+#
+#                 run = obj.getRuntime()
+#
+#                 print("Total ExecutionTime in seconds:", run)
+
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+"""
+
+from PAMI.correlatedPattern.basic import abstract as _ab
 
-from PAMI.relativeFrequentPatterns.basic import abstract as _ab
 
 
 class _Node:
     """
-        A class used to represent the node of frequentPatterntree
+        A class used to represent the node of frequentPatternTree
 
-    Attributes:
+    Attributes :
     ----------
         itemId: int
             storing item of a node
         counter: int
             To maintain the support of node
         parent: node
             To maintain the parent of every node
         child: list
             To maintain the children of node
         nodeLink : node
             Points to the node with same itemId
 
-    Methods:
+    Methods :
     -------
 
         getChild(itemName)
-            returns the node with same itemName from frequentPatterntree
+            returns the node with same itemName from frequentPatternTree
     """
 
     def __init__(self):
         self.itemId = -1
         self.counter = 1
         self.parent = None
         self.child = []
         self.nodeLink = None
 
     def getChild(self, itemName):
-        """ Retrieving the child from the tree
+        """
+        Retrieving the child from the tree
 
             :param itemName: name of the child
             :type itemName: list
             :return: returns the node with same itemName from frequentPatternTree
-            :rtype: None or Node
+            :rtype: list
 
         """
         for i in self.child:
             if i.itemId == itemName:
                 return i
         return None
 
 
 class _Tree:
     """
         A class used to represent the frequentPatternGrowth tree structure
 
-    Attributes:
+    Attributes :
     ----------
         headerList : list
             storing the list of items in tree sorted in ascending of their supports
         mapItemNodes : dictionary
             storing the nodes with same item name
         mapItemLastNodes : dictionary
             representing the map that indicates the last node for each item
         root : Node
             representing the root Node in a tree
 
-    Methods:
+    Methods :
     -------
         createHeaderList(items,minSup)
             takes items only which are greater than minSup and sort the items in ascending order
         addTransaction(transaction)
             creating transaction as a branch in frequentPatternTree
         fixNodeLinks(item,newNode)
             To create the link for nodes with same item
@@ -95,15 +133,16 @@
     def __init__(self):
         self.headerList = []
         self.mapItemNodes = {}
         self.mapItemLastNodes = {}
         self.root = _Node()
 
     def addTransaction(self, transaction):
-        """adding transaction into tree
+        """
+        Adding a transaction into a tree
 
         :param transaction: it represents the one transactions in database
         :type transaction: list
         """
 
         # This method taken a transaction as input and returns the tree
         current = self.root
@@ -117,15 +156,16 @@
                 self.fixNodeLinks(i, newNode)
                 current = newNode
             else:
                 child.counter += 1
                 current = child
 
     def fixNodeLinks(self, item, newNode):
-        """Fixing node link for the newNode that inserted into frequentPatternTree
+        """
+        Fixing node link for the newNode that inserted into frequentPatternTree
 
         :param item: it represents the item of newNode
         :type item: int
         :param newNode: it represents the newNode that inserted in frequentPatternTree
         :type newNode: Node
 
         """
@@ -133,103 +173,121 @@
             lastNode = self.mapItemLastNodes[item]
             lastNode.nodeLink = newNode
         self.mapItemLastNodes[item] = newNode
         if item not in self.mapItemNodes.keys():
             self.mapItemNodes[item] = newNode
 
     def printTree(self, root):
-        """Print the details of Node in frequentPatternTree
+        """
+
+        Print the details of Node in frequentPatternTree
 
         :param root: it represents the Node in frequentPatternTree
         :type root: Node
 
         """
 
         # this method is used print the details of tree
         if not root.child:
             return
         else:
             for i in root.child:
                 print(i.itemId, i.counter, i.parent.itemId)
                 self.printTree(i)
 
-    def createHeaderList(self, __mapSupport, minSup):
-        """To create the headerList
+    def createHeaderList(self, mapSupport, minSup):
+        """
+
+        To create the headerList
 
-        :param __mapSupport: it represents the items with their supports
-        :type __mapSupport: dictionary
+        :param mapSupport: it represents the items with their supports
+        :type mapSupport: dictionary
         :param minSup: it represents the minSup
         :param minSup: float
+
         """
         # the frequentPatternTree always maintains the header table to start the mining from leaf nodes
         t1 = []
-        for x, y in __mapSupport.items():
+        for x, y in mapSupport.items():
             if y >= minSup:
                 t1.append(x)
-        __itemSetBuffer = [k for k, v in sorted(__mapSupport.items(), key=lambda x: x[1], reverse=True)]
-        self.headerList = [i for i in t1 if i in __itemSetBuffer]
+        itemSetBuffer = [k for k, v in sorted(mapSupport.items(), key=lambda x: x[1], reverse=True)]
+        self.headerList = [i for i in t1 if i in itemSetBuffer]
+
+    def addPrefixPath(self, prefix, mapSupportBeta, minSup):
+        """
 
-    def addPrefixPath(self, prefix, __mapSupportBeta, minSup):
-        """To construct the conditional tree with prefix paths of a node in frequentPatternTree
+        To construct the conditional tree with prefix paths of a node in frequentPatternTree
 
         :param prefix: it represents the prefix items of a Node
         :type prefix: list
-        :param __mapSupportBeta: it represents the items with their supports
-        :param __mapSupportBeta: dictionary
+        :param mapSupportBeta: it represents the items with their supports
+        :param mapSupportBeta: dictionary
         :param minSup: to check the item meets with minSup
         :param minSup: float
+
         """
         # this method is used to add prefix paths in conditional trees of frequentPatternTree
         pathCount = prefix[0].counter
         current = self.root
         prefix.reverse()
         for i in range(0, len(prefix) - 1):
             pathItem = prefix[i]
-            if __mapSupportBeta.get(pathItem.itemId) >= minSup:
+            if mapSupportBeta.get(pathItem.itemId) >= minSup:
                 child = current.getChild(pathItem.itemId)
                 if not child:
                     newNode = _Node()
                     newNode.itemId = pathItem.itemId
                     newNode.parent = current
                     newNode.counter = pathCount
                     current.child.append(newNode)
                     current = newNode
                     self.fixNodeLinks(pathItem.itemId, newNode)
                 else:
                     child.counter += pathCount
                     current = child
 
 
-class RSFPGrowth(_ab._frequentPatterns):
-    """
-        Algorithm to find all items with relative support from given dataset
+class CPGrowthPlus(_ab._correlatedPatterns):
+    """ 
+    :Description:    CPGrowthPlus is one of the efficient algorithm to discover Correlated frequent patterns in a transactional database.
+                     Using Item Support Intervals technique which is generating correlated patterns of higher order by combining only with items that
+                     have support within specified interval.
+
+    :Reference:
+        Uday Kiran R., Kitsuregawa M. (2012) Efficient Discovery of Correlated Patterns in Transactional Databases Using Items Support Intervals.
+        In: Liddle S.W., Schewe KD., Tjoa A.M., Zhou X. (eds) Database and Expert Systems Applications. DEXA 2012. Lecture Notes in Computer Science, vol 7446. Springer, Berlin, Heidelberg.
+        https://doi.org/10.1007/978-3-642-32600-4_18
+
+    :param  iFile: str :
+                   Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  minSup: int or float or str :
+                   The user can specify minSup either in count or proportion of database size. If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+    :param  minAllConf: str :
+                   Name of Neighbourhood file name
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
 
-    Reference:
-    --------
-        'Towards Efficient Discovery of Frequent Patterns with Relative Support' R. Uday Kiran and
-               Masaru Kitsuregawa, http://comad.in/comad2012/pdf/kiran.pdf
 
-    Attributes:
-    ----------
-        iFile : file
-            Name of the Input file to mine complete set of frequent patterns
-        oFile : file
-            Name of the output file to store complete set of frequent patterns
+    :Attributes:
+
         memoryUSS : float
             To store the total amount of USS memory consumed by the program
         memoryRSS : float
             To store the total amount of RSS memory consumed by the program
         startTime:float
             To record the start time of the mining process
         endTime:float
             To record the completion time of the mining process
         minSup : float
             The user given minSup
-        minRS : float
-            The user given minRS
+        minAllConf: float
+            The user given minimum all confidence Ratio (should be in range of 0 to 1)
         Database : list
             To store the transactions of a database in list
         mapSupport : Dictionary
             To maintain the information of item and their frequency
         lno : int
             it represents the total no of transactions
         tree : class
@@ -239,433 +297,405 @@
         finalPatterns : dict
             it represents to store the patterns
         itemSetBuffer : list
             it represents the store the items in mining
         maxPatternLength : int
            it represents the constraint for pattern length
 
-    Methods:
-    -------
-        startMine()
-            Mining process will start from here
-        getFrequentPatterns()
-            Complete set of patterns will be retrieved with this function
-        save(oFile)
-            Complete set of frequent patterns will be loaded in to a output file
-        getPatternsAsDataFrame()
-            Complete set of frequent patterns will be loaded in to a dataframe
-        getmemoryUSS()
-            Total amount of USS memory consumed by the mining process will be retrieved from this function
-        getMemoryRSS()
-            Total amount of RSS memory consumed by the mining process will be retrieved from this function
-        getRuntime()
-            Total amount of runtime taken by the mining process will be retrieved from this function
-        check(line)
-            To check the delimiter used in the user input file
-        creatingItemSets(fileName)
-            Scans the dataset or dataframes and stores in list format
-        frequentOneItem()
-            Extracts the one-frequent patterns from transactions
-        saveAllCombination(tempBuffer,s,position,prefix,prefixLength)
-            Forms all the combinations between prefix and tempBuffer lists with support(s)
-        saveItemSet(pattern,support)
-            Stores all the frequent patterns with their respective support
-        frequentPatternGrowthGenerate(frequentPatternTree,prefix,port)
-            Mining the frequent patterns by forming conditional frequentPatternTrees to particular prefix item.
-            __mapSupport represents the 1-length items with their respective support
+    **Methods to execute code on terminal**
+    ---------------------------------------
 
-    Executing the code on terminal:
-    -------
-        Format:
-        -------
-            python3 RSFPGrowth.py <inputFile> <outputFile> <minSup> <minRS>
+            Format:
+                      >>>  python3 CPPG.py <inputFile> <outputFile> <minRF> <minCS> <maxOR> <'\t'>
 
-        Examples:
-        ---------
-            python3 RSFPGrowth.py sampleDB.txt patterns.txt 0.23 0.2  (minSup will be considered in percentage of database transactions)
+            Example:
+                      >>>   python3 CPPG.py sampleTDB.txt patterns.txt 0.4 0.7 0.5 ','
 
-            python3 RSFPGrowth.py sampleDB.txt patterns.txt 3   0.2  (minSup will be considered in support count or frequency)
 
 
-    Sample run of the importing code:
-    -----------
-        from PAMI.frequentPatternUsingOtherMeasures import RSFPGrowth as alg
+    **Importing this algorithm into a python program**
+    -----------------------------------------------------------------
 
-        obj = alg.RSFPGrowth(iFile, minSup, minRS)
+    .. code-block:: python
 
-        obj.startMine()
+                from PAMI.coveragePattern.basic import CPPG as alg
 
-        frequentPatterns = obj.getPatterns()
+                obj = alg.CPPG(iFile, minRF, minCS, maxOR)
 
-        print("Total number of Frequent Patterns:", len(frequentPatterns))
+                obj.startMine()
 
-        obj.save(oFile)
+                coveragePatterns = obj.getPatterns()
 
-        Df = obj.getPatternsAsDataFrame()
+                print("Total number of coverage Patterns:", len(coveragePatterns))
 
-        memUSS = obj.getmemoryUSS()
+                obj.save(oFile)
 
-        print("Total Memory in USS:", memUSS)
+                Df = obj.getPatternsAsDataFrame()
 
-        memRSS = obj.getMemoryRSS()
+                memUSS = obj.getMemoryUSS()
 
-        print("Total Memory in RSS", memRSS)
+                print("Total Memory in USS:", memUSS)
 
-        run = obj.getRuntime()
+                memRSS = obj.getMemoryRSS()
 
-        print("Total ExecutionTime in seconds:", run)
+                print("Total Memory in RSS", memRSS)
 
-    Credits:
-    -------
-        The complete program was written by Sai Chitra.B  under the supervision of Professor Rage Uday Kiran.
+                run = obj.getRuntime()
+
+                print("Total ExecutionTime in seconds:", run)
+
+
+    **Credits:**
+    -------------
+
+             The complete program was written by B.Sai Chitra under the supervision of Professor Rage Uday Kiran.
 
         """
 
-    __startTime = float()
-    __endTime = float()
+    _startTime = float()
+    _endTime = float()
     _minSup = str()
-    _minRS = float()
-    __finalPatterns = {}
+    _finalPatterns = {}
     _iFile = " "
     _oFile = " "
-    _sep = " "
-    __memoryUSS = float()
-    __memoryRSS = float()
-    __Database = []
-    __mapSupport = {}
-    __lno = 0
-    __tree = _Tree()
-    __itemSetBuffer = None
-    __fpNodeTempBuffer = []
-    __itemSetCount = 0
-    __maxPatternLength = 1000
-
-    def __init__(self, iFile, __minSup, __minRS, sep='\t'):
-        super().__init__(iFile, __minSup, __minRS, sep)
-        self.__finalPatterns = {}
+    _minAllConf = 0.0
+    _memoryUSS = float()
+    _memoryRSS = float()
+    _Database = []
+    _mapSupport = {}
+    _lno = 0
+    _tree = str()
+    _itemSetBuffer = None
+    _fpNodeTempBuffer = []
+    _itemSetCount = 0
+    _maxPatternLength = 1000
+    _sep = "\t"
+
+    def __init__(self, iFile, minSup, minAllConf, sep="\t"):
+        super().__init__(iFile, minSup, minAllConf, sep)
 
-    def __creatingItemSets(self):
+    def _creatingItemSets(self):
         """
-            Storing the complete transactions of the __Database/input file in a __Database variable
+            Storing the complete transactions of the database/input file in a database variable
 
 
             """
-        self.__Database = []
+        self._Database = []
         if isinstance(self._iFile, _ab._pd.DataFrame):
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
-                self.__Database = self._iFile['Transactions'].tolist()
+                self._Database = self._iFile['Transactions'].tolist()
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
-                    self.__Database.append(temp)
+                    self._Database.append(temp)
             else:
                 try:
                     with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
                             line.strip()
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
-                            self.__Database.append(temp)
+                            self._Database.append(temp)
                 except IOError:
                     print("File Not Found")
                     quit()
 
-    def __frequentOneItem(self):
-        """Generating One frequent items sets
+    def _frequentOneItem(self):
+        """
+        Generating One frequent items sets
 
         """
-        self.__mapSupport = {}
-        for i in self.__Database:
+        self._mapSupport = {}
+        for i in self._Database:
             for j in i:
-                if j not in self.__mapSupport:
-                    self.__mapSupport[j] = 1
+                if j not in self._mapSupport:
+                    self._mapSupport[j] = 1
                 else:
-                    self.__mapSupport[j] += 1
+                    self._mapSupport[j] += 1
 
-    def __saveItemSet(self, prefix, prefixLength, support, ratio):
-        """To save the frequent patterns mined form frequentPatternTree
+    def _saveItemSet(self, prefix, prefixLength, support, ratio):
+        """
+        To save the frequent patterns mined form frequentPatternTree
 
         :param prefix: the frequent pattern
         :type prefix: list
         :param prefixLength: the length of a frequent pattern
         :type prefixLength: int
         :param support: the support of a pattern
         :type support:  int
         """
 
         sample = []
         for i in range(prefixLength):
             sample.append(prefix[i])
-        self.__itemSetCount += 1
-        self.__finalPatterns[tuple(sample)] = str(support) + " : " + str(ratio)
+        self._itemSetCount += 1
+        self._finalPatterns[tuple(sample)] = [support, ratio]
 
-    def __saveAllCombinations(self, tempBuffer, s, position, prefix, prefixLength):
-        """Generating all the combinations for items in single branch in frequentPatternTree
+    def _saveAllCombinations(self, tempBuffer, s, position, prefix, prefixLength):
+        """
+        Generating all the combinations for items in single branch in frequentPatternTree
 
         :param tempBuffer: items in a list
         :type tempBuffer: list
         :param s: support at leaf node of a branch
         :param position: the length of a tempBuffer
         :type position: int
         :param prefix: it represents the list of leaf node
         :type prefix: list
         :param prefixLength: the length of prefix
         :type prefixLength: int
-
+        
         """
         max1 = 1 << position
         for i in range(1, max1):
             newPrefixLength = prefixLength
             for j in range(position):
                 isSet = i & (1 << j)
                 if isSet > 0:
                     prefix.insert(newPrefixLength, tempBuffer[j].itemId)
                     newPrefixLength += 1
-            ratio = s / self.__mapSupport[self.__getMinItem(prefix, newPrefixLength)]
-            if ratio >= self._minRS:
-                self.__saveItemSet(prefix, newPrefixLength, s, ratio)
+            ratio = s/self._mapSupport[self._getMaxItem(prefix, newPrefixLength)]
+            if ratio >= self._minAllConf:
+                self._saveItemSet(prefix, newPrefixLength, s, ratio)
 
-    def __frequentPatternGrowthGenerate(self, frequentPatternTree, prefix, prefixLength, __mapSupport, minConf):
-        """Mining the fp tree
+    def _frequentPatternGrowthGenerate(self, frequentPatternTree, prefix, prefixLength, mapSupport, minConf):
+        """
+        Mining the fp tree
 
         :param frequentPatternTree: it represents the frequentPatternTree
         :type frequentPatternTree: class Tree
         :param prefix: it represents a empty list and store the patterns that are mined
         :type prefix: list
         :param param prefixLength: the length of prefix
         :type prefixLength: int
-        :param __mapSupport : it represents the support of item
-        :type __mapSupport : dictionary
+        :param mapSupport : it represents the support of item
+        :type mapSupport : dictionary
         """
         singlePath = True
         position = 0
         s = 0
         if len(frequentPatternTree.root.child) > 1:
             singlePath = False
         else:
             currentNode = frequentPatternTree.root.child[0]
             while True:
                 if len(currentNode.child) > 1:
                     singlePath = False
                     break
-                self.__fpNodeTempBuffer.insert(position, currentNode)
+                self._fpNodeTempBuffer.insert(position, currentNode)
                 s = currentNode.counter
                 position += 1
                 if len(currentNode.child) == 0:
                     break
                 currentNode = currentNode.child[0]
         if singlePath is True:
-            self.__saveAllCombinations(self.__fpNodeTempBuffer, s, position, prefix, prefixLength)
+            self._saveAllCombinations(self._fpNodeTempBuffer, s, position, prefix, prefixLength)
         else:
             for i in reversed(frequentPatternTree.headerList):
                 item = i
-                support = __mapSupport[i]
-                CminSup = max(self._minSup, support * self._minRS)
-                betaSupport = support
+                support = mapSupport[i]
+                low = max(int(_ab._math.floor(mapSupport[i]*self._minAllConf)), self._minSup)
+                high = max(int(_ab._math.floor(mapSupport[i]/minConf)), self._minSup)
+                betaSupport = support              
                 prefix.insert(prefixLength, item)
-                max1 = self.__getMinItem(prefix, prefixLength)
-                if self.__mapSupport[max1] > self.__mapSupport[item]:
+                max1 = self._getMaxItem(prefix, prefixLength)
+                if self._mapSupport[max1] < self._mapSupport[item]:
                     max1 = item
-                ratio = support / self.__mapSupport[max1]
-                if ratio >= self._minRS:
-                    self.__saveItemSet(prefix, prefixLength + 1, betaSupport, ratio)
-                if prefixLength + 1 < self.__maxPatternLength:
+                ratio = support / self._mapSupport[max1]
+                if ratio >= self._minAllConf:
+                    self._saveItemSet(prefix, prefixLength + 1, betaSupport, ratio)
+                if prefixLength + 1 < self._maxPatternLength:
                     prefixPaths = []
                     path = frequentPatternTree.mapItemNodes.get(item)
-                    __mapSupportBeta = {}
+                    mapSupportBeta = {}
                     while path is not None:
                         if path.parent.itemId != -1:
                             prefixPath = [path]
                             pathCount = path.counter
                             parent1 = path.parent
-                            if __mapSupport.get(parent1.itemId) >= CminSup:
+                            if mapSupport.get(parent1.itemId) >= low and mapSupport.get(parent1.itemId) <= high:
                                 while parent1.itemId != -1:
-                                    mins = CminSup
-                                    if __mapSupport.get(parent1.itemId) >= mins:
+                                    allconf = int(support/max(mapSupport.get(parent1.itemId), support))
+                                    if mapSupport.get(parent1.itemId) >= allconf:
                                         prefixPath.append(parent1)
-                                        if __mapSupportBeta.get(parent1.itemId) is None:
-                                            __mapSupportBeta[parent1.itemId] = pathCount
+                                        if mapSupportBeta.get(parent1.itemId) is None:
+                                            mapSupportBeta[parent1.itemId] = pathCount
                                         else:
-                                            __mapSupportBeta[parent1.itemId] = __mapSupportBeta[
-                                                                                   parent1.itemId] + pathCount
+                                            mapSupportBeta[parent1.itemId] = mapSupportBeta[parent1.itemId] + pathCount
                                         parent1 = parent1.parent
                                     else:
                                         break
                                 prefixPaths.append(prefixPath)
                         path = path.nodeLink
-                    __treeBeta = _Tree()
+                    treeBeta = _Tree()
                     for k in prefixPaths:
-                        __treeBeta.addPrefixPath(k, __mapSupportBeta, self._minSup)
-                    if len(__treeBeta.root.child) > 0:
-                        __treeBeta.createHeaderList(__mapSupportBeta, self._minSup)
-                        self.__frequentPatternGrowthGenerate(__treeBeta, prefix, prefixLength + 1, __mapSupportBeta,
-                                                           minConf)
+                        treeBeta.addPrefixPath(k, mapSupportBeta, self._minSup)
+                    if len(treeBeta.root.child) > 0:
+                        treeBeta.createHeaderList(mapSupportBeta, self._minSup)
+                        self._frequentPatternGrowthGenerate(treeBeta, prefix, prefixLength + 1, mapSupportBeta, minConf)
 
-    def __convert(self, value):
+    def _convert(self, value):
         """
-        to convert the type of user specified __minSup value
-        :param value: user specified __minSup value
+        to convert the type of user specified minSup value
+        :param value: user specified minSup value
         :return: converted type
         """
         if type(value) is int:
             value = int(value)
         if type(value) is float:
-            value = (len(self.__Database) * value)
+            value = (len(self._Database) * value)
         if type(value) is str:
             if '.' in value:
-                value = float(value)
-                value = (len(self.__Database) * value)
+                value = (len(self._Database) * value)
             else:
                 value = int(value)
         return value
 
     def startMine(self):
         """
-            main program to start the operation
+        main program to start the operation
+
         """
 
-        self.__startTime = _ab._time.time()
+        self._startTime = _ab._time.time()
         if self._iFile is None:
             raise Exception("Please enter the file path or file name:")
         if self._minSup is None:
             raise Exception("Please enter the Minimum Support")
-        self.__creatingItemSets()
-        self._minSup = self.__convert(self._minSup)
-        self._minRS = float(self._minRS)
-        self.__frequentOneItem()
-        self.__finalPatterns = {}
-        self.__mapSupport = {k: v for k, v in self.__mapSupport.items() if v >= self._minSup}
-        __itemSetBuffer = [k for k, v in sorted(self.__mapSupport.items(), key=lambda x: x[1], reverse=True)]
-        for i in self.__Database:
-            transaction = []
+        self._creatingItemSets()
+        self._finalPatterns = {}
+        self._tree = _Tree()
+        self._minSup = self._convert(self._minSup)
+        self._frequentOneItem()
+        self._mapSupport = {k: v for k, v in self._mapSupport.items() if v >= self._minSup}
+        _itemSetBuffer = [k for k, v in sorted(self._mapSupport.items(), key=lambda x: x[1], reverse=True)]
+        for i in self._Database:
+            _transaction = []
             for j in i:
-                if j in __itemSetBuffer:
-                    transaction.append(j)
-            transaction.sort(key=lambda val: self.__mapSupport[val], reverse=True)
-            self.__tree.addTransaction(transaction)
-        self.__tree.createHeaderList(self.__mapSupport, self._minSup)
-        if len(self.__tree.headerList) > 0:
-            self.__itemSetBuffer = []
-            self.__frequentPatternGrowthGenerate(self.__tree, self.__itemSetBuffer, 0, self.__mapSupport, self._minRS)
-        print("Relative support frequent patterns were generated successfully using RSFPGrowth algorithm")
-        self.__endTime = _ab._time.time()
+                if j in _itemSetBuffer:
+                    _transaction.append(j)
+            _transaction.sort(key=lambda val: self._mapSupport[val], reverse=True)
+            self._tree.addTransaction(_transaction)
+        self._tree.createHeaderList(self._mapSupport, self._minSup)
+        if len(self._tree.headerList) > 0:
+            self._itemSetBuffer = []
+            self._frequentPatternGrowthGenerate(self._tree, self._itemSetBuffer, 0, self._mapSupport, self._minAllConf)
+        print("Correlated Frequent patterns were generated successfully using CorrelatedPatternGrowth algorithm")
+        self._endTime = _ab._time.time()
         process = _ab._psutil.Process(_ab._os.getpid())
-        self.__memoryRSS = float()
-        self.__memoryUSS = float()
-        self.__memoryUSS = process.memory_full_info().uss
-        self.__memoryRSS = process.memory_info().rss
+        self._memoryRSS = float()
+        self._memoryUSS = float()
+        self._memoryUSS = process.memory_full_info().uss
+        self._memoryRSS = process.memory_info().rss
 
     def getMemoryUSS(self):
-        """Total amount of USS memory consumed by the mining process will be retrieved from this function
+        """
+        Total amount of USS memory consumed by the mining process will be retrieved from this function
 
         :return: returning USS memory consumed by the mining process
         :rtype: float
         """
 
-        return self.__memoryUSS
+        return self._memoryUSS
 
     def getMemoryRSS(self):
-        """Total amount of RSS memory consumed by the mining process will be retrieved from this function
+        """
+        Total amount of RSS memory consumed by the mining process will be retrieved from this function
 
         :return: returning RSS memory consumed by the mining process
         :rtype: float
         """
 
-        return self.__memoryRSS
+        return self._memoryRSS
 
-    def __getMinItem(self, prefix, prefixLength):
-        """
-            returns the minItem from prefix
-        """
-        minItem = prefix[0]
+    def _getMaxItem(self, prefix, prefixLength):
+        maxItem = prefix[0]
         for i in range(prefixLength):
-            if self.__mapSupport[minItem] > self.__mapSupport[prefix[i]]:
-                minItem = prefix[i]
-        return minItem
-
+            if self._mapSupport[maxItem] < self._mapSupport[prefix[i]]:
+                maxItem = prefix[i]
+        return maxItem
+    
     def getRuntime(self):
-        """Calculating the total amount of runtime taken by the mining process
+        """
+        Calculating the total amount of runtime taken by the mining process
 
 
         :return: returning total amount of runtime taken by the mining process
         :rtype: float
         """
 
-        return self.__endTime - self.__startTime
+        return self._endTime - self._startTime
 
     def getPatternsAsDataFrame(self):
-        """Storing final frequent patterns in a dataframe
+        """
+        Storing final frequent patterns in a dataframe
 
         :return: returning frequent patterns in a dataframe
         :rtype: pd.DataFrame
         """
 
         dataframe = {}
         data = []
-        for a, b in self.__finalPatterns.items():
-            pattern = str()
+        for a, b in self._finalPatterns.items():
+            pat = " "
             for i in a:
-                pattern = pattern + i + " "
-            data.append([pattern, b])
-            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
+                pat += str(i) + " "
+            data.append([pat, b[0], b[1]])
+            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Confidence'])
         return dataframe
 
     def save(self, outFile):
-        """Complete set of frequent patterns will be loaded in to a output file
+        """
+        Complete set of frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
         :type outFile: file
         """
-        self.__oFile = outFile
-        writer = open(self.__oFile, 'w+')
-        for x, y in self.__finalPatterns.items():
+        self._oFile = outFile
+        writer = open(self._oFile, 'w+')
+        for x, y in self._finalPatterns.items():
             pattern = str()
             for i in x:
                 pattern = pattern + i + "\t"
-            s1 = pattern.strip() + ": " + str(y)
+            s1 = str(pattern.strip()) + ":" + str(y[0]) + ":" + str(y[1])
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
-        """ Function to send the set of frequent patterns after completion of the mining process
+        """
+        Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
         :rtype: dict
         """
-        res = dict()
-        for x, y in self.__finalPatterns.items():
-            pattern = str()
-            for i in x:
-                pattern = pattern + i + "\t"
-            s1 = str(y)
-            res[pattern] = s1
-        return res
+        return self._finalPatterns
 
     def printResults(self):
-        print("Total number of Relative Frequent Patterns:", len(self.getPatterns()))
+        print("Total number of Correlated Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
     if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
         if len(_ab._sys.argv) == 6:
-            _ap = RSFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
+            _ap = CPGrowthPlus(_ab._sys.argv[1], _ab._sys.argv[3], float(_ab._sys.argv[4]), _ab._sys.argv[5])
         if len(_ab._sys.argv) == 5:
-            _ap = RSFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+            _ap = CPGrowthPlus(_ab._sys.argv[1], _ab._sys.argv[3], float(_ab._sys.argv[4]))
         _ap.startMine()
-        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
+        _correlatedPatterns = _ap.getPatterns()
+        print("Total number of Correlated-Frequent Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
-        print("Total ExecutionTime in ms:", _ap.getRuntime())
+        print("Total ExecutionTime in seconds:", _ap.getRuntime())
     else:
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `pami-2023.4.1/PAMI/relativeFrequentPatterns/basic/abstract.py` & `pami-2023.5.1/PAMI/relativeFrequentPatterns/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/relativeHighUtilityPatterns/basic/RHUIM.py` & `pami-2023.5.1/PAMI/relativeHighUtilityPatterns/basic/RHUIM.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,57 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.relativeHighUtilityPatterns.basic import RHUIM as alg
+#
+#     obj = alg.RHUIM("input.txt", 35, 20)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     memUSS = obj.getmemoryUSS()
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 
 from PAMI.relativeHighUtilityPatterns.basic import abstract as _ab
 
 
 class _Transaction:
     """
@@ -247,18 +283,22 @@
             A method to return transactions from database
         """
         return self.transactions
 
 
 class RHUIM(_ab._utilityPatterns):
     """
-    RHUIM algorithm helps us to mine Relative High Utility itemSets from transactional databases.
+
+    Description:
+    --------------
+
+        RHUIM algorithm helps us to mine Relative High Utility itemSets from transactional databases.
     
     Reference:
-    ---------
+    ----------
         R. U. Kiran, P. Pallikila, J. M. Luna, P. Fournier-Viger, M. Toyoda and P. K. Reddy,
         "Discovering Relative High Utility Itemsets in Very Large Transactional Databases Using Null-Invariant Measure,"
         2021 IEEE International Conference on Big Data (Big Data), Orlando, FL, USA, 2021, pp. 252-262,
         doi: 10.1109/BigData52589.2021.9672064.
     
     Attributes:
     -----------
@@ -326,53 +366,57 @@
         sortDatabase(self, transactions)
               A Method to sort transaction
         sort_transaction(self, trans1, trans2)
               A Method to sort transaction
         useUtilityBinArrayToCalculateLocalUtilityFirstTime(self, dataset)
              A method to calculate local utility values for single itemSets
 
-    Executing the code on terminal :
-    -------
-        Format:
-            python3 RHUIM.py <inputFile> <outputFile> <minUtil> <sep>
-        Examples:
-            python3 RHUIM.py sampleTDB.txt output.txt 35 20 (it will consider "\t" as separator)
 
-            python3 RHUIM.py sampleTDB.txt output.txt 35 20 , (it will consider "," as separator)
+    **Methods to execute code on terminal**
 
-    Sample run of importing the code:
-    -------------------------------
-        
-        from PAMI.relativeHighUtilityPatterns.basic import RHUIM as alg
+            Format:
+                      >>> python3 RHUIM.py <inputFile> <outputFile> <minUtil> <sep>
+            Example:
+                      >>>  python3 RHUIM.py sampleTDB.txt output.txt 35 20
 
-        obj=alg.RHUIM("input.txt", 35, 20)
 
-        obj.startMine()
+    **Importing this algorithm into a python program**
 
-        Patterns = obj.getPatterns()
+    .. code-block:: python
 
-        print("Total number of relative high utility Patterns:", len(Patterns))
+            from PAMI.relativeHighUtilityPatterns.basic import RHUIM as alg
 
-        obj.save("output")
+            obj=alg.RHUIM("input.txt", 35, 20)
 
-        memUSS = obj.getMemoryUSS()
+            obj.startMine()
 
-        print("Total Memory in USS:", memUSS)
+            frequentPatterns = obj.getPatterns()
 
-        memRSS = obj.getMemoryRSS()
+            print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-        print("Total Memory in RSS", memRSS)
+            obj.savePatterns(oFile)
+
+            Df = obj.getPatternsAsDataFrame()
+
+            memUSS = obj.getmemoryUSS()
+
+            print("Total Memory in USS:", memUSS)
+
+            memRSS = obj.getMemoryRSS()
+
+            print("Total Memory in RSS", memRSS)
+
+            run = obj.getRuntime()
+
+            print("Total ExecutionTime in seconds:", run)
+    **Credits:**
+
+             The complete program was written by  Pradeep Pallikila  under the supervision of Professor Rage Uday Kiran.
 
-        run = obj.getRuntime()
 
-        print("Total ExecutionTime in seconds:", run)
-   
-    Credits:
-    -------
-        The complete program was written by Pradeep Pallikila under the supervision of Professor Rage Uday Kiran.
      
     """
 
     _relativeHighUtilityItemSets = []
     _candidateCount = 0
     _utilityBinArrayLU = {}
     _utilityBinArraySU = {}
```

### Comparing `pami-2023.4.1/PAMI/relativeHighUtilityPatterns/basic/abstract.py` & `pami-2023.5.1/PAMI/relativeHighUtilityPatterns/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/sequentialPatternMining/basic/SPADE.py` & `pami-2023.5.1/PAMI/sequentialPatternMining/basic/SPADE.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,38 +1,77 @@
 
-#  Copyright (C)  2023 Rage Uday Kiran
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#     import PAMI.frequentPattern.basic.SPADE as alg
+#
+#     obj = alg.SPADE(iFile, minSup)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     print("Total Memory in USS:", memUSS)
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 
 from PAMI.sequentialPatternMining.basic import abstract as _ab
 
 _ab._sys.setrecursionlimit(10000)
 
 class SPADE(_ab._sequentialPatterns):
     """
+    Description:
+    -------------
         SPADE is one of the fundamental algorithm to discover sequential frequent patterns in a transactional database.
         This program employs SPADE property (or downward closure property) to  reduce the search space effectively.
         This algorithm employs breadth-first search technique when 1-2 length patterns and depth-first serch when above 3 length patterns to find the complete set of frequent patterns in a
         transactional database.
-        Reference:
-        ----------
+
+    Reference:
+    ----------
             Mohammed J. Zaki. 2001. SPADE: An Efficient Algorithm for Mining Frequent Sequences. Mach. Learn. 42, 1-2 (January 2001), 31-60. DOI=10.1023/A:1007652502315 http://dx.doi.org/10.1023/A:1007652502315
-        Attributes:
-        ----------
+
+    Attributes:
+    ----------
             iFile : str
                 Input file name or path of the input file
             oFile : str
                 Name of the output file or the path of output file
             minSup: float or int or str
                 The user can specify minSup either in count or proportion of database size.
                 If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
@@ -54,16 +93,16 @@
             Database : list
                 To store the transactions of a database in list
             _xLenDatabase: dict
                 To store the datas in different sequence separated by sequence, rownumber, length.
             _xLenDatabaseSame : dict
                 To store the datas in same sequence separated by sequence, rownumber, length.
 
-        Methods:
-        -------
+    Methods:
+    -------
             startMine()
                 Mining process will start from here
             getPatterns()
                 Complete set of patterns will be retrieved with this function
             savePatterns(oFile)
                 Complete set of frequent patterns will be loaded in to a output file
             getPatternsAsDataFrame()
@@ -74,43 +113,57 @@
                 Total amount of RSS memory consumed by the mining process will be retrieved from this function
             getRuntime()
                 Total amount of runtime taken by the mining process will be retrieved from this function
             candidateToFrequent(candidateList)
                 Generates frequent patterns from the candidate patterns
             frequentToCandidate(frequentList, length)
                 Generates candidate patterns from the frequent patterns
+    **Methods to execute code on terminal**
 
-
-        Executing the code on terminal:
-        -------------------------------
             Format:
-            ------
-                python3 SPADE.py <inputFile> <outputFile> <minSup>
-            Examples:
-            ---------
-                python3 SPADE.py sampleDB.txt patterns.txt 10.0   (minSup will be considered in times of minSup and count of database transactions)
-                python3 SPADE.py sampleDB.txt patterns.txt 10     (minSup will be considered in support count or frequency)
-        Sample run of the importing code:
-        ---------------------------------
+                      >>>  python3 SPADE.py <inputFile> <outputFile> <minSup>
+            Example:
+                      >>>  python3 SPADE.py sampleDB.txt patterns.txt 10.0   (minSup will be considered in times of minSup and count of database transactions)
+
+
+
+    **Importing this algorithm into a python program**
+
+        .. code-block:: python
+
             import PAMI.frequentPattern.basic.SPADE as alg
+
             obj = alg.SPADE(iFile, minSup)
+
             obj.startMine()
+
             frequentPatterns = obj.getPatterns()
+
             print("Total number of Frequent Patterns:", len(frequentPatterns))
+
             obj.savePatterns(oFile)
+
             Df = obj.getPatternInDataFrame()
+
             memUSS = obj.getMemoryUSS()
+
             print("Total Memory in USS:", memUSS)
+
             memRSS = obj.getMemoryRSS()
+
             print("Total Memory in RSS", memRSS)
+
             run = obj.getRuntime()
+
             print("Total ExecutionTime in seconds:", run)
-        Credits:
-        --------
-            The complete program was written by Shota Suzuki  under the supervision of Professor Rage Uday Kiran.
+
+    **Credits:**
+
+              The complete program was written by Suzuki Shota under the supervision of Professor Rage  Uday Kiran.
+
     """
 
     _minSup = float()
     _startTime = float()
     _endTime = float()
     _finalPatterns = {}
     _iFile = " "
```

### Comparing `pami-2023.4.1/PAMI/sequentialPatternMining/basic/abstract.py` & `pami-2023.5.1/PAMI/sequentialPatternMining/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/sequentialPatternMining/basic/prefixSpan.py` & `pami-2023.5.1/PAMI/sequentialPatternMining/basic/prefixSpan.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,110 +1,169 @@
 
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     import PAMI.frequentPattern.basic.prefixSpan as alg
+#
+#     obj = alg.prefixSpan(iFile, minSup)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 from PAMI.sequentialPatternMining.basic import abstract as _ab
 import copy
 _ab._sys.setrecursionlimit(10000)
 
 class prefixSpan(_ab._sequentialPatterns):
     """
-        Prifix Span is one of the fundamental algorithm to discover sequential frequent patterns in a transactional database.
+
+    Description:
+    --------------
+
+        Prefix Span is one of the fundamental algorithm to discover sequential frequent patterns in a transactional database.
         This program employs Prifix Span property (or downward closure property) to  reduce the search space effectively.
         This algorithm employs depth-first search technique to find the complete set of frequent patterns in a
         transactional database.
-        Reference:
-        ----------
-           J. Pei, J. Han, B. Mortazavi-Asl, J. Wang, H. Pinto, Q. Chen, U. Dayal, M. Hsu: Mining Sequential Patterns by Pattern-Growth: The PrefixSpan Approach. IEEE Trans. Knowl. Data Eng. 16(11): 1424-1440 (2004)
-        ----------
-            iFile : str
-                Input file name or path of the input file
-            oFile : str
-                Name of the output file or the path of output file
-            minSup: float or int or str
-                The user can specify minSup either in count or proportion of database size.
-                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-            sep : str
-                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                However, the users can override their default separator.
-            startTime:float
-                To record the start time of the mining process
-            endTime:float
-                To record the completion time of the mining process
-            finalPatterns: dict
-                Storing the complete set of patterns in a dictionary variable
-            memoryUSS : float
-                To store the total amount of USS memory consumed by the program
-            memoryRSS : float
-                To store the total amount of RSS memory consumed by the program
-            Database : list
-                To store the transactions of a database in list
-        Methods:
-        -------
-            startMine()
-                Mining process will start from here
-            getPatterns()
-                Complete set of patterns will be retrieved with this function
-            savePatterns(oFile)
-                Complete set of frequent patterns will be loaded in to a output file
-            getPatternsAsDataFrame()
-                Complete set of frequent patterns will be loaded in to a dataframe
-            getMemoryUSS()
-                Total amount of USS memory consumed by the mining process will be retrieved from this function
-            getMemoryRSS()
-                Total amount of RSS memory consumed by the mining process will be retrieved from this function
-            getRuntime()
-                Total amount of runtime taken by the mining process will be retrieved from this function
-            candidateToFrequent(candidateList)
-                Generates frequent patterns from the candidate patterns
-            frequentToCandidate(frequentList, length)
-                Generates candidate patterns from the frequent patterns
 
+    Reference:
+    -------------
+
+       J. Pei, J. Han, B. Mortazavi-Asl, J. Wang, H. Pinto, Q. Chen, U. Dayal, M. Hsu: Mining Sequential Patterns by Pattern-Growth: The PrefixSpan Approach. IEEE Trans. Knowl. Data Eng. 16(11): 1424-1440 (2004)
+
+    Attributes:
+    -------------
+        iFile : str
+            Input file name or path of the input file
+        oFile : str
+            Name of the output file or the path of output file
+        minSup: float or int or str
+            The user can specify minSup either in count or proportion of database size.
+            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+        sep : str
+            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+            However, the users can override their default separator.
+        startTime:float
+            To record the start time of the mining process
+        endTime:float
+            To record the completion time of the mining process
+        finalPatterns: dict
+            Storing the complete set of patterns in a dictionary variable
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
+        Database : list
+            To store the transactions of a database in list
+    Methods:
+    ---------
+        startMine()
+            Mining process will start from here
+        getPatterns()
+            Complete set of patterns will be retrieved with this function
+        savePatterns(oFile)
+            Complete set of frequent patterns will be loaded in to a output file
+        getPatternsAsDataFrame()
+            Complete set of frequent patterns will be loaded in to a dataframe
+        getMemoryUSS()
+            Total amount of USS memory consumed by the mining process will be retrieved from this function
+        getMemoryRSS()
+            Total amount of RSS memory consumed by the mining process will be retrieved from this function
+        getRuntime()
+            Total amount of runtime taken by the mining process will be retrieved from this function
+        candidateToFrequent(candidateList)
+            Generates frequent patterns from the candidate patterns
+        frequentToCandidate(frequentList, length)
+            Generates candidate patterns from the frequent patterns
+
+    **Methods to execute code on terminal**
 
-        Executing the code on terminal:
-        -------------------------------
             Format:
-            ------
-                python3 prefixSpan.py <inputFile> <outputFile> <minSup>
-            Examples:
-            ---------
-                python3 prefixSpan.py sampleDB.txt patterns.txt 10.0   (minSup will be considered in times of minSup and count of database transactions)
-                python3 prefixSpan.py sampleDB.txt patterns.txt 10     (minSup will be considered in support count or frequency)
-        Sample run of the importing code:
-        ---------------------------------
+                      >>>  python3 prefixSpan.py <inputFile> <outputFile> <minSup>
+            Example:
+                      >>>  python3 prefixSpan.py sampleDB.txt patterns.txt 10.0   (minSup will be considered in times of minSup and count of database transactions)
+
+                      >>>  python3 prefixSpan.py sampleDB.txt patterns.txt 10     (minSup will be considered in support count or frequency)
+
+
+    **Importing this algorithm into a python program**
+
+        .. code-block:: python
+
             import PAMI.frequentPattern.basic.prefixSpan as alg
+
             obj = alg.prefixSpan(iFile, minSup)
+
             obj.startMine()
+
             frequentPatterns = obj.getPatterns()
+
             print("Total number of Frequent Patterns:", len(frequentPatterns))
+
             obj.savePatterns(oFile)
+
             Df = obj.getPatternInDataFrame()
+
             memUSS = obj.getMemoryUSS()
+
             print("Total Memory in USS:", memUSS)
+
             memRSS = obj.getMemoryRSS()
+
             print("Total Memory in RSS", memRSS)
+
             run = obj.getRuntime()
+
             print("Total ExecutionTime in seconds:", run)
-        Credits:
-        --------
-            The complete program was written by Suzuki Shota under the supervision of Professor Rage Uday Kiran.
+
+    **Credits:**
+
+              The complete program was written by Suzuki Shota under the supervision of Professor Rage  Uday Kiran.
+
+
     """
 
     _minSup = float()
     _startTime = float()
     _endTime = float()
     _finalPatterns = {}
     _iFile = " "
```

### Comparing `pami-2023.4.1/PAMI/sequentialPatternMining/closed/abstract.py` & `pami-2023.5.1/PAMI/sequentialPatternMining/closed/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/basic/SPPEclat.py` & `pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/basic/SPPEclat.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,139 +1,192 @@
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.stablePeriodicFrequentPattern.basic import SPPECLAT as alg
+#
+#     obj = alg.PFPECLAT("../basic/sampleTDB.txt", 5, 3, 3)
+#
+#     obj.startMine()
+#
+#     Patterns = obj.getPatterns()
+#
+#     print("Total number of Stable Periodic Frequent Patterns:", len(Patterns))
+#
+#     obj.save("patterns")
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+
 from PAMI.stablePeriodicFrequentPattern.basic import abstract as _ab
 
 class SPPEclat(_ab._stablePeriodicFrequentPatterns):
-    """  Stable periodic pattern mining aims to dicover all interesting patterns in a temporal database using three contraints minimum support,
-         maximum period and maximum lability, that have support no less than the user-specified minimum support  constraint and lability no
-          greater than maximum lability.
-
-            Reference:
-            --------
-                Dao, H.N. et al. (2022). Towards Efficient Discovery of Stable Periodic Patterns in Big Columnar Temporal Databases. 
-                In: Fujita, H., Fournier-Viger, P., Ali, M., Wang, Y. (eds) Advances and Trends in Artificial Intelligence.
-                Theory and Practices in Artificial Intelligence. IEA/AIE 2022. Lecture Notes in Computer Science(), vol 13343. Springer, Cham. 
-                https://doi.org/10.1007/978-3-031-08530-7_70
-
-
-
-        Attributes:
-        ---------
-            iFile : file
-                Name of the Input file or path of the input file
-            oFile : file
-                Name of the output file or path of the output file
-            minSup: int or float or str
-                The user can specify minSup either in count or proportion of database size.
-                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-            maxPer: int or float or str
-                The user can specify maxPer either in count or proportion of database size.
-                If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
-            maxLa: int or float or str
-                The user can specify maxLa either in count or proportion of database size.
-                If the program detects the data type of maxLa is integer, then it treats maxLa is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: maxLa=10 will be treated as integer, while maxLa=10.0 will be treated as float
-            sep : str
-                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                However, the users can override their default separator.
-            memoryUSS : float
-                To store the total amount of USS memory consumed by the program
-            memoryRSS : float
-                To store the total amount of RSS memory consumed by the program
-            startTime:float
-                To record the start time of the mining process
-            endTime:float
-                To record the completion time of the mining process
-            Database : list
-                To store the transactions of a database in list
-            mapSupport : Dictionary
-                To maintain the information of item and their frequency
-            lno : int
-                it represents the total no of transactions
-            tree : class
-                it represents the Tree class
-            itemSetCount : int
-                it represents the total no of patterns
-            finalPatterns : dict
-                it represents to store the patterns
-            tidList : dict
-                stores the timestamps of an item
-
-        Methods:
-        -------
-            startMine()
-                Mining process will start from here
-            getPatterns()
-                Complete set of patterns will be retrieved with this function
-            save(oFile)
-                Complete set of periodic-frequent patterns will be loaded in to a output file
-            getPatternsAsDataFrame()
-                Complete set of periodic-frequent patterns will be loaded in to a dataframe
-            getMemoryUSS()
-                Total amount of USS memory consumed by the mining process will be retrieved from this function
-            getMemoryRSS()
-                Total amount of RSS memory consumed by the mining process will be retrieved from this function
-            getRuntime()
-                Total amount of runtime taken by the mining process will be retrieved from this function
-            creatingItemSets()
-                Scan the database and store the items with their timestamps which are periodic frequent
-            calculateLa()
-                Calculates the support and period for a list of timestamps.
-            Generation()
-                Used to implement prefix class equivalence method to generate the periodic patterns recursively
+    """
+    Description:
+    -------------
+    Stable periodic pattern mining aims to dicover all interesting patterns in a temporal database using three contraints minimum support,
+    maximum period and maximum lability, that have support no less than the user-specified minimum support  constraint and lability no
+    greater than maximum lability.
+
+    Reference:
+    ----------
+        Fournier-Viger, P., Yang, P., Lin, J. C.-W., Kiran, U. (2019). Discovering Stable Periodic-Frequent Patterns in Transactional Data. Proc.
+         32nd Intern. Conf. on Industrial, Engineering and Other Applications of Applied Intelligent Systems (IEA AIE 2019), Springer LNAI, pp. 230-244
+
+    Attributes:
+    -----------
+        iFile : file
+            Name of the Input file or path of the input file
+        oFile : file
+            Name of the output file or path of the output file
+        minSup: int or float or str
+            The user can specify minSup either in count or proportion of database size.
+            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+        maxPer: int or float or str
+            The user can specify maxPer either in count or proportion of database size.
+            If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
+        maxLa: int or float or str
+            The user can specify maxLa either in count or proportion of database size.
+            If the program detects the data type of maxLa is integer, then it treats maxLa is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: maxLa=10 will be treated as integer, while maxLa=10.0 will be treated as float
+        sep : str
+            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+            However, the users can override their default separator.
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
+        startTime:float
+            To record the start time of the mining process
+        endTime:float
+            To record the completion time of the mining process
+        Database : list
+            To store the transactions of a database in list
+        mapSupport : Dictionary
+            To maintain the information of item and their frequency
+        lno : int
+            it represents the total no of transactions
+        tree : class
+            it represents the Tree class
+        itemSetCount : int
+            it represents the total no of patterns
+        finalPatterns : dict
+            it represents to store the patterns
+        tidList : dict
+            stores the timestamps of an item
+
+    Methods:
+    ---------
+        startMine()
+            Mining process will start from here
+        getPatterns()
+            Complete set of patterns will be retrieved with this function
+        save(oFile)
+            Complete set of periodic-frequent patterns will be loaded in to a output file
+        getPatternsAsDataFrame()
+            Complete set of periodic-frequent patterns will be loaded in to a dataframe
+        getMemoryUSS()
+            Total amount of USS memory consumed by the mining process will be retrieved from this function
+        getMemoryRSS()
+            Total amount of RSS memory consumed by the mining process will be retrieved from this function
+        getRuntime()
+            Total amount of runtime taken by the mining process will be retrieved from this function
+        creatingItemSets()
+            Scan the database and store the items with their timestamps which are periodic frequent
+        calculateLa()
+            Calculates the support and period for a list of timestamps.
+        Generation()
+            Used to implement prefix class equivalence method to generate the periodic patterns recursively
+
+
+
+    **Methods to execute code on terminal**
 
-            Executing the code on terminal:
-            -------
             Format:
-            ------
-                python3 SPPECLAT.py <inputFile> <outputFile> <minSup> <maxPer> <maxLa>
+                      >>>   python3 SPPECLAT.py <inputFile> <outputFile> <minSup> <maxPer> <maxLa>
+
+            Example:
+                      >>>    python3 SPPECLAT.py sampleDB.txt patterns.txt 10.0 4.0 2.0
+
+            .. note:: constraints will be considered in percentage of database transactions
 
-            Examples:
-            --------
-                python3 SPPECLAT.py sampleDB.txt patterns.txt 10.0 4.0 2.0   (constraints will be considered in percentage of database transactions)
+    **Importing this algorithm into a python program**
 
-                python3 SPPECLAT.py sampleDB.txt patterns.txt 10 4 2    (constraint will be considered in support count or frequency)
+    .. code-block:: python
 
-            Sample run of the imported code:
-            --------------
+                    from PAMI.stablePeriodicFrequentPattern.basic import SPPECLAT as alg
 
-                from PAMI.stablePeriodicFrequentPattern.basic import SPPECLAT as alg
+                    obj = alg.PFPECLAT("../basic/sampleTDB.txt", 5, 3, 3)
 
-                obj = alg.PFPECLAT("../basic/sampleTDB.txt", 5, 3, 3)
+                    obj.startMine()
 
-                obj.startMine()
+                    Patterns = obj.getPatterns()
 
-                Patterns = obj.getPatterns()
+                    print("Total number of Stable Periodic Frequent Patterns:", len(Patterns))
 
-                print("Total number of Stable Periodic Frequent Patterns:", len(Patterns))
+                    obj.save("patterns")
 
-                obj.save("patterns")
+                    Df = obj.getPatternsAsDataFrame()
 
-                Df = obj.getPatternsAsDataFrame()
+                    memUSS = obj.getMemoryUSS()
 
-                memUSS = obj.getMemoryUSS()
+                    print("Total Memory in USS:", memUSS)
 
-                print("Total Memory in USS:", memUSS)
+                    memRSS = obj.getMemoryRSS()
 
-                memRSS = obj.getMemoryRSS()
+                    print("Total Memory in RSS", memRSS)
 
-                print("Total Memory in RSS", memRSS)
+                    run = obj.getRuntime()
 
-                run = obj.getRuntime()
+                    print("Total ExecutionTime in seconds:", run)
 
-                print("Total ExecutionTime in seconds:", run)
+    **Credits:**
 
-        Credits:
-        -------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+             The complete program was written by  P.Likhitha under the supervision of Professor Rage Uday Kiran.
 
-            """
+       """
     _iFile = " "
     _oFile = " "
     _minSup = str()
     _maxPer = str()
     _maxLa = float()
     _sep = " "
     _SPPList = {}
```

### Comparing `pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/basic/SPPGrowth.py` & `pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/topK/TSPIN.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,16 +1,88 @@
-from PAMI.stablePeriodicFrequentPattern.basic import abstract as _ab
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.stablePeriodicFrequentPattern.basic import TSPIN as alg
+#
+#     obj = alg.TSPIN(iFile, maxPer, maxLa, k)
+#
+#     obj.startMine()
+#
+#     stablePeriodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Periodic Frequent Patterns:", len(stablePeriodicFrequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
 
-_minSup = int()
-_maxPer = int()
-_maxLa = int()
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+from PAMI.stablePeriodicFrequentPattern.topK import abstract as _ab
+
+
+_maxPer = float()
+_maxLa = float()
+_k = float()
+_lno = int()
 _last = int()
 
 
-class _Node:
+class _Node(object):
+    """
+        A class used to represent the node of stablePeriodicFrequentPatternTree
+
+        Attributes:
+        ----------
+            item : int or None
+                Storing item of a node
+            timeStamps : list
+                To maintain the timestamps of a database at the end of the branch
+            parent : node
+                To maintain the parent of every node
+            children : list
+                To maintain the children of a node
+
+        Methods:
+        -------
+            addChild(itemName)
+                Storing the children to their respective parent nodes
+        """
 
     def __init__(self, item, children):
         """ Initializing the Node class
 
         :param item: Storing the item of a node
         :type item: int or None
         :param children: To maintain the children of a node
@@ -27,15 +99,45 @@
 
             :param node: parent node in the tree
         """
 
         self.children[node.item] = node
         node.parent = self
 
-class _Tree:
+
+class _Tree(object):
+    """
+        A class used to represent the stablePeriodic frequentPatternGrowth tree structure
+
+        Attributes:
+        ----------
+            root : Node
+                Represents the root node of the tree
+            summaries : dictionary
+                Storing the nodes with same item name
+            info : dictionary
+                Stores the support of the items
+
+
+        Methods:
+        -------
+            addTransactions(Database)
+                Creating transaction as a branch in frequentPatternTree
+            getConditionalPatterns(Node)
+                Generates the conditional patterns from tree for specific node
+            conditionalTransaction(prefixPaths,Support)
+                Takes the prefixPath of a node and support at child of the path and extract the frequent patterns from
+                prefixPaths and generates prefixPaths with items which are frequent
+            remove(Node)
+                Removes the node from tree once after generating all the patterns respective to the node
+            generatePatterns(Node)
+                Starts from the root node of the tree and mines the periodic-frequent patterns
+
+        """
+
     def __init__(self):
         self.root = _Node(None, {})
         self.summaries = {}
         self.info = {}
 
     def addTransaction(self, transaction, tid):
         """     Adding a transaction into tree
@@ -120,196 +222,196 @@
     @staticmethod
     def getSupportAndPeriod(timeStamps):
         """To calculate the periodicity and support
 
         :param timeStamps: Timestamps of an item set
         :return: support, periodicity
         """
+
         global _maxPer, _last
         previous = 0
         la = 0
         tsList = sorted(timeStamps)
-        laList = []
         for ts in tsList:
             la = max(0, la + ts - previous - _maxPer)
-            laList.append(la)
             previous = ts
         la = max(0, la + _last - previous - _maxPer)
-        laList.append(la)
-
-        maxla = max(laList)
-        return len(timeStamps), maxla
+        return len(timeStamps), la
 
     def conditionalDatabases(self, conditionalPatterns, conditionalTimeStamps):
         """ It generates the conditional patterns with periodic-frequent items
 
             :param conditionalPatterns: conditionalPatterns generated from conditionPattern method of a respective node
             :type conditionalPatterns: list
             :param conditionalTimeStamps: Represents the timestamps of a conditional patterns of a node
             :type conditionalTimeStamps: list
             :returns: Returns conditional transactions by removing non-periodic and non-frequent items
         """
 
-        global _maxPer, _minSup, _maxLa
+        global _maxPer, _minSup
         pat = []
         timeStamps = []
         data1 = {}
         for i in range(len(conditionalPatterns)):
             for j in conditionalPatterns[i]:
                 if j in data1:
                     data1[j] = data1[j] + conditionalTimeStamps[i]
                 else:
                     data1[j] = conditionalTimeStamps[i]
         updatedDictionary = {}
         for m in data1:
             updatedDictionary[m] = self.getSupportAndPeriod(data1[m])
-        updatedDictionary = {k: v for k, v in updatedDictionary.items() if v[0] >= _minSup and v[1] <= _maxLa}
+        updatedDictionary = {k: v for k, v in updatedDictionary.items() if v[1] <= _maxLa}
         count = 0
         for p in conditionalPatterns:
             p1 = [v for v in p if v in updatedDictionary]
             trans = sorted(p1, key=lambda x: (updatedDictionary.get(x)[0], -x), reverse=True)
             if len(trans) > 0:
                 pat.append(trans)
                 timeStamps.append(conditionalTimeStamps[count])
             count += 1
         return pat, timeStamps, updatedDictionary
 
-    def generatePatterns(self, prefix):
+    def generatePatterns(self, minSup, prefix, Qk):
         """ Generates the patterns
 
             :param prefix: Forms the combination of items
             :type prefix: list
             :returns: yields patterns with their support and periodicity
         """
 
+        global _k
         for i in sorted(self.summaries, key=lambda x: (self.info.get(x)[0], -x)):
             pattern = prefix[:]
             pattern.append(i)
-            yield pattern, self.info[i]
+            Qk[tuple(pattern)] = self.info[i]
+            if len(Qk) >= _k:
+                minSup = min([v[0] for v in Qk.values()])
+            if len(Qk) > _k:
+                temp = min([v[0] for v in Qk.values()])
+                res = [key for key in Qk if Qk[key] == temp]
+                for j in res:
+                    Qk[j] = None
             patterns, timeStamps, info = self.getConditionalPatterns(i)
             conditionalTree = _Tree()
             conditionalTree.info = info.copy()
             for pat in range(len(patterns)):
                 conditionalTree.addTransaction(patterns[pat], timeStamps[pat])
             if len(patterns) > 0:
-                for q in conditionalTree.generatePatterns(pattern):
-                    yield q
+                conditionalTree.generatePatterns(minSup, pattern, Qk)
             self.removeNode(i)
 
-class SPPGrowth(_ab._stablePeriodicFrequentPatterns):
-    """ Stable periodic pattern mining aims to dicover all interesting patterns in a temporal database using three contraints minimum support,
-         maximum period and maximum lability, that have support no less than the user-specified minimum support  constraint and lability no
-          greater than maximum lability.
-
-        Reference:
-        --------
-            Dao, H.N. et al. (2022). Towards Efficient Discovery of Stable Periodic Patterns in Big Columnar Temporal Databases.
-            In: Fujita, H., Fournier-Viger, P., Ali, M., Wang, Y. (eds) Advances and Trends in Artificial Intelligence.
-            Theory and Practices in Artificial Intelligence. IEA/AIE 2022. Lecture Notes in Computer Science(), vol 13343. Springer, Cham.
-            https://doi.org/10.1007/978-3-031-08530-7_70
 
-        Attributes:
-        ----------
-            iFile : file
-                Name of the Input file or path of the input file
-            oFile : file
-                Name of the output file or path of the output file
-            minSup: int or float or str
-                The user can specify minSup either in count or proportion of database size.
-                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-            maxPer: int or float or str
-                The user can specify maxPer either in count or proportion of database size.
-                If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
-            maxLa: int or float or str
-                The user can specify maxLa either in count or proportion of database size.
-                If the program detects the data type of maxLa is integer, then it treats maxLa is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: maxLa=10 will be treated as integer, while maxLa=10.0 will be treated as float
-            sep : str
-                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                However, the users can override their default separator.
-            memoryUSS : float
-                To store the total amount of USS memory consumed by the program
-            memoryRSS : float
-                To store the total amount of RSS memory consumed by the program
-            startTime:float
-                To record the start time of the mining process
-            endTime:float
-                To record the completion time of the mining process
-            Database : list
-                To store the transactions of a database in list
-            mapSupport : Dictionary
-                To maintain the information of item and their frequency
-            lno : int
-                To represent the total no of transaction
-            tree : class
-                To represents the Tree class
-            itemSetCount : int
-                To represents the total no of patterns
-            finalPatterns : dict
-                To store the complete patterns
+class TSPIN(_ab._stablePeriodicFrequentPatterns):
+    """
+    Description:
+    -------------
+
+        TSPIN is an algorithm to discover top stable periodic-frequent patterns in a transactional database.
+
+    Reference:
+    -----------
+        Fournier-Viger, P., Wang, Y., Yang, P. et al. TSPIN: mining top-k stable periodic patterns.
+        Appl Intell 52, 69176938 (2022). https://doi.org/10.1007/s10489-020-02181-6
+
+    Attributes:
+    ------------
+        iFile : file
+            Name of the Input file or path of the input file
+        oFile : file
+            Name of the output file or path of the output file
+        maxPer: int or float or str
+            The user can specify maxPer either in count or proportion of database size.
+            If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
+        maxLa: int or float or str
+            The user can specify maxLa either in count or proportion of database size.
+            If the program detects the data type of maxLa is integer, then it treats maxLa is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: maxLa=10 will be treated as integer, while maxLa=10.0 will be treated as float
+        sep : str
+            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+            However, the users can override their default separator.
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
+        startTime:float
+            To record the start time of the mining process
+        endTime:float
+            To record the completion time of the mining process
+        Database : list
+            To store the transactions of a database in list
+        mapSupport : Dictionary
+            To maintain the information of item and their frequency
+        lno : int
+            To represent the total no of transaction
+        tree : class
+            To represents the Tree class
+        itemSetCount : int
+            To represents the total no of patterns
+        finalPatterns : dict
+            To store the complete patterns
+
+    Methods:
+    ---------
+        startMine()
+            Mining process will start from here
+        getPatterns()
+            Complete set of patterns will be retrieved with this function
+        save(oFile)
+            Complete set of periodic-frequent patterns will be loaded in to a output file
+        getPatternsAsDataFrame()
+            Complete set of periodic-frequent patterns will be loaded in to a dataframe
+        getMemoryUSS()
+            Total amount of USS memory consumed by the mining process will be retrieved from this function
+        getMemoryRSS()
+            Total amount of RSS memory consumed by the mining process will be retrieved from this function
+        getRuntime()
+            Total amount of runtime taken by the mining process will be retrieved from this function
+        creatingItemSets(fileName)
+            Scans the dataset and stores in a list format
+        PeriodicFrequentOneItem()
+            Extracts the one-periodic-frequent patterns from database
+        updateDatabases()
+            Update the database by removing aperiodic items and sort the Database by item decreased support
+        buildTree()
+            After updating the Database, remaining items will be added into the tree by setting root node as null
+        convert()
+            to convert the user specified value
 
-        Methods:
-        -------
-            startMine()
-                Mining process will start from here
-            getPatterns()
-                Complete set of patterns will be retrieved with this function
-            save(oFile)
-                Complete set of periodic-frequent patterns will be loaded in to a output file
-            getPatternsAsDataFrame()
-                Complete set of periodic-frequent patterns will be loaded in to a dataframe
-            getMemoryUSS()
-                Total amount of USS memory consumed by the mining process will be retrieved from this function
-            getMemoryRSS()
-                Total amount of RSS memory consumed by the mining process will be retrieved from this function
-            getRuntime()
-                Total amount of runtime taken by the mining process will be retrieved from this function
-            creatingItemSets(fileName)
-                Scans the dataset and stores in a list format
-            PeriodicFrequentOneItem()
-                Extracts the one-periodic-frequent patterns from database
-            updateDatabases()
-                Update the database by removing aperiodic items and sort the Database by item decreased support
-            buildTree()
-                After updating the Database, remaining items will be added into the tree by setting root node as null
-            convert()
-                to convert the user specified value
 
-            Executing the code on terminal:
-            -------
+
+    **Methods to execute code on terminal**
+
             Format:
-            ------
-            python3 SPPGrowth.py <inputFile> <outputFile> <minSup> <maxPer> <maxLa>
+                      >>>   python3 TSPIN.py <inputFile> <outputFile> <maxPer> <maxLa>
+            Example:
+                      >>>  python3 TSPIN.py sampleTDB.txt patterns.txt 0.3 0.4 0.6
+
+            .. note:: maxPer, maxLa and k will be considered in percentage of database transactions
+
 
-            Examples:
-            --------
-            python3 SPPGrowth.py sampleTDB.txt patterns.txt 0.3 0.4 0.3  (constraints will be considered in percentage of database
-            transactions)
 
-            python3 SPPGrowth.py sampleTDB.txt patterns.txt 3 4 3    (constraints will be considered in support count or frequency)
+    **Importing this algorithm into a python program**
 
-            Sample run of importing the code:
-            -------------------
+    .. code-block:: python
 
-                from PAMI.stablePeriodicFrequentPattern.basic import SPPGrowth as alg
+                from PAMI.stablePeriodicFrequentPattern.basic import TSPIN as alg
 
-                obj = alg.SPPGrowth(iFile, minSup, maxPer, maxLa)
+                obj = alg.TSPIN(iFile, maxPer, maxLa, k)
 
                 obj.startMine()
 
-                Patterns = obj.getPatterns()
+                stablePeriodicFrequentPatterns = obj.getPatterns()
 
-                print("Total number of Stable Periodic Frequent Patterns:", len(Patterns))
+                print("Total number of Periodic Frequent Patterns:", len(stablePeriodicFrequentPatterns))
 
-                obj.save(oFile)
+                obj.savePatterns(oFile)
 
                 Df = obj.getPatternsAsDataFrame()
 
                 memUSS = obj.getMemoryUSS()
 
                 print("Total Memory in USS:", memUSS)
 
@@ -317,42 +419,36 @@
 
                 print("Total Memory in RSS", memRSS)
 
                 run = obj.getRuntime()
 
                 print("Total ExecutionTime in seconds:", run)
 
-            Credits:
-            -------
-                The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+    **Credits:**
 
-        """
+             The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+
+
+    """
     _startTime = float()
     _endTime = float()
-    _minSup = str()
+    _maxLa = str()
     _maxPer = float()
-    _maxLa = float()
+    _k = float()
+    _SPPList = {}
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
     _rank = {}
     _rankedUp = {}
     _lno = 0
-    SPPList = {}
-
-    def __init__(self, inputFile, minSup, maxPer, maxLa, sep='\t'):
-        self._iFile = inputFile
-        self._minSup = minSup
-        self._maxPer = maxPer
-        self._maxLa = maxLa
-        self._sep = sep
 
     def _creatingItemSets(self):
         """
             Storing the complete transactions of the database/input file in a database variable
 
 
         """
@@ -378,55 +474,56 @@
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
                     self._Database.append(temp)
             else:
                 try:
+                    count = 0
                     with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
+                            count += 1
                             line.strip()
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
                             self._Database.append(temp)
                 except IOError:
                     print("File Not Found")
                     quit()
 
+
     def _periodicFrequentOneItem(self):
         """ Calculates the support of each item in the database and assign ranks to the items
             by decreasing support and returns the frequent items list
 
             :returns: return the one-length periodic frequent patterns
         """
         global _last
         tidLast = {}
         la = {}
-        self.SPPList = {}
         for transaction in self._Database:
             ts = int(transaction[0])
             for item in transaction[1:]:
-                if item not in self.SPPList:
+                if item not in self._SPPList:
                     la[item] = max(0, ts - self._maxPer)
-                    self.SPPList[item] = [1, la[item]]
+                    self._SPPList[item] = [1, la[item]]
                 else:
-                    s = self.SPPList[item][0] + 1
+                    s = self._SPPList[item][0] + 1
                     la[item] = max(0, la[item] + ts - tidLast.get(item) - self._maxPer)
-                    self.SPPList[item] = [s, max(la[item], self.SPPList[item][1])]
+                    self._SPPList[item] = [s, max(la[item], self._SPPList[item][1])]
                 tidLast[item] = ts
             _last = ts
-        for item in self.SPPList:
+        for item in self._SPPList:
             la[item] = max(0, la[item] + _last - tidLast[item] - self._maxPer)
-            self.SPPList[item][1] = max(la[item], self.SPPList[item][1])
-        self.SPPList = {k: v for k, v in self.SPPList.items() if v[0] >= self._minSup and v[1] <= self._maxLa}
-        self.SPPList = {k: v for k, v in sorted(self.SPPList.items(), key=lambda x: x[1][0], reverse=True)}
-        data = self.SPPList
-        pfList = [k for k, v in sorted(data.items(), key=lambda x: (x[1][0], x[0]), reverse=True)]
+            self._SPPList[item][1] = max(la[item], self._SPPList[item][1])
+        self._SPPList = {k: v for k, v in self._SPPList.items() if v[1] <= self._maxLa}
+        self._SPPList = {k: v for k, v in sorted(self._SPPList.items(), key=lambda x: (x[1][0]), reverse=True)}
+        data = self._SPPList
+        pfList = [k for k, v in data.items()]
         self._rank = dict([(index, item) for (item, index) in enumerate(pfList)])
-        #print(len(pfList))
         return data, pfList
 
     def _updateDatabases(self, dict1):
         """ Remove the items which are not frequent from database and updates the database with rank of items
 
             :param dict1: frequent items with support
             :type dict1: dictionary
@@ -467,15 +564,15 @@
         """ To convert the ranks of items in to their original item names
 
             :param itemSet: frequent pattern
             :return: frequent pattern with original item names
         """
         t1 = str()
         for i in itemSet:
-            t1 = t1 + self._rankedUp[i] + "\t"
+            t1 = t1 + self._rankedUp[i] + " "
         return t1
 
     def _convert(self, value):
         """
         To convert the given user specified value
 
         :param value: user specified value
@@ -493,46 +590,46 @@
                 value = int(value)
         return value
 
     def startMine(self):
         """ Mining process will start from this function
         """
 
-        global _minSup, _maxPer, _lno, _maxLa
+        global _maxLa, _maxPer, _k, _lno
         self._startTime = _ab._time.time()
         if self._iFile is None:
             raise Exception("Please enter the file path or file name:")
-        if self._minSup is None:
+        if self._maxLa is None:
             raise Exception("Please enter the Minimum Support")
         self._creatingItemSets()
-        self._minSup = self._convert(self._minSup)
-        self._maxPer = self._convert(self._maxPer)
         self._maxLa = self._convert(self._maxLa)
-        _minSup, _maxPer, _maxLa, _lno = self._minSup, self._maxPer, self._maxLa, len(self._Database)
-        #print(_minSup, _maxPer, _maxLa)
-        if self._minSup > len(self._Database):
+        self._maxPer = self._convert(self._maxPer)
+        self._k = self._convert(self._k)
+        _maxLa, _maxPer, _k, _lno = self._maxLa, self._maxPer, self._k, len(self._Database)
+        if self._maxLa > len(self._Database):
             raise Exception("Please enter the minSup in range between 0 to 1")
         generatedItems, pfList = self._periodicFrequentOneItem()
         updatedDatabases = self._updateDatabases(generatedItems)
         for x, y in self._rank.items():
             self._rankedUp[y] = x
         info = {self._rank[k]: v for k, v in generatedItems.items()}
         Tree = self._buildTree(updatedDatabases, info)
-        patterns = Tree.generatePatterns([])
+        patterns = {}
+        Tree.generatePatterns(1, [], patterns)
         self._finalPatterns = {}
-        for i in patterns:
-            sample = self._savePeriodic(i[0])
-            self._finalPatterns[sample] = i[1]
+        for x, y in patterns.items():
+            sample = self._savePeriodic(x)
+            self._finalPatterns[sample] = y
         self._endTime = _ab._time.time()
         process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryUSS = float()
         self._memoryRSS = float()
         self._memoryUSS = process.memory_full_info().uss
         self._memoryRSS = process.memory_info().rss
-        print("Stable Periodic Frequent patterns were generated successfully using SPPGrowth algorithm ")
+        print("Top-K Stable Periodic patterns were generated successfully using TSPIN algorithm ")
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
         :return: returning USS memory consumed by the mining process
         :rtype: float
         """
@@ -564,54 +661,67 @@
         :return: returning periodic-frequent patterns in a dataframe
         :rtype: pd.DataFrame
         """
 
         dataFrame = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a.replace('\t', ' '), b[0], b[1]])
+            data.append([a, b[0], b[1]])
             dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Periodicity'])
         return dataFrame
 
     def save(self, outFile):
         """Complete set of periodic-frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
         :type outFile: file
         """
         self._oFile = outFile
         writer = open(self._oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            s1 = x.strip() + ":" + str(y[0]) + ":" + str(y[1])
+            s1 = x + ":" + str(y[0]) + ":" + str(y[1])
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
         """ Function to send the set of periodic-frequent patterns after completion of the mining process
 
         :return: returning periodic-frequent patterns
         :rtype: dict
         """
         return self._finalPatterns
 
-    def printResults(self):
-        print("Total number of Stable Periodic  Patterns:", len(self.getPatterns()))
-        print("Total Memory in USS:", self.getMemoryUSS())
-        print("Total Memory in RSS", self.getMemoryRSS())
-        print("Total ExecutionTime in ms:", self.getRuntime())
-
 
 if __name__ == "__main__":
     _ap = str()
     if len(_ab._sys.argv) == 6 or len(_ab._sys.argv) == 7:
         if len(_ab._sys.argv) == 7:
-            _ap = SPPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5], _ab._sys.argv[6])
+            _ap = TSPIN(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5], _ab._sys.argv[6])
         if len(_ab._sys.argv) == 6:
-            _ap = SPPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
+            _ap = TSPIN(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
         _ap.startMine()
-        print("Total number of Patterns:", len(_ap.getPatterns()))
+        _Patterns = _ap.getPatterns()
+        print("Total number of Patterns:", len(_Patterns))
         _ap.save(_ab._sys.argv[2])
-        print("Total Memory in USS:", _ap.getMemoryUSS())
-        print("Total Memory in RSS", _ap.getMemoryRSS())
-        print("Total ExecutionTime in ms:", _ap.getRuntime())
+        _memUSS = _ap.getMemoryUSS()
+        print("Total Memory in USS:", _memUSS)
+        _memRSS = _ap.getMemoryRSS()
+        print("Total Memory in RSS", _memRSS)
+        _run = _ap.getRuntime()
+        print("Total ExecutionTime in ms:", _run)
     else:
+        _ap = TSPIN('/Users/Likhitha/Downloads/SPP_sample.txt', 5, 1, 1, ' ')
+        _ap.startMine()
+        print(len(_ap._Database))
+        _Patterns = _ap.getPatterns()
+        for x, y in _Patterns.items():
+            print(x, y)
+        print("Total number of Patterns:", len(_Patterns))
+        _ap.save('/Users/Likhitha/Downloads/output.txt')
+        _memUSS = _ap.getMemoryUSS()
+        print("Total Memory in USS:", _memUSS)
+        _memRSS = _ap.getMemoryRSS()
+        print("Total Memory in RSS", _memRSS)
+        _run = _ap.getRuntime()
+        print("Total ExecutionTime in ms:", _run)
         print("Error! The number of input parameters do not match the total number of parameters provided")
 
+
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/basic/SPPGrowthDump.py` & `pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/basic/SPPGrowthDump.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/topK/TSPIN.py` & `pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/basic/SPPGrowth.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,52 +1,68 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#
+#     from PAMI.stablePeriodicFrequentPattern.basic import SPPGrowth as alg
+#
+#     obj = alg.SPPGrowth(iFile, minSup, maxPer, maxLa)
+#
+#     obj.startMine()
+#
+#     Patterns = obj.getPatterns()
+#
+#     print("Total number of Stable Periodic Frequent Patterns:", len(Patterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
+#     print("Total Memory in USS:", memUSS)
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     memRSS = obj.getMemoryRSS()
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
 
-from PAMI.stablePeriodicFrequentPattern.topK import abstract as _ab
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
 
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
 
-_maxPer = float()
-_maxLa = float()
-_k = float()
-_lno = int()
-_last = int()
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
 
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
 
-class _Node(object):
-    """
-        A class used to represent the node of stablePeriodicFrequentPatternTree
+"""
 
-        Attributes:
-        ----------
-            item : int or None
-                Storing item of a node
-            timeStamps : list
-                To maintain the timestamps of a database at the end of the branch
-            parent : node
-                To maintain the parent of every node
-            children : list
-                To maintain the children of a node
-
-        Methods:
-        -------
-            addChild(itemName)
-                Storing the children to their respective parent nodes
-        """
+
+from PAMI.stablePeriodicFrequentPattern.basic import abstract as _ab
+
+_minSup = int()
+_maxPer = int()
+_maxLa = int()
+_last = int()
+
+
+class _Node:
 
     def __init__(self, item, children):
         """ Initializing the Node class
 
         :param item: Storing the item of a node
         :type item: int or None
         :param children: To maintain the children of a node
@@ -63,45 +79,15 @@
 
             :param node: parent node in the tree
         """
 
         self.children[node.item] = node
         node.parent = self
 
-
-class _Tree(object):
-    """
-        A class used to represent the stablePeriodic frequentPatternGrowth tree structure
-
-        Attributes:
-        ----------
-            root : Node
-                Represents the root node of the tree
-            summaries : dictionary
-                Storing the nodes with same item name
-            info : dictionary
-                Stores the support of the items
-
-
-        Methods:
-        -------
-            addTransactions(Database)
-                Creating transaction as a branch in frequentPatternTree
-            getConditionalPatterns(Node)
-                Generates the conditional patterns from tree for specific node
-            conditionalTransaction(prefixPaths,Support)
-                Takes the prefixPath of a node and support at child of the path and extract the frequent patterns from
-                prefixPaths and generates prefixPaths with items which are frequent
-            remove(Node)
-                Removes the node from tree once after generating all the patterns respective to the node
-            generatePatterns(Node)
-                Starts from the root node of the tree and mines the periodic-frequent patterns
-
-        """
-
+class _Tree:
     def __init__(self):
         self.root = _Node(None, {})
         self.summaries = {}
         self.info = {}
 
     def addTransaction(self, transaction, tid):
         """     Adding a transaction into tree
@@ -186,136 +172,144 @@
     @staticmethod
     def getSupportAndPeriod(timeStamps):
         """To calculate the periodicity and support
 
         :param timeStamps: Timestamps of an item set
         :return: support, periodicity
         """
-
         global _maxPer, _last
         previous = 0
         la = 0
         tsList = sorted(timeStamps)
+        laList = []
         for ts in tsList:
             la = max(0, la + ts - previous - _maxPer)
+            laList.append(la)
             previous = ts
         la = max(0, la + _last - previous - _maxPer)
-        return len(timeStamps), la
+        laList.append(la)
+
+        maxla = max(laList)
+        return len(timeStamps), maxla
 
     def conditionalDatabases(self, conditionalPatterns, conditionalTimeStamps):
         """ It generates the conditional patterns with periodic-frequent items
 
             :param conditionalPatterns: conditionalPatterns generated from conditionPattern method of a respective node
             :type conditionalPatterns: list
             :param conditionalTimeStamps: Represents the timestamps of a conditional patterns of a node
             :type conditionalTimeStamps: list
             :returns: Returns conditional transactions by removing non-periodic and non-frequent items
         """
 
-        global _maxPer, _minSup
+        global _maxPer, _minSup, _maxLa
         pat = []
         timeStamps = []
         data1 = {}
         for i in range(len(conditionalPatterns)):
             for j in conditionalPatterns[i]:
                 if j in data1:
                     data1[j] = data1[j] + conditionalTimeStamps[i]
                 else:
                     data1[j] = conditionalTimeStamps[i]
         updatedDictionary = {}
         for m in data1:
             updatedDictionary[m] = self.getSupportAndPeriod(data1[m])
-        updatedDictionary = {k: v for k, v in updatedDictionary.items() if v[1] <= _maxLa}
+        updatedDictionary = {k: v for k, v in updatedDictionary.items() if v[0] >= _minSup and v[1] <= _maxLa}
         count = 0
         for p in conditionalPatterns:
             p1 = [v for v in p if v in updatedDictionary]
             trans = sorted(p1, key=lambda x: (updatedDictionary.get(x)[0], -x), reverse=True)
             if len(trans) > 0:
                 pat.append(trans)
                 timeStamps.append(conditionalTimeStamps[count])
             count += 1
         return pat, timeStamps, updatedDictionary
 
-    def generatePatterns(self, minSup, prefix, Qk):
+    def generatePatterns(self, prefix):
         """ Generates the patterns
 
             :param prefix: Forms the combination of items
             :type prefix: list
             :returns: yields patterns with their support and periodicity
         """
 
-        global _k
         for i in sorted(self.summaries, key=lambda x: (self.info.get(x)[0], -x)):
             pattern = prefix[:]
             pattern.append(i)
-            Qk[tuple(pattern)] = self.info[i]
-            if len(Qk) >= _k:
-                minSup = min([v[0] for v in Qk.values()])
-            if len(Qk) > _k:
-                temp = min([v[0] for v in Qk.values()])
-                res = [key for key in Qk if Qk[key] == temp]
-                for j in res:
-                    Qk[j] = None
+            yield pattern, self.info[i]
             patterns, timeStamps, info = self.getConditionalPatterns(i)
             conditionalTree = _Tree()
             conditionalTree.info = info.copy()
             for pat in range(len(patterns)):
                 conditionalTree.addTransaction(patterns[pat], timeStamps[pat])
             if len(patterns) > 0:
-                conditionalTree.generatePatterns(minSup, pattern, Qk)
+                for q in conditionalTree.generatePatterns(pattern):
+                    yield q
             self.removeNode(i)
 
-
-class TSPIN(_ab._stablePeriodicFrequentPatterns):
-    """ TSPIN is an algorithm to discover top stable periodic-frequent patterns in a transactional database.
+class SPPGrowth():
+    """
+    Description:
+    --------------
+    Stable periodic pattern mining aims to dicover all interesting patterns in a temporal database using three contraints minimum support,
+    maximum period and maximum lability, that have support no less than the user-specified minimum support  constraint and lability no
+    greater than maximum lability.
 
     Reference:
-    --------
-        Fournier-Viger, P., Wang, Y., Yang, P. et al. TSPIN: mining top-k stable periodic patterns.
-        Appl Intell 52, 69176938 (2022). https://doi.org/10.1007/s10489-020-02181-6
+    -----------
+    Dao, H.N. et al. (2022). Towards Efficient Discovery of Stable Periodic Patterns in Big Columnar Temporal Databases.
+    In: Fujita, H., Fournier-Viger, P., Ali, M., Wang, Y. (eds) Advances and Trends in Artificial Intelligence.
+    Theory and Practices in Artificial Intelligence. IEA/AIE 2022. Lecture Notes in Computer Science(), vol 13343. Springer, Cham.
+    https://doi.org/10.1007/978-3-031-08530-7_70
 
     Attributes:
     ----------
-        iFile : file
-            Name of the Input file or path of the input file
-        oFile : file
-            Name of the output file or path of the output file
-        maxPer: int or float or str
-            The user can specify maxPer either in count or proportion of database size.
-            If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
-        maxLa: int or float or str
-            The user can specify maxLa either in count or proportion of database size.
-            If the program detects the data type of maxLa is integer, then it treats maxLa is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: maxLa=10 will be treated as integer, while maxLa=10.0 will be treated as float
-        sep : str
-            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-            However, the users can override their default separator.
-        memoryUSS : float
-            To store the total amount of USS memory consumed by the program
-        memoryRSS : float
-            To store the total amount of RSS memory consumed by the program
-        startTime:float
-            To record the start time of the mining process
-        endTime:float
-            To record the completion time of the mining process
-        Database : list
-            To store the transactions of a database in list
-        mapSupport : Dictionary
-            To maintain the information of item and their frequency
-        lno : int
-            To represent the total no of transaction
-        tree : class
-            To represents the Tree class
-        itemSetCount : int
-            To represents the total no of patterns
-        finalPatterns : dict
-            To store the complete patterns
+            iFile : file
+                Name of the Input file or path of the input file
+            oFile : file
+                Name of the output file or path of the output file
+            minSup: int or float or str
+                The user can specify minSup either in count or proportion of database size.
+                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+                Otherwise, it will be treated as float.
+                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+            maxPer: int or float or str
+                The user can specify maxPer either in count or proportion of database size.
+                If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
+                Otherwise, it will be treated as float.
+                Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
+            maxLa: int or float or str
+                The user can specify maxLa either in count or proportion of database size.
+                If the program detects the data type of maxLa is integer, then it treats maxLa is expressed in count.
+                Otherwise, it will be treated as float.
+                Example: maxLa=10 will be treated as integer, while maxLa=10.0 will be treated as float
+            sep : str
+                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+                However, the users can override their default separator.
+            memoryUSS : float
+                To store the total amount of USS memory consumed by the program
+            memoryRSS : float
+                To store the total amount of RSS memory consumed by the program
+            startTime:float
+                To record the start time of the mining process
+            endTime:float
+                To record the completion time of the mining process
+            Database : list
+                To store the transactions of a database in list
+            mapSupport : Dictionary
+                To maintain the information of item and their frequency
+            lno : int
+                To represent the total no of transaction
+            tree : class
+                To represents the Tree class
+            itemSetCount : int
+                To represents the total no of patterns
+            finalPatterns : dict
+                To store the complete patterns
 
     Methods:
     -------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
@@ -336,39 +330,37 @@
         updateDatabases()
             Update the database by removing aperiodic items and sort the Database by item decreased support
         buildTree()
             After updating the Database, remaining items will be added into the tree by setting root node as null
         convert()
             to convert the user specified value
 
-        Executing the code on terminal:
-        -------
-        Format:
-        ------
-        python3 TSPIN.py <inputFile> <outputFile> <k> <maxPer> <maxLa>
 
-        Examples:
-        --------
-        python3 TSPIN.py sampleTDB.txt patterns.txt 7 0.4 0.6   (maxPer, maxLa and k will be considered in percentage of database
-        transactions)
+    **Methods to execute code on terminal**
+
+            Format:
+                      >>>   python3 SPPGrowth.py <inputFile> <outputFile> <minSup> <maxPer> <maxLa>
+            Example:
+                      >>>  python3 SPPGrowth.py sampleTDB.txt patterns.txt 0.3 0.4 0.3
+
+            .. note:: constraints will be considered in percentage of database transactions
 
-        python3 TSPIN.py sampleTDB.txt patterns.txt 3 4 6    (maxPer, maxLa and k will be considered in support count or frequency)
+    **Importing this algorithm into a python program**
 
-        Sample run of importing the code:
-        -------------------
+    .. code-block:: python
 
-            from PAMI.stablePeriodicFrequentPattern.basic import TSPIN as alg
+            from PAMI.stablePeriodicFrequentPattern.basic import SPPGrowth as alg
 
-            obj = alg.TSPIN(iFile, k, maxPer, maxLa)
+            obj = alg.SPPGrowth(iFile, minSup, maxPer, maxLa)
 
             obj.startMine()
 
-            stablePeriodicFrequentPatterns = obj.getPatterns()
+            Patterns = obj.getPatterns()
 
-            print("Total number of Top-K Stable Periodic Patterns:", len(stablePeriodicFrequentPatterns))
+            print("Total number of Stable Periodic Frequent Patterns:", len(Patterns))
 
             obj.save(oFile)
 
             Df = obj.getPatternsAsDataFrame()
 
             memUSS = obj.getMemoryUSS()
 
@@ -378,35 +370,42 @@
 
             print("Total Memory in RSS", memRSS)
 
             run = obj.getRuntime()
 
             print("Total ExecutionTime in seconds:", run)
 
-        Credits:
-        -------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+    **Credits:**
 
-    """
+             The complete program was written by  P.Likhitha under the supervision of Professor Rage Uday Kiran.
+
+        """
     _startTime = float()
     _endTime = float()
-    _maxLa = str()
+    _minSup = str()
     _maxPer = float()
-    _k = float()
-    _SPPList = {}
+    _maxLa = float()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
     _rank = {}
     _rankedUp = {}
     _lno = 0
+    SPPList = {}
+
+    def __init__(self, inputFile, minSup, maxPer, maxLa, sep='\t'):
+        self._iFile = inputFile
+        self._minSup = minSup
+        self._maxPer = maxPer
+        self._maxLa = maxLa
+        self._sep = sep
 
     def _creatingItemSets(self):
         """
             Storing the complete transactions of the database/input file in a database variable
 
 
         """
@@ -432,56 +431,55 @@
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
                     self._Database.append(temp)
             else:
                 try:
-                    count = 0
                     with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
-                            count += 1
                             line.strip()
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
                             self._Database.append(temp)
                 except IOError:
                     print("File Not Found")
                     quit()
 
-
     def _periodicFrequentOneItem(self):
         """ Calculates the support of each item in the database and assign ranks to the items
             by decreasing support and returns the frequent items list
 
             :returns: return the one-length periodic frequent patterns
         """
         global _last
         tidLast = {}
         la = {}
+        self.SPPList = {}
         for transaction in self._Database:
             ts = int(transaction[0])
             for item in transaction[1:]:
-                if item not in self._SPPList:
+                if item not in self.SPPList:
                     la[item] = max(0, ts - self._maxPer)
-                    self._SPPList[item] = [1, la[item]]
+                    self.SPPList[item] = [1, la[item]]
                 else:
-                    s = self._SPPList[item][0] + 1
+                    s = self.SPPList[item][0] + 1
                     la[item] = max(0, la[item] + ts - tidLast.get(item) - self._maxPer)
-                    self._SPPList[item] = [s, max(la[item], self._SPPList[item][1])]
+                    self.SPPList[item] = [s, max(la[item], self.SPPList[item][1])]
                 tidLast[item] = ts
             _last = ts
-        for item in self._SPPList:
+        for item in self.SPPList:
             la[item] = max(0, la[item] + _last - tidLast[item] - self._maxPer)
-            self._SPPList[item][1] = max(la[item], self._SPPList[item][1])
-        self._SPPList = {k: v for k, v in self._SPPList.items() if v[1] <= self._maxLa}
-        self._SPPList = {k: v for k, v in sorted(self._SPPList.items(), key=lambda x: (x[1][0]), reverse=True)}
-        data = self._SPPList
-        pfList = [k for k, v in data.items()]
+            self.SPPList[item][1] = max(la[item], self.SPPList[item][1])
+        self.SPPList = {k: v for k, v in self.SPPList.items() if v[0] >= self._minSup and v[1] <= self._maxLa}
+        self.SPPList = {k: v for k, v in sorted(self.SPPList.items(), key=lambda x: x[1][0], reverse=True)}
+        data = self.SPPList
+        pfList = [k for k, v in sorted(data.items(), key=lambda x: (x[1][0], x[0]), reverse=True)]
         self._rank = dict([(index, item) for (item, index) in enumerate(pfList)])
+        #print(len(pfList))
         return data, pfList
 
     def _updateDatabases(self, dict1):
         """ Remove the items which are not frequent from database and updates the database with rank of items
 
             :param dict1: frequent items with support
             :type dict1: dictionary
@@ -522,15 +520,15 @@
         """ To convert the ranks of items in to their original item names
 
             :param itemSet: frequent pattern
             :return: frequent pattern with original item names
         """
         t1 = str()
         for i in itemSet:
-            t1 = t1 + self._rankedUp[i] + " "
+            t1 = t1 + self._rankedUp[i] + "\t"
         return t1
 
     def _convert(self, value):
         """
         To convert the given user specified value
 
         :param value: user specified value
@@ -548,46 +546,46 @@
                 value = int(value)
         return value
 
     def startMine(self):
         """ Mining process will start from this function
         """
 
-        global _maxLa, _maxPer, _k, _lno
+        global _minSup, _maxPer, _lno, _maxLa
         self._startTime = _ab._time.time()
         if self._iFile is None:
             raise Exception("Please enter the file path or file name:")
-        if self._maxLa is None:
+        if self._minSup is None:
             raise Exception("Please enter the Minimum Support")
         self._creatingItemSets()
-        self._maxLa = self._convert(self._maxLa)
+        self._minSup = self._convert(self._minSup)
         self._maxPer = self._convert(self._maxPer)
-        self._k = self._convert(self._k)
-        _maxLa, _maxPer, _k, _lno = self._maxLa, self._maxPer, self._k, len(self._Database)
-        if self._maxLa > len(self._Database):
+        self._maxLa = self._convert(self._maxLa)
+        _minSup, _maxPer, _maxLa, _lno = self._minSup, self._maxPer, self._maxLa, len(self._Database)
+        #print(_minSup, _maxPer, _maxLa)
+        if self._minSup > len(self._Database):
             raise Exception("Please enter the minSup in range between 0 to 1")
         generatedItems, pfList = self._periodicFrequentOneItem()
         updatedDatabases = self._updateDatabases(generatedItems)
         for x, y in self._rank.items():
             self._rankedUp[y] = x
         info = {self._rank[k]: v for k, v in generatedItems.items()}
         Tree = self._buildTree(updatedDatabases, info)
-        patterns = {}
-        Tree.generatePatterns(1, [], patterns)
+        patterns = Tree.generatePatterns([])
         self._finalPatterns = {}
-        for x, y in patterns.items():
-            sample = self._savePeriodic(x)
-            self._finalPatterns[sample] = y
+        for i in patterns:
+            sample = self._savePeriodic(i[0])
+            self._finalPatterns[sample] = i[1]
         self._endTime = _ab._time.time()
         process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryUSS = float()
         self._memoryRSS = float()
         self._memoryUSS = process.memory_full_info().uss
         self._memoryRSS = process.memory_info().rss
-        print("Top-K Stable Periodic patterns were generated successfully using TSPIN algorithm ")
+        print("Stable Periodic Frequent patterns were generated successfully using SPPGrowth algorithm ")
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
         :return: returning USS memory consumed by the mining process
         :rtype: float
         """
@@ -619,67 +617,54 @@
         :return: returning periodic-frequent patterns in a dataframe
         :rtype: pd.DataFrame
         """
 
         dataFrame = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a, b[0], b[1]])
+            data.append([a.replace('\t', ' '), b[0], b[1]])
             dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Periodicity'])
         return dataFrame
 
     def save(self, outFile):
         """Complete set of periodic-frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
         :type outFile: file
         """
         self._oFile = outFile
         writer = open(self._oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            s1 = x + ":" + str(y[0]) + ":" + str(y[1])
+            s1 = x.strip() + ":" + str(y[0]) + ":" + str(y[1])
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
         """ Function to send the set of periodic-frequent patterns after completion of the mining process
 
         :return: returning periodic-frequent patterns
         :rtype: dict
         """
         return self._finalPatterns
 
+    def printResults(self):
+        print("Total number of Stable Periodic  Patterns:", len(self.getPatterns()))
+        print("Total Memory in USS:", self.getMemoryUSS())
+        print("Total Memory in RSS", self.getMemoryRSS())
+        print("Total ExecutionTime in ms:", self.getRuntime())
+
 
 if __name__ == "__main__":
     _ap = str()
     if len(_ab._sys.argv) == 6 or len(_ab._sys.argv) == 7:
         if len(_ab._sys.argv) == 7:
-            _ap = TSPIN(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5], _ab._sys.argv[6])
+            _ap = SPPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5], _ab._sys.argv[6])
         if len(_ab._sys.argv) == 6:
-            _ap = TSPIN(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
+            _ap = SPPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
         _ap.startMine()
-        _Patterns = _ap.getPatterns()
-        print("Total number of Patterns:", len(_Patterns))
+        print("Total number of Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
-        _memUSS = _ap.getMemoryUSS()
-        print("Total Memory in USS:", _memUSS)
-        _memRSS = _ap.getMemoryRSS()
-        print("Total Memory in RSS", _memRSS)
-        _run = _ap.getRuntime()
-        print("Total ExecutionTime in ms:", _run)
+        print("Total Memory in USS:", _ap.getMemoryUSS())
+        print("Total Memory in RSS", _ap.getMemoryRSS())
+        print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
-        _ap = TSPIN('/Users/Likhitha/Downloads/SPP_sample.txt', 5, 1, 1, ' ')
-        _ap.startMine()
-        print(len(_ap._Database))
-        _Patterns = _ap.getPatterns()
-        for x, y in _Patterns.items():
-            print(x, y)
-        print("Total number of Patterns:", len(_Patterns))
-        _ap.save('/Users/Likhitha/Downloads/output.txt')
-        _memUSS = _ap.getMemoryUSS()
-        print("Total Memory in USS:", _memUSS)
-        _memRSS = _ap.getMemoryRSS()
-        print("Total Memory in RSS", _memRSS)
-        _run = _ap.getRuntime()
-        print("Total ExecutionTime in ms:", _run)
         print("Error! The number of input parameters do not match the total number of parameters provided")
 
-
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `pami-2023.4.1/PAMI/stablePeriodicFrequentPattern/topK/abstract.py` & `pami-2023.5.1/PAMI/stablePeriodicFrequentPattern/topK/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/uncertainFrequentPattern/__init__.py` & `pami-2023.5.1/PAMI/uncertainFrequentPattern/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/CUFPTree.py` & `pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/TubeP.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,77 +1,120 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
+#     from PAMI.uncertainFrequentPattern.basic import TubeP as alg
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     obj = alg.TubeP(iFile, minSup)
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getmemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
-from PAMI.uncertainFrequentPattern.basic import abstract as _ab
+from PAMI.uncertainFrequentPattern.basic import abstract as _fp
 
-_minSup = str()
-_ab._sys.setrecursionlimit(20000)
+_minSup = float()
+_fp._sys.setrecursionlimit(20000)
 _finalPatterns = {}
 
 
 class _Item:
     """
     A class used to represent the item with probability in transaction of dataset
     ...
-    Attributes:
-    __________
-        item : int or word
-            Represents the name of the item
-        probability : float
-            Represent the existential probability(likelihood presence) of an item
+        Attributes:
+        __________
+            item : int or word
+                Represents the name of the item
+            probability : float
+                Represent the existential probability(likelihood presence) of an item
     """
 
     def __init__(self, item, probability):
         self.item = item
         self.probability = probability
 
 
 class _Node(object):
     """
-    A class used to represent the node of frequentPatternTree
+        A class used to represent the node of frequentPatternTree
         ...
-    Attributes:
-    ----------
-        item : int
-            storing item of a node
-        probability : int
-            To maintain the expected support of node
-        parent : node
-            To maintain the parent of every node
-        children : list
-            To maintain the children of node
-    Methods:
-    -------
-        addChild(itemName)
-            storing the children to their respective parent nodes
+        Attributes:
+        ----------
+            item : int
+                storing item of a node
+            probability : int
+                To maintain the expected support of node
+            parent : node
+                To maintain the parent of every node
+            children : list
+                To maintain the children of node
+        Methods:
+        -------
+            addChild(itemName)
+                storing the children to their respective parent nodes
     """
 
     def __init__(self, item, children):
         self.item = item
         self.probability = 1
+        self.maxPrefixProbability = 1
+        self.p = 1
         self.children = children
         self.parent = None
 
     def addChild(self, node):
         self.children[node.item] = node
         node.parent = self
 
 
+def printTree(root):
+    for x, y in root.children.items():
+        print(x, y.item, y.probability, y.parent.item, y.tids, y.maxPrefixProbability)
+        printTree(y)
+
+
 class _Tree(object):
     """
     A class used to represent the frequentPatternGrowth tree structure
     ...
     Attributes:
     ----------
         root : Node
@@ -80,189 +123,210 @@
             storing the nodes with same item name
         info : dictionary
             stores the support of items
     Methods:
     -------
         addTransaction(transaction)
             creating transaction as a branch in frequentPatternTree
-        addConditionalPattern(prefixPaths, supportOfItems)
+        addConditionalTransaction(prefixPaths, supportOfItems)
             construct the conditional tree for prefix paths
         conditionalPatterns(Node)
             generates the conditional patterns from tree for specific node
         conditionalTransactions(prefixPaths,Support)
-            takes the prefixPath of a node and support at child of the path and extract the frequent items from
-            prefixPaths and generates prefixPaths with items which are frequent
+                takes the prefixPath of a node and support at child of the path and extract the frequent items from
+                prefixPaths and generates prefixPaths with items which are frequent
         remove(Node)
-            removes the node from tree once after generating all the patterns respective to the node
+                removes the node from tree once after generating all the patterns respective to the node
         generatePatterns(Node)
             starts from the root node of the tree and mines the frequent patterns
     """
 
     def __init__(self):
         self.root = _Node(None, {})
         self.summaries = {}
         self.info = {}
 
     def addTransaction(self, transaction):
         """adding transaction into tree
-            :param transaction : it represents the one self.Database in database
-            :type transaction : list
-        """
-
+                :param transaction : it represents the one transactions in database
+                :type transaction : list
+                        """
         currentNode = self.root
+        k = 0
         for i in range(len(transaction)):
+            k += 1
             if transaction[i].item not in currentNode.children:
                 newNode = _Node(transaction[i].item, {})
+                newNode.k = k
+                newNode.prefixProbability = transaction[i].probability
                 l1 = i - 1
-                lp = []
+                temp = []
                 while l1 >= 0:
-                    lp.append(transaction[l1].probability)
+                    temp.append(transaction[l1].probability)
                     l1 -= 1
-                if len(lp) == 0:
-                    newNode.probability = transaction[i].probability
+                if len(temp) == 0:
+                    newNode.probability = round(transaction[i].probability, 2)
                 else:
-                    newNode.probability = max(lp) * transaction[i].probability
+                    newNode.probability = round(max(temp) * transaction[i].probability, 2)
                 currentNode.addChild(newNode)
                 if transaction[i].item in self.summaries:
                     self.summaries[transaction[i].item].append(newNode)
                 else:
                     self.summaries[transaction[i].item] = [newNode]
                 currentNode = newNode
             else:
                 currentNode = currentNode.children[transaction[i].item]
+                currentNode.prefixProbability = max(transaction[i].probability, currentNode.prefixProbability)
+                currentNode.k = k
                 l1 = i - 1
-                lp = []
+                temp = []
                 while l1 >= 0:
-                    lp.append(transaction[l1].probability)
+                    temp.append(transaction[l1].probability)
                     l1 -= 1
-                if len(lp) == 0:
-                    currentNode.probability += transaction[i].probability
+                if len(temp) == 0:
+                    currentNode.probability += round(transaction[i].probability, 2)
                 else:
-                    currentNode.probability += max(lp) * transaction[i].probability
+                    nn = max(temp) * transaction[i].probability
+                    currentNode.probability += round(nn, 2)
 
-    def addConditionalPattern(self, transaction, sup):
+    def addConditionalTransaction(self, transaction, sup, second):
         """constructing conditional tree from prefixPaths
-            :param transaction : it represents the one self.Database in database
-            :type transaction : list
-            :param sup : support of prefixPath taken at last child of the path
-            :type sup : int
+            :param transaction: it represents the one transactions in database
+            :type transaction: list
+            :param sup: support of prefixPath taken at last child of the path
+            :type sup: int
+            :param second: the second probability of the node
+            :type second: float
         """
-
-        # This method takes transaction, support and constructs the conditional tree
         currentNode = self.root
+        k = 0
         for i in range(len(transaction)):
+            k += 1
             if transaction[i] not in currentNode.children:
                 newNode = _Node(transaction[i], {})
+                newNode.k = k
+                newNode.prefixProbability = second
                 newNode.probability = sup
                 currentNode.addChild(newNode)
                 if transaction[i] in self.summaries:
                     self.summaries[transaction[i]].append(newNode)
                 else:
                     self.summaries[transaction[i]] = [newNode]
                 currentNode = newNode
             else:
                 currentNode = currentNode.children[transaction[i]]
+                currentNode.k = k
+                currentNode.prefixProbability = max(currentNode.prefixProbability, second)
                 currentNode.probability += sup
 
     def conditionalPatterns(self, alpha):
         """generates all the conditional patterns of respective node
             :param alpha : it represents the Node in tree
             :type alpha : _Node
         """
-
-        # This method generates conditional patterns of node by traversing the tree
         finalPatterns = []
         sup = []
+        second = []
         for i in self.summaries[alpha]:
             s = i.probability
+            s1 = i.maxPrefixProbability
             set2 = []
             while i.parent.item is not None:
                 set2.append(i.parent.item)
                 i = i.parent
             if len(set2) > 0:
                 set2.reverse()
                 finalPatterns.append(set2)
+                second.append(s1)
                 sup.append(s)
         finalPatterns, support, info = self.conditionalTransactions(finalPatterns, sup)
-        return finalPatterns, support, info
-
-    def removeNode(self, nodeValue):
-        """removing the node from tree
-            :param nodeValue : it represents the node in tree
-            :type nodeValue : node
-        """
-
-        for i in self.summaries[nodeValue]:
-            del i.parent.children[nodeValue]
+        return finalPatterns, support, info, second
 
     def conditionalTransactions(self, condPatterns, support):
         """ It generates the conditional patterns with frequent items
-                :param condPatterns : conditionalPatterns generated from conditionalPattern method for respective node
-                :type condPatterns : list
-                :support : the support of conditional pattern in tree
-                :support : int
+            :param condPatterns: condPatterns generated from condition pattern method for respective node
+            :type condPatterns: list
+            :param support: the support of conditional pattern in tree
+            :type support: list
         """
-
-        global minSup
+        global _minSup
         pat = []
         sup = []
-        count = {}
+        data1 = {}
         for i in range(len(condPatterns)):
             for j in condPatterns[i]:
-                if j in count:
-                    count[j] += support[i]
+                if j in data1:
+                    data1[j] += support[i]
                 else:
-                    count[j] = support[i]
+                    data1[j] = support[i]
         updatedDict = {}
-        updatedDict = {k: v for k, v in count.items() if v >= minSup}
+        updatedDict = {k: v for k, v in data1.items() if v >= _minSup}
         count = 0
         for p in condPatterns:
             p1 = [v for v in p if v in updatedDict]
-            trans = sorted(p1, key=lambda x: updatedDict[x], reverse=True)
+            trans = sorted(p1, key=lambda x: (updatedDict.get(x)), reverse=True)
             if len(trans) > 0:
                 pat.append(trans)
                 sup.append(support[count])
-                count += 1
+            count += 1
         return pat, sup, updatedDict
 
+    def removeNode(self, nodeValue):
+        """removing the node from tree
+            :param nodeValue : it represents the node in tree
+            :type nodeValue : node
+        """
+        for i in self.summaries[nodeValue]:
+            del i.parent.children[nodeValue]
+
     def generatePatterns(self, prefix):
         """generates the patterns
             :param prefix : forms the combination of items
             :type prefix : list
         """
-
-        global _finalPatterns, minSup
+        global _finalPatterns, _minSup
         for i in sorted(self.summaries, key=lambda x: (self.info.get(x))):
             pattern = prefix[:]
             pattern.append(i)
             s = 0
             for x in self.summaries[i]:
-                s += x.probability
+                #if x.k <= 2:
+                    #s += x.probability
+                #elif x.k >= 3:
+                    #n = x.probability * pow(x.prefixProbability, (x.k - 2))
+                    #s += n
+                if len(pattern) <= 2:
+                    s += x.probability
+                elif len(pattern) >= 3:
+                    n = x.probability * pow(x.secondProbability, (x.k - 2))
+                    s += n
             _finalPatterns[tuple(pattern)] = self.info[i]
-            if s >= minSup:
-                patterns, support, info = self.conditionalPatterns(i)
+            if s >= _minSup:
+                patterns, support, info, second = self.conditionalPatterns(i)
                 conditionalTree = _Tree()
                 conditionalTree.info = info.copy()
                 for pat in range(len(patterns)):
-                    conditionalTree.addConditionalPattern(patterns[pat], support[pat])
+                    conditionalTree.addConditionalTransaction(patterns[pat], support[pat], second[pat])
                 if len(patterns) > 0:
                     conditionalTree.generatePatterns(pattern)
             self.removeNode(i)
 
 
-class CUFPTree(_ab._frequentPatterns):
+class TubeP(_fp._frequentPatterns):
     """
-        It is one of the fundamental algorithm to discover frequent patterns in a uncertain transactional database
-        using CUFP-Tree.
+    Description:
+    -------------
+    TubeP is one of the fastest algorithm to discover frequent patterns in a uncertain transactional database.
+
     Reference:
-    --------
-        Chun-Wei Lin Tzung-PeiHong, 'new mining approach for uncertain databases using CUFP trees',
-        Expert Systems with Applications, Volume 39, Issue 4, March 2012, Pages 4084-4093, https://doi.org/10.1016/j.eswa.2011.09.087
-    Attributes:
     ----------
+        Carson Kai-Sang Leung and Richard Kyle MacKinnon. 2014. Fast Algorithms for Frequent Itemset Mining from Uncertain Data.
+        In Proceedings of the 2014 IEEE International Conference on Data Mining (ICDM '14). IEEE Computer Society, USA, 893898. https://doi.org/10.1109/ICDM.2014.146
+    Attributes:
+    -----------
         iFile : file
             Name of the Input file or path of the input file
         oFile : file
             Name of the output file or path of the output file
         minSup: float or int or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
@@ -288,15 +352,15 @@
         tree : class
             To represents the Tree class
         itemSetCount : int
             To represents the total no of patterns
         finalPatterns : dict
             To store the complete patterns
     Methods:
-    -------
+    ---------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -313,56 +377,58 @@
             Extracts the one-length frequent patterns from database
         updateTransactions()
             Update the transactions by removing non-frequent items and sort the Database by item decreased support
         buildTree()
             After updating the Database, remaining items will be added into the tree by setting root node as null
         convert()
             to convert the user specified value
-        startMine()
-            Mining process will start from this function
-    Executing the code on terminal:
-    -------
-        Format:
-        ------
-        python3 CUFPTree.py <inputFile> <outputFile> <minSup>
-        Examples:
-        --------
-        python3 CUFPTree.py sampleTDB.txt patterns.txt 3    (minSup  will be considered in support count or frequency)
 
-    Sample run of importing the code:
-    -------------------
-        from PAMI.uncertainFrequentPattern.basic import CUFPTree as alg
+    **Methods to execute code on terminal**
 
-        obj = alg.CUFPTree(iFile, minSup)
+            Format:
+                      >>> python3 TubeP.py <inputFile> <outputFile> <minSup>
+            Example:
+                      >>>  python3 TubeP.py sampleTDB.txt patterns.txt 3
 
-        obj.startMine()
+            .. note:: minSup  will be considered in support count or frequency
 
-        Patterns = obj.getPatterns()
+    **Importing this algorithm into a python program**
 
-        print("Total number of  Patterns:", len(Patterns))
+    .. code-block:: python
 
-        obj.save(oFile)
+            from PAMI.uncertainFrequentPattern.basic import TubeP as alg
 
-        Df = obj.getPatternsAsDataFrame()
+            obj = alg.TubeP(iFile, minSup)
 
-        memUSS = obj.getMemoryUSS()
+            obj.startMine()
 
-        print("Total Memory in USS:", memUSS)
+            frequentPatterns = obj.getPatterns()
 
-        memRSS = obj.getMemoryRSS()
+            print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-        print("Total Memory in RSS", memRSS)
+            obj.savePatterns(oFile)
 
-        run = obj.getRuntime()
+            Df = obj.getPatternsAsDataFrame()
 
-        print("Total ExecutionTime in seconds:", run)
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
-    """
+            memUSS = obj.getmemoryUSS()
+
+            print("Total Memory in USS:", memUSS)
+
+            memRSS = obj.getMemoryRSS()
+
+            print("Total Memory in RSS", memRSS)
+
+            run = obj.getRuntime()
+
+            print("Total ExecutionTime in seconds:", run)
+
+    **Credits:**
+
+             The complete program was written by  P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+"""
     _startTime = float()
     _endTime = float()
     _minSup = str()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
@@ -372,18 +438,18 @@
     _rank = {}
 
     def __init__(self, iFile, minSup, sep='\t'):
         super().__init__(iFile, minSup, sep)
 
     def _creatingItemSets(self):
         """
-            Scans the uncertain transactional dataset
+        Scans the dataset and stores the transactions into Database variable
         """
         self._Database = []
-        if isinstance(self._iFile, _ab._pd.DataFrame):
+        if isinstance(self._iFile, _fp._pd.DataFrame):
             uncertain, data = [], []
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
                 self._Database = self._iFile['Transactions'].tolist()
             if 'uncertain' in i:
@@ -393,152 +459,143 @@
                 for j in range(len(data[k])):
                     product = _Item(data[k][j], uncertain[k][j])
                     tr.append(product)
                 self._Database.append(tr)
 
             # print(self.Database)
         if isinstance(self._iFile, str):
-            if _ab._validators.url(self._iFile):
-                data = _ab._urlopen(self._iFile)
+            if _fp._validators.url(self._iFile):
+                data = _fp._urlopen(self._iFile)
                 for line in data:
-                    line.strip()
+                    line = line.strip()
                     line = line.decode("utf-8")
-                    temp = [i.rstrip() for i in line.split(self._sep)]
-                    temp = [x for x in temp if x]
+                    temp1 = line.split(':')
+                    temp = [i.rstrip() for i in temp[0].split(self._sep)]
+                    uncertain = [float(i.rstrip()) for i in temp[1].split(self._sep)]
                     tr = []
-                    for i in temp:
-                        i1 = i.index('(')
-                        i2 = i.index(')')
-                        item = i[0:i1]
-                        probability = float(i[i1 + 1:i2])
+                    for i in range(len(temp)):
+                        item = temp[i]
+                        probability = uncertain[i]
                         product = _Item(item, probability)
                         tr.append(product)
                     self._Database.append(temp)
             else:
                 try:
                     with open(self._iFile, 'r') as f:
                         for line in f:
-                            temp = [i.rstrip() for i in line.split(self._sep)]
-                            temp = [x for x in temp if x]
+                            temp1 = line.strip()
+                            temp1 = temp1.split(':')
+                            temp = [i.rstrip() for i in temp1[0].split(self._sep)]
+                            uncertain = [float(i.rstrip()) for i in temp1[1].split(self._sep)]
                             tr = []
-                            for i in temp:
-                                i1 = i.index('(')
-                                i2 = i.index(')')
-                                item = i[0:i1]
-                                probability = float(i[i1 + 1:i2])
+                            for i in range(len(temp)):
+                                item = temp[i]
+                                probability = uncertain[i]
                                 product = _Item(item, probability)
                                 tr.append(product)
                             self._Database.append(tr)
                 except IOError:
                     print("File Not Found")
 
     def _frequentOneItem(self):
-        """takes the self.Database and calculates the support of each item in the dataset and assign the
-            ranks to the items by decreasing support and returns the frequent items list
-                :param self.Database : it represents the one self.Database in database
-                :type self.Database : list
+        """takes the transactions and calculates the support of each item in the dataset and assign the
+                    ranks to the items by decreasing support and returns the frequent items list
         """
-
+        global _minSup
         mapSupport = {}
         for i in self._Database:
             for j in i:
                 if j.item not in mapSupport:
-                    mapSupport[j.item] = j.probability
+                    mapSupport[j.item] = round(j.probability, 2)
                 else:
-                    mapSupport[j.item] += j.probability
-        mapSupport = {k: v for k, v in mapSupport.items() if v >= self._minSup}
+                    mapSupport[j.item] += round(j.probability, 2)
+        mapSupport = {k: round(v, 2) for k, v in mapSupport.items() if v >= self._minSup}
         plist = [k for k, v in sorted(mapSupport.items(), key=lambda x: x[1], reverse=True)]
-        self.rank = dict([(index, item) for (item, index) in enumerate(plist)])
+        self._rank = dict([(index, item) for (item, index) in enumerate(plist)])
         return mapSupport, plist
 
-    @staticmethod
-    def _buildTree(data, info):
-        """it takes the self.Database and support of each item and construct the main tree with setting root
-            node as null
-                :param data : it represents the one self.Database in database
-                :type data : list
-                :param info : it represents the support of each item
-                :type info : dictionary
+    def _buildTree(self, data, info):
+        """it takes the transactions and support of each item and construct the main tree with setting root
+                    node as null
+            :param data : it represents the one transactions in database
+            :type data : list
+            :param info : it represents the support of each item
+            :type info : dictionary
         """
-
         rootNode = _Tree()
         rootNode.info = info.copy()
         for i in range(len(data)):
             rootNode.addTransaction(data[i])
         return rootNode
 
     def _updateTransactions(self, dict1):
-        """remove the items which are not frequent from self.Database and updates the self.Database with rank of items
+        """remove the items which are not frequent from transactions and updates the transactions with rank of items
             :param dict1 : frequent items with support
             :type dict1 : dictionary
         """
-
         list1 = []
         for tr in self._Database:
             list2 = []
             for i in range(0, len(tr)):
                 if tr[i].item in dict1:
                     list2.append(tr[i])
             if len(list2) >= 2:
                 basket = list2
-                basket.sort(key=lambda val: self.rank[val.item])
+                basket.sort(key=lambda val: self._rank[val.item])
                 list2 = basket
                 list1.append(list2)
         return list1
 
-    @staticmethod
-    def _check(i, x):
+    def _Check(self, i, x):
         """To check the presence of item or pattern in transaction
-                :param x: it represents the pattern
-                :type x : list
-                :param i : represents the uncertain self.Database
-                :type i : list
+            :param x: it represents the pattern
+            :type x : list
+            :param i : represents the uncertain transactions
+            :type i : list
         """
-
-        # This method taken a transaction as input and returns the tree
         for m in x:
             k = 0
             for n in i:
                 if m == n.item:
                     k += 1
             if k == 0:
                 return 0
         return 1
 
     def _convert(self, value):
         """
-        To convert the type of user specified minSup value
-            :param value: user specified minSup value
-            :return: converted type minSup value
+            To convert the type of user specified minSup value
+                :param value: user specified minSup value
+                :return: converted type minSup value
         """
         if type(value) is int:
             value = int(value)
         if type(value) is float:
             value = (len(self._Database) * value)
         if type(value) is str:
             if '.' in value:
                 value = (len(self._Database) * value)
             else:
                 value = int(value)
         return value
 
     def _removeFalsePositives(self):
         """
-            To remove the false positive patterns generated in frequent patterns
-            :return: patterns with accurate probability
+               To remove the false positive patterns generated in frequent patterns
+               :return: patterns with accurate probability
         """
         global _finalPatterns
         periods = {}
         for i in self._Database:
             for x, y in _finalPatterns.items():
                 if len(x) == 1:
                     periods[x] = y
                 else:
                     s = 1
-                    check = self._check(i, x)
+                    check = self._Check(i, x)
                     if check == 1:
                         for j in i:
                             if j.item in x:
                                 s *= j.probability
                         if x in periods:
                             periods[x] += s
                         else:
@@ -548,35 +605,35 @@
                 sample = str()
                 for i in x:
                     sample = sample + i + "\t"
                 self._finalPatterns[sample] = y
 
     def startMine(self):
         """Main method where the patterns are mined by constructing tree and remove the remove the false patterns
-            by counting the original support of a patterns
+                           by counting the original support of a patterns
         """
-        global minSup
-        self._startTime = _ab._time.time()
+        global _minSup
+        self._startTime = _fp._time.time()
         self._creatingItemSets()
         self._minSup = self._convert(self._minSup)
-        minSup = self._minSup
+        _minSup = self._minSup
         self._finalPatterns = {}
         mapSupport, plist = self._frequentOneItem()
-        self.Database1 = self._updateTransactions(mapSupport)
+        transactions1 = self._updateTransactions(mapSupport)
         info = {k: v for k, v in mapSupport.items()}
-        Tree1 = self._buildTree(self.Database1, info)
+        Tree1 = self._buildTree(transactions1, info)
         Tree1.generatePatterns([])
         self._removeFalsePositives()
-        print("Uncertain Frequent patterns were successfully generated using CUFP algorithm")
-        self._endTime = _ab._time.time()
-        process = _ab._psutil.Process(_ab._os.getpid())
+        print("Uncertain Frequent patterns were generated successfully using TubeP algorithm")
+        self._endTime = _fp._time.time()
+        process = _fp._psutil.Process(_fp._os.getpid())
+        self._memoryRSS = float()
         self._memoryUSS = float()
-        self.memoryRSS = float()
         self._memoryUSS = process.memory_full_info().uss
-        self.memoryRSS = process.memory_info().rss
+        self._memoryRSS = process.memory_info().rss
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
         :return: returning USS memory consumed by the mining process
         :rtype: float
         """
 
@@ -584,15 +641,15 @@
 
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the mining process will be retrieved from this function
         :return: returning RSS memory consumed by the mining process
         :rtype: float
         """
 
-        return self.memoryRSS
+        return self._memoryRSS
 
     def getRuntime(self):
         """Calculating the total amount of runtime taken by the mining process
         :return: returning total amount of runtime taken by the mining process
         :rtype: float
         """
 
@@ -604,15 +661,15 @@
         :rtype: pd.DataFrame
         """
 
         dataframe = {}
         data = []
         for a, b in self._finalPatterns.items():
             data.append([a.replace('\t', ' '), b])
-            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
+            dataframe = _fp._pd.DataFrame(data, columns=['Patterns', 'Support'])
         return dataframe
 
     def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
         :param outFile: name of the output file
         :type outFile: file
         """
@@ -623,31 +680,31 @@
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
         :return: returning frequent patterns
         :rtype: dict
         """
-        return self._finalPatterns
+        return len(self._finalPatterns)
 
     def printResults(self):
         print("Total number of  Uncertain Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:
-        if len(_ab._sys.argv) == 5:
-            _ap = CUFPTree(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
-        if len(_ab._sys.argv) == 4:
-            _ap = CUFPTree(_ab._sys.argv[1], _ab._sys.argv[3])
+    if len(_fp._sys.argv) == 4 or len(_fp._sys.argv) == 5:
+        if len(_fp._sys.argv) == 5:
+            _ap = TubeP(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4])
+        if len(_fp._sys.argv) == 4:
+            _ap = TubeP(_fp._sys.argv[1], _fp._sys.argv[3])
         _ap.startMine()
-        print("Total number of Uncertain Frequent Patterns:", len(_ap.getPatterns()))
-        _ap.save(_ab._sys.argv[2])
+        print("Total number of  Uncertain Frequent Patterns:", len(_ap.getPatterns()))
+        _ap.save(_fp._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
-        print("Error! The number of input parameters do not match the total number of parameters provided")
+        print("Error! The number of input parameters do not match the total number of parameters provided")
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/PUFGrowth.py` & `pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/CUFPTree.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,21 +1,58 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     from PAMI.uncertainFrequentPattern.basic import CUFPTree as alg
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     obj = alg.CUFPTree(iFile, minSup)
+#     v
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getmemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
 
 from PAMI.uncertainFrequentPattern.basic import abstract as _ab
 
 _minSup = str()
 _ab._sys.setrecursionlimit(20000)
 _finalPatterns = {}
 
@@ -245,24 +282,26 @@
                 for pat in range(len(patterns)):
                     conditionalTree.addConditionalPattern(patterns[pat], support[pat])
                 if len(patterns) > 0:
                     conditionalTree.generatePatterns(pattern)
             self.removeNode(i)
 
 
-class PUFGrowth(_ab._frequentPatterns):
+class CUFPTree(_ab._frequentPatterns):
     """
+    Description:
+    ----------------------
         It is one of the fundamental algorithm to discover frequent patterns in a uncertain transactional database
-        using PUF-Tree.
+        using CUFP-Tree.
     Reference:
-    --------
-        Carson Kai-Sang Leung, Syed Khairuzzaman Tanbeer, "PUF-Tree: A Compact Tree Structure for Frequent Pattern Mining of Uncertain Data",
-        Pacific-Asia Conference on Knowledge Discovery and Data Mining(PAKDD 2013), https://link.springer.com/chapter/10.1007/978-3-642-37453-1_2
+    --------------------
+        Chun-Wei Lin Tzung-PeiHong, 'new mining approach for uncertain databases using CUFP trees',
+        Expert Systems with Applications, Volume 39, Issue 4, March 2012, Pages 4084-4093, https://doi.org/10.1016/j.eswa.2011.09.087
     Attributes:
-    ----------
+    ---------------------
         iFile : file
             Name of the Input file or path of the input file
         oFile : file
             Name of the output file or path of the output file
         minSup: float or int or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
@@ -288,15 +327,15 @@
         tree : class
             To represents the Tree class
         itemSetCount : int
             To represents the total no of patterns
         finalPatterns : dict
             To store the complete patterns
     Methods:
-    -------
+    ------------------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -315,41 +354,60 @@
             Update the transactions by removing non-frequent items and sort the Database by item decreased support
         buildTree()
             After updating the Database, remaining items will be added into the tree by setting root node as null
         convert()
             to convert the user specified value
         startMine()
             Mining process will start from this function
-    Executing the code on terminal:
-    -------
+    **Methods to execute code on terminal**
+    ----------------------------------------
+
         Format:
-        ------
-        python3 PUFGrowth.py <inputFile> <outputFile> <minSup>
-        Examples:
-        --------
-        python3 PUFGrowth.py sampleTDB.txt patterns.txt 3    (minSup  will be considered in support count or frequency)
-    Sample run of importing the code:
-    -------------------
-        from PAMI.uncertainFrequentPattern.basic import puf as alg
-        obj = alg.PUFGrowth(iFile, minSup)
-        obj.startMine()
-        Patterns = obj.getPatterns()
-        print("Total number of  Patterns:", len(Patterns))
-        obj.save(oFile)
-        Df = obj.getPatternsAsDataFrame()
-        memUSS = obj.getMemoryUSS()
-        print("Total Memory in USS:", memUSS)
-        memRSS = obj.getMemoryRSS()
-        print("Total Memory in RSS", memRSS)
-        run = obj.getRuntime()
-        print("Total ExecutionTime in seconds:", run)
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
-    """
+                  >>>  python3 CUFPTree.py <inputFile> <outputFile> <minSup>
+        Example:
+                  >>>  python3 CUFPTree.py sampleTDB.txt patterns.txt 3
+
+         .. note:: minSup  will be considered in support count or frequency
+
+
+    **Importing this algorithm into a python program**
+    ------------------------------------------------------------
+    .. code-block:: python
+
+            from PAMI.uncertainFrequentPattern.basic import CUFPTree as alg
+
+            obj = alg.CUFPTree(iFile, minSup)v
+
+            obj.startMine()
+
+            frequentPatterns = obj.getPatterns()
+
+            print("Total number of Frequent Patterns:", len(frequentPatterns))
+
+            obj.savePatterns(oFile)
+
+            Df = obj.getPatternsAsDataFrame()
+
+            memUSS = obj.getmemoryUSS()
+
+            print("Total Memory in USS:", memUSS)
+
+            memRSS = obj.getMemoryRSS()
+
+            print("Total Memory in RSS", memRSS)
+
+            run = obj.getRuntime()
+
+            print("Total ExecutionTime in seconds:", run)
+
+    **Credits:**
+    --------------------
+
+             The complete program was written by  P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+"""
     _startTime = float()
     _endTime = float()
     _minSup = str()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
@@ -383,40 +441,39 @@
                 self._Database.append(tr)
 
             # print(self.Database)
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
-                    line = line.strip()
+                    line.strip()
                     line = line.decode("utf-8")
-                    temp1 = line.split(':')
-                    temp = [i.rstrip() for i in temp[0].split(self._sep)]
-                    uncertain = [float(i.rstrip()) for i in temp[1].split(self._sep)]
+                    temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
-                    uncertain = [x for x in uncertain if x]
                     tr = []
-                    for i in range(len(temp)):
-                        item = temp[i]
-                        probability = uncertain[i]
+                    for i in temp:
+                        i1 = i.index('(')
+                        i2 = i.index(')')
+                        item = i[0:i1]
+                        probability = float(i[i1 + 1:i2])
                         product = _Item(item, probability)
                         tr.append(product)
-                    self._Database.append(tr)
+                    self._Database.append(temp)
             else:
                 try:
                     with open(self._iFile, 'r') as f:
                         for line in f:
-                            temp1 = line.strip()
-                            temp1 = temp1.split(':')
-                            temp = [i.rstrip() for i in temp1[0].split(self._sep)]
-                            uncertain = [float(i.rstrip()) for i in temp1[1].split(self._sep)]
+                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            temp = [x for x in temp if x]
                             tr = []
-                            for i in range(len(temp)):
-                                item = temp[i]
-                                probability = uncertain[i]
+                            for i in temp:
+                                i1 = i.index('(')
+                                i2 = i.index(')')
+                                item = i[0:i1]
+                                probability = float(i[i1 + 1:i2])
                                 product = _Item(item, probability)
                                 tr.append(product)
                             self._Database.append(tr)
                 except IOError:
                     print("File Not Found")
 
     def _frequentOneItem(self):
@@ -550,15 +607,15 @@
         self._finalPatterns = {}
         mapSupport, plist = self._frequentOneItem()
         self.Database1 = self._updateTransactions(mapSupport)
         info = {k: v for k, v in mapSupport.items()}
         Tree1 = self._buildTree(self.Database1, info)
         Tree1.generatePatterns([])
         self._removeFalsePositives()
-        print("Uncertain Frequent patterns were generated successfully using PUFGrowth algorithm")
+        print("Uncertain Frequent patterns were successfully generated using CUFP algorithm")
         self._endTime = _ab._time.time()
         process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryUSS = float()
         self.memoryRSS = float()
         self._memoryUSS = process.memory_full_info().uss
         self.memoryRSS = process.memory_info().rss
 
@@ -624,18 +681,18 @@
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
     if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:
         if len(_ab._sys.argv) == 5:
-            _ap = PUFGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+            _ap = CUFPTree(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
         if len(_ab._sys.argv) == 4:
-            _ap = PUFGrowth(_ab._sys.argv[1], _ab._sys.argv[3])
+            _ap = CUFPTree(_ab._sys.argv[1], _ab._sys.argv[3])
         _ap.startMine()
-        print("Total number of Uncertain Frequent Patterns:", _ap.getPatterns())
+        print("Total number of Uncertain Frequent Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
-        print("Error! The number of input parameters do not match the total number of parameters provided")
+        print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/TUFP.py` & `pami-2023.5.1/PAMI/frequentPattern/closed/CHARM.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,395 +1,467 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# CHARM is an algorithm to discover closed frequent patterns in a transactional database. Closed frequent patterns are patterns if there exists no superset that has the same support count as this original itemset. This algorithm employs depth-first search technique to find the complete set of closed frequent patterns in a
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
+#  **Importing this algorithm into a python program**
+#  --------------------------------------------------------------
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#             from PAMI.frequentPattern.closed import closed as alg
+#
+#             obj = alg.Closed(iFile, minSup)
+#
+#             obj.startMine()
+#
+#             frequentPatterns = obj.getPatterns()
+#
+#             print("Total number of Closed Frequent Patterns:", len(frequentPatterns))
+#
+#             obj.savePatterns(oFile)
+#
+#             Df = obj.getPatternsAsDataFrame()
+#
+#             memUSS = obj.getMemoryUSS()
+#
+#             print("Total Memory in USS:", memUSS)
+#
+#             memRSS = obj.getMemoryRSS()
+#
+#             print("Total Memory in RSS", memRSS)
+#
+#             run = obj.getRuntime()
+#
+#             print("Total ExecutionTime in seconds:", run)
 
-from PAMI.uncertainFrequentPattern.basic import abstract as _ab
 
-_minSup = float()
-_finalPatterns = {}
 
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
 
-class _Item:
-    """
-    A class used to represent the item with probability in transaction of dataset
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
 
-    ...
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
 
-    Attributes:
-    __________
-        item : int or word
-            Represents the name of the item
-        probability : float
-            Represent the existential probability(likelihood presence) of an item
-    """
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
 
-    def __init__(self, item, probability):
-        self.item = item
-        self.probability = probability
 
+from PAMI.frequentPattern.closed import abstract as _ab
 
-class TUFP(_ab._frequentPatterns):
+
+class CHARM(_ab._frequentPatterns):
     """
-        It is one of the fundamental algorithm to discover top-k frequent patterns in a uncertain transactional database
-        using CUP-Lists.
+    :Description: CHARM is an algorithm to discover closed frequent patterns in a transactional database. Closed frequent patterns are patterns if there exists no superset that has the same support count as this original itemset. This algorithm employs depth-first search technique to find the complete set of closed frequent patterns in a
+
+
+    :Reference:   Mohammed J. Zaki and Ching-Jui Hsiao, CHARM: An Efficient Algorithm for Closed Itemset Mining,
+            Proceedings of the 2002 SIAM, SDM. 2002, 457-473, https://doi.org/10.1137/1.9781611972726.27
+
+    :param  iFile: str :
+                   Name of the Input file to mine complete set of frequent patterns
+    :param  oFile: str :
+                   Name of the output file to store complete set of frequent patterns
+    :param  minSup: int or float or str :
+                   The user can specify minSup either in count or proportion of database size. If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+    :param  sep: str :
+                   This variable is used to distinguish items from one another in a transaction. The default seperator is tab space. However, the users can override their default separator.
+
+
+
+    :Attributes:
+
+        startTime : float
+          To record the start time of the mining process
+
+        endTime : float
+          To record the completion time of the mining process
+
+        finalPatterns : dict
+          Storing the complete set of patterns in a dictionary variable
 
-    Reference:
-    --------
-        Tuong Le, Bay Vo, Van-Nam Huynh, Ngoc Thanh Nguyen, Sung Wook Baik 5, "Mining top-k frequent patterns from uncertain databases",
-        Springer Science+Business Media, LLC, part of Springer Nature 2020, https://doi.org/10.1007/s10489-019-01622-1
-
-    Attributes:
-    ----------
-        iFile : file
-            Name of the Input file or path of the input file
-        oFile : file
-            Name of the output file or path of the output file
-        minSup: float or int or str
-            The user can specify minSup either in count or proportion of database size.
-            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-        sep : str
-            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-            However, the users can override their default separator.
         memoryUSS : float
-            To store the total amount of USS memory consumed by the program
+          To store the total amount of USS memory consumed by the program
+
         memoryRSS : float
-            To store the total amount of RSS memory consumed by the program
-        startTime:float
-            To record the start time of the mining process
-        endTime:float
-            To record the completion time of the mining process
+          To store the total amount of RSS memory consumed by the program
+
         Database : list
-            To store the transactions of a database in list
+          To store the transactions of a database in list
+
         mapSupport : Dictionary
             To maintain the information of item and their frequency
         lno : int
-            To represent the total no of transaction
+            it represents the total no of transactions
         tree : class
-            To represents the Tree class
+            it represents the Tree class
         itemSetCount : int
-            To represents the total no of patterns
+            it represents the total no of patterns
         finalPatterns : dict
-            To store the complete patterns
-    Methods:
-    -------
-        startMine()
-            Mining process will start from here
-        getPatterns()
-            Complete set of patterns will be retrieved with this function
-        storePatternsInFile(oFile)
-            Complete set of frequent patterns will be loaded in to a output file
-        getPatternsInDataFrame()
-            Complete set of frequent patterns will be loaded in to a dataframe
-        getMemoryUSS()
-            Total amount of USS memory consumed by the mining process will be retrieved from this function
-        getMemoryRSS()
-            Total amount of RSS memory consumed by the mining process will be retrieved from this function
-        getRuntime()
-            Total amount of runtime taken by the mining process will be retrieved from this function
-        creatingItemSets(fileName)
-            Scans the dataset and stores in a list format
-        frequentOneItem()
-            Extracts the one-length frequent patterns from database
-        updateTransactions()
-            Update the transactions by removing non-frequent items and sort the Database by item decreased support
-        buildTree()
-            After updating the Database, remaining items will be added into the tree by setting root node as null
-        convert()
-            to convert the user specified value
-        startMine()
-            Mining process will start from this function
-
-    Executing the code on terminal:
-    -------
-        Format:
-        ------
-
-        python3 TUFP.py <inputFile> <outputFile> <minSup>
-        Examples:
-        --------
-        python3 TUFP.py sampleTDB.txt patterns.txt 0.6    (minSup  will be considered in support count or frequency)
-
-
-    Sample run of importing the code:
-    -------------------
-
-        from PAMI.uncertainFrequentPattern.basic import TUFP as alg
-
-        obj = alg.TUFP(iFile, minSup)
-
-        obj.startMine()
-
-        Patterns = obj.getPatterns()
-
-        print("Total number of  Patterns:", len(Patterns))
-
-        obj.storePatternsInFile(oFile)
-
-        Df = obj.getPatternsInDataFrame()
-
-        memUSS = obj.getMemoryUSS()
-
-        print("Total Memory in USS:", memUSS)
-
-        memRSS = obj.getMemoryRSS()
-
-        print("Total Memory in RSS", memRSS)
-
-        run = obj.getRuntime()
-
-        print("Total ExecutionTime in seconds:", run)
-
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+            it represents to store the patterns
+        tidList : dict
+            stores the timestamps of an item
+        hashing : dict
+            stores the patterns with their support to check for the closed property
 
-    """
+
+    **Methods to execute code on terminal**
+    --------------------------------------------------------------
+
+            Format:
+                      >>> python3 CHARM.py <inputFile> <outputFile> <minSup>
+
+            Example:
+                      >>> python3 CHARM.py sampleDB.txt patterns.txt 10.0
+
+            .. note:: minSup will be considered in percentage of database transactions
+
+
+    **Importing this algorithm into a python program**
+    --------------------------------------------------------------
+    .. code-block:: python
+
+            from PAMI.frequentPattern.closed import closed as alg
+
+            obj = alg.Closed(iFile, minSup)
+
+            obj.startMine()
+
+            frequentPatterns = obj.getPatterns()
+
+            print("Total number of Closed Frequent Patterns:", len(frequentPatterns))
+
+            obj.savePatterns(oFile)
+
+            Df = obj.getPatternsAsDataFrame()
+
+            memUSS = obj.getMemoryUSS()
+
+            print("Total Memory in USS:", memUSS)
+
+            memRSS = obj.getMemoryRSS()
+
+            print("Total Memory in RSS", memRSS)
+
+            run = obj.getRuntime()
+
+            print("Total ExecutionTime in seconds:", run)
+
+
+    **Credits:**
+    -------------------------------
+
+                 The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+
+        """
 
     _startTime = float()
     _endTime = float()
-    _minSup = str()
+    _minSup = float()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
-    _cupList = {}
-    _topk = {}
-    _minimum = 9999
+    _tidList = {}
+    _lno = 0
+    _mapSupport = {}
+    _hashing = {}
+    _itemSetCount = 0
+    _maxItemId = 0
+    _tableSize = 10000
+    _writer = None
+
+    def _convert(self, value):
+        """
+        to convert the type of user specified minSup value
+
+        :param value: user specified minSup value
 
-    def _creatingItemSets(self):
+        :return: converted type
         """
-            Scans the dataset
+        if type(value) is int:
+            value = int(value)
+        if type(value) is float:
+            value = (self._lno * value)
+        if type(value) is str:
+            if '.' in value:
+                value = float(value)
+                value = (self._lno * value)
+            else:
+                value = int(value)
+        return value
+
+    def _creatingItemsets(self):
+        """
+        Storing the complete frequent patterns of the database/input file in a database variable
         """
-        self._Database = []
+        self._mapSupport = {}
+        self._tidList = {}
+        self._lno = 0
         if isinstance(self._iFile, _ab._pd.DataFrame):
-            uncertain, data = [], []
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
                 self._Database = self._iFile['Transactions'].tolist()
-            if 'uncertain' in i:
-                uncertain = self._iFile['uncertain'].tolist()
-            for k in range(len(data)):
-                tr = []
-                for j in range(len(data[k])):
-                    product = _Item(data[k][j], uncertain[k][j])
-                    tr.append(product)
-                self._Database.append(tr)
-
-            # print(self.Database)
+            for i in self._Database:
+                self._lno += 1
+                for j in i:
+                    if j not in self._mapSupport:
+                        self._mapSupport[j] = 1
+                        self._tidList[j] = [self._lno]
+                    else:
+                        self._mapSupport[j] += 1
+                        self._tidList[j].append(self._lno)
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
                     line.strip()
+                    self._lno += 1
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
-                    tr = []
-                    for i in temp:
-                        i1 = i.index('(')
-                        i2 = i.index(')')
-                        item = i[0:i1]
-                        probability = float(i[i1 + 1:i2])
-                        product = _Item(item, probability)
-                        tr.append(product)
-                    self._Database.append(temp)
+                    for j in temp:
+                        if j not in self._mapSupport:
+                            self._mapSupport[j] = 1
+                            self._tidList[j] = [self._lno]
+                        else:
+                            self._mapSupport[j] += 1
+                            self._tidList[j].append(self._lno)
             else:
                 try:
                     with open(self._iFile, 'r') as f:
                         for line in f:
-                            temp = [i.rstrip() for i in line.split(self._sep)]
-                            temp = [x for x in temp if x]
-                            tr = []
-                            for i in temp:
-                                i1 = i.index('(')
-                                i2 = i.index(')')
-                                item = i[0:i1]
-                                probability = float(i[i1 + 1:i2])
-                                product = _Item(item, probability)
-                                tr.append(product)
-                            self._Database.append(tr)
+                            i = [i.rstrip() for i in line.split(self._sep)]
+                            i = [x for x in i if x]
+                            self._lno += 1
+                            for j in i:
+                                if j not in self._mapSupport:
+                                    self._mapSupport[j] = 1
+                                    self._tidList[j] = [self._lno]
+                                else:
+                                    self._mapSupport[j] += 1
+                                    self._tidList[j].append(self._lno)
                 except IOError:
                     print("File Not Found")
+        self._minSup = self._convert(self._minSup)
+        self._mapSupport = {k: v for k, v in self._mapSupport.items() if v >= self._minSup}
+        _flist = {}
+        self._tidList = {k: v for k, v in self._tidList.items() if k in self._mapSupport}
+        for x, y in self._tidList.items():
+            t1 = 0
+            for i in y:
+                t1 += i
+            _flist[x] = t1
+        _flist = [key for key, value in sorted(_flist.items(), key=lambda x: x[1])]
+        return _flist
 
-    def _frequentOneItem(self):
-        """takes the self.Database and calculates the support of each item in the dataset and assign the
-            ranks to the items by decreasing support and returns the frequent items list
-
-                :param self.Database : it represents the one self.Database in database
-
-                :type self.Database : list
-        """
-
-        mapSupport = {}
-        k = 0
-        for i in self._Database:
-            k += 1
-            for j in i:
-                if j.item not in mapSupport:
-                    mapSupport[j.item] = j.probability
-                    self._cupList[j.item] = {k:j.probability}
-                else:
-                    mapSupport[j.item] += j.probability
-                    self._cupList[j.item].update({k: j.probability})
-        plist = [k for k,v in sorted(mapSupport.items(), key=lambda x: x[1], reverse=True)]
-        k = 0
-        for x, in plist:
-            k +=1
-            if k >= self._minSup:
-                break
-            self._finalPatterns[x] = mapSupport[x]
-        self._minimum = min(list(self._finalPatterns.values()))
-        return plist
+    def _calculate(self, tidSet):
+        """To calculate the hashcode of pattern
 
-    @staticmethod
-    def _convert(value):
-        """
-        To convert the type of user specified minSup value
+            :param tidSet: the timestamps of a pattern
 
-            :param value: user specified minSup value
+            :type tidSet: list
 
-            :return: converted type minSup value
+            :rtype: int
         """
-        if type(value) is int:
-            value = int(value)
-        if type(value) is float:
-            value = float(value)
-        if type(value) is str:
-            if '.' in value:
-                value = float(value)
-            else:
-                value = int(value)
-        return value
 
-    def _save(self, prefix, suffix, tidSetI):
-        """Saves the patterns that satisfy the periodic frequent property.
+        hashcode = 0
+        for i in tidSet:
+            hashcode += i
+        if hashcode < 0:
+            hashcode = abs(0 - hashcode)
+        return hashcode % self._tableSize
+
+    def _contains(self, itemSet, value, hashcode):
+        """ Check for the closed property(patterns with same support) by checking the hashcode(sum of timestamps),
+            if hashcode key in hashing dict is none then returns a false, else returns with true.
+
+            :param itemSet: frequent pattern
+
+            :type itemSet: list
+
+            :param value: support of the pattern
+
+            :type value: int
+
+            :param hashcode: calculated from the timestamps of pattern
+
+            :type hashcode: int
+            """
+        if self._hashing.get(hashcode) is None:
+            return False
+        for i in self._hashing[hashcode]:
+            itemSetx = i
+            if value == self._hashing[hashcode][itemSetx] and set(itemSetx).issuperset(itemSet):
+                return True
+        return False
+
+    def _save(self, prefix, suffix, tidSetx):
+        """ Check for the closed property (patterns with same support), if found deletes the subsets and stores
+            supersets and also saves the patterns that satisfy the closed property
 
             :param prefix: the prefix of a pattern
-            :type prefix: list
+
             :param suffix: the suffix of a patterns
+
             :type suffix: list
-            :param tidSetI: the timestamp of a patterns
-            :type tidSetI: dict
-        """
 
+            :param tidSetx: the timestamp of a patterns
+
+            :type tidSetx: list
+        """
         if prefix is None:
             prefix = suffix
         else:
             prefix = prefix + suffix
-        val = sum(tidSetI.values())
-        #print(prefix, val)
-        if len(self._finalPatterns) <= self._minSup:
-            sample = str()
-            for i in prefix:
-                sample = sample + i + " "
-            self._finalPatterns[sample] = val
-        if len(self._finalPatterns) == self._minSup:
-            if val > self._minimum:
+        prefix = list(set(prefix))
+        prefix.sort()
+        val = len(tidSetx)
+        if val >= self._minSup:
+            hashcode = self._calculate(tidSetx)
+            if self._contains(prefix, val, hashcode) is False:
                 sample = str()
                 for i in prefix:
-                    sample = sample + i + " "
-                index = list(self._finalPatterns.keys())[list(self._finalPatterns.values()).index(self._minimum)]
-                del self._finalPatterns[index]
+                    sample = sample + i + "\t"
+                self._itemSetCount += 1
                 self._finalPatterns[sample] = val
-                self._minimum = min(list(self._finalPatterns.values()))
-        #print(self.finalPatterns, self.minimum, self.minSup)
-
+            if hashcode not in self._hashing:
+                self._hashing[hashcode] = {tuple(prefix): val}
+            else:
+                self._hashing[hashcode][tuple(prefix)] = val
 
-    def _Generation(self, prefix, itemSets, tidSets):
-        """Equivalence class is followed  and checks for the patterns generated for periodic-frequent patterns.
+    def _processEquivalenceClass(self, prefix, itemSets, tidSets):
+        """ Equivalence class is followed  and check for the patterns which satisfies frequent properties.
 
             :param prefix:  main equivalence prefix
-            :type prefix: periodic-frequent item or pattern
-            :param itemSets: patterns which are items combined with prefix and satisfying the periodicity
-                            and frequent with their timestamps
+
+            :type prefix: frequent item or pattern
+
+            :param itemSets: patterns which are items combined with prefix and satisfying the minSup
+
             :type itemSets: list
+
             :param tidSets: timestamps of the items in the argument itemSets
+
             :type tidSets: list
 
 
-                    """
+        """
         if len(itemSets) == 1:
             i = itemSets[0]
             tidI = tidSets[0]
             self._save(prefix, [i], tidI)
             return
-        for i in range(0, len(itemSets)):
-            itemI = itemSets[i]
-            if itemI is None:
+        if len(itemSets) == 2:
+            itemX = itemSets[0]
+            tidSetX = tidSets[0]
+            itemY = itemSets[1]
+            tidSetY = tidSets[1]
+            y1 = list(set(tidSetX).intersection(tidSetY))
+            if len(y1) >= self._minSup:
+                suffix = []
+                suffix += [itemX, itemY]
+                suffix = list(set(suffix))
+                self._save(prefix, suffix, y1)
+            if len(y1) != len(tidSetX):
+                self._save(prefix, [itemX], tidSetX)
+            if len(y1) != len(tidSetY):
+                self._save(prefix, [itemX], tidSetY)
+            return
+        for i in range(len(itemSets)):
+            itemX = itemSets[i]
+            if itemX is None:
                 continue
-            tidSetI = tidSets[i]
+            tidSetX = tidSets[i]
             classItemSets = []
             classTidSets = []
-            itemSetX = [itemI]
-            for j in range(i+1, len(itemSets)):
-                itemJ = itemSets[j]
-                tidSetJ = tidSets[j]
-                y = {key: tidSetJ[key] * tidSetI.get(key, 0) for key in tidSetJ.keys()}
-                sum2 = sum(list(y.values()))
-                #print(prefix, itemJ, y, sum2)
-                #if sum2 >= self.minimum:
-                self._save(prefix, [itemJ], y)
-                classItemSets.append(itemJ)
-                classTidSets.append(y)
-            #print(itemI, tidSetI, classItemSets)
-            newPrefix = list(set(itemSetX)) + prefix
-            self._Generation(newPrefix, classItemSets, classTidSets)
-            #self.save(prefix, list(set(itemSetX)), tidSetI)
+            itemSetx = [itemX]
+            for j in range(i + 1, len(itemSets)):
+                itemY = itemSets[j]
+                if itemY is None:
+                    continue
+                tidSetY = tidSets[j]
+                y = list(set(tidSetX).intersection(tidSetY))
+                if len(y) < self._minSup:
+                    continue
+                if len(tidSetX) == len(tidSetY) and len(y) == len(tidSetX):
+                    itemSets.insert(j, None)
+                    tidSets.insert(j, None)
+                    itemSetx.append(itemY)
+                elif len(tidSetX) < len(tidSetY) and len(y) == len(tidSetX):
+                    itemSetx.append(itemY)
+                elif len(tidSetX) > len(tidSetY) and len(y) == len(tidSetY):
+                    itemSets.insert(j, None)
+                    tidSets.insert(j, None)
+                    classItemSets.append(itemY)
+                    classTidSets.append(y)
+                else:
+                    classItemSets.append(itemY)
+                    classTidSets.append(y)
+            if len(classItemSets) > 0:
+                newPrefix = list(set(itemSetx)) + prefix
+                self._processEquivalenceClass(newPrefix, classItemSets, classTidSets)
+                self._save(prefix, list(set(itemSetx)), tidSetX)
 
     def startMine(self):
-        """Main method where the patterns are mined by constructing tree and remove the remove the false patterns
-            by counting the original support of a patterns
-
-
         """
-        global _minSup
+        Mining process will start from here by extracting the frequent patterns from the database. It performs prefix
+        equivalence to generate the combinations and closed frequent patterns.
+        """
         self._startTime = _ab._time.time()
-        self._creatingItemSets()
-        self._minSup = self._convert(self._minSup)
-        _minSup = self._minSup
-        plist = self._frequentOneItem()
-        for i in range(len(plist)):
-            itemI = plist[i]
-            tidSetI = self._cupList[itemI]
-            itemSetX = [itemI]
+        _plist = self._creatingItemsets()
+        self._finalPatterns = {}
+        self._hashing = {}
+        for i in range(len(_plist)):
+            itemX = _plist[i]
+            if itemX is None:
+                continue
+            tidSetx = self._tidList[itemX]
+            itemSetx = [itemX]
             itemSets = []
             tidSets = []
-            for j in range(i+1, len(plist)):
-                itemJ = plist[j]
-                tidSetJ = self._cupList[itemJ]
-                y1 = {key: tidSetJ[key] * tidSetI.get(key, 0)  for key in tidSetJ.keys()}
-                self._save(itemSetX, [itemJ], y1)
-                itemSets.append(itemJ)
-                tidSets.append(y1)
-            self._Generation(itemSetX, itemSets, tidSets)
-        print("Top-K Frequent patterns were generated from uncertain databases successfully using TUFP algorithm")
+            for j in range(i + 1, len(_plist)):
+                itemY = _plist[j]
+                if itemY is None:
+                    continue
+                tidSetY = self._tidList[itemY]
+                y1 = list(set(tidSetx).intersection(tidSetY))
+                if len(y1) < self._minSup:
+                    continue
+                if len(tidSetx) == len(tidSetY) and len(y1) == len(tidSetx):
+                    _plist.insert(j, None)
+                    itemSetx.append(itemY)
+                elif len(tidSetx) < len(tidSetY) and len(y1) == len(tidSetx):
+                    itemSetx.append(itemY)
+                elif len(tidSetx) > len(tidSetY) and len(y1) == len(tidSetY):
+                    _plist.insert(j, None)
+                    itemSets.append(itemY)
+                    tidSets.append(y1)
+                else:
+                    itemSets.append(itemY)
+                    tidSets.append(y1)
+            if len(itemSets) > 0:
+                self._processEquivalenceClass(itemSetx, itemSets, tidSets)
+            self._save(None, itemSetx, tidSetx)
+        print("Closed Frequent patterns were generated successfully using CHARM algorithm")
         self._endTime = _ab._time.time()
-        process = _ab._psutil.Process(_ab._os.getpid())
+        _process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryUSS = float()
         self._memoryRSS = float()
-        self._memoryUSS = process.memory_full_info().uss
-        self._memoryRSS = process.memory_info().rss
+        self._memoryUSS = _process.memory_full_info().uss
+        self._memoryRSS = _process.memory_info().rss
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
         :return: returning USS memory consumed by the mining process
 
         :rtype: float
@@ -406,15 +478,14 @@
         """
 
         return self._memoryRSS
 
     def getRuntime(self):
         """Calculating the total amount of runtime taken by the mining process
 
-
         :return: returning total amount of runtime taken by the mining process
 
         :rtype: float
         """
 
         return self._endTime - self._startTime
 
@@ -425,64 +496,57 @@
 
         :rtype: pd.DataFrame
         """
 
         dataframe = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a, b])
+            data.append([a.replace('\t', ' '), b])
             dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
         return dataframe
 
     def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
 
         :type outFile: file
         """
-        self.oFile = outFile
-        writer = open(self.oFile, 'w+')
+        self._oFile = outFile
+        writer = open(self._oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            s1 = x + ":" + str(y)
+            s1 = x.strip() + ":" + str(y)
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
 
         :rtype: dict
         """
+
         return self._finalPatterns
 
+    def printResults(self):
+        print("Total number of Closed Frequent Patterns:", len(self.getPatterns()))
+        print("Total Memory in USS:", self.getMemoryUSS())
+        print("Total Memory in RSS", self.getMemoryRSS())
+        print("Total ExecutionTime in ms:",  self.getRuntime())
+
 
 if __name__ == "__main__":
     _ap = str()
     if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:
         if len(_ab._sys.argv) == 5:
-            _ap = TUFP(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+            _ap = CHARM(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
         if len(_ab._sys.argv) == 4:
-            _ap = TUFP(_ab._sys.argv[1], _ab._sys.argv[3])
+            _ap = CHARM(_ab._sys.argv[1], _ab._sys.argv[3])
         _ap.startMine()
-        _Patterns = _ap.getPatterns()
-        print("Total number of Patterns:", len(_Patterns))
+        print("Total number of Closed Frequent Patterns:", len(_ap.getPatterns()))
         _ap.save(_ab._sys.argv[2])
-        _memUSS = _ap.getMemoryUSS()
-        print("Total Memory in USS:", _memUSS)
+        print("Total Memory in USS:", _ap.getMemoryUSS())
         _memRSS = _ap.getMemoryRSS()
-        print("Total Memory in RSS", _memRSS)
-        _run = _ap.getRuntime()
-        print("Total ExecutionTime in ms:", _run)
+        print("Total Memory in RSS", _ap.getMemoryRSS())
+        print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
-        '''ap = TUFP("/home/apiiit-rkv/Desktop/uncertain/tubeSample", 10, ' ')
-        ap.startMine()
-        Patterns = ap.getPatterns()
-        print("Total number of Patterns:", len(Patterns))
-        ap.save("patterns.txt")
-        memUSS = ap.getMemoryUSS()
-        print("Total Memory in USS:", memUSS)
-        memRSS = ap.getMemoryRSS()
-        print("Total Memory in RSS", memRSS)
-        run = ap.getRuntime()
-        print("Total ExecutionTime in ms:", run)'''
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/TubeP.py` & `pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/TubeS.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,82 +1,138 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation,  either version 3 of the License,  or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not,  see <https://www.gnu.org/licenses/>.
+#     from PAMI.uncertainFrequentPattern.basic import TubeS as alg
+#
+#     obj = alg.TubeS(iFile, minSup)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getmemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+#
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 from PAMI.uncertainFrequentPattern.basic import abstract as _fp
 
 _minSup = float()
 _fp._sys.setrecursionlimit(20000)
 _finalPatterns = {}
 
 
 class _Item:
     """
     A class used to represent the item with probability in transaction of dataset
     ...
-        Attributes:
-        __________
-            item : int or word
-                Represents the name of the item
-            probability : float
-                Represent the existential probability(likelihood presence) of an item
+    Attributes
+    __________
+        item : int or word
+            Represents the name of the item
+        probability : float
+            Represent the existential probability(likelihood presence) of an item
     """
 
     def __init__(self, item, probability):
         self.item = item
         self.probability = probability
 
 
 class _Node(object):
     """
-        A class used to represent the node of frequentPatternTree
-        ...
-        Attributes:
-        ----------
-            item : int
-                storing item of a node
-            probability : int
-                To maintain the expected support of node
-            parent : node
-                To maintain the parent of every node
-            children : list
-                To maintain the children of node
-        Methods:
-        -------
-            addChild(itemName)
-                storing the children to their respective parent nodes
-    """
+            A class used to represent the node of frequentPatternTree
+            ...
+            Attributes:
+            ----------
+                item : int
+                    storing item of a node
+                probability : int
+                    To maintain the expected support of node
+                parent : node
+                    To maintain the parent of every node
+                children : list
+                    To maintain the children of node
+            Methods:
+            -------
+                addChild(itemName)
+                    storing the children to their respective parent nodes
+            """
 
     def __init__(self, item, children):
         self.item = item
         self.probability = 1
-        self.maxPrefixProbability = 1
-        self.p = 1
+        self.secondProbability = 1
         self.children = children
         self.parent = None
 
     def addChild(self, node):
         self.children[node.item] = node
         node.parent = self
 
 
+def Second(transaction, i):
+    """
+    To calculate the second probability of a node in transaction
+        :param transaction: transaction in a database
+        :param i: index of item in transaction
+        :return: second probability of a node
+    """
+    temp = []
+    for j in range(0, i):
+        temp.append(transaction[j].probability)
+    l1 = max(temp)
+    temp.remove(l1)
+    l2 = max(temp)
+    return l2 * l2
+
+
 def printTree(root):
+    """
+    To print the tree with root node through recursion
+        :param root: root node of  tree
+        :return: details of tree
+    """
     for x, y in root.children.items():
-        print(x, y.item, y.probability, y.parent.item, y.tids, y.maxPrefixProbability)
+        print(x, y.item, y.probability, y.parent.item, y.tids, y.secondProbability)
         printTree(y)
 
 
 class _Tree(object):
     """
     A class used to represent the frequentPatternGrowth tree structure
     ...
@@ -93,40 +149,41 @@
         addTransaction(transaction)
             creating transaction as a branch in frequentPatternTree
         addConditionalTransaction(prefixPaths, supportOfItems)
             construct the conditional tree for prefix paths
         conditionalPatterns(Node)
             generates the conditional patterns from tree for specific node
         conditionalTransactions(prefixPaths,Support)
-                takes the prefixPath of a node and support at child of the path and extract the frequent items from
-                prefixPaths and generates prefixPaths with items which are frequent
-        remove(Node)
-                removes the node from tree once after generating all the patterns respective to the node
-        generatePatterns(Node)
+            takes the prefixPath of a node and support at child of the path and extract the frequent items from
+            prefixPaths and generates prefixPaths with items which are frequent
+        removeNode(Node)
+            removes the node from tree once after generating all the patterns respective to the node
+        generate_patterns(Node)
             starts from the root node of the tree and mines the frequent patterns
-    """
+            """
 
     def __init__(self):
         self.root = _Node(None, {})
         self.summaries = {}
         self.info = {}
 
     def addTransaction(self, transaction):
         """adding transaction into tree
-                :param transaction : it represents the one transactions in database
-                :type transaction : list
-                        """
+            :param transaction : it represents the one transactions in database
+            :type transaction : list
+        """
         currentNode = self.root
         k = 0
         for i in range(len(transaction)):
             k += 1
             if transaction[i].item not in currentNode.children:
                 newNode = _Node(transaction[i].item, {})
                 newNode.k = k
-                newNode.prefixProbability = transaction[i].probability
+                if k >= 3:
+                    newNode.secondProbability = Second(transaction, i)
                 l1 = i - 1
                 temp = []
                 while l1 >= 0:
                     temp.append(transaction[l1].probability)
                     l1 -= 1
                 if len(temp) == 0:
                     newNode.probability = round(transaction[i].probability, 2)
@@ -136,86 +193,87 @@
                 if transaction[i].item in self.summaries:
                     self.summaries[transaction[i].item].append(newNode)
                 else:
                     self.summaries[transaction[i].item] = [newNode]
                 currentNode = newNode
             else:
                 currentNode = currentNode.children[transaction[i].item]
-                currentNode.prefixProbability = max(transaction[i].probability, currentNode.prefixProbability)
+                if k >= 3:
+                    currentNode.secondProbability = max(transaction[i].probability, currentNode.secondProbability)
                 currentNode.k = k
                 l1 = i - 1
                 temp = []
                 while l1 >= 0:
                     temp.append(transaction[l1].probability)
                     l1 -= 1
                 if len(temp) == 0:
                     currentNode.probability += round(transaction[i].probability, 2)
                 else:
                     nn = max(temp) * transaction[i].probability
                     currentNode.probability += round(nn, 2)
 
     def addConditionalTransaction(self, transaction, sup, second):
         """constructing conditional tree from prefixPaths
-            :param transaction: it represents the one transactions in database
-            :type transaction: list
-            :param sup: support of prefixPath taken at last child of the path
-            :type sup: int
-            :param second: the second probability of the node
+            :param transaction : it represents the one transactions in database
+            :type transaction : list
+            :param sup : support of prefixPath taken at last child of the path
+            :type sup : int
+            :param second: second probability of the leaf node
             :type second: float
         """
         currentNode = self.root
         k = 0
         for i in range(len(transaction)):
             k += 1
             if transaction[i] not in currentNode.children:
                 newNode = _Node(transaction[i], {})
                 newNode.k = k
-                newNode.prefixProbability = second
+                newNode.secondProbability = second
                 newNode.probability = sup
                 currentNode.addChild(newNode)
                 if transaction[i] in self.summaries:
                     self.summaries[transaction[i]].append(newNode)
                 else:
                     self.summaries[transaction[i]] = [newNode]
                 currentNode = newNode
             else:
                 currentNode = currentNode.children[transaction[i]]
                 currentNode.k = k
-                currentNode.prefixProbability = max(currentNode.prefixProbability, second)
+                currentNode.secondProbability = max(currentNode.secondProbability, second)
                 currentNode.probability += sup
 
     def conditionalPatterns(self, alpha):
         """generates all the conditional patterns of respective node
             :param alpha : it represents the Node in tree
             :type alpha : _Node
         """
         finalPatterns = []
         sup = []
         second = []
         for i in self.summaries[alpha]:
             s = i.probability
-            s1 = i.maxPrefixProbability
+            s1 = i.secondProbability
             set2 = []
             while i.parent.item is not None:
                 set2.append(i.parent.item)
                 i = i.parent
             if len(set2) > 0:
                 set2.reverse()
                 finalPatterns.append(set2)
                 second.append(s1)
                 sup.append(s)
         finalPatterns, support, info = self.conditionalTransactions(finalPatterns, sup)
         return finalPatterns, support, info, second
 
     def conditionalTransactions(self, condPatterns, support):
         """ It generates the conditional patterns with frequent items
-            :param condPatterns: condPatterns generated from condition pattern method for respective node
-            :type condPatterns: list
-            :param support: the support of conditional pattern in tree
-            :type support: list
+            :param condPatterns : conditional patterns generated from conditionalPatterns() method for respective node
+            :type condPatterns : list
+            :param support : the support of conditional pattern in tree
+            :type support : list
         """
         global _minSup
         pat = []
         sup = []
         data1 = {}
         for i in range(len(condPatterns)):
             for j in condPatterns[i]:
@@ -253,15 +311,15 @@
             pattern = prefix[:]
             pattern.append(i)
             s = 0
             for x in self.summaries[i]:
                 #if x.k <= 2:
                     #s += x.probability
                 #elif x.k >= 3:
-                    #n = x.probability * pow(x.prefixProbability, (x.k - 2))
+                    #n = x.probability * pow(x.secondProbability, (x.k - 2))
                     #s += n
                 if len(pattern) <= 2:
                     s += x.probability
                 elif len(pattern) >= 3:
                     n = x.probability * pow(x.secondProbability, (x.k - 2))
                     s += n
             _finalPatterns[tuple(pattern)] = self.info[i]
@@ -272,23 +330,26 @@
                 for pat in range(len(patterns)):
                     conditionalTree.addConditionalTransaction(patterns[pat], support[pat], second[pat])
                 if len(patterns) > 0:
                     conditionalTree.generatePatterns(pattern)
             self.removeNode(i)
 
 
-class TubeP(_fp._frequentPatterns):
+class TubeS(_fp._frequentPatterns):
     """
-    TubeP is one of the fastest algorithm to discover frequent patterns in a uncertain transactional database.
+    Description:
+    -------------
+    TubeS is one of the fastest algorithm to discover frequent patterns in a uncertain transactional database.
+
     Reference:
-    --------
+    ----------
         Carson Kai-Sang Leung and Richard Kyle MacKinnon. 2014. Fast Algorithms for Frequent Itemset Mining from Uncertain Data.
         In Proceedings of the 2014 IEEE International Conference on Data Mining (ICDM '14). IEEE Computer Society, USA, 893898. https://doi.org/10.1109/ICDM.2014.146
     Attributes:
-    ----------
+    -----------
         iFile : file
             Name of the Input file or path of the input file
         oFile : file
             Name of the output file or path of the output file
         minSup: float or int or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
@@ -314,15 +375,15 @@
         tree : class
             To represents the Tree class
         itemSetCount : int
             To represents the total no of patterns
         finalPatterns : dict
             To store the complete patterns
     Methods:
-    -------
+    ---------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -339,76 +400,75 @@
             Extracts the one-length frequent patterns from database
         updateTransactions()
             Update the transactions by removing non-frequent items and sort the Database by item decreased support
         buildTree()
             After updating the Database, remaining items will be added into the tree by setting root node as null
         convert()
             to convert the user specified value
-    Executing the code on terminal:
-    -------
-        Format:
-        ------
 
-        python3 TubeP.py <inputFile> <outputFile> <minSup>
+    **Methods to execute code on terminal**
 
-        Examples:
-        --------
+            Format:
+                      >>> python3 TubeS.py <inputFile> <outputFile> <minSup>
+            Example:
+                      >>>  python3 TubeS.py sampleTDB.txt patterns.txt 3
 
-        python3 TubeP.py sampleTDB.txt patterns.txt 3    (minSup  will be considered in support count or frequency)
+            .. note:: minSup  will be considered in support count or frequency
 
-    Sample run of importing the code:
-    -------------------
-        from PAMI.uncertainFrequentPattern.basic import tubeP as alg
+    **Importing this algorithm into a python program**
 
-        obj = alg.TubeP(iFile, minSup)
+    .. code-block:: python
 
-        obj.startMine()
+            from PAMI.uncertainFrequentPattern.basic import TubeS as alg
 
-        Patterns = obj.getPatterns()
+            obj = alg.TubeS(iFile, minSup)
 
-        print("Total number of  Patterns:", len(Patterns))
+            obj.startMine()
 
-        obj.save(oFile)
+            frequentPatterns = obj.getPatterns()
 
-        Df = obj.getPatternsAsDataFrame()
+            print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-        memUSS = obj.getMemoryUSS()
+            obj.savePatterns(oFile)
 
-        print("Total Memory in USS:", memUSS)
+            Df = obj.getPatternsAsDataFrame()
 
-        memRSS = obj.getMemoryRSS()
+            memUSS = obj.getmemoryUSS()
 
-        print("Total Memory in RSS", memRSS)
+            print("Total Memory in USS:", memUSS)
 
-        run = obj.getRuntime()
+            memRSS = obj.getMemoryRSS()
 
-        print("Total ExecutionTime in seconds:", run)
+            print("Total Memory in RSS", memRSS)
 
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
-    """
+            run = obj.getRuntime()
+
+            print("Total ExecutionTime in seconds:", run)
+
+    **Credits:**
+
+             The complete program was written by  P.Likhitha   under the supervision of Professor Rage Uday Kiran.
+"""
     _startTime = float()
     _endTime = float()
-    _minSup = str()
+    _minSup = float()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
     _rank = {}
-
+    _lno = 0
     def __init__(self, iFile, minSup, sep='\t'):
         super().__init__(iFile, minSup, sep)
-
     def _creatingItemSets(self):
         """
-        Scans the dataset and stores the transactions into Database variable
+        Scans the databases and stores the transactions into Database variable
         """
         self._Database = []
         if isinstance(self._iFile, _fp._pd.DataFrame):
             uncertain, data = [], []
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
@@ -418,14 +478,15 @@
                 uncertain = self._iFile['uncertain'].tolist()
             for k in range(len(data)):
                 tr = []
                 for j in range(len(data[k])):
                     product = _Item(data[k][j], uncertain[k][j])
                     tr.append(product)
                 self._Database.append(tr)
+                self._lno += 1
 
             # print(self.Database)
         if isinstance(self._iFile, str):
             if _fp._validators.url(self._iFile):
                 data = _fp._urlopen(self._iFile)
                 for line in data:
                     line = line.strip()
@@ -435,14 +496,15 @@
                     uncertain = [float(i.rstrip()) for i in temp[1].split(self._sep)]
                     tr = []
                     for i in range(len(temp)):
                         item = temp[i]
                         probability = uncertain[i]
                         product = _Item(item, probability)
                         tr.append(product)
+                    self._lno += 1
                     self._Database.append(temp)
             else:
                 try:
                     with open(self._iFile, 'r') as f:
                         for line in f:
                             temp1 = line.strip()
                             temp1 = temp1.split(':')
@@ -450,14 +512,15 @@
                             uncertain = [float(i.rstrip()) for i in temp1[1].split(self._sep)]
                             tr = []
                             for i in range(len(temp)):
                                 item = temp[i]
                                 probability = uncertain[i]
                                 product = _Item(item, probability)
                                 tr.append(product)
+                            self._lno += 1
                             self._Database.append(tr)
                 except IOError:
                     print("File Not Found")
 
     def _frequentOneItem(self):
         """takes the transactions and calculates the support of each item in the dataset and assign the
                     ranks to the items by decreasing support and returns the frequent items list
@@ -485,26 +548,26 @@
         """
         rootNode = _Tree()
         rootNode.info = info.copy()
         for i in range(len(data)):
             rootNode.addTransaction(data[i])
         return rootNode
 
-    def _updateTransactions(self, dict1):
+    def updateTransactions(self, dict1):
         """remove the items which are not frequent from transactions and updates the transactions with rank of items
-            :param dict1 : frequent items with support
-            :type dict1 : dictionary
+                :param dict1 : frequent items with support
+                :type dict1 : dictionary
         """
         list1 = []
         for tr in self._Database:
             list2 = []
             for i in range(0, len(tr)):
                 if tr[i].item in dict1:
                     list2.append(tr[i])
-            if len(list2) >= 2:
+            if (len(list2) >= 2):
                 basket = list2
                 basket.sort(key=lambda val: self._rank[val.item])
                 list2 = basket
                 list1.append(list2)
         return list1
 
     def _Check(self, i, x):
@@ -538,16 +601,16 @@
                 value = (len(self._Database) * value)
             else:
                 value = int(value)
         return value
 
     def _removeFalsePositives(self):
         """
-               To remove the false positive patterns generated in frequent patterns
-               :return: patterns with accurate probability
+        To remove the false positive patterns generated in frequent patterns
+        :return: patterns with accurate probability
         """
         global _finalPatterns
         periods = {}
         for i in self._Database:
             for x, y in _finalPatterns.items():
                 if len(x) == 1:
                     periods[x] = y
@@ -576,24 +639,24 @@
         global _minSup
         self._startTime = _fp._time.time()
         self._creatingItemSets()
         self._minSup = self._convert(self._minSup)
         _minSup = self._minSup
         self._finalPatterns = {}
         mapSupport, plist = self._frequentOneItem()
-        transactions1 = self._updateTransactions(mapSupport)
+        transactions1 = self.updateTransactions(mapSupport)
         info = {k: v for k, v in mapSupport.items()}
         Tree1 = self._buildTree(transactions1, info)
         Tree1.generatePatterns([])
         self._removeFalsePositives()
-        print("Uncertain Frequent patterns were generated successfully using TubeP algorithm")
+        print("Uncertain Frequent patterns were generated successfully using TubeS algorithm")
         self._endTime = _fp._time.time()
         process = _fp._psutil.Process(_fp._os.getpid())
-        self._memoryRSS = float()
         self._memoryUSS = float()
+        self._memoryRSS = float()
         self._memoryUSS = process.memory_full_info().uss
         self._memoryRSS = process.memory_info().rss
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
         :return: returning USS memory consumed by the mining process
         :rtype: float
@@ -655,18 +718,18 @@
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
     if len(_fp._sys.argv) == 4 or len(_fp._sys.argv) == 5:
         if len(_fp._sys.argv) == 5:
-            _ap = TubeP(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4])
+            _ap = TubeS(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4])
         if len(_fp._sys.argv) == 4:
-            _ap = TubeP(_fp._sys.argv[1], _fp._sys.argv[3])
+            _ap = TubeS(_fp._sys.argv[1], _fp._sys.argv[3])
         _ap.startMine()
-        print("Total number of  Uncertain Frequent Patterns:", len(_ap.getPatterns()))
+        print("Total number of Uncertain Frequent Patterns:", len(_ap.getPatterns()))
         _ap.save(_fp._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/TubeS.py` & `pami-2023.5.1/PAMI/weightedFrequentPattern/basic/WFIM.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,698 +1,643 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation,  either version 3 of the License,  or
-#      (at your option) any later version.
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     from PAMI.weightFrequentPattern.basic import WFIM as alg
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not,  see <https://www.gnu.org/licenses/>.
-
+#     obj = alg.WFIM(iFile, wFile, minSup, minWeight)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getmemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
 
-from PAMI.uncertainFrequentPattern.basic import abstract as _fp
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
 
-_minSup = float()
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+from PAMI.weightedFrequentPattern.basic import abstract as _fp
+
+_minSup = str()
+_minWeight = int()
+_miniWeight = int()
+_maxWeight = int()
+_weights = {}
 _fp._sys.setrecursionlimit(20000)
-_finalPatterns = {}
 
 
-class _Item:
-    """
-    A class used to represent the item with probability in transaction of dataset
-    ...
-    Attributes
-    __________
-        item : int or word
-            Represents the name of the item
-        probability : float
-            Represent the existential probability(likelihood presence) of an item
+class _Node:
     """
-
-    def __init__(self, item, probability):
-        self.item = item
-        self.probability = probability
-
-
-class _Node(object):
+        A class used to represent the node of frequentPatternTree
+    Attributes:
+    ----------
+        itemId: int
+            storing item of a node
+        counter: int
+            To maintain the support of node
+        parent: node
+            To maintain the parent of node
+        children: list
+            To maintain the children of node
+    Methods:
+    -------
+        addChild(node)
+            Updates the nodes children list and parent for the given node
     """
-            A class used to represent the node of frequentPatternTree
-            ...
-            Attributes:
-            ----------
-                item : int
-                    storing item of a node
-                probability : int
-                    To maintain the expected support of node
-                parent : node
-                    To maintain the parent of every node
-                children : list
-                    To maintain the children of node
-            Methods:
-            -------
-                addChild(itemName)
-                    storing the children to their respective parent nodes
-            """
 
     def __init__(self, item, children):
-        self.item = item
-        self.probability = 1
-        self.secondProbability = 1
-        self.children = children
+        self.itemId = item
+        self.counter = 1
         self.parent = None
+        self.children = children
 
     def addChild(self, node):
-        self.children[node.item] = node
+        """
+            Retrieving the child from the tree
+            :param node: Children node
+            :type node: Node
+            :return: Updates the children nodes and parent nodes
+        """
+        self.children[node.itemId] = node
         node.parent = self
 
 
-def Second(transaction, i):
-    """
-    To calculate the second probability of a node in transaction
-        :param transaction: transaction in a database
-        :param i: index of item in transaction
-        :return: second probability of a node
-    """
-    temp = []
-    for j in range(0, i):
-        temp.append(transaction[j].probability)
-    l1 = max(temp)
-    temp.remove(l1)
-    l2 = max(temp)
-    return l2 * l2
-
-
-def printTree(root):
-    """
-    To print the tree with root node through recursion
-        :param root: root node of  tree
-        :return: details of tree
-    """
-    for x, y in root.children.items():
-        print(x, y.item, y.probability, y.parent.item, y.tids, y.secondProbability)
-        printTree(y)
-
-
-class _Tree(object):
+class _Tree:
     """
     A class used to represent the frequentPatternGrowth tree structure
-    ...
     Attributes:
     ----------
         root : Node
-            Represents the root node of the tree
+            The first node of the tree set to Null.
         summaries : dictionary
-            storing the nodes with same item name
+            Stores the nodes itemId which shares same itemId
         info : dictionary
-            stores the support of items
+            frequency of items in the transactions
     Methods:
     -------
-        addTransaction(transaction)
-            creating transaction as a branch in frequentPatternTree
-        addConditionalTransaction(prefixPaths, supportOfItems)
-            construct the conditional tree for prefix paths
-        conditionalPatterns(Node)
-            generates the conditional patterns from tree for specific node
-        conditionalTransactions(prefixPaths,Support)
-            takes the prefixPath of a node and support at child of the path and extract the frequent items from
-            prefixPaths and generates prefixPaths with items which are frequent
-        removeNode(Node)
-            removes the node from tree once after generating all the patterns respective to the node
-        generate_patterns(Node)
-            starts from the root node of the tree and mines the frequent patterns
-            """
+        addTransaction(transaction, freq)
+            adding items of  transactions into the tree as nodes and freq is the count of nodes
+        getFinalConditionalPatterns(node)
+            getting the conditional patterns from fp-tree for a node
+        getConditionalPatterns(patterns, frequencies)
+            sort the patterns by removing the items with lower minSup
+        generatePatterns(prefix)
+            generating the patterns from fp-tree
+    """
 
     def __init__(self):
         self.root = _Node(None, {})
         self.summaries = {}
         self.info = {}
 
-    def addTransaction(self, transaction):
+    def addTransaction(self, transaction, count):
         """adding transaction into tree
-            :param transaction : it represents the one transactions in database
-            :type transaction : list
+        :param transaction: it represents the one transactions in database
+        :type transaction: list
+        :param count: frequency of item
+        :type count: int
         """
-        currentNode = self.root
-        k = 0
-        for i in range(len(transaction)):
-            k += 1
-            if transaction[i].item not in currentNode.children:
-                newNode = _Node(transaction[i].item, {})
-                newNode.k = k
-                if k >= 3:
-                    newNode.secondProbability = Second(transaction, i)
-                l1 = i - 1
-                temp = []
-                while l1 >= 0:
-                    temp.append(transaction[l1].probability)
-                    l1 -= 1
-                if len(temp) == 0:
-                    newNode.probability = round(transaction[i].probability, 2)
-                else:
-                    newNode.probability = round(max(temp) * transaction[i].probability, 2)
-                currentNode.addChild(newNode)
-                if transaction[i].item in self.summaries:
-                    self.summaries[transaction[i].item].append(newNode)
-                else:
-                    self.summaries[transaction[i].item] = [newNode]
-                currentNode = newNode
-            else:
-                currentNode = currentNode.children[transaction[i].item]
-                if k >= 3:
-                    currentNode.secondProbability = max(transaction[i].probability, currentNode.secondProbability)
-                currentNode.k = k
-                l1 = i - 1
-                temp = []
-                while l1 >= 0:
-                    temp.append(transaction[l1].probability)
-                    l1 -= 1
-                if len(temp) == 0:
-                    currentNode.probability += round(transaction[i].probability, 2)
-                else:
-                    nn = max(temp) * transaction[i].probability
-                    currentNode.probability += round(nn, 2)
 
-    def addConditionalTransaction(self, transaction, sup, second):
-        """constructing conditional tree from prefixPaths
-            :param transaction : it represents the one transactions in database
-            :type transaction : list
-            :param sup : support of prefixPath taken at last child of the path
-            :type sup : int
-            :param second: second probability of the leaf node
-            :type second: float
-        """
+        # This method takes transaction as input and returns the tree
         currentNode = self.root
-        k = 0
         for i in range(len(transaction)):
-            k += 1
             if transaction[i] not in currentNode.children:
                 newNode = _Node(transaction[i], {})
-                newNode.k = k
-                newNode.secondProbability = second
-                newNode.probability = sup
+                newNode.freq = count
                 currentNode.addChild(newNode)
                 if transaction[i] in self.summaries:
                     self.summaries[transaction[i]].append(newNode)
                 else:
                     self.summaries[transaction[i]] = [newNode]
                 currentNode = newNode
             else:
                 currentNode = currentNode.children[transaction[i]]
-                currentNode.k = k
-                currentNode.secondProbability = max(currentNode.secondProbability, second)
-                currentNode.probability += sup
-
-    def conditionalPatterns(self, alpha):
-        """generates all the conditional patterns of respective node
-            :param alpha : it represents the Node in tree
-            :type alpha : _Node
+                currentNode.freq += count
+
+    def getFinalConditionalPatterns(self, alpha):
+        """
+        generates the conditional patterns for a node
+        Parameters:
+        ----------
+            alpha: node to generate conditional patterns
+        Returns
+        -------
+            returns conditional patterns, frequency of each item in conditional patterns
         """
         finalPatterns = []
-        sup = []
-        second = []
+        finalFreq = []
         for i in self.summaries[alpha]:
-            s = i.probability
-            s1 = i.secondProbability
+            set1 = i.freq
             set2 = []
-            while i.parent.item is not None:
-                set2.append(i.parent.item)
+            while i.parent.itemId is not None:
+                set2.append(i.parent.itemId)
                 i = i.parent
             if len(set2) > 0:
                 set2.reverse()
                 finalPatterns.append(set2)
-                second.append(s1)
-                sup.append(s)
-        finalPatterns, support, info = self.conditionalTransactions(finalPatterns, sup)
-        return finalPatterns, support, info, second
-
-    def conditionalTransactions(self, condPatterns, support):
-        """ It generates the conditional patterns with frequent items
-            :param condPatterns : conditional patterns generated from conditionalPatterns() method for respective node
-            :type condPatterns : list
-            :param support : the support of conditional pattern in tree
-            :type support : list
+                finalFreq.append(set1)
+        finalPatterns, finalFreq, info = self.getConditionalTransactions(finalPatterns, finalFreq)
+        return finalPatterns, finalFreq, info
+
+    @staticmethod
+    def getConditionalTransactions(ConditionalPatterns, conditionalFreq):
+        """
+        To calculate the frequency of items in conditional patterns and sorting the patterns
+        Parameters
+        ----------
+        ConditionalPatterns: paths of a node
+        conditionalFreq: frequency of each item in the path
+        Returns
+        -------
+            conditional patterns and frequency of each item in transactions
         """
-        global _minSup
+        global _minSup, _miniWeight
         pat = []
-        sup = []
+        freq = []
         data1 = {}
-        for i in range(len(condPatterns)):
-            for j in condPatterns[i]:
+        for i in range(len(ConditionalPatterns)):
+            for j in ConditionalPatterns[i]:
                 if j in data1:
-                    data1[j] += support[i]
+                    data1[j] += conditionalFreq[i]
                 else:
-                    data1[j] = support[i]
-        updatedDict = {}
-        updatedDict = {k: v for k, v in data1.items() if v >= _minSup}
+                    data1[j] = conditionalFreq[i]
+        up_dict = {k: v for k, v in data1.items() if v >= _minSup and v * _miniWeight > _minSup}
         count = 0
-        for p in condPatterns:
-            p1 = [v for v in p if v in updatedDict]
-            trans = sorted(p1, key=lambda x: (updatedDict.get(x)), reverse=True)
+        for p in ConditionalPatterns:
+            p1 = [v for v in p if v in up_dict]
+            trans = sorted(p1, key=lambda x: (up_dict.get(x), -x), reverse=True)
             if len(trans) > 0:
                 pat.append(trans)
-                sup.append(support[count])
+                freq.append(conditionalFreq[count])
             count += 1
-        return pat, sup, updatedDict
-
-    def removeNode(self, nodeValue):
-        """removing the node from tree
-            :param nodeValue : it represents the node in tree
-            :type nodeValue : node
-        """
-        for i in self.summaries[nodeValue]:
-            del i.parent.children[nodeValue]
+        return pat, freq, up_dict
 
     def generatePatterns(self, prefix):
-        """generates the patterns
-            :param prefix : forms the combination of items
-            :type prefix : list
         """
-        global _finalPatterns, _minSup
-        for i in sorted(self.summaries, key=lambda x: (self.info.get(x))):
+        To generate the frequent patterns
+        Parameters
+        ----------
+        prefix: an empty list
+        Returns
+        -------
+        Frequent patterns that are extracted from fp-tree
+        """
+        global _miniWeight, _maxWeight, _minWeight, _minSup
+        for i in sorted(self.summaries, key=lambda x: (self.info.get(x), -x)):
             pattern = prefix[:]
             pattern.append(i)
-            s = 0
-            for x in self.summaries[i]:
-                #if x.k <= 2:
-                    #s += x.probability
-                #elif x.k >= 3:
-                    #n = x.probability * pow(x.secondProbability, (x.k - 2))
-                    #s += n
-                if len(pattern) <= 2:
-                    s += x.probability
-                elif len(pattern) >= 3:
-                    n = x.probability * pow(x.secondProbability, (x.k - 2))
-                    s += n
-            _finalPatterns[tuple(pattern)] = self.info[i]
-            if s >= _minSup:
-                patterns, support, info, second = self.conditionalPatterns(i)
-                conditionalTree = _Tree()
-                conditionalTree.info = info.copy()
-                for pat in range(len(patterns)):
-                    conditionalTree.addConditionalTransaction(patterns[pat], support[pat], second[pat])
-                if len(patterns) > 0:
-                    conditionalTree.generatePatterns(pattern)
-            self.removeNode(i)
+            yield pattern, self.info[i]
+            patterns, freq, info = self.getFinalConditionalPatterns(i)
+            conditionalTree = _Tree()
+            conditionalTree.info = info.copy()
+            for pat in range(len(patterns)):
+                conditionalTree.addTransaction(patterns[pat], freq[pat])
+            if len(patterns) > 0:
+                for q in conditionalTree.generatePatterns(pattern):
+                    yield q
 
 
-class TubeS(_fp._frequentPatterns):
+class WFIM(_fp._weightedFrequentPatterns):
     """
-    TubeP is one of the fastest algorithm to discover frequent patterns in a uncertain transactional database.
-    Reference:
-    --------
-        Carson Kai-Sang Leung and Richard Kyle MacKinnon. 2014. Fast Algorithms for Frequent Itemset Mining from Uncertain Data.
-        In Proceedings of the 2014 IEEE International Conference on Data Mining (ICDM '14). IEEE Computer Society, USA, 893898. https://doi.org/10.1109/ICDM.2014.146
-    Attributes:
-    ----------
+    Description:
+    -------------
+       WFMiner is one of the fundamental algorithm to discover weighted frequent patterns in a transactional database.
+       It stores the database in compressed fp-tree decreasing the memory usage and extracts the
+       patterns from tree.It employs employs downward closure property to  reduce the search space effectively.
+    Reference :
+    -----------
+           U. Yun and J. J. Leggett, Wfim: weighted frequent itemset mining with a weight range and a minimum weight,
+           in Proceedings of the 2005 SIAM International Conference on Data Mining. SIAM, 2005, pp. 636640.
+           https://epubs.siam.org/doi/pdf/10.1137/1.9781611972757.76
+    Attributes :
+    ------------
         iFile : file
-            Name of the Input file or path of the input file
-        oFile : file
-            Name of the output file or path of the output file
+            Input file name or path of the input file
         minSup: float or int or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
             Otherwise, it will be treated as float.
             Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+        minWeight: float or int or str
+            The user can specify minWeight either in count or proportion of database size.
+            If the program detects the data type of minWeight is integer, then it treats minWeight is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minWeight=10 will be treated as integer, while minWeight=10.0 will be treated as float
         sep : str
-            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+            This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
             However, the users can override their default separator.
-        memoryUSS : float
-            To store the total amount of USS memory consumed by the program
-        memoryRSS : float
-            To store the total amount of RSS memory consumed by the program
+        oFile : file
+            Name of the output file or the path of the output file
         startTime:float
             To record the start time of the mining process
         endTime:float
             To record the completion time of the mining process
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
         Database : list
             To store the transactions of a database in list
         mapSupport : Dictionary
             To maintain the information of item and their frequency
         lno : int
-            To represent the total no of transaction
+            it represents the total no of transactions
         tree : class
-            To represents the Tree class
-        itemSetCount : int
-            To represents the total no of patterns
+            it represents the Tree class
         finalPatterns : dict
-            To store the complete patterns
-    Methods:
-    -------
+            it represents to store the patterns
+    Methods :
+    ---------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
             Complete set of frequent patterns will be loaded in to a dataframe
         getMemoryUSS()
             Total amount of USS memory consumed by the mining process will be retrieved from this function
         getMemoryRSS()
             Total amount of RSS memory consumed by the mining process will be retrieved from this function
         getRuntime()
             Total amount of runtime taken by the mining process will be retrieved from this function
-        creatingItemSets(fileName)
-            Scans the dataset and stores in a list format
+        creatingItemSets()
+            Scans the dataset or dataframes and stores in list format
         frequentOneItem()
-            Extracts the one-length frequent patterns from database
-        updateTransactions()
-            Update the transactions by removing non-frequent items and sort the Database by item decreased support
-        buildTree()
-            After updating the Database, remaining items will be added into the tree by setting root node as null
-        convert()
-            to convert the user specified value
-    Executing the code on terminal:
-    -------
+            Extracts the one-frequent patterns from transactions
+    Methods to execute code on terminal
+    ------------------------------------
         Format:
-        ------
+                  >>>  python3 WFIM.py <inputFile> <weightFile> <outputFile> <minSup> <minWeight>
+        Example:
+                  >>>  python3 WFIM.py sampleDB.txt weightSample.txt patterns.txt 10.0 3.4
 
-        python3 TubeS.py <inputFile> <outputFile> <minSup>
+                 .. note:: minSup and maxPer will be considered in support count or frequency
 
-        Examples:
-        --------
+    **Importing this algorithm into a python program**
+    --------------------------------------------------
+    .. code-block:: python
 
-        python3 TubeS.py sampleTDB.txt patterns.txt 3    (minSup  will be considered in support count or frequency)
+            from PAMI.weightFrequentPattern.basic import WFIM as alg
 
-    Sample run of importing the code:
-    -------------------
+            obj = alg.WFIM(iFile, wFile, minSup, minWeight)
 
-        from PAMI.uncertainFrequentPattern.basic import tubeS as alg
+            obj.startMine()
 
-        obj = alg.TubeS(iFile, minSup)
+            frequentPatterns = obj.getPatterns()
 
-        obj.startMine()
+            print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-        Patterns = obj.getPatterns()
+            obj.savePatterns(oFile)
 
-        print("Total number of  Patterns:", len(Patterns))
+            Df = obj.getPatternsAsDataFrame()
 
-        obj.save(oFile)
+            memUSS = obj.getmemoryUSS()
 
-        Df = obj.getPatternsAsDataFrame()
+            print("Total Memory in USS:", memUSS)
 
-        memUSS = obj.getMemoryUSS()
+            memRSS = obj.getMemoryRSS()
 
-        print("Total Memory in USS:", memUSS)
+            print("Total Memory in RSS", memRSS)
 
-        memRSS = obj.getMemoryRSS()
+            run = obj.getRuntime()
 
-        print("Total Memory in RSS", memRSS)
+            print("Total ExecutionTime in seconds:", run)
 
-        run = obj.getRuntime()
+    **Credits:**
 
-        print("Total ExecutionTime in seconds:", run)\n
+             The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
 
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
-    """
-    _startTime = float()
-    _endTime = float()
-    _minSup = float()
-    _finalPatterns = {}
+  """
+
+    __startTime = float()
+    __endTime = float()
+    _minSup = str()
+    __finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
-    _memoryUSS = float()
-    _memoryRSS = float()
-    _Database = []
-    _rank = {}
-    _lno = 0
-    def __init__(self, iFile, minSup, sep='\t'):
-        super().__init__(iFile, minSup, sep)
-    def _creatingItemSets(self):
+    __memoryUSS = float()
+    __memoryRSS = float()
+    __Database = []
+    __mapSupport = {}
+    __lno = 0
+    __tree = _Tree()
+    __rank = {}
+    __rankDup = {}
+
+    def __init__(self, iFile, wFile, minSup, minWeight, sep='\t'):
+        super().__init__(iFile, wFile, minSup, minWeight, sep)
+
+    def __creatingItemSets(self):
         """
-        Scans the databases and stores the transactions into Database variable
+            Storing the complete transactions of the database/input file in a database variable
         """
-        self._Database = []
+        self.__Database = []
         if isinstance(self._iFile, _fp._pd.DataFrame):
-            uncertain, data = [], []
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
-                self._Database = self._iFile['Transactions'].tolist()
-            if 'uncertain' in i:
-                uncertain = self._iFile['uncertain'].tolist()
-            for k in range(len(data)):
-                tr = []
-                for j in range(len(data[k])):
-                    product = _Item(data[k][j], uncertain[k][j])
-                    tr.append(product)
-                self._Database.append(tr)
-                self._lno += 1
+                self.__Database = self._iFile['Transactions'].tolist()
 
             # print(self.Database)
         if isinstance(self._iFile, str):
             if _fp._validators.url(self._iFile):
                 data = _fp._urlopen(self._iFile)
                 for line in data:
-                    line = line.strip()
+                    line.strip()
                     line = line.decode("utf-8")
-                    temp1 = line.split(':')
-                    temp = [i.rstrip() for i in temp[0].split(self._sep)]
-                    uncertain = [float(i.rstrip()) for i in temp[1].split(self._sep)]
-                    tr = []
-                    for i in range(len(temp)):
-                        item = temp[i]
-                        probability = uncertain[i]
-                        product = _Item(item, probability)
-                        tr.append(product)
-                    self._lno += 1
-                    self._Database.append(temp)
+                    temp = [i.rstrip() for i in line.split(self._sep)]
+                    temp = [x for x in temp if x]
+                    self.__Database.append(temp)
             else:
                 try:
-                    with open(self._iFile, 'r') as f:
+                    with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
-                            temp1 = line.strip()
-                            temp1 = temp1.split(':')
-                            temp = [i.rstrip() for i in temp1[0].split(self._sep)]
-                            uncertain = [float(i.rstrip()) for i in temp1[1].split(self._sep)]
-                            tr = []
-                            for i in range(len(temp)):
-                                item = temp[i]
-                                probability = uncertain[i]
-                                product = _Item(item, probability)
-                                tr.append(product)
-                            self._lno += 1
-                            self._Database.append(tr)
+                            line.strip()
+                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            temp = [x for x in temp if x]
+                            # print(len(temp))
+                            self.__Database.append(temp)
                 except IOError:
                     print("File Not Found")
+                    quit()
 
-    def _frequentOneItem(self):
-        """takes the transactions and calculates the support of each item in the dataset and assign the
-                    ranks to the items by decreasing support and returns the frequent items list
-        """
-        global _minSup
-        mapSupport = {}
-        for i in self._Database:
-            for j in i:
-                if j.item not in mapSupport:
-                    mapSupport[j.item] = round(j.probability, 2)
-                else:
-                    mapSupport[j.item] += round(j.probability, 2)
-        mapSupport = {k: round(v, 2) for k, v in mapSupport.items() if v >= self._minSup}
-        plist = [k for k, v in sorted(mapSupport.items(), key=lambda x: x[1], reverse=True)]
-        self._rank = dict([(index, item) for (item, index) in enumerate(plist)])
-        return mapSupport, plist
-
-    def _buildTree(self, data, info):
-        """it takes the transactions and support of each item and construct the main tree with setting root
-                    node as null
-            :param data : it represents the one transactions in database
-            :type data : list
-            :param info : it represents the support of each item
-            :type info : dictionary
+    def _scanningWeights(self):
         """
-        rootNode = _Tree()
-        rootNode.info = info.copy()
-        for i in range(len(data)):
-            rootNode.addTransaction(data[i])
-        return rootNode
-
-    def updateTransactions(self, dict1):
-        """remove the items which are not frequent from transactions and updates the transactions with rank of items
-                :param dict1 : frequent items with support
-                :type dict1 : dictionary
+            Storing the weights of the variables in input file in a weights variable
         """
-        list1 = []
-        for tr in self._Database:
-            list2 = []
-            for i in range(0, len(tr)):
-                if tr[i].item in dict1:
-                    list2.append(tr[i])
-            if (len(list2) >= 2):
-                basket = list2
-                basket.sort(key=lambda val: self._rank[val.item])
-                list2 = basket
-                list1.append(list2)
-        return list1
+        global _weights
+        _weights = {}
+        if isinstance(self._wFile, _fp._pd.DataFrame):
+            items, weights = [], []
+            if self._wFile.empty:
+                print("its empty..")
+            i = self._wFile.columns.values.tolist()
+            if 'items' in i:
+                items = self._wFile['items'].tolist()
+            if 'weights' in i:
+                weights = self._wFile['weights'].tolist()
+            for i in range(len(weights)):
+                _weights[items[i]] = weights[i]
 
-    def _Check(self, i, x):
-        """To check the presence of item or pattern in transaction
-            :param x: it represents the pattern
-            :type x : list
-            :param i : represents the uncertain transactions
-            :type i : list
-        """
-        for m in x:
-            k = 0
-            for n in i:
-                if m == n.item:
-                    k += 1
-            if k == 0:
-                return 0
-        return 1
-
-    def _convert(self, value):
-        """
-            To convert the type of user specified minSup value
-                :param value: user specified minSup value
-                :return: converted type minSup value
+            # print(self.Database)
+        if isinstance(self._wFile, str):
+            if _fp._validators.url(self._wFile):
+                data = _fp._urlopen(self._wFile)
+                for line in data:
+                    line.strip()
+                    line = line.decode("utf-8")
+                    temp = [i.rstrip() for i in line.split(self._sep)]
+                    temp = [x for x in temp if x]
+                    _weights[temp[0]] = temp[1]
+            else:
+                try:
+                    with open(self._wFile, 'r', encoding='utf-8') as f:
+                        for line in f:
+                            line.strip()
+                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            temp = [x for x in temp if x]
+                            s = int(float(temp[1]))
+                            _weights[temp[0]] = s
+                except IOError:
+                    print("File Not Found")
+                    quit()
+
+    def __convert(self, value):
+        """
+        to convert the type of user specified minSup value
+        :param value: user specified minSup value
+        :return: converted type
         """
         if type(value) is int:
             value = int(value)
         if type(value) is float:
-            value = (len(self._Database) * value)
+            value = (len(self.__Database) * value)
         if type(value) is str:
             if '.' in value:
-                value = (len(self._Database) * value)
+                value = float(value)
+                value = (len(self.__Database) * value)
             else:
                 value = int(value)
         return value
 
-    def _removeFalsePositives(self):
+    def __frequentOneItem(self):
         """
-        To remove the false positive patterns generated in frequent patterns
-        :return: patterns with accurate probability
+        Generating One frequent items sets
         """
-        global _finalPatterns
-        periods = {}
-        for i in self._Database:
-            for x, y in _finalPatterns.items():
-                if len(x) == 1:
-                    periods[x] = y
+        global _maxWeight
+        self.__mapSupport = {}
+        for tr in self.__Database:
+            for i in range(0, len(tr)):
+                if tr[i] not in self.__mapSupport:
+                    self.__mapSupport[tr[i]] = 1
                 else:
-                    s = 1
-                    check = self._Check(i, x)
-                    if check == 1:
-                        for j in i:
-                            if j.item in x:
-                                s *= j.probability
-                        if x in periods:
-                            periods[x] += s
-                        else:
-                            periods[x] = s
-        for x, y in periods.items():
-            if y >= self._minSup:
-                sample = str()
-                for i in x:
-                    sample = sample + i + "\t"
-                self._finalPatterns[sample] = y
+                    self.__mapSupport[tr[i]] += 1
+        self.__mapSupport = {k: v for k, v in self.__mapSupport.items() if v >= self._minSup and v * _maxWeight > self._minSup}
+        genList = [k for k, v in sorted(self.__mapSupport.items(), key=lambda x: x[1], reverse=True)]
+        self.__rank = dict([(index, item) for (item, index) in enumerate(genList)])
+        return genList
+
+    def __updateTransactions(self, itemSet):
+        """
+        Updates the items in transactions with rank of items according to their support
+        :Example: oneLength = {'a':7, 'b': 5, 'c':'4', 'd':3}
+                    rank = {'a':0, 'b':1, 'c':2, 'd':3}
+        Parameters
+        ----------
+        itemSet: list of one-frequent items
+        -------
+        """
+        list1 = []
+        for tr in self.__Database:
+            list2 = []
+            for i in range(len(tr)):
+                if tr[i] in itemSet:
+                    list2.append(self.__rank[tr[i]])
+            if len(list2) >= 1:
+                list2.sort()
+                list1.append(list2)
+        return list1
+
+    @staticmethod
+    def __buildTree(transactions, info):
+        """
+        Builds the tree with updated transactions
+        Parameters:
+        ----------
+            transactions: updated transactions
+            info: support details of each item in transactions
+        Returns:
+        -------
+            transactions compressed in fp-tree
+        """
+        rootNode = _Tree()
+        rootNode.info = info.copy()
+        for i in range(len(transactions)):
+            rootNode.addTransaction(transactions[i], 1)
+        return rootNode
+
+    def __savePeriodic(self, itemSet):
+        """
+        The duplication items and their ranks
+        Parameters:
+        ----------
+            itemSet: frequent itemSet that generated
+        Returns:
+        -------
+            patterns with original item names.
+        """
+        temp = str()
+        for i in itemSet:
+            temp = temp + self.__rankDup[i] + "\t"
+        return temp
 
     def startMine(self):
-        """Main method where the patterns are mined by constructing tree and remove the remove the false patterns
-                           by counting the original support of a patterns
         """
-        global _minSup
-        self._startTime = _fp._time.time()
-        self._creatingItemSets()
-        self._minSup = self._convert(self._minSup)
+            main program to start the operation
+        """
+        global _minSup, _minWeight, _miniWeight, _maxWeight, _weights
+        self.__startTime = _fp._time.time()
+        if self._iFile is None:
+            raise Exception("Please enter the file path or file name:")
+        if self._minSup is None:
+            raise Exception("Please enter the Minimum Support")
+        self.__creatingItemSets()
+        self._scanningWeights()
+        _weights = {k: v for k, v in _weights.items() if v >= _minWeight}
+        _maxWeight = max([s for s in _weights.values()])
+        _miniWeight = min([s for s in _weights.values()])
+        self._minSup = self.__convert(self._minSup)
         _minSup = self._minSup
-        self._finalPatterns = {}
-        mapSupport, plist = self._frequentOneItem()
-        transactions1 = self.updateTransactions(mapSupport)
-        info = {k: v for k, v in mapSupport.items()}
-        Tree1 = self._buildTree(transactions1, info)
-        Tree1.generatePatterns([])
-        self._removeFalsePositives()
-        print("Uncertain Frequent patterns were generated successfully using TubeS algorithm")
-        self._endTime = _fp._time.time()
+        itemSet = self.__frequentOneItem()
+        updatedTransactions = self.__updateTransactions(itemSet)
+        for x, y in self.__rank.items():
+            self.__rankDup[y] = x
+        info = {self.__rank[k]: v for k, v in self.__mapSupport.items()}
+        __Tree = self.__buildTree(updatedTransactions, info)
+        patterns = __Tree.generatePatterns([])
+        self.__finalPatterns = {}
+        for k in patterns:
+            s = self.__savePeriodic(k[0])
+            self.__finalPatterns[str(s)] = k[1]
+        print("Weighted Frequent patterns were generated successfully using WFIM algorithm")
+        self.__endTime = _fp._time.time()
+        self.__memoryUSS = float()
+        self.__memoryRSS = float()
         process = _fp._psutil.Process(_fp._os.getpid())
-        self._memoryUSS = float()
-        self._memoryRSS = float()
-        self._memoryUSS = process.memory_full_info().uss
-        self._memoryRSS = process.memory_info().rss
+        self.__memoryUSS = process.memory_full_info().uss
+        self.__memoryRSS = process.memory_info().rss
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
         :return: returning USS memory consumed by the mining process
         :rtype: float
         """
 
-        return self._memoryUSS
+        return self.__memoryUSS
 
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the mining process will be retrieved from this function
         :return: returning RSS memory consumed by the mining process
         :rtype: float
         """
 
-        return self._memoryRSS
+        return self.__memoryRSS
 
     def getRuntime(self):
         """Calculating the total amount of runtime taken by the mining process
         :return: returning total amount of runtime taken by the mining process
         :rtype: float
         """
 
-        return self._endTime - self._startTime
+        return self.__endTime - self.__startTime
 
     def getPatternsAsDataFrame(self):
         """Storing final frequent patterns in a dataframe
         :return: returning frequent patterns in a dataframe
         :rtype: pd.DataFrame
         """
 
         dataframe = {}
         data = []
-        for a, b in self._finalPatterns.items():
+        for a, b in self.__finalPatterns.items():
             data.append([a.replace('\t', ' '), b])
             dataframe = _fp._pd.DataFrame(data, columns=['Patterns', 'Support'])
         return dataframe
 
     def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
         :param outFile: name of the output file
         :type outFile: file
         """
-        self.oFile = outFile
-        writer = open(self.oFile, 'w+')
-        for x, y in self._finalPatterns.items():
+        self._oFile = outFile
+        writer = open(self._oFile, 'w+')
+        for x, y in self.__finalPatterns.items():
             s1 = x.strip() + ":" + str(y)
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
         :return: returning frequent patterns
         :rtype: dict
         """
-        return len(self._finalPatterns)
+        return self.__finalPatterns
 
     def printResults(self):
-        print("Total number of  Uncertain Frequent Patterns:", len(self.getPatterns()))
+        print("Total number of  Weighted Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
+        
+
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_fp._sys.argv) == 4 or len(_fp._sys.argv) == 5:
-        if len(_fp._sys.argv) == 5:
-            _ap = TubeS(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4])
-        if len(_fp._sys.argv) == 4:
-            _ap = TubeS(_fp._sys.argv[1], _fp._sys.argv[3])
+    if len(_fp._sys.argv) == 6 or len(_fp._sys.argv) == 7:
+        if len(_fp._sys.argv) == 7:
+            _ap = WFIM(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4], _fp._sys.argv[5], _fp._sys.argv[6])
+        if len(_fp._sys.argv) == 6:
+            _ap = WFIM(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4], _fp._sys.argv[5])
         _ap.startMine()
-        print("Total number of Uncertain Frequent Patterns:", len(_ap.getPatterns()))
+        print("Total number of Weighted Frequent Patterns:", len(_ap.getPatterns()))
         _ap.save(_fp._sys.argv[2])
-        print("Total Memory in USS:", _ap.getMemoryUSS())
+        print("Total Memory in USS:",  _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/UFGrowth.py` & `pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/UFGrowth.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,21 +1,55 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     from PAMI.uncertainFrequentPattern.basic import UFGrowth as alg
+#
+#     obj = alg.UFGrowth(iFile, minSup)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getmemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 from PAMI.uncertainFrequentPattern.basic import abstract as _ab
 
 _minSup = str()
 _ab._sys.setrecursionlimit(20000)
 _finalPatterns = {}
 
@@ -210,22 +244,24 @@
                         current = newNode
                         self.fixNodeLinks(pathItem.itemid, newNode)
         return q
 
 
 class UFGrowth(_ab._frequentPatterns):
     """
+    Description:
+    -------------
         It is one of the fundamental algorithm to discover frequent patterns in a uncertain transactional database
         using PUF-Tree.
     Reference:
-    --------
+    -----------
         Carson Kai-Sang Leung, Syed Khairuzzaman Tanbeer, "PUF-Tree: A Compact Tree Structure for Frequent Pattern Mining of Uncertain Data",
         Pacific-Asia Conference on Knowledge Discovery and Data Mining(PAKDD 2013), https://link.springer.com/chapter/10.1007/978-3-642-37453-1_2
     Attributes:
-    ----------
+    -----------
         iFile : file
             Name of the Input file or path of the input file
         oFile : file
             Name of the output file or path of the output file
         minSup: float or int or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
@@ -251,15 +287,15 @@
         tree : class
             To represents the Tree class
         itemSetCount : int
             To represents the total no of patterns
         finalPatterns : dict
             To store the complete patterns
     Methods:
-    -------
+    --------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
         save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
@@ -278,40 +314,58 @@
             Update the transactions by removing non-frequent items and sort the Database by item decreased support
         buildTree()
             After updating the Database, remaining items will be added into the tree by setting root node as null
         convert()
             to convert the user specified value
         startMine()
             Mining process will start from this function
-    Executing the code on terminal:
-    -------
-        Format:
-        ------
-        python3 PUFGrowth.py <inputFile> <outputFile> <minSup>
-        Examples:
-        --------
-        python3 PUFGrowth.py sampleTDB.txt patterns.txt 3    (minSup  will be considered in support count or frequency)
-    Sample run of importing the code:
-    -------------------
-        from PAMI.uncertainFrequentPattern.basic import puf as alg
-        obj = alg.PUFGrowth(iFile, minSup)
-        obj.startMine()
-        Patterns = obj.getPatterns()
-        print("Total number of  Patterns:", len(Patterns))
-        obj.save(oFile)
-        Df = obj.getPatternsAsDataFrame()
-        memUSS = obj.getMemoryUSS()
-        print("Total Memory in USS:", memUSS)
-        memRSS = obj.getMemoryRSS()
-        print("Total Memory in RSS", memRSS)
-        run = obj.getRuntime()
-        print("Total ExecutionTime in seconds:", run)
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+
+    **Methods to execute code on terminal**
+
+            Format:
+                      >>>  python3 PUFGrowth.py <inputFile> <outputFile> <minSup>
+            Example:
+                      >>>  python3 PUFGrowth.py sampleTDB.txt patterns.txt 3
+
+            .. note:: minSup  will be considered in support count or frequency
+
+    **Importing this algorithm into a python program**
+
+    .. code-block:: python
+
+            from PAMI.uncertainFrequentPattern.basic import UFGrowth as alg
+
+            obj = alg.UFGrowth(iFile, minSup)
+
+            obj.startMine()
+
+            frequentPatterns = obj.getPatterns()
+
+            print("Total number of Frequent Patterns:", len(frequentPatterns))
+
+            obj.savePatterns(oFile)
+
+            Df = obj.getPatternsAsDataFrame()
+
+            memUSS = obj.getmemoryUSS()
+
+            print("Total Memory in USS:", memUSS)
+
+            memRSS = obj.getMemoryRSS()
+
+            print("Total Memory in RSS", memRSS)
+
+            run = obj.getRuntime()
+
+            print("Total ExecutionTime in seconds:", run)
+
+    **Credits:**
+
+             The complete program was written by P.Likhitha under the supervision of Professor Rage Uday Kiran.
+
     """
     _startTime = float()
     _endTime = float()
     _minSup = str()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
```

### Comparing `pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/UVECLAT.py` & `pami-2023.5.1/PAMI/faultTolerantFrequentPattern/basic/FTFPGrowth.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,481 +1,644 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
+#     from PAMI.frequentPattern.basic import FPGrowth as alg
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     obj = alg.FPGrowth(iFile, minSup)
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+"""
+
 
-import operator as _operator
-from PAMI.uncertainFrequentPattern.basic import abstract as _ab
 
 
-_minSup = float()
-_finalPatterns = {}
 
 
-class _Item:
+
+
+
+from PAMI.faultTolerantFrequentPattern.basic import abstract as _ab
+from PAMI.faultTolerantFrequentPattern.basic import abstract as _fp
+
+_minSup = str()
+_fp._sys.setrecursionlimit(20000)
+
+
+class _Node:
     """
-    A class used to represent the item with probability in transaction of dataset
-    ...
+        A class used to represent the node of frequentPatternTree
+
     Attributes:
-    __________
-        item : int or word
-            Represents the name of the item
-        probability : float
-            Represent the existential probability(likelihood presence) of an item
+    ----------
+        itemId: int
+            storing item of a node
+        counter: int
+            To maintain the support of node
+        parent: node
+            To maintain the parent of node
+        children: list
+            To maintain the children of node
+
+    Methods:
+    -------
+
+        addChild(node)
+            Updates the nodes children list and parent for the given node
+
     """
 
-    def __init__(self, item, probability):
-        self.item = item
-        self.probability = probability
+    def __init__(self, item, children):
+        self.itemId = item
+        self.counter = 1
+        self.parent = None
+        self.children = children
+
+    def addChild(self, node):
+        """
+            Retrieving the child from the tree
 
+            :param node: Children node
+            :type node: Node
+            :return: Updates the children nodes and parent nodes
 
-class UVEclat(_ab._frequentPatterns):
+        """
+        self.children[node.itemId] = node
+        node.parent = self
+
+
+class _Tree:
     """
-        It is one of the fundamental algorithm to discover frequent patterns in a uncertain transactional database
-        using PUF-Tree.
-    Reference:
-    --------
-    Carson Kai-Sang Leung, Lijing Sun: "Equivalence class transformation based mining of frequent itemsets from uncertain data",
-    SAC '11: Proceedings of the 2011 ACM Symposium on Applied ComputingMarch, 2011, Pages 983984,
-    https://doi.org/10.1145/1982185.1982399
+    A class used to represent the frequentPatternGrowth tree structure
 
     Attributes:
     ----------
+        root : Node
+            The first node of the tree set to Null.
+        summaries : dictionary
+            Stores the nodes itemId which shares same itemId
+        info : dictionary
+            frequency of items in the transactions
+
+    Methods:
+    -------
+        addTransaction(transaction, freq)
+            adding items of  transactions into the tree as nodes and freq is the count of nodes
+        getFinalConditionalPatterns(node)
+            getting the conditional patterns from fp-tree for a node
+        getConditionalPatterns(patterns, frequencies)
+            sort the patterns by removing the items with lower minSup
+        generatePatterns(prefix)
+            generating the patterns from fp-tree
+    """
+
+    def __init__(self):
+        self.headerList = []
+        self.root = _Node(None, {})
+        self.summaries = {}
+        self.info = {}
+
+    def addTransaction(self, transaction, count):
+        """adding transaction into tree
+
+        :param transaction: it represents the one transactions in database
+
+        :type transaction: list
+
+        :param count: frequency of item
+
+        :type count: int
+        """
+
+        # This method takes transaction as input and returns the tree
+        currentNode = self.root
+        for i in range(len(transaction)):
+            if transaction[i] not in currentNode.children:
+                newNode = _Node(transaction[i], {})
+                newNode.freq = count
+                currentNode.addChild(newNode)
+                if transaction[i] in self.summaries:
+                    self.summaries[transaction[i]].append(newNode)
+                else:
+                    self.summaries[transaction[i]] = [newNode]
+                currentNode = newNode
+            else:
+                currentNode = currentNode.children[transaction[i]]
+                currentNode.freq += count
+
+    def getFinalConditionalPatterns(self, alpha):
+        """
+        generates the conditional patterns for a node
+
+        Parameters:
+        ----------
+            alpha: node to generate conditional patterns
+
+        Returns
+        -------
+            returns conditional patterns, frequency of each item in conditional patterns
+
+        """
+        finalPatterns = []
+        finalFreq = []
+        for i in self.summaries[alpha]:
+            set1 = i.freq
+            set2 = []
+            while i.parent.itemId is not None:
+                set2.append(i.parent.itemId)
+                i = i.parent
+            if len(set2) > 0:
+                set2.reverse()
+                finalPatterns.append(set2)
+                finalFreq.append(set1)
+        finalPatterns, finalFreq, info = self.getConditionalTransactions(finalPatterns, finalFreq)
+        return finalPatterns, finalFreq, info
+
+    @staticmethod
+    def getConditionalTransactions(ConditionalPatterns, conditionalFreq):
+        """
+        To calculate the frequency of items in conditional patterns and sorting the patterns
+        Parameters
+        ----------
+        ConditionalPatterns: paths of a node
+        conditionalFreq: frequency of each item in the path
+
+        Returns
+        -------
+            conditional patterns and frequency of each item in transactions
+        """
+        global _minSup
+        pat = []
+        freq = []
+        data1 = {}
+        for i in range(len(ConditionalPatterns)):
+            for j in ConditionalPatterns[i]:
+                if j in data1:
+                    data1[j] += conditionalFreq[i]
+                else:
+                    data1[j] = conditionalFreq[i]
+        up_dict = {k: v for k, v in data1.items() if v >= _minSup}
+        count = 0
+        for p in ConditionalPatterns:
+            p1 = [v for v in p if v in up_dict]
+            trans = sorted(p1, key=lambda x: (up_dict.get(x), -x), reverse=True)
+            if len(trans) > 0:
+                pat.append(trans)
+                freq.append(conditionalFreq[count])
+            count += 1
+        return pat, freq, up_dict
+
+    def generatePatterns(self, prefix):
+        """
+        To generate the frequent patterns
+        Parameters
+        ----------
+        prefix: an empty list
+
+        Returns
+        -------
+        Frequent patterns that are extracted from fp-tree
+
+        """
+        for i in sorted(self.summaries, key=lambda x: (self.info.get(x), -x)):
+            pattern = prefix[:]
+            pattern.append(i)
+            yield pattern, self.info[i]
+            patterns, freq, info = self.getFinalConditionalPatterns(i)
+            conditionalTree = _Tree()
+            conditionalTree.info = info.copy()
+            for pat in range(len(patterns)):
+                conditionalTree.addTransaction(patterns[pat], freq[pat])
+            if len(patterns) > 0:
+                for q in conditionalTree.generatePatterns(pattern):
+                    yield q
+
+
+class FTFPGrowth(_fp._faultTolerantFrequentPatterns):
+    """
+    Description:
+    ------------
+       FPGrowth is one of the fundamental algorithm to discover frequent patterns in a transactional database.
+       It stores the database in compressed fp-tree decreasing the memory usage and extracts the
+       patterns from tree.It employs employs downward closure property to  reduce the search space effectively.
+
+    Reference :
+    ---------
+       Han, J., Pei, J., Yin, Y. et al. Mining Frequent Patterns without Candidate Generation: A Frequent-Pattern
+       Tree Approach. Data  Mining and Knowledge Discovery 8, 5387 (2004). https://doi.org/10.1023
+
+    Attributes :
+    ----------
         iFile : file
-            Name of the Input file or path of the input file
-        oFile : file
-            Name of the output file or path of the output file
+            Input file name or path of the input file
         minSup: float or int or str
             The user can specify minSup either in count or proportion of database size.
             If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
             Otherwise, it will be treated as float.
             Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
         sep : str
-            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+            This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
             However, the users can override their default separator.
-        memoryUSS : float
-            To store the total amount of USS memory consumed by the program
-        memoryRSS : float
-            To store the total amount of RSS memory consumed by the program
+        oFile : file
+            Name of the output file or the path of the output file
         startTime:float
             To record the start time of the mining process
         endTime:float
             To record the completion time of the mining process
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
         Database : list
             To store the transactions of a database in list
         mapSupport : Dictionary
             To maintain the information of item and their frequency
         lno : int
-            To represent the total no of transaction
+            it represents the total no of transactions
         tree : class
-            To represents the Tree class
-        itemSetCount : int
-            To represents the total no of patterns
+            it represents the Tree class
         finalPatterns : dict
-            To store the complete patterns
-    Methods:
+            it represents to store the patterns
+
+    Methods :
     -------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
-        storePatternsInFile(oFile)
+        save(oFile)
             Complete set of frequent patterns will be loaded in to a output file
-        getPatternsInDataFrame()
+        getPatternsAsDataFrame()
             Complete set of frequent patterns will be loaded in to a dataframe
         getMemoryUSS()
             Total amount of USS memory consumed by the mining process will be retrieved from this function
         getMemoryRSS()
             Total amount of RSS memory consumed by the mining process will be retrieved from this function
         getRuntime()
             Total amount of runtime taken by the mining process will be retrieved from this function
-        creatingItemSets(fileName)
-            Scans the dataset and stores in a list format
+        creatingItemSets()
+            Scans the dataset or dataframes and stores in list format
         frequentOneItem()
-            Extracts the one-length frequent patterns from database
+            Extracts the one-frequent patterns from transactions
 
     Executing the code on terminal:
-    -------
+    -------------------------------
         Format:
-        ------
-        python3 uveclat.py <inputFile> <outputFile> <minSup>
+        -------
+            >>> python3 FPGrowth.py <inputFile> <outputFile> <minSup>
+
         Examples:
-        --------
-        python3 uveclat.py sampleTDB.txt patterns.txt 3    (minSup  will be considered in support count or frequency)
+        ---------
+            >>> python3 FPGrowth.py sampleDB.txt patterns.txt 10.0   (minSup will be considered in times of minSup and count of database transactions)
 
-    Sample run of importing the code:
-    -------------------
-        from PAMI.uncertainFrequentPattern.basic import uveclat as alg
 
-        obj = alg.UVEclat(iFile, minSup)
+
+    Sample run of the importing code:
+    -----------------------------------
+    .. code-block:: python
+
+        from PAMI.frequentPattern.basic import FPGrowth as alg
+
+        obj = alg.FPGrowth(iFile, minSup)
 
         obj.startMine()
 
-        Patterns = obj.getPatterns()
+        frequentPatterns = obj.getPatterns()
 
-        print("Total number of  Patterns:", len(Patterns))
+        print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-        obj.storePatternsInFile(oFile)
+        obj.save(oFile)
 
-        Df = obj.getPatternsInDataFrame()
+        Df = obj.getPatternInDataFrame()
 
         memUSS = obj.getMemoryUSS()
 
         print("Total Memory in USS:", memUSS)
 
         memRSS = obj.getMemoryRSS()
 
         print("Total Memory in RSS", memRSS)
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
 
     Credits:
-    -------
+    --------
         The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
-    """
-    _startTime = float()
-    _endTime = float()
+
+        """
+
+    __startTime = float()
+    __endTime = float()
     _minSup = str()
-    _finalPatterns = {}
+    __finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
-    _memoryUSS = float()
-    _memoryRSS = float()
-    _Database = []
-    _tidList = {}
-    _rank = {}
-
-    def _creatingItemSets(self):
-        """
-            Scans the dataset
-        """
-        self._Database = []
-        if isinstance(self._iFile, _ab._pd.DataFrame):
-            uncertain, data = [], []
+    __memoryUSS = float()
+    __memoryRSS = float()
+    __Database = []
+    __mapSupport = {}
+    __lno = 0
+    __tree = _Tree()
+    __rank = {}
+    __rankDup = {}
+
+    def __init__(self, iFile, minSup, itemSup, minLength, faultTolerance, sep='\t'):
+        super().__init__(iFile, minSup, itemSup, minLength, faultTolerance, sep)
+
+    def __creatingItemSets(self):
+        """
+            Storing the complete transactions of the database/input file in a database variable
+
+
+        """
+        self.__Database = []
+        if isinstance(self._iFile, _fp._pd.DataFrame):
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
-                self._Database = self._iFile['Transactions'].tolist()
-            if 'uncertain' in i:
-                uncertain = self._iFile['uncertain'].tolist()
-            for k in range(len(data)):
-                tr = []
-                for j in range(len(data[k])):
-                    product = _Item(data[k][j], uncertain[k][j])
-                    tr.append(product)
-                self._Database.append(tr)
+                self.__Database = self._iFile['Transactions'].tolist()
 
             # print(self.Database)
         if isinstance(self._iFile, str):
-            if _ab._validators.url(self._iFile):
-                data = _ab._urlopen(self._iFile)
+            if _fp._validators.url(self._iFile):
+                data = _fp._urlopen(self._iFile)
                 for line in data:
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
-                    tr = []
-                    for i in temp:
-                        i1 = i.index('(')
-                        i2 = i.index(')')
-                        item = i[0:i1]
-                        probability = float(i[i1 + 1:i2])
-                        product = _Item(item, probability)
-                        tr.append(product)
-                    self._Database.append(temp)
+                    self.__Database.append(temp)
             else:
                 try:
-                    with open(self._iFile, 'r') as f:
+                    with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
+                            line.strip()
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
-                            tr = []
-                            for i in temp:
-                                i1 = i.index('(')
-                                i2 = i.index(')')
-                                item = i[0:i1]
-                                probability = float(i[i1 + 1:i2])
-                                product = _Item(item, probability)
-                                tr.append(product)
-                            self._Database.append(tr)
+                            self.__Database.append(temp)
                 except IOError:
                     print("File Not Found")
+                    quit()
 
-    def _frequentOneItem(self):
-        """takes the self.Database and calculates the support of each item in the dataset and assign the
-            ranks to the items by decreasing support and returns the frequent items list
+    def __convert(self, value):
         """
+        to convert the type of user specified minSup value
 
-        mapSupport = {}
-        k = 0
-        for i in self._Database:
-            k += 1
-            for j in i:
-                if j.item not in mapSupport:
-                    mapSupport[str(j.item)] = j.probability
-                    self._tidList[str(j.item)] = {k: j.probability}
-                else:
-                    mapSupport[str(j.item)] += j.probability
-                    self._tidList[str(j.item)].update({k: j.probability})
-        mapSupport = {k: v for k, v in mapSupport.items() if v >= self._minSup}
-        plist = dict( sorted(mapSupport.items(), key=_operator.itemgetter(1),reverse=True))
-        return list(plist.keys())
-
-    @staticmethod
-    def _check(i, x):
-        """To check the presence of item or pattern in transaction
-                :param x: it represents the pattern
-                :type x : list
-                :param i : represents the uncertain self.Database
-                :type i : list
-        """
-
-        # This method taken a transaction as input and returns the tree
-        for m in x:
-            k = 0
-            for n in i:
-                if m == n.item:
-                    k += 1
-            if k == 0:
-                return 0
-        return 1
+        :param value: user specified minSup value
 
-    @staticmethod
-    def _convert(value):
-        """
-        To convert the type of user specified minSup value
-            :param value: user specified minSup value
-            :return: converted type minSup value
+        :return: converted type
         """
         if type(value) is int:
             value = int(value)
         if type(value) is float:
-            value = float(value)
+            value = (len(self.__Database) * value)
         if type(value) is str:
             if '.' in value:
                 value = float(value)
+                value = (len(self.__Database) * value)
             else:
                 value = int(value)
         return value
 
-    def _removeFalsePositives(self):
+    def __frequentOneItem(self):
         """
-            To remove the false positive patterns generated in frequent patterns
-            :return: patterns with accurate probability
+        Generating One frequent items sets
+
         """
-        global _finalPatterns
-        periods = {}
-        for i in self._Database:
-            for x, y in _finalPatterns.items():
-                if len(x) == 1:
-                    periods[x] = y
+        self.__mapSupport = {}
+        for tr in self.__Database:
+            for i in range(0, len(tr)):
+                if tr[i] not in self.__mapSupport:
+                    self.__mapSupport[tr[i]] = 1
                 else:
-                    s = 1
-                    check = self._check(i, x)
-                    if check == 1:
-                        for j in i:
-                            if j.item in x:
-                                s *= j.probability
-                        if x in periods:
-                            periods[x] += s
-                        else:
-                            periods[x] = s
-        for x, y in periods.items():
-            if y >= self._minSup:
-                sample = str()
-                for i in x:
-                    sample = sample + i + "\t"
-                self._finalPatterns[sample] = y
+                    self.__mapSupport[tr[i]] += 1
+        self.__mapSupport = {k: v for k, v in self.__mapSupport.items() if v >= self._minSup}
+        genList = [k for k, v in sorted(self.__mapSupport.items(), key=lambda x: x[1], reverse=True)]
+        self.__rank = dict([(index, item) for (item, index) in enumerate(genList)])
+        return genList
+
+    def __updateTransactions(self, itemSet):
+        """
+        Updates the items in transactions with rank of items according to their support
+
+        :Example: oneLength = {'a':7, 'b': 5, 'c':'4', 'd':3}
+                    rank = {'a':0, 'b':1, 'c':2, 'd':3}
+
+        Parameters
+        ----------
+        itemSet: list of one-frequent items
+
+        -------
+
+        """
+        list1 = []
+        for tr in self.__Database:
+            list2 = []
+            for i in range(len(tr)):
+                if tr[i] in itemSet:
+                    list2.append(self.__rank[tr[i]])
+            if len(list2) >= 1:
+                list2.sort()
+                list1.append(list2)
+        return list1
 
     @staticmethod
-    def _Intersection(tidSetx, tidSetY):
-        tids = []
-        support = []
-        tidDict = {}
-        for x, y in tidSetx.items():
-            for x1, y1 in tidSetY.items():
-                if x == x1:
-                    tids.append(x)
-                    support.append(y * y1)
-                    tidDict.update({x: y * y1})
-        return tidDict
-
-    def _calculateExpSup(self, tidList):
-        return sum(tidList.values())
-
-    def _save(self, prefix, suffix, tidSetI):
-        """Saves the patterns that satisfy the periodic frequent property.
-            :param prefix: the prefix of a pattern
-            :type prefix: list
-            :param suffix: the suffix of a patterns
-            :type suffix: list
-            :param tidSetI: the timestamp of a patterns
-            :type tidSetI: dict
-        """
-
-        global _finalPatterns
-        if prefix is None:
-            prefix = suffix
-        else:
-            prefix = prefix + suffix
-        val = self._calculateExpSup(tidSetI)
-        _finalPatterns[tuple(prefix)] = val
-
-    def _Generation(self, prefix, itemSets, tidSets):
-        """Equivalence class is followed  and checks for the patterns generated for periodic-frequent patterns.
-            :param prefix:  main equivalence prefix
-            :type prefix: periodic-frequent item or pattern
-            :param itemSets: patterns which are items combined with prefix and satisfying the periodicity
-                            and frequent with their timestamps
-            :type itemSets: list
-            :param tidSets: timestamps of the items in the argument itemSets
-            :type tidSets: list
-                    """
-        if len(itemSets) == 1:
-            i = itemSets[0]
-            tidI = tidSets[0]
-            self._save(prefix, [i], tidI)
-            return
-        for i in range(len(itemSets)):
-            itemI = itemSets[i]
-            if itemI is None:
-                continue
-            tidSetI = tidSets[i]
-            classItemSets = []
-            classTidSets = []
-            itemSetX = [itemI]
-            for j in range(i + 1, len(itemSets)):
-                itemJ = itemSets[j]
-                tidSetJ = tidSets[j]
-                y = self._Intersection(tidSetI, tidSetJ)
-                if self._calculateExpSup(y) >= self._minSup:
-                    classItemSets.append(itemJ)
-                    classTidSets.append(y)
-            newPrefix = list(set(itemSetX)) + prefix
-            self._Generation(newPrefix, classItemSets, classTidSets)
-            self._save(prefix, list(set(itemSetX)), tidSetI)
+    def __buildTree(transactions, info):
+        """
+        Builds the tree with updated transactions
+        Parameters:
+        ----------
+            transactions: updated transactions
+            info: support details of each item in transactions
+
+        Returns:
+        -------
+            transactions compressed in fp-tree
+
+        """
+        rootNode = _Tree()
+        rootNode.info = info.copy()
+        for i in range(len(transactions)):
+            rootNode.addTransaction(transactions[i], 1)
+        return rootNode
+
+    def __savePeriodic(self, itemSet):
+        """
+        The duplication items and their ranks
+        Parameters:
+        ----------
+            itemSet: frequent itemSet that generated
+
+        Returns:
+        -------
+            patterns with original item names.
+
+        """
+        temp = str()
+        for i in itemSet:
+            temp = temp + self.__rankDup[i] + "\t"
+        return temp
 
     def startMine(self):
-        """Main method where the patterns are mined by constructing tree and remove the remove the false patterns
-            by counting the original support of a patterns
+        """
+            main program to start the operation
+
         """
         global _minSup
-        self._startTime = _ab._time.time()
-        self._creatingItemSets()
-        self._minSup = self._convert(self._minSup)
+        self.__startTime = _fp._time.time()
+        if self._iFile is None:
+            raise Exception("Please enter the file path or file name:")
+        if self._minSup is None:
+            raise Exception("Please enter the Minimum Support")
+        self.__creatingItemSets()
+        self._minSup = self.__convert(self._minSup)
         _minSup = self._minSup
-        plist = self._frequentOneItem()
-        for i in range(len(plist)):
-            itemI = plist[i]
-            tidSetI = self._tidList[itemI]
-            itemSetX = [itemI]
-            itemSets = []
-            tidSets = []
-            for j in range(i+1, len(plist)):
-                itemJ = plist[j]
-                tidSetJ = self._tidList[itemJ]
-                y1 = self._Intersection(tidSetI, tidSetJ)
-                if self._calculateExpSup(y1) >= self._minSup:
-                    itemSets.append(itemJ)
-                    tidSets.append(y1)
-            self._Generation(itemSetX, itemSets, tidSets)
-            self._save(None, itemSetX, tidSetI)
-        self._removeFalsePositives()
-        print("Frequent patterns were generated from uncertain databases successfully using PUF algorithm")
-        self._endTime = _ab._time.time()
-        process = _ab._psutil.Process(_ab._os.getpid())
-        self._memoryRSS = float()
-        self._memoryUSS = float()
-        self._memoryUSS = process.memory_full_info().uss
-        self._memoryRSS = process.memory_info().rss
+        itemSet = self.__frequentOneItem()
+        updatedTransactions = self.__updateTransactions(itemSet)
+        for x, y in self.__rank.items():
+            self.__rankDup[y] = x
+        info = {self.__rank[k]: v for k, v in self.__mapSupport.items()}
+        __Tree = self.__buildTree(updatedTransactions, info)
+        patterns = __Tree.generatePatterns([])
+        self.__finalPatterns = {}
+        for k in patterns:
+            s = self.__savePeriodic(k[0])
+            self.__finalPatterns[str(s)] = k[1]
+        print("Frequent patterns were generated successfully using frequentPatternGrowth algorithm")
+        self.__endTime = _fp._time.time()
+        self.__memoryUSS = float()
+        self.__memoryRSS = float()
+        process = _fp._psutil.Process(_fp._os.getpid())
+        self.__memoryUSS = process.memory_full_info().uss
+        self.__memoryRSS = process.memory_info().rss
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
+
         :return: returning USS memory consumed by the mining process
+
         :rtype: float
         """
 
-        return self._memoryUSS
+        return self.__memoryUSS
 
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the mining process will be retrieved from this function
+
         :return: returning RSS memory consumed by the mining process
+
         :rtype: float
         """
 
-        return self._memoryRSS
+        return self.__memoryRSS
 
     def getRuntime(self):
         """Calculating the total amount of runtime taken by the mining process
+
+
         :return: returning total amount of runtime taken by the mining process
+
         :rtype: float
         """
 
-        return self._endTime - self._startTime
+        return self.__endTime - self.__startTime
 
     def getPatternsAsDataFrame(self):
         """Storing final frequent patterns in a dataframe
+
         :return: returning frequent patterns in a dataframe
+
         :rtype: pd.DataFrame
         """
 
         dataframe = {}
         data = []
-        for a, b in self._finalPatterns.items():
+        for a, b in self.__finalPatterns.items():
             data.append([a.replace('\t', ' '), b])
-            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
+            dataframe = _fp._pd.DataFrame(data, columns=['Patterns', 'Support'])
         return dataframe
 
-    def save(self, oFile):
+    def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
-        :param oFile: name of the output file
-        :type oFile: file
+
+        :param outFile: name of the output file
+
+        :type outFile: file
         """
-        self.oFile = oFile
-        writer = open(self.oFile, 'w+')
-        for x, y in self._finalPatterns.items():
+        self._oFile = outFile
+        writer = open(self._oFile, 'w+')
+        for x, y in self.__finalPatterns.items():
             s1 = x.strip() + ":" + str(y)
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
+
         :return: returning frequent patterns
+
         :rtype: dict
         """
-        return self._finalPatterns
+        return self.__finalPatterns
 
     def printResults(self):
-        print("Total number of  Uncertain Frequent Patterns:", len(self.getPatterns()))
+        print("Total number of Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
-        print("Total ExecutionTime in ms:",  self.getRuntime())
+        print("Total ExecutionTime in ms:", self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:
-        if len(_ab._sys.argv) == 5:
-            _ap = UVEclat(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
-        if len(_ab._sys.argv) == 4:
-            _ap = UVEclat(_ab._sys.argv[1], _ab._sys.argv[3])
+    if len(_fp._sys.argv) == 7 or len(_fp._sys.argv) == 8:
+        if len(_fp._sys.argv) == 8:
+            _ap = FTFPGrowth(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4],
+                             _fp._sys.argv[5], _fp._sys.argv[6], _fp._sys.argv[7])
+        if len(_fp._sys.argv) == 7:
+            _ap = FTFPGrowth(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4], _fp._sys.argv[5], _fp._sys.argv[6])
         _ap.startMine()
-        print("Total number of Patterns:", len(_ap.getPatterns()))
-        _ap.save(_ab._sys.argv[2])
+        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
+        _ap.save(_fp._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
-        print("Error! The number of input parameters do not match the total number of parameters provided")
+        print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/uncertainFrequentPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/uncertainFrequentPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/__init__.py` & `pami-2023.5.1/PAMI/uncertainPeriodicFrequentPattern/__init__.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/basic/UPFPGrowth.py` & `pami-2023.5.1/PAMI/weightedFrequentRegularPattern/basic/WFRIMiner.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,732 +1,679 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     from PAMI.weightedFrequentRegularpattern.basic import WFRIMiner as alg
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     obj = alg.WFRIMiner(iFile, WS, regularity)
+#
+#     obj.startMine()
+#
+#     weightedFrequentRegularPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(weightedFrequentRegularPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternInDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
 
-from PAMI.uncertainPeriodicFrequentPattern.basic import abstract as _ab
 
-_minSup = float()
-__maxPer = float()
-__first = int()
-_last = int()
-__lno = int()
-#rank = {}
-#periodic = {}
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
 
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
 
-class _Item:
-    """
-    A class used to represent the item with probability in transaction of dataset
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
 
-        ...
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
 
-        Attributes:
-        __________
-            item: int or word
-                Represents the name of the item
-            probability: float
-                Represent the existential probability(likelihood presence) of an item
-    """
+"""
 
-    def __init__(self, item, probability):
-        self.item = item
-        self.probability = probability
+from PAMI.weightedFrequentRegularPattern.basic import abstract as _fp
 
+_WS = str()
+_regularity = str()
+_lno = int()
+_weights = {}
+_wf = {}
+_fp._sys.setrecursionlimit(20000)
 
-class _Node(object):
+
+class _Node:
     """
         A class used to represent the node of frequentPatternTree
 
-        ...
+    Attributes:
+    ----------
+        itemId: int
+            storing item of a node
+        counter: int
+            To maintain the support of node
+        parent: node
+            To maintain the parent of node
+        children: list
+            To maintain the children of node
 
-        Attributes:
-        ----------
-            item: int
-                storing item of a node
-            probability: int
-                To maintain the expected support of node
-            parent: node
-                To maintain the parent of every node
-            children: list
-                To maintain the children of node
-            timeStamps: list
-                To maintain the timeStamps of node
+    Methods:
+    -------
 
-        Methods:
-        -------
-            addChild(itemName)
-                storing the children to their respective parent nodes
-        """
+        addChild(node)
+            Updates the nodes children list and parent for the given node
+
+    """
 
     def __init__(self, item, children):
+        """ Initializing the Node class
+
+        :param item: Storing the item of a node
+        :type item: int or None
+        :param children: To maintain the children of a node
+        :type children: dict
+        """
+
         self.item = item
-        self.probability = 1
         self.children = children
         self.parent = None
         self.timeStamps = []
 
     def addChild(self, node):
-        """
-        To add the children details to parent node
-
-        :param node: children node
+        """ To add the children to a node
 
-        :return: updated parent node children
+            :param node: parent node in the tree
         """
+
         self.children[node.item] = node
         node.parent = self
 
 
-def _printTree(root):
+class _Tree:
     """
-    To print the details of tree
+    A class used to represent the frequentPatternGrowth tree structure
 
-    :param root: root node of the tree
+    Attributes:
+    ----------
+        root : Node
+            The first node of the tree set to Null.
+        summaries : dictionary
+            Stores the nodes itemId which shares same itemId
+        info : dictionary
+            frequency of items in the transactions
 
-    :return: details of tree
-    """
-    for x, y in root.children.items():
-        print(x, y.item, y.probability, y.parent.item, y.timeStamps)
-        _printTree(y)
-
-
-class _Tree(object):
+    Methods:
+    -------
+        addTransaction(transaction, freq)
+            adding items of  transactions into the tree as nodes and freq is the count of nodes
+        getFinalConditionalPatterns(node)
+            getting the conditional patterns from fp-tree for a node
+        getConditionalPatterns(patterns, frequencies)
+            sort the patterns by removing the items with lower minSup
+        generatePatterns(prefix)
+            generating the patterns from fp-tree
     """
-        A class used to represent the frequentPatternGrowth tree structure
-
-        ...
-
-        Attributes:
-        ----------
-            root : Node
-                Represents the root node of the tree
-            summaries : dictionary
-                storing the nodes with same item name
-            info : dictionary
-                stores the support of items
-
-
-        Methods:
-        -------
-            addTransactions(transaction)
-                creating transaction as a branch in frequentPatternTree
-            addConditionalTransaction(prefixPaths, supportOfItems)
-                construct the conditional tree for prefix paths
-            conditionalPatterns(Node)
-                generates the conditional patterns from tree for specific node
-            conditionalTransactions(prefixPaths,Support)
-                takes the prefixPath of a node and support at child of the path and extract the frequent items from
-                prefixPaths and generates prefixPaths with items which are frequent
-            remove(Node)
-                removes the node from tree once after generating all the patterns respective to the node
-            generatePatterns(Node)
-                starts from the root node of the tree and mines the frequent patterns
-
-        """
 
     def __init__(self):
         self.root = _Node(None, {})
         self.summaries = {}
         self.info = {}
 
-    def addTransactions(self, transaction, tid):
-        """adding transaction into tree
-
-            :param transaction: it represents the one transactions in database
-
-            :type transaction: list
-
-            :param tid: the timestamp of transaction
+    def addTransaction(self, transaction, tid):
+        """     Adding a transaction into tree
 
-            :type tid: list
+                :param transaction: To represent the complete database
+                :type transaction: list
+                :param tid: To represent the timestamp of a database
+                :type tid: list
+                :return: pfp-growth tree
         """
-        currentNode = self.root
-        for i in range(len(transaction)):
-            if transaction[i].item not in currentNode.children:
-                newNode = _Node(transaction[i].item, {})
-                l1 = i - 1
-                temp = []
-                while l1 >= 0:
-                    temp.append(transaction[l1].probability)
-                    l1 -= 1
-                if len(temp) == 0:
-                    newNode.probability = transaction[i].probability
-                else:
-                    newNode.probability = max(temp) * transaction[i].probability
-                currentNode.addChild(newNode)
-                if transaction[i].item in self.summaries:
-                    self.summaries[transaction[i].item].append(newNode)
-                else:
-                    self.summaries[transaction[i].item] = [newNode]
-                currentNode = newNode
-            else:
-                currentNode = currentNode.children[transaction[i].item]
-                l1 = i - 1
-                temp = []
-                while l1 >= 0:
-                    temp.append(transaction[l1].probability)
-                    l1 -= 1
-                if len(temp) == 0:
-                    currentNode.probability += transaction[i].probability
-                else:
-                    currentNode.probability += max(temp) * transaction[i].probability
-        currentNode.timeStamps = currentNode.timeStamps + tid
-
-    def addConditionalTransaction(self, transaction, ts, sup):
-        """constructing conditional tree from prefixPaths
-
-                :param transaction : it represents the one transactions in database
 
-                :type transaction : list
-
-                :param ts: timeStamp of a transaction
-
-                :type ts: list
-
-                :param sup : support of prefixPath taken at last child of the path
-
-                :type sup : int
-        """
         currentNode = self.root
         for i in range(len(transaction)):
             if transaction[i] not in currentNode.children:
                 newNode = _Node(transaction[i], {})
-                newNode.probability = sup
                 currentNode.addChild(newNode)
                 if transaction[i] in self.summaries:
                     self.summaries[transaction[i]].append(newNode)
                 else:
                     self.summaries[transaction[i]] = [newNode]
                 currentNode = newNode
             else:
                 currentNode = currentNode.children[transaction[i]]
-                currentNode.probability += sup
-        currentNode.timeStamps = currentNode.timeStamps + ts
-
-    def getConditionalPatterns(self, alpha):
-        """generates all the conditional patterns of respective node
+        currentNode.timeStamps = currentNode.timeStamps + tid
 
-            :param alpha : it represents the Node in tree
+    def getConditionalPatterns(self, alpha, pattern):
+        """Generates all the conditional patterns of a respective node
 
-            :type alpha : Node
+            :param alpha: To represent a Node in the tree
+            :type alpha: Node
+            :param pattern: prefix of the pattern
+            :type alpha: list
+            :return: A tuple consisting of finalPatterns, conditional pattern base and information
         """
-
         finalPatterns = []
-        finalTimeStamps = []
-        sup = []
+        finalSets = []
         for i in self.summaries[alpha]:
             set1 = i.timeStamps
-            s = i.probability
             set2 = []
             while i.parent.item is not None:
                 set2.append(i.parent.item)
                 i = i.parent
             if len(set2) > 0:
                 set2.reverse()
                 finalPatterns.append(set2)
-                finalTimeStamps.append(set1)
-                sup.append(s)
-        finalPatterns, finalTimeStamps, support, info = self.conditionalTransactions(finalPatterns, finalTimeStamps,
-                                                                                     sup)
-        return finalPatterns, finalTimeStamps, support, info
+                finalSets.append(set1)
+        finalPatterns, finalSets, info = self.conditionalDatabases(finalPatterns, finalSets, pattern)
+        return finalPatterns, finalSets, info
 
-    def removeNode(self, nodeValue):
-        """removing the node from tree
+    @staticmethod
+    def generateTimeStamps(node):
+        """To get the timestamps of a node
+
+        :param node: A node in the tree
+        :return: Timestamps of a node
+        """
+
+        finalTimeStamps = node.timeStamps
+        return finalTimeStamps
 
-            :param nodeValue : it represents the node in tree
+    def removeNode(self, nodeValue):
+        """ Removing the node from tree
 
-            :type nodeValue : node
+            :param nodeValue: To represent a node in the tree
+            :type nodeValue: node
+            :return: Tree with their nodes updated with timestamps
         """
+
         for i in self.summaries[nodeValue]:
             i.parent.timeStamps = i.parent.timeStamps + i.timeStamps
             del i.parent.children[nodeValue]
 
-    def getPeriodAndSupport(self, s, timeStamps):
-        global _lno, _maxPer
-        timeStamps.sort()
-        cur = 0
-        per = 0
-        sup = s
-        for j in range(len(timeStamps)):
-            per = max(per, timeStamps[j] - cur)
-            if per > _maxPer:
-                return [0, 0]
-            cur = timeStamps[j]
-        per = max(per, _lno - cur)
-        return [sup, per]
-
-    def conditionalTransactions(self, condPatterns, condTimeStamps, support):
-        """ It generates the conditional patterns with frequent items
-
-                :param condPatterns : conditional patterns generated from getConditionalPatterns method for respective node
-
-                :type condPatterns : list
+    def getTimeStamps(self, alpha):
+        """ To get all the timestamps of the nodes which share same item name
 
-                :param condTimeStamps: timeStamps of conditional transactions
+            :param alpha: Node in a tree
+            :return: Timestamps of a  node
+        """
+        temporary = []
+        for i in self.summaries[alpha]:
+            temporary += i.timeStamps
+        return temporary
 
-                :type condTimeStamps: list
+    @staticmethod
+    def getSupportAndPeriod(timeStamps, pattern):
+        """To calculate the periodicity and support
 
-                :param support : the support of conditional pattern in tree
+        :param timeStamps: Timestamps of an item set
+        :type timeStamps: list
+        :param pattern: pattern to evaluate the weighted frequent regular or not
+        :type pattern: list
+        :return: support, periodicity
+        """
 
-                :type support : list
+        global _WS, _regularity, _lno, _weights
+        timeStamps.sort()
+        cur = 0
+        per = list()
+        sup = 0
+        for j in range(len(timeStamps)):
+            per.append(timeStamps[j] - cur)
+            cur = timeStamps[j]
+            sup += 1
+        per.append(_lno - cur)
+        l = int()
+        for i in pattern:
+            l = l + _weights[i]
+        wf = (l / (len(pattern))) * sup
+        if len(per) == 0:
+            return [0, 0]
+        return [sup, max(per), wf]
+
+    def conditionalDatabases(self, conditionalPatterns, conditionalTimeStamps, pattern):
+        """ It generates the conditional patterns with periodic-frequent items
+
+            :param conditionalPatterns: conditionalPatterns generated from conditionPattern method of a respective node
+            :type conditionalPatterns: list
+            :param conditionalTimeStamps: Represents the timestamps of a conditional patterns of a node
+            :type conditionalTimeStamps: list
+            :param pattern: prefix of the pattern
+            :type pattern: list
+            :returns: Returns conditional transactions by removing non-periodic and non-frequent items
         """
-        global _minSup, _maxPer
+
+        global _WS, _regularity
         pat = []
         timeStamps = []
-        sup = []
         data1 = {}
-        count = {}
-        for i in range(len(condPatterns)):
-            for j in condPatterns[i]:
+        for i in range(len(conditionalPatterns)):
+            for j in conditionalPatterns[i]:
                 if j in data1:
-                    data1[j] = data1[j] + condTimeStamps[i]
-                    count[j] += support[i]
+                    data1[j] = data1[j] + conditionalTimeStamps[i]
                 else:
-                    data1[j] = condTimeStamps[i]
-                    count[j] = support[i]
-        updatedDict = {}
+                    data1[j] = conditionalTimeStamps[i]
+        updatedDictionary = {}
         for m in data1:
-            updatedDict[m] = self.getPeriodAndSupport(count[m], data1[m])
-        updatedDict = {k: v for k, v in updatedDict.items() if v[0] >= _minSup and v[1] <= _maxPer}
+            updatedDictionary[m] = self.getSupportAndPeriod(data1[m], pattern + [m])
+        updatedDictionary = {k: v for k, v in updatedDictionary.items() if v[0] >= _WS and v[1] <= _regularity}
         count = 0
-        for p in condPatterns:
-            p1 = [v for v in p if v in updatedDict]
-            trans = sorted(p1, key=lambda x: (updatedDict.get(x)[0]), reverse=True)
+        for p in conditionalPatterns:
+            p1 = [v for v in p if v in updatedDictionary]
+            trans = sorted(p1, key=lambda x: (updatedDictionary.get(x)[0], -x), reverse=True)
             if len(trans) > 0:
                 pat.append(trans)
-                timeStamps.append(condTimeStamps[count])
-                sup.append(support[count])
+                timeStamps.append(conditionalTimeStamps[count])
             count += 1
-        return pat, timeStamps, sup, updatedDict
+        return pat, timeStamps, updatedDictionary
 
-    def generatePatterns(self, prefix, periodic):
-        """generates the patterns
+    def generatePatterns(self, prefix):
+        """ Generates the patterns
 
-            :param prefix : forms the combination of items
-
-            :type prefix : list
+            :param prefix: Forms the combination of items
+            :type prefix: list
+            :returns: yields patterns with their support and periodicity
         """
-
-        global _minSup
-        for i in sorted(self.summaries, key=lambda x: (self.info.get(x)[0])):
+        global _WS
+        for i in sorted(self.summaries, key=lambda x: (self.info.get(x)[0], -x)):
             pattern = prefix[:]
             pattern.append(i)
-            s = 0
-            for x in self.summaries[i]:
-                s += x.probability
-            periodic[tuple(pattern)] = self.info[i]
-            if s >= _minSup:
-                patterns, timeStamps, support, info = self.getConditionalPatterns(i)
+            if self.info[i][2] >= _WS:
+                yield pattern, self.info[i]
+                patterns, timeStamps, info = self.getConditionalPatterns(i, pattern)
                 conditionalTree = _Tree()
                 conditionalTree.info = info.copy()
                 for pat in range(len(patterns)):
-                    conditionalTree.addConditionalTransaction(patterns[pat], timeStamps[pat], support[pat])
+                    conditionalTree.addTransaction(patterns[pat], timeStamps[pat])
                 if len(patterns) > 0:
-                    conditionalTree.generatePatterns(pattern, periodic)
+                    for q in conditionalTree.generatePatterns(pattern):
+                        yield q
             self.removeNode(i)
 
 
-class UPFPGrowth(_ab._periodicFrequentPatterns):
+class WFRIMiner(_fp._weightedFrequentRegularPatterns):
     """
+       WFRIMiner is one of the fundamental algorithm to discover weighted frequent regular patterns in a transactional database.
+       It stores the database in compressed WFRI-tree decreasing the memory usage and extracts the
+       patterns from tree.It employs employs downward closure property to  reduce the search space effectively.
+
+    Reference :
+    ---------
+           K. Klangwisan and K. Amphawan, "Mining weighted-frequent-regular itemsets from transactional database,"
+           2017 9th International Conference on Knowledge and Smart Technology (KST), 2017, pp. 66-71,
+           doi: 10.1109/KST.2017.7886090.
+
+    Attributes :
+    ----------
+        iFile : file
+            Input file name or path of the input file
+        WS: float or int or str
+            The user can specify WS either in count or proportion of database size.
+            If the program detects the data type of WS is integer, then it treats WS is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: WS=10 will be treated as integer, while WS=10.0 will be treated as float
+        regularity: float or int or str
+            The user can specify regularity either in count or proportion of database size.
+            If the program detects the data type of regularity is integer, then it treats regularity is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: regularity=10 will be treated as integer, while regularity=10.0 will be treated as float
+        sep : str
+            This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
+            However, the users can override their default separator.
+        oFile : file
+            Name of the output file or the path of the output file
+        startTime:float
+            To record the start time of the mining process
+        endTime:float
+            To record the completion time of the mining process
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
+        Database : list
+            To store the transactions of a database in list
+        mapSupport : Dictionary
+            To maintain the information of item and their frequency
+        lno : int
+            it represents the total no of transactions
+        tree : class
+            it represents the Tree class
+        finalPatterns : dict
+            it represents to store the patterns
 
-        UPFPGrowth is  to discover periodic-frequent patterns in a uncertain temporal database.
-
-        Reference:
-        --------
-            Uday Kiran, R., Likhitha, P., Dao, MS., Zettsu, K., Zhang, J. (2021).
-            Discovering Periodic-Frequent Patterns in Uncertain Temporal Databases. In:
-            Mantoro, T., Lee, M., Ayu, M.A., Wong, K.W., Hidayanto, A.N. (eds) Neural Information Processing.
-            ICONIP 2021. Communications in Computer and Information Science, vol 1516. Springer, Cham.
-            https://doi.org/10.1007/978-3-030-92307-5_83
+    Methods :
+    -------
+        startMine()
+            Mining process will start from here
+        getPatterns()
+            Complete set of patterns will be retrieved with this function
+        save(oFile)
+            Complete set of frequent patterns will be loaded in to a output file
+        getPatternsAsDataFrame()
+            Complete set of frequent patterns will be loaded in to a dataframe
+        getMemoryUSS()
+            Total amount of USS memory consumed by the mining process will be retrieved from this function
+        getMemoryRSS()
+            Total amount of RSS memory consumed by the mining process will be retrieved from this function
+        getRuntime()
+            Total amount of runtime taken by the mining process will be retrieved from this function
+        creatingItemSets()
+            Scans the dataset or dataframes and stores in list format
+        frequentOneItem()
+            Extracts the one-frequent patterns from transactions
 
-        Attributes:
-        ----------
-            iFile : file
-                Name of the Input file or path of the input file
-            oFile : file
-                Name of the output file or path of output file
-            minSup: int or float or str
-                The user can specify minSup either in count or proportion of database size.
-                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-            maxPer: int or float or str
-                The user can specify maxPer either in count or proportion of database size.
-                If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
-            sep: str
-                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                However, the users can override their default separator.
-            memoryUSS: float
-                To store the total amount of USS memory consumed by the program
-            memoryRSS: float
-                To store the total amount of RSS memory consumed by the program
-            startTime: float
-                To record the start time of the mining process
-            endTime: float
-                To record the completion time of the mining process
-            Database : list
-                To store the transactions of a database in list
-            mapSupport : Dictionary
-                To maintain the information of item and their frequency
-            _lno : int
-                To represent the total no of transaction
-            tree : class
-                To represents the Tree class
-            finalPatterns : dict
-                To store the complete patterns
 
-        Methods:
-        -------
-            startMine()
-                Mining process will start from here
-            getPatterns()
-                Complete set of patterns will be retrieved with this function
-            save(oFile)
-                Complete set of periodic-frequent patterns will be loaded in to a output file
-            getPatternsAsDataFrame()
-                Complete set of periodic-frequent patterns will be loaded in to a dataframe
-            getMemoryUSS()
-                Total amount of USS memory consumed by the mining process will be retrieved from this function
-            getMemoryRSS()
-                Total amount of RSS memory consumed by the mining process will be retrieved from this function
-            getRuntime()
-                Total amount of runtime taken by the mining process will be retrieved from this function
-            creatingItemSets()
-                Scans the dataset and stores in a list format
-            PeriodicFrequentOneItem()
-                Extracts the one-periodic-frequent patterns from database
-            updateTransaction()
-                Update the database by removing aperiodic items and sort the Database by item decreased support
-            buildTree()
-                After updating the Database, remaining items will be added into the tree by setting root node as null
-            convert()
-                to convert the user specified value
-            removeFalsePositives()
-                to remove the false positives in generated patterns
+    **Methods to execute code on terminal**
 
-        Executing the code on terminal:
-        -------
             Format:
-            ------
-                python3 UPFPGrowth.py <inputFile> <outputFile> <minSup> <maxPer>
-            Examples:
-            --------
-                python3 UPFPGrowth.py sampleTDB.txt patterns.txt 0.3 4     (minSup and maxPer will be considered in support count or frequency)
+                      >>> python3 WFRIMiner.py <inputFile> <outputFile> <weightSupport> <regularity>
+            Example:
+                      >>>  python3 WFRIMiner.py sampleDB.txt patterns.txt 10 5
+
+                     .. note:: WS & regularity will be considered in support count or frequency
 
-        Sample run of importing the code:
-        -------------------
+    **Importing this algorithm into a python program**
 
-            from PAMI.uncertainPeriodicFrequentPattern import UPFPGrowth as alg
+    .. code-block:: python
 
-            obj = alg.UPFPGrowth(iFile, minSup, maxPer)
+            from PAMI.weightedFrequentRegularpattern.basic import WFRIMiner as alg
+
+            obj = alg.WFRIMiner(iFile, WS, regularity)
 
             obj.startMine()
 
-            periodicFrequentPatterns = obj.getPatterns()
+            weightedFrequentRegularPatterns = obj.getPatterns()
 
-            print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+            print("Total number of Frequent Patterns:", len(weightedFrequentRegularPatterns))
 
-            obj.save(oFile)
+            obj.savePatterns(oFile)
 
-            Df = obj.getPatternsAsDataFrame()
+            Df = obj.getPatternInDataFrame()
 
             memUSS = obj.getMemoryUSS()
 
             print("Total Memory in USS:", memUSS)
 
             memRSS = obj.getMemoryRSS()
 
             print("Total Memory in RSS", memRSS)
 
             run = obj.getRuntime()
 
             print("Total ExecutionTime in seconds:", run)
 
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+    **Credits:**
+
+             The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+
+        """
 
-    """
-    _rank = {}
     _startTime = float()
     _endTime = float()
-    _minSup = float()
-    _maxPer = float()
+    _WS = str()
+    _regularity = str()
+    _weight = {}
     _finalPatterns = {}
+    _wFile = " "
     _iFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
+    _mapSupport = {}
     _lno = 0
-    _periodic = {}
+    _tree = _Tree()
+    _rank = {}
+    _rankDup = {}
+
+    def __init__(self, iFile, _wFile, WS, regularity, sep='\t'):
+        super().__init__(iFile, _wFile, WS, regularity, sep)
 
     def _creatingItemSets(self):
         """
             Storing the complete transactions of the database/input file in a database variable
 
+
         """
         self._Database = []
-        if isinstance(self._iFile, _ab._pd.DataFrame):
-            uncertain, data, ts = [], [], []
+        self._weight = {}
+        if isinstance(self._iFile, _fp._pd.DataFrame):
             if self._iFile.empty:
                 print("its empty..")
-            i = self._iFile._columns.values.tolist()
-            if 'TS' in i:
-                ts = self._iFile['TS'].tolist()
+            i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
-                data = self._iFile['Transactions'].tolist()
-            if 'uncertain' in i:
-                uncertain = self._iFile['uncertain'].tolist()
-            for k in range(len(data)):
-                tr = [ts[k]]
-                for j in range(len(k)):
-                    product = _Item(data[k][j], uncertain[k][j])
-                    tr.append(product)
-                self._Database.append(tr)
-                self._lno += 1
+                self._Database = self._iFile['Transactions'].tolist()
+
+        if isinstance(self._wFile, _fp._pd.DataFrame):
+            _items, _weights = [], []
+            if self._wFile.empty:
+                print("its empty..")
+            i = self._wFile.columns.values.tolist()
+            if 'items' in i:
+                _items = self._wFile['items'].tolist()
+            if 'weight' in i:
+                _weights = self._wFile['weight'].tolist()
+            for i in range(len(_items)):
+                self._weight[_items[i]] = _weights[i]
 
             # print(self.Database)
         if isinstance(self._iFile, str):
-            if _ab._validators.url(self._iFile):
-                data = _ab._urlopen(self._iFile)
+            if _fp._validators.url(self._iFile):
+                data = _fp._urlopen(self._iFile)
                 for line in data:
+                    line.strip()
                     line = line.decode("utf-8")
-                    line = line.strip()
-                    line = [i for i in line.split(':')]
-                    temp1 = [i.rstrip() for i in line[0].split(self._sep)]
-                    temp2 = [i.rstrip() for i in line[1].split(self._sep)]
-                    temp1 = [x for x in temp1 if x]
-                    temp2 = [x for x in temp2 if x]
-                    tr = [int(temp1[0])]
-                    for i in range(len(temp1[1:])):
-                        item = temp1[i]
-                        probability = float(temp2[i])
-                        product = _Item(item, probability)
-                        tr.append(product)
-                    self._lno += 1
-                    self._Database.append(tr)
+                    temp = [i.rstrip() for i in line.split(self._sep)]
+                    temp = [x for x in temp if x]
+                    self._Database.append(temp)
             else:
                 try:
-                    count = 0
-                    with open(self._iFile, 'r') as f:
+                    with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
-                            #count += 1
-                            line = line.strip()
-                            line = [i for i in line.split(':')]
-                            temp1 = [i.rstrip() for i in line[0].split(self._sep)]
-                            temp2 = [i.rstrip() for i in line[1].split(self._sep)]
-                            temp1 = [x for x in temp1 if x]
-                            temp2 = [x for x in temp2 if x]
-                            tr = [int(temp1[0])]
-                            for i in range(len(temp1[1:])):
-                                item = temp1[i]
-                                probability = float(temp2[i])
-                                product = _Item(item, probability)
-                                tr.append(product)
-                            self._lno += 1
-                            self._Database.append(tr)
+                            line.strip()
+                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            temp = [x for x in temp if x]
+                            self._Database.append(temp)
                 except IOError:
                     print("File Not Found")
+                    quit()
 
-    def _periodicFrequentOneItem(self):
-        """takes the transactions and calculates the support of each item in the dataset and assign the
-                    ranks to the items by decreasing support and returns the frequent items list
+        if isinstance(self._wFile, str):
+            if _fp._validators.url(self._wFile):
+                data = _fp._urlopen(self._wFile)
+                for line in data:
+                    line.strip()
+                    line = line.decode("utf-8")
+                    temp = [i.rstrip() for i in line.split(self._sep)]
+                    temp = [x for x in temp if x]
+                    self._weight[temp[0]] = float(temp[1])
+            else:
+                try:
+                    with open(self._wFile, 'r', encoding='utf-8') as f:
+                        for line in f:
+                            line.strip()
+                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            temp = [x for x in temp if x]
+                            self._weight[temp[0]] = float(temp[1])
+                except IOError:
+                    print("File Not Found")
+                    quit()
 
+    def _convert(self, value):
         """
-        mapSupport = {}
-        for i in self._Database:
-            n = i[0]
-            for j in i[1:]:
-                if j.item not in mapSupport:
-                    mapSupport[j.item] = [round(j.probability, 3), abs(0 - n), n]
-                else:
-                    mapSupport[j.item][0] += round(j.probability, 3)
-                    mapSupport[j.item][1] = max(mapSupport[j.item][1], abs(n - mapSupport[j.item][2]))
-                    mapSupport[j.item][2] = n
-        for key in mapSupport:
-            mapSupport[key][1] = max(mapSupport[key][1], self._lno - mapSupport[key][2])
-        mapSupport = {k: [v[0], v[1]] for k, v in mapSupport.items() if v[1] <= self._maxPer and v[0] >= self._minSup}
-        plist = [k for k, v in sorted(mapSupport.items(), key=lambda x: (x[1][0], x[0]), reverse=True)]
-        self._rank = dict([(index, item) for (item, index) in enumerate(plist)])
-        return mapSupport, plist
+        to convert the type of user specified minSup value
 
-    def _check(self, i, x):
-        """To check the presence of item or pattern in transaction
+        :param value: user specified minSup value
 
-            :param x: it represents the pattern
-
-            :type x : list
-
-            :param i : represents the uncertain transactions
-
-            :type i : list
+        :return: converted type
         """
+        if type(value) is int:
+            value = int(value)
+        if type(value) is float:
+            value = (len(self._Database) * value)
+        if type(value) is str:
+            if '.' in value:
+                value = float(value)
+                value = (len(self._Database) * value)
+            else:
+                value = int(value)
+        return value
 
-        for m in x:
-            k = 0
-            for n in i:
-                if m == n.item:
-                    k += 1
-            if k == 0:
-                return 0
-        return 1
-
-    def _getPeriodAndSupport(self, s, timeStamps):
+    def _frequentOneItem(self):
         """
-        To calculate periodicity of timeStamps
-
-            :param s: support of a pattern
-
-            :param timeStamps: timeStamps of a pattern
+        Generating One frequent items sets
 
-            :return: periodicity and Support
         """
-        global __lno, _maxPer
-        timeStamps.sort()
-        cur = 0
-        per = 0
-        sup = s
-        for j in range(len(timeStamps)):
-            per = max(per, timeStamps[j] - cur)
-            if per > _maxPer:
-                return [0, 0]
-            cur = timeStamps[j]
-        per = max(per, _lno - cur)
-        return [sup, per]
-
-    def _buildTree(self, data, info):
-        """it takes the transactions and support of each item and construct the main tree with setting root
-                    node as null
-
-            :param data: it represents the one transactions in database
-
-            :type data: list
-
-            :param info: it represents the support of each item
+        global _lno, _wf, _weights
+        self._mapSupport = {}
+        _owf = {}
+        for tr in self._Database:
+            for i in range(1, len(tr)):
+                if tr[i] not in self._mapSupport:
+                    self._mapSupport[tr[i]] = [int(tr[0]), int(tr[0]), 1]
+                else:
+                    self._mapSupport[tr[i]][0] = max(self._mapSupport[tr[i]][0], (int(tr[0]) - self._mapSupport[tr[i]][1]))
+                    self._mapSupport[tr[i]][1] = int(tr[0])
+                    self._mapSupport[tr[i]][2] += 1
+        for key in self._mapSupport:
+            self._mapSupport[key][0] = max(self._mapSupport[key][0], abs(len(self._Database) - self._mapSupport[key][1]))
+        _lno = len(self._Database)
+        self._mapSupport = {k: [v[2], v[0]] for k, v in self._mapSupport.items() if v[0] <= self._regularity}
+        for x, y in self._mapSupport.items():
+            if self._weight.get(x) is None:
+                self._weight[x] = 0
+        gmax = max([self._weight[values] for values in self._mapSupport.keys()])
+        for x, y in self._mapSupport.items():
+            _owf[x] = y[0] * gmax
+        self._mapSupport = {k: v for k, v in self._mapSupport.items() if v[0] * _owf[k] >= self._WS}
+        for x, y in self._mapSupport.items():
+            temp = self._weight[x] * y[0]
+            _wf[x] = temp
+            self._mapSupport[x].append(temp)
+        genList = [k for k, v in sorted(self._mapSupport.items(), key=lambda x: x[1], reverse= True)]
+        self._rank = dict([(index, item) for (item, index) in enumerate(genList)])
+        for x, y in self._rank.items():
+            _weights[y] = self._weight[x]
+        return genList
 
-            :type info : dictionary
+    def _updateTransactions(self, itemSet):
         """
-        rootNode = _Tree()
-        rootNode.info = info.copy()
-        for i in range(len(data)):
-            set1 = [data[i][0]]
-            rootNode.addTransactions(data[i][1:], set1)
-        return rootNode
+        Updates the items in transactions with rank of items according to their support
 
-    def _updateTransactions(self, dict1):
-        """remove the items which are not frequent from transactions and updates the transactions with rank of items
+        :Example: oneLength = {'a':7, 'b': 5, 'c':'4', 'd':3}
+                    rank = {'a':0, 'b':1, 'c':2, 'd':3}
 
-            :param dict1 : frequent items with support
+        Parameters
+        ----------
+        itemSet: list of one-frequent items
 
-            :type dict1 : dictionary
-        """
+        -------
 
+        """
         list1 = []
         for tr in self._Database:
             list2 = [int(tr[0])]
             for i in range(1, len(tr)):
-                if tr[i].item in dict1:
-                    list2.append(tr[i])
+                if tr[i] in itemSet:
+                    list2.append(self._rank[tr[i]])
             if len(list2) >= 2:
                 basket = list2[1:]
-                basket.sort(key=lambda val: self._rank[val.item])
+                basket.sort()
                 list2[1:] = basket[0:]
                 list1.append(list2)
         return list1
 
-    def _convert(self, value):
+    @staticmethod
+    def _buildTree(transactions, info):
         """
-            To convert the given user specified value
+        Builds the tree with updated transactions
+        Parameters:
+        ----------
+            transactions: updated transactions
+            info: support details of each item in transactions
 
-            :param value: user specified value
+        Returns:
+        -------
+            transactions compressed in fp-tree
 
-            :return: converted value
         """
-        if type(value) is int:
-            value = int(value)
-        if type(value) is float:
-            value = float(value)
-        if type(value) is str:
-            if '.' in value:
-                value = float(value)
-            else:
-                value = int(value)
-
-        return value
+        rootNode = _Tree()
+        rootNode.info = info.copy()
+        for i in range(len(transactions)):
+            set1 = [transactions[i][0]]
+            rootNode.addTransaction(transactions[i][1:], set1)
+        return rootNode
 
-    def _removeFalsePositives(self):
+    def _savePeriodic(self, itemSet):
         """
+        The duplication items and their ranks
+        Parameters:
+        ----------
+            itemSet: frequent itemSet that generated
 
-        Returns
+        Returns:
         -------
-            removes the false positive patterns in generated patterns
+            patterns with original item names.
+
         """
-        periods = {}
-        for i in self._Database:
-            for x, y in self._periodic.items():
-                if len(x) == 1:
-                    periods[x] = y
-                else:
-                    s = 1
-                    check = self._check(i[1:], x)
-                    if check == 1:
-                        for j in i[1:]:
-                            if j.item in x:
-                                s *= j.probability
-                        if x in periods:
-                            periods[x][0] += s
-                        else:
-                            periods[x] = [s, y[1]]
-        for x, y in periods.items():
-            if y[0] >= _minSup:
-                sample = str()
-                for i in x:
-                    sample = sample + i + "\t"
-                self._finalPatterns[sample] = y
+        temp = str()
+        for i in itemSet:
+            temp = temp + self._rankDup[i] + "\t"
+        return temp
 
     def startMine(self):
-        """Main method where the patterns are mined by constructing tree and remove the remove the false patterns
-                    by counting the original support of a patterns
-
+        """
+            main program to start the operation
 
         """
-        global _lno, _maxPer, _minSup, _first, _last, periodic
-        self._startTime = _ab._time.time()
+        global _WS, _regularity, _weights
+        self._startTime = _fp._time.time()
+        if self._iFile is None:
+            raise Exception("Please enter the file path or file name:")
+        if self._WS is None:
+            raise Exception("Please enter the Minimum Support")
         self._creatingItemSets()
+        self._WS = self._convert(self._WS)
+        self._regularity = self._convert(self._regularity)
+        _WS, _regularity, _weights = self._WS, self._regularity, self._weight
+        itemSet = self._frequentOneItem()
+        updatedTransactions = self._updateTransactions(itemSet)
+        for x, y in self._rank.items():
+            self._rankDup[y] = x
+        info = {self._rank[k]: v for k, v in self._mapSupport.items()}
+        _Tree = self._buildTree(updatedTransactions, info)
+        patterns = _Tree.generatePatterns([])
         self._finalPatterns = {}
-        self._minSup = self._convert(self._minSup)
-        self._maxPer = self._convert(self._maxPer)
-        _minSup, _maxPer, _lno = self._minSup, self._maxPer, self._lno
-        mapSupport, plist = self._periodicFrequentOneItem()
-        updatedTrans = self._updateTransactions(mapSupport)
-        info = {k: v for k, v in mapSupport.items()}
-        Tree1 = self._buildTree(updatedTrans, info)
-        self._periodic = {}
-        Tree1.generatePatterns([], self._periodic)
-        self._removeFalsePositives()
-        print("Periodic frequent patterns were generated successfully using UPFP algorithm")
-        self._endTime = _ab._time.time()
-        process = _ab._psutil.Process(_ab._os.getpid())
+        for k in patterns:
+            s = self._savePeriodic(k[0])
+            self._finalPatterns[str(s)] = k[1]
+        print("Weighted Frequent Regular patterns were generated successfully using WFRIM algorithm")
+        self._endTime = _fp._time.time()
         self._memoryUSS = float()
         self._memoryRSS = float()
+        process = _fp._psutil.Process(_fp._os.getpid())
+        self._memoryRSS = float()
+        self._memoryUSS = float()
         self._memoryUSS = process.memory_full_info().uss
         self._memoryRSS = process.memory_info().rss
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
         :return: returning USS memory consumed by the mining process
@@ -745,14 +692,15 @@
         """
 
         return self._memoryRSS
 
     def getRuntime(self):
         """Calculating the total amount of runtime taken by the mining process
 
+
         :return: returning total amount of runtime taken by the mining process
 
         :rtype: float
         """
 
         return self._endTime - self._startTime
 
@@ -763,66 +711,55 @@
 
         :rtype: pd.DataFrame
         """
 
         dataframe = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a.replace('\t', ' '), b[0], b[1]])
-            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Periodicity'])
+            data.append([a.replace('\t', ' '), b])
+            dataframe = _fp._pd.DataFrame(data, columns=['Patterns', 'Support'])
         return dataframe
 
     def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
 
         :type outFile: file
         """
-        self.oFile = outFile
-        writer = open(self.oFile, 'w+')
+        self._oFile = outFile
+        writer = open(self._oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            s1 = x.strip() + ":" + str(y[0]) + ":" + str(y[1])
+            s1 = x.strip() + ":" + str(y)
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
 
         :rtype: dict
         """
         return self._finalPatterns
 
     def printResults(self):
-        print("Total number of  Uncertain Periodic-Frequent Patterns:", len(self.getPatterns()))
+        print("Total number of  Weighted Frequent Regular Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
-        if len(_ab._sys.argv) == 6:
-            _ap = UPFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
-        if len(_ab._sys.argv) == 5:
-            _ap = UPFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+    if len(_fp._sys.argv) == 6 or len(_fp._sys.argv) == 7:
+        if len(_fp._sys.argv) == 7:
+            _ap = WFRIMiner(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4], _fp._sys.argv[5], _fp._sys.argv[6])
+        if len(_fp._sys.argv) == 5:
+            _ap = WFRIMiner(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4], _fp._sys.argv[5])
         _ap.startMine()
-        print("Total number of Uncertain Periodic-Frequent Patterns:", len(_ap.getPatterns()))
-        _ap.save(_ab._sys.argv[2])
-        print("Total Memory in USS:", _ap.getMemoryUSS())
+        print("Total number of Weighted Frequent Regular Patterns:", len(_ap.getPatterns()))
+        _ap.save(_fp._sys.argv[2])
+        print("Total Memory in USS:",  _ap.getMemoryUSS())
         print("Total Memory in RSS", _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
-        ap = UPFPGrowth('/Users/likhitha/Downloads/uncertainTemporal_T10I4D100K.csv', 500, 5000, '\t')
-        ap.startMine()
-        Patterns = ap.getPatterns()
-        print("Total number of Patterns:", len(Patterns))
-        ap.save('/Users/Likhitha/Downloads/uncertain/output.txt')
-        memUSS = ap.getMemoryUSS()
-        print("Total Memory in USS:", memUSS)
-        memRSS = ap.getMemoryRSS()
-        print("Total Memory in RSS", memRSS)
-        run = ap.getRuntime()
-        print("Total ExecutionTime in ms:", run)
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/basic/UPFPGrowthPlus.py` & `pami-2023.5.1/PAMI/uncertainPeriodicFrequentPattern/basic/UPFPGrowthPlus.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,21 +1,58 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     from PAMI.uncertainPeriodicFrequentPattern import UPFPGrowthPlus as alg
+#
+#     obj = alg.UPFPGrowthPlus(iFile, minSup, maxPer)
+#
+#     obj.startMine()
+#
+#     periodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of uncertain Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
 
 
 from PAMI.uncertainPeriodicFrequentPattern.basic import abstract as _ab
 
 _minSup = float()
 _maxPer = float()
 _lno = int()
@@ -358,131 +395,135 @@
                 conditionalTree.info = info.copy()
                 for pat in range(len(patterns)):
                     conditionalTree.addConditionalPatterns(patterns[pat], TimeStamps[pat], support[pat], probability[pat])
                 if len(patterns) > 0:
                     conditionalTree.generatePatterns(pattern, periodic)
             self.removeNode(i)
 
-
 class UPFPGrowthPlus(_ab._periodicFrequentPatterns):
     """
-        Periodic-TubeP is  to discover periodic-frequent patterns in a temporal database.
+    Description:
+    -------------
 
-        Reference:
-        --------
+        UPFPGrowth Plus is  to discover periodic-frequent patterns in a uncertain temporal database.
 
+    Reference:
+    ------------
 
-        Attributes:
-        ----------
-            iFile: file
-                Name of the Input file or path of input file
-            oFile: file
-                Name of the output file or path of output file
-            minSup: int or float or str
-                The user can specify minSup either in count or proportion of database size.
-                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-            maxPer: int or float or str
-                The user can specify maxPer either in count or proportion of database size.
-                If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
-            sep: str
-                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                However, the users can override their default separator.
-            memoryUSS: float
-                To store the total amount of USS memory consumed by the program
-            memoryRSS: float
-                To store the total amount of RSS memory consumed by the program
-            startTime: float
-                To record the start time of the mining process
-            endTime: float
-                To record the completion time of the mining process
-            Database: list
-                To store the transactions of a database in list
-            mapSupport: Dictionary
-                To maintain the information of item and their frequency
-            lno: int
-                To represent the total no of transaction
-            tree: class
-                To represents the Tree class
-            itemSetCount: int
-                To represents the total no of patterns
-            finalPatterns: dict
-                To store the complete patterns
-        Methods:
-        -------
-            startMine()
-                Mining process will start from here
-            getPatterns()
-                Complete set of patterns will be retrieved with this function
-            savePatterns(oFile)
-                Complete set of periodic-frequent patterns will be loaded in to a output file
-            getPatternsAsDataFrame()
-                Complete set of periodic-frequent patterns will be loaded in to a dataframe
-            getMemoryUSS()
-                Total amount of USS memory consumed by the mining process will be retrieved from this function
-            getMemoryRSS()
-                Total amount of RSS memory consumed by the mining process will be retrieved from this function
-            getRuntime()
-                Total amount of runtime taken by the mining process will be retrieved from this function
-            creatingItemSets(fileName)
-                Scans the dataset and stores in a list format
-            updateDatabases()
-                Update the database by removing aperiodic items and sort the Database by item decreased support
-            buildTree()
-                After updating the Database, remaining items will be added into the tree by setting root node as null
-            convert()
-                to convert the user specified value
-            PeriodicFrequentOneItems()
-                To extract the one-length periodic-frequent items
 
-        Executing the code on terminal:
+
+    Attributes:
+    ----------
+        iFile: file
+            Name of the Input file or path of input file
+        oFile: file
+            Name of the output file or path of output file
+        minSup: int or float or str
+            The user can specify minSup either in count or proportion of database size.
+            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+        maxPer: int or float or str
+            The user can specify maxPer either in count or proportion of database size.
+            If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
+        sep: str
+            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+            However, the users can override their default separator.
+        memoryUSS: float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS: float
+            To store the total amount of RSS memory consumed by the program
+        startTime: float
+            To record the start time of the mining process
+        endTime: float
+            To record the completion time of the mining process
+        Database: list
+            To store the transactions of a database in list
+        mapSupport: Dictionary
+            To maintain the information of item and their frequency
+        lno: int
+            To represent the total no of transaction
+        tree: class
+            To represents the Tree class
+        itemSetCount: int
+            To represents the total no of patterns
+        finalPatterns: dict
+            To store the complete patterns
+    Methods:
+    ---------
+        startMine()
+            Mining process will start from here
+        getPatterns()
+            Complete set of patterns will be retrieved with this function
+        savePatterns(oFile)
+            Complete set of periodic-frequent patterns will be loaded in to a output file
+        getPatternsAsDataFrame()
+            Complete set of periodic-frequent patterns will be loaded in to a dataframe
+        getMemoryUSS()
+            Total amount of USS memory consumed by the mining process will be retrieved from this function
+        getMemoryRSS()
+            Total amount of RSS memory consumed by the mining process will be retrieved from this function
+        getRuntime()
+            Total amount of runtime taken by the mining process will be retrieved from this function
+        creatingItemSets(fileName)
+            Scans the dataset and stores in a list format
+        updateDatabases()
+            Update the database by removing aperiodic items and sort the Database by item decreased support
+        buildTree()
+            After updating the Database, remaining items will be added into the tree by setting root node as null
+        convert()
+            to convert the user specified value
+        PeriodicFrequentOneItems()
+            To extract the one-length periodic-frequent items
+
+    Executing the code on terminal:
+    --------------------------------------------
+        Format:
         -------
-            Format:
-            ------
-                python3 PTubeP.py <inputFile> <outputFile> <minSup> <maxPer>
+           >>> python3 UPFPGrowthPlus.py <inputFile> <outputFile> <minSup> <maxPer>
+        Examples:
+        ---------
+           >>> python3 UPFPGrowthPlus.py sampleTDB.txt patterns.txt 0.3 4     (minSup and maxPer will be considered in support count or frequency)
 
-            Examples:
-            --------
-                python3 PTubeP.py sampleTDB.txt patterns.txt 0.3 4     (minSup and maxPer will be considered in support count or frequency)
+     Importing this algorithm into a python program
+    -----------------------------------------------------------------
 
-        Sample run of importing the code:
-        -------------------
+    .. code-block:: python
 
-            from PAMI.uncertainPeriodicFrequentPattern.basic import PTubeP as alg
+        from PAMI.uncertainPeriodicFrequentPattern import UPFPGrowthPlus as alg
 
-            obj = alg.PTubeP(iFile, minSup, maxPer)
+        obj = alg.UPFPGrowthPlus(iFile, minSup, maxPer)
 
-            obj.startMine()
+        obj.startMine()
 
-            periodicFrequentPatterns = obj.getPatterns()
+        periodicFrequentPatterns = obj.getPatterns()
 
-            print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+        print("Total number of uncertain Periodic Frequent Patterns:", len(periodicFrequentPatterns))
 
-            obj.savePatterns(oFile)
+        obj.save(oFile)
 
-            Df = obj.getPatternsAsDataFrame()
+        Df = obj.getPatternsAsDataFrame()
 
-            memUSS = obj.getMemoryUSS()
+        memUSS = obj.getMemoryUSS()
 
-            print("Total Memory in USS:", memUSS)
+        print("Total Memory in USS:", memUSS)
 
-            memRSS = obj.getMemoryRSS()
+        memRSS = obj.getMemoryRSS()
 
-            print("Total Memory in RSS", memRSS)
+        print("Total Memory in RSS", memRSS)
 
-            run = obj.getRuntime()
+        run = obj.getRuntime()
 
-            print("Total ExecutionTime in seconds:", run)
+        print("Total ExecutionTime in seconds:", run)
 
-        Credits:
-        -------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+    Credits:
+    -----------
+        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
 
     """
     _startTime = float()
     _endTime = float()
     _minSup = float()
     _maxPer = float()
     _finalPatterns = {}
```

### Comparing `pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/uncertainPeriodicFrequentPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/basic/upfp.py` & `pami-2023.5.1/PAMI/weightedFrequentNeighbourhoodPattern/basic/SWFPGrowth.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,848 +1,782 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
 #
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
+#     from PAMI.weightFrequentNeighbourhoodPattern.basic import SWFPGrowth as alg
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     obj = alg.SWFPGrowth(iFile, wFile, nFile, minSup, minWeight, seperator)
+#
+#     obj.startMine()
+#
+#     frequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Frequent Patterns:", len(frequentPatterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getmemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
 
-from PAMI.uncertainPeriodicFrequentPattern.basic import abstract as _ab
 
-_minSup = float()
-__maxPer = float()
-__first = int()
-_last = int()
-__lno = int()
-#rank = {}
-#periodic = {}
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
 
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
 
-class _Item:
-    """
-    A class used to represent the item with probability in transaction of dataset
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
 
-        ...
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
 
-        Attributes:
-        __________
-            item: int or word
-                Represents the name of the item
-            probability: float
-                Represent the existential probability(likelihood presence) of an item
-    """
+"""
+
+from PAMI.weightedFrequentNeighbourhoodPattern.basic import abstract as _fp
+
+_minWS = str()
+_weights = {}
+_rank = {}
+_neighbourList = {}
 
-    def __init__(self, item, probability):
+_fp._sys.setrecursionlimit(20000)
+
+
+class _WeightedItem:
+    def __init__(self, item, weight):
         self.item = item
-        self.probability = probability
+        self.weight = weight
 
 
-class _Node(object):
+class _Node:
     """
         A class used to represent the node of frequentPatternTree
 
-        ...
+    Attributes:
+    ----------
+        itemId: int
+            storing item of a node
+        counter: int
+            To maintain the support of node
+        parent: node
+            To maintain the parent of node
+        children: list
+            To maintain the children of node
 
-        Attributes:
-        ----------
-            item: int
-                storing item of a node
-            probability: int
-                To maintain the expected support of node
-            parent: node
-                To maintain the parent of every node
-            children: list
-                To maintain the children of node
-            timeStamps: list
-                To maintain the timeStamps of node
+    Methods:
+    -------
 
-        Methods:
-        -------
-            addChild(itemName)
-                storing the children to their respective parent nodes
-        """
+        addChild(node)
+            Updates the nodes children list and parent for the given node
+
+    """
 
     def __init__(self, item, children):
-        self.item = item
-        self.probability = 1
-        self.children = children
+        self.itemId = item
+        self.counter = 1
+        self.weight = 0
         self.parent = None
-        self.timeStamps = []
+        self.children = children
 
     def addChild(self, node):
         """
-        To add the children details to parent node
+            Retrieving the child from the tree
 
-        :param node: children node
+            :param node: Children node
+            :type node: Node
+            :return: Updates the children nodes and parent nodes
 
-        :return: updated parent node children
         """
-        self.children[node.item] = node
+        self.children[node.itemId] = node
         node.parent = self
 
 
-def _printTree(root):
+class _Tree:
     """
-    To print the details of tree
-
-    :param root: root node of the tree
+    A class used to represent the frequentPatternGrowth tree structure
 
-    :return: details of tree
-    """
-    for x, y in root.children.items():
-        print(x, y.item, y.probability, y.parent.item, y.timeStamps)
-        _printTree(y)
+    Attributes:
+    ----------
+        root : Node
+            The first node of the tree set to Null.
+        summaries : dictionary
+            Stores the nodes itemId which shares same itemId
+        info : dictionary
+            frequency of items in the transactions
 
-
-class _Tree(object):
+    Methods:
+    -------
+        addTransaction(transaction, freq)
+            adding items of  transactions into the tree as nodes and freq is the count of nodes
+        getFinalConditionalPatterns(node)
+            getting the conditional patterns from fp-tree for a node
+        getConditionalPatterns(patterns, frequencies)
+            sort the patterns by removing the items with lower minWS
+        generatePatterns(prefix)
+            generating the patterns from fp-tree
     """
-        A class used to represent the frequentPatternGrowth tree structure
-
-        ...
-
-        Attributes:
-        ----------
-            root : Node
-                Represents the root node of the tree
-            summaries : dictionary
-                storing the nodes with same item name
-            info : dictionary
-                stores the support of items
-
-
-        Methods:
-        -------
-            addTransactions(transaction)
-                creating transaction as a branch in frequentPatternTree
-            addConditionalTransaction(prefixPaths, supportOfItems)
-                construct the conditional tree for prefix paths
-            conditionalPatterns(Node)
-                generates the conditional patterns from tree for specific node
-            conditionalTransactions(prefixPaths,Support)
-                takes the prefixPath of a node and support at child of the path and extract the frequent items from
-                prefixPaths and generates prefixPaths with items which are frequent
-            remove(Node)
-                removes the node from tree once after generating all the patterns respective to the node
-            generatePatterns(Node)
-                starts from the root node of the tree and mines the frequent patterns
-
-        """
 
     def __init__(self):
         self.root = _Node(None, {})
         self.summaries = {}
         self.info = {}
 
-    def addTransactions(self, transaction, tid):
+    def addTransaction(self, transaction, count):
         """adding transaction into tree
 
-            :param transaction: it represents the one transactions in database
+        :param transaction: it represents the one transactions in database
 
-            :type transaction: list
+        :type transaction: list
 
-            :param tid: the timestamp of transaction
+        :param count: frequency of item
 
-            :type tid: list
+        :type count: int
         """
+
+        # This method takes transaction as input and returns the tree
+        global _neighbourList, _rank
         currentNode = self.root
         for i in range(len(transaction)):
+            wei = 0
+            l1 = i
+            while l1 >= 0:
+                wei += transaction[l1].weight
+                l1 -= 1
             if transaction[i].item not in currentNode.children:
                 newNode = _Node(transaction[i].item, {})
-                l1 = i - 1
-                temp = []
-                while l1 >= 0:
-                    temp.append(transaction[l1].probability)
-                    l1 -= 1
-                if len(temp) == 0:
-                    newNode.probability = transaction[i].probability
-                else:
-                    newNode.probability = max(temp) * transaction[i].probability
+                newNode.freq = count
+                newNode.weight = wei
                 currentNode.addChild(newNode)
-                if transaction[i].item in self.summaries:
-                    self.summaries[transaction[i].item].append(newNode)
+                if _rank[transaction[i].item] in self.summaries:
+                    self.summaries[_rank[transaction[i].item]].append(newNode)
                 else:
-                    self.summaries[transaction[i].item] = [newNode]
+                    self.summaries[_rank[transaction[i].item]] = [newNode]
                 currentNode = newNode
             else:
                 currentNode = currentNode.children[transaction[i].item]
-                l1 = i - 1
-                temp = []
-                while l1 >= 0:
-                    temp.append(transaction[l1].probability)
-                    l1 -= 1
-                if len(temp) == 0:
-                    currentNode.probability += transaction[i].probability
-                else:
-                    currentNode.probability += max(temp) * transaction[i].probability
-        currentNode.timeStamps = currentNode.timeStamps + tid
-
-    def addConditionalTransaction(self, transaction, ts, sup):
-        """constructing conditional tree from prefixPaths
-
-                :param transaction : it represents the one transactions in database
+                currentNode.freq += count
+                currentNode.weight += wei
 
-                :type transaction : list
+    def addConditionalPattern(self, transaction, count):
+        """adding transaction into tree
 
-                :param ts: timeStamp of a transaction
+        :param transaction: it represents the one transactions in database
 
-                :type ts: list
+        :type transaction: list
 
-                :param sup : support of prefixPath taken at last child of the path
+        :param count: frequency of item
 
-                :type sup : int
+        :type count: int
         """
+
+        # This method takes transaction as input and returns the tree
+        global _neighbourList, _rank
         currentNode = self.root
         for i in range(len(transaction)):
-            if transaction[i] not in currentNode.children:
-                newNode = _Node(transaction[i], {})
-                newNode.probability = sup
+            wei = 0
+            l1 = i
+            while l1 >= 0:
+                wei += transaction[l1].weight
+                l1 -= 1
+            if transaction[i].itemId not in currentNode.children:
+                newNode = _Node(transaction[i].itemId, {})
+                newNode.freq = count
+                newNode.weight = wei
                 currentNode.addChild(newNode)
-                if transaction[i] in self.summaries:
-                    self.summaries[transaction[i]].append(newNode)
+                if _rank[transaction[i].itemId] in self.summaries:
+                    self.summaries[_rank[transaction[i].itemId]].append(newNode)
                 else:
-                    self.summaries[transaction[i]] = [newNode]
+                    self.summaries[_rank[transaction[i].itemId]] = [newNode]
                 currentNode = newNode
             else:
-                currentNode = currentNode.children[transaction[i]]
-                currentNode.probability += sup
-        currentNode.timeStamps = currentNode.timeStamps + ts
+                currentNode = currentNode.children[transaction[i].itemId]
+                currentNode.freq += count
+                currentNode.weight += wei
 
-    def getConditionalPatterns(self, alpha):
-        """generates all the conditional patterns of respective node
+    def printTree(self, root):
+        if len(root.children) == 0:
+            return
+        else:
+            for x, y in root.children.items():
+                #print(y.itemId, y.parent.itemId, y.freq, y.weight)
+                self.printTree(y)
 
-            :param alpha : it represents the Node in tree
 
-            :type alpha : Node
+    def getFinalConditionalPatterns(self, alpha):
         """
+        generates the conditional patterns for a node
+
+        Parameters:
+        ----------
+            alpha: node to generate conditional patterns
+
+        Returns
+        -------
+            returns conditional patterns, frequency of each item in conditional patterns
 
+        """
         finalPatterns = []
-        finalTimeStamps = []
-        sup = []
+        finalFreq = []
+        global _neighbourList
         for i in self.summaries[alpha]:
-            set1 = i.timeStamps
-            s = i.probability
+            set1 = i.weight
             set2 = []
-            while i.parent.item is not None:
-                set2.append(i.parent.item)
+            while i.parent.itemId is not None:
+                if i.parent.itemId in _neighbourList[i.itemId]:
+                    set2.append(i.parent)
                 i = i.parent
             if len(set2) > 0:
                 set2.reverse()
                 finalPatterns.append(set2)
-                finalTimeStamps.append(set1)
-                sup.append(s)
-        finalPatterns, finalTimeStamps, support, info = self.conditionalTransactions(finalPatterns, finalTimeStamps,
-                                                                                     sup)
-        return finalPatterns, finalTimeStamps, support, info
-
-    def removeNode(self, nodeValue):
-        """removing the node from tree
-
-            :param nodeValue : it represents the node in tree
+                finalFreq.append(set1)
+        finalPatterns, finalFreq, info = self.getConditionalTransactions(finalPatterns, finalFreq)
+        return finalPatterns, finalFreq, info
 
-            :type nodeValue : node
+    @staticmethod
+    def getConditionalTransactions(ConditionalPatterns, conditionalFreq):
         """
-        for i in self.summaries[nodeValue]:
-            i.parent.timeStamps = i.parent.timeStamps + i.timeStamps
-            del i.parent.children[nodeValue]
-
-    def getPeriodAndSupport(self, s, timeStamps):
-        global _lno, _maxPer
-        timeStamps.sort()
-        cur = 0
-        per = 0
-        sup = s
-        for j in range(len(timeStamps)):
-            per = max(per, timeStamps[j] - cur)
-            if per > _maxPer:
-                return [0, 0]
-            cur = timeStamps[j]
-        per = max(per, _lno - cur)
-        return [sup, per]
-
-    def conditionalTransactions(self, condPatterns, condTimeStamps, support):
-        """ It generates the conditional patterns with frequent items
-
-                :param condPatterns : conditional patterns generated from getConditionalPatterns method for respective node
-
-                :type condPatterns : list
-
-                :param condTimeStamps: timeStamps of conditional transactions
-
-                :type condTimeStamps: list
-
-                :param support : the support of conditional pattern in tree
+        To calculate the frequency of items in conditional patterns and sorting the patterns
+        Parameters
+        ----------
+        ConditionalPatterns: paths of a node
+        conditionalFreq: frequency of each item in the path
 
-                :type support : list
+        Returns
+        -------
+            conditional patterns and frequency of each item in transactions
         """
-        global _minSup, _maxPer
+        global _rank
         pat = []
-        timeStamps = []
-        sup = []
+        freq = []
         data1 = {}
-        count = {}
-        for i in range(len(condPatterns)):
-            for j in condPatterns[i]:
-                if j in data1:
-                    data1[j] = data1[j] + condTimeStamps[i]
-                    count[j] += support[i]
+        for i in range(len(ConditionalPatterns)):
+            for j in ConditionalPatterns[i]:
+                if j.itemId in data1:
+                    data1[j.itemId] += conditionalFreq[i]
                 else:
-                    data1[j] = condTimeStamps[i]
-                    count[j] = support[i]
-        updatedDict = {}
-        for m in data1:
-            updatedDict[m] = self.getPeriodAndSupport(count[m], data1[m])
-        updatedDict = {k: v for k, v in updatedDict.items() if v[0] >= _minSup and v[1] <= _maxPer}
+                    data1[j.itemId] = conditionalFreq[i]
+        up_dict = {k: v for k, v in data1.items() if v >= _minWS}
         count = 0
-        for p in condPatterns:
-            p1 = [v for v in p if v in updatedDict]
-            trans = sorted(p1, key=lambda x: (updatedDict.get(x)[0]), reverse=True)
+        for p in ConditionalPatterns:
+            p1 = [v for v in p if v.itemId in up_dict]
+            trans = sorted(p1, key=lambda x: (up_dict.get(x)), reverse=True)
             if len(trans) > 0:
                 pat.append(trans)
-                timeStamps.append(condTimeStamps[count])
-                sup.append(support[count])
+                freq.append(conditionalFreq[count])
             count += 1
-        return pat, timeStamps, sup, updatedDict
+        up_dict = {_rank[k]: v for k, v in up_dict.items()}
+        return pat, freq, up_dict
 
-    def generatePatterns(self, prefix, periodic):
-        """generates the patterns
+    def generatePatterns(self, prefix):
+        """
+        To generate the frequent patterns
+        Parameters
+        ----------
+        prefix: an empty list
 
-            :param prefix : forms the combination of items
+        Returns
+        -------
+        Frequent patterns that are extracted from fp-tree
 
-            :type prefix : list
         """
-
-        global _minSup
-        for i in sorted(self.summaries, key=lambda x: (self.info.get(x)[0])):
+        global _minWS
+        for i in sorted(self.summaries, key=lambda x: (self.info.get(x))):
             pattern = prefix[:]
             pattern.append(i)
-            s = 0
-            '''for x in self.summaries[i]:
-                print(x.item, x.probability)
-            print('.....')'''
-            for x in self.summaries[i]:
-                s += x.probability
-            #print(pattern, self.info[i], s)
-            periodic[tuple(pattern)] = self.info[i]
-            if self.info[i][0] >= _minSup:
-                patterns, timeStamps, support, info = self.getConditionalPatterns(i)
-                conditionalTree = _Tree()
-                conditionalTree.info = info.copy()
-                for pat in range(len(patterns)):
-                    conditionalTree.addConditionalTransaction(patterns[pat], timeStamps[pat], support[pat])
-                if len(patterns) > 0:
-                    conditionalTree.generatePatterns(pattern, periodic)
-            self.removeNode(i)
+            yield pattern, self.info[i]
+            patterns, freq, info = self.getFinalConditionalPatterns(i)
+            conditionalTree = _Tree()
+            conditionalTree.info = info.copy()
+            for pat in range(len(patterns)):
+                conditionalTree.addConditionalPattern(patterns[pat], freq[pat])
+            if len(patterns) > 0:
+                for q in conditionalTree.generatePatterns(pattern):
+                    yield q
 
 
-class UPFPGrowth(_ab._periodicFrequentPatterns):
+class SWFPGrowth(_fp._weightedFrequentSpatialPatterns):
     """
+    Description:
+    -------------
+       SWFPGrowth is an algorithm to mine the weighted spatial frequent patterns in spatiotemporal databases.
+
+    Reference :
+    ------------
+        R. Uday Kiran, P. P. C. Reddy, K. Zettsu, M. Toyoda, M. Kitsuregawa and P. Krishna Reddy,
+        "Discovering Spatial Weighted Frequent Itemsets in Spatiotemporal Databases," 2019 International
+        Conference on Data Mining Workshops (ICDMW), 2019, pp. 987-996, doi: 10.1109/ICDMW.2019.00143.
+
+    Attributes :
+    ------------
+        iFile : file
+            Input file name or path of the input file
+        minWS: float or int or str
+            The user can specify minWS either in count or proportion of database size.
+            If the program detects the data type of minWS is integer, then it treats minWS is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minWS=10 will be treated as integer, while minWS=10.0 will be treated as float
+        minWeight: float or int or str
+            The user can specify minWeight either in count or proportion of database size.
+            If the program detects the data type of minWeight is integer, then it treats minWeight is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minWeight=10 will be treated as integer, while minWeight=10.0 will be treated as float
+        sep : str
+            This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
+            However, the users can override their default separator.
+        oFile : file
+            Name of the output file or the path of the output file
+        startTime:float
+            To record the start time of the mining process
+        endTime:float
+            To record the completion time of the mining process
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
+        Database : list
+            To store the transactions of a database in list
+        mapSupport : Dictionary
+            To maintain the information of item and their frequency
+        lno : int
+            it represents the total no of transactions
+        tree : class
+            it represents the Tree class
+        finalPatterns : dict
+            it represents to store the patterns
+
+    Methods :
+    --------------
+        startMine()
+            Mining process will start from here
+        getPatterns()
+            Complete set of patterns will be retrieved with this function
+        save(oFile)
+            Complete set of frequent patterns will be loaded in to a output file
+        getPatternsAsDataFrame()
+            Complete set of frequent patterns will be loaded in to a dataframe
+        getMemoryUSS()
+            Total amount of USS memory consumed by the mining process will be retrieved from this function
+        getMemoryRSS()
+            Total amount of RSS memory consumed by the mining process will be retrieved from this function
+        getRuntime()
+            Total amount of runtime taken by the mining process will be retrieved from this function
+        creatingItemSets()
+            Scans the dataset or dataframes and stores in list format
+        frequentOneItem()
+            Extracts the one-frequent patterns from transactions
+
+    Executing the code on terminal:
+    -----------------------------------
+        Format:
+        --------------
+            python3 SWFPGrowth.py <inputFile> <weightFile> <outputFile> <minWS>
+
+        Examples:
+        ----------------
+            python3 SWFPGrowth.py sampleDB.txt weightSample.txt patterns.txt 10.0   (minWS will be considered in times of minWS and count of database transactions)
 
-        UPFPGrowth is  to discover periodic-frequent patterns in a uncertain temporal database.
+            python3 SWFPGrowth.py sampleDB.txt weightFile.txt patterns.txt 10     (minWS will be considered in support count or frequency) (it will consider "\t" as a separator)
 
-        Reference:
-        --------
-            Uday Kiran, R., Likhitha, P., Dao, MS., Zettsu, K., Zhang, J. (2021).
-            Discovering Periodic-Frequent Patterns in Uncertain Temporal Databases. In:
-            Mantoro, T., Lee, M., Ayu, M.A., Wong, K.W., Hidayanto, A.N. (eds) Neural Information Processing.
-            ICONIP 2021. Communications in Computer and Information Science, vol 1516. Springer, Cham.
-            https://doi.org/10.1007/978-3-030-92307-5_83
+            python3 SWFPGrowth.py sampleTDB.txt weightFile.txt output.txt sampleN.txt 3 ',' (it will consider "," as a separator)
 
-        Attributes:
-        ----------
-            iFile : file
-                Name of the Input file or path of the input file
-            oFile : file
-                Name of the output file or path of output file
-            minSup: int or float or str
-                The user can specify minSup either in count or proportion of database size.
-                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-            maxPer: int or float or str
-                The user can specify maxPer either in count or proportion of database size.
-                If the program detects the data type of maxPer is integer, then it treats maxPer is expressed in count.
-                Otherwise, it will be treated as float.
-                Example: maxPer=10 will be treated as integer, while maxPer=10.0 will be treated as float
-            sep: str
-                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
-                However, the users can override their default separator.
-            memoryUSS: float
-                To store the total amount of USS memory consumed by the program
-            memoryRSS: float
-                To store the total amount of RSS memory consumed by the program
-            startTime: float
-                To record the start time of the mining process
-            endTime: float
-                To record the completion time of the mining process
-            Database : list
-                To store the transactions of a database in list
-            mapSupport : Dictionary
-                To maintain the information of item and their frequency
-            _lno : int
-                To represent the total no of transaction
-            tree : class
-                To represents the Tree class
-            finalPatterns : dict
-                To store the complete patterns
 
-        Methods:
-        -------
-            startMine()
-                Mining process will start from here
-            getPatterns()
-                Complete set of patterns will be retrieved with this function
-            save(oFile)
-                Complete set of periodic-frequent patterns will be loaded in to a output file
-            getPatternsAsDataFrame()
-                Complete set of periodic-frequent patterns will be loaded in to a dataframe
-            getMemoryUSS()
-                Total amount of USS memory consumed by the mining process will be retrieved from this function
-            getMemoryRSS()
-                Total amount of RSS memory consumed by the mining process will be retrieved from this function
-            getRuntime()
-                Total amount of runtime taken by the mining process will be retrieved from this function
-            creatingItemSets()
-                Scans the dataset and stores in a list format
-            PeriodicFrequentOneItem()
-                Extracts the one-periodic-frequent patterns from database
-            updateTransaction()
-                Update the database by removing aperiodic items and sort the Database by item decreased support
-            buildTree()
-                After updating the Database, remaining items will be added into the tree by setting root node as null
-            convert()
-                to convert the user specified value
-            removeFalsePositives()
-                to remove the false positives in generated patterns
 
-        Executing the code on terminal:
-        -------
+    **Methods to execute code on terminal**
+
             Format:
-            ------
-                python3 UPFPGrowth.py <inputFile> <outputFile> <minSup> <maxPer>
-            Examples:
-            --------
-                python3 UPFPGrowth.py sampleTDB.txt patterns.txt 0.3 4     (minSup and maxPer will be considered in support count or frequency)
+                      >>>  python3 SWFPGrowth.py <inputFile> <weightFile> <outputFile> <minSup> <minWeight>
+            Example:
+                      >>>  python3 SWFPGrowth.py sampleDB.txt weightFile.txt patterns.txt 10  2
+
+                     .. note:: minSup will be considered in support count or frequency
 
-        Sample run of importing the code:
-        -------------------
+    **Importing this algorithm into a python program**
 
-            from PAMI.uncertainPeriodicFrequentPattern import UPFPGrowth as alg
+    .. code-block:: python
 
-            obj = alg.UPFPGrowth(iFile, minSup, maxPer)
+            from PAMI.weightFrequentNeighbourhoodPattern.basic import SWFPGrowth as alg
+
+            obj = alg.SWFPGrowth(iFile, wFile, nFile, minSup, minWeight, seperator)
 
             obj.startMine()
 
-            periodicFrequentPatterns = obj.getPatterns()
+            frequentPatterns = obj.getPatterns()
 
-            print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+            print("Total number of Frequent Patterns:", len(frequentPatterns))
 
-            obj.save(oFile)
+            obj.savePatterns(oFile)
 
             Df = obj.getPatternsAsDataFrame()
 
-            memUSS = obj.getMemoryUSS()
+            memUSS = obj.getmemoryUSS()
 
             print("Total Memory in USS:", memUSS)
 
             memRSS = obj.getMemoryRSS()
 
             print("Total Memory in RSS", memRSS)
 
             run = obj.getRuntime()
 
             print("Total ExecutionTime in seconds:", run)
+    **Credits:**
 
-    Credits:
-    -------
-        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+             The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
 
-    """
-    _rank = {}
-    _startTime = float()
-    _endTime = float()
-    _minSup = float()
-    _maxPer = float()
-    _finalPatterns = {}
+        """
+
+    __startTime = float()
+    __endTime = float()
+    _Weights = {}
+    _minWS = str()
+    __finalPatterns = {}
+    _neighbourList = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
-    _memoryUSS = float()
-    _memoryRSS = float()
-    _Database = []
-    _lno = 0
-    _periodic = {}
+    __memoryUSS = float()
+    __memoryRSS = float()
+    __Database = []
+    __mapSupport = {}
+    __lno = 0
+    __tree = _Tree()
+    __rank = {}
+    __rankDup = {}
+
+    def __init__(self, iFile, nFile, minWS, sep='\t'):
+        super().__init__(iFile, nFile, minWS, sep)
 
-    def _creatingItemSets(self):
+    def __creatingItemSets(self):
         """
             Storing the complete transactions of the database/input file in a database variable
 
+
         """
         self._Database = []
-        if isinstance(self._iFile, _ab._pd.DataFrame):
-            uncertain, data, ts = [], [], []
+        if isinstance(self._iFile, _fp._pd.DataFrame):
             if self._iFile.empty:
                 print("its empty..")
-            i = self._iFile._columns.values.tolist()
-            if 'TS' in i:
-                ts = self._iFile['TS'].tolist()
+            i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
-                data = self._iFile['Transactions'].tolist()
-            if 'uncertain' in i:
-                uncertain = self._iFile['uncertain'].tolist()
-            for k in range(len(data)):
-                tr = [ts[k]]
-                for j in range(len(k)):
-                    product = _Item(data[k][j], uncertain[k][j])
-                    tr.append(product)
-                self._Database.append(tr)
-                self._lno += 1
-
+                self._Database = self._iFile['Transactions'].tolist()
             # print(self.Database)
         if isinstance(self._iFile, str):
-            if _ab._validators.url(self._iFile):
-                data = _ab._urlopen(self._iFile)
+            if _fp._validators.url(self._iFile):
+                data = _fp._urlopen(self._iFile)
                 for line in data:
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
-                    tr = [int(temp[0])]
-                    for i in temp[1:]:
-                        i1 = i.index('(')
-                        i2 = i.index(')')
-                        item = i[0:i1]
-                        probability = float(i[i1 + 1:i2])
-                        product = _Item(item, probability)
-                        tr.append(product)
-                    self._lno += 1
-                    self._Database.append(tr)
+                    self._Database.append(temp)
             else:
                 try:
-                    count = 0
-                    with open(self._iFile, 'r') as f:
+                    with open(self._iFile, 'r', encoding='utf-8') as f:
                         for line in f:
-                            #count += 1
-                            temp = [i.rstrip() for i in line.split(self._sep)]
-                            temp = [x for x in temp if x]
-                            tr = [int(temp[0])]
-                            for i in temp[1:]:
-                                i1 = i.index('(')
-                                i2 = i.index(')')
-                                item = i[0:i1]
-                                probability = float(i[i1 + 1:i2])
-                                product = _Item(item, probability)
-                                tr.append(product)
-                            self._lno += 1
+                            line = line.strip()
+                            line = line.split(':')
+                            temp1 = [i.rstrip() for i in line[0].split(self._sep)]
+                            temp2 = [int(i.strip()) for i in line[1].split(self._sep)]
+                            tr = []
+                            for i in range(len(temp1)):
+                                we = _WeightedItem(temp1[i], temp2[i])
+                                tr.append(we)
                             self._Database.append(tr)
                 except IOError:
                     print("File Not Found")
+                    quit()
 
-    def _periodicFrequentOneItem(self):
-        """takes the transactions and calculates the support of each item in the dataset and assign the
-                    ranks to the items by decreasing support and returns the frequent items list
+    def _scanNeighbours(self):
+        self._neighbourList = {}
+        if isinstance(self._nFile, _fp._pd.DataFrame):
+            data, items = [], []
+            if self._nFile.empty:
+                print("its empty..")
+            i = self._nFile.columns.values.tolist()
+            if 'item' in i:
+                items = self._nFile['items'].tolist()
+            if 'Neighbours' in i:
+                data = self._nFile['Neighbours'].tolist()
+            for k in range(len(items)):
+                self._neighbourList[items[k][0]] = data[k]
+            # print(self.Database)
+        if isinstance(self._nFile, str):
+            if _fp._validators.url(self._nFile):
+                data = _fp._urlopen(self._nFile)
+                for line in data:
+                    line.strip()
+                    line = line.decode("utf-8")
+                    temp = [i.rstrip() for i in line.split(self._sep)]
+                    temp = [x for x in temp if x]
+                    self._neighbourList[temp[0]] = temp[1:]
+            else:
+                try:
+                    with open(self._nFile, 'r', encoding='utf-8') as f:
+                        for line in f:
+                            line.strip()
+                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            temp = [x for x in temp if x]
+                            self._neighbourList[temp[0]] = temp[1:]
+                except IOError:
+                    print("File Not Found2")
+                    quit()
 
+    def __convert(self, value):
         """
-        mapSupport = {}
-        for i in self._Database:
-            n = i[0]
-            for j in i[1:]:
-                if j.item not in mapSupport:
-                    mapSupport[j.item] = [round(j.probability, 3), abs(0 - n), n]
-                else:
-                    mapSupport[j.item][0] += round(j.probability, 3)
-                    mapSupport[j.item][1] = max(mapSupport[j.item][1], abs(n - mapSupport[j.item][2]))
-                    mapSupport[j.item][2] = n
-        for key in mapSupport:
-            mapSupport[key][1] = max(mapSupport[key][1], self._lno - mapSupport[key][2])
-        mapSupport = {k: [v[0], v[1]] for k, v in mapSupport.items() if v[1] <= self._maxPer and v[0] >= self._minSup}
-        plist = [k for k, v in sorted(mapSupport.items(), key=lambda x: (x[1][0], x[0]), reverse=True)]
-        self._rank = dict([(index, item) for (item, index) in enumerate(plist)])
-        return mapSupport, plist
-
-    def _check(self, i, x):
-        """To check the presence of item or pattern in transaction
-
-            :param x: it represents the pattern
+        to convert the type of user specified minWS value
 
-            :type x : list
+        :param value: user specified minWS value
 
-            :param i : represents the uncertain transactions
-
-            :type i : list
+        :return: converted type
         """
+        if type(value) is int:
+            value = int(value)
+        if type(value) is float:
+            value = (len(self._Database) * value)
+        if type(value) is str:
+            if '.' in value:
+                value = float(value)
+                value = (len(self._Database) * value)
+            else:
+                value = int(value)
+        return value
 
-        for m in x:
-            k = 0
-            for n in i:
-                if m == n.item:
-                    k += 1
-            if k == 0:
-                return 0
-        return 1
-
-    def _getPeriodAndSupport(self, s, timeStamps):
+    def __frequentOneItem(self):
         """
-        To calculate periodicity of timeStamps
-
-            :param s: support of a pattern
-
-            :param timeStamps: timeStamps of a pattern
+        Generating One frequent items sets
 
-            :return: periodicity and Support
         """
-        global __lno, _maxPer
-        timeStamps.sort()
-        cur = 0
-        per = 0
-        sup = s
-        for j in range(len(timeStamps)):
-            per = max(per, timeStamps[j] - cur)
-            if per > _maxPer:
-                return [0, 0]
-            cur = timeStamps[j]
-        per = max(per, _lno - cur)
-        return [sup, per]
-
-    def _buildTree(self, data, info):
-        """it takes the transactions and support of each item and construct the main tree with setting root
-                    node as null
-
-            :param data: it represents the one transactions in database
-
-            :type data: list
-
-            :param info: it represents the support of each item
+        global _maxWeight
+        self._mapSupport = {}
+        for tr in self._Database:
+            for i in tr:
+                nn = [j for j in tr if j.item in self._neighbourList[i.item]]
+                if i.item not in self._mapSupport:
+                    self._mapSupport[i.item] = i.weight
+                else:
+                    self._mapSupport[i.item] += i.weight
+                for k in nn:
+                    self._mapSupport[i.item] += k.weight
+        self._mapSupport = {k: v for k, v in self._mapSupport.items() if v >= self._minWS}
+        genList = [k for k, v in sorted(self._mapSupport.items(), key=lambda x: x[1], reverse=True)]
+        self.__rank = dict([(index, item) for (item, index) in enumerate(genList)])
+        return genList
 
-            :type info : dictionary
+    def __updateTransactions(self, itemSet):
         """
-        rootNode = _Tree()
-        rootNode.info = info.copy()
-        for i in range(len(data)):
-            set1 = [data[i][0]]
-            rootNode.addTransactions(data[i][1:], set1)
-        return rootNode
+        Updates the items in transactions with rank of items according to their support
 
-    def _updateTransactions(self, dict1):
-        """remove the items which are not frequent from transactions and updates the transactions with rank of items
+        :Example: oneLength = {'a':7, 'b': 5, 'c':'4', 'd':3}
+                    rank = {'a':0, 'b':1, 'c':2, 'd':3}
 
-            :param dict1 : frequent items with support
+        Parameters
+        ----------
+        itemSet: list of one-frequent items
 
-            :type dict1 : dictionary
-        """
+        -------
 
+        """
         list1 = []
         for tr in self._Database:
-            list2 = [int(tr[0])]
-            for i in range(1, len(tr)):
-                if tr[i].item in dict1:
+            list2 = []
+            for i in range(len(tr)):
+                if tr[i].item in itemSet:
                     list2.append(tr[i])
-            if len(list2) >= 2:
-                basket = list2[1:]
-                basket.sort(key=lambda val: self._rank[val.item])
-                list2[1:] = basket[0:]
-                list1.append(list2)
+            if len(list2) >= 1:
+                basket = list2
+                basket.sort(key=lambda val: self.__rank[val.item])
+                list1.append(basket)
         return list1
 
-    def _convert(self, value):
+    @staticmethod
+    def __buildTree(transactions, info):
         """
-            To convert the given user specified value
+        Builds the tree with updated transactions
+        Parameters:
+        ----------
+            transactions: updated transactions
+            info: support details of each item in transactions
 
-            :param value: user specified value
+        Returns:
+        -------
+            transactions compressed in fp-tree
 
-            :return: converted value
         """
-        if type(value) is int:
-            value = int(value)
-        if type(value) is float:
-            value = float(value)
-        if type(value) is str:
-            if '.' in value:
-                value = float(value)
-            else:
-                value = int(value)
-
-        return value
+        rootNode = _Tree()
+        rootNode.info = info.copy()
+        for i in range(len(transactions)):
+            rootNode.addTransaction(transactions[i], 1)
+        return rootNode
 
-    def _removeFalsePositives(self):
+    def __savePeriodic(self, itemSet):
         """
+        The duplication items and their ranks
+        Parameters:
+        ----------
+            itemSet: frequent itemSet that generated
 
-        Returns
+        Returns:
         -------
-            removes the false positive patterns in generated patterns
+            patterns with original item names.
+
         """
-        periods = {}
-        for i in self._Database:
-            for x, y in self._periodic.items():
-                if len(x) == 1:
-                    periods[x] = y
-                else:
-                    s = 1
-                    check = self._check(i[1:], x)
-                    if check == 1:
-                        for j in i[1:]:
-                            if j.item in x:
-                                s *= j.probability
-                        if x in periods:
-                            periods[x][0] += s
-                        else:
-                            periods[x] = [s, y[1]]
-        count = 0
-        for x, y in periods.items():
-            if y[0] >= _minSup:
-                count += 1
-                sample = str()
-                for i in x:
-                    sample = sample + i + "\t"
-                self._finalPatterns[sample] = y
-        #print("Total false patterns generated:", len(self._periodic) - count)
+        temp = str()
+        for i in itemSet:
+            temp = temp + self.__rankDup[i] + "\t"
+        return temp
 
     def startMine(self):
-        """Main method where the patterns are mined by constructing tree and remove the remove the false patterns
-                    by counting the original support of a patterns
-
+        """
+            main program to start the operation
 
         """
-        global _lno, _maxPer, _minSup, _first, _last, periodic
-        self._startTime = _ab._time.time()
-        self._creatingItemSets()
-        self._finalPatterns = {}
-        self._minSup = self._convert(self._minSup)
-        self._maxPer = self._convert(self._maxPer)
-        _minSup, _maxPer, _lno = self._minSup, self._maxPer, self._lno
-        mapSupport, plist = self._periodicFrequentOneItem()
-        updatedTrans = self._updateTransactions(mapSupport)
-        info = {k: v for k, v in mapSupport.items()}
-        Tree1 = self._buildTree(updatedTrans, info)
-        self._periodic = {}
-        Tree1.generatePatterns([], self._periodic)
-        self._removeFalsePositives()
-        print("Periodic frequent patterns were generated successfully using UPFP algorithm")
-        self._endTime = _ab._time.time()
-        process = _ab._psutil.Process(_ab._os.getpid())
-        self._memoryUSS = float()
-        self._memoryRSS = float()
-        self._memoryUSS = process.memory_full_info().uss
-        self._memoryRSS = process.memory_info().rss
+        global _minWS, _neighbourList, _rank
+        self.__startTime = _fp._time.time()
+        if self._iFile is None:
+            raise Exception("Please enter the file path or file name:")
+        if self._minWS is None:
+            raise Exception("Please enter the Minimum Support")
+        self.__creatingItemSets()
+        self._scanNeighbours()
+        self._minWS = self.__convert(self._minWS)
+        _minWS = self._minWS
+        itemSet = self.__frequentOneItem()
+        updatedTransactions = self.__updateTransactions(itemSet)
+        info = {self.__rank[k]: v for k, v in self._mapSupport.items()}
+        _rank = self.__rank
+        for x, y in self.__rank.items():
+            self.__rankDup[y] = x
+        _neighbourList = self._neighbourList
+        #self._neighbourList = {k:v for k, v in self._neighbourList.items() if k in self._mapSupport.keys()}
+        # for x, y in self._neighbourList.items():
+        #     xx = [self.__rank[i] for i in y if i in self._mapSupport.keys()]
+        #     _neighbourList[self.__rank[x]] = xx
+        # print(_neighbourList)
+        __Tree = self.__buildTree(updatedTransactions, info)
+        patterns = __Tree.generatePatterns([])
+        self.__finalPatterns = {}
+        for k in patterns:
+            s = self.__savePeriodic(k[0])
+            self.__finalPatterns[str(s)] = k[1]
+        print("Weighted Frequent patterns were generated successfully using SWFPGrowth algorithm")
+        self.__endTime = _fp._time.time()
+        self.__memoryUSS = float()
+        self.__memoryRSS = float()
+        process = _fp._psutil.Process(_fp._os.getpid())
+        self.__memoryUSS = process.memory_full_info().uss
+        self.__memoryRSS = process.memory_info().rss
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
 
         :return: returning USS memory consumed by the mining process
 
         :rtype: float
         """
 
-        return self._memoryUSS
+        return self.__memoryUSS
 
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the mining process will be retrieved from this function
 
         :return: returning RSS memory consumed by the mining process
 
         :rtype: float
         """
 
-        return self._memoryRSS
+        return self.__memoryRSS
 
     def getRuntime(self):
         """Calculating the total amount of runtime taken by the mining process
 
+
         :return: returning total amount of runtime taken by the mining process
 
         :rtype: float
         """
 
-        return self._endTime - self._startTime
+        return self.__endTime - self.__startTime
 
     def getPatternsAsDataFrame(self):
         """Storing final frequent patterns in a dataframe
 
         :return: returning frequent patterns in a dataframe
 
         :rtype: pd.DataFrame
         """
 
         dataframe = {}
         data = []
-        for a, b in self._finalPatterns.items():
-            data.append([a.replace('\t', ' '), b[0], b[1]])
-            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Periodicity'])
+        for a, b in self.__finalPatterns.items():
+            data.append([a.replace('\t', ' '), b])
+            dataframe = _fp._pd.DataFrame(data, columns=['Patterns', 'Support'])
         return dataframe
 
     def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
 
         :type outFile: file
         """
-        self.oFile = outFile
-        writer = open(self.oFile, 'w+')
-        for x, y in self._finalPatterns.items():
-            s1 = x.strip() + ":" + str(y[0]) + ":" + str(y[1])
+        self._oFile = outFile
+        writer = open(self._oFile, 'w+')
+        for x, y in self.__finalPatterns.items():
+            s1 = x.strip() + ":" + str(y)
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
 
         :rtype: dict
         """
-        return self._finalPatterns
+        return self.__finalPatterns
 
     def printResults(self):
-        print("Total number of  Uncertain Periodic-Frequent Patterns:", len(self.getPatterns()))
+        print("Total number of  Weighted Spatial Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
         print("Total Memory in RSS", self.getMemoryRSS())
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
-        if len(_ab._sys.argv) == 6:
-            _ap = UPFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
-        if len(_ab._sys.argv) == 5:
-            _ap = UPFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+    if len(_fp._sys.argv) == 7 or len(_fp._sys.argv) == 8:
+        if len(_fp._sys.argv) == 8:
+            _ap = SWFPGrowth(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4], _fp._sys.argv[5], _fp._sys.argv[6],
+                             _fp._sys.argv[7])
+        if len(_fp._sys.argv) == 7:
+            _ap = SWFPGrowth(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4], _fp._sys.argv[5], _fp._sys.argv[6])
         _ap.startMine()
-        print("Total number of Uncertain Periodic-Frequent Patterns:", len(_ap.getPatterns()))
-        _ap.save(_ab._sys.argv[2])
+        print("Total number of Weighted Spatial Frequent Patterns:", len(_ap.getPatterns()))
+        _ap.save(_fp._sys.argv[2])
         print("Total Memory in USS:", _ap.getMemoryUSS())
-        print("Total Memory in RSS", _ap.getMemoryRSS())
+        print("Total Memory in RSS",  _ap.getMemoryRSS())
         print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
-        l = [400, 500, 600, 700, 800]
-        for i in l:
-            ap = UPFPGrowth('/Users/Likhitha/Downloads/uncertain/additionalMaterial/T10I4D200K.txt', i, 8000, ' ')
-            ap.startMine()
-            Patterns = ap.getPatterns()
-            print("Total number of Patterns:", len(Patterns))
-            ap.save('/Users/Likhitha/Downloads/uncertain/output.txt')
-            memUSS = ap.getMemoryUSS()
-            print("Total Memory in USS:", memUSS)
-            memRSS = ap.getMemoryRSS()
-            print("Total Memory in RSS", memRSS)
-            run = ap.getRuntime()
-            print("Total ExecutionTime in ms:", run)
-
-        '''l = [0.04]
-        for i in l:
-            ap = UPFPGrowth('sample', i, 6, ' ')
-            ap.startMine()
-            Patterns = ap.getPatterns()
-            print("Total number of Patterns:", len(Patterns))
-            ap.save('output1.txt')
-            memUSS = ap.getMemoryUSS()
-            print("Total Memory in USS:", memUSS)
-            memRSS = ap.getMemoryRSS()
-            print("Total Memory in RSS", memRSS)
-            run = ap.getRuntime()
-            print("Total ExecutionTime in ms:", run)'''
+        _ap = SWFPGrowth('sample.txt', 'neighbourSample.txt', 150, ' ')
+        _ap.startMine()
+        print("Total number of Weighted Spatial Frequent Patterns:", len(_ap.getPatterns()))
+        _ap.save('output.txt')
+        print("Total Memory in USS:", _ap.getMemoryUSS())
+        print("Total Memory in RSS", _ap.getMemoryRSS())
+        print("Total ExecutionTime in ms:", _ap.getRuntime())
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/uncertainPeriodicFrequentPattern/basic/upfpplus.py` & `pami-2023.5.1/PAMI/uncertainPeriodicFrequentPattern/basic/UPFPGrowth.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,429 +1,400 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
 #
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#     from PAMI.uncertainPeriodicFrequentPattern import UPFPGrowth as alg
+#
+#     obj = alg.UPFPGrowth(iFile, minSup, maxPer)
+#
+#     obj.startMine()
+#
+#     periodicFrequentPatterns = obj.getPatterns()
+#
+#     print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+#
+#     obj.save(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
+#
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+
+
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
 
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
 
+"""
 from PAMI.uncertainPeriodicFrequentPattern.basic import abstract as _ab
 
 _minSup = float()
-_maxPer = float()
-_lno = int()
-_first = int()
+__maxPer = float()
+__first = int()
 _last = int()
+__lno = int()
+#rank = {}
+#periodic = {}
 
 
 class _Item:
     """
     A class used to represent the item with probability in transaction of dataset
 
-    Attributes:
-    __________
-        item : int or string
-            Represents the name of the item
-        probability : float
-            Represent the existential probability(likelihood presence) of an item
+        ...
+
+        Attributes:
+        __________
+            item: int or word
+                Represents the name of the item
+            probability: float
+                Represent the existential probability(likelihood presence) of an item
     """
 
     def __init__(self, item, probability):
         self.item = item
         self.probability = probability
 
 
-def printTree(root):
-    for x, y in root.children.items():
-        print(x, y.item, y.probability, y.parent.item, y.tids, y.secondProbability)
-        printTree(y)
-
 class _Node(object):
     """
         A class used to represent the node of frequentPatternTree
 
         ...
+
         Attributes:
         ----------
-            item : int
+            item: int
                 storing item of a node
-            probability : int
+            probability: int
                 To maintain the expected support of node
-            parent : node
+            parent: node
                 To maintain the parent of every node
-            children : list
+            children: list
                 To maintain the children of node
+            timeStamps: list
+                To maintain the timeStamps of node
 
         Methods:
         -------
             addChild(itemName)
                 storing the children to their respective parent nodes
-    """
+        """
 
     def __init__(self, item, children):
         self.item = item
         self.probability = 1
-        self.secondProbability = 1
-        self.p = 1
         self.children = children
         self.parent = None
-        self.TimeStamps = []
+        self.timeStamps = []
 
     def addChild(self, node):
         """
-            to add children details to parent node
+        To add the children details to parent node
 
-            :param node: children node
+        :param node: children node
 
-            :return: update parent node children
+        :return: updated parent node children
         """
         self.children[node.item] = node
         node.parent = self
 
 
+def _printTree(root):
+    """
+    To print the details of tree
+
+    :param root: root node of the tree
+
+    :return: details of tree
+    """
+    for x, y in root.children.items():
+        print(x, y.item, y.probability, y.parent.item, y.timeStamps)
+        _printTree(y)
+
+
 class _Tree(object):
     """
         A class used to represent the frequentPatternGrowth tree structure
 
         ...
 
         Attributes:
         ----------
-            root: Node
+            root : Node
                 Represents the root node of the tree
-            summaries: dictionary
+            summaries : dictionary
                 storing the nodes with same item name
-            info: dictionary
+            info : dictionary
                 stores the support of items
 
 
         Methods:
         -------
-            addTransaction(transaction)
-                creating transaction as a branch in Tree
+            addTransactions(transaction)
+                creating transaction as a branch in frequentPatternTree
             addConditionalTransaction(prefixPaths, supportOfItems)
                 construct the conditional tree for prefix paths
-            getConditionalPatterns(Node)
+            conditionalPatterns(Node)
                 generates the conditional patterns from tree for specific node
             conditionalTransactions(prefixPaths,Support)
                 takes the prefixPath of a node and support at child of the path and extract the frequent items from
                 prefixPaths and generates prefixPaths with items which are frequent
             remove(Node)
                 removes the node from tree once after generating all the patterns respective to the node
             generatePatterns(Node)
                 starts from the root node of the tree and mines the frequent patterns
 
-    """
+        """
 
     def __init__(self):
         self.root = _Node(None, {})
         self.summaries = {}
         self.info = {}
 
+    def addTransactions(self, transaction, tid):
+        """adding transaction into tree
 
-    def addTransaction(self, transaction, tid):
-        """
-            adding transaction into tree
-
-            :param transaction : it represents the one transactions in database
+            :param transaction: it represents the one transactions in database
 
-            :type transaction : list
+            :type transaction: list
 
-            :param tid : the timestamp of transaction
+            :param tid: the timestamp of transaction
 
-            :type tid : list
+            :type tid: list
         """
         currentNode = self.root
-        k = 0
         for i in range(len(transaction)):
-            k += 1
             if transaction[i].item not in currentNode.children:
                 newNode = _Node(transaction[i].item, {})
-                newNode.k = k
-                newNode.secondProbability = transaction[i].probability
                 l1 = i - 1
                 temp = []
                 while l1 >= 0:
                     temp.append(transaction[l1].probability)
                     l1 -= 1
                 if len(temp) == 0:
-                    newNode.probability = round(transaction[i].probability, 2)
+                    newNode.probability = transaction[i].probability
                 else:
-                    newNode.probability = round(max(temp) * transaction[i].probability, 2)
+                    newNode.probability = max(temp) * transaction[i].probability
                 currentNode.addChild(newNode)
                 if transaction[i].item in self.summaries:
                     self.summaries[transaction[i].item].append(newNode)
                 else:
                     self.summaries[transaction[i].item] = [newNode]
                 currentNode = newNode
             else:
                 currentNode = currentNode.children[transaction[i].item]
-                currentNode.secondProbability = max(transaction[i].probability, currentNode.secondProbability)
-                currentNode.k = k
                 l1 = i - 1
                 temp = []
                 while l1 >= 0:
                     temp.append(transaction[l1].probability)
                     l1 -= 1
                 if len(temp) == 0:
-                    currentNode.probability += round(transaction[i].probability, 2)
+                    currentNode.probability += transaction[i].probability
                 else:
-                    nn = max(temp) * transaction[i].probability
-                    currentNode.probability += round(nn, 2)
-        currentNode.TimeStamps = currentNode.TimeStamps + tid
+                    currentNode.probability += max(temp) * transaction[i].probability
+        currentNode.timeStamps = currentNode.timeStamps + tid
 
-    def addConditionalPatterns(self, transaction, tid, sup, probability):
-        """
-            constructing conditional tree from prefixPaths
+    def addConditionalTransaction(self, transaction, ts, sup):
+        """constructing conditional tree from prefixPaths
 
-            :param transaction : it represents the one transactions in database
+                :param transaction : it represents the one transactions in database
 
-            :type transaction : list
+                :type transaction : list
 
-            :param tid : timestamps of a pattern or transaction in tree
+                :param ts: timeStamp of a transaction
 
-            :param tid : list
+                :type ts: list
 
-            :param sup : support of prefixPath taken at last child of the path
+                :param sup : support of prefixPath taken at last child of the path
 
-            :type sup : int
+                :type sup : int
         """
         currentNode = self.root
-        k = 0
         for i in range(len(transaction)):
-            k += 1
             if transaction[i] not in currentNode.children:
                 newNode = _Node(transaction[i], {})
-                newNode.k = k
                 newNode.probability = sup
-                newNode.secondProbability = probability
                 currentNode.addChild(newNode)
                 if transaction[i] in self.summaries:
                     self.summaries[transaction[i]].append(newNode)
                 else:
                     self.summaries[transaction[i]] = [newNode]
                 currentNode = newNode
             else:
                 currentNode = currentNode.children[transaction[i]]
-                currentNode.k = k
                 currentNode.probability += sup
-                currentNode.secondProbability = max(probability, currentNode.secondProbability)
-        currentNode.TimeStamps = currentNode.TimeStamps + tid
+        currentNode.timeStamps = currentNode.timeStamps + ts
 
-    def conditionalPatterns(self, alpha):
+    def getConditionalPatterns(self, alpha):
         """generates all the conditional patterns of respective node
 
-                :param alpha : it represents the Node in tree
+            :param alpha : it represents the Node in tree
 
-                :type alpha : Node
+            :type alpha : Node
         """
+
         finalPatterns = []
-        finalSets = []
+        finalTimeStamps = []
         sup = []
-        prob = []
         for i in self.summaries[alpha]:
-            set1 = i.TimeStamps
+            set1 = i.timeStamps
             s = i.probability
-            p = i.secondProbability
             set2 = []
             while i.parent.item is not None:
                 set2.append(i.parent.item)
                 i = i.parent
             if len(set2) > 0:
                 set2.reverse()
                 finalPatterns.append(set2)
-                finalSets.append(set1)
+                finalTimeStamps.append(set1)
                 sup.append(s)
-                prob.append(p)
-        finalPatterns, finalSets, support, prob, info = self.conditionalTransactions(finalPatterns, finalSets, sup, prob)
-        return finalPatterns, finalSets, support, prob, info
+        finalPatterns, finalTimeStamps, support, info = self.conditionalTransactions(finalPatterns, finalTimeStamps,
+                                                                                     sup)
+        return finalPatterns, finalTimeStamps, support, info
 
     def removeNode(self, nodeValue):
         """removing the node from tree
 
             :param nodeValue : it represents the node in tree
 
             :type nodeValue : node
         """
         for i in self.summaries[nodeValue]:
-            i.parent.TimeStamps = i.parent.TimeStamps + i.TimeStamps
+            i.parent.timeStamps = i.parent.timeStamps + i.timeStamps
             del i.parent.children[nodeValue]
 
-    def getPeriodAndSupport(self, support, TimeStamps, probability):
-        """
-
-        Parameters
-        ----------
-        support: support of pattern
-        probability: support of pattern
-        TimeStamps: timmeStamps of a pattern
-
-        Returns
-        -------
-        support and period
-
-        """
-        global _maxPer
-        global _lno
-        TimeStamps.sort()
+    def getPeriodAndSupport(self, s, timeStamps):
+        global _lno, _maxPer
+        timeStamps.sort()
         cur = 0
         per = 0
-        sup = support
-        for j in range(len(TimeStamps)):
-            per = max(per, TimeStamps[j] - cur)
+        sup = s
+        for j in range(len(timeStamps)):
+            per = max(per, timeStamps[j] - cur)
             if per > _maxPer:
                 return [0, 0]
-            cur = TimeStamps[j]
+            cur = timeStamps[j]
         per = max(per, _lno - cur)
         return [sup, per]
 
-    def conditionalTransactions(self, conditionalPatterns, conditionalTimeStamps, support, probability):
+    def conditionalTransactions(self, condPatterns, condTimeStamps, support):
         """ It generates the conditional patterns with frequent items
 
-            :param conditionalPatterns : conditional patterns generated from conditionalPatterns() method for respective node
+                :param condPatterns : conditional patterns generated from getConditionalPatterns method for respective node
 
-            :type conditionalPatterns : list
+                :type condPatterns : list
 
-            :param conditionalTimeStamps : timestamps of respective conditional timestamps
+                :param condTimeStamps: timeStamps of conditional transactions
 
-            :type conditionalTimeStamps : list
+                :type condTimeStamps: list
 
-            :param support : the support of conditional pattern in tree
+                :param support : the support of conditional pattern in tree
 
-            :type support : list
+                :type support : list
         """
-        global _minSup, _maxPer, _lno
+        global _minSup, _maxPer
         pat = []
-        TimeStamps = []
+        timeStamps = []
         sup = []
-        prob = []
         data1 = {}
         count = {}
-        probab = {}
-        for i in range(len(conditionalPatterns)):
-            for j in conditionalPatterns[i]:
+        for i in range(len(condPatterns)):
+            for j in condPatterns[i]:
                 if j in data1:
-                    data1[j] = data1[j] + conditionalTimeStamps[i]
+                    data1[j] = data1[j] + condTimeStamps[i]
                     count[j] += support[i]
-                    probab[j].append(probability[i])
                 else:
-                    data1[j] = conditionalTimeStamps[i]
+                    data1[j] = condTimeStamps[i]
                     count[j] = support[i]
-                    probab[j] = [probability[i]]
         updatedDict = {}
-        #for m in data1:
-            #print(m, data1[m], count[m])
         for m in data1:
-            updatedDict[m] = self.getPeriodAndSupport(count[m], data1[m], probab[m])
+            updatedDict[m] = self.getPeriodAndSupport(count[m], data1[m])
         updatedDict = {k: v for k, v in updatedDict.items() if v[0] >= _minSup and v[1] <= _maxPer}
         count = 0
-        for p in conditionalPatterns:
+        for p in condPatterns:
             p1 = [v for v in p if v in updatedDict]
             trans = sorted(p1, key=lambda x: (updatedDict.get(x)[0]), reverse=True)
             if len(trans) > 0:
                 pat.append(trans)
-                TimeStamps.append(conditionalTimeStamps[count])
+                timeStamps.append(condTimeStamps[count])
                 sup.append(support[count])
-                prob.append(probability[count])
             count += 1
-        return pat, TimeStamps, sup, prob, updatedDict
-
-    def findParent(self, node, name):
-        while node.parent != None:
-            if node.parent.item == name:
-                return True
-            node.parent = node.parent.parent
-        return False
-
-
-    def getTimeStamps(self, alpha):
-        """ To get all the timestamps of the nodes which share same item name
-
-            :param alpha: Node in a tree
-            :return: Timestamps of a  node
-        """
-        temporary = []
-        support = int()
-        maxProbability = int()
-        for i in self.summaries[alpha]:
-            temporary += i.timeStamps
-            support += i.probability
-        return temporary
+        return pat, timeStamps, sup, updatedDict
 
     def generatePatterns(self, prefix, periodic):
         """generates the patterns
 
             :param prefix : forms the combination of items
 
             :type prefix : list
         """
+
         global _minSup
         for i in sorted(self.summaries, key=lambda x: (self.info.get(x)[0])):
             pattern = prefix[:]
             pattern.append(i)
-            if len(pattern) <= 2:
-                periodic[tuple(pattern)] = self.info[i]
-                if self.info[i][0] >= _minSup:
-                    periodic[tuple(pattern)] = self.info[i]
-                    patterns, TimeStamps, support, probability, info = self.conditionalPatterns(i)
-                    conditionalTree = _Tree()
-                    conditionalTree.info = info.copy()
-                    for pat in range(len(patterns)):
-                        conditionalTree.addConditionalPatterns(patterns[pat], TimeStamps[pat], support[pat],
-                                                               probability[pat])
-                    if len(patterns) > 0:
-                        conditionalTree.generatePatterns(pattern, periodic)
-                self.removeNode(i)
-            if len(pattern) >= 3:
-                support, probability = 0, 0
-                for k in pattern:
-                    for j in self.summaries[i]:
-                        probability = max(probability, j.secondProbability)
-                periodic[tuple(pattern)] = self.info[i]
-                #print(pattern, support * probability)
-                if self.info[i][0] * probability >= _minSup:
-                    periodic[tuple(pattern)] = self.info[i]
-                    patterns, TimeStamps, support, probability, info = self.conditionalPatterns(i)
-                    conditionalTree = _Tree()
-                    conditionalTree.info = info.copy()
-                    for pat in range(len(patterns)):
-                        conditionalTree.addConditionalPatterns(patterns[pat], TimeStamps[pat], support[pat],
-                                                               probability[pat])
-                    if len(patterns) > 0:
-                        conditionalTree.generatePatterns(pattern, periodic)
-                self.removeNode(i)
-
-
-
-
-
+            s = 0
+            for x in self.summaries[i]:
+                s += x.probability
+            periodic[tuple(pattern)] = self.info[i]
+            if s >= _minSup:
+                patterns, timeStamps, support, info = self.getConditionalPatterns(i)
+                conditionalTree = _Tree()
+                conditionalTree.info = info.copy()
+                for pat in range(len(patterns)):
+                    conditionalTree.addConditionalTransaction(patterns[pat], timeStamps[pat], support[pat])
+                if len(patterns) > 0:
+                    conditionalTree.generatePatterns(pattern, periodic)
+            self.removeNode(i)
 
 
-
-class PTubeP(_ab._periodicFrequentPatterns):
+class UPFPGrowth(_ab._periodicFrequentPatterns):
     """
-        Periodic-TubeP is  to discover periodic-frequent patterns in a temporal database.
+    Description:
+    -------------
 
-        Reference:
-        --------
+        UPFPGrowth is  to discover periodic-frequent patterns in a uncertain temporal database.
 
+    Reference:
+    ---------------
+            Uday Kiran, R., Likhitha, P., Dao, MS., Zettsu, K., Zhang, J. (2021).
+            Discovering Periodic-Frequent Patterns in Uncertain Temporal Databases. In:
+            Mantoro, T., Lee, M., Ayu, M.A., Wong, K.W., Hidayanto, A.N. (eds) Neural Information Processing.
+            ICONIP 2021. Communications in Computer and Information Science, vol 1516. Springer, Cham.
+            https://doi.org/10.1007/978-3-030-92307-5_83
 
-        Attributes:
-        ----------
-            iFile: file
-                Name of the Input file or path of input file
-            oFile: file
+    Attributes:
+    -----------------
+            iFile : file
+                Name of the Input file or path of the input file
+            oFile : file
                 Name of the output file or path of output file
             minSup: int or float or str
                 The user can specify minSup either in count or proportion of database size.
                 If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
                 Otherwise, it will be treated as float.
                 Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
             maxPer: int or float or str
@@ -438,125 +409,127 @@
                 To store the total amount of USS memory consumed by the program
             memoryRSS: float
                 To store the total amount of RSS memory consumed by the program
             startTime: float
                 To record the start time of the mining process
             endTime: float
                 To record the completion time of the mining process
-            Database: list
+            Database : list
                 To store the transactions of a database in list
-            mapSupport: Dictionary
+            mapSupport : Dictionary
                 To maintain the information of item and their frequency
-            lno: int
+            _lno : int
                 To represent the total no of transaction
-            tree: class
+            tree : class
                 To represents the Tree class
-            itemSetCount: int
-                To represents the total no of patterns
-            finalPatterns: dict
+            finalPatterns : dict
                 To store the complete patterns
-        Methods:
-        -------
+
+    Methods:
+    --------------
             startMine()
                 Mining process will start from here
             getPatterns()
                 Complete set of patterns will be retrieved with this function
-            savePatterns(oFile)
+            save(oFile)
                 Complete set of periodic-frequent patterns will be loaded in to a output file
             getPatternsAsDataFrame()
                 Complete set of periodic-frequent patterns will be loaded in to a dataframe
             getMemoryUSS()
                 Total amount of USS memory consumed by the mining process will be retrieved from this function
             getMemoryRSS()
                 Total amount of RSS memory consumed by the mining process will be retrieved from this function
             getRuntime()
                 Total amount of runtime taken by the mining process will be retrieved from this function
-            creatingItemSets(fileName)
+            creatingItemSets()
                 Scans the dataset and stores in a list format
-            updateDatabases()
+            PeriodicFrequentOneItem()
+                Extracts the one-periodic-frequent patterns from database
+            updateTransaction()
                 Update the database by removing aperiodic items and sort the Database by item decreased support
             buildTree()
                 After updating the Database, remaining items will be added into the tree by setting root node as null
             convert()
                 to convert the user specified value
-            PeriodicFrequentOneItems()
-                To extract the one-length periodic-frequent items
+            removeFalsePositives()
+                to remove the false positives in generated patterns
 
-        Executing the code on terminal:
+    Executing the code on terminal:
+    --------------------------------------------
+        Format:
         -------
-            Format:
-            ------
-                python3 PTubeP.py <inputFile> <outputFile> <minSup> <maxPer>
 
-            Examples:
-            --------
-                python3 PTubeP.py sampleTDB.txt patterns.txt 0.3 4     (minSup and maxPer will be considered in support count or frequency)
+           >>> python3 UPFPGrowth.py <inputFile> <outputFile> <minSup> <maxPer>
 
-        Sample run of importing the code:
-        -------------------
+        Examples:
+        ------------------------
+           >>> python3 UPFPGrowth.py sampleTDB.txt patterns.txt 0.3 4     (minSup and maxPer will be considered in support count or frequency)
 
-            from PAMI.uncertainPeriodicFrequentPattern.basic import PTubeP as alg
+    **Importing this algorithm into a python program**
+    -----------------------------------------------------------------
 
-            obj = alg.PTubeP(iFile, minSup, maxPer)
+    .. code-block:: python
 
-            obj.startMine()
+        from PAMI.uncertainPeriodicFrequentPattern import UPFPGrowth as alg
 
-            periodicFrequentPatterns = obj.getPatterns()
+        obj = alg.UPFPGrowth(iFile, minSup, maxPer)
 
-            print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
+        obj.startMine()
 
-            obj.savePatterns(oFile)
+        periodicFrequentPatterns = obj.getPatterns()
 
-            Df = obj.getPatternsAsDataFrame()
+        print("Total number of Periodic Frequent Patterns:", len(periodicFrequentPatterns))
 
-            memUSS = obj.getMemoryUSS()
+        obj.save(oFile)
 
-            print("Total Memory in USS:", memUSS)
+        Df = obj.getPatternsAsDataFrame()
 
-            memRSS = obj.getMemoryRSS()
+        memUSS = obj.getMemoryUSS()
 
-            print("Total Memory in RSS", memRSS)
+        print("Total Memory in USS:", memUSS)
 
-            run = obj.getRuntime()
+        memRSS = obj.getMemoryRSS()
 
-            print("Total ExecutionTime in seconds:", run)
+        print("Total Memory in RSS", memRSS)
 
-        Credits:
-        -------
-            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
+        run = obj.getRuntime()
+
+        print("Total ExecutionTime in seconds:", run)
+
+    Credits:
+    -------
+        The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
 
     """
+    _rank = {}
     _startTime = float()
     _endTime = float()
     _minSup = float()
     _maxPer = float()
     _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
     _memoryUSS = float()
     _memoryRSS = float()
     _Database = []
-    _rank = {}
     _lno = 0
     _periodic = {}
 
     def _creatingItemSets(self):
         """
             Storing the complete transactions of the database/input file in a database variable
 
-
         """
-
         self._Database = []
         if isinstance(self._iFile, _ab._pd.DataFrame):
             uncertain, data, ts = [], [], []
             if self._iFile.empty:
                 print("its empty..")
-            i = self._iFile.columns.values.tolist()
+            i = self._iFile._columns.values.tolist()
             if 'TS' in i:
                 ts = self._iFile['TS'].tolist()
             if 'Transactions' in i:
                 data = self._iFile['Transactions'].tolist()
             if 'uncertain' in i:
                 uncertain = self._iFile['uncertain'].tolist()
             for k in range(len(data)):
@@ -568,132 +541,158 @@
                 self._lno += 1
 
             # print(self.Database)
         if isinstance(self._iFile, str):
             if _ab._validators.url(self._iFile):
                 data = _ab._urlopen(self._iFile)
                 for line in data:
-                    line.strip()
                     line = line.decode("utf-8")
-                    temp = [i.rstrip() for i in line.split(self._sep)]
-                    temp = [x for x in temp if x]
-                    tr = [int(temp[0])]
-                    for i in temp[1:]:
-                        i1 = i.index('(')
-                        i2 = i.index(')')
-                        item = i[0:i1]
-                        probability = float(i[i1 + 1:i2])
+                    line = line.strip()
+                    line = [i for i in line.split(':')]
+                    temp1 = [i.rstrip() for i in line[0].split(self._sep)]
+                    temp2 = [i.rstrip() for i in line[1].split(self._sep)]
+                    temp1 = [x for x in temp1 if x]
+                    temp2 = [x for x in temp2 if x]
+                    tr = [int(temp1[0])]
+                    for i in range(len(temp1[1:])):
+                        item = temp1[i]
+                        probability = float(temp2[i])
                         product = _Item(item, probability)
                         tr.append(product)
                     self._lno += 1
                     self._Database.append(tr)
             else:
                 try:
                     count = 0
                     with open(self._iFile, 'r') as f:
                         for line in f:
-                            count += 1
-                            temp = [i.rstrip() for i in line.split(self._sep)]
-                            temp = [x for x in temp if x]
-                            tr = [int(temp[0])]
-                            for i in temp[1:]:
-                                i1 = i.index('(')
-                                i2 = i.index(')')
-                                item = i[0:i1]
-                                probability = float(i[i1 + 1:i2])
+                            #count += 1
+                            line = line.strip()
+                            line = [i for i in line.split(':')]
+                            temp1 = [i.rstrip() for i in line[0].split(self._sep)]
+                            temp2 = [i.rstrip() for i in line[1].split(self._sep)]
+                            temp1 = [x for x in temp1 if x]
+                            temp2 = [x for x in temp2 if x]
+                            tr = [int(temp1[0])]
+                            for i in range(len(temp1[1:])):
+                                item = temp1[i]
+                                probability = float(temp2[i])
                                 product = _Item(item, probability)
                                 tr.append(product)
                             self._lno += 1
                             self._Database.append(tr)
                 except IOError:
                     print("File Not Found")
 
-    def _PeriodicFrequentOneItems(self):
+    def _periodicFrequentOneItem(self):
         """takes the transactions and calculates the support of each item in the dataset and assign the
-                            ranks to the items by decreasing support and returns the frequent items list
+                    ranks to the items by decreasing support and returns the frequent items list
 
         """
-        global first, last
         mapSupport = {}
         for i in self._Database:
-            n = int(i[0])
+            n = i[0]
             for j in i[1:]:
                 if j.item not in mapSupport:
                     mapSupport[j.item] = [round(j.probability, 3), abs(0 - n), n]
                 else:
-                    mapSupport[j.item][0] += round(j.probability, 2)
+                    mapSupport[j.item][0] += round(j.probability, 3)
                     mapSupport[j.item][1] = max(mapSupport[j.item][1], abs(n - mapSupport[j.item][2]))
                     mapSupport[j.item][2] = n
         for key in mapSupport:
             mapSupport[key][1] = max(mapSupport[key][1], self._lno - mapSupport[key][2])
-        mapSupport = {k: [round(v[0], 2), v[1]] for k, v in mapSupport.items() if
-                      v[1] <= self._maxPer and v[0] >= self._minSup}
+        mapSupport = {k: [v[0], v[1]] for k, v in mapSupport.items() if v[1] <= self._maxPer and v[0] >= self._minSup}
         plist = [k for k, v in sorted(mapSupport.items(), key=lambda x: (x[1][0], x[0]), reverse=True)]
         self._rank = dict([(index, item) for (item, index) in enumerate(plist)])
         return mapSupport, plist
 
+    def _check(self, i, x):
+        """To check the presence of item or pattern in transaction
+
+            :param x: it represents the pattern
+
+            :type x : list
+
+            :param i : represents the uncertain transactions
+
+            :type i : list
+        """
+
+        for m in x:
+            k = 0
+            for n in i:
+                if m == n.item:
+                    k += 1
+            if k == 0:
+                return 0
+        return 1
+
+    def _getPeriodAndSupport(self, s, timeStamps):
+        """
+        To calculate periodicity of timeStamps
+
+            :param s: support of a pattern
+
+            :param timeStamps: timeStamps of a pattern
+
+            :return: periodicity and Support
+        """
+        global __lno, _maxPer
+        timeStamps.sort()
+        cur = 0
+        per = 0
+        sup = s
+        for j in range(len(timeStamps)):
+            per = max(per, timeStamps[j] - cur)
+            if per > _maxPer:
+                return [0, 0]
+            cur = timeStamps[j]
+        per = max(per, _lno - cur)
+        return [sup, per]
+
     def _buildTree(self, data, info):
         """it takes the transactions and support of each item and construct the main tree with setting root
-                            node as null
+                    node as null
 
-            :param data : it represents the one transactions in database
+            :param data: it represents the one transactions in database
 
-            :type data : list
+            :type data: list
 
-            :param info : it represents the support of each item
+            :param info: it represents the support of each item
 
             :type info : dictionary
         """
         rootNode = _Tree()
         rootNode.info = info.copy()
         for i in range(len(data)):
             set1 = [data[i][0]]
-            rootNode.addTransaction(data[i][1:], set1)
+            rootNode.addTransactions(data[i][1:], set1)
         return rootNode
 
     def _updateTransactions(self, dict1):
         """remove the items which are not frequent from transactions and updates the transactions with rank of items
 
-                :param dict1 : frequent items with support
+            :param dict1 : frequent items with support
 
-                :type dict1 : dictionary
+            :type dict1 : dictionary
         """
+
         list1 = []
         for tr in self._Database:
             list2 = [int(tr[0])]
             for i in range(1, len(tr)):
                 if tr[i].item in dict1:
                     list2.append(tr[i])
             if len(list2) >= 2:
                 basket = list2[1:]
                 basket.sort(key=lambda val: self._rank[val.item])
                 list2[1:] = basket[0:]
                 list1.append(list2)
         return list1
 
-    def _Check(self, i, x):
-        """To check the presence of item or pattern in transaction
-
-            :param x: it represents the pattern
-
-            :type x : list
-
-            :param i : represents the uncertain transactions
-
-            :type i : list
-        """
-        for m in x:
-            k = 0
-            for n in i:
-                if m == n.item:
-                    k += 1
-            if k == 0:
-                return 0
-        return 1
-
     def _convert(self, value):
         """
             To convert the given user specified value
 
             :param value: user specified value
 
             :return: converted value
@@ -703,70 +702,68 @@
         if type(value) is float:
             value = float(value)
         if type(value) is str:
             if '.' in value:
                 value = float(value)
             else:
                 value = int(value)
+
         return value
 
     def _removeFalsePositives(self):
         """
-        To remove false positives in generated patterns
 
-        :return: original patterns
+        Returns
+        -------
+            removes the false positive patterns in generated patterns
         """
         periods = {}
         for i in self._Database:
             for x, y in self._periodic.items():
                 if len(x) == 1:
                     periods[x] = y
                 else:
                     s = 1
-                    check = self._Check(i[1:], x)
+                    check = self._check(i[1:], x)
                     if check == 1:
                         for j in i[1:]:
                             if j.item in x:
                                 s *= j.probability
                         if x in periods:
                             periods[x][0] += s
                         else:
                             periods[x] = [s, y[1]]
-
-        count = 0
         for x, y in periods.items():
             if y[0] >= _minSup:
-                count += 1
                 sample = str()
                 for i in x:
                     sample = sample + i + "\t"
                 self._finalPatterns[sample] = y
-        #print("Total false patterns generated:", len(self._periodic) - count)
 
     def startMine(self):
         """Main method where the patterns are mined by constructing tree and remove the remove the false patterns
-                           by counting the original support of a patterns
+                    by counting the original support of a patterns
 
 
-               """
-        global _minSup, _maxPer, _first, _last, _lno
+        """
+        global _lno, _maxPer, _minSup, _first, _last, periodic
         self._startTime = _ab._time.time()
         self._creatingItemSets()
+        self._finalPatterns = {}
         self._minSup = self._convert(self._minSup)
         self._maxPer = self._convert(self._maxPer)
-        self._finalPatterns = {}
-        _minSup, _maxPer, _lno = self._minSup, self._maxPer, len(self._Database)
-        mapSupport, plist = self._PeriodicFrequentOneItems()
+        _minSup, _maxPer, _lno = self._minSup, self._maxPer, self._lno
+        mapSupport, plist = self._periodicFrequentOneItem()
         updatedTrans = self._updateTransactions(mapSupport)
         info = {k: v for k, v in mapSupport.items()}
-        root = self._buildTree(updatedTrans, info)
+        Tree1 = self._buildTree(updatedTrans, info)
         self._periodic = {}
-        root.generatePatterns([], self._periodic)
+        Tree1.generatePatterns([], self._periodic)
         self._removeFalsePositives()
-        print("Periodic Frequent patterns were generated successfully using Periodic-TubeP algorithm")
+        print("Periodic frequent patterns were generated successfully using UPFP algorithm")
         self._endTime = _ab._time.time()
         process = _ab._psutil.Process(_ab._os.getpid())
         self._memoryUSS = float()
         self._memoryRSS = float()
         self._memoryUSS = process.memory_full_info().uss
         self._memoryRSS = process.memory_info().rss
 
@@ -807,35 +804,36 @@
 
         :rtype: pd.DataFrame
         """
 
         dataframe = {}
         data = []
         for a, b in self._finalPatterns.items():
-            data.append([a, b[0], b[1]])
+            data.append([a.replace('\t', ' '), b[0], b[1]])
             dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support', 'Periodicity'])
         return dataframe
 
     def save(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
 
         :param outFile: name of the output file
 
         :type outFile: file
         """
-        self._oFile = outFile
-        writer = open(self._oFile, 'w+')
+        self.oFile = outFile
+        writer = open(self.oFile, 'w+')
         for x, y in self._finalPatterns.items():
-            s1 = x + ":" + str(y)
+            s1 = x.strip() + ":" + str(y[0]) + ":" + str(y[1])
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
 
         :return: returning frequent patterns
+
         :rtype: dict
         """
         return self._finalPatterns
 
     def printResults(self):
         print("Total number of  Uncertain Periodic-Frequent Patterns:", len(self.getPatterns()))
         print("Total Memory in USS:", self.getMemoryUSS())
@@ -843,62 +841,29 @@
         print("Total ExecutionTime in ms:",  self.getRuntime())
 
 
 if __name__ == "__main__":
     _ap = str()
     if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
         if len(_ab._sys.argv) == 6:
-            _ap = PTubeP(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
+            _ap = UPFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
         if len(_ab._sys.argv) == 5:
-            _ap = PTubeP(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+            _ap = UPFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
         _ap.startMine()
-        _Patterns = _ap.getPatterns()
-        print("Total number of Patterns:", len(_Patterns))
-        _ap.savePatterns(_ab._sys.argv[2])
-        # print(ap.getPatternsAsDataFrame())
-        _memUSS = _ap.getMemoryUSS()
-        print("Total Memory in USS:", _memUSS)
-        _memRSS = _ap.getMemoryRSS()
-        print("Total Memory in RSS", _memRSS)
-        _run = _ap.getRuntime()
-        print("Total ExecutionTime in ms:", _run)
+        print("Total number of Uncertain Periodic-Frequent Patterns:", len(_ap.getPatterns()))
+        _ap.save(_ab._sys.argv[2])
+        print("Total Memory in USS:", _ap.getMemoryUSS())
+        print("Total Memory in RSS", _ap.getMemoryRSS())
+        print("Total ExecutionTime in ms:", _ap.getRuntime())
     else:
-        l = [400, 500, 600, 700, 800]
-        for i in l:
-            ap = PTubeP('/Users/Likhitha/Downloads/uncertain/additionalMaterial/T10I4D200K.txt', i, 8000, ' ')
-            ap.startMine()
-            Patterns = ap.getPatterns()
-            print("Total number of Patterns:", len(Patterns))
-            ap.save('/Users/Likhitha/Downloads/uncertain/output.txt')
-            memUSS = ap.getMemoryUSS()
-            print("Total Memory in USS:", memUSS)
-            memRSS = ap.getMemoryRSS()
-            print("Total Memory in RSS", memRSS)
-            run = ap.getRuntime()
-            print("Total ExecutionTime in ms:", run)
-
-        '''l = [0.04]
-        for i in l:
-            ap = PTubeP('sample', i, 6, ' ')
-            ap.startMine()
-            Patterns = ap.getPatterns()
-            print("Total number of Patterns:", len(Patterns))l = [400, 500, 600, 700, 800]
-        for i in l:
-            ap = PTubeP('/Users/Likhitha/Downloads/uncertain/additionalMaterial/T10I4D200K.txt', i, 8000, ' ')
-            ap.startMine()
-            Patterns = ap.getPatterns()
-            print("Total number of Patterns:", len(Patterns))
-            ap.save('/Users/Likhitha/Downloads/uncertain/output.txt')
-            memUSS = ap.getMemoryUSS()
-            print("Total Memory in USS:", memUSS)
-            memRSS = ap.getMemoryRSS()
-            print("Total Memory in RSS", memRSS)
-            run = ap.getRuntime()
-            print("Total ExecutionTime in ms:", run)
-            ap.save('output.txt')
-            memUSS = ap.getMemoryUSS()
-            print("Total Memory in USS:", memUSS)
-            memRSS = ap.getMemoryRSS()
-            print("Total Memory in RSS", memRSS)
-            run = ap.getRuntime()
-            print("Total ExecutionTime in ms:", run)'''
+        ap = UPFPGrowth('/Users/likhitha/Downloads/uncertainTemporal_T10I4D100K.csv', 500, 5000, '\t')
+        ap.startMine()
+        Patterns = ap.getPatterns()
+        print("Total number of Patterns:", len(Patterns))
+        ap.save('/Users/Likhitha/Downloads/uncertain/output.txt')
+        memUSS = ap.getMemoryUSS()
+        print("Total Memory in USS:", memUSS)
+        memRSS = ap.getMemoryRSS()
+        print("Total Memory in RSS", memRSS)
+        run = ap.getRuntime()
+        print("Total ExecutionTime in ms:", run)
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/uncertainProbablisticFrequentPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/weightedUncertainFrequentPattern/basic/abstract.py`

 * *Files 10% similar despite different names*

```diff
@@ -9,29 +9,30 @@
 import os.path as _ospath
 import psutil as _psutil
 import sys as _sys
 import validators as _validators
 from urllib.request import urlopen as _urlopen
 
 
-class _frequentPatterns(_ABC):
+class _weightedFrequentPatterns(_ABC):
     """ This abstract base class defines the variables and methods that every frequent pattern mining algorithm must
     employ in PAMI
 
     ...
 
     Attributes:
     ----------
         iFile : str
             Input file name or path of the input file
-        minSup: float or int or str
-            The user can specify minSup either in count or proportion of database size.
-            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+        wFile : str
+            Input file name or path of the input file
+        expSup: float or int or str
+            The user can specify expSup in count.
+        expWeSup: float or int or str
+            The user can specify  in count .
         sep : str
             This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
             However, the users can override their default separator.
         startTime:float
             To record the start time of the algorithm
         endTime:float
             To record the completion time of the algorithm
@@ -58,29 +59,32 @@
             Total amount of USS memory consumed by the program will be retrieved from this function
         getMemoryRSS()
             Total amount of RSS memory consumed by the program will be retrieved from this function
         getRuntime()
             Total amount of runtime taken by the program will be retrieved from this function
     """
 
-    def __init__(self, iFile, minSup, sep = '\t'):
+    def __init__(self, iFile, wFile, expSup, expWSup, sep = '\t'):
         """
         :param iFile: Input file name or path of the input file
         :type iFile: str
-        :param minSup: The user can specify minSup either in count or proportion of database size.
-            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-        :type minSup: int or float or str
+        :param wFile: Input file name or path of the input file
+        :type wFile: str
+        :param expSup: The user can specify expSup  in count
+        :type expSup: int or float or str
+        :param expWSup: The user can specify expWSup  in count
+        :type expWSup: int or float or str
         :param sep: separator used to distinguish items from each other. The default separator is tab space. However, users can override the default separator
         :type sep: str
         """
 
         self._iFile = iFile
-        self._minSup = minSup
+        self._wFile = wFile
+        self._expSup = expSup
+        self._expWSup = expWSup
         self._sep = sep
         self._oFile = " "
         self._finalPatterns = {}
         self._startTime = float()
         self._endTime = float()
         self._memoryUSS = float()
         self._memoryRSS = float()
```

### Comparing `pami-2023.4.1/PAMI/weightedFrequentNeighbourhoodPattern/basic/SWFPGrowth.py` & `pami-2023.5.1/PAMI/geoReferencedFrequentPattern/GFPGrowth.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,736 +1,763 @@
-#  Copyright (C)  2021 Rage Uday Kiran
+
+# **Importing this algorithm into a python program**
+# --------------------------------------------------------
+#
+#     from PAMI.geoReferenceFrequentPattern.basic import GFPGrowth as alg
+#
+#     obj = alg.GFPGrowth(iFile, nFile, minSup)
+#
+#     obj.startMine()
+#
+#     Patterns = obj.getPatterns()
+#
+#     print("Total number of  Patterns:", len(Patterns))
+#
+#     obj.savePatterns(oFile)
+#
+#     Df = obj.getPatternsAsDataFrame()
+#
+#     memUSS = obj.getMemoryUSS()
+#
+#     print("Total Memory in USS:", memUSS)
+#
+#     memRSS = obj.getMemoryRSS()
+#
+#     print("Total Memory in RSS", memRSS)
 #
-#      This program is free software: you can redistribute it and/or modify
-#      it under the terms of the GNU General Public License as published by
-#      the Free Software Foundation, either version 3 of the License, or
-#      (at your option) any later version.
-#
-#      This program is distributed in the hope that it will be useful,
-#      but WITHOUT ANY WARRANTY; without even the implied warranty of
-#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#      GNU General Public License for more details.
-#
-#      You should have received a copy of the GNU General Public License
-#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
-
-from PAMI.weightedFrequentNeighbourhoodPattern.basic import abstract as _fp
-
-_minWS = str()
-_weights = {}
-_rank = {}
+#     run = obj.getRuntime()
+#
+#     print("Total ExecutionTime in seconds:", run)
+#
+
+__copyright__ = """
+ Copyright (C)  2021 Rage Uday Kiran
+
+     This program is free software: you can redistribute it and/or modify
+     it under the terms of the GNU General Public License as published by
+     the Free Software Foundation, either version 3 of the License, or
+     (at your option) any later version.
+
+     This program is distributed in the hope that it will be useful,
+     but WITHOUT ANY WARRANTY; without even the implied warranty of
+     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+     GNU General Public License for more details.
+
+     You should have received a copy of the GNU General Public License
+     along with this program.  If not, see <https://www.gnu.org/licenses/>.
+     Copyright (C)  2021 Rage Uday Kiran
+
+"""
+
+# from geoReferencedFrequentPatterns import abstract as _ab
+from PAMI.geoReferencedFrequentPaterns import abstract as _ab
+# import abstract as _ab
+
+_minSup = str()
 _neighbourList = {}
+_ab._sys.setrecursionlimit(20000)
+_finalPatterns = {}
 
-_fp._sys.setrecursionlimit(20000)
 
+class _Item:
+    """
+    A class used to represent the item with probability in transaction of dataset
+    ...
+    Attributes:
+    __________
+        item : int or word
+            Represents the name of the item
+        probability : float
+            Represent the existential probability(likelihood presence) of an item
+    """
 
-class _WeightedItem:
-    def __init__(self, item, weight):
+    def __init__(self, item, probability):
         self.item = item
-        self.weight = weight
+        self.probability = probability
 
 
-class _Node:
+class _Node(object):
     """
-        A class used to represent the node of frequentPatternTree
-
+    A class used to represent the node of frequentPatternTree
+        ...
     Attributes:
     ----------
-        itemId: int
+        item : int
             storing item of a node
-        counter: int
-            To maintain the support of node
-        parent: node
-            To maintain the parent of node
-        children: list
+        probability : int
+            To maintain the expected support of node
+        parent : node
+            To maintain the parent of every node
+        children : list
             To maintain the children of node
-
     Methods:
     -------
-
-        addChild(node)
-            Updates the nodes children list and parent for the given node
-
+        addChild(itemName)
+            storing the children to their respective parent nodes
     """
 
     def __init__(self, item, children):
-        self.itemId = item
-        self.counter = 1
-        self.weight = 0
-        self.parent = None
+        self.item = item
+        self.probability = 1
         self.children = children
+        self.parent = None
 
     def addChild(self, node):
-        """
-            Retrieving the child from the tree
-
-            :param node: Children node
-            :type node: Node
-            :return: Updates the children nodes and parent nodes
-
-        """
-        self.children[node.itemId] = node
+        self.children[node.item] = node
         node.parent = self
 
 
-class _Tree:
+class _Tree(object):
     """
     A class used to represent the frequentPatternGrowth tree structure
-
+    ...
     Attributes:
     ----------
         root : Node
-            The first node of the tree set to Null.
+            Represents the root node of the tree
         summaries : dictionary
-            Stores the nodes itemId which shares same itemId
+            storing the nodes with same item name
         info : dictionary
-            frequency of items in the transactions
-
+            stores the support of items
     Methods:
     -------
-        addTransaction(transaction, freq)
-            adding items of  transactions into the tree as nodes and freq is the count of nodes
-        getFinalConditionalPatterns(node)
-            getting the conditional patterns from fp-tree for a node
-        getConditionalPatterns(patterns, frequencies)
-            sort the patterns by removing the items with lower minWS
-        generatePatterns(prefix)
-            generating the patterns from fp-tree
+        addTransaction(transaction)
+            creating transaction as a branch in frequentPatternTree
+        addConditionalPattern(prefixPaths, supportOfItems)
+            construct the conditional tree for prefix paths
+        conditionalPatterns(Node)
+            generates the conditional patterns from tree for specific node
+        conditionalTransactions(prefixPaths,Support)
+            takes the prefixPath of a node and support at child of the path and extract the frequent items from
+            prefixPaths and generates prefixPaths with items which are frequent
+        remove(Node)
+            removes the node from tree once after generating all the patterns respective to the node
+        generatePatterns(Node)
+            starts from the root node of the tree and mines the frequent patterns
     """
 
     def __init__(self):
         self.root = _Node(None, {})
         self.summaries = {}
         self.info = {}
 
-    def addTransaction(self, transaction, count):
+    def addTransaction(self, transaction):
         """adding transaction into tree
-
-        :param transaction: it represents the one transactions in database
-
-        :type transaction: list
-
-        :param count: frequency of item
-
-        :type count: int
+            :param transaction : it represents the one self.Database in database
+            :type transaction : list
         """
-
-        # This method takes transaction as input and returns the tree
-        global _neighbourList, _rank
+        global _neighbourList
         currentNode = self.root
         for i in range(len(transaction)):
-            wei = 0
-            l1 = i
-            while l1 >= 0:
-                wei += transaction[l1].weight
-                l1 -= 1
             if transaction[i].item not in currentNode.children:
                 newNode = _Node(transaction[i].item, {})
-                newNode.freq = count
-                newNode.weight = wei
+                nei = _neighbourList.get(transaction[i].item)
+                l1 = i - 1
+                lp = []
+                while l1 >= 0:
+                    if nei == None:
+                        break
+                    if transaction[l1].item in nei:
+                        lp.append(transaction[l1].probability)
+                    l1 -= 1
+                if len(lp) == 0:
+                    newNode.probability = transaction[i].probability
+                else:
+                    newNode.probability = max(lp) * transaction[i].probability
                 currentNode.addChild(newNode)
-                if _rank[transaction[i].item] in self.summaries:
-                    self.summaries[_rank[transaction[i].item]].append(newNode)
+                if transaction[i].item in self.summaries:
+                    self.summaries[transaction[i].item].append(newNode)
                 else:
-                    self.summaries[_rank[transaction[i].item]] = [newNode]
+                    self.summaries[transaction[i].item] = [newNode]
                 currentNode = newNode
             else:
                 currentNode = currentNode.children[transaction[i].item]
-                currentNode.freq += count
-                currentNode.weight += wei
-
-    def addConditionalPattern(self, transaction, count):
-        """adding transaction into tree
-
-        :param transaction: it represents the one transactions in database
-
-        :type transaction: list
-
-        :param count: frequency of item
+                l1 = i - 1
+                lp = []
+                while l1 >= 0:
+                    lp.append(transaction[l1].probability)
+                    l1 -= 1
+                if len(lp) == 0:
+                    currentNode.probability += transaction[i].probability
+                else:
+                    currentNode.probability += max(lp) * transaction[i].probability
 
-        :type count: int
+    def addConditionalPattern(self, transaction, sup):
+        """constructing conditional tree from prefixPaths
+            :param transaction : it represents the one self.Database in database
+            :type transaction : list
+            :param sup : support of prefixPath taken at last child of the path
+            :type sup : int
         """
 
-        # This method takes transaction as input and returns the tree
-        global _neighbourList, _rank
+        # This method takes transaction, support and constructs the conditional tree
         currentNode = self.root
         for i in range(len(transaction)):
-            wei = 0
-            l1 = i
-            while l1 >= 0:
-                wei += transaction[l1].weight
-                l1 -= 1
-            if transaction[i].itemId not in currentNode.children:
-                newNode = _Node(transaction[i].itemId, {})
-                newNode.freq = count
-                newNode.weight = wei
+            if transaction[i] not in currentNode.children:
+                newNode = _Node(transaction[i], {})
+                newNode.probability = sup
                 currentNode.addChild(newNode)
-                if _rank[transaction[i].itemId] in self.summaries:
-                    self.summaries[_rank[transaction[i].itemId]].append(newNode)
+                if transaction[i] in self.summaries:
+                    self.summaries[transaction[i]].append(newNode)
                 else:
-                    self.summaries[_rank[transaction[i].itemId]] = [newNode]
+                    self.summaries[transaction[i]] = [newNode]
                 currentNode = newNode
             else:
-                currentNode = currentNode.children[transaction[i].itemId]
-                currentNode.freq += count
-                currentNode.weight += wei
-
-    def printTree(self, root):
-        if len(root.children) == 0:
-            return
-        else:
-            for x, y in root.children.items():
-                #print(y.itemId, y.parent.itemId, y.freq, y.weight)
-                self.printTree(y)
-
+                currentNode = currentNode.children[transaction[i]]
+                currentNode.probability += sup
 
-    def getFinalConditionalPatterns(self, alpha):
+    def conditionalPatterns(self, alpha):
+        """generates all the conditional patterns of respective node
+            :param alpha : it represents the Node in tree
+            :type alpha : _Node
         """
-        generates the conditional patterns for a node
-
-        Parameters:
-        ----------
-            alpha: node to generate conditional patterns
-
-        Returns
-        -------
-            returns conditional patterns, frequency of each item in conditional patterns
 
-        """
-        finalPatterns = []
-        finalFreq = []
+        # This method generates conditional patterns of node by traversing the tree
         global _neighbourList
+        finalPatterns = []
+        sup = []
         for i in self.summaries[alpha]:
-            set1 = i.weight
+            j = i.item
+            s = i.probability
             set2 = []
-            while i.parent.itemId is not None:
-                if i.parent.itemId in _neighbourList[i.itemId]:
-                    set2.append(i.parent)
+            while i.parent.item is not None:
+                if _neighbourList.get(j) is not None:
+                    #print(_neighbourList.get(j))
+                    if i.parent.item in _neighbourList[j]:
+                        set2.append(i.parent.item)
                 i = i.parent
             if len(set2) > 0:
                 set2.reverse()
                 finalPatterns.append(set2)
-                finalFreq.append(set1)
-        finalPatterns, finalFreq, info = self.getConditionalTransactions(finalPatterns, finalFreq)
-        return finalPatterns, finalFreq, info
+                sup.append(s)
+        finalPatterns, support, info = self.conditionalTransactions(finalPatterns, sup)
+        return finalPatterns, support, info
 
-    @staticmethod
-    def getConditionalTransactions(ConditionalPatterns, conditionalFreq):
+    def removeNode(self, nodeValue):
+        """removing the node from tree
+            :param nodeValue : it represents the node in tree
+            :type nodeValue : node
         """
-        To calculate the frequency of items in conditional patterns and sorting the patterns
-        Parameters
-        ----------
-        ConditionalPatterns: paths of a node
-        conditionalFreq: frequency of each item in the path
 
-        Returns
-        -------
-            conditional patterns and frequency of each item in transactions
+        for i in self.summaries[nodeValue]:
+            del i.parent.children[nodeValue]
+
+    def conditionalTransactions(self, condPatterns, support):
+        """ It generates the conditional patterns with frequent items
+                :param condPatterns : conditionalPatterns generated from conditionalPattern method for respective node
+                :type condPatterns : list
+                :support : the support of conditional pattern in tree
+                :support : int
         """
-        global _rank
+
+        global minSup
         pat = []
-        freq = []
-        data1 = {}
-        for i in range(len(ConditionalPatterns)):
-            for j in ConditionalPatterns[i]:
-                if j.itemId in data1:
-                    data1[j.itemId] += conditionalFreq[i]
+        sup = []
+        count = {}
+        for i in range(len(condPatterns)):
+            for j in condPatterns[i]:
+                if j in count:
+                    count[j] += support[i]
                 else:
-                    data1[j.itemId] = conditionalFreq[i]
-        up_dict = {k: v for k, v in data1.items() if v >= _minWS}
+                    count[j] = support[i]
+        updatedDict = {}
+        updatedDict = {k: v for k, v in count.items() if v >= minSup}
         count = 0
-        for p in ConditionalPatterns:
-            p1 = [v for v in p if v.itemId in up_dict]
-            trans = sorted(p1, key=lambda x: (up_dict.get(x)), reverse=True)
+        for p in condPatterns:
+            p1 = [v for v in p if v in updatedDict]
+            trans = sorted(p1, key=lambda x: updatedDict[x], reverse=True)
             if len(trans) > 0:
                 pat.append(trans)
-                freq.append(conditionalFreq[count])
-            count += 1
-        up_dict = {_rank[k]: v for k, v in up_dict.items()}
-        return pat, freq, up_dict
+                sup.append(support[count])
+                count += 1
+        return pat, sup, updatedDict
 
     def generatePatterns(self, prefix):
+        """generates the patterns
+            :param prefix : forms the combination of items
+            :type prefix : list
         """
-        To generate the frequent patterns
-        Parameters
-        ----------
-        prefix: an empty list
 
-        Returns
-        -------
-        Frequent patterns that are extracted from fp-tree
-
-        """
-        global _minWS
+        global _finalPatterns, minSup
         for i in sorted(self.summaries, key=lambda x: (self.info.get(x))):
             pattern = prefix[:]
             pattern.append(i)
-            yield pattern, self.info[i]
-            patterns, freq, info = self.getFinalConditionalPatterns(i)
-            conditionalTree = _Tree()
-            conditionalTree.info = info.copy()
-            for pat in range(len(patterns)):
-                conditionalTree.addConditionalPattern(patterns[pat], freq[pat])
-            if len(patterns) > 0:
-                for q in conditionalTree.generatePatterns(pattern):
-                    yield q
+            s = 0
+            for x in self.summaries[i]:
+                s += x.probability
+            _finalPatterns[tuple(pattern)] = self.info[i]
+            if s >= minSup:
+                patterns, support, info = self.conditionalPatterns(i)
+                conditionalTree = _Tree()
+                conditionalTree.info = info.copy()
+                for pat in range(len(patterns)):
+                    conditionalTree.addConditionalPattern(patterns[pat], support[pat])
+                if len(patterns) > 0:
+                    conditionalTree.generatePatterns(pattern)
+            self.removeNode(i)
 
 
-class SWFPGrowth(_fp._weightedFrequentSpatialPatterns):
+class GFPGrowth(_ab._frequentPatterns):
     """
-       SWFPGrowth is an algorithm to mine the weighted spatial frequent patterns in spatiotemporal databases.
-
-    Reference :
-    ---------
-        R. Uday Kiran, P. P. C. Reddy, K. Zettsu, M. Toyoda, M. Kitsuregawa and P. Krishna Reddy,
-        "Discovering Spatial Weighted Frequent Itemsets in Spatiotemporal Databases," 2019 International
-        Conference on Data Mining Workshops (ICDMW), 2019, pp. 987-996, doi: 10.1109/ICDMW.2019.00143.
-
-    Attributes :
+    Description:
+    ------------
+        It is one of the fundamental algorithm to discover frequent patterns in a uncertain transactional database
+        using GFP-Tree.
+    Reference:
+    -----------
+        
+    Attributes:
     ----------
         iFile : file
-            Input file name or path of the input file
-        minWS: float or int or str
-            The user can specify minWS either in count or proportion of database size.
-            If the program detects the data type of minWS is integer, then it treats minWS is expressed in count.
-            Otherwise, it will be treated as float.
-            Example: minWS=10 will be treated as integer, while minWS=10.0 will be treated as float
-        minWeight: float or int or str
-            The user can specify minWeight either in count or proportion of database size.
-            If the program detects the data type of minWeight is integer, then it treats minWeight is expressed in count.
+            Name of the Input file or path of the input file
+        oFile : file
+            Name of the output file or path of the output file
+        minSup: float or int or str
+            The user can specify minSup either in count or proportion of database size.
+            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
             Otherwise, it will be treated as float.
-            Example: minWeight=10 will be treated as integer, while minWeight=10.0 will be treated as float
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
         sep : str
-            This variable is used to distinguish items from one another in a transaction. The default separator is tab space or \t.
+            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
             However, the users can override their default separator.
-        oFile : file
-            Name of the output file or the path of the output file
-        startTime:float
-            To record the start time of the mining process
-        endTime:float
-            To record the completion time of the mining process
         memoryUSS : float
             To store the total amount of USS memory consumed by the program
         memoryRSS : float
             To store the total amount of RSS memory consumed by the program
+        startTime:float
+            To record the start time of the mining process
+        endTime:float
+            To record the completion time of the mining process
         Database : list
             To store the transactions of a database in list
         mapSupport : Dictionary
             To maintain the information of item and their frequency
         lno : int
-            it represents the total no of transactions
+            To represent the total no of transaction
         tree : class
-            it represents the Tree class
+            To represents the Tree class
+        itemSetCount : int
+            To represents the total no of patterns
         finalPatterns : dict
-            it represents to store the patterns
-
-    Methods :
-    -------
+            To store the complete patterns
+    Methods:
+    -----------
         startMine()
             Mining process will start from here
         getPatterns()
             Complete set of patterns will be retrieved with this function
-        save(oFile)
+        savePatterns(oFile)
             Complete set of frequent patterns will be loaded in to a output file
         getPatternsAsDataFrame()
             Complete set of frequent patterns will be loaded in to a dataframe
         getMemoryUSS()
             Total amount of USS memory consumed by the mining process will be retrieved from this function
         getMemoryRSS()
             Total amount of RSS memory consumed by the mining process will be retrieved from this function
         getRuntime()
             Total amount of runtime taken by the mining process will be retrieved from this function
-        creatingItemSets()
-            Scans the dataset or dataframes and stores in list format
+        creatingItemSets(fileName)
+            Scans the dataset and stores in a list format
         frequentOneItem()
-            Extracts the one-frequent patterns from transactions
-
+            Extracts the one-length frequent patterns from database
+        updateTransactions()
+            Update the transactions by removing non-frequent items and sort the Database by item decreased support
+        buildTree()
+            After updating the Database, remaining items will be added into the tree by setting root node as null
+        convert()
+            to convert the user specified value
+        startMine()
+            Mining process will start from this function
     Executing the code on terminal:
-    -------
+    -----------------------------------
         Format:
-        -------
-            python3 SWFPGrowth.py <inputFile> <weightFile> <outputFile> <minWS>
-
+        ----------
+          >>>  python3 GFPGrowth.py <inputFile> <neighborFile> <outputFile> <minSup>
         Examples:
-        ---------
-            python3 SWFPGrowth.py sampleDB.txt weightSample.txt patterns.txt 10.0   (minWS will be considered in times of minWS and count of database transactions)
-
-            python3 SWFPGrowth.py sampleDB.txt weightFile.txt patterns.txt 10     (minWS will be considered in support count or frequency) (it will consider "\t" as a separator)
-
-            python3 SWFPGrowth.py sampleTDB.txt weightFile.txt output.txt sampleN.txt 3 ',' (it will consider "," as a separator)
-
-
-    Sample run of the importing code:
-    -----------
-
+        ------------
+          >>> python3 GFPGrowth.py sampleTDB.txt sampleNeighbor.txt patterns.txt 3    (minSup  will be considered in support count or frequency)
+    
+    Sample run of importing the code:
+    -----------------------------------
+     .. code-block:: python
 
-        from PAMI.weightFrequentNeighbourhoodPattern.basic import SWFPGrowth as alg
+        from PAMI.geoReferenceFrequentPattern.basic import GFPGrowth as alg
 
-        obj = alg.SWFPGrowth(iFile, wFile, nFile, minWS, minWeight, seperator)
+        obj = alg.GFPGrowth(iFile, nFile, minSup)
 
         obj.startMine()
 
         Patterns = obj.getPatterns()
 
-        print("Total number of weighted spatial Frequent Patterns:", len(Patterns))
+        print("Total number of  Patterns:", len(Patterns))
 
-        obj.save(oFile)
+        obj.savePatterns(oFile)
 
-        Df = obj.getPatternInDataFrame()
+        Df = obj.getPatternsAsDataFrame()
 
         memUSS = obj.getMemoryUSS()
 
         print("Total Memory in USS:", memUSS)
 
         memRSS = obj.getMemoryRSS()
 
         print("Total Memory in RSS", memRSS)
 
         run = obj.getRuntime()
 
         print("Total ExecutionTime in seconds:", run)
-
-        Credits:
-        -------
+        
+    Credits:
+    -------
         The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.\n
-
-        """
-
-    __startTime = float()
-    __endTime = float()
-    _Weights = {}
-    _minWS = str()
-    __finalPatterns = {}
-    _neighbourList = {}
+    """
+    _startTime = float()
+    _endTime = float()
+    _minSup = str()
+    _finalPatterns = {}
     _iFile = " "
     _oFile = " "
     _sep = " "
-    __memoryUSS = float()
-    __memoryRSS = float()
-    __Database = []
-    __mapSupport = {}
-    __lno = 0
-    __tree = _Tree()
-    __rank = {}
-    __rankDup = {}
+    _memoryUSS = float()
+    _memoryRSS = float()
+    _Database = []
+    _rank = {}
 
-    def __init__(self, iFile, nFile, minWS, sep='\t'):
-        super().__init__(iFile, nFile, minWS, sep)
+    def __init__(self, iFile, nFile, minSup, sep='\t'):
+        super().__init__(iFile, nFile, minSup, sep)
 
-    def __creatingItemSets(self):
+    def _creatingItemSets(self):
         """
-            Storing the complete transactions of the database/input file in a database variable
-
-
+            Scans the uncertain transactional dataset
         """
         self._Database = []
-        if isinstance(self._iFile, _fp._pd.DataFrame):
+        if isinstance(self._iFile, _ab._pd.DataFrame):
+            uncertain, data = [], []
             if self._iFile.empty:
                 print("its empty..")
             i = self._iFile.columns.values.tolist()
             if 'Transactions' in i:
                 self._Database = self._iFile['Transactions'].tolist()
+            if 'uncertain' in i:
+                uncertain = self._iFile['uncertain'].tolist()
+            for k in range(len(data)):
+                tr = []
+                for j in range(len(data[k])):
+                    product = _Item(data[k][j], uncertain[k][j])
+                    tr.append(product)
+                self._Database.append(tr)
+
             # print(self.Database)
         if isinstance(self._iFile, str):
-            if _fp._validators.url(self._iFile):
-                data = _fp._urlopen(self._iFile)
+            if _ab._validators.url(self._iFile):
+                data = _ab._urlopen(self._iFile)
                 for line in data:
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
+                    tr = []
+                    for i in temp:
+                        i1 = i.index('(')
+                        i2 = i.index(')')
+                        item = i[0:i1]
+                        probability = float(i[i1 + 1:i2])
+                        product = _Item(item, probability)
+                        tr.append(product)
                     self._Database.append(temp)
             else:
                 try:
-                    with open(self._iFile, 'r', encoding='utf-8') as f:
+                    with open(self._iFile, 'r') as f:
                         for line in f:
-                            line = line.strip()
-                            line = line.split(':')
-                            temp1 = [i.rstrip() for i in line[0].split(self._sep)]
-                            temp2 = [int(i.strip()) for i in line[1].split(self._sep)]
+                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            temp = [x for x in temp if x]
                             tr = []
-                            for i in range(len(temp1)):
-                                we = _WeightedItem(temp1[i], temp2[i])
-                                tr.append(we)
+                            for i in temp[1:]:
+                                i1 = i.index('(')
+                                i2 = i.index(')')
+                                item = i[0:i1]
+                                probability = float(i[i1 + 1:i2])
+                                product = _Item(item, probability)
+                                tr.append(product)
                             self._Database.append(tr)
                 except IOError:
                     print("File Not Found")
-                    quit()
-
-    def _scanNeighbours(self):
-        self._neighbourList = {}
-        if isinstance(self._nFile, _fp._pd.DataFrame):
-            data, items = [], []
-            if self._nFile.empty:
+                    
+    def _creatingNeighbours(self):
+        """
+            Scans the uncertain transactional dataset
+        """
+        global _neighbourList
+        _neighbourList = {}
+        if isinstance(self._nFile, _ab._pd.DataFrame):
+            uncertain, data = [], []
+            if self._iFile.empty:
                 print("its empty..")
-            i = self._nFile.columns.values.tolist()
-            if 'item' in i:
-                items = self._nFile['items'].tolist()
-            if 'Neighbours' in i:
-                data = self._nFile['Neighbours'].tolist()
-            for k in range(len(items)):
-                self._neighbourList[items[k][0]] = data[k]
+            i = self._iFile.columns.values.tolist()
+            if 'Transactions' in i:
+                self._Database = self._iFile['Transactions'].tolist()
+            if 'uncertain' in i:
+                uncertain = self._iFile['uncertain'].tolist()
+            for k in range(len(data)):
+                tr = []
+                for j in range(len(data[k])):
+                    product = _Item(data[k][j], uncertain[k][j])
+                    tr.append(product)
+                self._Database.append(tr)
+
             # print(self.Database)
         if isinstance(self._nFile, str):
-            if _fp._validators.url(self._nFile):
-                data = _fp._urlopen(self._nFile)
+            if _ab._validators.url(self._iFile):
+                data = _ab._urlopen(self._iFile)
                 for line in data:
                     line.strip()
                     line = line.decode("utf-8")
                     temp = [i.rstrip() for i in line.split(self._sep)]
                     temp = [x for x in temp if x]
-                    self._neighbourList[temp[0]] = temp[1:]
+                    tr = []
+                    for i in temp:
+                        i1 = i.index('(')
+                        i2 = i.index(')')
+                        item = i[0:i1]
+                        probability = float(i[i1 + 1:i2])
+                        product = _Item(item, probability)
+                        tr.append(product)
+                    self._Database.append(temp)
             else:
                 try:
-                    with open(self._nFile, 'r', encoding='utf-8') as f:
+                    with open(self._nFile, 'r') as f:
                         for line in f:
-                            line.strip()
                             temp = [i.rstrip() for i in line.split(self._sep)]
                             temp = [x for x in temp if x]
-                            self._neighbourList[temp[0]] = temp[1:]
+                            _neighbourList[temp[0]] = temp[1:]
                 except IOError:
-                    print("File Not Found2")
-                    quit()
-
-    def __convert(self, value):
-        """
-        to convert the type of user specified minWS value
-
-        :param value: user specified minWS value
-
-        :return: converted type
-        """
-        if type(value) is int:
-            value = int(value)
-        if type(value) is float:
-            value = (len(self._Database) * value)
-        if type(value) is str:
-            if '.' in value:
-                value = float(value)
-                value = (len(self._Database) * value)
-            else:
-                value = int(value)
-        return value
+                    print("File Not Found")
 
-    def __frequentOneItem(self):
+    def _frequentOneItem(self):
+        """takes the self.Database and calculates the support of each item in the dataset and assign the
+            ranks to the items by decreasing support and returns the frequent items list
+                :param self.Database : it represents the one self.Database in database
+                :type self.Database : list
         """
-        Generating One frequent items sets
 
-        """
-        global _maxWeight
-        self._mapSupport = {}
-        for tr in self._Database:
-            for i in tr:
-                nn = [j for j in tr if j.item in self._neighbourList[i.item]]
-                if i.item not in self._mapSupport:
-                    self._mapSupport[i.item] = i.weight
+        mapSupport = {}
+        for i in self._Database:
+            for j in i:
+                if j.item not in mapSupport:
+                    mapSupport[j.item] = j.probability
                 else:
-                    self._mapSupport[i.item] += i.weight
-                for k in nn:
-                    self._mapSupport[i.item] += k.weight
-        self._mapSupport = {k: v for k, v in self._mapSupport.items() if v >= self._minWS}
-        genList = [k for k, v in sorted(self._mapSupport.items(), key=lambda x: x[1], reverse=True)]
-        self.__rank = dict([(index, item) for (item, index) in enumerate(genList)])
-        return genList
+                    mapSupport[j.item] += j.probability
+        mapSupport = {k: v for k, v in mapSupport.items() if v >= self._minSup}
+        plist = [k for k, v in sorted(mapSupport.items(), key=lambda x: x[1], reverse=True)]
+        self.rank = dict([(index, item) for (item, index) in enumerate(plist)])
+        return mapSupport, plist
 
-    def __updateTransactions(self, itemSet):
+    @staticmethod
+    def _buildTree(data, info):
+        """it takes the self.Database and support of each item and construct the main tree with setting root
+            node as null
+                :param data : it represents the one self.Database in database
+                :type data : list
+                :param info : it represents the support of each item
+                :type info : dictionary
         """
-        Updates the items in transactions with rank of items according to their support
-
-        :Example: oneLength = {'a':7, 'b': 5, 'c':'4', 'd':3}
-                    rank = {'a':0, 'b':1, 'c':2, 'd':3}
-
-        Parameters
-        ----------
-        itemSet: list of one-frequent items
 
-        -------
+        rootNode = _Tree()
+        rootNode.info = info.copy()
+        for i in range(len(data)):
+            rootNode.addTransaction(data[i])
+        return rootNode
 
+    def _updateTransactions(self, dict1):
+        """remove the items which are not frequent from self.Database and updates the self.Database with rank of items
+            :param dict1 : frequent items with support
+            :type dict1 : dictionary
         """
+
         list1 = []
         for tr in self._Database:
             list2 = []
-            for i in range(len(tr)):
-                if tr[i].item in itemSet:
+            for i in range(0, len(tr)):
+                if tr[i].item in dict1:
                     list2.append(tr[i])
-            if len(list2) >= 1:
+            if len(list2) >= 2:
                 basket = list2
-                basket.sort(key=lambda val: self.__rank[val.item])
-                list1.append(basket)
+                basket.sort(key=lambda val: self.rank[val.item])
+                list2 = basket
+                list1.append(list2)
         return list1
 
     @staticmethod
-    def __buildTree(transactions, info):
+    def _check(i, x):
+        """To check the presence of item or pattern in transaction
+                :param x: it represents the pattern
+                :type x : list
+                :param i : represents the uncertain self.Database
+                :type i : list
+        """
+
+        # This method taken a transaction as input and returns the tree
+        for m in x:
+            k = 0
+            for n in i:
+                if m == n.item:
+                    k += 1
+            if k == 0:
+                return 0
+        return 1
+
+    def _convert(self, value):
+        """
+        To convert the type of user specified minSup value
+            :param value: user specified minSup value
+            :return: converted type minSup value
         """
-        Builds the tree with updated transactions
-        Parameters:
-        ----------
-            transactions: updated transactions
-            info: support details of each item in transactions
-
-        Returns:
-        -------
-            transactions compressed in fp-tree
-
-        """
-        rootNode = _Tree()
-        rootNode.info = info.copy()
-        for i in range(len(transactions)):
-            rootNode.addTransaction(transactions[i], 1)
-        return rootNode
+        if type(value) is int:
+            value = int(value)
+        if type(value) is float:
+            value = (len(self._Database) * value)
+        if type(value) is str:
+            if '.' in value:
+                value = (len(self._Database) * value)
+            else:
+                value = int(value)
+        return value
 
-    def __savePeriodic(self, itemSet):
+    def _removeFalsePositives(self):
         """
-        The duplication items and their ranks
-        Parameters:
-        ----------
-            itemSet: frequent itemSet that generated
-
-        Returns:
-        -------
-            patterns with original item names.
-
+            To remove the false positive patterns generated in frequent patterns
+            :return: patterns with accurate probability
         """
-        temp = str()
-        for i in itemSet:
-            temp = temp + self.__rankDup[i] + "\t"
-        return temp
+        global _finalPatterns
+        periods = {}
+        for i in self._Database:
+            for x, y in _finalPatterns.items():
+                if len(x) == 1:
+                    periods[x] = y
+                else:
+                    s = 1
+                    check = self._check(i, x)
+                    if check == 1:
+                        for j in i:
+                            if j.item in x:
+                                s *= j.probability
+                        if x in periods:
+                            periods[x] += s
+                        else:
+                            periods[x] = s
+        for x, y in periods.items():
+            if y >= self._minSup:
+                sample = str()
+                for i in x:
+                    sample = sample + i + " "
+                self._finalPatterns[sample] = y
 
     def startMine(self):
+        """Main method where the patterns are mined by constructing tree and remove the remove the false patterns
+            by counting the original support of a patterns
         """
-            main program to start the operation
-
-        """
-        global _minWS, _neighbourList, _rank
-        self.__startTime = _fp._time.time()
-        if self._iFile is None:
-            raise Exception("Please enter the file path or file name:")
-        if self._minWS is None:
-            raise Exception("Please enter the Minimum Support")
-        self.__creatingItemSets()
-        self._scanNeighbours()
-        self._minWS = self.__convert(self._minWS)
-        _minWS = self._minWS
-        itemSet = self.__frequentOneItem()
-        updatedTransactions = self.__updateTransactions(itemSet)
-        info = {self.__rank[k]: v for k, v in self._mapSupport.items()}
-        _rank = self.__rank
-        for x, y in self.__rank.items():
-            self.__rankDup[y] = x
-        _neighbourList = self._neighbourList
-        #self._neighbourList = {k:v for k, v in self._neighbourList.items() if k in self._mapSupport.keys()}
-        # for x, y in self._neighbourList.items():
-        #     xx = [self.__rank[i] for i in y if i in self._mapSupport.keys()]
-        #     _neighbourList[self.__rank[x]] = xx
-        # print(_neighbourList)
-        __Tree = self.__buildTree(updatedTransactions, info)
-        patterns = __Tree.generatePatterns([])
-        self.__finalPatterns = {}
-        for k in patterns:
-            s = self.__savePeriodic(k[0])
-            self.__finalPatterns[str(s)] = k[1]
-        print("Weighted Frequent patterns were generated successfully using SWFPGrowth algorithm")
-        self.__endTime = _fp._time.time()
-        self.__memoryUSS = float()
-        self.__memoryRSS = float()
-        process = _fp._psutil.Process(_fp._os.getpid())
-        self.__memoryUSS = process.memory_full_info().uss
-        self.__memoryRSS = process.memory_info().rss
+        global minSup
+        self._startTime = _ab._time.time()
+        self._creatingItemSets()
+        self._creatingNeighbours()
+        #self._minSup = self._convert(self._minSup)
+        minSup = self._minSup
+        self._finalPatterns = {}
+        mapSupport, plist = self._frequentOneItem()
+        self.Database1 = self._updateTransactions(mapSupport)
+        info = {k: v for k, v in mapSupport.items()}
+        Tree1 = self._buildTree(self.Database1, info)
+        Tree1.generatePatterns([])
+        self._removeFalsePositives()
+        print("Geo-Referenced Frequent patterns were generated from uncertain databases successfully using GFP algorithm")
+        self._endTime = _ab._time.time()
+        process = _ab._psutil.Process(_ab._os.getpid())
+        self._memoryUSS = float()
+        self.memoryRSS = float()
+        self._memoryUSS = process.memory_full_info().uss
+        self.memoryRSS = process.memory_info().rss
 
     def getMemoryUSS(self):
         """Total amount of USS memory consumed by the mining process will be retrieved from this function
-
         :return: returning USS memory consumed by the mining process
-
         :rtype: float
         """
 
-        return self.__memoryUSS
+        return self._memoryUSS
 
     def getMemoryRSS(self):
         """Total amount of RSS memory consumed by the mining process will be retrieved from this function
-
         :return: returning RSS memory consumed by the mining process
-
         :rtype: float
         """
 
-        return self.__memoryRSS
+        return self.memoryRSS
 
     def getRuntime(self):
         """Calculating the total amount of runtime taken by the mining process
-
-
         :return: returning total amount of runtime taken by the mining process
-
         :rtype: float
         """
 
-        return self.__endTime - self.__startTime
+        return self._endTime - self._startTime
 
     def getPatternsAsDataFrame(self):
         """Storing final frequent patterns in a dataframe
-
         :return: returning frequent patterns in a dataframe
-
         :rtype: pd.DataFrame
         """
 
         dataframe = {}
         data = []
-        for a, b in self.__finalPatterns.items():
-            data.append([a.replace('\t', ' '), b])
-            dataframe = _fp._pd.DataFrame(data, columns=['Patterns', 'Support'])
+        for a, b in self._finalPatterns.items():
+            data.append([a, b])
+            dataframe = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
         return dataframe
 
-    def save(self, outFile):
+    def savePatterns(self, outFile):
         """Complete set of frequent patterns will be loaded in to a output file
-
         :param outFile: name of the output file
-
         :type outFile: file
         """
-        self._oFile = outFile
-        writer = open(self._oFile, 'w+')
-        for x, y in self.__finalPatterns.items():
-            s1 = x.strip() + ":" + str(y)
+        self.oFile = outFile
+        writer = open(self.oFile, 'w+')
+        for x, y in self._finalPatterns.items():
+            s1 = x + ":" + str(y)
             writer.write("%s \n" % s1)
 
     def getPatterns(self):
         """ Function to send the set of frequent patterns after completion of the mining process
-
         :return: returning frequent patterns
-
         :rtype: dict
         """
-        return self.__finalPatterns
-
+        return self._finalPatterns
+    
     def printResults(self):
-        print("Total number of  Weighted Spatial Frequent Patterns:", len(self.getPatterns()))
-        print("Total Memory in USS:", self.getMemoryUSS())
-        print("Total Memory in RSS", self.getMemoryRSS())
-        print("Total ExecutionTime in ms:",  self.getRuntime())
+        print("Total number of Patterns:", len(self.getPatterns()))
+        self.savePatterns("patterns.txt")
+        memUSS = self.getMemoryUSS()
+        print("Total Memory in USS:", memUSS)
+        memRSS = self.getMemoryRSS()
+        print("Total Memory in RSS", memRSS)
+        run = self.getRuntime()
+        print("Total ExecutionTime in ms:", run)
 
 
 if __name__ == "__main__":
     _ap = str()
-    if len(_fp._sys.argv) == 7 or len(_fp._sys.argv) == 8:
-        if len(_fp._sys.argv) == 8:
-            _ap = SWFPGrowth(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4], _fp._sys.argv[5], _fp._sys.argv[6],
-                             _fp._sys.argv[7])
-        if len(_fp._sys.argv) == 7:
-            _ap = SWFPGrowth(_fp._sys.argv[1], _fp._sys.argv[3], _fp._sys.argv[4], _fp._sys.argv[5], _fp._sys.argv[6])
+    if len(_ab._sys.argv) == 5 or len(_ab._sys.argv) == 6:
+        if len(_ab._sys.argv) == 6:
+            _ap = GFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4], _ab._sys.argv[5])
+        if len(_ab._sys.argv) == 5:
+            _ap = GFPGrowth(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
         _ap.startMine()
-        print("Total number of Weighted Spatial Frequent Patterns:", len(_ap.getPatterns()))
-        _ap.save(_fp._sys.argv[2])
-        print("Total Memory in USS:", _ap.getMemoryUSS())
-        print("Total Memory in RSS",  _ap.getMemoryRSS())
-        print("Total ExecutionTime in ms:", _ap.getRuntime())
+        _Patterns = _ap.getPatterns()
+        print("Total number of Patterns:", len(_Patterns))
+        _ap.savePatterns(_ab._sys.argv[2])
+        _memUSS = _ap.getMemoryUSS()
+        print("Total Memory in USS:", _memUSS)
+        _memRSS = _ap.getMemoryRSS()
+        print("Total Memory in RSS", _memRSS)
+        _run = _ap.getRuntime()
+        print("Total ExecutionTime in ms:", _run)
     else:
-        _ap = SWFPGrowth('sample.txt', 'neighbourSample.txt', 150, ' ')
-        _ap.startMine()
-        print("Total number of Weighted Spatial Frequent Patterns:", len(_ap.getPatterns()))
-        _ap.save('output.txt')
-        print("Total Memory in USS:", _ap.getMemoryUSS())
-        print("Total Memory in RSS", _ap.getMemoryRSS())
-        print("Total ExecutionTime in ms:", _ap.getRuntime())
         print("Error! The number of input parameters do not match the total number of parameters provided")
```

### Comparing `pami-2023.4.1/PAMI/weightedFrequentNeighbourhoodPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/weightedFrequentNeighbourhoodPattern/basic/abstract.py`

 * *Files identical despite different names*

### Comparing `pami-2023.4.1/PAMI/weightedFrequentPattern/basic/abstract.py` & `pami-2023.5.1/PAMI/weightedFrequentRegularPattern/basic/abstract.py`

 * *Files 15% similar despite different names*

```diff
@@ -38,28 +38,31 @@
 import psutil as _psutil
 import sys as _sys
 import validators as _validators
 from urllib.request import urlopen as _urlopen
 import functools as _functools
 
 
-class _weightedFrequentPatterns(_ABC):
+class _weightedFrequentRegularPatterns(_ABC):
     """ This abstract base class defines the variables and methods that every frequent pattern mining algorithm must
         employ in PAMI
 
 
        Attributes:
        ----------
         iFile : str
             Input file name or path of the input file
-        minSup: integer or float or str
-            The user can specify minSup either in count or proportion of database size.
-            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+        :param weightSupport(ws): The user can specify ws either in count or proportion of database size.
+            If the program detects the data type of ws is integer, then it treats ws is expressed in count.
             Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+            Example: ws=10 will be treated as integer, while ws=10.0 will be treated as float
+        :param regularity: The user can specify regularity either in count or proportion of database size.
+            If the program detects the data type of regularity is integer, then it treats regularity is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: regularity=10 will be treated as integer, while regularity=10.0 will be treated as float
         sep : str
             This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
             However, the users can override their default separator
         startTime:float
             To record the start time of the algorithm
         endTime:float
             To record the completion time of the algorithm
@@ -87,34 +90,39 @@
         getMemoryRSS()
             This function outputs the total amount of RSS memory consumed by a mining algorithm
         getRuntime()
             This function outputs the total runtime of a mining algorithm
 
     """
 
-    def __init__(self, iFile, wFile, minSup, minWeight, sep="\t"):
+    def __init__(self, iFile, wFile, weightSupport, regularity, sep="\t"):
         """
         :param iFile: Input file name or path of the input file
         :type iFile: str or DataFrame
-        :param wFile: Input file name or path of the input file
+        :param wFile: Input weight file name or path of the input file
         :type wFile: str or DataFrame
-        :param minSup: The user can specify minSup either in count or proportion of database size.
-            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+        :param weightSupport(ws): The user can specify ws either in count or proportion of database size.
+            If the program detects the data type of ws is integer, then it treats ws is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: ws=10 will be treated as integer, while ws=10.0 will be treated as float
+        :type weightSupport: int or float or str
+        :param regularity: The user can specify regularity either in count or proportion of database size.
+            If the program detects the data type of regularity is integer, then it treats regularity is expressed in count.
             Otherwise, it will be treated as float.
-            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
-        :type minSup: int or float or str
+            Example: regularity=10 will be treated as integer, while regularity=10.0 will be treated as float
+        :type regularity: int or float or str
         :param sep: separator used to distinguish items from each other. The default separator is tab space. However, users can override the default separator
         :type sep: str
         """
 
         self._iFile = iFile
         self._wFile = wFile
         self._sep = sep
-        self._minSup = minSup
-        self._minWeight = minWeight
+        self._regularity = regularity
+        self._WS = weightSupport
         self._finalPatterns = {}
         self._oFile = str()
         self._memoryUSS = float()
         self._memoryRSS = float()
         self._startTime = float()
         self._endTime = float()
 
@@ -164,9 +172,8 @@
 
         pass
 
     @_abstractmethod
     def printResults(self):
         """ To print all the results of execution"""
 
-
         pass
```

### Comparing `pami-2023.4.1/PKG-INFO` & `pami-2023.5.1/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: pami
-Version: 2023.4.1
+Version: 2023.5.1
 Summary: This software is being developed at the University of Aizu, Aizu-Wakamatsu, Fukushima, Japan
 Home-page: https://github.com/udayRage/PAMI
 Author: Rage Uday Kiran
 Author-email: uday.rage@gmail.com
 License: GPLv3
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Programming Language :: Python :: 3
@@ -29,17 +29,19 @@
 
 # Introduction
 PAttern MIning (PAMI) is a Python library containing several algorithms to discover user interest-based patterns in transactional/temporal/geo-referencial/sequence databases across multiple computing platforms.
 
 
 1. User manual https://udayrage.github.io/PAMI/manuals/index.html
 
-2. Datasets   https://u-aizu.ac.jp/~udayrage/datasets.html
+2. Coders manual https://udayrage.github.io/PAMI/codersManual/index.html
 
-3. Code documentation file:///Users/likhitha/Downloads/PAMI-main-docs/docs/_build/html/index.html
+3. Code documentation [PAMI documentation](https://raw.githack.com/udayRage/PAMI/main/htmlDocs/_build/html/index.html)
+
+3. Datasets   https://u-aizu.ac.jp/~udayrage/datasets.html
 
 4. Discussions on PAMI usage https://github.com/udayRage/PAMI/discussions
 
 5. Report issues https://github.com/udayRage/PAMI/issues
   
  __Recent versions__
```

### Comparing `pami-2023.4.1/README.md` & `pami-2023.5.1/pami.egg-info/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,7 +1,23 @@
+Metadata-Version: 2.1
+Name: pami
+Version: 2023.5.1
+Summary: This software is being developed at the University of Aizu, Aizu-Wakamatsu, Fukushima, Japan
+Home-page: https://github.com/udayRage/PAMI
+Author: Rage Uday Kiran
+Author-email: uday.rage@gmail.com
+License: GPLv3
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Programming Language :: Python :: 3
+Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
+Classifier: Operating System :: OS Independent
+Requires-Python: >=3.5
+Description-Content-Type: text/markdown
+License-File: LICENSE
+
 ![PyPI](https://img.shields.io/pypi/v/PAMI)
 ![AppVeyor](https://img.shields.io/appveyor/build/udayRage/PAMI)
 ![PyPI - Python Version](https://img.shields.io/pypi/pyversions/PAMI)
 ![GitHub all releases](https://img.shields.io/github/downloads/udayRage/PAMI/total)
 [![GitHub license](https://img.shields.io/github/license/udayRage/PAMI)](https://github.com/udayRage/PAMI/blob/main/LICENSE)
 ![PyPI - Implementation](https://img.shields.io/pypi/implementation/PAMI)
 ![PyPI - Wheel](https://img.shields.io/pypi/wheel/PAMI)
@@ -13,17 +29,19 @@
 
 # Introduction
 PAttern MIning (PAMI) is a Python library containing several algorithms to discover user interest-based patterns in transactional/temporal/geo-referencial/sequence databases across multiple computing platforms.
 
 
 1. User manual https://udayrage.github.io/PAMI/manuals/index.html
 
-2. Datasets   https://u-aizu.ac.jp/~udayrage/datasets.html
+2. Coders manual https://udayrage.github.io/PAMI/codersManual/index.html
+
+3. Code documentation [PAMI documentation](https://raw.githack.com/udayRage/PAMI/main/htmlDocs/_build/html/index.html)
 
-3. Code documentation file:///Users/likhitha/Downloads/PAMI-main-docs/docs/_build/html/index.html
+3. Datasets   https://u-aizu.ac.jp/~udayrage/datasets.html
 
 4. Discussions on PAMI usage https://github.com/udayRage/PAMI/discussions
 
 5. Report issues https://github.com/udayRage/PAMI/issues
   
  __Recent versions__
```

### Comparing `pami-2023.4.1/pami.egg-info/PKG-INFO` & `pami-2023.5.1/README.md`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,7 @@
-Metadata-Version: 2.1
-Name: pami
-Version: 2023.4.1
-Summary: This software is being developed at the University of Aizu, Aizu-Wakamatsu, Fukushima, Japan
-Home-page: https://github.com/udayRage/PAMI
-Author: Rage Uday Kiran
-Author-email: uday.rage@gmail.com
-License: GPLv3
-Classifier: Development Status :: 5 - Production/Stable
-Classifier: Programming Language :: Python :: 3
-Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
-Classifier: Operating System :: OS Independent
-Requires-Python: >=3.5
-Description-Content-Type: text/markdown
-License-File: LICENSE
-
 ![PyPI](https://img.shields.io/pypi/v/PAMI)
 ![AppVeyor](https://img.shields.io/appveyor/build/udayRage/PAMI)
 ![PyPI - Python Version](https://img.shields.io/pypi/pyversions/PAMI)
 ![GitHub all releases](https://img.shields.io/github/downloads/udayRage/PAMI/total)
 [![GitHub license](https://img.shields.io/github/license/udayRage/PAMI)](https://github.com/udayRage/PAMI/blob/main/LICENSE)
 ![PyPI - Implementation](https://img.shields.io/pypi/implementation/PAMI)
 ![PyPI - Wheel](https://img.shields.io/pypi/wheel/PAMI)
@@ -29,17 +13,19 @@
 
 # Introduction
 PAttern MIning (PAMI) is a Python library containing several algorithms to discover user interest-based patterns in transactional/temporal/geo-referencial/sequence databases across multiple computing platforms.
 
 
 1. User manual https://udayrage.github.io/PAMI/manuals/index.html
 
-2. Datasets   https://u-aizu.ac.jp/~udayrage/datasets.html
+2. Coders manual https://udayrage.github.io/PAMI/codersManual/index.html
+
+3. Code documentation [PAMI documentation](https://raw.githack.com/udayRage/PAMI/main/htmlDocs/_build/html/index.html)
 
-3. Code documentation file:///Users/likhitha/Downloads/PAMI-main-docs/docs/_build/html/index.html
+3. Datasets   https://u-aizu.ac.jp/~udayrage/datasets.html
 
 4. Discussions on PAMI usage https://github.com/udayRage/PAMI/discussions
 
 5. Report issues https://github.com/udayRage/PAMI/issues
   
  __Recent versions__
```

### Comparing `pami-2023.4.1/pami.egg-info/SOURCES.txt` & `pami-2023.5.1/pami.egg-info/SOURCES.txt`

 * *Files 1% similar despite different names*

```diff
@@ -66,17 +66,14 @@
 PAMI/extras/neighbours/findNeighboursUsingEuclidean.py
 PAMI/faultTolerantFrequentPattern/__init__.py
 PAMI/faultTolerantFrequentPattern/basic/FTApriori.py
 PAMI/faultTolerantFrequentPattern/basic/FTFPGrowth.py
 PAMI/faultTolerantFrequentPattern/basic/VBFTMine.py
 PAMI/faultTolerantFrequentPattern/basic/__init__.py
 PAMI/faultTolerantFrequentPattern/basic/abstract.py
-PAMI/faultTolerantFrequentPattern/maximal/__init__.py
-PAMI/faultTolerantFrequentPattern/maximal/abstract.py
-PAMI/faultTolerantFrequentPattern/maximal/maxFTP.py
 PAMI/frequentPattern/__init__.py
 PAMI/frequentPattern/basic/Apriori.py
 PAMI/frequentPattern/basic/ECLAT.py
 PAMI/frequentPattern/basic/ECLATDiffset.py
 PAMI/frequentPattern/basic/ECLATbitset.py
 PAMI/frequentPattern/basic/FPGrowth.py
 PAMI/frequentPattern/basic/__init__.py
@@ -186,17 +183,17 @@
 PAMI/partialPeriodicPattern/closed/abstract.py
 PAMI/partialPeriodicPattern/maximal/Max3PGrowth.py
 PAMI/partialPeriodicPattern/maximal/__init__.py
 PAMI/partialPeriodicPattern/maximal/abstract.py
 PAMI/partialPeriodicPattern/timeSeries/PPGrowth.py
 PAMI/partialPeriodicPattern/timeSeries/__init__.py
 PAMI/partialPeriodicPattern/timeSeries/abstract.py
-PAMI/partialPeriodicPattern/topk/Topk_PPPGrowth.py
 PAMI/partialPeriodicPattern/topk/__init__.py
 PAMI/partialPeriodicPattern/topk/abstract.py
+PAMI/partialPeriodicPattern/topk/k3PMiner.py
 PAMI/partialPeriodicSpatialPattern/__init__.py
 PAMI/partialPeriodicSpatialPattern/basic/STEclat.py
 PAMI/partialPeriodicSpatialPattern/basic/__init__.py
 PAMI/partialPeriodicSpatialPattern/basic/abstract.py
 PAMI/periodicCorrelatedPattern/__init__.py
 PAMI/periodicCorrelatedPattern/basic/EPCPGrowth.py
 PAMI/periodicCorrelatedPattern/basic/__init__.py
@@ -264,19 +261,14 @@
 PAMI/uncertainFrequentPattern/basic/__init__.py
 PAMI/uncertainFrequentPattern/basic/abstract.py
 PAMI/uncertainPeriodicFrequentPattern/__init__.py
 PAMI/uncertainPeriodicFrequentPattern/basic/UPFPGrowth.py
 PAMI/uncertainPeriodicFrequentPattern/basic/UPFPGrowthPlus.py
 PAMI/uncertainPeriodicFrequentPattern/basic/__init__.py
 PAMI/uncertainPeriodicFrequentPattern/basic/abstract.py
-PAMI/uncertainPeriodicFrequentPattern/basic/upfp.py
-PAMI/uncertainPeriodicFrequentPattern/basic/upfpplus.py
-PAMI/uncertainProbablisticFrequentPattern/__init__.py
-PAMI/uncertainProbablisticFrequentPattern/basic/__init__.py
-PAMI/uncertainProbablisticFrequentPattern/basic/abstract.py
 PAMI/weightedFrequentNeighbourhoodPattern/__init__.py
 PAMI/weightedFrequentNeighbourhoodPattern/basic/SWFPGrowth.py
 PAMI/weightedFrequentNeighbourhoodPattern/basic/__init__.py
 PAMI/weightedFrequentNeighbourhoodPattern/basic/abstract.py
 PAMI/weightedFrequentPattern/__init__.py
 PAMI/weightedFrequentPattern/basic/WFIM.py
 PAMI/weightedFrequentPattern/basic/__init__.py
```

### Comparing `pami-2023.4.1/setup.py` & `pami-2023.5.1/setup.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import setuptools
 
 with open('README.md', 'r') as fh:
     long_description = fh.read()
 
 setuptools.setup(
     name = 'pami',
-    version = '2023.04.01',
+    version = '2023.05.01',
     author = 'Rage Uday Kiran',
     author_email = 'uday.rage@gmail.com',
     description = 'This software is being developed at the University of Aizu, Aizu-Wakamatsu, Fukushima, Japan',
     long_description = long_description,
     long_description_content_type = 'text/markdown',
     packages=setuptools.find_packages(),
     url = 'https://github.com/udayRage/PAMI',
```

