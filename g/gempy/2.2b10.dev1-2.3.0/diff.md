# Comparing `tmp/gempy-2.2b10.dev1.tar.gz` & `tmp/gempy-2.3.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist\gempy-2.2b10.dev1.tar", last modified: Thu Nov 11 12:59:34 2021, max compression
+gzip compressed data, was "gempy-2.3.0.tar", last modified: Tue Jun 20 12:48:48 2023, max compression
```

## Comparing `gempy-2.2b10.dev1.tar` & `gempy-2.3.0.tar`

### file list

```diff
@@ -1,205 +1,228 @@
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.235931 gempy-2.2b10.dev1/
--rw-rw-rw-   0        0        0     7651 2021-04-01 15:14:27.000000 gempy-2.2b10.dev1/LICENSE
--rw-rw-rw-   0        0        0       36 2021-04-01 15:14:27.000000 gempy-2.2b10.dev1/MANIFEST.in
--rw-rw-rw-   0        0        0      466 2021-11-11 12:59:34.235931 gempy-2.2b10.dev1/PKG-INFO
--rw-rw-rw-   0        0        0     9189 2021-11-11 12:52:24.000000 gempy-2.2b10.dev1/README.md
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.647951 gempy-2.2b10.dev1/examples/
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.661952 gempy-2.2b10.dev1/examples/examples/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/__init__.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.694950 gempy-2.2b10.dev1/examples/examples/geometries/
--rw-rw-rw-   0        0        0     1483 2021-10-02 06:34:34.000000 gempy-2.2b10.dev1/examples/examples/geometries/1_horizontal_stratigraphic.py
--rw-rw-rw-   0        0        0     1417 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/geometries/2_fold.py
--rw-rw-rw-   0        0        0     1411 2021-11-11 12:30:21.000000 gempy-2.2b10.dev1/examples/examples/geometries/3_recumbent_fold.py
--rw-rw-rw-   0        0        0     1503 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/geometries/4_pinchout.py
--rw-rw-rw-   0        0        0     1598 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/geometries/5_fault.py
--rw-rw-rw-   0        0        0     1519 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/geometries/6_unconformity.py
--rw-rw-rw-   0        0        0     1682 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/geometries/7_combination.py
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/geometries/__init__.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.705952 gempy-2.2b10.dev1/examples/examples/geometries/foo/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/geometries/foo/__init__.py
--rw-rw-rw-   0        0        0     5685 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/geometries/foo/more_examples.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.752952 gempy-2.2b10.dev1/examples/examples/real/
--rw-rw-rw-   0        0        0     2759 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/real/Alesmodel.py
--rw-rw-rw-   0        0        0     7763 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/real/Claudius.py
--rw-rw-rw-   0        0        0     1988 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/real/Greenstone.py
--rw-rw-rw-   0        0        0     5979 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/real/Hecho.py
--rw-rw-rw-   0        0        0     4677 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/real/Moureze.py
--rw-rw-rw-   0        0        0     4760 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/real/Perth_basin.py
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/examples/real/__init__.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.759951 gempy-2.2b10.dev1/examples/getting_started/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/getting_started/__init__.py
--rw-rw-rw-   0        0        0     9399 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/getting_started/get_started.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.774949 gempy-2.2b10.dev1/examples/integrations/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/integrations/__init__.py
--rw-rw-rw-   0        0        0     6174 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/integrations/gempy_export_MOOSE.py
--rw-rw-rw-   0        0        0     5611 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/integrations/gempy_striplog.py
--rw-rw-rw-   0        0        0     5924 2021-11-11 12:52:43.000000 gempy-2.2b10.dev1/examples/integrations/gempy_subsurface.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.775950 gempy-2.2b10.dev1/examples/tutorials/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/tutorials/__init__.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.791951 gempy-2.2b10.dev1/examples/tutorials/ch2-Geophysics/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/tutorials/ch2-Geophysics/__init__.py
--rw-rw-rw-   0        0        0     4154 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/tutorials/ch2-Geophysics/ch2_1_gravity.py
--rw-rw-rw-   0        0        0     3620 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/tutorials/ch2-Geophysics/ch2_2_cell_selection.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.799951 gempy-2.2b10.dev1/examples/tutorials/ch4-Topology/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/tutorials/ch4-Topology/__init__.py
--rw-rw-rw-   0        0        0     4820 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/examples/tutorials/ch4-Topology/ch4-1-Topology.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.800950 gempy-2.2b10.dev1/gempy/
--rw-rw-rw-   0        0        0     1228 2021-11-11 12:56:18.000000 gempy-2.2b10.dev1/gempy/__init__.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.827952 gempy-2.2b10.dev1/gempy/addons/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/addons/__init__.py
--rw-rw-rw-   0        0        0    29233 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/addons/gempy_to_rexfile.py
--rw-rw-rw-   0        0        0     7684 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/addons/map2gempy.py
--rw-rw-rw-   0        0        0    11114 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/addons/rex_api.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.884949 gempy-2.2b10.dev1/gempy/api_modules/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/api_modules/__init__.py
--rw-rw-rw-   0        0        0     1169 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/api_modules/aux_func.py
--rw-rw-rw-   0        0        0     1527 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/api_modules/editing.py
--rw-rw-rw-   0        0        0     2161 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/api_modules/getters.py
--rw-rw-rw-   0        0        0    11840 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/api_modules/io.py
--rw-rw-rw-   0        0        0    12360 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/api_modules/setters.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.933949 gempy-2.2b10.dev1/gempy/assets/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/assets/__init__.py
--rw-rw-rw-   0        0        0    40734 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/assets/coKriging.py
--rw-rw-rw-   0        0        0    26753 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/assets/decision_making.py
--rw-rw-rw-   0        0        0     5196 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/assets/geophysics.py
--rw-rw-rw-   0        0        0    24097 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/assets/kriging.py
--rw-rw-rw-   0        0        0    19878 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/assets/spill_analysis.py
--rw-rw-rw-   0        0        0    19669 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/assets/topology.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.952950 gempy-2.2b10.dev1/gempy/bayesian/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/bayesian/__init__.py
--rw-rw-rw-   0        0        0     4521 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/bayesian/axes_utils.py
--rw-rw-rw-   0        0        0     1959 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/bayesian/fields.py
--rw-rw-rw-   0        0        0    20202 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/bayesian/joyplot.py
--rw-rw-rw-   0        0        0    24967 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/bayesian/plot_posterior.py
--rw-rw-rw-   0        0        0    21538 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/bayesian/posterior_analysis_DEP.py
--rw-rw-rw-   0        0        0     8611 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/bayesian/posterior_analysis_elisa.py
--rw-rw-rw-   0        0        0     5469 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/bayesian/theano_op.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.984949 gempy-2.2b10.dev1/gempy/core/
--rw-rw-rw-   0        0        0       36 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/__init__.py
--rw-rw-rw-   0        0        0     1734 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/checkers.py
--rw-rw-rw-   0        0        0    51825 2021-11-11 12:52:24.000000 gempy-2.2b10.dev1/gempy/core/data.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.992949 gempy-2.2b10.dev1/gempy/core/data_modules/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/data_modules/__init__.py
--rw-rw-rw-   0        0        0    57068 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/data_modules/geometric_data.py
--rw-rw-rw-   0        0        0    18785 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/data_modules/stack.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.023953 gempy-2.2b10.dev1/gempy/core/grid_modules/
--rw-rw-rw-   0        0        0       36 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/grid_modules/__init__.py
--rw-rw-rw-   0        0        0    10692 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/grid_modules/create_topography.py
--rw-rw-rw-   0        0        0    14738 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/grid_modules/diamond_square.py
--rw-rw-rw-   0        0        0    24018 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/grid_modules/grid_types.py
--rw-rw-rw-   0        0        0     4041 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/grid_modules/section_utils.py
--rw-rw-rw-   0        0        0     3964 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/grid_modules/topography.py
--rw-rw-rw-   0        0        0    48879 2021-11-11 12:52:43.000000 gempy-2.2b10.dev1/gempy/core/interpolator.py
--rw-rw-rw-   0        0        0    75550 2021-11-11 12:52:24.000000 gempy-2.2b10.dev1/gempy/core/model.py
--rw-rw-rw-   0        0        0    22785 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/qgrid_integration.py
--rw-rw-rw-   0        0        0    14749 2021-11-11 12:52:43.000000 gempy-2.2b10.dev1/gempy/core/solution.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.050949 gempy-2.2b10.dev1/gempy/core/theano_modules/
--rw-rw-rw-   0        0        0       36 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/theano_modules/__init__.py
--rw-rw-rw-   0        0        0    55968 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/theano_modules/theano_export.py
--rw-rw-rw-   0        0        0   103144 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/theano_modules/theano_graph.py
--rw-rw-rw-   0        0        0   108248 2021-11-11 12:52:43.000000 gempy-2.2b10.dev1/gempy/core/theano_modules/theano_graph_pro.py
--rw-rw-rw-   0        0        0    23070 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/core/theano_modules/theano_kriging.py
--rw-rw-rw-   0        0        0    11984 2021-05-04 13:21:04.000000 gempy-2.2b10.dev1/gempy/core/xsolution.py
--rw-rw-rw-   0        0        0    13534 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/gempy_api.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.112950 gempy-2.2b10.dev1/gempy/plot/
--rw-rw-rw-   0        0        0       38 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/plot/__init__.py
--rw-rw-rw-   0        0        0    14507 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/plot/_plot.py
--rw-rw-rw-   0        0        0    41787 2021-11-11 12:52:24.000000 gempy-2.2b10.dev1/gempy/plot/_vista.py
--rw-rw-rw-   0        0        0    54309 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/plot/_visualization_2d.py
--rw-rw-rw-   0        0        0     4337 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/plot/decorators.py
--rw-rw-rw-   0        0        0     1080 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/plot/helpers.py
--rw-rw-rw-   0        0        0    22374 2021-05-04 10:03:57.000000 gempy-2.2b10.dev1/gempy/plot/plot_api.py
--rw-rw-rw-   0        0        0    12753 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/plot/plot_utils.py
--rw-rw-rw-   0        0        0    13726 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/plot/sequential_pile.py
--rw-rw-rw-   0        0        0    38060 2021-11-11 12:52:24.000000 gempy-2.2b10.dev1/gempy/plot/vista.py
--rw-rw-rw-   0        0        0     6536 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/plot/vista_aux.py
--rw-rw-rw-   0        0        0     2552 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/plot/vista_qt.py
--rw-rw-rw-   0        0        0    36828 2021-11-11 12:52:43.000000 gempy-2.2b10.dev1/gempy/plot/visualization_2d.py
--rw-rw-rw-   0        0        0    60969 2021-11-11 12:52:24.000000 gempy-2.2b10.dev1/gempy/plot/visualization_3d.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.186950 gempy-2.2b10.dev1/gempy/utils/
--rw-rw-rw-   0        0        0       71 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/utils/__init__.py
--rw-rw-rw-   0        0        0     6482 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/utils/analysis.py
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/utils/decimation.py
--rw-rw-rw-   0        0        0     5970 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/utils/docstring.py
--rw-rw-rw-   0        0        0     4339 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/utils/export.py
--rw-rw-rw-   0        0        0     9895 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/utils/extract_geomodeller_data.py
--rw-rw-rw-   0        0        0    25931 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/utils/geogrid.py
--rw-rw-rw-   0        0        0    53224 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/utils/geomodeller_integration.py
--rw-rw-rw-   0        0        0     2800 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/utils/gradient.py
--rw-rw-rw-   0        0        0     8343 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/utils/input_manipulation.py
--rw-rw-rw-   0        0        0     3265 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/utils/meta.py
--rw-rw-rw-   0        0        0    14049 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/gempy/utils/qgrid_api.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.818951 gempy-2.2b10.dev1/gempy.egg-info/
--rw-rw-rw-   0        0        0      466 2021-11-11 12:59:33.000000 gempy-2.2b10.dev1/gempy.egg-info/PKG-INFO
--rw-rw-rw-   0        0        0     5394 2021-11-11 12:59:33.000000 gempy-2.2b10.dev1/gempy.egg-info/SOURCES.txt
--rw-rw-rw-   0        0        0        1 2021-11-11 12:59:33.000000 gempy-2.2b10.dev1/gempy.egg-info/dependency_links.txt
--rw-rw-rw-   0        0        0      131 2021-11-11 12:59:33.000000 gempy-2.2b10.dev1/gempy.egg-info/requires.txt
--rw-rw-rw-   0        0        0       20 2021-11-11 12:59:33.000000 gempy-2.2b10.dev1/gempy.egg-info/top_level.txt
--rw-rw-rw-   0        0        0       86 2021-11-11 12:59:34.236933 gempy-2.2b10.dev1/setup.cfg
--rw-rw-rw-   0        0        0     1013 2021-11-11 12:56:18.000000 gempy-2.2b10.dev1/setup.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:33.657951 gempy-2.2b10.dev1/test/
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.187952 gempy-2.2b10.dev1/test/figs/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/figs/__init__.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.187952 gempy-2.2b10.dev1/test/input_data/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/input_data/__init__.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.190953 gempy-2.2b10.dev1/test/test_addons/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_addons/__init__.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.190953 gempy-2.2b10.dev1/test/test_addons/rexfiles/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_addons/rexfiles/__init__.py
--rw-rw-rw-   0        0        0     1531 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_addons/test_gempy_to_rexfile.py
--rw-rw-rw-   0        0        0     3922 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_addons/test_rex_cloud_api.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.192950 gempy-2.2b10.dev1/test/test_anisotropies/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_anisotropies/__init__.py
--rw-rw-rw-   0        0        0     4796 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_anisotropies/test_anisotropies.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.194951 gempy-2.2b10.dev1/test/test_api/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_api/__init__.py
--rw-rw-rw-   0        0        0      248 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_api/test_api.py
--rw-rw-rw-   0        0        0     4858 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_api/test_geometry_api.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.197951 gempy-2.2b10.dev1/test/test_assets/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_assets/__init__.py
--rw-rw-rw-   0        0        0     1484 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_assets/test_gravity.py
--rw-rw-rw-   0        0        0      519 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_assets/test_grid_tz.py
--rw-rw-rw-   0        0        0     3648 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_assets/test_magnetics.py
--rw-rw-rw-   0        0        0     2679 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_assets/test_topology_np.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.198952 gempy-2.2b10.dev1/test/test_community_bugs/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_community_bugs/__init__.py
--rw-rw-rw-   0        0        0     3657 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_community_bugs/test_community_bugs.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.222375 gempy-2.2b10.dev1/test/test_core/
--rw-rw-rw-   0        0        0     9774 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/UPDATE_data.py
--rw-rw-rw-   0        0        0      203 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/UPDATE_model.py
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/__init__.py
--rw-rw-rw-   0        0        0      325 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/test_colors.py
--rw-rw-rw-   0        0        0     8040 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/test_data_classes.py
--rw-rw-rw-   0        0        0     2735 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/test_data_mutation.py
--rw-rw-rw-   0        0        0     1015 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/test_data_mutation2.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.225374 gempy-2.2b10.dev1/test/test_core/test_grids/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/test_grids/__init__.py
--rw-rw-rw-   0        0        0     8154 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/test_grids/test_diamond_square.py
--rw-rw-rw-   0        0        0     2318 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/test_grids/test_grid.py
--rw-rw-rw-   0        0        0     5550 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/test_grids/test_topography.py
--rw-rw-rw-   0        0        0     3050 2021-05-04 10:03:49.000000 gempy-2.2b10.dev1/test/test_core/test_io.py
--rw-rw-rw-   0        0        0     6801 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/test_model.py
--rw-rw-rw-   0        0        0      211 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/test_performance.py
--rw-rw-rw-   0        0        0    13146 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/test_pile_manipulation.py
--rw-rw-rw-   0        0        0     2436 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/test_solution.py
--rw-rw-rw-   0        0        0     1267 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/test_sort_surfaces.py
--rw-rw-rw-   0        0        0     6065 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_core/test_xsol.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.226374 gempy-2.2b10.dev1/test/test_integrations/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_integrations/__init__.py
--rw-rw-rw-   0        0        0     6039 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_integrations/test_map2loop.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.228931 gempy-2.2b10.dev1/test/test_model_types/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_model_types/__init__.py
--rw-rw-rw-   0        0        0      433 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_model_types/test_complex_model.py
--rw-rw-rw-   0        0        0      941 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_model_types/test_one_fault_model.py
--rw-rw-rw-   0        0        0    11721 2021-04-05 13:18:08.000000 gempy-2.2b10.dev1/test/test_model_types/test_simple_models.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.231933 gempy-2.2b10.dev1/test/test_plotting/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_plotting/__init__.py
--rw-rw-rw-   0        0        0     3818 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_plotting/test_2d.py
--rw-rw-rw-   0        0        0     2769 2021-05-04 10:08:49.000000 gempy-2.2b10.dev1/test/test_plotting/test_plot_3d.py
--rw-rw-rw-   0        0        0    12495 2021-11-11 12:52:43.000000 gempy-2.2b10.dev1/test/test_plotting/test_vista.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.233933 gempy-2.2b10.dev1/test/test_prob_modeling/
--rw-rw-rw-   0        0        0     1512 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_prob_modeling/TEST_pymc3.py
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_prob_modeling/__init__.py
-drwxrwxrwx   0        0        0        0 2021-11-11 12:59:34.234932 gempy-2.2b10.dev1/test/test_utilities/
--rw-rw-rw-   0        0        0        0 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_utilities/__init__.py
--rw-rw-rw-   0        0        0      218 2021-04-01 15:14:28.000000 gempy-2.2b10.dev1/test/test_utilities/test_utilities.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     7816 2023-06-19 14:33:41.000000 gempy-2.3.0/LICENSE
+-rw-r--r--   0 leguark   (1000) leguark   (1000)       38 2023-06-19 14:33:41.000000 gempy-2.3.0/MANIFEST.in
+-rw-r--r--   0 leguark   (1000) leguark   (1000)      726 2023-06-20 12:48:48.836705 gempy-2.3.0/PKG-INFO
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     9512 2023-06-20 11:58:46.000000 gempy-2.3.0/README.md
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/examples/
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/examples/examples/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/examples/examples/__init__.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/examples/examples/geometries/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1553 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/examples/geometries/1_horizontal_stratigraphic.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1492 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/examples/geometries/2_fold.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1485 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/examples/geometries/3_recumbent_fold.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1581 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/examples/geometries/4_pinchout.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1680 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/examples/geometries/5_fault.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1596 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/examples/geometries/6_unconformity.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1765 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/examples/geometries/7_combination.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/examples/examples/geometries/__init__.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/examples/examples/geometries/foo/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/examples/examples/geometries/foo/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     5875 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/examples/geometries/foo/more_examples.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/examples/examples/real/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     2863 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/examples/real/Alesmodel.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     8064 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/examples/real/Claudius.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     2064 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/examples/real/Greenstone.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     6213 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/examples/real/Hecho.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     4871 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/examples/real/Moureze.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     4952 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/examples/real/Perth_basin.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/examples/examples/real/__init__.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/examples/getting_started/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/examples/getting_started/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     9801 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/getting_started/get_started.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/examples/integrations/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/examples/integrations/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     6380 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/integrations/gempy_export_MOOSE.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     6452 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/integrations/gempy_export_perth_bassin_pflotran.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     5855 2023-06-19 14:33:41.000000 gempy-2.3.0/examples/integrations/gempy_striplog.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     5924 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/integrations/gempy_subsurface.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/examples/tutorials/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/examples/tutorials/__init__.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/examples/tutorials/ch2-Geophysics/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/examples/tutorials/ch2-Geophysics/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     4327 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/tutorials/ch2-Geophysics/ch2_1_gravity.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     3761 2023-06-20 11:58:26.000000 gempy-2.3.0/examples/tutorials/ch2-Geophysics/ch2_2_cell_selection.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/examples/tutorials/ch4-Topology/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/examples/tutorials/ch4-Topology/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     5049 2023-06-19 14:33:41.000000 gempy-2.3.0/examples/tutorials/ch4-Topology/ch4-1-Topology.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/gempy/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1717 2023-06-20 12:03:26.000000 gempy-2.3.0/gempy/__init__.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/gempy/addons/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/addons/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    30016 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/addons/gempy_to_rexfile.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     7896 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/addons/map2gempy.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    11414 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/addons/rex_api.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/gempy/api_modules/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/api_modules/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1203 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/api_modules/aux_func.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1601 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/api_modules/editing.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     2228 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/api_modules/getters.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    12277 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/api_modules/io.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    12690 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/api_modules/setters.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/gempy/assets/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/assets/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    41806 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/assets/coKriging.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    27334 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/assets/decision_making.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     5321 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/assets/geophysics.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    24669 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/assets/kriging.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    20321 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/assets/spill_analysis.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    21012 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/assets/topology.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/gempy/bayesian/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/bayesian/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     5616 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/bayesian/aesara_op.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     4661 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/bayesian/axes_utils.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     2023 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/bayesian/fields.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    20737 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/bayesian/joyplot.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    25590 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/bayesian/plot_posterior.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    22081 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/bayesian/posterior_analysis_DEP.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     8817 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/bayesian/posterior_analysis_elisa.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/gempy/core/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)       38 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/core/__init__.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/gempy/core/aesara_modules/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)       38 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/aesara_modules/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    57229 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/aesara_modules/aesara_export.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)   105387 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/aesara_modules/aesara_graph.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)   107894 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/aesara_modules/aesara_graph_pro.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    23557 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/aesara_modules/aesara_kriging.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1787 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/checkers.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     6737 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/colors.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    11497 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/data.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/gempy/core/data_modules/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/core/data_modules/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     6959 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/data_modules/geometric_data.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    23136 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/data_modules/orientations.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    18082 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/data_modules/scaling_system.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    19384 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/data_modules/stack.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    11698 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/data_modules/surface_points.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     9992 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/grid.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/gempy/core/grid_modules/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)       38 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/core/grid_modules/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    10978 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/core/grid_modules/create_topography.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    15090 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/core/grid_modules/diamond_square.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    24696 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/grid_modules/grid_types.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     4155 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/core/grid_modules/section_utils.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     4102 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/core/grid_modules/topography.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    48755 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/interpolator.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)      810 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/meta_data.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    76823 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/model.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    23331 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/core/qgrid_integration.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    15345 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/solution.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     6907 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/structure.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    16217 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/surfaces.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    12397 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/core/xsolution.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    13933 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/gempy_api.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/gempy/plot/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)       42 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/plot/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    14932 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/plot/_plot.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    41762 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/plot/_vista.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    55437 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/plot/_visualization_2d.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     4454 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/plot/decorators.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)      919 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/plot/helpers.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    22986 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/plot/plot_api.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    13186 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/plot/plot_utils.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    14062 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/plot/sequential_pile.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    37792 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/plot/vista.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     6703 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/plot/vista_aux.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     2633 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/plot/vista_qt.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    36772 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/plot/visualization_2d.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    60969 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/plot/visualization_3d.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/gempy/utils/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)       75 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/utils/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     6662 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/utils/analysis.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/utils/decimation.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     6060 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy/utils/docstring.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    16043 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/utils/export.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    10157 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/utils/extract_geomodeller_data.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    26546 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/utils/geogrid.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    54441 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/utils/geomodeller_integration.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     2887 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/utils/gradient.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     8568 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/utils/input_manipulation.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     3372 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/utils/meta.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    14411 2023-06-19 14:33:41.000000 gempy-2.3.0/gempy/utils/qgrid_api.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/gempy.egg-info/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)      726 2023-06-20 12:48:48.000000 gempy-2.3.0/gempy.egg-info/PKG-INFO
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     6080 2023-06-20 12:48:48.000000 gempy-2.3.0/gempy.egg-info/SOURCES.txt
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        1 2023-06-20 12:48:48.000000 gempy-2.3.0/gempy.egg-info/dependency_links.txt
+-rw-r--r--   0 leguark   (1000) leguark   (1000)      159 2023-06-20 12:48:48.000000 gempy-2.3.0/gempy.egg-info/requires.txt
+-rw-r--r--   0 leguark   (1000) leguark   (1000)       28 2023-06-20 12:48:48.000000 gempy-2.3.0/gempy.egg-info/top_level.txt
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/gempy_3/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy_3/__init__.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/gempy_3/api/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy_3/api/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     4327 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy_3/api/gp2_to_gp3_input.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     3612 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy_3/api/gp3_to_gp2_output.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/gempy_3/api/test_api/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy_3/api/test_api/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1242 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy_3/api/test_api/_gp2togp3_test_utils.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     2939 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy_3/api/test_api/test_basic_model_gempy2_to_gempy3.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    10154 2023-06-20 11:58:26.000000 gempy-2.3.0/gempy_3/api/test_api/test_unconformities_gempy2_to_gempy3.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)       79 2023-06-20 12:48:48.836705 gempy-2.3.0/setup.cfg
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1402 2023-06-20 12:46:58.000000 gempy-2.3.0/setup.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.826705 gempy-2.3.0/test/
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/figs/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/test/figs/__init__.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/input_data/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/test/input_data/__init__.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/test_addons/
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/test_addons/DEP/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_addons/DEP/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     5745 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_addons/DEP/_test_google_earth.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     4129 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_addons/DEP/est_rex_cloud_api.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/test_addons/DEP/rexfiles/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_addons/DEP/rexfiles/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1649 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_addons/DEP/te_gempy_to_rexfile.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_addons/__init__.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/test_anisotropies/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_anisotropies/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     4972 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_anisotropies/test_anisotropies.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/test_api/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_api/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)      257 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_api/test_api.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     4977 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_api/test_geometry_api.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/test_assets/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_assets/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1483 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_assets/test_gravity.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)      538 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_assets/test_grid_tz.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     3685 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_assets/test_magnetics.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     2801 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_assets/test_topology_np.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/test_community_bugs/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_community_bugs/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     3804 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_community_bugs/test_community_bugs.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/test_core/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    10316 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_core/UPDATE_data.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)      215 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_core/UPDATE_model.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_core/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)      334 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_core/test_colors.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     8489 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_core/test_data_classes.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     2899 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_core/test_data_mutation.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1043 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_core/test_data_mutation2.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/test_core/test_grids/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_core/test_grids/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     8302 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_core/test_grids/test_diamond_square.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     2458 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_core/test_grids/test_grid.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     5751 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_core/test_grids/test_topography.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     3350 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_core/test_io.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     8337 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_core/test_model.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)      273 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_core/test_performance.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    13513 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_core/test_pile_manipulation.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     2417 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_core/test_solution.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1361 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_core/test_sort_surfaces.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     6376 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_core/test_xsol.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/test_integrations/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_integrations/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     7094 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_integrations/test_map2loop.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/test_model_types/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_model_types/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)      450 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_model_types/test_complex_model.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1016 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_model_types/test_one_fault_model.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    12058 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_model_types/test_simple_models.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/test_plotting/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_plotting/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     3999 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_plotting/test_2d.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     2881 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_plotting/test_plot_3d.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)    13427 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_plotting/test_vista.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/test_prob_modeling/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)     1599 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_prob_modeling/TEST_pymc3.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_prob_modeling/__init__.py
+drwxr-xr-x   0 leguark   (1000) leguark   (1000)        0 2023-06-20 12:48:48.836705 gempy-2.3.0/test/test_utilities/
+-rw-r--r--   0 leguark   (1000) leguark   (1000)        0 2023-06-19 14:33:41.000000 gempy-2.3.0/test/test_utilities/__init__.py
+-rw-r--r--   0 leguark   (1000) leguark   (1000)      237 2023-06-20 11:58:26.000000 gempy-2.3.0/test/test_utilities/test_utilities.py
```

### Comparing `gempy-2.2b10.dev1/LICENSE` & `gempy-2.3.0/LICENSE`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,165 +1,165 @@
-                   GNU LESSER GENERAL PUBLIC LICENSE
-                       Version 3, 29 June 2007
-
- Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>
- Everyone is permitted to copy and distribute verbatim copies
- of this license document, but changing it is not allowed.
-
-
-  This version of the GNU Lesser General Public License incorporates
-the terms and conditions of version 3 of the GNU General Public
-License, supplemented by the additional permissions listed below.
-
-  0. Additional Definitions.
-
-  As used herein, "this License" refers to version 3 of the GNU Lesser
-General Public License, and the "GNU GPL" refers to version 3 of the GNU
-General Public License.
-
-  "The Library" refers to a covered work governed by this License,
-other than an Application or a Combined Work as defined below.
-
-  An "Application" is any work that makes use of an interface provided
-by the Library, but which is not otherwise based on the Library.
-Defining a subclass of a class defined by the Library is deemed a mode
-of using an interface provided by the Library.
-
-  A "Combined Work" is a work produced by combining or linking an
-Application with the Library.  The particular version of the Library
-with which the Combined Work was made is also called the "Linked
-Version".
-
-  The "Minimal Corresponding Source" for a Combined Work means the
-Corresponding Source for the Combined Work, excluding any source code
-for portions of the Combined Work that, considered in isolation, are
-based on the Application, and not on the Linked Version.
-
-  The "Corresponding Application Code" for a Combined Work means the
-object code and/or source code for the Application, including any data
-and utility programs needed for reproducing the Combined Work from the
-Application, but excluding the System Libraries of the Combined Work.
-
-  1. Exception to Section 3 of the GNU GPL.
-
-  You may convey a covered work under sections 3 and 4 of this License
-without being bound by section 3 of the GNU GPL.
-
-  2. Conveying Modified Versions.
-
-  If you modify a copy of the Library, and, in your modifications, a
-facility refers to a function or data to be supplied by an Application
-that uses the facility (other than as an argument passed when the
-facility is invoked), then you may convey a copy of the modified
-version:
-
-   a) under this License, provided that you make a good faith effort to
-   ensure that, in the event an Application does not supply the
-   function or data, the facility still operates, and performs
-   whatever part of its purpose remains meaningful, or
-
-   b) under the GNU GPL, with none of the additional permissions of
-   this License applicable to that copy.
-
-  3. Object Code Incorporating Material from Library Header Files.
-
-  The object code form of an Application may incorporate material from
-a header file that is part of the Library.  You may convey such object
-code under terms of your choice, provided that, if the incorporated
-material is not limited to numerical parameters, data structure
-layouts and accessors, or small macros, inline functions and templates
-(ten or fewer lines in length), you do both of the following:
-
-   a) Give prominent notice with each copy of the object code that the
-   Library is used in it and that the Library and its use are
-   covered by this License.
-
-   b) Accompany the object code with a copy of the GNU GPL and this license
-   document.
-
-  4. Combined Works.
-
-  You may convey a Combined Work under terms of your choice that,
-taken together, effectively do not restrict modification of the
-portions of the Library contained in the Combined Work and reverse
-engineering for debugging such modifications, if you also do each of
-the following:
-
-   a) Give prominent notice with each copy of the Combined Work that
-   the Library is used in it and that the Library and its use are
-   covered by this License.
-
-   b) Accompany the Combined Work with a copy of the GNU GPL and this license
-   document.
-
-   c) For a Combined Work that displays copyright notices during
-   execution, include the copyright notice for the Library among
-   these notices, as well as a reference directing the user to the
-   copies of the GNU GPL and this license document.
-
-   d) Do one of the following:
-
-       0) Convey the Minimal Corresponding Source under the terms of this
-       License, and the Corresponding Application Code in a form
-       suitable for, and under terms that permit, the user to
-       recombine or relink the Application with a modified version of
-       the Linked Version to produce a modified Combined Work, in the
-       manner specified by section 6 of the GNU GPL for conveying
-       Corresponding Source.
-
-       1) Use a suitable shared library mechanism for linking with the
-       Library.  A suitable mechanism is one that (a) uses at run time
-       a copy of the Library already present on the user's computer
-       system, and (b) will operate properly with a modified version
-       of the Library that is interface-compatible with the Linked
-       Version.
-
-   e) Provide Installation Information, but only if you would otherwise
-   be required to provide such information under section 6 of the
-   GNU GPL, and only to the extent that such information is
-   necessary to install and execute a modified version of the
-   Combined Work produced by recombining or relinking the
-   Application with a modified version of the Linked Version. (If
-   you use option 4d0, the Installation Information must accompany
-   the Minimal Corresponding Source and Corresponding Application
-   Code. If you use option 4d1, you must provide the Installation
-   Information in the manner specified by section 6 of the GNU GPL
-   for conveying Corresponding Source.)
-
-  5. Combined Libraries.
-
-  You may place library facilities that are a work based on the
-Library side by side in a single library together with other library
-facilities that are not Applications and are not covered by this
-License, and convey such a combined library under terms of your
-choice, if you do both of the following:
-
-   a) Accompany the combined library with a copy of the same work based
-   on the Library, uncombined with any other library facilities,
-   conveyed under the terms of this License.
-
-   b) Give prominent notice with the combined library that part of it
-   is a work based on the Library, and explaining where to find the
-   accompanying uncombined form of the same work.
-
-  6. Revised Versions of the GNU Lesser General Public License.
-
-  The Free Software Foundation may publish revised and/or new versions
-of the GNU Lesser General Public License from time to time. Such new
-versions will be similar in spirit to the present version, but may
-differ in detail to address new problems or concerns.
-
-  Each version is given a distinguishing version number. If the
-Library as you received it specifies that a certain numbered version
-of the GNU Lesser General Public License "or any later version"
-applies to it, you have the option of following the terms and
-conditions either of that published version or of any later version
-published by the Free Software Foundation. If the Library as you
-received it does not specify a version number of the GNU Lesser
-General Public License, you may choose any version of the GNU Lesser
-General Public License ever published by the Free Software Foundation.
-
-  If the Library as you received it specifies that a proxy can decide
-whether future versions of the GNU Lesser General Public License shall
-apply, that proxy's public statement of acceptance of any version is
-permanent authorization for you to choose that version for the
-Library.
+                   GNU LESSER GENERAL PUBLIC LICENSE
+                       Version 3, 29 June 2007
+
+ Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+
+  This version of the GNU Lesser General Public License incorporates
+the terms and conditions of version 3 of the GNU General Public
+License, supplemented by the additional permissions listed below.
+
+  0. Additional Definitions.
+
+  As used herein, "this License" refers to version 3 of the GNU Lesser
+General Public License, and the "GNU GPL" refers to version 3 of the GNU
+General Public License.
+
+  "The Library" refers to a covered work governed by this License,
+other than an Application or a Combined Work as defined below.
+
+  An "Application" is any work that makes use of an interface provided
+by the Library, but which is not otherwise based on the Library.
+Defining a subclass of a class defined by the Library is deemed a mode
+of using an interface provided by the Library.
+
+  A "Combined Work" is a work produced by combining or linking an
+Application with the Library.  The particular version of the Library
+with which the Combined Work was made is also called the "Linked
+Version".
+
+  The "Minimal Corresponding Source" for a Combined Work means the
+Corresponding Source for the Combined Work, excluding any source code
+for portions of the Combined Work that, considered in isolation, are
+based on the Application, and not on the Linked Version.
+
+  The "Corresponding Application Code" for a Combined Work means the
+object code and/or source code for the Application, including any data
+and utility programs needed for reproducing the Combined Work from the
+Application, but excluding the System Libraries of the Combined Work.
+
+  1. Exception to Section 3 of the GNU GPL.
+
+  You may convey a covered work under sections 3 and 4 of this License
+without being bound by section 3 of the GNU GPL.
+
+  2. Conveying Modified Versions.
+
+  If you modify a copy of the Library, and, in your modifications, a
+facility refers to a function or data to be supplied by an Application
+that uses the facility (other than as an argument passed when the
+facility is invoked), then you may convey a copy of the modified
+version:
+
+   a) under this License, provided that you make a good faith effort to
+   ensure that, in the event an Application does not supply the
+   function or data, the facility still operates, and performs
+   whatever part of its purpose remains meaningful, or
+
+   b) under the GNU GPL, with none of the additional permissions of
+   this License applicable to that copy.
+
+  3. Object Code Incorporating Material from Library Header Files.
+
+  The object code form of an Application may incorporate material from
+a header file that is part of the Library.  You may convey such object
+code under terms of your choice, provided that, if the incorporated
+material is not limited to numerical parameters, data structure
+layouts and accessors, or small macros, inline functions and templates
+(ten or fewer lines in length), you do both of the following:
+
+   a) Give prominent notice with each copy of the object code that the
+   Library is used in it and that the Library and its use are
+   covered by this License.
+
+   b) Accompany the object code with a copy of the GNU GPL and this license
+   document.
+
+  4. Combined Works.
+
+  You may convey a Combined Work under terms of your choice that,
+taken together, effectively do not restrict modification of the
+portions of the Library contained in the Combined Work and reverse
+engineering for debugging such modifications, if you also do each of
+the following:
+
+   a) Give prominent notice with each copy of the Combined Work that
+   the Library is used in it and that the Library and its use are
+   covered by this License.
+
+   b) Accompany the Combined Work with a copy of the GNU GPL and this license
+   document.
+
+   c) For a Combined Work that displays copyright notices during
+   execution, include the copyright notice for the Library among
+   these notices, as well as a reference directing the user to the
+   copies of the GNU GPL and this license document.
+
+   d) Do one of the following:
+
+       0) Convey the Minimal Corresponding Source under the terms of this
+       License, and the Corresponding Application Code in a form
+       suitable for, and under terms that permit, the user to
+       recombine or relink the Application with a modified version of
+       the Linked Version to produce a modified Combined Work, in the
+       manner specified by section 6 of the GNU GPL for conveying
+       Corresponding Source.
+
+       1) Use a suitable shared library mechanism for linking with the
+       Library.  A suitable mechanism is one that (a) uses at run time
+       a copy of the Library already present on the user's computer
+       system, and (b) will operate properly with a modified version
+       of the Library that is interface-compatible with the Linked
+       Version.
+
+   e) Provide Installation Information, but only if you would otherwise
+   be required to provide such information under section 6 of the
+   GNU GPL, and only to the extent that such information is
+   necessary to install and execute a modified version of the
+   Combined Work produced by recombining or relinking the
+   Application with a modified version of the Linked Version. (If
+   you use option 4d0, the Installation Information must accompany
+   the Minimal Corresponding Source and Corresponding Application
+   Code. If you use option 4d1, you must provide the Installation
+   Information in the manner specified by section 6 of the GNU GPL
+   for conveying Corresponding Source.)
+
+  5. Combined Libraries.
+
+  You may place library facilities that are a work based on the
+Library side by side in a single library together with other library
+facilities that are not Applications and are not covered by this
+License, and convey such a combined library under terms of your
+choice, if you do both of the following:
+
+   a) Accompany the combined library with a copy of the same work based
+   on the Library, uncombined with any other library facilities,
+   conveyed under the terms of this License.
+
+   b) Give prominent notice with the combined library that part of it
+   is a work based on the Library, and explaining where to find the
+   accompanying uncombined form of the same work.
+
+  6. Revised Versions of the GNU Lesser General Public License.
+
+  The Free Software Foundation may publish revised and/or new versions
+of the GNU Lesser General Public License from time to time. Such new
+versions will be similar in spirit to the present version, but may
+differ in detail to address new problems or concerns.
+
+  Each version is given a distinguishing version number. If the
+Library as you received it specifies that a certain numbered version
+of the GNU Lesser General Public License "or any later version"
+applies to it, you have the option of following the terms and
+conditions either of that published version or of any later version
+published by the Free Software Foundation. If the Library as you
+received it does not specify a version number of the GNU Lesser
+General Public License, you may choose any version of the GNU Lesser
+General Public License ever published by the Free Software Foundation.
+
+  If the Library as you received it specifies that a proxy can decide
+whether future versions of the GNU Lesser General Public License shall
+apply, that proxy's public statement of acceptance of any version is
+permanent authorization for you to choose that version for the
+Library.
```

### Comparing `gempy-2.2b10.dev1/README.md` & `gempy-2.3.0/README.md`

 * *Files 3% similar despite different names*

```diff
@@ -2,15 +2,14 @@
 
 > Open-source, implicit 3D structural geological modeling in Python.
 
 [![PyPI](https://img.shields.io/badge/python-3-blue.svg)](https://www.python.org/downloads/)
 [![PyPI](https://img.shields.io/badge/pypi-1.0-blue.svg)](https://pypi.org/project/gempy/)
 [![license: LGPL v3](https://img.shields.io/badge/license-LGPL%20v3-blue.svg)](https://github.com/cgre-aachen/gempy/blob/master/LICENSE)
 [![Documentation Status](https://assets.readthedocs.org/static/projects/badges/passing-flat.svg)](http://docs.gempy.org)
-[![Travis Build](https://travis-ci.org/cgre-aachen/gempy.svg?branch=master)](https://travis-ci.org/github/cgre-aachen/gempy/branches)
 [![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/cgre-aachen/gempy/master)
 [![DOI](https://zenodo.org/badge/96211155.svg)](https://zenodo.org/badge/latestdoi/96211155)
 [![DOCKER](https://img.shields.io/docker/cloud/automated/leguark/gempy.svg)](https://cloud.docker.com/repository/docker/leguark/gempy)
 
 ## Overview
 
 [GemPy](https://www.gempy.org/) is a Python-based, **open-source geomodeling library**. It is
@@ -22,53 +21,64 @@
 
 We provide the latest release version of GemPy via PyPi package services. We highly recommend using PyPi,
 
 `$ pip install gempy`
 
 as it will take care of automatically installing all the required dependencies - except in windows that requires one extra step.
 
-Windows does not have a gcc compilers pre-installed. The easiest way to get a theano compatible compiler is by using 
-the theano conda installation. Therefore the process would be the following:
+Windows does not have a gcc compilers pre-installed. The easiest way to get a aesara compatible compiler is by using 
+the aesara conda installation. Therefore the process would be the following:
 
-`$ conda install theano`
+`$ conda install aesara`
 
 `$ pip install gempy`
 
 For more information, refer to the [installation documentation](https://docs.gempy.org/installation.html).
 
+## Requirements
+
+The following versions are required/strongly recommended for the main dependencies of GemPy (as of June 2023):
+- python>=3.10
+- pandas>=2.0
+- matplotlib>=3.7
+- pyvista>=0.39
+
 ## Resources
 
-After installation you can either check the [notebook tutorials](https://docs.gempy.org/getting_started/get_started.html#sphx-glr-getting-started-get-started-py) 
+After installation, you can either check the [notebook tutorials](https://docs.gempy.org/getting_started/get_started.html#sphx-glr-getting-started-get-started-py) 
 or the [video introduction](https://www.youtube.com/watch?v=n0btC5Zilyc) to get started.
 
-Got to the [documentation site](http://docs.gempy.org/) for further information and enjoy the [tutorials and examples](https://www.gempy.org/tutorials).
+Go to the [documentation site](http://docs.gempy.org/) for further information and enjoy the [tutorials and examples](https://www.gempy.org/tutorials).
 
 For questions and support, please use [discussions](https://github.com/cgre-aachen/gempy/discussions).
 
 If you find a bug or have a feature request, create an [issue](https://github.com/cgre-aachen/gempy/issues).
 
 Follow these [guidelines](https://github.com/cgre-aachen/gempy/blob/WIP_readme-update-march21/CONTRIBUTING.md) to contribute to GemPy.
 
 <a name="ref"></a>
 ## References 
 
 * de la Varga, M., Schaaf, A., and Wellmann, F. (2019). [GemPy 1.0: open-source stochastic geological modeling and inversion](https://gmd.copernicus.org/articles/12/1/2019/gmd-12-1-2019.pdf), Geosci. Model Dev., 12, 1-32.
 * Wellmann, F., & Caumon, G. (2018). [3-D Structural geological models: Concepts, methods, and uncertainties.](https://hal.univ-lorraine.fr/hal-01921494/file/structural_models_for_geophysicsHAL.pdf) In Advances in Geophysics (Vol. 59, pp. 1-121). Elsevier.
-* Calcagno, P., Chilès, J. P., Courrioux, G., & Guillen, A. (2008). Geological modelling from field data and geological knowledge: Part I. Modelling method coupling 3D potential-field interpolation and geological rules. Physics of the Earth and Planetary Interiors, 171(1-4), 147-157.
-* Lajaunie, C., Courrioux, G., & Manuel, L. (1997). Foliation fields and 3D cartography in geology: principles of a method based on potential interpolation. Mathematical Geology, 29(4), 571-584.
+* Calcagno, P., Chilès, J. P., Courrioux, G., & Guillen, A. (2008). [Geological modelling from field data and geological knowledge: Part I. Modelling method coupling 3D potential-field interpolation and geological rules](https://www.sciencedirect.com/science/article/abs/pii/S0031920108001258). Physics of the Earth and Planetary Interiors, 171(1-4), 147-157.
+* Lajaunie, C., Courrioux, G., & Manuel, L. (1997). [Foliation fields and 3D cartography in geology: principles of a method based on potential interpolation](https://link.springer.com/article/10.1007/BF02775087). Mathematical Geology, 29(4), 571-584.
 
 ## Publications using GemPy
 
-* Güdük, N.; de la Varga, M.; Kaukolinna, J.; Wellmann, F. (2021). [Model-Based Probabilistic Inversion Using Magnetic Data: A Case Study on the Kevitsa Deposit](https://doi.org/10.3390/geosciences11040150). Geosciences, 11, 150. https://doi.org/10.3390/geosciences11040150 (open access).
-* Schaaf, A., de la Varga, M., Wellmann, F., & Bond, C. E. (2020). [Constraining stochastic 3-D structural geological models with topology information using Approximate Bayesian Computation using GemPy 2.1](https://gmd.copernicus.org/preprints/gmd-2020-136/gmd-2020-136.pdf). Geoscientific Model Development Discussions, 1-24 (open access).
-* Stamm, F. A., de la Varga, M., and Wellmann, F. (2019). [Actors, actions, and uncertainties: optimizing decision-making based on 3-D structural geological models](https://se.copernicus.org/articles/10/2015/2019/se-10-2015-2019.html), Solid Earth, 10, 2015–2043 (open access).
+
+* Schaaf, A., de la Varga, M., Wellmann, F., & Bond, C. E. (2021). [Constraining stochastic 3-D structural geological models with topology information using approximate Bayesian computation in GemPy 2.1](https://gmd.copernicus.org/articles/14/3899/2021/gmd-14-3899-2021.html). Geosci. Model Dev., 14(6), 3899-3913. doi:10.5194/gmd-14-3899-2021
+* Güdük, N., de la Varga, M. Kaukolinna, J. and Wellmann, F. (2021). [Model-Based Probabilistic Inversion Using Magnetic Data: A Case Study on the Kevitsa Deposit](https://www.mdpi.com/2076-3263/11/4/150), _Geosciences_, 11(4):150. https://doi.org/10.3390/geosciences11040150.
+* Stamm, F. A., de la Varga, M., and Wellmann, F. (2019). [Actors, actions, and uncertainties: optimizing decision-making based on 3-D structural geological models](https://se.copernicus.org/articles/10/2015/2019/se-10-2015-2019.html), Solid Earth, 10, 2015–2043.
 * Wellmann, F., Schaaf, A., de la Varga, M., & von Hagke, C. (2019). [From Google Earth to 3D Geology Problem 2: Seeing Below the Surface of the Digital Earth](
 https://www.sciencedirect.com/science/article/pii/B9780128140482000156).
 In Developments in Structural Geology and Tectonics (Vol. 5, pp. 189-204). Elsevier.
 
+A continuously growing list of gempy-applications (e.g. listing real-world models) can be found [here](https://hackmd.io/@Japhiolite/B1juPvCxc).
+
 ## Gallery
 
 ### Geometries
 
 <p>
 <table>
 <tr>
```

### Comparing `gempy-2.2b10.dev1/examples/examples/geometries/1_horizontal_stratigraphic.py` & `gempy-2.3.0/examples/examples/geometries/3_recumbent_fold.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,63 +1,67 @@
-"""
-Model 1 - Horizontal stratigraphic
-==================================
-
-"""
-
-# %%
-# This is the most simple model of horizontally stacked layers. We start
-# by importing the necessary dependencies:
-# 
-
-# %%
-# Importing GemPy
-import gempy as gp
-
-import pandas as pd
-pd.set_option('precision', 2)
-
-# %%
-# Creating the model by importing the input data and displaying it:
-# 
-
-# %%
-data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
-geo_data = gp.create_data('horizontal', extent=[0, 1000, 0, 1000, 0, 1000], resolution=[50, 50, 50],
-                          path_o=data_path + "/data/input_data/jan_models/model1_orientations.csv",
-                          path_i=data_path + "/data/input_data/jan_models/model1_surface_points.csv")
-
-# %%
-# Setting and ordering the units and series:
-# 
-
-# %% 
-gp.map_stack_to_surfaces(geo_data, {"Strat_Series": ('rock2', 'rock1'), "Basement_Series": ('basement')})
-
-# %% 
-gp.plot_2d(geo_data, direction=['y'])
-
-# %%
-# Calculating the model:
-# 
-
-# %% 
-interp_data = gp.set_interpolator(geo_data, compile_theano=True,
-                                  theano_optimizer='fast_compile')
-
-# %% 
-sol = gp.compute_model(geo_data)
-
-# %%
-# Displaying the result in x and y direction:
-# 
-
-# %%
-gp.plot_2d(geo_data, cell_number=[25],
-           direction=['x'], show_data=True)
-
-# %%
-# sphinx_gallery_thumbnail_number = 2
-gp.plot_2d(geo_data, cell_number=[25],
-           direction=['y'], show_data=True)
-
+"""
+Model 3 - Recumbent Fold
+========================
+
+"""
+
+# %%
+# A recumbent (overturned) fold. We start by importing the necessary
+# dependencies:
+# 
+
+# %%
+# Importing GemPy
+import gempy as gp
+
+# Importing auxiliary libraries
+import pandas as pd
+pd.set_option('display.precision', 2)
+
+# %%
+# Creating the model by importing the input data and displaying it:
+# 
+
+# %%
+data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
+path_to_data = data_path + "/data/input_data/jan_models/"
+geo_data = gp.create_data('recumbent',
+                          extent=[0, 1000, 0, 1000, 0, 1000], resolution=[50, 50, 50],
+                          path_o=path_to_data + "model3_orientations.csv",
+                          path_i=path_to_data + "model3_surface_points.csv")
+
+# %% 
+geo_data.get_data()
+
+# %%
+# Setting and ordering the units and series:
+# 
+
+# %% 
+gp.map_stack_to_surfaces(geo_data, {"Strat_Series": ('rock2', 'rock1'), "Basement_Series": ('basement')})
+
+# %%
+gp.plot_2d(geo_data, direction=['y'])
+
+# %%
+# Calculating the model:
+# 
+
+# %% 
+interp_data = gp.set_interpolator(geo_data, aesara_optimizer='fast_compile')
+
+# %% 
+geo_data.additional_data
+
+# %% 
+sol = gp.compute_model(geo_data)
+
+# %%
+# Displaying the result in x and y direction:
+# 
+
+# %%
+# sphinx_gallery_thumbnail_number = 2
+gp.plot_2d(geo_data, cell_number=[25],
+           direction=['y'], show_data=True)
+
 gp.save_model(geo_data)
```

### Comparing `gempy-2.2b10.dev1/examples/examples/geometries/4_pinchout.py` & `gempy-2.3.0/examples/examples/geometries/5_fault.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,71 +1,75 @@
-"""
-Model 4 - Pinchout
-==================
-
-"""
-
-# %%
-# Forcing GemPy to create a layer of varying thickness. We start by
-# importing the necessary dependencies:
-# 
-
-# %%
-# Importing GemPy
-import gempy as gp
-
-import pandas as pd
-pd.set_option('precision', 2)
-
-# %%
-# Creating the model by importing the input data and displaying it:
-# 
-
-# %%
-data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
-
-path_to_data = data_path + "/data/input_data/jan_models/"
-geo_data = gp.create_data('pinchout',
-                          extent=[0, 1000, 0, 1000, 0, 1000], resolution=[50, 50, 50],
-                          path_o=path_to_data + "model4_orientations.csv",
-                          path_i=path_to_data + "model4_surface_points.csv")
-
-# %% 
-geo_data.get_data()
-
-# %%
-# Setting and ordering the units and series:
-# 
-
-# %% 
-gp.map_stack_to_surfaces(geo_data,
-                         {"Strat_Series": ('rock2', 'rock1'),
-                          "Basement_Series": ('basement')})
-
-# %%
-gp.plot_2d(geo_data, direction=['y'])
-
-# %%
-# Calculating the model:
-# 
-
-# %% 
-interp_data = gp.set_interpolator(geo_data, theano_optimizer='fast_compile')
-
-# %% 
-sol = gp.compute_model(geo_data)
-
-# %%
-# Displaying the result in x and y direction:
-# 
-
-# %%
-gp.plot_2d(geo_data, cell_number=[25],
-           direction=['x'], show_data=True)
-
-# %%
-# sphinx_gallery_thumbnail_number = 3
-gp.plot_2d(geo_data, cell_number=[25],
-           direction=['y'], show_data=True)
-
-# %%
+"""
+Model 5 - Fault
+===============
+
+"""
+
+# %%
+# A simple fault model with constant offset. We start by importing the
+# necessary dependencies:
+# 
+
+# %%
+# Importing GemPy
+import gempy as gp
+
+import pandas as pd
+pd.set_option('display.precision', 2)
+
+# %%
+# Creating the model by importing the input data and displaying it:
+# 
+
+# %%
+data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
+path_to_data = data_path + "/data/input_data/jan_models/"
+
+geo_data = gp.create_data('fault', extent=[0, 1000, 0, 1000, 0, 1000], resolution=[50, 50, 50],
+                          path_o=path_to_data + "model5_orientations.csv",
+                          path_i=path_to_data + "model5_surface_points.csv")
+
+# %% 
+geo_data.get_data()
+
+# %%
+# Setting and ordering the units and series:
+# 
+
+# %% 
+gp.map_stack_to_surfaces(geo_data, {"Fault_Series": 'fault',
+                                    "Strat_Series": ('rock2', 'rock1')})
+geo_data.set_is_fault(['Fault_Series'])
+
+# %%
+gp.plot_2d(geo_data, direction='y')
+
+# %%
+# Calculating the model:
+# 
+
+# %% 
+interp_data = gp.set_interpolator(geo_data, aesara_optimizer='fast_compile')
+
+# %% 
+sol = gp.compute_model(geo_data)
+
+# %%
+# Displaying the result in x and y direction:
+# 
+
+# %%
+# sphinx_gallery_thumbnail_number = 2
+gp.plot_2d(geo_data, cell_number=25,
+           direction='y', show_data=False, show_all_data=True)
+
+# %%
+gp.plot_2d(geo_data, cell_number=25,
+           direction='x', show_data=True)
+
+# %% 
+
+gp.plot_2d(geo_data, cell_number=25,
+           direction='y', show_data=True, show_scalar=True, series_n=1)
+
+
 gp.save_model(geo_data)
```

### Comparing `gempy-2.2b10.dev1/examples/examples/geometries/5_fault.py` & `gempy-2.3.0/examples/examples/geometries/7_combination.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,75 +1,75 @@
-"""
-Model 5 - Fault
-===============
-
-"""
-
-# %%
-# A simple fault model with constant offset. We start by importing the
-# necessary dependencies:
-# 
-
-# %%
-# Importing GemPy
-import gempy as gp
-
-import pandas as pd
-pd.set_option('precision', 2)
-
-# %%
-# Creating the model by importing the input data and displaying it:
-# 
-
-# %%
-data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
-path_to_data = data_path + "/data/input_data/jan_models/"
-
-geo_data = gp.create_data('fault', extent=[0, 1000, 0, 1000, 0, 1000], resolution=[50, 50, 50],
-                          path_o=path_to_data + "model5_orientations.csv",
-                          path_i=path_to_data + "model5_surface_points.csv")
-
-# %% 
-geo_data.get_data()
-
-# %%
-# Setting and ordering the units and series:
-# 
-
-# %% 
-gp.map_stack_to_surfaces(geo_data, {"Fault_Series": 'fault',
-                                    "Strat_Series": ('rock2', 'rock1')})
-geo_data.set_is_fault(['Fault_Series'])
-
-# %%
-gp.plot_2d(geo_data, direction='y')
-
-# %%
-# Calculating the model:
-# 
-
-# %% 
-interp_data = gp.set_interpolator(geo_data, theano_optimizer='fast_compile')
-
-# %% 
-sol = gp.compute_model(geo_data)
-
-# %%
-# Displaying the result in x and y direction:
-# 
-
-# %%
-# sphinx_gallery_thumbnail_number = 2
-gp.plot_2d(geo_data, cell_number=25,
-           direction='y', show_data=False, show_all_data=True)
-
-# %%
-gp.plot_2d(geo_data, cell_number=25,
-           direction='x', show_data=True)
-
-# %% 
-
-gp.plot_2d(geo_data, cell_number=25,
-           direction='y', show_data=True, show_scalar=True, series_n=1)
-
-
-gp.save_model(geo_data)
+"""
+Model 7 - Combination
+======================
+
+"""
+
+# %%
+# A folded domain featuring an unconformity and a fault. We start by importing
+# the necessary dependencies:
+#
+
+# %%
+# Importing GemPy
+import gempy as gp
+
+import pandas as pd
+pd.set_option('display.precision', 2)
+
+# %%
+# Creating the model by importing the input data and displaying it:
+#
+
+# %%
+data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
+path_to_data = data_path + "/data/input_data/jan_models/"
+
+geo_data = gp.create_data('combination',
+                          extent=[0, 2500, 0, 1000, 0, 1000],
+                          resolution=[125, 50, 50],
+                          path_o=path_to_data + "model7_orientations.csv",
+                          path_i=path_to_data + "model7_surface_points.csv")
+
+# %%
+geo_data.get_data()
+
+# %%
+# Setting and ordering the units and series:
+#
+
+# %%
+gp.map_stack_to_surfaces(geo_data, {"Fault_Series": ('fault'), "Strat_Series1": ('rock3'),
+                                     "Strat_Series2": ('rock2','rock1'),
+                                     "Basement_Series":('basement')})
+
+geo_data.set_is_fault(['Fault_Series'])
+
+# %%
+gp.plot_2d(geo_data, direction='y')
+
+# %%
+# Calculating the model:
+#
+
+# %%
+interp_data = gp.set_interpolator(geo_data, aesara_optimizer='fast_compile')
+
+# %%
+sol = gp.compute_model(geo_data)
+
+# %%
+# Displaying the result in x and y direction:
+#
+
+# %%
+gp.plot_2d(geo_data, cell_number=5,
+           direction='y', show_data=False, show_boundaries=True)
+
+# %%
+# sphinx_gallery_thumbnail_number = 2
+gp.plot_2d(geo_data, cell_number=5,
+           direction='x', show_data=True)
+
+# %%
+gp.plot_3d(geo_data)
+#gp.save_model(geo_data)
```

### Comparing `gempy-2.2b10.dev1/examples/examples/geometries/6_unconformity.py` & `gempy-2.3.0/examples/examples/geometries/6_unconformity.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,69 +1,69 @@
-"""
-Model 6 - Unconformity
-======================
-
-"""
-
-# %%
-# An unconformity cutting an anticline structure. We start by importing
-# the necessary dependencies:
-# 
-
-# %%
-# Importing GemPy
-import gempy as gp
-
-import pandas as pd
-pd.set_option('precision', 2)
-
-# %%
-# Creating the model by importing the input data and displaying it:
-# 
-
-# %%
-data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
-path_to_data = data_path + "/data/input_data/jan_models/"
-
-geo_data = gp.create_data('unconformity', extent=[0, 1000, 0, 1000, 0, 1000], resolution=[50, 50, 50],
-                          path_o=path_to_data + "model6_orientations.csv",
-                          path_i=path_to_data + "model6_surface_points.csv")
-
-# %% 
-geo_data.get_data()
-
-# %%
-# Setting and ordering the units and series:
-# 
-
-# %% 
-gp.map_stack_to_surfaces(geo_data, {"Strat_Series1": ('rock3'),
-                                    "Strat_Series2": ('rock2', 'rock1'),
-                                    "Basement_Series": ('basement')})
-
-# %%
-gp.plot_2d(geo_data, direction='y')
-
-# %%
-# Calculating the model:
-# 
-
-# %% 
-interp_data = gp.set_interpolator(geo_data, theano_optimizer='fast_compile')
-
-# %% 
-sol = gp.compute_model(geo_data)
-
-# %%
-# Displaying the result in x and y direction:
-# 
-
-# %%
-gp.plot_2d(geo_data, cell_number=25,
-           direction='y', show_data=True)
-
-# %%
-# sphinx_gallery_thumbnail_number = 2
-gp.plot_2d(geo_data, cell_number=25,
-           direction='x', show_data=True)
-
-gp.save_model(geo_data)
+"""
+Model 6 - Unconformity
+======================
+
+"""
+
+# %%
+# An unconformity cutting an anticline structure. We start by importing
+# the necessary dependencies:
+# 
+
+# %%
+# Importing GemPy
+import gempy as gp
+
+import pandas as pd
+pd.set_option('display.precision', 2)
+
+# %%
+# Creating the model by importing the input data and displaying it:
+# 
+
+# %%
+data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
+path_to_data = data_path + "/data/input_data/jan_models/"
+
+geo_data = gp.create_data('unconformity', extent=[0, 1000, 0, 1000, 0, 1000], resolution=[50, 50, 50],
+                          path_o=path_to_data + "model6_orientations.csv",
+                          path_i=path_to_data + "model6_surface_points.csv")
+
+# %% 
+geo_data.get_data()
+
+# %%
+# Setting and ordering the units and series:
+# 
+
+# %% 
+gp.map_stack_to_surfaces(geo_data, {"Strat_Series1": ('rock3'),
+                                    "Strat_Series2": ('rock2', 'rock1'),
+                                    "Basement_Series": ('basement')})
+
+# %%
+gp.plot_2d(geo_data, direction='y')
+
+# %%
+# Calculating the model:
+# 
+
+# %% 
+interp_data = gp.set_interpolator(geo_data, aesara_optimizer='fast_compile')
+
+# %% 
+sol = gp.compute_model(geo_data)
+
+# %%
+# Displaying the result in x and y direction:
+# 
+
+# %%
+gp.plot_2d(geo_data, cell_number=25,
+           direction='y', show_data=True)
+
+# %%
+# sphinx_gallery_thumbnail_number = 2
+gp.plot_2d(geo_data, cell_number=25,
+           direction='x', show_data=True)
+
+gp.save_model(geo_data)
```

### Comparing `gempy-2.2b10.dev1/examples/examples/geometries/7_combination.py` & `gempy-2.3.0/examples/examples/geometries/2_fold.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,75 +1,68 @@
-"""
-Model 7 - Combination
-======================
-
-"""
-
-# %%
-# A folded domain featuring an unconformity and a fault. We start by importing
-# the necessary dependencies:
-#
-
-# %%
-# Importing GemPy
-import gempy as gp
-
-import pandas as pd
-pd.set_option('precision', 2)
-
-# %%
-# Creating the model by importing the input data and displaying it:
-#
-
-# %%
-data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
-path_to_data = data_path + "/data/input_data/jan_models/"
-
-geo_data = gp.create_data('combination',
-                          extent=[0, 2500, 0, 1000, 0, 1000],
-                          resolution=[125, 50, 50],
-                          path_o=path_to_data + "model7_orientations.csv",
-                          path_i=path_to_data + "model7_surface_points.csv")
-
-# %%
-geo_data.get_data()
-
-# %%
-# Setting and ordering the units and series:
-#
-
-# %%
-gp.map_stack_to_surfaces(geo_data, {"Fault_Series": ('fault'), "Strat_Series1": ('rock3'),
-                                     "Strat_Series2": ('rock2','rock1'),
-                                     "Basement_Series":('basement')})
-
-geo_data.set_is_fault(['Fault_Series'])
-
-# %%
-gp.plot_2d(geo_data, direction='y')
-
-# %%
-# Calculating the model:
-#
-
-# %%
-interp_data = gp.set_interpolator(geo_data, theano_optimizer='fast_compile')
-
-# %%
-sol = gp.compute_model(geo_data)
-
-# %%
-# Displaying the result in x and y direction:
-#
-
-# %%
-gp.plot_2d(geo_data, cell_number=5,
-           direction='y', show_data=False, show_boundaries=True)
-
-# %%
-# sphinx_gallery_thumbnail_number = 2
-gp.plot_2d(geo_data, cell_number=5,
-           direction='x', show_data=True)
-
-# %%
-gp.plot_3d(geo_data)
+"""
+Model 2 - Anticline
+===================
+
+"""
+
+# %%
+# A simple anticline structure. We start by importing the necessary
+# dependencies:
+# 
+
+# Importing GemPy
+import gempy as gp
+
+import pandas as pd
+pd.set_option('display.precision', 2)
+
+# %%
+# Creating the model by importing the input data and displaying it:
+# 
+
+# %%
+data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
+path_to_data = data_path + "/data/input_data/jan_models/"
+geo_data = gp.create_data('fold', extent=[0, 1000, 0, 1000, 0, 1000], resolution=[50, 50, 50],
+                          path_o=path_to_data + "model2_orientations.csv",
+                          path_i=path_to_data + "model2_surface_points.csv")
+
+# %% 
+geo_data.get_data().head()
+
+# %%
+# Setting and ordering the units and series:
+# 
+
+# %% 
+gp.map_stack_to_surfaces(geo_data, {"Strat_Series": ('rock2', 'rock1'), "Basement_Series": ('basement')})
+
+# %%
+gp.plot_2d(geo_data, direction=['y'])
+
+# %%
+# Calculating the model:
+# 
+
+# %% 
+interp_data = gp.set_interpolator(geo_data, aesara_optimizer='fast_compile')
+
+# %% 
+geo_data.orientations
+
+# %% 
+sol = gp.compute_model(geo_data)
+
+# %%
+# Displaying the result in y and x direction:
+# 
+
+# %%
+gp.plot_2d(geo_data, cell_number=15,
+           direction='y', show_data=True)
+
+# %%
+# sphinx_gallery_thumbnail_number = 2
+gp.plot_2d(geo_data, cell_number=25,
+           direction='x', show_data=True)
+
 gp.save_model(geo_data)
```

### Comparing `gempy-2.2b10.dev1/examples/examples/real/Alesmodel.py` & `gempy-2.3.0/examples/examples/real/Alesmodel.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,105 +1,105 @@
-"""
-Alesmodel: Plotting sections and maps.
-======================================
-
-"""
-
-import gempy as gp
-import numpy as np
-import matplotlib.pyplot as plt
-import os
-
-# %%
-cwd = os.getcwd()
-if 'examples' not in cwd:
-    data_path = os.getcwd() + '/examples'
-else:
-    data_path = cwd + '/../..'
-
-path_interf = data_path + "/data/input_data/AlesModel/2018_interf.csv"
-path_orient = data_path + "/data/input_data/AlesModel/2018_orient_clust_n_init5_0.csv"
-path_dem = data_path + "/data/input_data/AlesModel/_cropped_DEM_coarse.tif"
-
-# %% 
-resolution = [100, 100, 100]
-extent = np.array([729550.0, 751500.0, 1913500.0, 1923650.0, -1800.0, 800.0])
-geo_model = gp.create_model('Alesmodel')
-gp.init_data(geo_model, extent=extent, resolution=resolution,
-             path_i=path_interf,
-             path_o=path_orient)
-
-# %% 
-sdict = {'section1': ([732000, 1916000], [745000, 1916000], [200, 150])}
-geo_model.set_section_grid(sdict)
-
-# %% 
-# sorting of lithologies
-gp.map_stack_to_surfaces(geo_model, {'fault_left': ('fault_left'),
-                                     'fault_right': ('fault_right'),
-                                     'fault_lr': ('fault_lr'),
-                                     'Trias_Series': ('TRIAS', 'LIAS'),
-                                     'Carbon_Series': ('CARBO'),
-                                     'Basement_Series': ('basement')}, remove_unused_series=True)
-
-# %% 
-colordict = {'LIAS': '#015482', 'TRIAS': '#9f0052', 'CARBO': '#ffbe00', 'basement': '#728f02',
-             'fault_left': '#2a2a2a', 'fault_right': '#545454', 'fault_lr': '#a5a391'}
-geo_model.surfaces.colors.change_colors(colordict)
-
-# %% 
-a = gp.plot_2d(geo_model, direction='y')
-
-# %% 
-geo_model.rescaling
-
-# %% 
-gp.plot.plot_section_traces(geo_model)
-
-# %%
-# Faults
-# ''''''
-# 
-
-# %% 
-geo_model.set_is_fault(['fault_right', 'fault_left', 'fault_lr'], change_color=True)
-
-# %% 
-gp.set_interpolator(geo_model,
-                    output=['geology'], compile_theano=True,
-                    theano_optimizer='fast_run', dtype='float64',
-                    verbose=[])
-
-# %%
-# Topography
-# ~~~~~~~~~~
-# 
-
-# %% 
-geo_model.set_topography(source='gdal', filepath=path_dem)
-
-# %% 
-geo_model.surfaces
-
-# %% 
-_ = gp.compute_model(geo_model, compute_mesh=True, compute_mesh_options={'rescale': False})
-
-# %% 
-gp.plot_2d(geo_model, cell_number=[4], direction=['y'], show_topography=True,
-           show_data=True)
-
-# %% 
-gp.plot_2d(geo_model, section_names=['topography'], show_data=False,
-           show_boundaries=False)
-
-# %%
-# sphinx_gallery_thumbnail_number = 5
-gp.plot_3d(geo_model)
-
-# %%
-# np.save('Ales_vert3', geo_model.solutions.vertices)
-# np.save('Ales_edges3', geo_model.solutions.edges)
-
-# %% 
-# gp.plot.plot_ar(geo_model)
-
+"""
+Alesmodel: Plotting sections and maps.
+======================================
+
+"""
+
+import gempy as gp
+import numpy as np
+import matplotlib.pyplot as plt
+import os
+
+# %%
+cwd = os.getcwd()
+if 'examples' not in cwd:
+    data_path = os.getcwd() + '/examples'
+else:
+    data_path = cwd + '/../..'
+
+path_interf = data_path + "/data/input_data/AlesModel/2018_interf.csv"
+path_orient = data_path + "/data/input_data/AlesModel/2018_orient_clust_n_init5_0.csv"
+path_dem = data_path + "/data/input_data/AlesModel/_cropped_DEM_coarse.tif"
+
+# %% 
+resolution = [100, 100, 100]
+extent = np.array([729550.0, 751500.0, 1913500.0, 1923650.0, -1800.0, 800.0])
+geo_model = gp.create_model('Alesmodel')
+gp.init_data(geo_model, extent=extent, resolution=resolution,
+             path_i=path_interf,
+             path_o=path_orient)
+
+# %% 
+sdict = {'section1': ([732000, 1916000], [745000, 1916000], [200, 150])}
+geo_model.set_section_grid(sdict)
+
+# %% 
+# sorting of lithologies
+gp.map_stack_to_surfaces(geo_model, {'fault_left': ('fault_left'),
+                                     'fault_right': ('fault_right'),
+                                     'fault_lr': ('fault_lr'),
+                                     'Trias_Series': ('TRIAS', 'LIAS'),
+                                     'Carbon_Series': ('CARBO'),
+                                     'Basement_Series': ('basement')}, remove_unused_series=True)
+
+# %% 
+colordict = {'LIAS': '#015482', 'TRIAS': '#9f0052', 'CARBO': '#ffbe00', 'basement': '#728f02',
+             'fault_left': '#2a2a2a', 'fault_right': '#545454', 'fault_lr': '#a5a391'}
+geo_model.surfaces.colors.change_colors(colordict)
+
+# %% 
+a = gp.plot_2d(geo_model, direction='y')
+
+# %% 
+geo_model.rescaling
+
+# %% 
+gp.plot.plot_section_traces(geo_model)
+
+# %%
+# Faults
+# ''''''
+# 
+
+# %% 
+geo_model.set_is_fault(['fault_right', 'fault_left', 'fault_lr'], change_color=True)
+
+# %% 
+gp.set_interpolator(geo_model,
+                    output=['geology'], compile_aesara=True,
+                    aesara_optimizer='fast_run', dtype='float64',
+                    verbose=[])
+
+# %%
+# Topography
+# ~~~~~~~~~~
+# 
+
+# %% 
+geo_model.set_topography(source='gdal', filepath=path_dem)
+
+# %% 
+geo_model.surfaces
+
+# %% 
+_ = gp.compute_model(geo_model, compute_mesh=True, compute_mesh_options={'rescale': False})
+
+# %% 
+gp.plot_2d(geo_model, cell_number=[4], direction=['y'], show_topography=True,
+           show_data=True)
+
+# %% 
+gp.plot_2d(geo_model, section_names=['topography'], show_data=False,
+           show_boundaries=False)
+
+# %%
+# sphinx_gallery_thumbnail_number = 5
+gp.plot_3d(geo_model)
+
+# %%
+# np.save('Ales_vert3', geo_model.solutions.vertices)
+# np.save('Ales_edges3', geo_model.solutions.edges)
+
+# %% 
+# gp.plot.plot_ar(geo_model)
+
 gp.save_model(geo_model)
```

### Comparing `gempy-2.2b10.dev1/examples/examples/real/Claudius.py` & `gempy-2.3.0/examples/examples/real/Claudius.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,302 +1,302 @@
-"""
-Claudius
-~~~~~~~~
-
-"""
-
-# %%
-import sys, os
-os.environ["THEANO_FLAGS"] = "mode=FAST_RUN,device=cpu"
-
-# Importing gempy
-import gempy as gp
-
-# Aux imports
-import numpy as np
-import pandas as pn
-
-# %%
-# Loading data from repository:
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# 
-# With pandas we can do it directly from the web and with the right args
-# we can directly tidy the data in gempy style:
-# 
-
-# %% 
-dfs = []
-for letter in 'ABCD':
-    dfs.append(pn.read_csv('https://raw.githubusercontent.com/Loop3D/ImplicitBenchmark/master/Claudius/' +
-                           letter + 'Points.csv', sep=';',
-                           names=['X', 'Y', 'Z', 'surface', 'cutoff'], header=0)[::5])
-# Add fault:
-dfs.append(pn.read_csv('https://raw.githubusercontent.com/Loop3D/ImplicitBenchmark/master/Claudius/Fault.csv',
-                       names=['X', 'Y', 'Z', 'surface'], header=0, sep=';'))
-
-surface_points = pn.concat(dfs, sort=True)
-surface_points['surface'] =surface_points['surface'].astype('str')
-# surface_points['surface'] = surface_points['surface'].astype('str')
-surface_points.reset_index(inplace=True, drop=False)
-surface_points.tail()
-
-# %%
-surface_points.dtypes
-
-# %%
-# How many points are per surface
-# 
-
-# %% 
-surface_points.groupby('surface').count()
-
-# %%
-# Now we do the same with the orientations:
-# 
-
-# %% 
-dfs = []
-
-for surf in ['0', '330']:
-    o = pn.read_csv('https://raw.githubusercontent.com/Loop3D/ImplicitBenchmark/master/Claudius/Dips.csv', sep=';',
-                    names=['X', 'Y', 'Z', 'G_x', 'G_y', 'G_z', '-'], header=1)
-
-    # Orientation needs to belong to a surface. This is mainly to categorize to which series belong and to
-    # use the same color
-    o['surface'] = surf
-    dfs.append(o)
-orientations = pn.concat(dfs, sort=True)
-orientations.reset_index(inplace=True, drop=False)
-
-orientations.tail()
-
-# %%
-orientations.dtypes
-
-# %%
-# Data initialization:
-# ~~~~~~~~~~~~~~~~~~~~
-# 
-# Suggested size of the axis-aligned modeling box: Origin: 548800 7816600
-# -8400 Maximum: 552500 7822000 -11010
-# 
-# Suggested resolution: 100m x 100m x -90m (grid size 38 x 55 x 30)
-# 
-
-# %% 
-# Number of voxels:
-np.array([38, 55, 30]).prod()
-
-# %% 
-geo_model = gp.create_model('Claudius')
-# Importing the data from csv files and settign extent and resolution
-geo_model = gp.init_data(geo_model,
-                         extent=[548800, 552500, 7816600, 7822000, -11010, -8400], resolution=[38, 55, 30],
-                         surface_points_df=surface_points[::5], orientations_df=orientations, surface_name='surface',
-                         add_basement=True)
-
-# %%
-# We are going to increase the smoothness (nugget) of the data to increase
-# the conditional number of the matrix:
-# 
-
-# %% 
-geo_model.modify_surface_points(geo_model.surface_points.df.index, smooth=0.1).df.tail()
-
-# %%
-# Also the original poles are pointing downwards. We can change the
-# direction by calling the following:
-# 
-
-# %% 
-geo_model.modify_orientations(geo_model.orientations.df.index, polarity=-1).df.tail()
-
-# %%
-# We need an orientation per series/fault. The faults does not have
-# orientation so the easiest is to create an orientation from the surface
-# points availablle:
-# 
-
-# %% 
-fault_idx = geo_model.surface_points.df.index[geo_model.surface_points.df['surface'] == 'Claudius_fault']
-gp.set_orientation_from_surface_points(geo_model, fault_idx).df.tail()
-
-# %%
-# Now we can see how the data looks so far:
-# 
-
-# %%
-geo_model.surfaces
-
-# %% 
-gp.plot_2d(geo_model, direction='y')
-
-# %%
-# By default all surfaces belong to one unique series.
-# 
-
-# %% 
-geo_model.surfaces
-
-# %%
-# We will need to separate with surface belong to each series:
-# 
-
-# %% 
-stratigraphy = 'fixed'
-
-# %% 
-if stratigraphy == 'original':
-    gp.map_stack_to_surfaces(geo_model, {'Fault': 'Claudius_fault',
-                                         'Default series': ('0', '60', '250', '330'),
-                                         })
-    # Ordering the events from younger to older:
-    geo_model.reorder_series(['Fault', 'Default series', 'Basement'])
-
-
-elif stratigraphy == 'fixed':
-    gp.map_stack_to_surfaces(geo_model, {'Default series': ('0', '60', '250'),
-                                         'Fault': 'Claudius_fault',
-                                         'Uncomformity': '330',
-                                         })
-    # Ordering the events from younger to older:
-    geo_model.reorder_series(['Default series', 'Fault', 'Uncomformity', 'Basement'])
-
-# %%
-# So far we did not specify which series/faults are actula faults:
-# 
-
-# %% 
-geo_model.set_is_fault('Fault')
-
-# %%
-# Ordering the events from younger to older:
-# 
-
-# %% 
-# geo_model.reorder_series(['Default series', 'Fault', 'Uncomformity', 'Basement'])
-
-
-# %%
-# Check which series/faults are affected by other faults (rows offset
-# columns):
-# 
-
-# %% 
-geo_model.faults.faults_relations_df
-
-# %%
-# Now we are good to go:
-# 
-
-# %% 
-gp.set_interpolator(geo_model, theano_optimizer='fast_run',
-                    compile_theano=True)
-
-# %% 
-gp.compute_model(geo_model)
-
-# %% 
-sect = [35]
-
-gp.plot_2d(geo_model, cell_number=sect, series_n=1, show_scalar=True, direction='x')
-
-
-# %% 
-gp.plot_2d(geo_model, cell_number=sect, show_data=True, direction='x')
-
-# %% 
-gp.plot_2d(geo_model, cell_number=[28], series_n=0, direction='y', show_scalar=True)
-gp.plot_2d(geo_model, cell_number=[28], series_n=1, direction='y', show_scalar=True)
-gp.plot_2d(geo_model, cell_number=[28], series_n=2, direction='y', show_scalar=True)
-
-# %% 
-gp.plot_2d(geo_model, cell_number=[28], show_data=True, direction='y')
-
-# %%
-
-# sphinx_gallery_thumbnail_number = 8
-gp.plot_3d(geo_model)
-
-
-
-# %%
-# Export data:
-# ~~~~~~~~~~~~
-# 
-# The solution is stored in a numpy array of the following shape. Axis 0
-# are the scalar fields of each correspondent series/faults in the
-# following order (except basement):
-# 
-
-# %% 
-geo_model.series
-
-# %%
-# For the surfaces, there are two numpy arrays, one with vertices and the
-# other with triangles. Axis 0 is each surface in the order:
-# 
-
-# %% 
-geo_model.surfaces
-
-
-# %%
-# np.save('Claudius_scalar', geo_model.solutions.scalar_field_matrix)
-# np.save('Claudius_ver', geo_model.solutions.vertices)
-# np.save('Claudius_edges', geo_model.solutions.edges)
-# gp.plot.export_to_vtk(geo_model, 'Claudius')
-
-
-# %%
-# Timing:
-# -------
-# 
-# Fault
-# ~~~~~
-# 
-# Dense 20k input, 62k voxels
-# ^^^^^^^^^^^^^^^^^^^^^^^^^^^
-# 
-# -  CPU Memory 8 Gb 44.9 s ± 150 ms per loop (mean ± std. dev. of 7 runs,
-#    1 loop each)
-# -  GPU Memory 6.8 gb:
-# 
-#    -  2.13 s ± 3.39 ms per loop (mean ± std. dev. of 7 runs, 1 loop
-#       each) + steps **str** = [64.56394268] + steps **str** =
-#       [9927.69441126] + steps **str** = [196.15202667]
-# 
-#    -  1.13 s ± 2.08 ms per loop (mean ± std. dev. of 7 runs, 1 loop
-#       each)
-# 
-#       ::
-# 
-#          + steps __str__ = [645.63943742]
-#          + steps __str__ = [99276.94573919]
-#          + steps __str__ = [1961.52029888]
-# 
-
-
-# %%
-# Export to gocad
-# ---------------
-# 
-
-# %% 
-def write_property_to_gocad_voxet(propertyfilename, propertyvalues):
-    """
-    This function writes a numpy array into the right format for a gocad
-    voxet property file. This assumet there is a property already added to the .vo file,
-    and is just updating the file.
-    propertyfile - string giving the path to the file to write
-    propertyvalues - numpy array nz,ny,nx ordering and in float format
-    """
-    propertyvalues = propertyvalues.astype('>f4')  # big endian
-    #     array = propertyvalues.newbyteorder()
-    propertyvalues.tofile(propertyfilename)
-
-
-# %%
-write_property_to_gocad_voxet('claudius_sf_gempy',
-                              geo_model.solutions.scalar_field_matrix[1].reshape([38, 55, 30]).ravel('F'))
-
+"""
+Claudius
+~~~~~~~~
+
+"""
+
+# %%
+import sys, os
+os.environ["aesara_FLAGS"] = "mode=FAST_RUN,device=cpu"
+
+# Importing gempy
+import gempy as gp
+
+# Aux imports
+import numpy as np
+import pandas as pn
+
+# %%
+# Loading data from repository:
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# 
+# With pandas we can do it directly from the web and with the right args
+# we can directly tidy the data in gempy style:
+# 
+
+# %% 
+dfs = []
+for letter in 'ABCD':
+    dfs.append(pn.read_csv('https://raw.githubusercontent.com/Loop3D/ImplicitBenchmark/master/Claudius/' +
+                           letter + 'Points.csv', sep=';',
+                           names=['X', 'Y', 'Z', 'surface', 'cutoff'], header=0)[::5])
+# Add fault:
+dfs.append(pn.read_csv('https://raw.githubusercontent.com/Loop3D/ImplicitBenchmark/master/Claudius/Fault.csv',
+                       names=['X', 'Y', 'Z', 'surface'], header=0, sep=';'))
+
+surface_points = pn.concat(dfs, sort=True)
+surface_points['surface'] =surface_points['surface'].astype('str')
+# surface_points['surface'] = surface_points['surface'].astype('str')
+surface_points.reset_index(inplace=True, drop=False)
+surface_points.tail()
+
+# %%
+surface_points.dtypes
+
+# %%
+# How many points are per surface
+# 
+
+# %% 
+surface_points.groupby('surface').count()
+
+# %%
+# Now we do the same with the orientations:
+# 
+
+# %% 
+dfs = []
+
+for surf in ['0', '330']:
+    o = pn.read_csv('https://raw.githubusercontent.com/Loop3D/ImplicitBenchmark/master/Claudius/Dips.csv', sep=';',
+                    names=['X', 'Y', 'Z', 'G_x', 'G_y', 'G_z', '-'], header=1)
+
+    # Orientation needs to belong to a surface. This is mainly to categorize to which series belong and to
+    # use the same color
+    o['surface'] = surf
+    dfs.append(o)
+orientations = pn.concat(dfs, sort=True)
+orientations.reset_index(inplace=True, drop=False)
+
+orientations.tail()
+
+# %%
+orientations.dtypes
+
+# %%
+# Data initialization:
+# ~~~~~~~~~~~~~~~~~~~~
+# 
+# Suggested size of the axis-aligned modeling box: Origin: 548800 7816600
+# -8400 Maximum: 552500 7822000 -11010
+# 
+# Suggested resolution: 100m x 100m x -90m (grid size 38 x 55 x 30)
+# 
+
+# %% 
+# Number of voxels:
+np.array([38, 55, 30]).prod()
+
+# %% 
+geo_model = gp.create_model('Claudius')
+# Importing the data from csv files and settign extent and resolution
+geo_model = gp.init_data(geo_model,
+                         extent=[548800, 552500, 7816600, 7822000, -11010, -8400], resolution=[38, 55, 30],
+                         surface_points_df=surface_points[::5], orientations_df=orientations, surface_name='surface',
+                         add_basement=True)
+
+# %%
+# We are going to increase the smoothness (nugget) of the data to increase
+# the conditional number of the matrix:
+# 
+
+# %% 
+geo_model.modify_surface_points(geo_model.surface_points.df.index, smooth=0.1).df.tail()
+
+# %%
+# Also the original poles are pointing downwards. We can change the
+# direction by calling the following:
+# 
+
+# %% 
+geo_model.modify_orientations(geo_model.orientations.df.index, polarity=-1).df.tail()
+
+# %%
+# We need an orientation per series/fault. The faults does not have
+# orientation so the easiest is to create an orientation from the surface
+# points availablle:
+# 
+
+# %% 
+fault_idx = geo_model.surface_points.df.index[geo_model.surface_points.df['surface'] == 'Claudius_fault']
+gp.set_orientation_from_surface_points(geo_model, fault_idx).df.tail()
+
+# %%
+# Now we can see how the data looks so far:
+# 
+
+# %%
+geo_model.surfaces
+
+# %% 
+gp.plot_2d(geo_model, direction='y')
+
+# %%
+# By default all surfaces belong to one unique series.
+# 
+
+# %% 
+geo_model.surfaces
+
+# %%
+# We will need to separate with surface belong to each series:
+# 
+
+# %% 
+stratigraphy = 'fixed'
+
+# %% 
+if stratigraphy == 'original':
+    gp.map_stack_to_surfaces(geo_model, {'Fault': 'Claudius_fault',
+                                         'Default series': ('0', '60', '250', '330'),
+                                         })
+    # Ordering the events from younger to older:
+    geo_model.reorder_series(['Fault', 'Default series', 'Basement'])
+
+
+elif stratigraphy == 'fixed':
+    gp.map_stack_to_surfaces(geo_model, {'Default series': ('0', '60', '250'),
+                                         'Fault': 'Claudius_fault',
+                                         'Uncomformity': '330',
+                                         })
+    # Ordering the events from younger to older:
+    geo_model.reorder_series(['Default series', 'Fault', 'Uncomformity', 'Basement'])
+
+# %%
+# So far we did not specify which series/faults are actula faults:
+# 
+
+# %% 
+geo_model.set_is_fault('Fault')
+
+# %%
+# Ordering the events from younger to older:
+# 
+
+# %% 
+# geo_model.reorder_series(['Default series', 'Fault', 'Uncomformity', 'Basement'])
+
+
+# %%
+# Check which series/faults are affected by other faults (rows offset
+# columns):
+# 
+
+# %% 
+geo_model.faults.faults_relations_df
+
+# %%
+# Now we are good to go:
+# 
+
+# %% 
+gp.set_interpolator(geo_model, aesara_optimizer='fast_run',
+                    compile_aesara=True)
+
+# %% 
+gp.compute_model(geo_model)
+
+# %% 
+sect = [35]
+
+gp.plot_2d(geo_model, cell_number=sect, series_n=1, show_scalar=True, direction='x')
+
+
+# %% 
+gp.plot_2d(geo_model, cell_number=sect, show_data=True, direction='x')
+
+# %% 
+gp.plot_2d(geo_model, cell_number=[28], series_n=0, direction='y', show_scalar=True)
+gp.plot_2d(geo_model, cell_number=[28], series_n=1, direction='y', show_scalar=True)
+gp.plot_2d(geo_model, cell_number=[28], series_n=2, direction='y', show_scalar=True)
+
+# %% 
+gp.plot_2d(geo_model, cell_number=[28], show_data=True, direction='y')
+
+# %%
+
+# sphinx_gallery_thumbnail_number = 8
+gp.plot_3d(geo_model)
+
+
+
+# %%
+# Export data:
+# ~~~~~~~~~~~~
+# 
+# The solution is stored in a numpy array of the following shape. Axis 0
+# are the scalar fields of each correspondent series/faults in the
+# following order (except basement):
+# 
+
+# %% 
+geo_model.series
+
+# %%
+# For the surfaces, there are two numpy arrays, one with vertices and the
+# other with triangles. Axis 0 is each surface in the order:
+# 
+
+# %% 
+geo_model.surfaces
+
+
+# %%
+# np.save('Claudius_scalar', geo_model.solutions.scalar_field_matrix)
+# np.save('Claudius_ver', geo_model.solutions.vertices)
+# np.save('Claudius_edges', geo_model.solutions.edges)
+# gp.plot.export_to_vtk(geo_model, 'Claudius')
+
+
+# %%
+# Timing:
+# -------
+# 
+# Fault
+# ~~~~~
+# 
+# Dense 20k input, 62k voxels
+# ^^^^^^^^^^^^^^^^^^^^^^^^^^^
+# 
+# -  CPU Memory 8 Gb 44.9 s ± 150 ms per loop (mean ± std. dev. of 7 runs,
+#    1 loop each)
+# -  GPU Memory 6.8 gb:
+# 
+#    -  2.13 s ± 3.39 ms per loop (mean ± std. dev. of 7 runs, 1 loop
+#       each) + steps **str** = [64.56394268] + steps **str** =
+#       [9927.69441126] + steps **str** = [196.15202667]
+# 
+#    -  1.13 s ± 2.08 ms per loop (mean ± std. dev. of 7 runs, 1 loop
+#       each)
+# 
+#       ::
+# 
+#          + steps __str__ = [645.63943742]
+#          + steps __str__ = [99276.94573919]
+#          + steps __str__ = [1961.52029888]
+# 
+
+
+# %%
+# Export to gocad
+# ---------------
+# 
+
+# %% 
+def write_property_to_gocad_voxet(propertyfilename, propertyvalues):
+    """
+    This function writes a numpy array into the right format for a gocad
+    voxet property file. This assumet there is a property already added to the .vo file,
+    and is just updating the file.
+    propertyfile - string giving the path to the file to write
+    propertyvalues - numpy array nz,ny,nx ordering and in float format
+    """
+    propertyvalues = propertyvalues.astype('>f4')  # big endian
+    #     array = propertyvalues.newbyteorder()
+    propertyvalues.tofile(propertyfilename)
+
+
+# %%
+write_property_to_gocad_voxet('claudius_sf_gempy',
+                              geo_model.solutions.scalar_field_matrix[1].reshape([38, 55, 30]).ravel('F'))
+
 gp.save_model(geo_model)
```

### Comparing `gempy-2.2b10.dev1/examples/examples/real/Greenstone.py` & `gempy-2.3.0/examples/examples/real/Greenstone.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,77 +1,77 @@
-"""
-Greenstone.
-===========
-"""
-
-# Importing gempy
-import gempy as gp
-
-# Aux imports
-import numpy as np
-import matplotlib.pyplot as plt
-import os
-
-print(gp.__version__)
-
-# %% 
-geo_model = gp.create_model('Greenstone')
-
-# %%
-
-data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
-
-# Importing the data from csv files and settign extent and resolution
-geo_model = gp.init_data(geo_model, [696000, 747000, 6863000, 6930000, -20000, 200], [50, 50, 50],
-                         path_o=data_path + "/data/input_data/tut_SandStone/SandStone_Foliations.csv",
-                         path_i=data_path + "/data/input_data/tut_SandStone/SandStone_Points.csv")
-
-# %% 
-gp.plot_2d(geo_model, direction=['z'])
-
-# %% 
-gp.map_stack_to_surfaces(geo_model, {"EarlyGranite_Series": 'EarlyGranite',
-                                     "BIF_Series": ('SimpleMafic2', 'SimpleBIF'),
-                                     "SimpleMafic_Series": 'SimpleMafic1', 'Basement': 'basement'})
-
-# %% 
-geo_model.add_surface_values([2.61, 2.92, 3.1, 2.92, 2.61])
-
-# %% 
-gp.set_interpolator(geo_model,
-                    compile_theano=True,
-                    theano_optimizer='fast_compile',
-                    verbose=[])
-
-# %% 
-gp.compute_model(geo_model, set_solutions=True)
-
-# %% 
-gp.plot_2d(geo_model, cell_number=[-1], direction=['z'], show_data=False)
-
-# %% 
-gp.plot_2d(geo_model, cell_number=[25], direction='x')
-
-# %% 
-geo_model.solutions.values_matrix
-
-# %% 
-p2d = gp.plot_2d(geo_model, cell_number=[25], block=geo_model.solutions.values_matrix,
-           direction=['y'], show_data=True,
-           kwargs_regular_grid={'cmap': 'viridis', 'norm':None})
-
-# %%
-# sphinx_gallery_thumbnail_number = 5
-gp.plot_3d(geo_model)
-
-# %% 
-np.save('greenstone_ver', geo_model.solutions.vertices)
-np.save('greenstone_edges', geo_model.solutions.edges)
-
-# %%
-# Saving the model
-# ~~~~~~~~~~~~~~~~
-# 
-
-# %% 
-# gp.save_model(geo_model, path=os.pardir + '/data/gempy_models')
+"""
+Greenstone.
+===========
+"""
+
+# Importing gempy
+import gempy as gp
+
+# Aux imports
+import numpy as np
+import matplotlib.pyplot as plt
+import os
+
+print(gp.__version__)
+
+# %% 
+geo_model = gp.create_model('Greenstone')
+
+# %%
+
+data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
+
+# Importing the data from csv files and settign extent and resolution
+geo_model = gp.init_data(geo_model, [696000, 747000, 6863000, 6930000, -20000, 200], [50, 50, 50],
+                         path_o=data_path + "/data/input_data/tut_SandStone/SandStone_Foliations.csv",
+                         path_i=data_path + "/data/input_data/tut_SandStone/SandStone_Points.csv")
+
+# %% 
+gp.plot_2d(geo_model, direction=['z'])
+
+# %% 
+gp.map_stack_to_surfaces(geo_model, {"EarlyGranite_Series": 'EarlyGranite',
+                                     "BIF_Series": ('SimpleMafic2', 'SimpleBIF'),
+                                     "SimpleMafic_Series": 'SimpleMafic1', 'Basement': 'basement'})
+
+# %% 
+geo_model.add_surface_values([2.61, 2.92, 3.1, 2.92, 2.61])
+
+# %% 
+gp.set_interpolator(geo_model,
+                    compile_aesara=True,
+                    aesara_optimizer='fast_compile',
+                    verbose=[])
+
+# %% 
+gp.compute_model(geo_model, set_solutions=True)
+
+# %% 
+gp.plot_2d(geo_model, cell_number=[-1], direction=['z'], show_data=False)
+
+# %% 
+gp.plot_2d(geo_model, cell_number=[25], direction='x')
+
+# %% 
+geo_model.solutions.values_matrix
+
+# %% 
+p2d = gp.plot_2d(geo_model, cell_number=[25], block=geo_model.solutions.values_matrix,
+           direction=['y'], show_data=True,
+           kwargs_regular_grid={'cmap': 'viridis', 'norm':None})
+
+# %%
+# sphinx_gallery_thumbnail_number = 5
+gp.plot_3d(geo_model)
+
+# %% 
+np.save('greenstone_ver', geo_model.solutions.vertices)
+np.save('greenstone_edges', geo_model.solutions.edges)
+
+# %%
+# Saving the model
+# ~~~~~~~~~~~~~~~~
+# 
+
+# %% 
+# gp.save_model(geo_model, path=os.pardir + '/data/gempy_models')
 gp.save_model(geo_model)
```

### Comparing `gempy-2.2b10.dev1/examples/examples/real/Moureze.py` & `gempy-2.3.0/examples/examples/real/Moureze.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,195 +1,195 @@
-"""
-Moureze
-~~~~~~~
-
-"""
-
-# %% 
-# These two lines are necessary only if gempy is not installed
-import sys, os
-os.environ["THEANO_FLAGS"] = "mode=FAST_RUN,device=cpu"
-
-# Importing gempy
-import gempy as gp
-
-# Aux imports
-import numpy as np
-import pandas as pn
-import matplotlib.pyplot as plt
-
-
-# %%
-# Loading surface points from repository:
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# 
-# With pandas we can do it directly from the web and with the right args
-# we can directly tidy the data in gempy style:
-# 
-
-# %% 
-Moureze_points = pn.read_csv(
-    'https://raw.githubusercontent.com/Loop3D/ImplicitBenchmark/master/Moureze/Moureze_Points.csv', sep=';',
-    names=['X', 'Y', 'Z', 'G_x', 'G_y', 'G_z', '_'], header=0, )
-Sections_EW = pn.read_csv('https://raw.githubusercontent.com/Loop3D/ImplicitBenchmark/master/Moureze/Sections_EW.csv',
-                          sep=';',
-                          names=['X', 'Y', 'Z', 'ID', '_'], header=1).dropna()
-Sections_NS = pn.read_csv('https://raw.githubusercontent.com/Loop3D/ImplicitBenchmark/master/Moureze/Sections_NS.csv',
-                          sep=';',
-                          names=['X', 'Y', 'Z', 'ID', '_'], header=1).dropna()
-
-# %%
-# Extracting the orientatins:
-# 
-
-# %% 
-mask_surfpoints = Moureze_points['G_x'] < -9999
-surfpoints = Moureze_points[mask_surfpoints]
-orientations = Moureze_points[~mask_surfpoints]
-
-# %%
-# Giving an arbitrary value name to the surface
-# 
-
-# %% 
-surfpoints['surface'] = '0'
-orientations['surface'] = '0'
-
-# %% 
-surfpoints.tail()
-
-# %% 
-orientations.tail()
-
-# %%
-# Data initialization:
-# ~~~~~~~~~~~~~~~~~~~~
-# 
-# Suggested size of the axis-aligned modeling box:
-# 
-# Origin: -5 -5 -200
-# 
-# Maximum: 305 405 -50
-# 
-# Suggested resolution: 2m (grid size 156 x 206 x 76)
-# 
-
-
-# %%
-# Only using one orientation because otherwhise it gets a mess
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# 
-
-# %% 
-# Number voxels
-np.array([156, 206, 76]).prod()
-
-# %% 
-resolution_requ = [156, 206, 76]
-resolution = [77, 103, 38]
-resolution_low = [45, 51, 38]
-geo_model = gp.create_model('Moureze')
-geo_model = gp.init_data(geo_model,
-                         extent=[-5, 305, -5, 405, -200, -50], resolution=resolution_low,
-                         surface_points_df=surfpoints, orientations_df=orientations,
-                         surface_name='surface',
-                         add_basement=True)
-
-# %%
-# Now we can see how the data looks so far:
-# 
-
-# %% 
-gp.plot_2d(geo_model, direction='y')
-
-# %% 
-gp.set_interpolator(geo_model,
-                    theano_optimizer='fast_run', dtype='float64')
-
-# %%
-# The default range is always the diagonal of the extent. Since in this
-# model data is very close we will need to reduce the range to 5-10% of
-# that value:
-# 
-
-# %% 
-
-new_range = geo_model.get_additional_data().loc[('Kriging', 'range'), 'values'] * 0.2
-geo_model.modify_kriging_parameters('range', new_range)
-
-# %%
-gp.compute_model(geo_model, set_solutions=True, sort_surfaces=False)
-
-# %%
-# Time
-# ~~~~
-# 
-# 300k voxels 3.5k points
-# ^^^^^^^^^^^^^^^^^^^^^^^
-# 
-# -  Nvidia 2080: 500 ms ± 1.3 ms per loop (mean ± std. dev. of 7 runs, 1
-#    loop each), Memory 1 Gb
-# -  CPU 14.2 s ± 82.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop
-#    each), Memory: 1.3 Gb
-# 
-# 2.4 M voxels, 3.5k points
-# ^^^^^^^^^^^^^^^^^^^^^^^^^
-# 
-# -  CPU 2min 33s ± 216 ms per loop (mean ± std. dev. of 7 runs, 1 loop
-#    each) Memory: 1.3 GB
-# -  Nvidia 2080: 1.92 s ± 6.74 ms per loop (mean ± std. dev. of 7 runs, 1
-#    loop each) 1 Gb
-# 
-# 2.4 M voxels, 3.5k points 3.5 k orientations
-# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
-# 
-# -  Nvidia 2080: 2.53 s ± 1.31 ms per loop (mean ± std. dev. of 7 runs, 1
-#    loop each)
-# 
-
-# %% 
-
-gp.plot_2d(geo_model, cell_number=[16], series_n=0, show_scalar=True)
-# %% 
-gp.plot_2d(geo_model, cell_number=16, show_data=True, direction='y')
-
-# %%
-# sphinx_gallery_thumbnail_number = 4
-gp.plot_3d(geo_model)
-
-
-# %%
-# |image0|
-# 
-# .. |image0| image:: ./Moureze.png
-# 
-# 
-
-
-# %%
-# Export data:
-# ~~~~~~~~~~~~
-# 
-# The solution is stored in a numpy array of the following shape. Axis 0
-# are the scalar fields of each correspondent series/faults in the
-# following order (except basement):
-# 
-
-# %% 
-geo_model.series
-
-# %%
-# For the surfaces, there are two numpy arrays, one with vertices and the
-# other with triangles. Axis 0 is each surface in the order:
-# 
-
-# %% 
-geo_model.surfaces
-
-
-# %%
-# np.save('Moureze_scalar', geo_model.solutions.scalar_field_matrix)
-# np.save('Moureze_ver', geo_model.solutions.vertices)
-# np.save('Moureze_edges', geo_model.solutions.edges)
-# gp.plot.export_to_vtk(geo_model, 'Moureze')
-
+"""
+Moureze
+~~~~~~~
+
+"""
+
+# %% 
+# These two lines are necessary only if gempy is not installed
+import sys, os
+os.environ["aesara_FLAGS"] = "mode=FAST_RUN,device=cpu"
+
+# Importing gempy
+import gempy as gp
+
+# Aux imports
+import numpy as np
+import pandas as pn
+import matplotlib.pyplot as plt
+
+
+# %%
+# Loading surface points from repository:
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# 
+# With pandas we can do it directly from the web and with the right args
+# we can directly tidy the data in gempy style:
+# 
+
+# %% 
+Moureze_points = pn.read_csv(
+    'https://raw.githubusercontent.com/Loop3D/ImplicitBenchmark/master/Moureze/Moureze_Points.csv', sep=';',
+    names=['X', 'Y', 'Z', 'G_x', 'G_y', 'G_z', '_'], header=0, )
+Sections_EW = pn.read_csv('https://raw.githubusercontent.com/Loop3D/ImplicitBenchmark/master/Moureze/Sections_EW.csv',
+                          sep=';',
+                          names=['X', 'Y', 'Z', 'ID', '_'], header=1).dropna()
+Sections_NS = pn.read_csv('https://raw.githubusercontent.com/Loop3D/ImplicitBenchmark/master/Moureze/Sections_NS.csv',
+                          sep=';',
+                          names=['X', 'Y', 'Z', 'ID', '_'], header=1).dropna()
+
+# %%
+# Extracting the orientatins:
+# 
+
+# %% 
+mask_surfpoints = Moureze_points['G_x'] < -9999
+surfpoints = Moureze_points[mask_surfpoints]
+orientations = Moureze_points[~mask_surfpoints]
+
+# %%
+# Giving an arbitrary value name to the surface
+# 
+
+# %% 
+surfpoints['surface'] = '0'
+orientations['surface'] = '0'
+
+# %% 
+surfpoints.tail()
+
+# %% 
+orientations.tail()
+
+# %%
+# Data initialization:
+# ~~~~~~~~~~~~~~~~~~~~
+# 
+# Suggested size of the axis-aligned modeling box:
+# 
+# Origin: -5 -5 -200
+# 
+# Maximum: 305 405 -50
+# 
+# Suggested resolution: 2m (grid size 156 x 206 x 76)
+# 
+
+
+# %%
+# Only using one orientation because otherwhise it gets a mess
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# 
+
+# %% 
+# Number voxels
+np.array([156, 206, 76]).prod()
+
+# %% 
+resolution_requ = [156, 206, 76]
+resolution = [77, 103, 38]
+resolution_low = [45, 51, 38]
+geo_model = gp.create_model('Moureze')
+geo_model = gp.init_data(geo_model,
+                         extent=[-5, 305, -5, 405, -200, -50], resolution=resolution_low,
+                         surface_points_df=surfpoints, orientations_df=orientations,
+                         surface_name='surface',
+                         add_basement=True)
+
+# %%
+# Now we can see how the data looks so far:
+# 
+
+# %% 
+gp.plot_2d(geo_model, direction='y')
+
+# %% 
+gp.set_interpolator(geo_model,
+                    aesara_optimizer='fast_run', dtype='float64')
+
+# %%
+# The default range is always the diagonal of the extent. Since in this
+# model data is very close we will need to reduce the range to 5-10% of
+# that value:
+# 
+
+# %% 
+
+new_range = geo_model.get_additional_data().loc[('Kriging', 'range'), 'values'] * 0.2
+geo_model.modify_kriging_parameters('range', new_range)
+
+# %%
+gp.compute_model(geo_model, set_solutions=True, sort_surfaces=False)
+
+# %%
+# Time
+# ~~~~
+# 
+# 300k voxels 3.5k points
+# ^^^^^^^^^^^^^^^^^^^^^^^
+# 
+# -  Nvidia 2080: 500 ms ± 1.3 ms per loop (mean ± std. dev. of 7 runs, 1
+#    loop each), Memory 1 Gb
+# -  CPU 14.2 s ± 82.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop
+#    each), Memory: 1.3 Gb
+# 
+# 2.4 M voxels, 3.5k points
+# ^^^^^^^^^^^^^^^^^^^^^^^^^
+# 
+# -  CPU 2min 33s ± 216 ms per loop (mean ± std. dev. of 7 runs, 1 loop
+#    each) Memory: 1.3 GB
+# -  Nvidia 2080: 1.92 s ± 6.74 ms per loop (mean ± std. dev. of 7 runs, 1
+#    loop each) 1 Gb
+# 
+# 2.4 M voxels, 3.5k points 3.5 k orientations
+# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+# 
+# -  Nvidia 2080: 2.53 s ± 1.31 ms per loop (mean ± std. dev. of 7 runs, 1
+#    loop each)
+# 
+
+# %% 
+
+gp.plot_2d(geo_model, cell_number=[16], series_n=0, show_scalar=True)
+# %% 
+gp.plot_2d(geo_model, cell_number=16, show_data=True, direction='y')
+
+# %%
+# sphinx_gallery_thumbnail_number = 4
+gp.plot_3d(geo_model)
+
+
+# %%
+# |image0|
+# 
+# .. |image0| image:: ./Moureze.png
+# 
+# 
+
+
+# %%
+# Export data:
+# ~~~~~~~~~~~~
+# 
+# The solution is stored in a numpy array of the following shape. Axis 0
+# are the scalar fields of each correspondent series/faults in the
+# following order (except basement):
+# 
+
+# %% 
+geo_model.series
+
+# %%
+# For the surfaces, there are two numpy arrays, one with vertices and the
+# other with triangles. Axis 0 is each surface in the order:
+# 
+
+# %% 
+geo_model.surfaces
+
+
+# %%
+# np.save('Moureze_scalar', geo_model.solutions.scalar_field_matrix)
+# np.save('Moureze_ver', geo_model.solutions.vertices)
+# np.save('Moureze_edges', geo_model.solutions.edges)
+# gp.plot.export_to_vtk(geo_model, 'Moureze')
+
 gp.save_model(geo_model)
```

### Comparing `gempy-2.2b10.dev1/examples/examples/real/Perth_basin.py` & `gempy-2.3.0/examples/examples/real/Perth_basin.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,191 +1,191 @@
-"""
-Perth basin.
-============
-"""
-import os
-
-# Importing GemPy
-import gempy as gp
-
-# Importing auxiliary libraries
-import matplotlib
-matplotlib.rcParams['figure.figsize'] = (20.0, 10.0)
-os.environ["THEANO_FLAGS"] = "mode=FAST_RUN,device=cuda"
-
-# %%
-data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
-geo_model = gp.create_model('Perth_Basin')
-
-# %% 
-gp.init_data(geo_model,
-             extent=[337000, 400000, 6640000, 6710000, -18000, 1000],
-             resolution=[100, 100, 100],
-             path_i=data_path + "/data/input_data/Perth_basin/Paper_GU2F_sc_faults_topo_Points.csv",
-             path_o=data_path + "/data/input_data/Perth_basin/Paper_GU2F_sc_faults_topo_Foliations.csv")
-
-# %%
-geo_model.surfaces
-
-# %% 
-del_surfaces = ['Cadda', 'Woodada_Kockatea', 'Cattamarra']
-
-# %% 
-geo_model.delete_surfaces(del_surfaces, remove_data=True)
-
-# %% 
-# %debug
-
-# %% 
-geo_model.stack
-
-# %% 
-gp.map_stack_to_surfaces(geo_model,
-                          {"fault_Abrolhos_Transfer": ["Abrolhos_Transfer"],
-                           "fault_Coomallo": ["Coomallo"],
-                           "fault_Eneabba_South": ["Eneabba_South"],
-                           "fault_Hypo_fault_W": ["Hypo_fault_W"],
-                           "fault_Hypo_fault_E": ["Hypo_fault_E"],
-                           "fault_Urella_North": ["Urella_North"],
-                           "fault_Urella_South": ["Urella_South"],
-                           "fault_Darling": ["Darling"],
-                           "Sedimentary_Series": ['Cretaceous',
-                                                  'Yarragadee',
-                                                  'Eneabba',
-                                                  'Lesueur',
-                                                  'Permian']
-                           })
-
-# %%
-geo_model.series
-
-# %% 
-order_series = ["fault_Abrolhos_Transfer",
-                "fault_Coomallo",
-                "fault_Eneabba_South",
-                "fault_Hypo_fault_W",
-                "fault_Hypo_fault_E",
-                "fault_Urella_North",
-                "fault_Darling",
-                "fault_Urella_South",
-                "Sedimentary_Series", 'Basement']
-
-geo_model.reorder_series(order_series)
-
-# %%
-# Drop input data from the deleted series:
-# 
-
-# %% 
-geo_model.surface_points.df.dropna(inplace=True)
-geo_model.orientations.df.dropna(inplace=True)
-
-# %%
-# Select which series are faults
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# 
-
-# %% 
-geo_model.faults
-
-# %% 
-geo_model.set_is_fault(["fault_Abrolhos_Transfer",
-                        "fault_Coomallo",
-                        "fault_Eneabba_South",
-                        "fault_Hypo_fault_W",
-                        "fault_Hypo_fault_E",
-                        "fault_Urella_North",
-                        "fault_Darling",
-                        "fault_Urella_South"])
-
-# %%
-# Fault Network
-# -------------
-# 
-
-# %% 
-geo_model.faults.faults_relations_df
-
-# %% 
-fr = geo_model.faults.faults_relations_df.values
-
-# %% 
-fr[:, :-2] = False
-fr
-
-# %% 
-geo_model.set_fault_relation(fr)
-
-# %% 
-# %matplotlib inline
-gp.plot_2d(geo_model, direction=['z'])
-
-# %% 
-geo_model.set_topography(source='random')
-
-# %% 
-gp.plot_3d(geo_model)
-
-# %% 
-interp_data = gp.set_interpolator(geo_model,
-                                  compile_theano=True,
-                                  theano_optimizer='fast_run', gradient=False,
-                                  dtype='float32')
-
-# %% 
-gp.compute_model(geo_model)
-
-# %% 
-gp.plot_2d(geo_model, cell_number=[25])
-
-# %% 
-gp.plot_2d(geo_model, cell_number=[25], series_n=-1, show_scalar=True)
-
-# %% 
-gp.plot_2d(geo_model, cell_number=[12], direction=["y"], show_data=True, show_topography=True)
-
-# %%
-# sphinx_gallery_thumbnail_number = 6
-gp.plot_3d(geo_model, show_topography=True)
-
-# %%
-# Times
-# -----
-# 
-# Fast run
-# ^^^^^^^^
-# 
-# -  1M voxels:
-# 
-#    -  CPU: intel® Core™ i7-7700HQ CPU @ 2.80GHz × 8 15 s ± 1.02 s per
-#       loop (mean ± std. dev. of 7 runs, 1 loop each)
-#    -  GPU (4gb) not enough memmory
-#    -  Ceres 1M voxels 2080 851 ms
-# 
-# -  250k voxels
-# 
-#    -  GPU 1050Ti: 3.11 s ± 11.8 ms per loop (mean ± std. dev. of 7 runs,
-#       1 loop each)
-#    -  CPU: intel® Core™ i7-7700HQ CPU @ 2.80GHz × 8 2.27 s ± 47.3 ms
-#    -  
-# 
-# Fast Compile
-# ^^^^^^^^^^^^
-# 
-# -  250k voxels
-# 
-#    -  GPU 1050Ti: 3.7 s ± 11.8 ms per loop (mean ± std. dev. of 7 runs,
-#       1 loop each)
-#    -  CPU: intel® Core™ i7-7700HQ CPU @ 2.80GHz × 8 14.2 s ± 51.1 ms per
-#       loop (mean ± std. dev. of 7 runs, 1 loop each)
-# 
-
-# %% 
-# %%timeit
-# gp.compute_model(geo_model)
-
-# %% 
-# ver = np.load('ver.npy')
-# sim = np.load('sim.npy')
-# lith_block = np.load('lith.npy')
-
-gp.save_model(geo_model)
+"""
+Perth basin.
+============
+"""
+import os
+
+# Importing GemPy
+import gempy as gp
+
+# Importing auxiliary libraries
+import matplotlib
+matplotlib.rcParams['figure.figsize'] = (20.0, 10.0)
+os.environ["aesara_FLAGS"] = "mode=FAST_RUN,device=cuda"
+
+# %%
+data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
+geo_model = gp.create_model('Perth_Basin')
+
+# %% 
+gp.init_data(geo_model,
+             extent=[337000, 400000, 6640000, 6710000, -18000, 1000],
+             resolution=[100, 100, 100],
+             path_i=data_path + "/data/input_data/Perth_basin/Paper_GU2F_sc_faults_topo_Points.csv",
+             path_o=data_path + "/data/input_data/Perth_basin/Paper_GU2F_sc_faults_topo_Foliations.csv")
+
+# %%
+geo_model.surfaces
+
+# %% 
+del_surfaces = ['Cadda', 'Woodada_Kockatea', 'Cattamarra']
+
+# %% 
+geo_model.delete_surfaces(del_surfaces, remove_data=True)
+
+# %% 
+# %debug
+
+# %% 
+geo_model.stack
+
+# %% 
+gp.map_stack_to_surfaces(geo_model,
+                          {"fault_Abrolhos_Transfer": ["Abrolhos_Transfer"],
+                           "fault_Coomallo": ["Coomallo"],
+                           "fault_Eneabba_South": ["Eneabba_South"],
+                           "fault_Hypo_fault_W": ["Hypo_fault_W"],
+                           "fault_Hypo_fault_E": ["Hypo_fault_E"],
+                           "fault_Urella_North": ["Urella_North"],
+                           "fault_Urella_South": ["Urella_South"],
+                           "fault_Darling": ["Darling"],
+                           "Sedimentary_Series": ['Cretaceous',
+                                                  'Yarragadee',
+                                                  'Eneabba',
+                                                  'Lesueur',
+                                                  'Permian']
+                           })
+
+# %%
+geo_model.series
+
+# %% 
+order_series = ["fault_Abrolhos_Transfer",
+                "fault_Coomallo",
+                "fault_Eneabba_South",
+                "fault_Hypo_fault_W",
+                "fault_Hypo_fault_E",
+                "fault_Urella_North",
+                "fault_Darling",
+                "fault_Urella_South",
+                "Sedimentary_Series", 'Basement']
+
+geo_model.reorder_series(order_series)
+
+# %%
+# Drop input data from the deleted series:
+# 
+
+# %% 
+geo_model.surface_points.df.dropna(inplace=True)
+geo_model.orientations.df.dropna(inplace=True)
+
+# %%
+# Select which series are faults
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# 
+
+# %% 
+geo_model.faults
+
+# %% 
+geo_model.set_is_fault(["fault_Abrolhos_Transfer",
+                        "fault_Coomallo",
+                        "fault_Eneabba_South",
+                        "fault_Hypo_fault_W",
+                        "fault_Hypo_fault_E",
+                        "fault_Urella_North",
+                        "fault_Darling",
+                        "fault_Urella_South"])
+
+# %%
+# Fault Network
+# -------------
+# 
+
+# %% 
+geo_model.faults.faults_relations_df
+
+# %% 
+fr = geo_model.faults.faults_relations_df.values
+
+# %% 
+fr[:, :-2] = False
+fr
+
+# %% 
+geo_model.set_fault_relation(fr)
+
+# %% 
+# %matplotlib inline
+gp.plot_2d(geo_model, direction=['z'])
+
+# %% 
+geo_model.set_topography(source='random')
+
+# %% 
+gp.plot_3d(geo_model)
+
+# %% 
+interp_data = gp.set_interpolator(geo_model,
+                                  compile_aesara=True,
+                                  aesara_optimizer='fast_run', gradient=False,
+                                  dtype='float32')
+
+# %% 
+gp.compute_model(geo_model)
+
+# %% 
+gp.plot_2d(geo_model, cell_number=[25])
+
+# %% 
+gp.plot_2d(geo_model, cell_number=[25], series_n=-1, show_scalar=True)
+
+# %% 
+gp.plot_2d(geo_model, cell_number=[12], direction=["y"], show_data=True, show_topography=True)
+
+# %%
+# sphinx_gallery_thumbnail_number = 6
+gp.plot_3d(geo_model, show_topography=True)
+
+# %%
+# Times
+# -----
+# 
+# Fast run
+# ^^^^^^^^
+# 
+# -  1M voxels:
+# 
+#    -  CPU: intel® Core™ i7-7700HQ CPU @ 2.80GHz × 8 15 s ± 1.02 s per
+#       loop (mean ± std. dev. of 7 runs, 1 loop each)
+#    -  GPU (4gb) not enough memmory
+#    -  Ceres 1M voxels 2080 851 ms
+# 
+# -  250k voxels
+# 
+#    -  GPU 1050Ti: 3.11 s ± 11.8 ms per loop (mean ± std. dev. of 7 runs,
+#       1 loop each)
+#    -  CPU: intel® Core™ i7-7700HQ CPU @ 2.80GHz × 8 2.27 s ± 47.3 ms
+#    -  
+# 
+# Fast Compile
+# ^^^^^^^^^^^^
+# 
+# -  250k voxels
+# 
+#    -  GPU 1050Ti: 3.7 s ± 11.8 ms per loop (mean ± std. dev. of 7 runs,
+#       1 loop each)
+#    -  CPU: intel® Core™ i7-7700HQ CPU @ 2.80GHz × 8 14.2 s ± 51.1 ms per
+#       loop (mean ± std. dev. of 7 runs, 1 loop each)
+# 
+
+# %% 
+# %%timeit
+# gp.compute_model(geo_model)
+
+# %% 
+# ver = np.load('ver.npy')
+# sim = np.load('sim.npy')
+# lith_block = np.load('lith.npy')
+
+gp.save_model(geo_model)
```

### Comparing `gempy-2.2b10.dev1/examples/getting_started/get_started.py` & `gempy-2.3.0/examples/getting_started/get_started.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,402 +1,402 @@
-"""
-Getting Started
-===============
-
-"""
-
-# %%
-
-# Importing GemPy
-import gempy as gp
-
-# Importing aux libraries
-import numpy as np
-import matplotlib.pyplot as plt
-import matplotlib.image as mpimg
-
-# %%
-# Initializing the model:
-# ~~~~~~~~~~~~~~~~~~~~~~~
-# 
-# The first step to create a GemPy model is create a gempy.Model object
-# that will contain all the other data structures and necessary
-# functionality.
-# 
-# In addition for this example we will define a regular grid since the
-# beginning. This is the grid where we will interpolate the 3D geological
-# model. GemPy comes with an array of different grids for different
-# pourposes as we will see below. For visualization usually a regular grid
-# is the one that makes more sense.
-# 
-
-# %% 
-geo_model = gp.create_model('Model1')
-geo_model = gp.init_data(geo_model, extent=[0, 791, 0, 200, -582, 0], resolution=[100, 10, 100])
-
-# %%
-# GemPy core code is written in Python. However for efficiency (and other
-# reasons) most of heavy computations happend in optimize compile code,
-# either C or CUDA for GPU. To do so, GemPy rely on the library theano. To
-# guarantee maximum optimization theano requires to compile the code for
-# every Python kernel. The compilation is done by calling the following
-# line at any point (before computing the model):
-# 
-
-# %% 
-gp.set_interpolator(geo_model, theano_optimizer='fast_compile', verbose=[])
-
-# %%
-# Creating figure:
-# ~~~~~~~~~~~~~~~~
-# 
-# GemPy uses matplotlib and pyvista-vtk libraries for 2d and 3d
-# visualization of the model respectively. One of the design decisions of
-# GemPy is to allow real time construction of the model. What this means
-# is that you can start adding input data and see in real time how the 3D
-# surfaces evolve. Lets initialize the visualization windows.
-# 
-# The first one is the 2d figure. Just place the window where you can see
-# it (maybe move the jupyter notebook to half screen and use the other
-# half for the renderers).
-# 
-
-# %% 
-# %matplotlib qt5
-p2d = gp.plot_2d(geo_model)
-
-# %%
-# Add model section
-# ^^^^^^^^^^^^^^^^^
-# 
-# In the 2d renderer we can add several cross section of the model. In
-# this case, for simplicity sake we are just adding one perpendicular to
-# y.
-# 
-
-
-# %%
-# Loading cross-section image:
-# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
-# 
-# Remember that gempy is simply using matplotlib and therofe the ax object
-# created above is a standard matplotlib axes. This allow to manipulate it
-# freely. Lets load an image with the information of couple of boreholes
-# 
-
-# %% 
-# Reading image
-img = mpimg.imread('wells.png')
-# Plotting it inplace
-p2d = gp.plot_2d(geo_model, show=False)
-p2d.axes[0].imshow(img, origin='upper', alpha=.8, extent=(0, 791, -582, 0))
-plt.show()
-
-# %%
-# We can do the same in 3D through pyvista and vtk rendering:
-# 
-
-# %% 
-p3d = gp.plot_3d(geo_model)
-
-# %%
-# Building the model
-# ------------------
-# 
-# Now that we have everything initialize we can start the construction of
-# the geological model.
-# 
-# Surfaces
-# ~~~~~~~~
-# 
-# GemPy is a surface based interpolator. This means that all the input
-# data we add has to be refered to a surface. The surfaces always mark the
-# bottom of a unit. By default GemPy surfaces are empty:
-# 
-
-# %% 
-geo_model.surfaces
-
-# %%
-# If we do not care about the names and we just want to interpolate a
-# surface we can use:
-# 
-
-# %% 
-# Default surfaces:
-geo_model.set_default_surfaces()
-
-# %%
-# Now we can start adding data. GemPy input data consist on surface points
-# and orientations (perpendicular to the layers). The 2D plot gives you
-# the X and Z coordinates when hovering the mouse over. We can add a
-# surface point as follows:
-# 
-
-# %% 
-# Add a point
-geo_model.add_surface_points(X=223, Y=0.01, Z=-94, surface='surface1')
-
-# Plot in 2D
-gp.plot_2d(geo_model, cell_number=11)
-
-# Plot in 3D
-gp.plot_3d(geo_model)
-
-# %%
-# Now we can add the other two points of the layer:
-# 
-
-# %% 
-# Add points
-geo_model.add_surface_points(X=458, Y=0, Z=-107, surface='surface1')
-geo_model.add_surface_points(X=612, Y=0, Z=-14, surface='surface1')
-
-# Plotting
-gp.plot_2d(geo_model, cell_number=11)
-gp.plot_3d(geo_model)
-
-# %%
-# The minimum amount of data to interpolate anything in gempy is: a) 2
-# surface points per surface b) One orientation per series.
-# 
-# Lets add an orientation anywhere in space:
-# 
-
-# %% 
-# Adding orientation
-geo_model.add_orientations(X=350, Y=0, Z=-300, surface='surface1', pole_vector=(0, 0, 1))
-gp.plot_2d(geo_model, cell_number=5)
-gp.plot_3d(geo_model)
-
-# %%
-# Now we have enough data for finally interpolate!
-# 
-
-# %% 
-gp.compute_model(geo_model)
-
-# %% 
-geo_model.additional_data.kriging_data
-
-# %% 
-geo_model.additional_data.rescaling_data
-
-# %%
-# That is, we have interpolated the 3D surface. We can visualize:
-# 
-
-# %% 
-# In 2D
-gp.plot_2d(geo_model, cell_number=[5])
-
-# In 3D
-gp.plot_3d(geo_model, show_surfaces=True)
-
-# %%
-# Adding more layers:
-# ~~~~~~~~~~~~~~~~~~~
-# 
-# So far we only need 2 units defined. The cross-section image that we
-# load have 4 however. Lets add two layers more:
-# 
-
-# %% 
-geo_model.surfaces
-
-# %% 
-geo_model.series
-
-# %% 
-geo_model.add_surfaces(['surface3', 'basement'])
-
-# %%
-# Layer 2
-# ~~~~~~~
-# 
-# Add the layer next layers:
-# 
-
-# %% 
-# Your code here:
-geo_model.add_surface_points(X=225, Y=0, Z=-269, surface='surface2')
-geo_model.add_surface_points(X=459, Y=0, Z=-279, surface='surface2')
-
-# --------------------
-
-# %% 
-# Compute model
-gp.compute_model(geo_model)
-
-# %% 
-gp.plot_2d(geo_model, cell_number=5, legend='force')
-gp.plot_3d(geo_model)
-
-# %%
-# Layer 3
-# ~~~~~~~
-# 
-
-# %% 
-# Your code here:
-geo_model.add_surface_points(X=225, Y=0, Z=-439, surface='surface3')
-geo_model.add_surface_points(X=464, Y=0, Z=-456, surface='surface3')
-geo_model.add_surface_points(X=619, Y=0, Z=-433, surface='surface3')
-
-# ------------------
-
-# %% 
-# Computing and plotting 3D
-gp.compute_model(geo_model)
-
-gp.plot_2d(geo_model, cell_number=5, legend='force')
-gp.plot_3d(geo_model, kwargs_plot_structured_grid={'opacity': .2})
-
-# %%
-# Adding a Fault
-# --------------
-# 
-# So far the model is simply a depositional unit. GemPy allows for
-# unconformities and faults to build complex models. This input is given
-# by categorical data. In general:
-# 
-# input data (surface points/ orientations) <belong to< surface <belong
-# to< series
-# 
-# And series can be a fault—i.e. offset the rest of surface— or not. We
-# are going to show how to add a fault as an example.
-# 
-# First we need to add a series:
-# 
-
-# %% 
-geo_model.add_features('Fault1')
-
-# %% 
-geo_model.reorder_features(['Fault1', 'Default series'])
-
-# %%
-# Then define that is a fault:
-# 
-
-# %% 
-geo_model.set_is_fault('Fault1')
-
-# %%
-# But we also need to add a new surface:
-# 
-
-# %% 
-geo_model.add_surfaces('fault1')
-
-# %%
-# And finally assign the new surface to the new series/fault
-# 
-
-# %% 
-gp.map_stack_to_surfaces(geo_model, {'Fault1': 'fault1'})
-
-# %%
-# Now we can just add input data as before (remember the minimum amount of
-# input data to compute a model):
-# 
-
-# %% 
-# Add input data of the fault
-geo_model.add_surface_points(X=550, Y=0, Z=-30, surface='fault1')
-geo_model.add_surface_points(X=650, Y=0, Z=-200, surface='fault1')
-geo_model.add_orientations(X=600, Y=0, Z=-100, surface='fault1', pole_vector=(.3, 0, .3))
-
-# Plotting Inpute data
-gp.plot_2d(geo_model, show_solutions=False)
-
-# %%
-# And now is computing as before:
-# 
-
-# %% 
-# Compute
-gp.compute_model(geo_model)
-
-# Plot
-gp.plot_2d(geo_model, cell_number=5, legend='force')
-gp.plot_3d(geo_model, kwargs_plot_structured_grid={'opacity': .2})
-
-# %%
-# As you can see now instead of having folding layers we have a sharp
-# jump. Building on this you can pretty much any model you can imagine.
-# 
-
-
-# %%
-# Additional features:
-# ====================
-# 
-# Over the years we have built a bunch of assets integrate with gempy.
-# Here we will show some of them:
-# 
-# Topography
-# ----------
-# 
-# GemPy has a built-in capabilities to read and manipulate topographic
-# data (through gdal). To show an example we can just create a random
-# topography:
-# 
-
-# %% 
-# Adding random topography
-geo_model.set_topography(source='random', fd=1.9, d_z=np.array([-150, 0]),
-                         resolution=np.array([200, 200]))
-
-# %%
-# The topography can we visualize in both renderers:
-# 
-
-# %% 
-gp.plot_2d(geo_model, cell_number=5, legend='force')
-gp.plot_3d(geo_model, kwargs_plot_structured_grid={'opacity':.2})
-
-# %%
-# But also allows us to compute the geological map of an area:
-# 
-
-# %% 
-gp.compute_model(geo_model)
-
-# sphinx_gallery_thumbnail_number = 16
-gp.plot_3d(geo_model, show_topography=True)
-
-# %%
-# Gravity inversion
-# -----------------
-# 
-# GemPy also allows for inversions (in production only gravity so far). We
-# can see a small demo how this works.
-# 
-# The first thing to do is to assign densities to each of the units:
-# 
-
-# %% 
-geo_model.add_surface_values([0, 2.6, 2.4, 3.2, 3.6], ['density'])
-
-# %%
-# Also we can create a centered grid around a device for precision:
-# 
-
-# %% 
-geo_model.set_centered_grid(centers=[[400, 0, 0]], resolution=[10, 10, 100], radius=800)
-
-# %%
-# We need to modify the compile code:
-# 
-
-# %% 
-gp.set_interpolator(geo_model, output=['gravity'], theano_optimizer='fast_run')
-
-# %%
-# But now additionally to the interpolation we also compute the forward
-# gravity of the model (at the point XYZ = 400, 0, 0)
-# 
-
-# %% 
-gp.compute_model(geo_model)
-geo_model.solutions.fw_gravity
+"""
+Getting Started
+===============
+
+"""
+
+# %%
+
+# Importing GemPy
+import gempy as gp
+
+# Importing aux libraries
+import numpy as np
+import matplotlib.pyplot as plt
+import matplotlib.image as mpimg
+
+# %%
+# Initializing the model:
+# ~~~~~~~~~~~~~~~~~~~~~~~
+# 
+# The first step to create a GemPy model is create a gempy.Model object
+# that will contain all the other data structures and necessary
+# functionality.
+# 
+# In addition for this example we will define a regular grid since the
+# beginning. This is the grid where we will interpolate the 3D geological
+# model. GemPy comes with an array of different grids for different
+# pourposes as we will see below. For visualization usually a regular grid
+# is the one that makes more sense.
+# 
+
+# %% 
+geo_model = gp.create_model('Model1')
+geo_model = gp.init_data(geo_model, extent=[0, 791, 0, 200, -582, 0], resolution=[100, 10, 100])
+
+# %%
+# GemPy core code is written in Python. However for efficiency (and other
+# reasons) most of heavy computations happend in optimize compile code,
+# either C or CUDA for GPU. To do so, GemPy rely on the library aesara. To
+# guarantee maximum optimization aesara requires to compile the code for
+# every Python kernel. The compilation is done by calling the following
+# line at any point (before computing the model):
+# 
+
+# %% 
+gp.set_interpolator(geo_model, aesara_optimizer='fast_compile', verbose=[])
+
+# %%
+# Creating figure:
+# ~~~~~~~~~~~~~~~~
+# 
+# GemPy uses matplotlib and pyvista-vtk libraries for 2d and 3d
+# visualization of the model respectively. One of the design decisions of
+# GemPy is to allow real time construction of the model. What this means
+# is that you can start adding input data and see in real time how the 3D
+# surfaces evolve. Lets initialize the visualization windows.
+# 
+# The first one is the 2d figure. Just place the window where you can see
+# it (maybe move the jupyter notebook to half screen and use the other
+# half for the renderers).
+# 
+
+# %% 
+# %matplotlib qt5
+p2d = gp.plot_2d(geo_model)
+
+# %%
+# Add model section
+# ^^^^^^^^^^^^^^^^^
+# 
+# In the 2d renderer we can add several cross section of the model. In
+# this case, for simplicity sake we are just adding one perpendicular to
+# y.
+# 
+
+
+# %%
+# Loading cross-section image:
+# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+# 
+# Remember that gempy is simply using matplotlib and therofe the ax object
+# created above is a standard matplotlib axes. This allow to manipulate it
+# freely. Lets load an image with the information of couple of boreholes
+# 
+
+# %% 
+# Reading image
+img = mpimg.imread('wells.png')
+# Plotting it inplace
+p2d = gp.plot_2d(geo_model, show=False)
+p2d.axes[0].imshow(img, origin='upper', alpha=.8, extent=(0, 791, -582, 0))
+plt.show()
+
+# %%
+# We can do the same in 3D through pyvista and vtk rendering:
+# 
+
+# %% 
+p3d = gp.plot_3d(geo_model)
+
+# %%
+# Building the model
+# ------------------
+# 
+# Now that we have everything initialize we can start the construction of
+# the geological model.
+# 
+# Surfaces
+# ~~~~~~~~
+# 
+# GemPy is a surface based interpolator. This means that all the input
+# data we add has to be refered to a surface. The surfaces always mark the
+# bottom of a unit. By default GemPy surfaces are empty:
+# 
+
+# %% 
+geo_model.surfaces
+
+# %%
+# If we do not care about the names and we just want to interpolate a
+# surface we can use:
+# 
+
+# %% 
+# Default surfaces:
+geo_model.set_default_surfaces()
+
+# %%
+# Now we can start adding data. GemPy input data consist on surface points
+# and orientations (perpendicular to the layers). The 2D plot gives you
+# the X and Z coordinates when hovering the mouse over. We can add a
+# surface point as follows:
+# 
+
+# %% 
+# Add a point
+geo_model.add_surface_points(X=223, Y=0.01, Z=-94, surface='surface1')
+
+# Plot in 2D
+gp.plot_2d(geo_model, cell_number=11)
+
+# Plot in 3D
+gp.plot_3d(geo_model)
+
+# %%
+# Now we can add the other two points of the layer:
+# 
+
+# %% 
+# Add points
+geo_model.add_surface_points(X=458, Y=0, Z=-107, surface='surface1')
+geo_model.add_surface_points(X=612, Y=0, Z=-14, surface='surface1')
+
+# Plotting
+gp.plot_2d(geo_model, cell_number=11)
+gp.plot_3d(geo_model)
+
+# %%
+# The minimum amount of data to interpolate anything in gempy is: a) 2
+# surface points per surface b) One orientation per series.
+# 
+# Lets add an orientation anywhere in space:
+# 
+
+# %% 
+# Adding orientation
+geo_model.add_orientations(X=350, Y=0, Z=-300, surface='surface1', pole_vector=(0, 0, 1))
+gp.plot_2d(geo_model, cell_number=5)
+gp.plot_3d(geo_model)
+
+# %%
+# Now we have enough data for finally interpolate!
+# 
+
+# %% 
+gp.compute_model(geo_model)
+
+# %% 
+geo_model.additional_data.kriging_data
+
+# %% 
+geo_model.additional_data.rescaling_data
+
+# %%
+# That is, we have interpolated the 3D surface. We can visualize:
+# 
+
+# %% 
+# In 2D
+gp.plot_2d(geo_model, cell_number=[5])
+
+# In 3D
+gp.plot_3d(geo_model, show_surfaces=True)
+
+# %%
+# Adding more layers:
+# ~~~~~~~~~~~~~~~~~~~
+# 
+# So far we only need 2 units defined. The cross-section image that we
+# load have 4 however. Lets add two layers more:
+# 
+
+# %% 
+geo_model.surfaces
+
+# %% 
+geo_model.series
+
+# %% 
+geo_model.add_surfaces(['surface3', 'basement'])
+
+# %%
+# Layer 2
+# ~~~~~~~
+# 
+# Add the layer next layers:
+# 
+
+# %% 
+# Your code here:
+geo_model.add_surface_points(X=225, Y=0, Z=-269, surface='surface2')
+geo_model.add_surface_points(X=459, Y=0, Z=-279, surface='surface2')
+
+# --------------------
+
+# %% 
+# Compute model
+gp.compute_model(geo_model)
+
+# %% 
+gp.plot_2d(geo_model, cell_number=5, legend='force')
+gp.plot_3d(geo_model)
+
+# %%
+# Layer 3
+# ~~~~~~~
+# 
+
+# %% 
+# Your code here:
+geo_model.add_surface_points(X=225, Y=0, Z=-439, surface='surface3')
+geo_model.add_surface_points(X=464, Y=0, Z=-456, surface='surface3')
+geo_model.add_surface_points(X=619, Y=0, Z=-433, surface='surface3')
+
+# ------------------
+
+# %% 
+# Computing and plotting 3D
+gp.compute_model(geo_model)
+
+gp.plot_2d(geo_model, cell_number=5, legend='force')
+gp.plot_3d(geo_model, kwargs_plot_structured_grid={'opacity': .2})
+
+# %%
+# Adding a Fault
+# --------------
+# 
+# So far the model is simply a depositional unit. GemPy allows for
+# unconformities and faults to build complex models. This input is given
+# by categorical data. In general:
+# 
+# input data (surface points/ orientations) <belong to< surface <belong
+# to< series
+# 
+# And series can be a fault—i.e. offset the rest of surface— or not. We
+# are going to show how to add a fault as an example.
+# 
+# First we need to add a series:
+# 
+
+# %% 
+geo_model.add_features('Fault1')
+
+# %% 
+geo_model.reorder_features(['Fault1', 'Default series'])
+
+# %%
+# Then define that is a fault:
+# 
+
+# %% 
+geo_model.set_is_fault('Fault1')
+
+# %%
+# But we also need to add a new surface:
+# 
+
+# %% 
+geo_model.add_surfaces('fault1')
+
+# %%
+# And finally assign the new surface to the new series/fault
+# 
+
+# %% 
+gp.map_stack_to_surfaces(geo_model, {'Fault1': 'fault1'})
+
+# %%
+# Now we can just add input data as before (remember the minimum amount of
+# input data to compute a model):
+# 
+
+# %% 
+# Add input data of the fault
+geo_model.add_surface_points(X=550, Y=0, Z=-30, surface='fault1')
+geo_model.add_surface_points(X=650, Y=0, Z=-200, surface='fault1')
+geo_model.add_orientations(X=600, Y=0, Z=-100, surface='fault1', pole_vector=(.3, 0, .3))
+
+# Plotting Inpute data
+gp.plot_2d(geo_model, show_solutions=False)
+
+# %%
+# And now is computing as before:
+# 
+
+# %% 
+# Compute
+gp.compute_model(geo_model)
+
+# Plot
+gp.plot_2d(geo_model, cell_number=5, legend='force')
+gp.plot_3d(geo_model, kwargs_plot_structured_grid={'opacity': .2})
+
+# %%
+# As you can see now instead of having folding layers we have a sharp
+# jump. Building on this you can pretty much any model you can imagine.
+# 
+
+
+# %%
+# Additional features:
+# ====================
+# 
+# Over the years we have built a bunch of assets integrate with gempy.
+# Here we will show some of them:
+# 
+# Topography
+# ----------
+# 
+# GemPy has a built-in capabilities to read and manipulate topographic
+# data (through gdal). To show an example we can just create a random
+# topography:
+# 
+
+# %% 
+# Adding random topography
+geo_model.set_topography(source='random', fd=1.9, d_z=np.array([-150, 0]),
+                         resolution=np.array([200, 200]))
+
+# %%
+# The topography can we visualize in both renderers:
+# 
+
+# %% 
+gp.plot_2d(geo_model, cell_number=5, legend='force')
+gp.plot_3d(geo_model, kwargs_plot_structured_grid={'opacity':.2})
+
+# %%
+# But also allows us to compute the geological map of an area:
+# 
+
+# %% 
+gp.compute_model(geo_model)
+
+# sphinx_gallery_thumbnail_number = 16
+gp.plot_3d(geo_model, show_topography=True)
+
+# %%
+# Gravity inversion
+# -----------------
+# 
+# GemPy also allows for inversions (in production only gravity so far). We
+# can see a small demo how this works.
+# 
+# The first thing to do is to assign densities to each of the units:
+# 
+
+# %% 
+geo_model.add_surface_values([0, 2.6, 2.4, 3.2, 3.6], ['density'])
+
+# %%
+# Also we can create a centered grid around a device for precision:
+# 
+
+# %% 
+geo_model.set_centered_grid(centers=[[400, 0, 0]], resolution=[10, 10, 100], radius=800)
+
+# %%
+# We need to modify the compile code:
+# 
+
+# %% 
+gp.set_interpolator(geo_model, output=['gravity'], aesara_optimizer='fast_run')
+
+# %%
+# But now additionally to the interpolation we also compute the forward
+# gravity of the model (at the point XYZ = 400, 0, 0)
+# 
+
+# %% 
+gp.compute_model(geo_model)
+geo_model.solutions.fw_gravity
```

### Comparing `gempy-2.2b10.dev1/examples/integrations/gempy_striplog.py` & `gempy-2.3.0/examples/integrations/gempy_striplog.py`

 * *Ordering differences only*

 * *Files 27% similar despite different names*

```diff
@@ -1,244 +1,244 @@
-"""
-Transform 2019: Integrating Striplog and GemPy
-==============================================
-
-"""
-
-# %% 
-# ! pip install welly striplog
-
-# %% 
-# Authors: M. de la Varga, Evan Bianco, Brian Burnham and Dieter Werthmüller
-# Importing GemPy
-import gempy as gp
-
-# Importing auxiliary libraries
-import numpy as np
-import pandas as pn
-import matplotlib.pyplot as plt
-import os
-import welly
-from welly import Location, Project
-import glob
-from striplog import Striplog, Legend, Decor
-
-pn.set_option('precision', 2)
-
-# %%
-# Creating striplog object
-# -----------------------------
-# 
-
-# %% 
-# get well header coordinates
-well_heads = {'alpha': {'kb_coords': (0, 0, 0)},
-              'beta': {'kb_coords': (10, 10, 0)},
-              'gamma': {'kb_coords': (12, 0, 0)},
-              'epsilon': {'kb_coords': (20, 0, 0)}}
-
-# %% 
-# Reading tops file
-cwd = os.getcwd()
-if 'examples' not in cwd:
-    data_path = os.getcwd() + '/examples'
-else:
-    data_path = cwd + '/..'
-
-print(data_path+'/data/input_data/striplog_integration/*.tops')
-topsfiles = glob.glob(data_path+'/data/input_data/striplog_integration/*.tops')
-topsfiles
-
-# %% 
-# Creating striplog object
-my_striplogs = []
-
-for file in topsfiles:
-    with open(file) as f:
-        text = f.read()
-        striplog = Striplog.from_csv(text=text)
-        my_striplogs.append(striplog)
-
-striplog_dict = {'alpha': my_striplogs[1],
-                 'beta': my_striplogs[2],
-                 'gamma': my_striplogs[3],
-                 'epsilon': my_striplogs[0]}
-
-striplog_dict['alpha'][0]
-
-# %% 
-# Plot striplog
-f, a = plt.subplots(ncols=4, sharey=True)
-
-for e, log in enumerate(striplog_dict.items()):
-    log[1].plot(ax=a[e], legend=None)
-f.tight_layout()
-plt.show()
-
-# %%
-# Striplog to pandas df of bottoms
-rows = []
-for wellname in striplog_dict.keys():
-    for i, interval in enumerate(striplog_dict[wellname]):
-        surface_name = interval.primary.lith
-        surface_base = interval.base.middle
-        x, y = well_heads[wellname]['kb_coords'][:-1]
-        series = 1
-        rows.append([x, y, surface_base, surface_name, series, wellname])
-
-column_names = ['X', 'Y', 'Z', 'surface', 'series', 'wellname']
-df = pn.DataFrame(rows, columns=column_names)
-df
-
-# %%
-# GemPy model
-# ----------------
-# 
-
-# %% 
-# Create gempy model object
-geo_model = gp.create_model('welly_integration')
-
-extent = [-100, 300, -100, 200, -150, 0]
-res = [60, 60, 60]
-
-# Initializting model using the striplog df
-gp.init_data(geo_model, extent, res, surface_points_df=df)
-
-# %% 
-geo_model.surface_points.df.head()
-
-# %% 
-geo_model.surfaces
-
-# %% 
-dec_list = []
-for e, i in enumerate(striplog_dict['alpha']):
-    dec_list.append(Decor({'_colour': geo_model.surfaces.df.loc[e, 'color'],
-                           'width': None,
-                           'component': i.primary,
-                           'hatch': None}))
-
-
-# %% 
-# welly plot with gempy colors
-# Create Decor list
-dec_list = []
-for e, i in enumerate(striplog_dict['alpha']):
-    dec_list.append(Decor({'_colour': geo_model.surfaces.df.loc[e, 'color'],
-                           'width': None,
-                           'component': i.primary,
-                           'hatch': None}))
-
-# Create legend
-legend = Legend(dec_list)
-legend
-
-# %% 
-# Plot striplogs:
-f, a = plt.subplots(ncols=4, sharey=True)
-
-for e, log in enumerate(striplog_dict.items()):
-    log[1].plot(ax=a[e], legend=legend)
-f.tight_layout()
-plt.show()
-
-# %% 
-# Modifying the coordinates to make more sense
-geo_model.surface_points.df[['X', 'Y']] = geo_model.surface_points.df[['X', 'Y']] * 10
-geo_model.surface_points.df['Z'] *= -1
-
-# %% 
-# Delete points of the basement surface since we are intepolating bottoms (that surface wont exit).
-geo_model.delete_surface_points_basement()
-
-# %% 
-# Adding an arbitrary orientation. Remember gempy need an orientation per series
-geo_model.set_default_orientation()
-geo_model.modify_orientations(0, X=-500)
-
-# %% 
-gp.plot_2d(geo_model)
-
-
-# %%
-gp.set_interpolator(geo_model)
-
-# %% 
-gp.compute_model(geo_model)
-
-# %% 
-
-p2d = gp.plot_2d(geo_model, cell_number=[30], show_data=True, show=True)
-
-# %%
-gp.plot_3d(geo_model)
-
-
-# %%
-# Pinch out model
-# ------------------
-# 
-# As we can see the 3D model generated above does not honor the forth well
-# lets fix it. First lets add an unconformity: between the yellow and
-# green layer:
-# 
-
-# %% 
-geo_model.add_features('Unconformity')
-
-# %%
-# Now we set the green layer in the second series
-# 
-
-# %% 
-geo_model.map_stack_to_surfaces({'Uncomformity': ['brian', 'evan', 'dieter']})
-geo_model.add_surfaces('basement')
-
-# %%
-# Lastly we need to add a dummy orientation to the new series:
-# 
-
-# %% 
-geo_model.add_orientations(-500, 0, -100, 'dieter', [0, 0, 1])
-
-# %%
-# Now we can compute:
-# 
-
-# %% 
-gp.compute_model(geo_model)
-
-# %% 
-p = gp.plot_2d(geo_model, cell_number=[30], show_data=True)
-f, a = plt.subplots(ncols=4, sharey=True)
-
-for e, log in enumerate(striplog_dict.items()):
-    log[1].plot(ax=a[e], legend=legend)
-f.tight_layout()
-plt.show()
-
-# %%
-# Getting better but not quite there yet. Since the yellow does not show
-# up in the last well the pinch out has to happen somewhere before so lets
-# add an artifial point to get that shape:
-# 
-
-# %% 
-geo_model.add_surface_points(200, 0, -75, 'evan');
-
-# %% 
-gp.compute_model(geo_model)
-p = gp.plot_2d(geo_model, cell_number=[30], show_data=True)
-f, a = plt.subplots(ncols=4, sharey=True)
-
-for e, log in enumerate(striplog_dict.items()):
-    log[1].plot(ax=a[e], legend=legend)
-f.tight_layout()
-plt.show()
-
-# %%
-# sphinx_gallery_thumbnail_number = 7
-gp.plot_3d(geo_model)
-
-# %%
-# gp.save_model(geo_model)
+"""
+Transform 2019: Integrating Striplog and GemPy
+==============================================
+
+"""
+
+# %% 
+# ! pip install welly striplog
+
+# %% 
+# Authors: M. de la Varga, Evan Bianco, Brian Burnham and Dieter Werthmüller
+# Importing GemPy
+import gempy as gp
+
+# Importing auxiliary libraries
+import numpy as np
+import pandas as pn
+import matplotlib.pyplot as plt
+import os
+import welly
+from welly import Location, Project
+import glob
+from striplog import Striplog, Legend, Decor
+
+pn.set_option('precision', 2)
+
+# %%
+# Creating striplog object
+# -----------------------------
+# 
+
+# %% 
+# get well header coordinates
+well_heads = {'alpha': {'kb_coords': (0, 0, 0)},
+              'beta': {'kb_coords': (10, 10, 0)},
+              'gamma': {'kb_coords': (12, 0, 0)},
+              'epsilon': {'kb_coords': (20, 0, 0)}}
+
+# %% 
+# Reading tops file
+cwd = os.getcwd()
+if 'examples' not in cwd:
+    data_path = os.getcwd() + '/examples'
+else:
+    data_path = cwd + '/..'
+
+print(data_path+'/data/input_data/striplog_integration/*.tops')
+topsfiles = glob.glob(data_path+'/data/input_data/striplog_integration/*.tops')
+topsfiles
+
+# %% 
+# Creating striplog object
+my_striplogs = []
+
+for file in topsfiles:
+    with open(file) as f:
+        text = f.read()
+        striplog = Striplog.from_csv(text=text)
+        my_striplogs.append(striplog)
+
+striplog_dict = {'alpha': my_striplogs[1],
+                 'beta': my_striplogs[2],
+                 'gamma': my_striplogs[3],
+                 'epsilon': my_striplogs[0]}
+
+striplog_dict['alpha'][0]
+
+# %% 
+# Plot striplog
+f, a = plt.subplots(ncols=4, sharey=True)
+
+for e, log in enumerate(striplog_dict.items()):
+    log[1].plot(ax=a[e], legend=None)
+f.tight_layout()
+plt.show()
+
+# %%
+# Striplog to pandas df of bottoms
+rows = []
+for wellname in striplog_dict.keys():
+    for i, interval in enumerate(striplog_dict[wellname]):
+        surface_name = interval.primary.lith
+        surface_base = interval.base.middle
+        x, y = well_heads[wellname]['kb_coords'][:-1]
+        series = 1
+        rows.append([x, y, surface_base, surface_name, series, wellname])
+
+column_names = ['X', 'Y', 'Z', 'surface', 'series', 'wellname']
+df = pn.DataFrame(rows, columns=column_names)
+df
+
+# %%
+# GemPy model
+# ----------------
+# 
+
+# %% 
+# Create gempy model object
+geo_model = gp.create_model('welly_integration')
+
+extent = [-100, 300, -100, 200, -150, 0]
+res = [60, 60, 60]
+
+# Initializting model using the striplog df
+gp.init_data(geo_model, extent, res, surface_points_df=df)
+
+# %% 
+geo_model.surface_points.df.head()
+
+# %% 
+geo_model.surfaces
+
+# %% 
+dec_list = []
+for e, i in enumerate(striplog_dict['alpha']):
+    dec_list.append(Decor({'_colour': geo_model.surfaces.df.loc[e, 'color'],
+                           'width': None,
+                           'component': i.primary,
+                           'hatch': None}))
+
+
+# %% 
+# welly plot with gempy colors
+# Create Decor list
+dec_list = []
+for e, i in enumerate(striplog_dict['alpha']):
+    dec_list.append(Decor({'_colour': geo_model.surfaces.df.loc[e, 'color'],
+                           'width': None,
+                           'component': i.primary,
+                           'hatch': None}))
+
+# Create legend
+legend = Legend(dec_list)
+legend
+
+# %% 
+# Plot striplogs:
+f, a = plt.subplots(ncols=4, sharey=True)
+
+for e, log in enumerate(striplog_dict.items()):
+    log[1].plot(ax=a[e], legend=legend)
+f.tight_layout()
+plt.show()
+
+# %% 
+# Modifying the coordinates to make more sense
+geo_model.surface_points.df[['X', 'Y']] = geo_model.surface_points.df[['X', 'Y']] * 10
+geo_model.surface_points.df['Z'] *= -1
+
+# %% 
+# Delete points of the basement surface since we are intepolating bottoms (that surface wont exit).
+geo_model.delete_surface_points_basement()
+
+# %% 
+# Adding an arbitrary orientation. Remember gempy need an orientation per series
+geo_model.set_default_orientation()
+geo_model.modify_orientations(0, X=-500)
+
+# %% 
+gp.plot_2d(geo_model)
+
+
+# %%
+gp.set_interpolator(geo_model)
+
+# %% 
+gp.compute_model(geo_model)
+
+# %% 
+
+p2d = gp.plot_2d(geo_model, cell_number=[30], show_data=True, show=True)
+
+# %%
+gp.plot_3d(geo_model)
+
+
+# %%
+# Pinch out model
+# ------------------
+# 
+# As we can see the 3D model generated above does not honor the forth well
+# lets fix it. First lets add an unconformity: between the yellow and
+# green layer:
+# 
+
+# %% 
+geo_model.add_features('Unconformity')
+
+# %%
+# Now we set the green layer in the second series
+# 
+
+# %% 
+geo_model.map_stack_to_surfaces({'Uncomformity': ['brian', 'evan', 'dieter']})
+geo_model.add_surfaces('basement')
+
+# %%
+# Lastly we need to add a dummy orientation to the new series:
+# 
+
+# %% 
+geo_model.add_orientations(-500, 0, -100, 'dieter', [0, 0, 1])
+
+# %%
+# Now we can compute:
+# 
+
+# %% 
+gp.compute_model(geo_model)
+
+# %% 
+p = gp.plot_2d(geo_model, cell_number=[30], show_data=True)
+f, a = plt.subplots(ncols=4, sharey=True)
+
+for e, log in enumerate(striplog_dict.items()):
+    log[1].plot(ax=a[e], legend=legend)
+f.tight_layout()
+plt.show()
+
+# %%
+# Getting better but not quite there yet. Since the yellow does not show
+# up in the last well the pinch out has to happen somewhere before so lets
+# add an artifial point to get that shape:
+# 
+
+# %% 
+geo_model.add_surface_points(200, 0, -75, 'evan');
+
+# %% 
+gp.compute_model(geo_model)
+p = gp.plot_2d(geo_model, cell_number=[30], show_data=True)
+f, a = plt.subplots(ncols=4, sharey=True)
+
+for e, log in enumerate(striplog_dict.items()):
+    log[1].plot(ax=a[e], legend=legend)
+f.tight_layout()
+plt.show()
+
+# %%
+# sphinx_gallery_thumbnail_number = 7
+gp.plot_3d(geo_model)
+
+# %%
+# gp.save_model(geo_model)
```

### Comparing `gempy-2.2b10.dev1/examples/integrations/gempy_subsurface.py` & `gempy-2.3.0/examples/integrations/gempy_subsurface.py`

 * *Files 2% similar despite different names*

```diff
@@ -77,15 +77,15 @@
 # The first step to create a GemPy model is create a gempy.
 
 # %%
 
 import gempy as gp
 geo_model = gp.create_model("getting started")
 geo_model.set_regular_grid(extent=[275619, 323824, 3914125, 3961793, -3972.6, 313.922], resolution=[50,50,50])
-gp.set_interpolator(geo_model, theano_optimizer='fast_compile', verbose=[])
+gp.set_interpolator(geo_model, aesara_optimizer='fast_compile', verbose=[])
 
 # %% md
 # Making a model step by step.
 # ----------------------------
 
 # The temptation at this point is to bring all the points into gempy and just interpolate. However, often that strategy
 # results in ill posed problems due to noise or irregularities in the data. gempy has been design to being able to
```

### Comparing `gempy-2.2b10.dev1/examples/tutorials/ch2-Geophysics/ch2_1_gravity.py` & `gempy-2.3.0/examples/tutorials/ch2-Geophysics/ch2_1_gravity.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,165 +1,165 @@
-"""
-2.1 Forward Gravity: Simple example
-^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
-
-"""
-
-# %%
-# Importing gempy
-import gempy as gp
-from gempy.assets.geophysics import GravityPreprocessing
-
-# Aux imports
-import numpy as np
-import pandas as pd
-import os
-import matplotlib.pyplot as plt
-
-np.random.seed(1515)
-pd.set_option('precision', 2)
-
-# %%
-cwd = os.getcwd()
-if 'examples' not in cwd:
-    data_path = os.getcwd() + '/examples/'
-else:
-    data_path = cwd + '/../../'
-
-geo_model = gp.load_model('Greenstone', path=data_path + 'data/gempy_models/Greenstone')
-
-# %% 
-geo_model.stack
-
-# %% 
-geo_model.surfaces
-
-# %% 
-gp.plot_2d(geo_model)
-
-# %%
-
-# %%
-# Creating grid
-# ~~~~~~~~~~~~~
-# 
-
-# %%
-# First we need to define the location of the devices. For this example we
-# can make a map:
-# 
-
-# %% 
-grav_res = 20
-X = np.linspace(7.050000e+05, 747000, grav_res)
-Y = np.linspace(6863000, 6925000, grav_res)
-Z = 300
-xyz = np.meshgrid(X, Y, Z)
-xy_ravel = np.vstack(list(map(np.ravel, xyz))).T
-xy_ravel
-
-# %%
-# We can see the location of the devices relative to the model data:
-# 
-
-# %%
-
-gp.plot_2d(geo_model, direction='z', show=False)
-plt.scatter(xy_ravel[:, 0], xy_ravel[:, 1], s=1)
-plt.show()
-
-# %%
-# Now we need to create the grid centered on the devices (see:
-# https://github.com/cgre-aachen/gempy/blob/master/notebooks/tutorials/ch1-3-Grids.ipynb)
-# 
-
-# %% 
-geo_model.set_centered_grid(xy_ravel, resolution=[10, 10, 15], radius=5000)
-
-# %% 
-geo_model.grid.centered_grid.kernel_centers
-
-# %%
-# Now we need to compute the component tz (see
-# https://github.com/cgre-achen/gempy/blob/master/notebooks/tutorials/ch2-2-Cell_selection.ipynb)
-# 
-
-# %% 
-g = GravityPreprocessing(geo_model.grid.centered_grid)
-
-# %% 
-tz = g.set_tz_kernel()
-
-# %% 
-tz
-
-# %%
-# Compiling the gravity graph
-# ~~~~~~~~~~~~~~~~~~~~~~~~~~~
-# 
-# If geo_model has already a centered grid, the calculation of tz happens
-# automatically.  This theano graph will return gravity
-# as well as the lithologies. In addition we need either to pass the density
-# block (see below). Or the position of density on the surface(in the
-# future the name) to compute the density block at running time.
-# 
-
-# %% 
-geo_model.surfaces
-
-# %%
-# In this case the densities of each layer are at the loc 1 (0 is the id)
-# 
-
-# New way
-gp.set_interpolator(geo_model, output=['gravity'], pos_density=1, gradient=False,
-                    theano_optimizer='fast_run')
-
-# %%
-# Once we have created a gravity interpolator we can call it from compute
-# model as follows:
-# 
-
-# %% 
-sol = gp.compute_model(geo_model)
-grav = sol.fw_gravity
-
-# %% 
-gp.plot_2d(geo_model, direction=['z'], height=7, show_results=False, show_data=True,
-           show=False)
-plt.scatter(xy_ravel[:, 0], xy_ravel[:, 1], s=1)
-plt.imshow(sol.fw_gravity.reshape(grav_res, grav_res),
-           extent=(xy_ravel[:, 0].min() + (xy_ravel[0, 0] - xy_ravel[1, 0]) / 2,
-                   xy_ravel[:, 0].max() - (xy_ravel[0, 0] - xy_ravel[1, 0]) / 2,
-                   xy_ravel[:, 1].min() + (xy_ravel[0, 1] - xy_ravel[30, 1]) / 2,
-                   xy_ravel[:, 1].max() - (xy_ravel[0, 1] - xy_ravel[30, 1]) / 2),
-           cmap='viridis_r', origin='lower')
-plt.show()
-# %%
-# Plotting lithologies
-# ^^^^^^^^^^^^^^^^^^^^
-# 
-# If we want to compute the lithologies we will need to create a normal
-# interpolator object as seen in the Chapter 1 of the tutorials
-# 
-
-
-# %%
-# Now we can plot all together (change the alpha parameter to see the
-# gravity overlying):
-# 
-
-# %%
-# sphinx_gallery_thumbnail_number = 4
-gp.plot_2d(geo_model, cell_number=[-1], direction=['z'], show=False,
-           kwargs_regular_grid={'alpha': .5})
-
-plt.scatter(xy_ravel[:, 0], xy_ravel[:, 1], s=1)
-plt.imshow(grav.reshape(grav_res, grav_res),
-           extent=(xy_ravel[:, 0].min() + (xy_ravel[0, 0] - xy_ravel[1, 0]) / 2,
-                   xy_ravel[:, 0].max() - (xy_ravel[0, 0] - xy_ravel[1, 0]) / 2,
-                   xy_ravel[:, 1].min() + (xy_ravel[0, 1] - xy_ravel[30, 1]) / 2,
-                   xy_ravel[:, 1].max() - (xy_ravel[0, 1] - xy_ravel[30, 1]) / 2),
-           cmap='viridis_r', origin='lower', alpha=.8)
-cbar = plt.colorbar()
-cbar.set_label(r'$\mu$gal')
-plt.show()
+"""
+2.1 Forward Gravity: Simple example
+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+
+"""
+
+# %%
+# Importing gempy
+import gempy as gp
+from gempy.assets.geophysics import GravityPreprocessing
+
+# Aux imports
+import numpy as np
+import pandas as pd
+import os
+import matplotlib.pyplot as plt
+
+np.random.seed(1515)
+pd.set_option('display.precision', 2)
+
+# %%
+cwd = os.getcwd()
+if 'examples' not in cwd:
+    data_path = os.getcwd() + '/examples/'
+else:
+    data_path = cwd + '/../../'
+
+geo_model = gp.load_model('Greenstone', path=data_path + 'data/gempy_models/Greenstone')
+
+# %% 
+geo_model.stack
+
+# %% 
+geo_model.surfaces
+
+# %% 
+gp.plot_2d(geo_model)
+
+# %%
+
+# %%
+# Creating grid
+# ~~~~~~~~~~~~~
+# 
+
+# %%
+# First we need to define the location of the devices. For this example we
+# can make a map:
+# 
+
+# %% 
+grav_res = 20
+X = np.linspace(7.050000e+05, 747000, grav_res)
+Y = np.linspace(6863000, 6925000, grav_res)
+Z = 300
+xyz = np.meshgrid(X, Y, Z)
+xy_ravel = np.vstack(list(map(np.ravel, xyz))).T
+xy_ravel
+
+# %%
+# We can see the location of the devices relative to the model data:
+# 
+
+# %%
+
+gp.plot_2d(geo_model, direction='z', show=False)
+plt.scatter(xy_ravel[:, 0], xy_ravel[:, 1], s=1)
+plt.show()
+
+# %%
+# Now we need to create the grid centered on the devices (see:
+# https://github.com/cgre-aachen/gempy/blob/master/notebooks/tutorials/ch1-3-Grids.ipynb)
+# 
+
+# %% 
+geo_model.set_centered_grid(xy_ravel, resolution=[10, 10, 15], radius=5000)
+
+# %% 
+geo_model.grid.centered_grid.kernel_centers
+
+# %%
+# Now we need to compute the component tz (see
+# https://github.com/cgre-achen/gempy/blob/master/notebooks/tutorials/ch2-2-Cell_selection.ipynb)
+# 
+
+# %% 
+g = GravityPreprocessing(geo_model.grid.centered_grid)
+
+# %% 
+tz = g.set_tz_kernel()
+
+# %% 
+tz
+
+# %%
+# Compiling the gravity graph
+# ~~~~~~~~~~~~~~~~~~~~~~~~~~~
+# 
+# If geo_model has already a centered grid, the calculation of tz happens
+# automatically.  This aesara graph will return gravity
+# as well as the lithologies. In addition we need either to pass the density
+# block (see below). Or the position of density on the surface(in the
+# future the name) to compute the density block at running time.
+# 
+
+# %% 
+geo_model.surfaces
+
+# %%
+# In this case the densities of each layer are at the loc 1 (0 is the id)
+# 
+
+# New way
+gp.set_interpolator(geo_model, output=['gravity'], pos_density=1, gradient=False,
+                    aesara_optimizer='fast_run')
+
+# %%
+# Once we have created a gravity interpolator we can call it from compute
+# model as follows:
+# 
+
+# %% 
+sol = gp.compute_model(geo_model)
+grav = sol.fw_gravity
+
+# %% 
+gp.plot_2d(geo_model, direction=['z'], height=7, show_results=False, show_data=True,
+           show=False)
+plt.scatter(xy_ravel[:, 0], xy_ravel[:, 1], s=1)
+plt.imshow(sol.fw_gravity.reshape(grav_res, grav_res),
+           extent=(xy_ravel[:, 0].min() + (xy_ravel[0, 0] - xy_ravel[1, 0]) / 2,
+                   xy_ravel[:, 0].max() - (xy_ravel[0, 0] - xy_ravel[1, 0]) / 2,
+                   xy_ravel[:, 1].min() + (xy_ravel[0, 1] - xy_ravel[30, 1]) / 2,
+                   xy_ravel[:, 1].max() - (xy_ravel[0, 1] - xy_ravel[30, 1]) / 2),
+           cmap='viridis_r', origin='lower')
+plt.show()
+# %%
+# Plotting lithologies
+# ^^^^^^^^^^^^^^^^^^^^
+# 
+# If we want to compute the lithologies we will need to create a normal
+# interpolator object as seen in the Chapter 1 of the tutorials
+# 
+
+
+# %%
+# Now we can plot all together (change the alpha parameter to see the
+# gravity overlying):
+# 
+
+# %%
+# sphinx_gallery_thumbnail_number = 4
+gp.plot_2d(geo_model, cell_number=[-1], direction=['z'], show=False,
+           kwargs_regular_grid={'alpha': .5})
+
+plt.scatter(xy_ravel[:, 0], xy_ravel[:, 1], s=1)
+plt.imshow(grav.reshape(grav_res, grav_res),
+           extent=(xy_ravel[:, 0].min() + (xy_ravel[0, 0] - xy_ravel[1, 0]) / 2,
+                   xy_ravel[:, 0].max() - (xy_ravel[0, 0] - xy_ravel[1, 0]) / 2,
+                   xy_ravel[:, 1].min() + (xy_ravel[0, 1] - xy_ravel[30, 1]) / 2,
+                   xy_ravel[:, 1].max() - (xy_ravel[0, 1] - xy_ravel[30, 1]) / 2),
+           cmap='viridis_r', origin='lower', alpha=.8)
+cbar = plt.colorbar()
+cbar.set_label(r'$\mu$gal')
+plt.show()
```

### Comparing `gempy-2.2b10.dev1/examples/tutorials/ch2-Geophysics/ch2_2_cell_selection.py` & `gempy-2.3.0/examples/tutorials/ch2-Geophysics/ch2_2_cell_selection.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,134 +1,134 @@
-"""
-2.2: Centered Grid.
-^^^^^^^^^^^^^^^^^^^
-
-Geophysics Preprocessing builds on the centered grid
-(https://github.com/cgre-aachen/gempy/blob/master/notebooks/tutorials/ch1-3-Grids.ipynb)
-to precompute the constant part of forward physical computations as for
-example gravity:
-
-.. math::
-
-    F_z = G_{\\rho} ||| x \\ln(y+r) + y \\ln (x+r) - z \\arctan (\\frac{x y}{z r}) |^{x_2}_{x_1}|^{y_2}_{y_1}|^{
-    z_2}_{z_1}
-
-
-where we can compress the grid dependent terms as
-
-.. math::
-
-    t_z = ||| x \ln (y+r) + y \ln (x+r)-z \\arctan ( \\frac{x y}{z r} ) |^{x_2}_{x_1}|^{y_2}_{y_1}|^{z_2}_{z_1}
-
-By doing this decomposition an keeping the grid constant we can compute
-the forward gravity by simply operate:
-
-.. math::
-
-    F_z = G_{\\rho} \cdot t_z
-
-"""
-
-
-# %%
-
-# Importing gempy
-from gempy.assets.geophysics import GravityPreprocessing
-
-# Aux imports
-import numpy as np
-import pandas as pd
-import matplotlib.pyplot as plt
-
-np.random.seed(1515)
-pd.set_option('precision', 2)
-
-# %% 
-g = GravityPreprocessing()
-
-# %% 
-kernel_centers, kernel_dxyz_left, kernel_dxyz_right = g.create_irregular_grid_kernel(resolution=[10, 10, 20],
-                                                                                     radius=100)
-
-# %%
-# ``create_irregular_grid_kernel`` will create a constant kernel around
-# the point 0,0,0. This kernel will be what we use for each device.
-# 
-
-# %% 
-kernel_centers
-
-# %%
-# :math:`t_z` is only dependent on distance and therefore we can use the
-# kerenel created on the previous cell
-# 
-
-# %% 
-tz = g.set_tz_kernel(resolution=[10, 10, 20], radius=100)
-tz
-
-# %%
-# To compute tz we also need the edges of each voxel. The distance to the
-# edges are stored on ``kernel_dxyz_left`` and ``kernel_dxyz_right``. We
-# can plot all the data as follows:
-# 
-
-# %% 
-a, b, c = kernel_centers, kernel_dxyz_left, kernel_dxyz_right
-
-# %% 
-fig = plt.figure(figsize=(13, 7))
-plt.quiver(a[:, 0].reshape(11, 11, 21)[5, :, :].ravel(),
-           a[:, 2].reshape(11, 11, 21)[:, 5, :].ravel(),
-           np.zeros(231),
-           tz.reshape(11, 11, 21)[5, :, :].ravel(), label='$t_z$', alpha=.3
-           )
-
-plt.plot(a[:, 0].reshape(11, 11, 21)[5, :, :].ravel(),
-         a[:, 2].reshape(11, 11, 21)[:, 5, :].ravel(), 'o', alpha=.3, label='Centers')
-
-plt.plot(a[:, 0].reshape(11, 11, 21)[5, :, :].ravel() - b[:, 0].reshape(11, 11, 21)[5, :, :].ravel(),
-         a[:, 2].reshape(11, 11, 21)[:, 5, :].ravel(), '.', alpha=.3, label='Lefts')
-
-plt.plot(a[:, 0].reshape(11, 11, 21)[5, :, :].ravel(),
-         a[:, 2].reshape(11, 11, 21)[:, 5, :].ravel() - b[:, 2].reshape(11, 11, 21)[:, 5, :].ravel(), '.', alpha=.6,
-         label='Ups')
-
-plt.plot(a[:, 0].reshape(11, 11, 21)[5, :, :].ravel() + c[:, 0].reshape(11, 11, 21)[5, :, :].ravel(),
-         a[:, 2].reshape(11, 11, 21)[:, 5, :].ravel(), '.', alpha=.3, label='Rights')
-
-plt.plot(a[:, 0].reshape(11, 11, 21)[5, :, :].ravel(),
-         a[:, 2].reshape(11, 11, 21)[:, 5, :].ravel() + c[:, 2].reshape(11, 11, 21)[5, :, :].ravel(), '.', alpha=.3,
-         label='Downs')
-
-plt.xlim(-200, 200)
-plt.ylim(-200, 0)
-plt.legend()
-plt.show()
-
-# %%
-# Just the quiver:
-# 
-
-# %%
-fig = plt.figure(figsize=(13, 7))
-plt.quiver(a[:, 0].reshape(11, 11, 21)[5, :, :].ravel(),
-           a[:, 2].reshape(11, 11, 21)[:, 5, :].ravel(),
-           np.zeros(231),
-           tz.reshape(11, 11, 21)[5, :, :].ravel()
-           )
-plt.show()
-
-# %%
-# Remember this is happening always in 3D:
-# 
-
-# %%
-fig = plt.figure()
-ax = fig.add_subplot(111, projection='3d')
-
-ax.scatter(a[:, 0], a[:, 1], a[:, 2], c=tz)
-
-ax.set_xlabel('X Label')
-ax.set_ylabel('Y Label')
-ax.set_zlabel('Z Label')
+"""
+2.2: Centered Grid.
+^^^^^^^^^^^^^^^^^^^
+
+Geophysics Preprocessing builds on the centered grid
+(https://github.com/cgre-aachen/gempy/blob/master/notebooks/tutorials/ch1-3-Grids.ipynb)
+to precompute the constant part of forward physical computations as for
+example gravity:
+
+.. math::
+
+    F_z = G_{\\rho} ||| x \\ln(y+r) + y \\ln (x+r) - z \\arctan (\\frac{x y}{z r}) |^{x_2}_{x_1}|^{y_2}_{y_1}|^{
+    z_2}_{z_1}
+
+
+where we can compress the grid dependent terms as
+
+.. math::
+
+    t_z = ||| x \ln (y+r) + y \ln (x+r)-z \\arctan ( \\frac{x y}{z r} ) |^{x_2}_{x_1}|^{y_2}_{y_1}|^{z_2}_{z_1}
+
+By doing this decomposition an keeping the grid constant we can compute
+the forward gravity by simply operate:
+
+.. math::
+
+    F_z = G_{\\rho} \cdot t_z
+
+"""
+
+
+# %%
+
+# Importing gempy
+from gempy.assets.geophysics import GravityPreprocessing
+
+# Aux imports
+import numpy as np
+import pandas as pd
+import matplotlib.pyplot as plt
+
+np.random.seed(1515)
+pd.set_option('display.precision', 2)
+
+# %% 
+g = GravityPreprocessing()
+
+# %% 
+kernel_centers, kernel_dxyz_left, kernel_dxyz_right = g.create_irregular_grid_kernel(resolution=[10, 10, 20],
+                                                                                     radius=100)
+
+# %%
+# ``create_irregular_grid_kernel`` will create a constant kernel around
+# the point 0,0,0. This kernel will be what we use for each device.
+# 
+
+# %% 
+kernel_centers
+
+# %%
+# :math:`t_z` is only dependent on distance and therefore we can use the
+# kerenel created on the previous cell
+# 
+
+# %% 
+tz = g.set_tz_kernel(resolution=[10, 10, 20], radius=100)
+tz
+
+# %%
+# To compute tz we also need the edges of each voxel. The distance to the
+# edges are stored on ``kernel_dxyz_left`` and ``kernel_dxyz_right``. We
+# can plot all the data as follows:
+# 
+
+# %% 
+a, b, c = kernel_centers, kernel_dxyz_left, kernel_dxyz_right
+
+# %% 
+fig = plt.figure(figsize=(13, 7))
+plt.quiver(a[:, 0].reshape(11, 11, 21)[5, :, :].ravel(),
+           a[:, 2].reshape(11, 11, 21)[:, 5, :].ravel(),
+           np.zeros(231),
+           tz.reshape(11, 11, 21)[5, :, :].ravel(), label='$t_z$', alpha=.3
+           )
+
+plt.plot(a[:, 0].reshape(11, 11, 21)[5, :, :].ravel(),
+         a[:, 2].reshape(11, 11, 21)[:, 5, :].ravel(), 'o', alpha=.3, label='Centers')
+
+plt.plot(a[:, 0].reshape(11, 11, 21)[5, :, :].ravel() - b[:, 0].reshape(11, 11, 21)[5, :, :].ravel(),
+         a[:, 2].reshape(11, 11, 21)[:, 5, :].ravel(), '.', alpha=.3, label='Lefts')
+
+plt.plot(a[:, 0].reshape(11, 11, 21)[5, :, :].ravel(),
+         a[:, 2].reshape(11, 11, 21)[:, 5, :].ravel() - b[:, 2].reshape(11, 11, 21)[:, 5, :].ravel(), '.', alpha=.6,
+         label='Ups')
+
+plt.plot(a[:, 0].reshape(11, 11, 21)[5, :, :].ravel() + c[:, 0].reshape(11, 11, 21)[5, :, :].ravel(),
+         a[:, 2].reshape(11, 11, 21)[:, 5, :].ravel(), '.', alpha=.3, label='Rights')
+
+plt.plot(a[:, 0].reshape(11, 11, 21)[5, :, :].ravel(),
+         a[:, 2].reshape(11, 11, 21)[:, 5, :].ravel() + c[:, 2].reshape(11, 11, 21)[5, :, :].ravel(), '.', alpha=.3,
+         label='Downs')
+
+plt.xlim(-200, 200)
+plt.ylim(-200, 0)
+plt.legend()
+plt.show()
+
+# %%
+# Just the quiver:
+# 
+
+# %%
+fig = plt.figure(figsize=(13, 7))
+plt.quiver(a[:, 0].reshape(11, 11, 21)[5, :, :].ravel(),
+           a[:, 2].reshape(11, 11, 21)[:, 5, :].ravel(),
+           np.zeros(231),
+           tz.reshape(11, 11, 21)[5, :, :].ravel()
+           )
+plt.show()
+
+# %%
+# Remember this is happening always in 3D:
+# 
+
+# %%
+fig = plt.figure()
+ax = fig.add_subplot(111, projection='3d')
+
+ax.scatter(a[:, 0], a[:, 1], a[:, 2], c=tz)
+
+ax.set_xlabel('X Label')
+ax.set_ylabel('Y Label')
+ax.set_zlabel('Z Label')
 plt.show()
```

### Comparing `gempy-2.2b10.dev1/gempy/addons/gempy_to_rexfile.py` & `gempy-2.3.0/gempy/addons/gempy_to_rexfile.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,783 +1,783 @@
-"""
-This file is part of gempy.
-
-Created on 21/02/2020
-
-@author: Miguel de la Varga
-"""
-
-import numpy as np
-import matplotlib.colors as mcolors
-import pandas as pd
-
-rexFileHeaderSize = 64
-rexCoordSize = 22
-
-file_header_size = 86
-rexDataBlockHeaderSize = 16
-
-file_header_and_data_header = 102
-mesh_header_size = 128
-all_header_size = 230
-
-# Supported block types
-# typeLineSet = 0
-# typeText = 1
-# typePointList = 2
-typeMesh = 3
-# typeImage = 4
-# typeMaterial = 5
-# typePeopleSimulation = 6
-# typeUnityPackage = 7
-# typeSceneNode = 8
-
-
-n_bytes = 0
-
-
-class GemPyToRex:
-    def __init__(self, geo_model=None):
-        """Writes GemPy data structures into binary Rex
-
-         https://github.com/roboticeyes/openrex/blob/master/doc/rex-spec-v1.md
-        """
-        self.rex_bytes = bytearray()
-        self.n_bytes = 0
-
-        self.data_id = 0
-        self.geo_model = geo_model
-
-    def __call__(self, geo_model=None, meshes=True, material=True,
-                 surfaces=None, topography=True, app='GemPlay'):
-        """
-
-        Args:
-            meshes:
-            surfaces (list): Subset of surfaces to send to the client
-            app (str): Either RexViewer or GemPlay. Set of default values
-
-        Returns:
-
-        """
-
-        byte_array = bytearray()
-        byte_size = 0
-        self.data_id = 0
-
-        if geo_model is None:
-            geo_model = self.geo_model
-        else:
-            self.geo_model = geo_model
-
-        if surfaces is not None:
-            raise NotImplementedError
-
-        flip_yz, backside, vertex_color = self.default_values(app)
-        # flip_yz, backside, vertex_color = False, True, False
-
-        surface_df = self.grab_meshes(geo_model)
-        if topography:
-            topography_dict = self.grab_topography(geo_model)
-        else:
-            topography_dict = None
-
-        # Data Blocks
-        # -----------
-        if material is True:
-            # Material
-            byte_array += self.gempy_color_to_rex_material(surface_df, topography)
-
-        if meshes is True:
-            # Mesh
-            byte_array += self.gempy_meshes_to_rex(
-                surface_df,
-                topography_dict=topography_dict,
-                flip_yz=flip_yz,
-                backside=backside,
-                vertex_color=vertex_color)
-
-        # Size of all data blocks together
-        byte_size += len(byte_array)
-
-        # Write file header
-        # -----------------
-        n_data_blocks = self.data_id
-
-        header_bytes = write_file_header_block(
-            n_data_blocks=n_data_blocks,
-            size_data_blocks=byte_size,
-            start_data=file_header_size)
-
-        return header_bytes + byte_array
-
-    @staticmethod
-    def grab_meshes(geo_model):
-        """Check if surfaces are computed. And return a pandas.DataFrame with
-         the meshes to be converted
-
-        Args:
-            geo_model:
-
-        Returns:
-
-        """
-
-        try:
-            # Drop basement
-            surface_df = geo_model._surfaces.df.groupby(
-                ['isActive', 'isBasement']).get_group((True, False))
-        except (IndexError, KeyError):
-            raise RuntimeError('No computed surfaces yet.')
-
-        return surface_df[['surface', 'vertices', 'edges', 'color']]
-
-    @staticmethod
-    def grab_topography(geo_model):
-        from scipy.spatial import Delaunay
-
-        if geo_model._grid.topography is None or geo_model._grid.topography.values.shape[0] == 0:
-            return None
-        else:
-            topography_dict = dict()
-            topography_dict['surface'] = "Topography"
-            topography_dict['vertices'] = geo_model._grid.topography.values
-            # tri = Delaunay(geo_model._grid.topography.values)
-            topography_dict['edges'] = Delaunay(geo_model._grid.topography.values[:, :2]).simplices
-            topography_dict['color'] = geo_model.solutions.geological_map
-
-            return topography_dict
-
-    @staticmethod
-    def hex_to_rgb(hex: str, normalize: bool = True) -> np.ndarray:
-        """Transform colors from hex to rgb"""
-        hex = hex.lstrip('#')
-        hlen = len(hex)
-        rgb = np.array([int(hex[i:i + hlen // 3], 16) for i in range(0, hlen, hlen // 3)])
-        if normalize is True:
-            rgb = rgb / 255
-        return rgb
-
-    @staticmethod
-    def default_values(app):
-        """
-
-        Args:
-            app:
-
-        Returns:
-            list: flip_yz, backside, vertex_color
-        """
-        if app == 'GemPlay':
-            return (False, True, False)
-        elif app == 'RexView':
-            return (True, True, True)
-        else:
-            raise AttributeError('app must be either GemPlay or RexView')
-
-    def gempy_meshes_to_rex(self,
-                            surface_df,
-                            topography_dict=None,
-                            flip_yz=False,
-                            backside=True,
-                            vertex_color=False):
-        """Write mesh to Rexfile.
-
-        Args:
-            surface_df:
-            topography_dict:
-            flip_yz: Fliping YZ coordinates. Rexview need this
-            backside: If True, create a second set of triangles on the backside of the mesh
-            vertex_color
-
-        Returns:
-
-        Notes:
-            At the moment 14.07.2020 it is not possible to write normals or texture
-
-        """
-        rex_bytes = bytearray()
-        mesh_number = 0
-
-        # Loop geological surfaces surfaces
-        for idx, surface_vals in surface_df.iterrows():
-
-            tri = surface_vals['edges']
-            if tri is np.nan:
-                continue
-
-            ver = surface_vals['vertices']
-            surface_name = surface_vals['surface']
-            if vertex_color:
-                # Hex Colors
-                col_ = surface_vals['color']
-            else:
-                col_ = None
-
-            rex_bytes = self.mesh_prepare_and_encode(rex_bytes, mesh_number, ver, tri,
-                                                     surface_name, col_=col_,
-                                                     flip_yz=flip_yz, backside=backside,
-                                                     vertex_color=False)
-            mesh_number += 1
-
-        # Add topography
-        if topography_dict is not None:
-
-            rex_bytes = self.mesh_prepare_and_encode(rex_bytes, n_surface=-1,
-                                                     ver=topography_dict['vertices'],
-                                                     tri=topography_dict['edges'],
-                                                     surface_name=topography_dict['surface'],
-                                                     col_=topography_dict['color'],
-                                                     flip_yz=flip_yz, backside=backside,
-                                                     vertex_color=True)
-
-        return rex_bytes
-
-    def mesh_prepare_and_encode(self, rex_bytes, n_surface, ver, tri, surface_name, col_=None, \
-                                flip_yz=False,
-                                backside=True,
-                                vertex_color=False):
-
-        if flip_yz:
-            # This depends. For RexViewer we need to flip XYZ. For GemPlay not really
-            ver_ = np.copy(ver)
-            ver[:, 2] = ver_[:, 1]
-            ver[:, 1] = ver_[:, 2]
-
-        # Pre-processing GemPy output
-        ver_ravel, tri_ravel, n_vtx_coord, n_triangles = mesh_preprocess(ver, tri)
-
-        # Number of vertex colors
-        if vertex_color:
-            n_vtx_colors = n_vtx_coord
-
-            # Give color to each vertex
-            # TODO: Is this necessary if I pass a material
-            if type(col_) is str:
-                colors = np.zeros_like(ver) + self.hex_to_rgb(col_, normalize=True)
-                c_r = colors.ravel()
-
-            elif type(col_) is np.ndarray:
-                surf_df = self.geo_model._surfaces.df.set_index('id')
-                colors_hex = surf_df.groupby(
-                    ['isActive', 'isFault']).get_group((True, False))['color']
-
-                colors_rgb_ = colors_hex.apply(lambda val: list(mcolors.hex2color(val)))
-                colors_rgb = pd.DataFrame(colors_rgb_.to_list(), index=colors_hex.index)
-
-                sel = np.round(col_[0]).astype(int)[0]
-                c_r = colors_rgb.loc[sel].values.ravel()
-            else:
-                raise AttributeError("col_ must be either hex string or rgb array")
-        else:
-            n_vtx_colors = 0
-            c_r = None
-
-        rex_bytes = self._mesh_encode(
-            rex_bytes, n_surface,
-            n_vtx_coord, n_triangles, n_vtx_colors,
-            surface_name, ver_ravel, tri_ravel, c_r)
-
-        if backside:
-            # Coping triangles to create the backside normal of the layers
-            tri_ = np.copy(tri)
-            # TURN normals - One side of the normals
-            tri_[:, 2] = tri[:, 1]
-            tri_[:, 1] = tri[:, 2]
-            # Pre-processing GemPy output
-            ver_ravel, tri_ravel, n_vtx_coord, n_triangles = mesh_preprocess(ver, tri_)
-            # tri = np.append(tri, tri_)
-
-            rex_bytes = self._mesh_encode(
-                rex_bytes, n_surface,
-                n_vtx_coord, n_triangles, n_vtx_colors,
-                surface_name, ver_ravel, tri_ravel, c_r)
-
-        return rex_bytes
-
-    def _mesh_encode(self, rex_bytes, material_id,
-                     n_vtx_coord, n_triangles, n_vtx_colors,
-                     surface_name, ver_ravel, tri_ravel, c_r):
-        # Write Mesh block - header
-        mesh_header_bytes = write_mesh_header(
-            n_vtx_coord / 3, n_triangles / 3,
-            n_vtx_colors=n_vtx_colors / 3,
-            start_vtx_coord=mesh_header_size,
-            start_nor_coord=mesh_header_size + n_vtx_coord * 4,
-            start_tex_coord=mesh_header_size + n_vtx_coord * 4,
-            start_vtx_colors=mesh_header_size + n_vtx_coord * 4,
-            start_triangles=mesh_header_size +
-                            ((n_vtx_coord + n_vtx_colors) * 4),
-            name=surface_name,
-            material_id=material_id  # self.data_id + surface_df.shape[0]
-        )
-
-        # Write Mesh block - Vertex, triangles
-        mesh_block_bytes = write_mesh_coordinates(ver_ravel, tri_ravel,
-                                                  colors=c_r  # When using
-                                                  # material we can avoid this
-                                                  )
-
-        # Calculate the size of the mesh block
-        mesh_block_size_no_data_block_header = len(mesh_header_bytes) + \
-                                               len(mesh_block_bytes)  # This is cte 128
-
-        # Write data block header for Mesh 1
-        data_header_bytes = write_data_block_header(
-            size_data=mesh_block_size_no_data_block_header,
-            data_id=self.data_id,
-            data_type=3,  # 3 for mesh
-            version_data=1  # Probably useful for counting
-            # the operation number
-        )
-        self.data_id += 1
-        rex_bytes += data_header_bytes + mesh_header_bytes + mesh_block_bytes
-
-        return rex_bytes
-
-    def gempy_color_to_rex_material(self, surface_df, topography=False):
-        rex_bytes = bytearray()
-
-        for idx, surface_vals in surface_df.iterrows():
-            # Write data block header for Material 1
-            data_header_bytes = write_data_block_header(
-                data_type=5,  # Material data type
-                version_data=1,  # Version. Probably useful for operation counter
-                size_data=68,  # Size of the block is FIXED
-                data_id=self.data_id  # self.data_id
-            )
-            self.data_id += 1
-
-            rgb_color = self.hex_to_rgb(surface_vals['color'], normalize=True)
-            # rgb_color = [1, 1, 1]
-            # Write Material
-            material_bytes = write_material_data(
-                ka_red=rgb_color[0], ka_green=rgb_color[1], ka_blue=rgb_color[2],
-                ka_texture_ID=9223372036854775807,  # ambient
-                ks_red=rgb_color[0], ks_green=rgb_color[1], ks_blue=rgb_color[2],
-                ks_texture_ID=9223372036854775807,  # specular
-                kd_red=rgb_color[0], kd_green=rgb_color[1], kd_blue=rgb_color[2],
-                kd_texture_ID=9223372036854775807,  # diffuse
-                ns=0.1,  # specular exponent
-                alpha=1  # opacity
-            )
-
-            rex_bytes += data_header_bytes + material_bytes
-
-        if topography is True:
-            # Write data block header for Material 1
-            data_header_bytes = write_data_block_header(
-                data_type=5,  # Material data type
-                version_data=1,  # Version. Probably useful for operation counter
-                size_data=68,  # Size of the block is FIXED
-                data_id=-1  # self.data_id
-            )
-
-            rgb_color = [1, 1, 1]
-            # Write Material
-            material_bytes = write_material_data(
-                ka_red=rgb_color[0], ka_green=rgb_color[1], ka_blue=rgb_color[2],
-                ka_texture_ID=9223372036854775807,  # ambient
-                ks_red=rgb_color[0], ks_green=rgb_color[1], ks_blue=rgb_color[2],
-                ks_texture_ID=9223372036854775807,  # specular
-                kd_red=rgb_color[0], kd_green=rgb_color[1], kd_blue=rgb_color[2],
-                kd_texture_ID=9223372036854775807,  # diffuse
-                ns=0.1,  # specular exponent
-                alpha=1  # opacity
-            )
-
-            self.data_id += 1
-            rex_bytes += data_header_bytes + material_bytes
-
-        return rex_bytes
-
-
-def encode(input_: list):
-    """Encode python objects - normally Python primitives or numpy arrays - into
-    its correspondent byte representation
-
-    Args:
-        input_ (List[tuples]): List of tuples: (object, type)
-
-    Returns:
-        byte: Array of bytes
-    """
-    global n_bytes
-    block = bytearray()
-
-    for tup in input_:
-        arr = np.array(tup[0], dtype=tup[1]).tobytes()
-        n_bytes += len(arr)
-        block += arr
-
-    return block
-
-
-def write_file_header_block(n_data_blocks, size_data_blocks, version=1,
-                            start_data=86, srid=3876, offsets=None):
-    """
-    Function that writes the header block of a rexfile:
-
-    Args:
-        n_data_blocks:
-        size_data_blocks:
-        version (int): Version of the file
-        start_data (int): Position where data start. This is after the header
-         and coordinate system. If everything works fine it should be 86
-        srid (int): Spatial reference system identifier (srid)
-        offsets:
-
-    Returns:
-
-    """
-    reserved = '0' * 42
-    if offsets is None:
-        offsets = [0, 0, 0]
-
-    input_ = [('REX1', 'bytes'),  # REX1
-              (version, 'uint16'),  # file version
-              (0, 'uint32'),  # CRC32
-              (n_data_blocks, 'uint16'),  # Number of DATA BLOCKS
-              (start_data, 'uint16'),  # StartData
-              (size_data_blocks, 'uint64'),  # Size of all data blocks
-              (reserved, 'bytes'),  # Reserved
-              # Coordinate system block
-              (srid, 'uint32'),  # Spatial reference system identifier (srid)
-              (4, 'uint16'),  # Size of the name of the used system.
-              ('EPSG', 'bytes'),  # name of the used system.
-              (offsets, 'float32')]  # Global x, y, z offset
-
-    block_bytes = encode(input_)
-    return block_bytes
-
-
-def write_data_block_header(size_data, data_id=1, data_type=3, version_data=1):
-    """Function to write a DATA BLOCK header.
-
-    Args:
-        size_data: data block size (without header)
-        data_id: id which is used in the database
-        data_type (int): Type of data the data block contains:
-            * 0	LineSet	A list of vertices which get connected by line segments
-            * 1	Text	A position information and the actual text
-            * 2	PointList	A list of 3D points with color information (e.g. point cloud)
-            * 3	Mesh	A triangle mesh datastructure️
-            * 4	Image	A single of arbitrary format can be stored in this block
-            * 5	MaterialStandard	A standard (mesh) material definition
-            * 6	SceneNode	A wrapper around a data block which can be used in the scenegraph
-            * 7	Track	A track is a tracked position and orientation of an AR device
-        version_data: version for this data block
-
-    Returns:
-
-    """
-
-    input_ = [(data_type, 'uint16'),  # data type
-              (version_data, 'uint16'),  # version for this data block
-              (size_data, 'uint32'),  # data block size (without header)
-              (data_id, 'uint64')]  # id which is used in the database
-
-    block_bytes = encode(input_)
-    return block_bytes
-
-
-def write_mesh_header(n_vtx_coord, n_triangles,
-                      start_vtx_coord, start_nor_coord, start_tex_coord, start_vtx_colors,
-                      start_triangles,
-                      name, material_id=1,  # material_id=9223372036854775807
-                      n_nor_coord=0, n_tex_coord=0, n_vtx_colors=0,
-                      lod=1, max_lod=1):
-    """Function to write MESH DATA BLOCK header. The header size is fixed at 128 bytes.
-
-    Args:
-        n_vtx_coord: number of vertex coordinates
-        n_triangles: number of triangles
-        start_vtx_coord: start vertex coordinate block (relative to mesh block start)
-        start_nor_coord: start vertex normals block (relative to mesh block start)
-        start_tex_coord: start of texture coordinate block (relative to mesh block start)
-        start_vtx_colors: start of colors block (relative to mesh block start)
-        start_triangles: start triangle block for vertices (relative to mesh block start)
-        name (str): Name of the mesh
-        material_id (int):  id which refers to the corresponding material block in this file
-        n_nor_coord:  number of normal coordinates (can be zero)
-        n_tex_coord:  number of texture coordinates (can be zero)
-        n_vtx_colors: number of vertex colors (can be zero)
-        lod (int): level of detail for the given geometry
-        max_lod (int): maximal level of detail for given geometry
-
-    Returns:
-        bytes: array of bytes
-    """
-
-    # Strings are immutable so there is no way to modify them in place
-    str_size = len(name)  # Size of the actual name of the mesh
-    rest_name = ' ' * (74 - str_size)  #
-    full_name = name + rest_name
-
-    input_ = [([lod, max_lod], 'uint16'),  # Level of detail
-              ([n_vtx_coord,  # number of vertex coordinates
-                n_nor_coord,  # number of normal coordinates (can be zero)
-                n_tex_coord,  # number of texture coordinates (can be zero)
-                n_vtx_colors,  # number of vertex colors (can be zero)
-                n_triangles,  # number of triangles
-                start_vtx_coord,  # start vertex coordinate block (relative to mesh block start)
-                start_nor_coord,  # start vertex normals block (relative to mesh block start)
-                start_tex_coord,  # start of texture coordinate block (relative to mesh block start)
-                start_vtx_colors,  # start of colors block (relative to mesh block start)
-                start_triangles  # start triangle block for vertices (relative to mesh block start)
-                ],
-               'uint32'),
-              (material_id, 'uint64'),
-              # id which refers to the corresponding material block in this file
-              (str_size, 'uint16'),  # size of the following string name
-              (full_name, 'bytes')]  # name of the mesh (this is user-readable)
-
-    block_bytes = encode(input_)
-    return block_bytes
-
-
-def write_mesh_coordinates(vertex, triangles, normal=None, texture=None, colors=None):
-    """Block with the coordinates of a mesh. This has to go with a header!
-
-    Args:
-        vertex (numpy.ndarray[float32]): Array of vertex XYZXYZ...
-        triangles (numpy.ndarray[int32]): This is a list of integers which form
-         one triangle. Please make sure that normal and texture coordinates are inline with the
-         vertex coordinates. One index refers to the same normal and texture position. The
-         triangle orientation is required to be counter-clockwise (CCW)
-        normal (numpy.ndarray):
-        texture (numpy.ndarray):
-        colors (numpy.ndarray):
-
-    Returns:
-
-    """
-
-    ver = vertex.ravel()
-    tri = triangles.ravel()
-    if normal is None:
-        normal = []
-    if texture is None:
-        texture = []
-    if colors is None:
-        colors = []
-
-    input_ = [(ver, 'float32'),
-              (normal, 'float32'),
-              (texture, 'float32'),
-              (colors, 'float32'),
-              (tri, 'uint32')]
-
-    block_bytes = encode(input_)
-    return block_bytes
-
-
-def write_material_data(ka_red=255.0 / 255, ka_green=255.0 / 255, ka_blue=255.0 / 255,
-                        ka_texture_ID=9223372036854775807,  # ambient
-                        ks_red=255.0 / 255, ks_green=255.0 / 255, ks_blue=255.0 / 255,
-                        ks_texture_ID=9223372036854775807,  # specular
-                        kd_red=255.0 / 255, kd_green=255.0 / 255, kd_blue=255.0 / 255,
-                        kd_texture_ID=9223372036854775807,  # diffuse
-                        ns=0.1,  # specular exponent
-                        alpha=1  # opacity
-                        ):
-    """Writes a standard material definition block
-
-    Returns: bytes (size:68) representation of the material
-
-    """
-
-    input_ = [(ka_red, 'float32'), (ka_green, 'float32'), (ka_blue, 'float32'),
-              (ka_texture_ID, 'uint64'),
-              (ks_red, 'float32'), (ks_green, 'float32'), (ks_blue, 'float32'),
-              (ks_texture_ID, 'uint64'),
-              (kd_red, 'float32'), (kd_green, 'float32'), (kd_blue, 'float32'),
-              (kd_texture_ID, 'uint64'),
-              (ns, 'float32'), (alpha, 'float32')]
-
-    block_bytes = encode(input_)
-    return block_bytes
-
-
-# TODO Move to utils
-def hex_to_rgb(hex):
-    """Transform colors from hex to rgb"""
-    hex = hex.lstrip('#')
-    hlen = len(hex)
-    return tuple(int(hex[i:i + hlen // 3], 16) for i in range(0, hlen, hlen // 3))
-
-
-def geomodel_to_rex(geo_model, backside=True):
-    """
-
-    Args:
-        geo_model (gempy.Model):
-    """
-
-    # Fixed sizes
-    mesh_header_size = 128
-    file_header_size = 86
-
-    # Init dict
-    rex_bytes = {}
-
-    # Check if surfaces are computed
-    try:
-        # Drop basement
-        surface_df = geo_model._surfaces.df.groupby(
-            ['isActive', 'isBasement']).get_group((True, False))
-    except (IndexError, KeyError):
-        raise RuntimeError('No computed surfaces yet.')
-
-    # Loop surfaces
-    for idx, surface_vals in surface_df.iterrows():
-        ver = surface_vals['vertices']
-        tri = surface_vals['edges']
-        if tri is np.nan:
-            break
-
-        # Grab surface color
-        col = surface_vals['color']
-
-        # Give color to each vertex
-        colors = (np.zeros_like(ver) + hex_to_rgb(col)) / 255
-
-        # This depends. For RexViewer we need to flip XYZ. For GemPlay not really
-        ver_ = np.copy(ver)
-        ver_[:, 2] = ver[:, 1]
-        ver_[:, 1] = ver[:, 2]
-        # ----------------
-
-        # Coping triangles to create the backside normal of the layers
-        tri_ = np.copy(tri)
-
-        # Preprocessing GemPy output
-        ver_ravel, tri_ravel, n_vtx_coord, n_triangles = mesh_preprocess(ver_, tri_)
-
-        # Calculate the size of the mesh block
-        if backside is True:
-            n_sides = 2
-        else:
-            n_sides = 1
-
-        mesh_block_size_no_data_block_header = (2 *  # Coordinates and colors
-                                                n_vtx_coord + n_triangles) * 4 + \
-                                               mesh_header_size  # This is cte 128
-
-        # Size of a MATERIAL DATA BLOCK is cte
-        material_block_size_no_data_block_header = 68
-
-        # Write file header
-        if backside is True:
-            n_data_blocks = 3
-        else:
-            n_data_blocks = 2
-        header_bytes = write_file_header_block(n_data_blocks=n_data_blocks,
-                                               size_data_blocks=
-                                               n_sides * mesh_block_size_no_data_block_header +
-                                               rexDataBlockHeaderSize +
-                                               material_block_size_no_data_block_header,
-                                               start_data=file_header_size)
-
-        # Write data block header for Mesh 1
-        data_bytes = write_data_block_header(size_data=mesh_block_size_no_data_block_header,
-                                             data_id=1, data_type=3, version_data=1)
-
-        # Write Mesh 1 block - header
-        mesh_header_bytes = write_mesh_header(n_vtx_coord / 3, n_triangles / 3,
-                                              n_vtx_colors=n_vtx_coord / 3,
-                                              start_vtx_coord=mesh_header_size,
-                                              start_nor_coord=mesh_header_size + n_vtx_coord * 4,
-                                              start_tex_coord=mesh_header_size + n_vtx_coord * 4,
-                                              start_vtx_colors=mesh_header_size + n_vtx_coord * 4,
-                                              start_triangles=mesh_header_size + 2 *
-                                                              (n_vtx_coord * 4),
-                                              name='rock1', material_id=0)
-
-        # Write Mesh 1 block - header
-        mesh_block_bytes = write_mesh_coordinates(ver_ravel, tri_ravel, colors=colors.ravel())
-
-        if backside:
-            # Write data block header for Mesh 2
-            data_bytes_r = write_data_block_header(size_data=mesh_block_size_no_data_block_header,
-                                                   data_id=2, data_type=3, version_data=1)
-
-            # TURN normals - One side of the normals
-            tri_[:, 2] = tri[:, 1]
-            tri_[:, 1] = tri[:, 2]
-
-            ver_ravel, tri_ravel, n_vtx_coord, n_triangles = mesh_preprocess(ver_, tri_)
-
-            # Write Mesh 2 block - header
-            mesh_header_bytes_r = write_mesh_header(n_vtx_coord / 3, n_triangles / 3,
-                                                    n_vtx_colors=n_vtx_coord / 3,
-                                                    start_vtx_coord=mesh_header_size,
-                                                    start_nor_coord=mesh_header_size + n_vtx_coord * 4,
-                                                    start_tex_coord=mesh_header_size + n_vtx_coord * 4,
-                                                    start_vtx_colors=mesh_header_size + n_vtx_coord * 4,
-                                                    start_triangles=mesh_header_size + 2 *
-                                                                    (n_vtx_coord * 4),
-                                                    name='test_a', material_id=0)
-
-            # Write Mesh 2 block - header
-            mesh_block_bytes_r = write_mesh_coordinates(ver_ravel, tri_ravel,
-                                                        colors=colors.ravel())
-
-        # Write data block header for Material 1
-        material_header_bytes = write_data_block_header(data_type=5, version_data=1, size_data=68,
-                                                        data_id=0)
-
-        # Write Material 1
-        material_bytes = write_material_data()
-
-        # Putting all data together
-        if backside is True:
-            all_bytes = header_bytes + data_bytes + mesh_header_bytes + mesh_block_bytes + \
-                        data_bytes_r + mesh_header_bytes_r + mesh_block_bytes_r + \
-                        material_header_bytes + material_bytes
-
-        else:
-            all_bytes = header_bytes + data_bytes + mesh_header_bytes + mesh_block_bytes + \
-                        material_header_bytes + material_bytes
-
-        # FOR REXView Saving each surface is a rexfile
-        rex_bytes[surface_vals['surface']] = all_bytes
-    return rex_bytes
-
-
-def mesh_preprocess(ver, tri):
-    """Prepare GemPy Output to be converted to rex
-
-    Args:
-        ver (numpy.ndarray):
-        tri (numpy.ndarray):
-
-    Returns:
-        list: vertices raveled, triangels ravel, n vertex, n triangles
-    """
-
-    # TODO: Remove the type transform. Technically it does nothing
-    ver_ravel = ver.ravel().astype('float32')
-    tri_ravel = tri.ravel().astype('int32')
-    n_vtx_coord = ver_ravel.shape[0]
-    n_triangles = tri_ravel.shape[0]
-    return ver_ravel, tri_ravel, n_vtx_coord, n_triangles
-
-
-def write_file(bytes, path: str):
-    """Write to disk a rexfile from its binary format"""
-
-    newFile = open(path + ".rex", "wb")
-    newFile.write(bytes)
-    return True
-
-
-def write_rex(rex_bytes: dict, path='./gempy_rex'):
-    file_names = []
-    e = 0
-    for key, value in rex_bytes.items():
-        file_name = path + key
-        write_file(value, file_name)
-        file_names.append(file_name + '.rex')
-        e += 1
-
-    return file_names
+"""
+This file is part of gempy.
+
+Created on 21/02/2020
+
+@author: Miguel de la Varga
+"""
+
+import numpy as np
+import matplotlib.colors as mcolors
+import pandas as pd
+
+rexFileHeaderSize = 64
+rexCoordSize = 22
+
+file_header_size = 86
+rexDataBlockHeaderSize = 16
+
+file_header_and_data_header = 102
+mesh_header_size = 128
+all_header_size = 230
+
+# Supported block types
+# typeLineSet = 0
+# typeText = 1
+# typePointList = 2
+typeMesh = 3
+# typeImage = 4
+# typeMaterial = 5
+# typePeopleSimulation = 6
+# typeUnityPackage = 7
+# typeSceneNode = 8
+
+
+n_bytes = 0
+
+
+class GemPyToRex:
+    def __init__(self, geo_model=None):
+        """Writes GemPy data structures into binary Rex
+
+         https://github.com/roboticeyes/openrex/blob/master/doc/rex-spec-v1.md
+        """
+        self.rex_bytes = bytearray()
+        self.n_bytes = 0
+
+        self.data_id = 0
+        self.geo_model = geo_model
+
+    def __call__(self, geo_model=None, meshes=True, material=True,
+                 surfaces=None, topography=True, app='GemPlay'):
+        """
+
+        Args:
+            meshes:
+            surfaces (list): Subset of surfaces to send to the client
+            app (str): Either RexViewer or GemPlay. Set of default values
+
+        Returns:
+
+        """
+
+        byte_array = bytearray()
+        byte_size = 0
+        self.data_id = 0
+
+        if geo_model is None:
+            geo_model = self.geo_model
+        else:
+            self.geo_model = geo_model
+
+        if surfaces is not None:
+            raise NotImplementedError
+
+        flip_yz, backside, vertex_color = self.default_values(app)
+        # flip_yz, backside, vertex_color = False, True, False
+
+        surface_df = self.grab_meshes(geo_model)
+        if topography:
+            topography_dict = self.grab_topography(geo_model)
+        else:
+            topography_dict = None
+
+        # Data Blocks
+        # -----------
+        if material is True:
+            # Material
+            byte_array += self.gempy_color_to_rex_material(surface_df, topography)
+
+        if meshes is True:
+            # Mesh
+            byte_array += self.gempy_meshes_to_rex(
+                surface_df,
+                topography_dict=topography_dict,
+                flip_yz=flip_yz,
+                backside=backside,
+                vertex_color=vertex_color)
+
+        # Size of all data blocks together
+        byte_size += len(byte_array)
+
+        # Write file header
+        # -----------------
+        n_data_blocks = self.data_id
+
+        header_bytes = write_file_header_block(
+            n_data_blocks=n_data_blocks,
+            size_data_blocks=byte_size,
+            start_data=file_header_size)
+
+        return header_bytes + byte_array
+
+    @staticmethod
+    def grab_meshes(geo_model):
+        """Check if surfaces are computed. And return a pandas.DataFrame with
+         the meshes to be converted
+
+        Args:
+            geo_model:
+
+        Returns:
+
+        """
+
+        try:
+            # Drop basement
+            surface_df = geo_model._surfaces.df.groupby(
+                ['isActive', 'isBasement']).get_group((True, False))
+        except (IndexError, KeyError):
+            raise RuntimeError('No computed surfaces yet.')
+
+        return surface_df[['surface', 'vertices', 'edges', 'color']]
+
+    @staticmethod
+    def grab_topography(geo_model):
+        from scipy.spatial import Delaunay
+
+        if geo_model._grid.topography is None or geo_model._grid.topography.values.shape[0] == 0:
+            return None
+        else:
+            topography_dict = dict()
+            topography_dict['surface'] = "Topography"
+            topography_dict['vertices'] = geo_model._grid.topography.values
+            # tri = Delaunay(geo_model._grid.topography.values)
+            topography_dict['edges'] = Delaunay(geo_model._grid.topography.values[:, :2]).simplices
+            topography_dict['color'] = geo_model.solutions.geological_map
+
+            return topography_dict
+
+    @staticmethod
+    def hex_to_rgb(hex: str, normalize: bool = True) -> np.ndarray:
+        """Transform colors from hex to rgb"""
+        hex = hex.lstrip('#')
+        hlen = len(hex)
+        rgb = np.array([int(hex[i:i + hlen // 3], 16) for i in range(0, hlen, hlen // 3)])
+        if normalize is True:
+            rgb = rgb / 255
+        return rgb
+
+    @staticmethod
+    def default_values(app):
+        """
+
+        Args:
+            app:
+
+        Returns:
+            list: flip_yz, backside, vertex_color
+        """
+        if app == 'GemPlay':
+            return (False, True, False)
+        elif app == 'RexView':
+            return (True, True, True)
+        else:
+            raise AttributeError('app must be either GemPlay or RexView')
+
+    def gempy_meshes_to_rex(self,
+                            surface_df,
+                            topography_dict=None,
+                            flip_yz=False,
+                            backside=True,
+                            vertex_color=False):
+        """Write mesh to Rexfile.
+
+        Args:
+            surface_df:
+            topography_dict:
+            flip_yz: Fliping YZ coordinates. Rexview need this
+            backside: If True, create a second set of triangles on the backside of the mesh
+            vertex_color
+
+        Returns:
+
+        Notes:
+            At the moment 14.07.2020 it is not possible to write normals or texture
+
+        """
+        rex_bytes = bytearray()
+        mesh_number = 0
+
+        # Loop geological surfaces surfaces
+        for idx, surface_vals in surface_df.iterrows():
+
+            tri = surface_vals['edges']
+            if tri is np.nan:
+                continue
+
+            ver = surface_vals['vertices']
+            surface_name = surface_vals['surface']
+            if vertex_color:
+                # Hex Colors
+                col_ = surface_vals['color']
+            else:
+                col_ = None
+
+            rex_bytes = self.mesh_prepare_and_encode(rex_bytes, mesh_number, ver, tri,
+                                                     surface_name, col_=col_,
+                                                     flip_yz=flip_yz, backside=backside,
+                                                     vertex_color=False)
+            mesh_number += 1
+
+        # Add topography
+        if topography_dict is not None:
+
+            rex_bytes = self.mesh_prepare_and_encode(rex_bytes, n_surface=-1,
+                                                     ver=topography_dict['vertices'],
+                                                     tri=topography_dict['edges'],
+                                                     surface_name=topography_dict['surface'],
+                                                     col_=topography_dict['color'],
+                                                     flip_yz=flip_yz, backside=backside,
+                                                     vertex_color=True)
+
+        return rex_bytes
+
+    def mesh_prepare_and_encode(self, rex_bytes, n_surface, ver, tri, surface_name, col_=None, \
+                                flip_yz=False,
+                                backside=True,
+                                vertex_color=False):
+
+        if flip_yz:
+            # This depends. For RexViewer we need to flip XYZ. For GemPlay not really
+            ver_ = np.copy(ver)
+            ver[:, 2] = ver_[:, 1]
+            ver[:, 1] = ver_[:, 2]
+
+        # Pre-processing GemPy output
+        ver_ravel, tri_ravel, n_vtx_coord, n_triangles = mesh_preprocess(ver, tri)
+
+        # Number of vertex colors
+        if vertex_color:
+            n_vtx_colors = n_vtx_coord
+
+            # Give color to each vertex
+            # TODO: Is this necessary if I pass a material
+            if type(col_) is str:
+                colors = np.zeros_like(ver) + self.hex_to_rgb(col_, normalize=True)
+                c_r = colors.ravel()
+
+            elif type(col_) is np.ndarray:
+                surf_df = self.geo_model._surfaces.df.set_index('id')
+                colors_hex = surf_df.groupby(
+                    ['isActive', 'isFault']).get_group((True, False))['color']
+
+                colors_rgb_ = colors_hex.apply(lambda val: list(mcolors.hex2color(val)))
+                colors_rgb = pd.DataFrame(colors_rgb_.to_list(), index=colors_hex.index)
+
+                sel = np.round(col_[0]).astype(int)[0]
+                c_r = colors_rgb.loc[sel].values.ravel()
+            else:
+                raise AttributeError("col_ must be either hex string or rgb array")
+        else:
+            n_vtx_colors = 0
+            c_r = None
+
+        rex_bytes = self._mesh_encode(
+            rex_bytes, n_surface,
+            n_vtx_coord, n_triangles, n_vtx_colors,
+            surface_name, ver_ravel, tri_ravel, c_r)
+
+        if backside:
+            # Coping triangles to create the backside normal of the layers
+            tri_ = np.copy(tri)
+            # TURN normals - One side of the normals
+            tri_[:, 2] = tri[:, 1]
+            tri_[:, 1] = tri[:, 2]
+            # Pre-processing GemPy output
+            ver_ravel, tri_ravel, n_vtx_coord, n_triangles = mesh_preprocess(ver, tri_)
+            # tri = np.append(tri, tri_)
+
+            rex_bytes = self._mesh_encode(
+                rex_bytes, n_surface,
+                n_vtx_coord, n_triangles, n_vtx_colors,
+                surface_name, ver_ravel, tri_ravel, c_r)
+
+        return rex_bytes
+
+    def _mesh_encode(self, rex_bytes, material_id,
+                     n_vtx_coord, n_triangles, n_vtx_colors,
+                     surface_name, ver_ravel, tri_ravel, c_r):
+        # Write Mesh block - header
+        mesh_header_bytes = write_mesh_header(
+            n_vtx_coord / 3, n_triangles / 3,
+            n_vtx_colors=n_vtx_colors / 3,
+            start_vtx_coord=mesh_header_size,
+            start_nor_coord=mesh_header_size + n_vtx_coord * 4,
+            start_tex_coord=mesh_header_size + n_vtx_coord * 4,
+            start_vtx_colors=mesh_header_size + n_vtx_coord * 4,
+            start_triangles=mesh_header_size +
+                            ((n_vtx_coord + n_vtx_colors) * 4),
+            name=surface_name,
+            material_id=material_id  # self.data_id + surface_df.shape[0]
+        )
+
+        # Write Mesh block - Vertex, triangles
+        mesh_block_bytes = write_mesh_coordinates(ver_ravel, tri_ravel,
+                                                  colors=c_r  # When using
+                                                  # material we can avoid this
+                                                  )
+
+        # Calculate the size of the mesh block
+        mesh_block_size_no_data_block_header = len(mesh_header_bytes) + \
+                                               len(mesh_block_bytes)  # This is cte 128
+
+        # Write data block header for Mesh 1
+        data_header_bytes = write_data_block_header(
+            size_data=mesh_block_size_no_data_block_header,
+            data_id=self.data_id,
+            data_type=3,  # 3 for mesh
+            version_data=1  # Probably useful for counting
+            # the operation number
+        )
+        self.data_id += 1
+        rex_bytes += data_header_bytes + mesh_header_bytes + mesh_block_bytes
+
+        return rex_bytes
+
+    def gempy_color_to_rex_material(self, surface_df, topography=False):
+        rex_bytes = bytearray()
+
+        for idx, surface_vals in surface_df.iterrows():
+            # Write data block header for Material 1
+            data_header_bytes = write_data_block_header(
+                data_type=5,  # Material data type
+                version_data=1,  # Version. Probably useful for operation counter
+                size_data=68,  # Size of the block is FIXED
+                data_id=self.data_id  # self.data_id
+            )
+            self.data_id += 1
+
+            rgb_color = self.hex_to_rgb(surface_vals['color'], normalize=True)
+            # rgb_color = [1, 1, 1]
+            # Write Material
+            material_bytes = write_material_data(
+                ka_red=rgb_color[0], ka_green=rgb_color[1], ka_blue=rgb_color[2],
+                ka_texture_ID=9223372036854775807,  # ambient
+                ks_red=rgb_color[0], ks_green=rgb_color[1], ks_blue=rgb_color[2],
+                ks_texture_ID=9223372036854775807,  # specular
+                kd_red=rgb_color[0], kd_green=rgb_color[1], kd_blue=rgb_color[2],
+                kd_texture_ID=9223372036854775807,  # diffuse
+                ns=0.1,  # specular exponent
+                alpha=1  # opacity
+            )
+
+            rex_bytes += data_header_bytes + material_bytes
+
+        if topography is True:
+            # Write data block header for Material 1
+            data_header_bytes = write_data_block_header(
+                data_type=5,  # Material data type
+                version_data=1,  # Version. Probably useful for operation counter
+                size_data=68,  # Size of the block is FIXED
+                data_id=-1  # self.data_id
+            )
+
+            rgb_color = [1, 1, 1]
+            # Write Material
+            material_bytes = write_material_data(
+                ka_red=rgb_color[0], ka_green=rgb_color[1], ka_blue=rgb_color[2],
+                ka_texture_ID=9223372036854775807,  # ambient
+                ks_red=rgb_color[0], ks_green=rgb_color[1], ks_blue=rgb_color[2],
+                ks_texture_ID=9223372036854775807,  # specular
+                kd_red=rgb_color[0], kd_green=rgb_color[1], kd_blue=rgb_color[2],
+                kd_texture_ID=9223372036854775807,  # diffuse
+                ns=0.1,  # specular exponent
+                alpha=1  # opacity
+            )
+
+            self.data_id += 1
+            rex_bytes += data_header_bytes + material_bytes
+
+        return rex_bytes
+
+
+def encode(input_: list):
+    """Encode python objects - normally Python primitives or numpy arrays - into
+    its correspondent byte representation
+
+    Args:
+        input_ (List[tuples]): List of tuples: (object, type)
+
+    Returns:
+        byte: Array of bytes
+    """
+    global n_bytes
+    block = bytearray()
+
+    for tup in input_:
+        arr = np.array(tup[0], dtype=tup[1]).tobytes()
+        n_bytes += len(arr)
+        block += arr
+
+    return block
+
+
+def write_file_header_block(n_data_blocks, size_data_blocks, version=1,
+                            start_data=86, srid=3876, offsets=None):
+    """
+    Function that writes the header block of a rexfile:
+
+    Args:
+        n_data_blocks:
+        size_data_blocks:
+        version (int): Version of the file
+        start_data (int): Position where data start. This is after the header
+         and coordinate system. If everything works fine it should be 86
+        srid (int): Spatial reference system identifier (srid)
+        offsets:
+
+    Returns:
+
+    """
+    reserved = '0' * 42
+    if offsets is None:
+        offsets = [0, 0, 0]
+
+    input_ = [('REX1', 'bytes'),  # REX1
+              (version, 'uint16'),  # file version
+              (0, 'uint32'),  # CRC32
+              (n_data_blocks, 'uint16'),  # Number of DATA BLOCKS
+              (start_data, 'uint16'),  # StartData
+              (size_data_blocks, 'uint64'),  # Size of all data blocks
+              (reserved, 'bytes'),  # Reserved
+              # Coordinate system block
+              (srid, 'uint32'),  # Spatial reference system identifier (srid)
+              (4, 'uint16'),  # Size of the name of the used system.
+              ('EPSG', 'bytes'),  # name of the used system.
+              (offsets, 'float32')]  # Global x, y, z offset
+
+    block_bytes = encode(input_)
+    return block_bytes
+
+
+def write_data_block_header(size_data, data_id=1, data_type=3, version_data=1):
+    """Function to write a DATA BLOCK header.
+
+    Args:
+        size_data: data block size (without header)
+        data_id: id which is used in the database
+        data_type (int): Type of data the data block contains:
+            * 0	LineSet	A list of vertices which get connected by line segments
+            * 1	Text	A position information and the actual text
+            * 2	PointList	A list of 3D points with color information (e.g. point cloud)
+            * 3	Mesh	A triangle mesh datastructure️
+            * 4	Image	A single of arbitrary format can be stored in this block
+            * 5	MaterialStandard	A standard (mesh) material definition
+            * 6	SceneNode	A wrapper around a data block which can be used in the scenegraph
+            * 7	Track	A track is a tracked position and orientation of an AR device
+        version_data: version for this data block
+
+    Returns:
+
+    """
+
+    input_ = [(data_type, 'uint16'),  # data type
+              (version_data, 'uint16'),  # version for this data block
+              (size_data, 'uint32'),  # data block size (without header)
+              (data_id, 'uint64')]  # id which is used in the database
+
+    block_bytes = encode(input_)
+    return block_bytes
+
+
+def write_mesh_header(n_vtx_coord, n_triangles,
+                      start_vtx_coord, start_nor_coord, start_tex_coord, start_vtx_colors,
+                      start_triangles,
+                      name, material_id=1,  # material_id=9223372036854775807
+                      n_nor_coord=0, n_tex_coord=0, n_vtx_colors=0,
+                      lod=1, max_lod=1):
+    """Function to write MESH DATA BLOCK header. The header size is fixed at 128 bytes.
+
+    Args:
+        n_vtx_coord: number of vertex coordinates
+        n_triangles: number of triangles
+        start_vtx_coord: start vertex coordinate block (relative to mesh block start)
+        start_nor_coord: start vertex normals block (relative to mesh block start)
+        start_tex_coord: start of texture coordinate block (relative to mesh block start)
+        start_vtx_colors: start of colors block (relative to mesh block start)
+        start_triangles: start triangle block for vertices (relative to mesh block start)
+        name (str): Name of the mesh
+        material_id (int):  id which refers to the corresponding material block in this file
+        n_nor_coord:  number of normal coordinates (can be zero)
+        n_tex_coord:  number of texture coordinates (can be zero)
+        n_vtx_colors: number of vertex colors (can be zero)
+        lod (int): level of detail for the given geometry
+        max_lod (int): maximal level of detail for given geometry
+
+    Returns:
+        bytes: array of bytes
+    """
+
+    # Strings are immutable so there is no way to modify them in place
+    str_size = len(name)  # Size of the actual name of the mesh
+    rest_name = ' ' * (74 - str_size)  #
+    full_name = name + rest_name
+
+    input_ = [([lod, max_lod], 'uint16'),  # Level of detail
+              ([n_vtx_coord,  # number of vertex coordinates
+                n_nor_coord,  # number of normal coordinates (can be zero)
+                n_tex_coord,  # number of texture coordinates (can be zero)
+                n_vtx_colors,  # number of vertex colors (can be zero)
+                n_triangles,  # number of triangles
+                start_vtx_coord,  # start vertex coordinate block (relative to mesh block start)
+                start_nor_coord,  # start vertex normals block (relative to mesh block start)
+                start_tex_coord,  # start of texture coordinate block (relative to mesh block start)
+                start_vtx_colors,  # start of colors block (relative to mesh block start)
+                start_triangles  # start triangle block for vertices (relative to mesh block start)
+                ],
+               'uint32'),
+              (material_id, 'uint64'),
+              # id which refers to the corresponding material block in this file
+              (str_size, 'uint16'),  # size of the following string name
+              (full_name, 'bytes')]  # name of the mesh (this is user-readable)
+
+    block_bytes = encode(input_)
+    return block_bytes
+
+
+def write_mesh_coordinates(vertex, triangles, normal=None, texture=None, colors=None):
+    """Block with the coordinates of a mesh. This has to go with a header!
+
+    Args:
+        vertex (numpy.ndarray[float32]): Array of vertex XYZXYZ...
+        triangles (numpy.ndarray[int32]): This is a list of integers which form
+         one triangle. Please make sure that normal and texture coordinates are inline with the
+         vertex coordinates. One index refers to the same normal and texture position. The
+         triangle orientation is required to be counter-clockwise (CCW)
+        normal (numpy.ndarray):
+        texture (numpy.ndarray):
+        colors (numpy.ndarray):
+
+    Returns:
+
+    """
+
+    ver = vertex.ravel()
+    tri = triangles.ravel()
+    if normal is None:
+        normal = []
+    if texture is None:
+        texture = []
+    if colors is None:
+        colors = []
+
+    input_ = [(ver, 'float32'),
+              (normal, 'float32'),
+              (texture, 'float32'),
+              (colors, 'float32'),
+              (tri, 'uint32')]
+
+    block_bytes = encode(input_)
+    return block_bytes
+
+
+def write_material_data(ka_red=255.0 / 255, ka_green=255.0 / 255, ka_blue=255.0 / 255,
+                        ka_texture_ID=9223372036854775807,  # ambient
+                        ks_red=255.0 / 255, ks_green=255.0 / 255, ks_blue=255.0 / 255,
+                        ks_texture_ID=9223372036854775807,  # specular
+                        kd_red=255.0 / 255, kd_green=255.0 / 255, kd_blue=255.0 / 255,
+                        kd_texture_ID=9223372036854775807,  # diffuse
+                        ns=0.1,  # specular exponent
+                        alpha=1  # opacity
+                        ):
+    """Writes a standard material definition block
+
+    Returns: bytes (size:68) representation of the material
+
+    """
+
+    input_ = [(ka_red, 'float32'), (ka_green, 'float32'), (ka_blue, 'float32'),
+              (ka_texture_ID, 'uint64'),
+              (ks_red, 'float32'), (ks_green, 'float32'), (ks_blue, 'float32'),
+              (ks_texture_ID, 'uint64'),
+              (kd_red, 'float32'), (kd_green, 'float32'), (kd_blue, 'float32'),
+              (kd_texture_ID, 'uint64'),
+              (ns, 'float32'), (alpha, 'float32')]
+
+    block_bytes = encode(input_)
+    return block_bytes
+
+
+# TODO Move to utils
+def hex_to_rgb(hex):
+    """Transform colors from hex to rgb"""
+    hex = hex.lstrip('#')
+    hlen = len(hex)
+    return tuple(int(hex[i:i + hlen // 3], 16) for i in range(0, hlen, hlen // 3))
+
+
+def geomodel_to_rex(geo_model, backside=True):
+    """
+
+    Args:
+        geo_model (gempy.Model):
+    """
+
+    # Fixed sizes
+    mesh_header_size = 128
+    file_header_size = 86
+
+    # Init dict
+    rex_bytes = {}
+
+    # Check if surfaces are computed
+    try:
+        # Drop basement
+        surface_df = geo_model._surfaces.df.groupby(
+            ['isActive', 'isBasement']).get_group((True, False))
+    except (IndexError, KeyError):
+        raise RuntimeError('No computed surfaces yet.')
+
+    # Loop surfaces
+    for idx, surface_vals in surface_df.iterrows():
+        ver = surface_vals['vertices']
+        tri = surface_vals['edges']
+        if tri is np.nan:
+            break
+
+        # Grab surface color
+        col = surface_vals['color']
+
+        # Give color to each vertex
+        colors = (np.zeros_like(ver) + hex_to_rgb(col)) / 255
+
+        # This depends. For RexViewer we need to flip XYZ. For GemPlay not really
+        ver_ = np.copy(ver)
+        ver_[:, 2] = ver[:, 1]
+        ver_[:, 1] = ver[:, 2]
+        # ----------------
+
+        # Coping triangles to create the backside normal of the layers
+        tri_ = np.copy(tri)
+
+        # Preprocessing GemPy output
+        ver_ravel, tri_ravel, n_vtx_coord, n_triangles = mesh_preprocess(ver_, tri_)
+
+        # Calculate the size of the mesh block
+        if backside is True:
+            n_sides = 2
+        else:
+            n_sides = 1
+
+        mesh_block_size_no_data_block_header = (2 *  # Coordinates and colors
+                                                n_vtx_coord + n_triangles) * 4 + \
+                                               mesh_header_size  # This is cte 128
+
+        # Size of a MATERIAL DATA BLOCK is cte
+        material_block_size_no_data_block_header = 68
+
+        # Write file header
+        if backside is True:
+            n_data_blocks = 3
+        else:
+            n_data_blocks = 2
+        header_bytes = write_file_header_block(n_data_blocks=n_data_blocks,
+                                               size_data_blocks=
+                                               n_sides * mesh_block_size_no_data_block_header +
+                                               rexDataBlockHeaderSize +
+                                               material_block_size_no_data_block_header,
+                                               start_data=file_header_size)
+
+        # Write data block header for Mesh 1
+        data_bytes = write_data_block_header(size_data=mesh_block_size_no_data_block_header,
+                                             data_id=1, data_type=3, version_data=1)
+
+        # Write Mesh 1 block - header
+        mesh_header_bytes = write_mesh_header(n_vtx_coord / 3, n_triangles / 3,
+                                              n_vtx_colors=n_vtx_coord / 3,
+                                              start_vtx_coord=mesh_header_size,
+                                              start_nor_coord=mesh_header_size + n_vtx_coord * 4,
+                                              start_tex_coord=mesh_header_size + n_vtx_coord * 4,
+                                              start_vtx_colors=mesh_header_size + n_vtx_coord * 4,
+                                              start_triangles=mesh_header_size + 2 *
+                                                              (n_vtx_coord * 4),
+                                              name='rock1', material_id=0)
+
+        # Write Mesh 1 block - header
+        mesh_block_bytes = write_mesh_coordinates(ver_ravel, tri_ravel, colors=colors.ravel())
+
+        if backside:
+            # Write data block header for Mesh 2
+            data_bytes_r = write_data_block_header(size_data=mesh_block_size_no_data_block_header,
+                                                   data_id=2, data_type=3, version_data=1)
+
+            # TURN normals - One side of the normals
+            tri_[:, 2] = tri[:, 1]
+            tri_[:, 1] = tri[:, 2]
+
+            ver_ravel, tri_ravel, n_vtx_coord, n_triangles = mesh_preprocess(ver_, tri_)
+
+            # Write Mesh 2 block - header
+            mesh_header_bytes_r = write_mesh_header(n_vtx_coord / 3, n_triangles / 3,
+                                                    n_vtx_colors=n_vtx_coord / 3,
+                                                    start_vtx_coord=mesh_header_size,
+                                                    start_nor_coord=mesh_header_size + n_vtx_coord * 4,
+                                                    start_tex_coord=mesh_header_size + n_vtx_coord * 4,
+                                                    start_vtx_colors=mesh_header_size + n_vtx_coord * 4,
+                                                    start_triangles=mesh_header_size + 2 *
+                                                                    (n_vtx_coord * 4),
+                                                    name='test_a', material_id=0)
+
+            # Write Mesh 2 block - header
+            mesh_block_bytes_r = write_mesh_coordinates(ver_ravel, tri_ravel,
+                                                        colors=colors.ravel())
+
+        # Write data block header for Material 1
+        material_header_bytes = write_data_block_header(data_type=5, version_data=1, size_data=68,
+                                                        data_id=0)
+
+        # Write Material 1
+        material_bytes = write_material_data()
+
+        # Putting all data together
+        if backside is True:
+            all_bytes = header_bytes + data_bytes + mesh_header_bytes + mesh_block_bytes + \
+                        data_bytes_r + mesh_header_bytes_r + mesh_block_bytes_r + \
+                        material_header_bytes + material_bytes
+
+        else:
+            all_bytes = header_bytes + data_bytes + mesh_header_bytes + mesh_block_bytes + \
+                        material_header_bytes + material_bytes
+
+        # FOR REXView Saving each surface is a rexfile
+        rex_bytes[surface_vals['surface']] = all_bytes
+    return rex_bytes
+
+
+def mesh_preprocess(ver, tri):
+    """Prepare GemPy Output to be converted to rex
+
+    Args:
+        ver (numpy.ndarray):
+        tri (numpy.ndarray):
+
+    Returns:
+        list: vertices raveled, triangels ravel, n vertex, n triangles
+    """
+
+    # TODO: Remove the type transform. Technically it does nothing
+    ver_ravel = ver.ravel().astype('float32')
+    tri_ravel = tri.ravel().astype('int32')
+    n_vtx_coord = ver_ravel.shape[0]
+    n_triangles = tri_ravel.shape[0]
+    return ver_ravel, tri_ravel, n_vtx_coord, n_triangles
+
+
+def write_file(bytes, path: str):
+    """Write to disk a rexfile from its binary format"""
+
+    newFile = open(path + ".rex", "wb")
+    newFile.write(bytes)
+    return True
+
+
+def write_rex(rex_bytes: dict, path='./gempy_rex'):
+    file_names = []
+    e = 0
+    for key, value in rex_bytes.items():
+        file_name = path + key
+        write_file(value, file_name)
+        file_names.append(file_name + '.rex')
+        e += 1
+
+    return file_names
```

### Comparing `gempy-2.2b10.dev1/gempy/addons/map2gempy.py` & `gempy-2.3.0/gempy/addons/map2gempy.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,213 +1,213 @@
-from typing import Iterable
-import gempy as gp
-import pandas as pd
-import numpy as np
-
-
-def loop2gempy(
-        contacts_file: str,
-        orientations_file: str,
-        bbox: Iterable,
-        groups_file: str,
-        model_base: float,
-        model_top: float, dtm_reproj_file: str = None,
-        faults_contact: str = None,
-        faults_orientations: str = None,
-        faults_faults_rel: str = None,
-        faults_groups_rel: str = None,
-        faults_rel_matrix = None,
-        model_name: str = None,
-        compute: bool = True,
-        vtk: bool = False,
-        vtk_path: str = None,
-        image_2d: bool = False,
-        plot_3d_kwargs=None
-):
-    """ Calculate the model using gempy as backend.
-
-        At the moment there is not support for finite faults since gempy does not
-         accept passing the ellipsoid parameters directly.
-
-        :param contacts_file (str): path of contacts file
-        :param orientations_file: path of orientations file
-        :param bbox: model bounding box
-        :param groups_file: path of groups file
-        :param model_base: z value of base of model
-        :param model_top: z value of top of model
-        :param dtm_reproj_file: path of dtm file
-        :param faults_contact: path of contacts file with fault data
-        :param faults_orientations: path of orientations file with fault data
-        :param faults_rel_matrix: bool matrix describing the interaction between groups. Rows offset columns
-        :param faults_groups_rel: bool matrix describing the interaction between faults and features
-        :param faults_faults_rel: bool matrix describing the interaction between faults and faults
-        :param model_name: name of the model
-        :param compute (bool): Default True. Whether or not compute the model
-        :param vtk (bool): Default False. Whether or not visualize the model
-        :param vtk_path (str): Default None. Path of vtk output directory
-        :param plot_3d_kwargs (dict): kwargs for `gempy.plot_3d`
-        :return: gempy.Project
-    """
-    if plot_3d_kwargs is None:
-        plot_3d_kwargs = {}
-
-    contacts = []
-    orientations = []
-
-    contacts.append(
-        pd.read_csv(
-            contacts_file,
-            sep=',',
-            names=['X', 'Y', 'Z', 'formation'],
-            header=1
-        )
-    )
-
-    if faults_contact is not None:
-        contacts.append(
-            pd.read_csv(
-                faults_contact,
-                sep=',',
-                names=['X', 'Y', 'Z', 'formation'],
-                header=1
-            )
-        )
-
-    orientations.append(
-        pd.read_csv(
-            orientations_file,
-            sep=',',
-            names=['X', 'Y', 'Z', 'azimuth', 'dip', 'polarity', 'formation'],
-            header=1
-        )
-    )
-
-    if faults_orientations is not None:
-        orientations.append(
-            pd.read_csv(
-                faults_orientations,
-                sep=',',
-                names=['X', 'Y', 'Z', 'azimuth', 'dip', 'polarity', 'formation'],
-                header=1
-            )
-        )
-
-    if faults_faults_rel is not None and faults_groups_rel is not None:
-        ff_ = pd.read_csv(faults_faults_rel).set_index('fault_id')
-        fg_ = pd.read_csv(faults_groups_rel).set_index('group')
-        p_ = pd.concat((ff_, fg_), axis=0, sort=True)
-        faults_rel_matrix = pd.concat((p_, fg_.T), axis=1, sort=True).fillna(0).values
-
-    surface_points_ready = pd.concat(contacts, sort=True)
-    surface_points_ready.reset_index(inplace=True, drop=False)
-    orientation_ready = pd.concat(orientations, sort=True)
-    orientation_ready.reset_index(inplace=True, drop=False)
-
-    if model_name is None:
-        model_name = 'loop2gempy'
-
-    geo_model = gp.create_model(model_name)
-    gp.init_data(
-        geo_model,
-        extent=[bbox[0], bbox[2], bbox[1], bbox[3], model_base, model_top],
-        resolution=[50, 50, 50],
-        orientations_df=orientation_ready,
-        surface_points_df=surface_points_ready
-    )
-
-    # Load Topology
-    if dtm_reproj_file is not None:
-        if type(dtm_reproj_file) is str:
-            source = 'gdal'
-            topo_kwarg = {'filepath': dtm_reproj_file}
-        elif type(dtm_reproj_file) is np.ndarray:
-            source = 'numpy'
-            topo_kwarg = {'array': dtm_reproj_file}
-        else:
-            raise AttributeError('dtm_proj_file must be either a path to gdal or a'
-                                 'numpy array with values')
-        geo_model.set_topography(source=source, **topo_kwarg)
-
-    # Stack Processing
-    contents = np.genfromtxt(groups_file, delimiter=',', dtype='U100')[1:, 4:-1]
-
-    map_series_to_surfaces = {}
-    for pair in contents:
-        map_series_to_surfaces.setdefault(pair[1], []).append(pair[0])
-
-    gp.map_stack_to_surfaces(geo_model, map_series_to_surfaces,
-                             remove_unused_series=False)
-
-    order_formations = geo_model.stack.df.index.drop('Default series')
-
-    # Get the unassigned series as faults
-    if faults_contact is not None and faults_orientations is not None:
-        faults_pair = geo_model._surfaces.df.groupby('series').get_group('Default series')[[
-            'surface']].values[:, 0]
-        faults_pair_dict = dict(zip(faults_pair, faults_pair))
-        gp.map_stack_to_surfaces(geo_model, faults_pair_dict, remove_unused_series=True)
-        # Grabbing the order of faults and Formations
-        ordered_features = np.append(faults_pair, order_formations)
-        # Sorting series
-        geo_model.reorder_features(ordered_features)
-        geo_model.set_is_fault(faults_pair)
-
-        # Faults relation
-        geo_model.set_fault_relation(faults_rel_matrix)
-
-    geo_model.add_surfaces('basement')
-
-    # Check if there is features without data and delete it
-    try:
-        f_ = geo_model.surfaces.df.groupby('isActive').get_group(False)
-        features_without_data = f_['series']
-        geo_model.delete_features(features_without_data, remove_surfaces=True, remove_data=True)
-    except KeyError:
-        pass
-
-    if faults_contact is not None and faults_orientations is not None:
-        get_fault_names = geo_model.stack.df.groupby(['isActive', 'isFault']).get_group(
-            (True, True)).index
-        geo_model._surfaces.colors.make_faults_black(get_fault_names)
-
-    try:
-        colours = pd.read_csv(groups_file).set_index('code')['colour']
-        # Drop formations that do not exist in surfaces
-        colours = colours.loc[colours.index.isin(geo_model.surfaces.df['surface'])].to_dict()
-
-        geo_model._surfaces.colors.change_colors(colours)
-    except KeyError:
-        pass
-
-    if compute is True:
-        gp.set_interpolator(geo_model, dtype='float64',
-                            # verbose=['solve_kriging']
-                            )
-
-        # Increasing nugget effect
-        geo_model.modify_surface_points(
-            geo_model.surface_points.df.index,
-            smooth=0.1
-        )
-
-        geo_model.modify_orientations(
-            geo_model.orientations.df.index,
-            smooth=0.01
-        )
-
-        new_range = geo_model.get_additional_data().loc[('Kriging', 'range'), 'values'] * 0.5
-        geo_model.modify_kriging_parameters('range', new_range)
-
-        gp.compute_model(geo_model)
-
-    if vtk is True:
-        gp.plot_3d(geo_model, show_topography=True,
-                   image=image_2d,
-                   show_lith=True,
-                   **plot_3d_kwargs
-                   )
-
-    if vtk_path is not None:
-        gp._plot.export_to_vtk(geo_model, path=vtk_path, name=model_name + '.vtk',
-                               voxels=False, block=None, surfaces=True)
-
+from typing import Iterable
+import gempy as gp
+import pandas as pd
+import numpy as np
+
+
+def loop2gempy(
+        contacts_file: str,
+        orientations_file: str,
+        bbox: Iterable,
+        groups_file: str,
+        model_base: float,
+        model_top: float, dtm_reproj_file: str = None,
+        faults_contact: str = None,
+        faults_orientations: str = None,
+        faults_faults_rel: str = None,
+        faults_groups_rel: str = None,
+        faults_rel_matrix = None,
+        model_name: str = None,
+        compute: bool = True,
+        vtk: bool = False,
+        vtk_path: str = None,
+        image_2d: bool = False,
+        plot_3d_kwargs=None
+):
+    """ Calculate the model using gempy as backend.
+
+        At the moment there is not support for finite faults since gempy does not
+         accept passing the ellipsoid parameters directly.
+
+        :param contacts_file (str): path of contacts file
+        :param orientations_file: path of orientations file
+        :param bbox: model bounding box
+        :param groups_file: path of groups file
+        :param model_base: z value of base of model
+        :param model_top: z value of top of model
+        :param dtm_reproj_file: path of dtm file
+        :param faults_contact: path of contacts file with fault data
+        :param faults_orientations: path of orientations file with fault data
+        :param faults_rel_matrix: bool matrix describing the interaction between groups. Rows offset columns
+        :param faults_groups_rel: bool matrix describing the interaction between faults and features
+        :param faults_faults_rel: bool matrix describing the interaction between faults and faults
+        :param model_name: name of the model
+        :param compute (bool): Default True. Whether or not compute the model
+        :param vtk (bool): Default False. Whether or not visualize the model
+        :param vtk_path (str): Default None. Path of vtk output directory
+        :param plot_3d_kwargs (dict): kwargs for `gempy.plot_3d`
+        :return: gempy.Project
+    """
+    if plot_3d_kwargs is None:
+        plot_3d_kwargs = {}
+
+    contacts = []
+    orientations = []
+
+    contacts.append(
+        pd.read_csv(
+            contacts_file,
+            sep=',',
+            names=['X', 'Y', 'Z', 'formation'],
+            header=1
+        )
+    )
+
+    if faults_contact is not None:
+        contacts.append(
+            pd.read_csv(
+                faults_contact,
+                sep=',',
+                names=['X', 'Y', 'Z', 'formation'],
+                header=1
+            )
+        )
+
+    orientations.append(
+        pd.read_csv(
+            orientations_file,
+            sep=',',
+            names=['X', 'Y', 'Z', 'azimuth', 'dip', 'polarity', 'formation'],
+            header=1
+        )
+    )
+
+    if faults_orientations is not None:
+        orientations.append(
+            pd.read_csv(
+                faults_orientations,
+                sep=',',
+                names=['X', 'Y', 'Z', 'azimuth', 'dip', 'polarity', 'formation'],
+                header=1
+            )
+        )
+
+    if faults_faults_rel is not None and faults_groups_rel is not None:
+        ff_ = pd.read_csv(faults_faults_rel).set_index('fault_id')
+        fg_ = pd.read_csv(faults_groups_rel).set_index('group')
+        p_ = pd.concat((ff_, fg_), axis=0, sort=True)
+        faults_rel_matrix = pd.concat((p_, fg_.T), axis=1, sort=True).fillna(0).values
+
+    surface_points_ready = pd.concat(contacts, sort=True)
+    surface_points_ready.reset_index(inplace=True, drop=False)
+    orientation_ready = pd.concat(orientations, sort=True)
+    orientation_ready.reset_index(inplace=True, drop=False)
+
+    if model_name is None:
+        model_name = 'loop2gempy'
+
+    geo_model = gp.create_model(model_name)
+    gp.init_data(
+        geo_model,
+        extent=[bbox[0], bbox[2], bbox[1], bbox[3], model_base, model_top],
+        resolution=[50, 50, 50],
+        orientations_df=orientation_ready,
+        surface_points_df=surface_points_ready
+    )
+
+    # Load Topology
+    if dtm_reproj_file is not None:
+        if type(dtm_reproj_file) is str:
+            source = 'gdal'
+            topo_kwarg = {'filepath': dtm_reproj_file}
+        elif type(dtm_reproj_file) is np.ndarray:
+            source = 'numpy'
+            topo_kwarg = {'array': dtm_reproj_file}
+        else:
+            raise AttributeError('dtm_proj_file must be either a path to gdal or a'
+                                 'numpy array with values')
+        geo_model.set_topography(source=source, **topo_kwarg)
+
+    # Stack Processing
+    contents = np.genfromtxt(groups_file, delimiter=',', dtype='U100')[1:, 4:-1]
+
+    map_series_to_surfaces = {}
+    for pair in contents:
+        map_series_to_surfaces.setdefault(pair[1], []).append(pair[0])
+
+    gp.map_stack_to_surfaces(geo_model, map_series_to_surfaces,
+                             remove_unused_series=False)
+
+    order_formations = geo_model.stack.df.index.drop('Default series')
+
+    # Get the unassigned series as faults
+    if faults_contact is not None and faults_orientations is not None:
+        faults_pair = geo_model._surfaces.df.groupby('series').get_group('Default series')[[
+            'surface']].values[:, 0]
+        faults_pair_dict = dict(zip(faults_pair, faults_pair))
+        gp.map_stack_to_surfaces(geo_model, faults_pair_dict, remove_unused_series=True)
+        # Grabbing the order of faults and Formations
+        ordered_features = np.append(faults_pair, order_formations)
+        # Sorting series
+        geo_model.reorder_features(ordered_features)
+        geo_model.set_is_fault(faults_pair)
+
+        # Faults relation
+        geo_model.set_fault_relation(faults_rel_matrix)
+
+    geo_model.add_surfaces('basement')
+
+    # Check if there is features without data and delete it
+    try:
+        f_ = geo_model.surfaces.df.groupby('isActive').get_group(False)
+        features_without_data = f_['series']
+        geo_model.delete_features(features_without_data, remove_surfaces=True, remove_data=True)
+    except KeyError:
+        pass
+
+    if faults_contact is not None and faults_orientations is not None:
+        get_fault_names = geo_model.stack.df.groupby(['isActive', 'isFault']).get_group(
+            (True, True)).index
+        geo_model._surfaces.colors.make_faults_black(get_fault_names)
+
+    try:
+        colours = pd.read_csv(groups_file).set_index('code')['colour']
+        # Drop formations that do not exist in surfaces
+        colours = colours.loc[colours.index.isin(geo_model.surfaces.df['surface'])].to_dict()
+
+        geo_model._surfaces.colors.change_colors(colours)
+    except KeyError:
+        pass
+
+    if compute is True:
+        gp.set_interpolator(geo_model, dtype='float64',
+                            # verbose=['solve_kriging']
+                            )
+
+        # Increasing nugget effect
+        geo_model.modify_surface_points(
+            geo_model.surface_points.df.index,
+            smooth=0.1
+        )
+
+        geo_model.modify_orientations(
+            geo_model.orientations.df.index,
+            smooth=0.01
+        )
+
+        new_range = geo_model.get_additional_data().loc[('Kriging', 'range'), 'values'] * 0.5
+        geo_model.modify_kriging_parameters('range', new_range)
+
+        gp.compute_model(geo_model)
+
+    if vtk is True:
+        gp.plot_3d(geo_model, show_topography=True,
+                   image=image_2d,
+                   show_lith=True,
+                   **plot_3d_kwargs
+                   )
+
+    if vtk_path is not None:
+        gp._plot.export_to_vtk(geo_model, path=vtk_path, name=model_name + '.vtk',
+                               voxels=False, block=None, surfaces=True)
+
     return geo_model
```

### Comparing `gempy-2.2b10.dev1/gempy/addons/rex_api.py` & `gempy-2.3.0/gempy/addons/rex_api.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,300 +1,300 @@
-import os
-import requests
-import json
-import datetime
-try:
-    import pyqrcode as qr
-    PYQRCODE_IMPORT = True
-except ImportError:
-    PYQRCODE_IMPORT = False
-
-package_directory = os.path.dirname(os.path.abspath(__file__))
-
-
-class RexAPI:
-
-    def __init__(self, project_name, api_token=None, secret=None):
-        """Rest client to connect to the RexOS system
-
-
-        Args:
-            project_name:
-            api_token:
-            secret:
-        """
-        self.response = None  # saves the most current server response
-
-        self.token_ID, self.secret = self.load_credentials(api_token=api_token, secret=secret)
-        self.access_token = self.authorize_session()
-        self.owner = self.get_user_information()
-        self.project_name = project_name
-        self.project_urn, self.project_link = self.create_project(self.project_name)
-        self.root_reference_link, self.root_reference_key = self.create_root_reference()
-        self.file_reference_link = self.create_file_resource_reference()
-
-        self.project_file_urn = None
-        self.project_file_uplink = None
-        self.project_reference = None
-
-        self.rextag = None
-
-    def load_credentials(self, filename=os.path.join(package_directory, 'RexCloud_Api_key.txt'),
-                         api_token: str = None, secret: str = None):
-
-        if not os.path.isfile(filename) or (api_token is not None and secret is not None):
-            file = open(filename, 'w')
-            login_data = False
-            if api_token is None or secret is None:
-                login_data = True
-
-            if api_token is None:
-                api_token = 'REPLACE_TEXT_WITH_YOUR_API_Token'
-            if secret is None:
-                secret = 'REPLACE_TEXT_WITH_SECRET'
-
-            file.write(api_token+'\n'+secret+'\n'+' # put your API tokens and secrets in the lines above.\n'
-                                                  ' # Do not track the file on git.')
-            file.close()
-
-            if login_data:
-                raise AttributeError('Cache key is not created. You need to pass as argument the REX api_token'
-                                     ' and secret, or adding them in RexCloud_API_key.txt.'
-                                     ' https://www.rexos.org/getting-started/')
-
-        with open(filename, "r") as credential_file:
-            token_id = credential_file.readline().strip('\n')
-            secret = credential_file.readline().strip('\n')
-
-        return token_id, secret
-
-    def authorize_session(self):
-
-        headers = {'Accept': 'application/json;charset=UTF-8',
-                   'Content-Type': 'application/x-www-form-urlencoded; charset=ISO-8859-1'}
-
-        data = {'grant_type': 'client_credentials'}
-
-        self.response = requests.post('https://rex.robotic-eyes.com/oauth/token',
-                                      headers=headers, data=data, auth=(self.token_ID, self.secret)
-                                      )
-        if self.response.status_code == 200:
-            access_token = self.response.json()['access_token']
-            return access_token
-
-        else:
-            raise ConnectionError("something went wrong! Status code: "+str(self.response.status_code) +
-                                  'Probably the token or the secret is not valid. '
-                                  'https://www.rexos.org/getting-started/')
-
-    def get_user_information(self):
-        headers = {'Authorization': 'Bearer ' + self.access_token, 'Accept': 'application/json;charset=UTF-8'}
-        self.response = requests.get('https://rex.robotic-eyes.com/api/v2/users/current', headers=headers)
-
-        if self.response.status_code == 200:
-            owner = self.response.json()['userId']
-            return owner
-
-        else:
-            print("something went wrong! Status code: "+str(self.response.status_code))
-
-    def create_project(self, project_name):
-        headers = {
-            'Authorization': 'Bearer ' + self.access_token,
-            'Accept': 'application/json;charset=UTF-8',
-            'Content-Type': 'application/json;charset=UTF-8'
-        }
-
-        data = json.dumps({"name" : project_name,  "owner" : self.owner})  # this call expects json!
-
-        self.response = requests.post('https://rex.robotic-eyes.com/api/v2/projects', headers=headers, data=data)
-
-        if self.response.status_code == 201:
-            project_urn = self.response.json()['urn']
-            project_link = self.response.json()['_links']['self']['href']
-
-            return project_urn, project_link
-
-        else:
-            raise ConnectionError("something went wrong! Status code: " + str(self.response.status_code) +
-                                  'Probably project name already exists.')
-
-    def create_root_reference(self):
-        headers = {
-            'Authorization': 'Bearer ' + self.access_token,
-            'Accept': 'application/json;charset=UTF-8',
-            'Content-Type': 'application/json;charset=UTF-8',
-        }
-
-        data = json.dumps({"project" : self.project_link,
-                "name" : "root reference",
-                "address" : {"addressLine1": "Sample", "postcode": "52072",
-                             "city": "Aachen",   "country" : "Austria"}}
-                          )
-
-        self.response = requests.post('https://rex.robotic-eyes.com/api/v2/rexReferences', headers=headers, data=data)
-        if self.response.status_code == 201:
-            root_reference_link = self.response.json()['_links']['self']['href']
-            root_reference_key = self.response.json()['key']
-
-            return root_reference_link, root_reference_key
-
-        else:
-            print("something went wrong! Status code: " + str(self.response.status_code))
-
-    def create_file_resource_reference(self):
-        headers = {
-            'Authorization': 'Bearer ' + self.access_token,
-            'Accept': 'application/json;charset=UTF-8',
-            'Content-Type': 'application/json;charset=UTF-8',
-        }
-
-        data = json.dumps({"project" : self.project_link,
-                           "name" : "file ressource reference",
-                           "rootReference" : "false",  #setting root reference to false
-                           "parentReference" : self.root_reference_link})
-
-        self.response = requests.post('https://rex.robotic-eyes.com/api/v2/rexReferences', headers=headers, data=data)
-        if self.response.status_code == 201:
-            file_reference_link = self.response.json()['_links']['self']['href']
-
-            return file_reference_link
-
-        else:
-            print("something went wrong! Status code: " + str(self.response.status_code))
-
-    def create_project_file(self, projectname):
-        headers = {
-            'Authorization':'Bearer ' + self.access_token,
-            'Accept': 'application/json;charset=UTF-8',
-            'Content-Type': 'application/json;charset=UTF-8',
-                 }
-
-        data = json.dumps({"project" : self.project_link,
-                           "name" : projectname,
-                           "type" : "rex",
-
-                           "rexReference" : self.file_reference_link
-                           })
-
-        self.response = requests.post('https://rex.robotic-eyes.com/api/v2/projectFiles', headers=headers, data=data)
-
-        if self.response.status_code == 201:
-            self.project_file_urn = self.response.json()['urn']
-            self.project_file_uplink = self.response.json()['_links']['file.upload']['href']
-            self.project_reference = self.response.json()['rexReferenceKey']
-
-            return True
-
-        else:
-            print("something went wrong! Status code: " + str(self.response.status_code))
-
-            return False
-
-    def upload_rexfile(self, filename):
-
-        headers = {
-            'Authorization': 'Bearer ' + self.access_token,
-            'contentType': 'application/octet-stream',
-            'type' : 'rex'
-        }
-
-        file = {
-            'file':  (filename, open(filename, 'rb')),
-
-        }
-
-        self.response = requests.post(self.project_file_uplink,
-                                 headers=headers, files=file)
-
-    def return_rextag(self):
-        self.rextag = Rextag(self.project_reference)
-
-        return self.rextag
-
-
-class Rextag:
-
-    def __init__(self, project_reference):
-        self.rextag_url, self.rextag = self.create_rextag(project_reference)
-
-    def __repr__(self):
-        return self.rextag.terminal(module_color="reverse", background="default", quiet_zone=1)
-
-    def create_rextag(self, project_reference):
-        if PYQRCODE_IMPORT is False:
-            raise ImportError('This method depends on pyqrcode and it is not possible to import.')
-        base_url = "https://rex.codes/v1/"
-        rextag_url = base_url+project_reference
-        rextag = qr.create(rextag_url)
-        return rextag_url, rextag
-
-    def display_tag(self, reverse=True):
-        """
-        displays the rextag to the terminal standard output as ascii.
-
-        you can invert the color by setting inverse=True, this is necessary if you run it in a jupyter notebook
-        after creation, you can save the rextag as svg using the rextag.svg method:
-        self.rextag.svg("project_name", scale=8)
-
-        Args:
-            reverse: (boolean) inverts background and foreground color in the terminal output
-
-        Returns: None, prints a QR code to terminal output
-
-        """
-
-        if reverse:
-            print(self.rextag.terminal(module_color="reverse", background="default", quiet_zone=1))
-
-        else:
-            print(self.rextag.terminal(quiet_zone=1))
-
-        return True
-
-    def save_svg(self, filename):
-        self.rextag.svg(filename, scale=8)
-
-
-def upload_to_rexcloud(infiles : list, project_name=None, **kwargs):
-    """
-    wrapper around api calls to upload rexfiles of a gempy model.
-
-    you will need to register an account under https://app.rexos.cloud/ .
-    create an api key and store the key and secret in RexCloud_Api_key.txt.
-
-    the function will take a list of rexos input filenames and uploads them into a newly created project.
-
-    an ar code is plotted that can be scanned with the rexview app to show the model in vr.
-    the qr code is plotted in ascii to the standard output, if the qr code is not recognizable,
-     try to revert the colors o0f the terminal output by setting reverse=False in thew show_tag() Method.
-
-    all api calls are python implementation of the Rex os api:
-    https://www.rexos.org/rex-api/#tutorial-rex-project-before-you-begin
-
-
-    Args:
-        infiles: List of rexos file names
-        project_name: name of the project under which it appears in the rexcloud. if none is specified,
-        the current timestamp is used.
-
-    Returns:
-        A Rextag Object
-
-    """
-
-    if project_name is None:
-        timestamp = datetime.datetime.now()
-        project_name = str(timestamp)
-
-    api = RexAPI(project_name, **kwargs)
-
-    for file in infiles:
-
-        api.create_project_file(file)
-        api.upload_rexfile(file)
-
-    tag = api.return_rextag()
-
-    return tag
-
-
+import os
+import requests
+import json
+import datetime
+try:
+    import pyqrcode as qr
+    PYQRCODE_IMPORT = True
+except ImportError:
+    PYQRCODE_IMPORT = False
+
+package_directory = os.path.dirname(os.path.abspath(__file__))
+
+
+class RexAPI:
+
+    def __init__(self, project_name, api_token=None, secret=None):
+        """Rest client to connect to the RexOS system
+
+
+        Args:
+            project_name:
+            api_token:
+            secret:
+        """
+        self.response = None  # saves the most current server response
+
+        self.token_ID, self.secret = self.load_credentials(api_token=api_token, secret=secret)
+        self.access_token = self.authorize_session()
+        self.owner = self.get_user_information()
+        self.project_name = project_name
+        self.project_urn, self.project_link = self.create_project(self.project_name)
+        self.root_reference_link, self.root_reference_key = self.create_root_reference()
+        self.file_reference_link = self.create_file_resource_reference()
+
+        self.project_file_urn = None
+        self.project_file_uplink = None
+        self.project_reference = None
+
+        self.rextag = None
+
+    def load_credentials(self, filename=os.path.join(package_directory, 'RexCloud_Api_key.txt'),
+                         api_token: str = None, secret: str = None):
+
+        if not os.path.isfile(filename) or (api_token is not None and secret is not None):
+            file = open(filename, 'w')
+            login_data = False
+            if api_token is None or secret is None:
+                login_data = True
+
+            if api_token is None:
+                api_token = 'REPLACE_TEXT_WITH_YOUR_API_Token'
+            if secret is None:
+                secret = 'REPLACE_TEXT_WITH_SECRET'
+
+            file.write(api_token+'\n'+secret+'\n'+' # put your API tokens and secrets in the lines above.\n'
+                                                  ' # Do not track the file on git.')
+            file.close()
+
+            if login_data:
+                raise AttributeError('Cache key is not created. You need to pass as argument the REX api_token'
+                                     ' and secret, or adding them in RexCloud_API_key.txt.'
+                                     ' https://www.rexos.org/getting-started/')
+
+        with open(filename, "r") as credential_file:
+            token_id = credential_file.readline().strip('\n')
+            secret = credential_file.readline().strip('\n')
+
+        return token_id, secret
+
+    def authorize_session(self):
+
+        headers = {'Accept': 'application/json;charset=UTF-8',
+                   'Content-Type': 'application/x-www-form-urlencoded; charset=ISO-8859-1'}
+
+        data = {'grant_type': 'client_credentials'}
+
+        self.response = requests.post('https://rex.robotic-eyes.com/oauth/token',
+                                      headers=headers, data=data, auth=(self.token_ID, self.secret)
+                                      )
+        if self.response.status_code == 200:
+            access_token = self.response.json()['access_token']
+            return access_token
+
+        else:
+            raise ConnectionError("something went wrong! Status code: "+str(self.response.status_code) +
+                                  'Probably the token or the secret is not valid. '
+                                  'https://www.rexos.org/getting-started/')
+
+    def get_user_information(self):
+        headers = {'Authorization': 'Bearer ' + self.access_token, 'Accept': 'application/json;charset=UTF-8'}
+        self.response = requests.get('https://rex.robotic-eyes.com/api/v2/users/current', headers=headers)
+
+        if self.response.status_code == 200:
+            owner = self.response.json()['userId']
+            return owner
+
+        else:
+            print("something went wrong! Status code: "+str(self.response.status_code))
+
+    def create_project(self, project_name):
+        headers = {
+            'Authorization': 'Bearer ' + self.access_token,
+            'Accept': 'application/json;charset=UTF-8',
+            'Content-Type': 'application/json;charset=UTF-8'
+        }
+
+        data = json.dumps({"name" : project_name,  "owner" : self.owner})  # this call expects json!
+
+        self.response = requests.post('https://rex.robotic-eyes.com/api/v2/projects', headers=headers, data=data)
+
+        if self.response.status_code == 201:
+            project_urn = self.response.json()['urn']
+            project_link = self.response.json()['_links']['self']['href']
+
+            return project_urn, project_link
+
+        else:
+            raise ConnectionError("something went wrong! Status code: " + str(self.response.status_code) +
+                                  'Probably project name already exists.')
+
+    def create_root_reference(self):
+        headers = {
+            'Authorization': 'Bearer ' + self.access_token,
+            'Accept': 'application/json;charset=UTF-8',
+            'Content-Type': 'application/json;charset=UTF-8',
+        }
+
+        data = json.dumps({"project" : self.project_link,
+                "name" : "root reference",
+                "address" : {"addressLine1": "Sample", "postcode": "52072",
+                             "city": "Aachen",   "country" : "Austria"}}
+                          )
+
+        self.response = requests.post('https://rex.robotic-eyes.com/api/v2/rexReferences', headers=headers, data=data)
+        if self.response.status_code == 201:
+            root_reference_link = self.response.json()['_links']['self']['href']
+            root_reference_key = self.response.json()['key']
+
+            return root_reference_link, root_reference_key
+
+        else:
+            print("something went wrong! Status code: " + str(self.response.status_code))
+
+    def create_file_resource_reference(self):
+        headers = {
+            'Authorization': 'Bearer ' + self.access_token,
+            'Accept': 'application/json;charset=UTF-8',
+            'Content-Type': 'application/json;charset=UTF-8',
+        }
+
+        data = json.dumps({"project" : self.project_link,
+                           "name" : "file ressource reference",
+                           "rootReference" : "false",  #setting root reference to false
+                           "parentReference" : self.root_reference_link})
+
+        self.response = requests.post('https://rex.robotic-eyes.com/api/v2/rexReferences', headers=headers, data=data)
+        if self.response.status_code == 201:
+            file_reference_link = self.response.json()['_links']['self']['href']
+
+            return file_reference_link
+
+        else:
+            print("something went wrong! Status code: " + str(self.response.status_code))
+
+    def create_project_file(self, projectname):
+        headers = {
+            'Authorization':'Bearer ' + self.access_token,
+            'Accept': 'application/json;charset=UTF-8',
+            'Content-Type': 'application/json;charset=UTF-8',
+                 }
+
+        data = json.dumps({"project" : self.project_link,
+                           "name" : projectname,
+                           "type" : "rex",
+
+                           "rexReference" : self.file_reference_link
+                           })
+
+        self.response = requests.post('https://rex.robotic-eyes.com/api/v2/projectFiles', headers=headers, data=data)
+
+        if self.response.status_code == 201:
+            self.project_file_urn = self.response.json()['urn']
+            self.project_file_uplink = self.response.json()['_links']['file.upload']['href']
+            self.project_reference = self.response.json()['rexReferenceKey']
+
+            return True
+
+        else:
+            print("something went wrong! Status code: " + str(self.response.status_code))
+
+            return False
+
+    def upload_rexfile(self, filename):
+
+        headers = {
+            'Authorization': 'Bearer ' + self.access_token,
+            'contentType': 'application/octet-stream',
+            'type' : 'rex'
+        }
+
+        file = {
+            'file':  (filename, open(filename, 'rb')),
+
+        }
+
+        self.response = requests.post(self.project_file_uplink,
+                                 headers=headers, files=file)
+
+    def return_rextag(self):
+        self.rextag = Rextag(self.project_reference)
+
+        return self.rextag
+
+
+class Rextag:
+
+    def __init__(self, project_reference):
+        self.rextag_url, self.rextag = self.create_rextag(project_reference)
+
+    def __repr__(self):
+        return self.rextag.terminal(module_color="reverse", background="default", quiet_zone=1)
+
+    def create_rextag(self, project_reference):
+        if PYQRCODE_IMPORT is False:
+            raise ImportError('This method depends on pyqrcode and it is not possible to import.')
+        base_url = "https://rex.codes/v1/"
+        rextag_url = base_url+project_reference
+        rextag = qr.create(rextag_url)
+        return rextag_url, rextag
+
+    def display_tag(self, reverse=True):
+        """
+        displays the rextag to the terminal standard output as ascii.
+
+        you can invert the color by setting inverse=True, this is necessary if you run it in a jupyter notebook
+        after creation, you can save the rextag as svg using the rextag.svg method:
+        self.rextag.svg("project_name", scale=8)
+
+        Args:
+            reverse: (boolean) inverts background and foreground color in the terminal output
+
+        Returns: None, prints a QR code to terminal output
+
+        """
+
+        if reverse:
+            print(self.rextag.terminal(module_color="reverse", background="default", quiet_zone=1))
+
+        else:
+            print(self.rextag.terminal(quiet_zone=1))
+
+        return True
+
+    def save_svg(self, filename):
+        self.rextag.svg(filename, scale=8)
+
+
+def upload_to_rexcloud(infiles : list, project_name=None, **kwargs):
+    """
+    wrapper around api calls to upload rexfiles of a gempy model.
+
+    you will need to register an account under https://app.rexos.cloud/ .
+    create an api key and store the key and secret in RexCloud_Api_key.txt.
+
+    the function will take a list of rexos input filenames and uploads them into a newly created project.
+
+    an ar code is plotted that can be scanned with the rexview app to show the model in vr.
+    the qr code is plotted in ascii to the standard output, if the qr code is not recognizable,
+     try to revert the colors o0f the terminal output by setting reverse=False in thew show_tag() Method.
+
+    all api calls are python implementation of the Rex os api:
+    https://www.rexos.org/rex-api/#tutorial-rex-project-before-you-begin
+
+
+    Args:
+        infiles: List of rexos file names
+        project_name: name of the project under which it appears in the rexcloud. if none is specified,
+        the current timestamp is used.
+
+    Returns:
+        A Rextag Object
+
+    """
+
+    if project_name is None:
+        timestamp = datetime.datetime.now()
+        project_name = str(timestamp)
+
+    api = RexAPI(project_name, **kwargs)
+
+    for file in infiles:
+
+        api.create_project_file(file)
+        api.upload_rexfile(file)
+
+    tag = api.return_rextag()
+
+    return tag
+
+
```

### Comparing `gempy-2.2b10.dev1/gempy/api_modules/aux_func.py` & `gempy-2.3.0/gempy/api_modules/aux_func.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,34 +1,34 @@
-from os import path
-import sys
-
-# This is for sphenix to find the packages
-sys.path.append(path.dirname( path.dirname( path.abspath(__file__) ) ) )
-
-from gempy.core.model import *
-from gempy.utils.meta import _setdoc
-
-# This warning comes from numpy complaining about a theano optimization
-warnings.filterwarnings("ignore",
-                        message='.* a non-tuple sequence for multidimensional indexing is deprecated; use*.',
-                        append=True)
-
-
-@_setdoc(Series.__doc__)
-def create_series(series_distribution=None, order=None):
-    return Series(series_distribution=series_distribution, order=order)
-
-
-@_setdoc(Surfaces.__doc__)
-def create_formations(values_array=None, values_names=np.empty(0), formation_names=np.empty(0)):
-    f = Surfaces(values_array=values_array, properties_names=values_names, formation_names=formation_names)
-    return f
-
-
-@_setdoc(Faults.__doc__)
-def create_faults(series: Series, series_fault=None, rel_matrix=None):
-    return Faults(series=series, series_fault=series_fault, rel_matrix=rel_matrix)
-
-
-@_setdoc(Grid.__doc__)
-def create_grid(grid_type: str, **kwargs):
+from os import path
+import sys
+
+# This is for sphenix to find the packages
+sys.path.append(path.dirname( path.dirname( path.abspath(__file__) ) ) )
+
+from gempy.core.model import *
+from gempy.utils.meta import _setdoc
+
+# This warning comes from numpy complaining about a aesara optimization
+warnings.filterwarnings("ignore",
+                        message='.* a non-tuple sequence for multidimensional indexing is deprecated; use*.',
+                        append=True)
+
+
+@_setdoc(Series.__doc__) 
+def create_series(series_distribution=None, order=None):
+    return Series(series_distribution=series_distribution, order=order)
+
+
+@_setdoc(Surfaces.__doc__)
+def create_formations(values_array=None, values_names=np.empty(0), formation_names=np.empty(0)):
+    f = Surfaces(values_array=values_array, properties_names=values_names, formation_names=formation_names)
+    return f
+
+
+@_setdoc(Faults.__doc__)
+def create_faults(series: Series, series_fault=None, rel_matrix=None):
+    return Faults(series=series, series_fault=series_fault, rel_matrix=rel_matrix)
+
+
+@_setdoc(Grid.__doc__)
+def create_grid(grid_type: str, **kwargs):
     return Grid(grid_type=grid_type, **kwargs)
```

### Comparing `gempy-2.2b10.dev1/gempy/api_modules/editing.py` & `gempy-2.3.0/gempy/api_modules/editing.py`

 * *Ordering differences only*

 * *Files 27% similar despite different names*

```diff
@@ -1,74 +1,74 @@
-from os import path
-import sys
-
-# This is for sphenix to find the packages
-sys.path.append(path.dirname( path.dirname( path.abspath(__file__) ) ) )
-
-from gempy.core.model import *
-from typing import Union
-
-
-def add_surface_points(data: Union[Project, SurfacePoints]):
-    pass
-
-
-def add_orienations(data: Union[Project, Orientations]):
-    pass
-
-
-def add_series(data: Union[Project, Series]):
-    pass
-
-
-def add_formations(data: Union[Project, Surfaces]):
-    pass
-
-def del_surface_points(data: Union[Project, SurfacePoints]):
-    pass
-
-
-def del_orientations(data: Union[Project, Orientations]):
-    pass
-
-
-def del_series(data: Union[Project, Series]):
-    pass
-
-
-def del_formations(data: Union[Project, Surfaces]):
-    pass
-
-
-def modify_surface_points(data: Union[Project, SurfacePoints]):
-    pass
-
-def modify_orientations(data: Union[Project, Orientations]):
-    pass
-
-
-def modify_series(data: Union[Project, Series]):
-    pass
-
-def modify_formations(data: Union[Project, Surfaces]):
-    pass
-
-def modify_faults(data: Union[Project, Faults]):
-    pass
-
-def set_is_fault(data: Union[Project, Faults], idx):
-    if isinstance(data, Project):
-        data.set_is_fault(idx)
-    elif isinstance(data, Faults):
-        data.set_is_fault()
-
-def modify_faults_network(data: Union[Project, Faults]):
-    pass
-
-def modify_options(data: Union[Project, Options]):
-    pass
-
-def modify_kriging_parameters(data: Union[Project, KrigingParameters]):
-    pass
-
-def modify_rescaling_parametesr(data: Union[Project, ScalingSystem]):
-    pass
+from os import path
+import sys
+
+# This is for sphenix to find the packages
+sys.path.append(path.dirname( path.dirname( path.abspath(__file__) ) ) )
+
+from gempy.core.model import *
+from typing import Union
+
+
+def add_surface_points(data: Union[Project, SurfacePoints]):
+    pass
+
+
+def add_orienations(data: Union[Project, Orientations]):
+    pass
+
+
+def add_series(data: Union[Project, Series]):
+    pass
+
+
+def add_formations(data: Union[Project, Surfaces]):
+    pass
+
+def del_surface_points(data: Union[Project, SurfacePoints]):
+    pass
+
+
+def del_orientations(data: Union[Project, Orientations]):
+    pass
+
+
+def del_series(data: Union[Project, Series]):
+    pass
+
+
+def del_formations(data: Union[Project, Surfaces]):
+    pass
+
+
+def modify_surface_points(data: Union[Project, SurfacePoints]):
+    pass
+
+def modify_orientations(data: Union[Project, Orientations]):
+    pass
+
+
+def modify_series(data: Union[Project, Series]):
+    pass
+
+def modify_formations(data: Union[Project, Surfaces]):
+    pass
+
+def modify_faults(data: Union[Project, Faults]):
+    pass
+
+def set_is_fault(data: Union[Project, Faults], idx):
+    if isinstance(data, Project):
+        data.set_is_fault(idx)
+    elif isinstance(data, Faults):
+        data.set_is_fault()
+
+def modify_faults_network(data: Union[Project, Faults]):
+    pass
+
+def modify_options(data: Union[Project, Options]):
+    pass
+
+def modify_kriging_parameters(data: Union[Project, KrigingParameters]):
+    pass
+
+def modify_rescaling_parametesr(data: Union[Project, ScalingSystem]):
+    pass
```

### Comparing `gempy-2.2b10.dev1/gempy/api_modules/getters.py` & `gempy-2.3.0/gempy/api_modules/getters.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,67 +1,67 @@
-""" Getters API
-
-"""
-from gempy import Project, Solution
-from typing import Union
-import warnings
-from gempy.utils.meta import _setdoc_pro
-
-
-@_setdoc_pro()
-def get_data(model: Project, itype='data', numeric=False, verbosity=0):
-    """Method to return the data stored in :class:`pandas.DataFrame` within a
-    :class:`gempy.core.model.Project` data object.
-
-    Args:
-        model: [s_geo_model]
-        itype: [s_itype]
-        numeric (bool): if True it only returns numerical properties. This may be useful due to memory issues
-        verbosity (int): Number of properties shown
-
-    Returns:
-        pandas.DataFrame: Data Object df.
-
-    """
-    return model.get_data(itype=itype, numeric=numeric, verbosity=verbosity)
-
-
-def get_surfaces(model_solution: Union[Project, Solution]):
-    """Get vertices and simplices of the surface_points for its vtk visualization and further analysis.
-
-    Args:
-       model_solution (:class:`Project` or :class:`Solution`)
-
-    Returns:
-        list[numpy.array]: vertices, simpleces
-    """
-    if isinstance(model_solution, Project):
-        return model_solution.solutions.vertices, model_solution.solutions.edges
-    elif isinstance(model_solution, Solution):
-        return model_solution.vertices, model_solution.edges
-    else:
-        raise AttributeError
-
-
-def get_interpolator(model: Project):
-    return model._interpolator
-
-
-def get_th_fn(model: Project):
-    """Get the compiled theano function
-
-    Args:
-        model (:class:`model.Project`)
-
-    Returns:
-        :class:`theano.compile.function_module.Function`: Compiled function if C or CUDA which computes the interpolation given the input data
-            (XYZ of dips, dip, azimuth, polarity, XYZ ref surface_points, XYZ rest surface_points)
-    """
-    assert getattr(model._interpolator, 'theano_function', False) is not None, 'Theano has not been compiled yet'
-
-    return model._interpolator.theano_function
-
-
-def get_additional_data(model: Project):
-    warnings.warn('get_additional_data will be deprecrated in GemPy 2.3 Use '
-                  'get(\'additional_data\') instead.', DeprecationWarning)
-    return model.get_additional_data()
+""" Getters API
+
+"""
+from gempy import Project, Solution
+from typing import Union
+import warnings
+from gempy.utils.meta import _setdoc_pro
+
+
+@_setdoc_pro()
+def get_data(model: Project, itype='data', numeric=False, verbosity=0):
+    """Method to return the data stored in :class:`pandas.DataFrame` within a
+    :class:`gempy.core.model.Project` data object.
+
+    Args:
+        model: [s_geo_model]
+        itype: [s_itype]
+        numeric (bool): if True it only returns numerical properties. This may be useful due to memory issues
+        verbosity (int): Number of properties shown
+
+    Returns:
+        pandas.DataFrame: Data Object df.
+
+    """
+    return model.get_data(itype=itype, numeric=numeric, verbosity=verbosity)
+
+
+def get_surfaces(model_solution: Union[Project, Solution]):
+    """Get vertices and simplices of the surface_points for its vtk visualization and further analysis.
+
+    Args:
+       model_solution (:class:`Project` or :class:`Solution`)
+
+    Returns:
+        list[numpy.array]: vertices, simpleces
+    """
+    if isinstance(model_solution, Project):
+        return model_solution.solutions.vertices, model_solution.solutions.edges
+    elif isinstance(model_solution, Solution):
+        return model_solution.vertices, model_solution.edges
+    else:
+        raise AttributeError
+
+
+def get_interpolator(model: Project):
+    return model._interpolator
+
+
+def get_th_fn(model: Project):
+    """Get the compiled aesara function
+
+    Args:
+        model (:class:`model.Project`)
+
+    Returns:
+        :class:`aesara.compile.function_module.Function`: Compiled function if C or CUDA which computes the interpolation given the input data
+            (XYZ of dips, dip, azimuth, polarity, XYZ ref surface_points, XYZ rest surface_points)
+    """
+    assert getattr(model._interpolator, 'aesara_function', False) is not None, 'aesara has not been compiled yet'
+
+    return model._interpolator.aesara_function
+
+
+def get_additional_data(model: Project):
+    warnings.warn('get_additional_data will be deprecrated in GemPy 2.3 Use '
+                  'get(\'additional_data\') instead.', DeprecationWarning)
+    return model.get_additional_data()
```

### Comparing `gempy-2.2b10.dev1/gempy/api_modules/setters.py` & `gempy-2.3.0/gempy/api_modules/setters.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,307 +1,311 @@
-""" setters API
-
-"""
-from gempy import get_data
-from gempy.utils.meta import _setdoc, _setdoc_pro
-from gempy.utils import docstring as ds
-from gempy.core.model import Model, InterpolatorModel
-from typing import Union
-import warnings
-import numpy as np
-# This warning comes from numpy complaining about a theano optimization
-warnings.filterwarnings("ignore",
-                        message='.* a non-tuple sequence for multidimensional '
-                                'indexing is deprecated; use*.',
-                        append=True)
-
-
-@_setdoc([InterpolatorModel.__doc__])
-@_setdoc_pro([Model.__doc__, ds.compile_theano, ds.theano_optimizer])
-def set_interpolator(geo_model: Model, output: list = None, compile_theano: bool = True,
-                     theano_optimizer=None, verbose: list = None, grid=None, type_=None,
-                     update_structure=True, update_kriging=True,
-                     **kwargs):
-    """
-    Method to create a graph and compile the theano code to compute the interpolation.
-
-    Args:
-        geo_model (:class:`gempy.core.model.Project`): [s0]
-        output (list[str:{geo, grav}]): type of interpolation.
-        compile_theano (bool): [s1]
-        theano_optimizer (str {'fast_run', 'fast_compile'}): [s2]
-        verbose:
-        update_kriging (bool): reset kriging values to its default.
-        update_structure (bool): sync Structure instance before setting theano graph.
-
-    Keyword Args:
-        -  pos_density (Optional[int]): Only necessary when type='grav'. Location on the Surfaces().df
-         where density is located (starting on id being 0).
-        - Vs
-        - pos_magnetics
-
-    Returns:
-
-    """
-    # output = list(output)
-    if output is None:
-        output = ['geology']
-
-    if type(output) is not list:
-        raise TypeError('Output must be a list.')
-
-    # TODO Geology is necessary for everthing?
-    if 'gravity' in output and 'geology' not in output:
-        output.append('geology')
-
-    if 'magnetics' in output and 'geology' not in output:
-        output.append('geology')
-
-    if type_ is not None:
-        warnings.warn('type warn is going to be deprecated. Use output insted', FutureWarning)
-        output = type_
-
-    if theano_optimizer is not None:
-        geo_model._additional_data.options.df.at['values', 'theano_optimizer'] = theano_optimizer
-    if verbose is not None:
-        geo_model._additional_data.options.df.at['values', 'verbosity'] = verbose
-    if 'dtype' in kwargs:
-        geo_model._additional_data.options.df.at['values', 'dtype'] = kwargs['dtype']
-    if 'device' in kwargs:
-        geo_model._additional_data.options.df.at['values', 'device'] = kwargs['device']
-
-    # TODO add kwargs
-    geo_model._rescaling.rescale_data()
-    geo_model.update_additional_data(update_structure=update_structure, update_kriging=update_kriging)
-    geo_model.update_to_interpolator()
-    geo_model._surface_points.sort_table()
-    geo_model._orientations.sort_table()
-
-    geo_model._interpolator.create_theano_graph(geo_model._additional_data, inplace=True,
-                                                output=output, **kwargs)
-
-    if 'gravity' in output:
-        pos_density = kwargs.get('pos_density', 1)
-        tz = kwargs.get('tz', 'auto')
-        if geo_model._grid.centered_grid is not None:
-            geo_model._interpolator.set_theano_shared_gravity(tz, pos_density)
-
-    if 'magnetics' in output:
-        pos_magnetics = kwargs.get('pos_magnetics', 1)
-        Vs = kwargs.get('Vs', 'auto')
-        incl = kwargs.get('incl')
-        decl = kwargs.get('decl')
-        B_ext = kwargs.get('B_ext', 52819.8506939139e-9)
-        if geo_model._grid.centered_grid is not None:
-            geo_model._interpolator.set_theano_shared_magnetics(Vs, pos_magnetics, incl, decl, B_ext)
-
-    if 'topology' in output:
-        # This id is necessary for topology
-        id_list = geo_model._surfaces.df.groupby('isFault').cumcount() + 1
-        geo_model.add_surface_values(id_list, 'topology_id')
-        geo_model._interpolator.set_theano_shared_topology()
-
-        # TODO it is missing to pass to theano the position of topology_id
-
-    if compile_theano is True:
-        geo_model._interpolator.set_all_shared_parameters(reset_ctrl=True)
-
-        geo_model._interpolator.compile_th_fn_geo(inplace=True, grid=grid)
-    else:
-        if grid == 'shared':
-            geo_model._interpolator.set_theano_shared_grid(grid)
-
-    print('Kriging values: \n', geo_model._additional_data.kriging_data)
-    return geo_model._interpolator
-
-
-@_setdoc_pro([Model.__doc__])
-def set_geometric_data(geo_model: Model, surface_points_df=None,
-                       orientations_df=None, **kwargs):
-    """ Function to set directly pandas.Dataframes to the gempy geometric data objects
-
-    Args:
-        geo_model: [s0]
-        surface_points_df:  A pn.Dataframe object with X, Y, Z, and surface columns
-        orientations_df: A pn.Dataframe object with X, Y, Z, surface columns and pole or orientation columns
-        **kwargs:
-
-    Returns:
-        Modified df
-    """
-
-    r_ = None
-
-    if surface_points_df is not None:
-        geo_model.set_surface_points(surface_points_df, **kwargs)
-        r_ = 'surface_points'
-
-    elif orientations_df is not None:
-        geo_model.set_orientations(orientations_df, **kwargs)
-        r_ = 'data' if r_ == 'surface_points' else 'orientations'
-
-    else:
-        raise AttributeError('You need to pass at least one dataframe')
-
-    return get_data(geo_model, itype=r_)
-
-
-def set_orientation_from_surface_points(geo_model, indices_array):
-    """
-    Create and set orientations from at least 3 points of the :attr:`gempy.data_management.InputData.surface_points`
-     Dataframe
-
-    Args:
-        geo_model (:class:`Model`):
-        indices_array (array-like): 1D or 2D array with the pandas indices of the
-          :attr:`surface_points`. If 2D every row of the 2D matrix will be used to create an
-          orientation
-
-
-    Returns:
-        :attr:`orientations`: Already updated inplace
-    """
-
-    if np.ndim(indices_array) is 1:
-        indices = indices_array
-        form = geo_model._surface_points.df['surface'].loc[indices].unique()
-        assert form.shape[0] is 1, 'The interface points must belong to the same surface'
-        form = form[0]
-
-        ori_parameters = geo_model._orientations.create_orientation_from_surface_points(
-            geo_model._surface_points, indices)
-        geo_model.add_orientations(X=ori_parameters[0], Y=ori_parameters[1], Z=ori_parameters[2],
-                                   orientation=ori_parameters[3:6], pole_vector=ori_parameters[6:9],
-                                   surface=form)
-    elif np.ndim(indices_array) is 2:
-        for indices in indices_array:
-            form = geo_model._surface_points.df['surface'].loc[indices].unique()
-            assert form.shape[0] is 1, 'The interface points must belong to the same surface'
-            form = form[0]
-            ori_parameters = geo_model._orientations.create_orientation_from_surface_points(
-                geo_model._surface_points, indices)
-            geo_model.add_orientations(X=ori_parameters[0], Y=ori_parameters[1], Z=ori_parameters[2],
-                                       orientation=ori_parameters[3:6], pole_vector=ori_parameters[6:9],
-                                       surface=form)
-
-    return geo_model._orientations
-
-def select_nearest_surfaces_points(geo_model, surface_points, searchcrit):
-    """
-    Find the neighbour points of the same surface
-    by given radius (radius-search) or fix number (knn).
-    Parameters
-    ----------
-    geo_model : geo_model
-        GemPy-model.
-    surface_points: Pandas-dataframe
-        Contains the dataframe of the (point-)data from the GemPy-model.
-    searchcrit : int or float
-        if is int: uses knn-search.
-        if is float: uses radius-search.
-    """
-
-    from sklearn.neighbors import NearestNeighbors
-
-    # extract surface names
-    surfaces = np.unique(surface_points['surface'])
-    neighbours = []
-    # for each surface
-    if isinstance(searchcrit, int):  # in case knn-search
-        searchcrit = searchcrit + 1  # because the point itself is also found
-        for s in range(surfaces.size):
-            # extract point-ids
-            i_surfaces = surface_points['surface'] == surfaces[s]
-            # extract point coordinates
-            p_surfaces = surface_points[i_surfaces][['X', 'Y', 'Z']]
-            # create search-tree
-            Tree = NearestNeighbors(n_neighbors=searchcrit)
-            # add data to tree
-            Tree.fit(p_surfaces)
-            # find neighbours
-            neighbours_surfaces = Tree.kneighbors(p_surfaces, n_neighbors=searchcrit,
-                                            return_distance=False)
-            # add neighbours with initial index to total list
-            for n in neighbours_surfaces:
-                neighbours.append(p_surfaces.index[n])
-    else:  # in case radius-search
-        for s in range(surfaces.size):
-            # extract point-ids
-            i_surfaces = surface_points['surface'] == surfaces[s]
-            # extract point coordinates
-            p_surfaces = surface_points[i_surfaces][['X', 'Y', 'Z']]
-            # create search-tree
-            Tree = NearestNeighbors(radius=searchcrit)
-            # add data to tree
-            Tree.fit(p_surfaces)
-            # find neighbours (attention: relativ index!)
-            neighbours_surfaces = Tree.radius_neighbors(p_surfaces,
-                                                  radius=searchcrit,
-                                                  return_distance=False)
-            # add neighbours with initial index to total list
-            for n in neighbours_surfaces:
-                neighbours.append(p_surfaces.index[n])
-    return neighbours
-
-
-def set_orientation_from_neighbours(geo_model, neighbours):
-
-    """
-    Calculates the orientation of one point with its neighbour points
-    of the same surface.
-    Parameters
-    ----------
-    geo_model : geo_model
-        GemPy-model.
-    neighbours : Int64Index
-        point-neighbours-id, first id is the point itself.
-    """
-
-    from sklearn.preprocessing import normalize
-
-    # compute normal vector for the point
-    if neighbours.size > 2:
-        # extract point coordinates
-        coo = geo_model._surface_points.df.loc[neighbours][['X', 'Y', 'Z']]
-        # calculates covariance matrix
-        cov = np.cov(coo.T)
-        # calculate normalized normal vector
-        normvec = normalize(np.cross(cov[0].T, cov[1].T).reshape(1, -1))[0]
-        # check orientation of normal vector (has to be oriented to sky)
-        if normvec[2] < 0:
-            normvec = normvec*(-1)
-        # append to the GemPy-model
-        geo_model.add_orientations(geo_model._surface_points.df['X'][neighbours[0]],
-                                   geo_model._surface_points.df['Y'][neighbours[0]],
-                                   geo_model._surface_points.df['Z'][neighbours[0]],
-                                   geo_model._surface_points.df['surface'][neighbours[0]],
-                                   normvec.tolist())
-    # if computation is impossible set normal vector to default orientation
-    else:
-        print("orientation calculation of point" + str(neighbours[0]) + "is impossible")
-        print("-> default vector is set [0,0,1]")
-        geo_model.add_orientations(geo_model._surface_points.df['X'][neighbours[0]],
-                                   geo_model._surface_points.df['Y'][neighbours[0]],
-                                   geo_model._surface_points.df['Z'][neighbours[0]],
-                                   geo_model._surface_points.df['surface'][neighbours[0]],
-                                   orientation=[0, 0, 1])
-    return geo_model._orientations
-
-
-def set_orientation_from_neighbours_all(geo_model, neighbours):
-
-    """
-    Calculates the orientations for all points with given neighbours.
-    Parameters
-    ----------
-    geo_model : geo_model
-        GemPy-model.
-    neighbours : list of Int64Index
-        point-neighbours-IDs, the first id is the id of the point
-        for which the orientation is calculated.
-    """
-
-    # compute normal vector for the points
-    for n in neighbours:
-        set_orientation_from_neighbours(geo_model, n)
-
-    return geo_model._orientations
+""" setters API
+
+"""
+from gempy import get_data
+from gempy.utils.meta import _setdoc, _setdoc_pro
+from gempy.utils import docstring as ds
+from gempy.core.model import Model, InterpolatorModel
+from typing import Union
+import warnings
+import numpy as np
+
+# This warning comes from numpy complaining about a aesara optimization
+warnings.filterwarnings("ignore",
+                        message='.* a non-tuple sequence for multidimensional '
+                                'indexing is deprecated; use*.',
+                        append=True)
+
+
+@_setdoc([InterpolatorModel.__doc__])
+@_setdoc_pro([Model.__doc__, ds.compile_aesara, ds.aesara_optimizer])
+def set_interpolator(geo_model: Model, output: list = None, compile_aesara: bool = True,
+                     aesara_optimizer=None, verbose: list = None, grid=None, type_=None,
+                     update_structure=True, update_kriging=True,
+                     **kwargs):
+    """
+    Method to create a graph and compile the aesara code to compute the interpolation.
+
+    Args:
+        geo_model (:class:`gempy.core.model.Project`): [s0]
+        output (list[str:{geo, grav}]): type of interpolation.
+        compile_aesara (bool): [s1]
+        aesara_optimizer (str {'fast_run', 'fast_compile'}): [s2]
+        verbose:
+        update_kriging (bool): reset kriging values to its default.
+        update_structure (bool): sync Structure instance before setting aesara graph.
+
+    Keyword Args:
+        -  pos_density (Optional[int]): Only necessary when type='grav'. Location on the Surfaces().df
+         where density is located (starting on id being 0).
+        - Vs
+        - pos_magnetics
+
+    Returns:
+
+    """
+    # output = list(output)
+    if output is None:
+        output = ['geology']
+
+    if type(output) is not list:
+        raise TypeError('Output must be a list.')
+
+    # TODO Geology is necessary for everthing?
+    if 'gravity' in output and 'geology' not in output:
+        output.append('geology')
+
+    if 'magnetics' in output and 'geology' not in output:
+        output.append('geology')
+
+    if type_ is not None:
+        warnings.warn('type warn is going to be deprecated. Use output insted', FutureWarning)
+        output = type_
+
+    if aesara_optimizer is not None:
+        geo_model._additional_data.options.df.at['values', 'aesara_optimizer'] = aesara_optimizer
+    if verbose is not None:
+        geo_model._additional_data.options.df.at['values', 'verbosity'] = verbose
+    if 'dtype' in kwargs:
+        geo_model._additional_data.options.df.at['values', 'dtype'] = kwargs['dtype']
+    if 'device' in kwargs:
+        geo_model._additional_data.options.df.at['values', 'device'] = kwargs['device']
+
+    # TODO add kwargs
+    geo_model._rescaling.rescale_data()
+    geo_model.update_additional_data(update_structure=update_structure, update_kriging=update_kriging)
+    geo_model.update_to_interpolator()
+    geo_model._surface_points.sort_table()
+    geo_model._orientations.sort_table()
+
+    geo_model._interpolator.create_aesara_graph(geo_model._additional_data, inplace=True,
+                                                output=output, **kwargs)
+
+    if 'gravity' in output:
+        pos_density = kwargs.get('pos_density', 1)
+        tz = kwargs.get('tz', 'auto')
+        if geo_model._grid.centered_grid is not None:
+            geo_model._interpolator.set_aesara_shared_gravity(tz, pos_density)
+
+    if 'magnetics' in output:
+        pos_magnetics = kwargs.get('pos_magnetics', 1)
+        Vs = kwargs.get('Vs', 'auto')
+        incl = kwargs.get('incl')
+        decl = kwargs.get('decl')
+        B_ext = kwargs.get('B_ext', 52819.8506939139e-9)
+        if geo_model._grid.centered_grid is not None:
+            geo_model._interpolator.set_aesara_shared_magnetics(Vs, pos_magnetics, incl, decl, B_ext)
+
+    if 'topology' in output:
+        # This id is necessary for topology
+        id_list = geo_model._surfaces.df.groupby('isFault').cumcount() + 1
+        geo_model.add_surface_values(id_list, 'topology_id')
+        geo_model._interpolator.set_aesara_shared_topology()
+
+        # TODO it is missing to pass to aesara the position of topology_id
+
+    if compile_aesara is True:
+        geo_model._interpolator.set_all_shared_parameters(reset_ctrl=True)
+
+        geo_model._interpolator.compile_th_fn_geo(inplace=True, grid=grid)
+    else:
+        if grid == 'shared':
+            geo_model._interpolator.set_aesara_shared_grid(grid)
+
+    print('Kriging values: \n', geo_model._additional_data.kriging_data)
+    return geo_model._interpolator
+
+
+@_setdoc_pro([Model.__doc__])
+def set_geometric_data(geo_model: Model, surface_points_df=None,
+                       orientations_df=None, **kwargs):
+    """ Function to set directly pandas.Dataframes to the gempy geometric data objects
+
+    Args:
+        geo_model: [s0]
+        surface_points_df:  A pn.Dataframe object with X, Y, Z, and surface columns
+        orientations_df: A pn.Dataframe object with X, Y, Z, surface columns and pole or orientation columns
+        **kwargs:
+
+    Returns:
+        Modified df
+    """
+
+    r_ = None
+
+    if surface_points_df is not None:
+        geo_model.set_surface_points(surface_points_df, **kwargs)
+        r_ = 'surface_points'
+
+    elif orientations_df is not None:
+        geo_model.set_orientations(orientations_df, **kwargs)
+        r_ = 'data' if r_ == 'surface_points' else 'orientations'
+
+    else:
+        raise AttributeError('You need to pass at least one dataframe')
+
+    return get_data(geo_model, itype=r_)
+
+
+def set_orientation_from_surface_points(geo_model, indices_array):
+    """
+    Create and set orientations from at least 3 points of the :attr:`gempy.data_management.InputData.surface_points`
+     Dataframe
+
+    Args:
+        geo_model (:class:`Model`):
+        indices_array (array-like): 1D or 2D array with the pandas indices of the
+          :attr:`surface_points`. If 2D every row of the 2D matrix will be used to create an
+          orientation
+
+
+    Returns:
+        :attr:`orientations`: Already updated inplace
+    """
+
+    if np.ndim(indices_array) == 1:
+        indices = indices_array
+        form = geo_model._surface_points.df['surface'].loc[indices].unique()
+        assert form.shape[0] == 1, 'The interface points must belong to the same surface'
+        form = form[0]
+
+        ori_parameters = geo_model._orientations.create_orientation_from_surface_points(geo_model._surface_points, indices)
+        geo_model.add_orientations(
+            X=ori_parameters[0],
+            Y=ori_parameters[1],
+            Z=ori_parameters[2],
+            orientation=ori_parameters[3:6],
+            pole_vector=ori_parameters[6:9],
+            surface=form
+        )
+    elif np.ndim(indices_array) == 2:
+        for indices in indices_array:
+            form = geo_model._surface_points.df['surface'].loc[indices].unique()
+            assert form.shape[0] == 1, 'The interface points must belong to the same surface'
+            form = form[0]
+            ori_parameters = geo_model._orientations.create_orientation_from_surface_points(
+                geo_model._surface_points, indices)
+            geo_model.add_orientations(X=ori_parameters[0], Y=ori_parameters[1], Z=ori_parameters[2],
+                                       orientation=ori_parameters[3:6], pole_vector=ori_parameters[6:9],
+                                       surface=form)
+
+    return geo_model._orientations
+
+
+def select_nearest_surfaces_points(geo_model, surface_points, searchcrit):
+    """
+    Find the neighbour points of the same surface
+    by given radius (radius-search) or fix number (knn).
+    Parameters
+    ----------
+    geo_model : geo_model
+        GemPy-model.
+    surface_points: Pandas-dataframe
+        Contains the dataframe of the (point-)data from the GemPy-model.
+    searchcrit : int or float
+        if is int: uses knn-search.
+        if is float: uses radius-search.
+    """
+
+    from sklearn.neighbors import NearestNeighbors
+
+    # extract surface names
+    surfaces = np.unique(surface_points['surface'])
+    neighbours = []
+    # for each surface
+    if isinstance(searchcrit, int):  # in case knn-search
+        searchcrit = searchcrit + 1  # because the point itself is also found
+        for s in range(surfaces.size):
+            # extract point-ids
+            i_surfaces = surface_points['surface'] == surfaces[s]
+            # extract point coordinates
+            p_surfaces = surface_points[i_surfaces][['X', 'Y', 'Z']]
+            # create search-tree
+            Tree = NearestNeighbors(n_neighbors=searchcrit)
+            # add data to tree
+            Tree.fit(p_surfaces)
+            # find neighbours
+            neighbours_surfaces = Tree.kneighbors(p_surfaces, n_neighbors=searchcrit,
+                                                  return_distance=False)
+            # add neighbours with initial index to total list
+            for n in neighbours_surfaces:
+                neighbours.append(p_surfaces.index[n])
+    else:  # in case radius-search
+        for s in range(surfaces.size):
+            # extract point-ids
+            i_surfaces = surface_points['surface'] == surfaces[s]
+            # extract point coordinates
+            p_surfaces = surface_points[i_surfaces][['X', 'Y', 'Z']]
+            # create search-tree
+            Tree = NearestNeighbors(radius=searchcrit)
+            # add data to tree
+            Tree.fit(p_surfaces)
+            # find neighbours (attention: relativ index!)
+            neighbours_surfaces = Tree.radius_neighbors(p_surfaces,
+                                                        radius=searchcrit,
+                                                        return_distance=False)
+            # add neighbours with initial index to total list
+            for n in neighbours_surfaces:
+                neighbours.append(p_surfaces.index[n])
+    return neighbours
+
+
+def set_orientation_from_neighbours(geo_model, neighbours):
+    """
+    Calculates the orientation of one point with its neighbour points
+    of the same surface.
+    Parameters
+    ----------
+    geo_model : geo_model
+        GemPy-model.
+    neighbours : Int64Index
+        point-neighbours-id, first id is the point itself.
+    """
+
+    from sklearn.preprocessing import normalize
+
+    # compute normal vector for the point
+    if neighbours.size > 2:
+        # extract point coordinates
+        coo = geo_model._surface_points.df.loc[neighbours][['X', 'Y', 'Z']]
+        # calculates covariance matrix
+        cov = np.cov(coo.T)
+        # calculate normalized normal vector
+        normvec = normalize(np.cross(cov[0].T, cov[1].T).reshape(1, -1))[0]
+        # check orientation of normal vector (has to be oriented to sky)
+        if normvec[2] < 0:
+            normvec = normvec * (-1)
+        # append to the GemPy-model
+        geo_model.add_orientations(geo_model._surface_points.df['X'][neighbours[0]],
+                                   geo_model._surface_points.df['Y'][neighbours[0]],
+                                   geo_model._surface_points.df['Z'][neighbours[0]],
+                                   geo_model._surface_points.df['surface'][neighbours[0]],
+                                   normvec.tolist())
+    # if computation is impossible set normal vector to default orientation
+    else:
+        print("orientation calculation of point" + str(neighbours[0]) + "is impossible")
+        print("-> default vector is set [0,0,1]")
+        geo_model.add_orientations(geo_model._surface_points.df['X'][neighbours[0]],
+                                   geo_model._surface_points.df['Y'][neighbours[0]],
+                                   geo_model._surface_points.df['Z'][neighbours[0]],
+                                   geo_model._surface_points.df['surface'][neighbours[0]],
+                                   orientation=[0, 0, 1])
+    return geo_model._orientations
+
+
+def set_orientation_from_neighbours_all(geo_model, neighbours):
+    """
+    Calculates the orientations for all points with given neighbours.
+    Parameters
+    ----------
+    geo_model : geo_model
+        GemPy-model.
+    neighbours : list of Int64Index
+        point-neighbours-IDs, the first id is the id of the point
+        for which the orientation is calculated.
+    """
+
+    # compute normal vector for the points
+    for n in neighbours:
+        set_orientation_from_neighbours(geo_model, n)
+
+    return geo_model._orientations
```

### Comparing `gempy-2.2b10.dev1/gempy/assets/coKriging.py` & `gempy-2.3.0/gempy/assets/coKriging.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,1072 +1,1072 @@
-"""
-
-    This file is part of gempy.
-
-    gempy is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    gempy is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
-
-Module with classes and methods to perform kriging of elements (and at some point exploit the potential field to
-choose the directions of the variograms)
-
-Tested on Ubuntu 16
-
-Created on 1/5/2017
-
-@author: Miguel de la Varga
-"""
-
-import theano
-import theano.tensor as T
-import matplotlib.pyplot as plt
-import pymc3 as pm
-import numpy as np
-import pandas as pn
-
-from bokeh.io import show
-import bokeh.layouts as bl
-import bokeh.plotting as bp
-
-
-def choose_lithology_elements(df, litho, elem=None, coord = True):
-    """
-    litho(str): Name of the lithology-domain
-    elem(list): List of strings with elements you want to analyze
-    """
-    # Choosing just the opx litology
-    if elem is not None:
-        if coord:
-            domain = df[df['Lithology'] == litho][np.append(['X', 'Y', 'Z'], elem)]
-        else:
-            domain = df[df['Lithology'] == litho][elem]
-        # Drop negative values
-        domain = domain[(domain[elem] > 0).all(1)]
-    else:
-        domain = df[df['Lithology'] == litho][['X', 'Y', 'Z']]
-
-    return domain
-
-
-def select_segmented_grid(df, litho, grid, block):
-
-    block = np.squeeze(block)
-    assert grid.shape[0] == block.shape[0], 'The grid you want to use for kriging and the grid used for the layers ' \
-                                            'segmentation are not the same'
-
-    litho_num = df['Lithology Number'][df["Lithology"] == litho].iloc[0]
-    segm_grid = grid[block == litho_num]
-    return segm_grid
-
-
-def transform_data(df_o, n_comp=1, log10=False):
-    """
-    Method to improve the normality of the input data before perform krigin
-    Args:
-        df_o: Dataframe with the data to interpolate
-        n_comp: Number of component in case of multimodal data
-        log10 (bool): If true return the log in base 10 of the properties:
-
-    Returns:
-        pandas.core.frame.DataFrame: Data frame with the transformed data
-    """
-
-    import copy
-    df = copy.deepcopy(df_o)
-
-    # Take log to try to aproximate better the normal distributions
-    if log10:
-        print('computing log')
-        df[df.columns.difference(['X', 'Y', 'Z'])] = np.log10(df[df.columns.difference(['X', 'Y', 'Z'])])
-
-    # Finding n modes in the data
-    if n_comp > 1:
-        from sklearn import mixture
-        gmm = mixture.GaussianMixture(n_components=n_comp,
-                                      covariance_type='full').fit(df[df.columns.difference(['X', 'Y', 'Z'])])
-
-        # Adding the categories to the pandas frame
-        labels_all = gmm.predict(df[df.columns.difference(['X', 'Y', 'Z'])])
-        df['cluster'] = labels_all
-    return df
-
-
-def theano_sed():
-    """
-    Function to create a theano function to compute the euclidian distances efficiently
-    Returns:
-        theano.compile.function_module.Function: Compiled function
-
-    """
-
-    theano.config.compute_test_value = "ignore"
-
-    # Set symbolic variable as matrix (with the XYZ coords)
-    coord_T_x1 = T.dmatrix()
-    coord_T_x2 = T.dmatrix()
-
-    # Euclidian distances function
-    def squared_euclidean_distances(x_1, x_2):
-        sqd = T.sqrt(T.maximum(
-            (x_1 ** 2).sum(1).reshape((x_1.shape[0], 1)) +
-            (x_2 ** 2).sum(1).reshape((1, x_2.shape[0])) -
-            2 * x_1.dot(x_2.T), 0
-        ))
-        return sqd
-
-    # Compiling function
-    f = theano.function([coord_T_x1, coord_T_x2],
-                        squared_euclidean_distances(coord_T_x1, coord_T_x2),
-                        allow_input_downcast=False)
-    return f
-
-
-# This is extremily ineficient. Try to vectorize it in theano, it is possible to gain X100
-def compute_variogram(df, properties, euclidian_distances, tol=10, lags=np.logspace(0, 2.5, 100), plot=[]):
-    """
-    Compute the experimental variogram and cross variogram for a par of properties
-    Args:
-        df (pandas.core.frame.DataFrame): Dataframe with the properties and coordinates used in the experimental
-         variogram computation
-        properties (list): List of the two properties to compute the semivariogram.
-        euclidian_distances (numpy.array): Precomputed distances of the euclidian distances
-        tol (float): Tolerance
-        lags (list): List of lags to compute the experimental variogram
-        plot (bool): If true plot the experimental variogram after computed
-
-    Returns:
-        list: semvariance aor cross-semivariance
-    """
-
-    # Tiling the properties to a square matrix
-    element = (df[properties[0]].values.reshape(-1, 1) -
-               np.tile(df[properties[1]], (df[properties[1]].shape[0], 1))) ** 2
-
-    # Semivariance computation
-    semivariance_lag = []
-
-    # Looping every lag to compute the semivariance
-    for i in lags:
-        # Selecting the points at the given lag and tolerance
-        points_at_lag = ((euclidian_distances > i - tol) * (euclidian_distances < i + tol))
-
-        # Extracting the values of the properties of the selected lags
-        var_points = element[points_at_lag]
-
-        # Appending the semivariance
-        semivariance_lag = np.append(semivariance_lag, np.mean(var_points) / 2)
-
-    if "experimental" in plot:
-        # Visualizetion of the experimental variogram
-        plt.plot(lags, semivariance_lag, 'o')
-
-    return semivariance_lag
-
-
-def exp_lags(max_range, exp=2, n_lags=100):
-    """
-    Function to create a more specific exponential distance between the lags in case that log10 gives too much weight
-    to the smaller lags
-    Args:
-        max_range(float): Maximum distance
-        exp (float): Exponential degree
-        n_lags (int): Number of lags
-
-    Returns:
-        list: lags
-
-    """
-    lags = np.empty(0)
-    for i in range(n_lags):
-        lags = np.append(lags, i ** exp)
-    lags = lags / lags.max() * max_range
-    return lags
-
-
-def compute_crossvariogram(df, properties_names, euclidian_distances=None, **kwargs):
-    """
-    Compute the experimental crossvariogram of all properties given
-    Args:
-        df (pandas.core.frame.DataFrame): Dataframe with the properties and coordinates used in the experimental
-         variogram computation
-        properties_names (list str): List of strings with the properties to compute
-        euclidian_distances (numpy.array): Precomputed euclidian distances. If None they are computed inplace
-        Keyword Args:
-            - lag_exp: Degree of the exponential. If None log10
-            - lag_range: Maximum distance to compute a lag
-            - n_lags: Number of lags
-
-    Returns:
-        pandas.core.frame.DataFrame: Every experimental cross-variogram
-    """
-
-    lag_exp = kwargs.get('lag_exp', None)
-    lag_range = kwargs.get('lag_range', 500)
-    n_lags = kwargs.get('n_lags', 100)
-
-    # Choosing the lag array
-    if lag_exp is not None:
-        lags = exp_lags(lag_range, lag_exp, n_lags)
-    else:
-        lags = np.logspace(0, np.log10(lag_range), n_lags)
-
-    # Compute euclidian distance
-    if not euclidian_distances:
-        euclidian_distances = theano_sed()(df[['X', 'Y', 'Z']], df[['X', 'Y', 'Z']])
-
-    # Init dataframe to store the results
-    experimental_variograms_frame = pn.DataFrame()
-
-    # This is extremily ineficient. Try to vectorize it in theano, it is possible to gain X100
-    # Nested loop. DEPRECATED enumerate
-    for i in properties_names:
-        for j in properties_names:
-            col_name = i + '-' + j
-            values = compute_variogram(df, [i, j], euclidian_distances, lags=lags)
-            experimental_variograms_frame[col_name] = values
-
-    # Add lags column for plot mainly
-    experimental_variograms_frame['lags'] = lags
-
-    return experimental_variograms_frame
-
-
-class SGS(object):
-    """
-    Class that contains the necessary methods to perform a sequential gaurssian simmulation from experimental variograms
-    """
-    def __init__(self, exp_var, properties=None,  n_exp=2, n_gauss=2,
-                 data=None, grid=None, grid_to_inter=None, lithology=None, geomodel=None):
-        """
-
-        Args:
-            exp_var (pandas.core.frame.DataFrame): Dataframe with the experimental variograms. Columns are the variables
-            while raws the lags
-            properties (list strings): Variables to be used
-            n_exp (int): number of exponential basic functions
-            n_gauss (int): number of gaussian basic functions
-        """
-
-        # Analytical covariance
-        # ---------------------
-        self.exp_var_raw = exp_var
-        if not properties:
-            self.properties = exp_var.columns[['ppm' in i for i in exp_var.columns]]
-        else:
-            self.properties = properties
-        self.n_properties = len(self.properties)
-        self.lags = self.exp_var_raw['lags']
-        self.exp_var, self.nuggets = self.preprocess()
-
-        self.n_exp = n_exp
-        self.n_gauss = n_gauss
-        self.trace = None
-
-        # Kriging
-        # -------
-        self.data = data
-        self.data_to_inter = None
-        self.grid = grid
-        self.grid_to_inter = grid_to_inter
-        self.lithology = lithology
-        self.geomodel = geomodel
-
-        # Theano functions
-        # ----------------
-        self.SED_f = theano_sed()
-
-        self._recursion_check = 0
-
-    def select_segmented_grid(self, grid=None, df=None, litho=None, block=None):
-        """
-        Extract from the full model the points belonging to a given domain (litho)
-        Args:
-            grid (numpy.arrau): Full model grid
-            df (pandas.core.frame.DataFrame): with all data
-            litho (str): Name of the lithology to interpolate
-            block (numpy.array): 3D block model generated by gempy
-
-        Returns:
-
-        """
-
-        # If we do not pass the attributes but are already a property of the object extract it
-        if grid is None:
-            grid = self.grid
-
-        if block is not None:
-            block = np.squeeze(block)
-        else:
-            block = self.geomodel
-
-        if df is None:
-            df = self.data
-
-        if litho is None:
-            litho = self.lithology
-
-        # Check that the attributes have value
-        assert all([any(block), ~df.empty, litho, np.any(grid)]), "Some of the attributes are not provided"
-        assert grid.shape[0] == block.shape[0], 'The grid you want to use for kriging and the grid used for the layers ' \
-                                                'segmentation are not the same'
-
-        # Translate lithology name to lithology number, i.e. the value of the lithology in the gempy block
-        litho_num = df['Lithology Number'][df["Lithology"] == litho].iloc[0]
-
-        # Extract from the grid the XYZ coordinates where the gempy block model is the given lithology
-        segm_grid = grid[block == litho_num]
-
-        # Set the segmented grid
-        self.grid_to_inter = segm_grid
-
-        return segm_grid
-
-    def choose_lithology_elements(self, df=None, litho=None, elem=None, coord=True):
-        """
-        Choose from the whole input data, those points which fall into the domain of interest
-        litho(str): Name of the lithology-domain
-        elem(list): List of strings with elements you want to analyze
-        """
-
-        # If we do not pass the attributes but are already a property of the object extract it
-        if not df:
-            df = self.data
-
-        if not litho:
-            litho = self.lithology
-
-        # Check that the attributes have value
-        assert all([~df.empty, litho]), "Some of the attributes are not provided"
-
-        # Choosing just one lithology
-        if elem is not None:
-            if coord:
-                domain = df[df['Lithology'] == litho][np.append(['X', 'Y', 'Z'], elem)]
-            else:
-                domain = df[df['Lithology'] == litho][elem]
-            # Drop negative values
-            domain = domain[(domain[elem] > 0).all(1)]
-        else:
-            domain = df[df['Lithology'] == litho][['X', 'Y', 'Z']]
-
-        # Set the segmented data
-        self.data_to_inter = domain
-
-        return domain
-
-    def set_data(self, data):
-        """
-        Data setter
-        Args:
-            data (pandas.core.frame.DataFrame): Dataframe with coordinates and values of the properties of interest
-        """
-        self.data = data
-
-    def set_grid_to_inter(self, grid):
-        """
-        Grid setter
-        Args:
-            grid (numpy.array): Grid object from gempy with the points of interest of the model
-        """
-        self.grid_to_inter = grid
-
-    def set_lithology(self, lithology):
-        """
-        Lithology setter
-        Args:
-            lithology (str): Name of the domain or lithology of interest
-        """
-        self.lithology = lithology
-
-    def set_geomodel(self, geomodel):
-        """
-        gempy model setter
-        Args:
-            geomodel (numpy.array): gempy block model
-        """
-        self.geomodel = geomodel
-
-    def set_trace(self, trace):
-        """
-        Analytical covarinace trace setter
-        Args:
-            trace (pymc3.trace): trace with the sill, range and weights of each property
-        """
-        self.trace = trace
-
-    def preprocess(self):
-        """
-        Normalization of data between 0 and 1 and subtraction of the nuggets
-        Returns:
-            pandas.core.frame.DataFrame: Dataframe containing the transformed data
-            pandas.core.frame.DataFrame: Containing the substracted nuggets
-
-        """
-        import sklearn.preprocessing as skp
-
-        # Normalization
-        scaled_data = pn.DataFrame(skp.minmax_scale(self.exp_var_raw[self.properties]), columns=self.properties)
-
-        # Nuggets
-        nuggets = scaled_data[self.properties].iloc[0]
-        processed_data = scaled_data - nuggets
-        return processed_data, nuggets
-
-    def plot_experimental(self, transformed=False):
-        """
-        Plotting the experimental data either transformed (see preprocess doc) or not
-        Args:
-            transformed (bool): if true plot the transformed data
-
-        Returns:
-            matplotlib.plot: plot of experimental variogram
-        """
-
-        if transformed:
-            plot = self.exp_var.plot(x=self.lags, y=self.properties, subplots=True, kind ='line',
-                                     style='.',
-                                     layout=(int(np.sqrt(self.n_properties)), int(np.sqrt(self.n_properties))),
-                                     figsize=(16, 8))
-        else:
-            plot = self.exp_var_raw.plot(x=self.lags, y=self.properties, subplots=True, kind='line',
-                                         style='.',
-                                         layout=(int(np.sqrt(self.n_properties)), int(np.sqrt(self.n_properties))),
-                                         figsize=(16, 8))
-        return plot
-
-    def fit_cross_cov(self, n_exp=2, n_gauss=2, range_mu=None):
-        """
-        Fit an analytical covariance to the experimental data.
-        Args:
-            n_exp (int): number of exponential basic functions
-            n_gauss (int): number of gaussian basic functions
-            range_mu: prior mean of the range. Default mean of the lags
-
-        Returns:
-            pymc.Model: PyMC3 model to be sampled using MCMC
-        """
-        self.n_exp = n_exp
-        self.n_gauss = n_gauss
-        n_var = self.n_properties
-        df = self.exp_var
-        lags = self.lags
-
-        # Prior standard deviation for the error of the regression
-        prior_std_reg = df.std(0).max() * 10
-
-        # Prior value for the mean of the ranges
-        if not range_mu:
-            range_mu = lags.mean()
-
-        # pymc3 Model
-        with pm.Model() as model:  # model specifications in PyMC3 are wrapped in a with-statement
-            # Define priors
-            sigma = pm.HalfCauchy('sigma', beta=prior_std_reg, testval=1., shape=n_var)
-
-            psill = pm.Normal('sill', prior_std_reg, sd=.5 * prior_std_reg, shape=(n_exp + n_gauss))
-            range_ = pm.Normal('range', range_mu, sd=range_mu * .3, shape=(n_exp + n_gauss))
-
-            lambda_ = pm.Uniform('weights', 0, 1, shape=(n_var * (n_exp + n_gauss)))
-
-            # Exponential covariance
-            exp = pm.Deterministic('exp',
-                                   # (lambda_[:n_exp*n_var]*
-                                   psill[:n_exp] *
-                                   (1. - T.exp(T.dot(-lags.values.reshape((len(lags), 1)),
-                                                     (range_[:n_exp].reshape((1, n_exp)) / 3.) ** -1))))
-
-            gauss = pm.Deterministic('gaus',
-                                     psill[n_exp:] *
-                                     (1. - T.exp(T.dot(-lags.values.reshape((len(lags), 1)) ** 2,
-                                                       (range_[n_exp:].reshape((1, n_gauss)) * 4 / 7.) ** -2))))
-
-            # We stack the basic functions in the same matrix and tile it to match the number of properties we have
-            func = pm.Deterministic('func', T.tile(T.horizontal_stack(exp, gauss), (n_var, 1, 1)))
-
-            # We weight each basic function and sum them
-            func_w = pm.Deterministic("func_w", T.sum(func * lambda_.reshape((n_var, 1, (n_exp + n_gauss))), axis=2))
-
-            for e, cross in enumerate(df.columns):
-                # Likelihoods
-                pm.Normal(cross + "_like", mu=func_w[e], sd=sigma[e], observed=df[cross].values)
-        return model
-
-    def plot_cross_variograms(self, iter_plot=200, trace=None, experimental=None):
-        """
-        Plot the analytical cross-variogram of a given MCMC inference
-        Args:
-            iter_plot (int): Number of traces to plot
-            trace (pymc3.trace): trace with the sill, range and weights of each property
-            experimental (bool): if True plot the experimental variogram as well
-
-        Returns:
-            None
-        """
-
-        if not trace:
-            trace = self.trace
-        assert trace, 'set the trace to the object'
-
-        n_exp = self.n_exp
-        n_gauss = self.n_gauss
-        lags = self.lags
-        # DEP- n_equations = trace['weights'].shape[1]
-        n_iter = trace['weights'].shape[0]
-        lags_tiled = np.tile(lags, (iter_plot, 1))
-        b_var = []
-        for i in range(0, self.n_properties):  # DEP- n_equations, (n_exp+n_gaus)):
-            # Init tensor
-            b = np.zeros((len(lags), n_iter, 0))
-            for i_exp in range(0, n_exp):
-
-                b = np.dstack((b, trace['weights'][:, i_exp + i * (n_exp + n_gauss)] *
-                               exp_vario(lags, trace['sill'][:, i_exp], trace['range'][:, i_exp])))
-            for i_gauss in range(n_exp, n_gauss + n_exp):
-                b = np.dstack((b, trace['weights'][:, i_gauss + i * (n_exp + n_gauss)] *
-                               gaus_vario(lags, trace['sill'][:, i_gauss], trace['range'][:, i_gauss])))
-
-            # Sum the contributins of each function
-            b_all = b.sum(axis=2)
-            # Append each variable
-            b_var.append(b_all[:, -iter_plot:].T)
-
-        # Bokeh code to plot this
-        p_all = []
-        for e, el in enumerate(self.properties):
-            p = bp.figure()#x_axis_type="log")
-            p.multi_line(list(lags_tiled), list(b_var[e]), color='olive', alpha=0.08)
-            if experimental:
-                p.scatter(self.lags, y=self.exp_var[el], color='navy', size=2)
-            p.title.text = el
-            p.xaxis.axis_label = "lags"
-            p.yaxis.axis_label = "Semivariance"
-
-            p_all = np.append(p_all, p)
-
-        grid = bl.gridplot(list(p_all), ncols=5, plot_width=250, plot_height=150)
-
-        show(grid)
-
-    def exp_vario(self, lags, sill, range_):
-        """
-        Vectorial computation of exponential variogram
-        Args:
-            lags (numpy.array): Distances
-            sill (numpy.array): Array of sills. The shape will be number of properties by number of exponential
-             basic functions
-            range_ (numpy.array): Array of ranges. The shape will be number of properties by number of exponential
-             basic functions
-
-        Returns:
-            numpy.array: Exponential variogram for every lag and every sill and range.
-        """
-        return sill * (1 - np.exp(np.dot(-lags.reshape(-1, 1) * 3, range_.reshape(1, -1) ** -1)))
-
-    def gaus_vario(self, lags, sill, range_):
-        """
-        Vectorial computation of gauss variogram
-        Args:
-            lags (numpy.array): Distances
-            sill (numpy.array): Array of sills. The shape will be number of properties by number of gauss
-             basic functions
-            range_ (numpy.array): Array of ranges. The shape will be number of properties by number of gauss
-             basic functions
-
-        Returns:
-            numpy.array: gauss variogram for every lag and every sill and range.
-        """
-        return sill * (1 - np.exp(np.dot(-lags.reshape(-1, 1) ** 2, (range_.reshape(1, -1) * 4 / 7) ** -2)))
-
-    def plot_cross_covariance(self, nuggets=False, iter_plot=200):
-        """
-        Plot the cross covariance for the given properties
-        Args:
-            nuggets (numpy.array): subtracted nuggets
-            iter_plot (int): number of traces to plot
-
-        Returns:
-            None
-        """
-        n_exp = self.n_exp
-        n_gauss = self.n_gauss
-        trace = self.trace
-        lags = self.lags
-
-        n_equations = trace['weights'].shape[1]
-        n_iter = trace['weights'].shape[0]
-        lags_tiled = np.tile(lags, (iter_plot, 1))
-        b_var = []
-        for i in range(0, self.n_properties):  # n_equations, (n_exp+n_gaus)):
-            # Init tensor
-            b = np.zeros((len(lags), n_iter, 0))
-            for i_exp in range(0, n_exp):
-                # print(i_exp, "exp")
-                b = np.dstack((b, trace['weights'][:, i_exp + i * (n_exp + n_gauss)] *
-                               exp_vario(lags, trace['sill'][:, i_exp], trace['range'][:, i_exp])))
-            for i_gaus in range(n_exp, n_gauss + n_exp):
-                # print(i_gaus)
-                b = np.dstack((b, trace['weights'][:, i_gaus + i * (n_exp + n_gauss)] *
-                               gaus_vario(lags, trace['sill'][:, i_gaus], trace['range'][:, i_gaus])))
-            # Sum the contributins of each function
-            if nuggets:
-                b_all = 1 - (b.sum(axis=2) + self.nuggets[i])
-            else:
-                b_all = 1 - (b.sum(axis=2))
-            # Append each variable
-            b_var.append(b_all[:, -iter_plot:].T)
-
-        p_all = []
-        for e, el in enumerate(self.properties):
-            p = bp.figure(x_axis_type="log")
-            p.multi_line(list(lags_tiled), list(b_var[e]), color='olive', alpha=0.08)
-
-            p.title.text = el
-            p.xaxis.axis_label = "lags"
-            p.yaxis.axis_label = "Semivariance"
-
-            p_all = np.append(p_all, p)
-
-        grid = bl.gridplot(list(p_all), ncols=5, plot_width=250, plot_height=150)
-
-        show(grid)
-
-    def solve_kriging(self, selection_A, selection_b, #selected_coord_data, selected_values_data, selected_grid_to_inter, trace,
-                      nuggets=None, n_var=1, n_exp=2, n_gauss=2):
-        """
-        Solve the kriging system for n given point of the grid_to_inter property selected by selection_b using n
-        points of data_to_inter given by selection_A
-        Args:
-            selection_A (bool): input points used in A matrix
-            selection_b (bool): points to interpolate from the grid
-            nuggets (numpy.array): Nugget effect of each cross variogram. If None take property
-            n_var: number of variables
-            n_exp (int): number of exponential basic functions
-            n_gauss (int): number of gaussian basic functions
-
-        Returns:
-
-        """
-
-        # Select input data and compute its euclidean distances
-        selected_coord_data = self.data_to_inter[selection_A][['X', 'Y', 'Z']]
-        selected_values_data = self.data_to_inter[selection_A][self.data_to_inter.columns.difference(['X', 'Y', 'Z'])].values
-        h_A = self.SED_f(selected_coord_data, selected_coord_data)
-
-        # Select points of grid to interpolate and compute the euclidean distances respect the input data
-        selected_grid_to_inter = self.grid_to_inter[selection_b]
-        h_b = self.SED_f(selected_coord_data, selected_grid_to_inter)
-
-        # Parameters for the covariances
-        trace = self.trace
-        nuggets = self.nuggets
-        n_var = int(np.sqrt(self.n_properties))
-        n_exp = self.n_exp
-        n_gauss = self.n_gauss
-
-        # Choose a random trace to conserve the covariance uncertainty of the regression
-        sample = np.random.randint(trace['weights'].shape[0] - 1000, trace['weights'].shape[0])
-
-       # Compute cross-covariances
-        cov_h = cross_covariance(trace, h_A, sample=sample,
-                                 nuggets=nuggets, n_var=n_var, n_exp=n_exp, n_gaus=n_gauss, ordinary=True)
-        cov_b = cross_covariance(trace, h_b, sample=sample, nuggets=nuggets, n_var=n_var, n_exp=n_exp,
-                                 n_gaus=n_gauss,
-                                 ordinary=True)
-
-        # Solve kriging system
-        k_weights = np.linalg.solve(cov_h, cov_b)
-
-        # Number of points to interpolate
-        npti = selected_grid_to_inter.shape[0]
-
-        # Repeat the input data for every point to interpolate
-        svd_tmp = np.tile(np.repeat(selected_values_data, npti, axis=1), (n_var, 1))
-
-        # Sol ordinary kriging mean
-        k_mean = (svd_tmp * k_weights[:-n_var]).sum(axis=0)
-
-        # Sol ordinary kriging std
-        k_std = svd_tmp.std(axis=0) - (k_weights * cov_b)[:-n_var].sum(axis=0) +\
-                (k_weights * cov_b)[-n_var:].sum(axis=0)
-
-        assert all(k_std) > -10, "A standard deviation of kringing is really off. Check nothing is wrong"
-        # Set negatives to 0
-        k_std[k_std < 0] = 0.1
-
-        # Check the results make sense else take another sample and recompute
-        import scipy
-        l_low, l_high = scipy.stats.norm.interval(.95, loc=np.mean(selected_values_data, axis=0),
-                                                  scale=np.std(selected_values_data, axis=0))
-
-        if not np.all((k_mean > l_low) * (k_mean < l_high)):
-
-            k_mean, k_std, cov_h, cov_b, k_weights, sample = self.solve_kriging(selection_A, selection_b)
-            self._recursion_check += 1
-            assert self._recursion_check<500, 'Too many recursions. Probably something goes wrong'
-
-        else:
-            self._recursion_check = 0
-            values_interp = np.random.normal(k_mean, k_std)
-
-        return k_mean, k_std, cov_h, cov_b, k_weights, sample  # , k_std# - svd_tmp.std(axis=0)
-
-
-def fit_cross_cov(df, lags, n_exp=2, n_gaus=2, range_mu=None):
-    n_var = df.columns.shape[0]
-    n_basis_f = n_var * (n_exp + n_gaus)
-    prior_std_reg = df.std(0).max() * 10
-    #
-    if not range_mu:
-        range_mu = lags.mean()
-
-    # Because is a experimental variogram I am not going to have outliers
-    nugget_max = df.values.max()
-    # print(n_basis_f, n_var*n_exp, nugget_max, range_mu, prior_std_reg)
-    # pymc3 Model
-    with pm.Model() as model:  # model specifications in PyMC3 are wrapped in a with-statement
-        # Define priors
-        sigma = pm.HalfCauchy('sigma', beta=prior_std_reg, testval=1., shape=n_var)
-
-        psill = pm.Normal('sill', prior_std_reg, sd=.5 * prior_std_reg, shape=(n_exp + n_gaus))
-        range_ = pm.Normal('range', range_mu, sd=range_mu * .3, shape=(n_exp + n_gaus))
-        #  nugget = pm.Uniform('nugget', 0, nugget_max, shape=n_var)
-
-        lambda_ = pm.Uniform('weights', 0, 1, shape=(n_var * (n_exp + n_gaus)))
-
-        # Exponential covariance
-        exp = pm.Deterministic('exp',
-                               # (lambda_[:n_exp*n_var]*
-                               psill[:n_exp] *
-                               (1. - T.exp(T.dot(-lags.values.reshape((len(lags), 1)),
-                                                 (range_[:n_exp].reshape((1, n_exp)) / 3.) ** -1))))
-
-        gaus = pm.Deterministic('gaus',
-                                psill[n_exp:] *
-                                (1. - T.exp(T.dot(-lags.values.reshape((len(lags), 1)) ** 2,
-                                                  (range_[n_exp:].reshape((1, n_gaus)) * 4 / 7.) ** -2))))
-
-        func = pm.Deterministic('func', T.tile(T.horizontal_stack(exp, gaus), (n_var, 1, 1)))
-
-        func_w = pm.Deterministic("func_w", T.sum(func * lambda_.reshape((n_var, 1, (n_exp + n_gaus))), axis=2))
-        #           nugget.reshape((n_var,1)))
-
-        for e, cross in enumerate(df.columns):
-            # Likelihoods
-            pm.Normal(cross + "_like", mu=func_w[e], sd=sigma[e], observed=df[cross].values)
-    return model
-
-
-def exp_vario(lags, sill, range_):
-    return sill * (1 - np.exp(np.dot(-lags.reshape(-1, 1) * 3, range_.reshape(1, -1) ** -1)))
-
-
-def gaus_vario(lags, sill, range_):
-    return sill * (1 - np.exp(np.dot(-lags.reshape(-1, 1) ** 2, (range_.reshape(1, -1) * 4 / 7) ** -2)))
-
-
-def plot_cross_variograms(trace, lags, df, n_exp=2, n_gaus=2, iter_plot=200, experimental=None):
-    n_equations = trace['weights'].shape[1]
-    n_iter = trace['weights'].shape[0]
-    lags_tiled = np.tile(lags, (iter_plot, 1))
-    b_var = []
-    for i in range(0, df.shape[1]):  # n_equations, (n_exp+n_gaus)):
-        # Init tensor
-        b = np.zeros((len(lags), n_iter, 0))
-        for i_exp in range(0, n_exp):
-            # print(i_exp, "exp")
-            b = np.dstack((b, trace['weights'][:, i_exp + i * (n_exp + n_gaus)] *
-                           exp_vario(lags, trace['sill'][:, i_exp], trace['range'][:, i_exp])))
-        for i_gaus in range(n_exp, n_gaus + n_exp):
-            # print(i_gaus)
-            b = np.dstack((b, trace['weights'][:, i_gaus + i * (n_exp + n_gaus)] *
-                           gaus_vario(lags, trace['sill'][:, i_gaus], trace['range'][:, i_gaus])))
-        # Sum the contributins of each function
-        b_all = b.sum(axis=2)
-        # Append each variable
-        b_var.append(b_all[:, -iter_plot:].T)
-
-    p_all = []
-    for e, el in enumerate(df.columns):
-        p = bp.figure(x_axis_type="log")
-        p.multi_line(list(lags_tiled), list(b_var[e]), color='olive', alpha=0.08)
-        if experimental is not None:
-            p.scatter(experimental['lags'], y=experimental[el], color='navy', size=2)
-        p.title.text = el
-        p.xaxis.axis_label = "lags"
-        p.yaxis.axis_label = "Semivariance"
-
-        p_all = np.append(p_all, p)
-
-    grid = bl.gridplot(list(p_all), ncols=5, plot_width=200, plot_height=150)
-
-    show(grid)
-
-
-def plot_cross_covariance(trace, lags, df, n_exp=2, n_gaus=2, nuggets=None, iter_plot=200):
-    n_equations = trace['weights'].shape[1]
-    n_iter = trace['weights'].shape[0]
-    lags_tiled = np.tile(lags, (iter_plot, 1))
-    b_var = []
-    for i in range(0, df.shape[1]):  # n_equations, (n_exp+n_gaus)):
-        # Init tensor
-        b = np.zeros((len(lags), n_iter, 0))
-        for i_exp in range(0, n_exp):
-            # print(i_exp, "exp")
-            b = np.dstack((b, trace['weights'][:, i_exp + i * (n_exp + n_gaus)] *
-                           exp_vario(lags, trace['sill'][:, i_exp], trace['range'][:, i_exp])))
-        for i_gaus in range(n_exp, n_gaus + n_exp):
-            # print(i_gaus)
-            b = np.dstack((b, trace['weights'][:, i_gaus + i * (n_exp + n_gaus)] *
-                           gaus_vario(lags, trace['sill'][:, i_gaus], trace['range'][:, i_gaus])))
-        # Sum the contributins of each function
-        if nuggets is not None:
-            b_all = 1 - (b.sum(axis=2) + nuggets[i])
-        else:
-            b_all = 1 - (b.sum(axis=2))
-        # Append each variable
-        b_var.append(b_all[:, -iter_plot:].T)
-
-    p_all = []
-    for e, el in enumerate(df.columns):
-        p = bp.figure(x_axis_type="log")
-        p.multi_line(list(lags_tiled), list(b_var[e]), color='olive', alpha=0.08)
-
-        p.title.text = el
-        p.xaxis.axis_label = "lags"
-        p.yaxis.axis_label = "Semivariance"
-
-        p_all = np.append(p_all, p)
-
-    grid = bl.gridplot(list(p_all), ncols=5, plot_width=250, plot_height=150)
-
-    show(grid)
-
-
-def cross_covariance(trace, sed, sample, nuggets=None, n_var=1, n_exp=2, n_gaus=2, ordinary=True):
-    """
-
-    Args:
-        trace:
-        sed:
-        nuggets:
-        n_var:
-        n_exp:
-        n_gaus:
-        ordinary:
-
-    Returns:
-
-    """
-    h = np.ravel(sed)
-    n_points = len(h)
-    n_points_r = sed.shape[0]
-    n_points_c = sed.shape[1]
-    #sample = np.random.randint(trace['weights'].shape[0]-200, trace['weights'].shape[0])
-    n_eq = trace['weights'].shape[1]
-    # Exp contribution
-    exp_cont = (np.tile(
-        exp_vario(h, trace['sill'][sample][:n_exp], trace['range'][sample][:n_exp]),
-        n_var**2
-    ) * trace['weights'][sample][np.linspace(0, n_eq-1, n_eq) % (n_exp + n_gaus) < n_exp]).reshape(n_points, n_exp, n_var**2, order="F")
-
-    # Gauss contribution
-    gaus_cont = (np.tile(
-        gaus_vario(h, trace['sill'][sample][n_exp:], trace['range'][sample][n_exp:]),
-        n_var**2
-    ) * trace['weights'][sample][np.linspace(0, n_eq-1, n_eq) % (n_exp + n_gaus) >= n_exp]).reshape(n_points, n_gaus, n_var**2, order="F")
-
-    # Stacking and summing
-    conts = np.hstack((exp_cont, gaus_cont)).sum(axis=1)
-
-    if nuggets is not None:
-        conts += nuggets
-
-    cov = 1 - conts
-
-    cov_str = np.zeros((0, n_points_c*n_var))
-
-    cov_aux = cov.reshape(n_points_r, n_points_c, n_var**2, order='F')
-
-    # This is a incredibly convoluted way to reshape the cross covariance but I did not find anything better
-    for i in range(n_var):
-        cov_str = np.vstack((cov_str,
-                             cov_aux[:, :, i*n_var:(i+1)*n_var].reshape(n_points_r, n_points_c*n_var, order='F')))
-
-    if ordinary:
-        ord = np.zeros((n_var, n_var*n_points_c+n_var))
-        for i in range(n_var):
-            ord[i, n_points_c * i:n_points_c * (i + 1)] = np.ones(n_points_c)
-        cov_str = np.vstack((cov_str, ord[:, :-n_var]))
-
-        # Stack the ordinary values to the C(h)
-        if n_points_r == n_points_c:
-             cov_str = np.hstack((cov_str, ord.T))
-
-    return cov_str
-
-
-def clustering_grid(grid_to_inter, n_clusters=50, plot=False):
-    from sklearn.cluster import KMeans
-    clust = KMeans(n_clusters=n_clusters).fit(grid_to_inter)
-    if plot:
-        fig = plt.figure()
-        ax = fig.add_subplot(111, projection='3d')
-
-        ax.scatter(clust.cluster_centers_[:, 0], clust.cluster_centers_[:, 1], clust.cluster_centers_[:, 2])
-
-        ax.set_xlabel('X Label')
-        ax.set_ylabel('Y Label')
-        ax.set_zlabel('Z Label')
-
-        plt.show()
-
-    return clust
-
-
-def select_points(df, grid_to_inter, cluster, SED_f = theano_sed(), n_rep=10):
-
-    points_cluster = np.bincount(cluster.labels_)
-  #  SED_f = theano_sed()
-
-    for i in range(n_rep):
-        for i_clust in range(cluster.n_clusters):
-            cluster_bool = cluster.labels_ == i_clust
-            cluster_grid = grid_to_inter[cluster_bool]
-            # Mix the values of each cluster
-            if i is 0:
-                np.random.shuffle(cluster_grid)
-
-            size_range = int(points_cluster[i_clust]/n_rep)
-            selected_cluster_grid = cluster_grid[i * size_range:(i + 1) * size_range]
-            dist = SED_f(df, selected_cluster_grid)
-
-            # Checking the radius of the simulation
-            for r in range(100, 1000, 100):
-                select = (dist < r).any(axis=1)
-                if select.sum() > 50:
-                    break
-
-            h_x0 = dist
-            yield (h_x0, select, selected_cluster_grid)
-
-
-def SGS_compute_points(selected_coord_data, selected_grid_to_inter, selected_values_data,
-                trace, nuggets=None, n_var=1, n_exp=2, n_gaus=2):
-    #SED_f = theano_sed()
-
-
-    #SED = SED_f(selected_coord_data, selected_coord_data)
-
-    npti = selected_grid_to_inter.shape[1]
-
-    cov_h = cross_covariance(trace, selected_coord_data,
-                             nuggets=nuggets, n_var=n_var, n_exp=n_exp, n_gaus=n_gaus, ordinary=True)
-    cov_b = cross_covariance(trace, selected_grid_to_inter, nuggets=nuggets, n_var=n_var, n_exp=n_exp, n_gaus=n_gaus,
-                             ordinary=True)
-
-    k_weights = np.linalg.solve(cov_h, cov_b)
-    svd_tmp = np.tile(np.repeat(selected_values_data, npti, axis=1), (n_var, 1))
-
-    # Sol ordinary kriging mean
-    k_mean = (svd_tmp * k_weights[:-n_var]).sum(axis=0)
-
-    # Sol ordinary kriging std
-    k_std = svd_tmp.std(axis=0) - (k_weights * cov_b)[:-n_var].sum(axis=0) + (k_weights * cov_b)[-n_var:].sum(axis=0)
-
-    assert all(k_std) > -10, "A standard deviation of kringing is really off. Check nothing is wrong"
-
-    # Set negatives to 0
-    k_std[k_std < 0] = 0.1
-
-    values_interp = np.random.normal(k_mean, k_std)
-  #  for point in range(npti-1):
-   #     values_data = np.vstack((values_data, values_interp[point::npti]))
-
-    #coord_data = np.vstack((coord_data, grid_interpolating))
-    return values_interp#, k_std# - svd_tmp.std(axis=0)
-
-
-def SGS_run(df, grid_to_inter, cluster,
-            trace, nuggets=None, n_var=1, n_exp=2, n_gaus=2,
-            n_rep=10, verbose = 0):
-
-    points_cluster = np.bincount(cluster.labels_)
-    coord_data = df[['X', 'Y', 'Z']].values
-    values_data = df[df.columns.difference(['X', 'Y', 'Z'])].values
-
-    SED_f = theano_sed()
-
-    for i in range(n_rep):
-        for i_clust in range(cluster.n_clusters):
-            cluster_bool = cluster.labels_ == i_clust
-            cluster_grid = grid_to_inter[cluster_bool]
-            # Mix the values of each cluster
-           # if i is 0:
-           #     np.random.shuffle(cluster_grid)
-
-            size_range = int(points_cluster[i_clust]/n_rep)
-
-            # Select points where interpolate
-            selected_cluster_grid = cluster_grid[i * size_range:(i + 1) * size_range]
-            npti = selected_cluster_grid.shape[0]
-
-            # Euclidiand distances
-            h_x0 = SED_f(coord_data, selected_cluster_grid)
-            # Drop any point already simulated
-            #print((h_x0==0).sum())
-          #  h_x0 = h_x0[~np.any(h_x0 == 0, axis=1)]
-            h_xi = SED_f(coord_data, coord_data)
-
-            # Checking the radius of the simulation
-            for r in range(50, 1000, 1):
-                select = (h_x0 < r).any(axis=1)
-                if select.sum() > 50:
-                    break
-            if verbose > 2:
-                print("sel", select.shape)
-                print("val", values_data.shape)
-            if verbose > 0:
-                print("Number of points used and number of points to interpolate", select.sum(), npti)
-            h_xi_sel = h_xi[select][:, select]
-            h_x0_sel = h_x0[select]
-            values_data_sel = values_data[select]
-
-            values_interpolated = SGS_compute(h_xi_sel, h_x0_sel, values_data_sel,
-                                              trace, nuggets, n_var, n_exp, n_gaus)
-
-            # Append the coordinates of the interpolated values to the values coord data since they will be interpolated
-            coord_data = np.vstack((coord_data, selected_cluster_grid))
-
-            # Setting negative values to 0
-            values_data[values_data < 0] = 0
-
-            # Append interpolated values to the initial values
-            for point in range(npti-1):
-                values_data = np.vstack((values_data, values_interpolated[point::npti]))
-
-    return coord_data, values_data
-
-# def SGS(coord_data, values_data, h_x0, select,
-#         trace, nuggets=None, n_var=1, n_exp=2, n_gaus=2):
-#     SED_f = theano_sed()
-#
-#     #for h_x0, select, grid_interpolating in selector:
-#
-#     SED = SED_f(coord_data, coord_data)
-#
-#     values_interp, npti = SGS_compute(SED[select], h_x0[select], values_data[select],
-#                                       trace, nuggets, n_var, n_exp, n_gaus)
-#
-#     for point in range(npti-1):
-#         values_data = np.vstack((values_data, values_interp[point::npti]))
-#
-#     coord_data = np.vstack((coord_data, grid_interpolating))
-
+"""
+
+    This file is part of gempy.
+
+    gempy is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    gempy is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
+
+Module with classes and methods to perform kriging of elements (and at some point exploit the potential field to
+choose the directions of the variograms)
+
+Tested on Ubuntu 16
+
+Created on 1/5/2017
+
+@author: Miguel de la Varga
+"""
+
+import aesara
+import aesara.tensor  as T
+import matplotlib.pyplot as plt
+import pymc as pm
+import numpy as np
+import pandas as pn
+
+from bokeh.io import show
+import bokeh.layouts as bl
+import bokeh.plotting as bp
+
+
+def choose_lithology_elements(df, litho, elem=None, coord = True):
+    """
+    litho(str): Name of the lithology-domain
+    elem(list): List of strings with elements you want to analyze
+    """
+    # Choosing just the opx litology
+    if elem is not None:
+        if coord:
+            domain = df[df['Lithology'] == litho][np.append(['X', 'Y', 'Z'], elem)]
+        else:
+            domain = df[df['Lithology'] == litho][elem]
+        # Drop negative values
+        domain = domain[(domain[elem] > 0).all(1)]
+    else:
+        domain = df[df['Lithology'] == litho][['X', 'Y', 'Z']]
+
+    return domain
+
+
+def select_segmented_grid(df, litho, grid, block):
+
+    block = np.squeeze(block)
+    assert grid.shape[0] == block.shape[0], 'The grid you want to use for kriging and the grid used for the layers ' \
+                                            'segmentation are not the same'
+
+    litho_num = df['Lithology Number'][df["Lithology"] == litho].iloc[0]
+    segm_grid = grid[block == litho_num]
+    return segm_grid
+
+
+def transform_data(df_o, n_comp=1, log10=False):
+    """
+    Method to improve the normality of the input data before perform krigin
+    Args:
+        df_o: Dataframe with the data to interpolate
+        n_comp: Number of component in case of multimodal data
+        log10 (bool): If true return the log in base 10 of the properties:
+
+    Returns:
+        pandas.core.frame.DataFrame: Data frame with the transformed data
+    """
+
+    import copy
+    df = copy.deepcopy(df_o)
+
+    # Take log to try to aproximate better the normal distributions
+    if log10:
+        print('computing log')
+        df[df.columns.difference(['X', 'Y', 'Z'])] = np.log10(df[df.columns.difference(['X', 'Y', 'Z'])])
+
+    # Finding n modes in the data
+    if n_comp > 1:
+        from sklearn import mixture
+        gmm = mixture.GaussianMixture(n_components=n_comp,
+                                      covariance_type='full').fit(df[df.columns.difference(['X', 'Y', 'Z'])])
+
+        # Adding the categories to the pandas frame
+        labels_all = gmm.predict(df[df.columns.difference(['X', 'Y', 'Z'])])
+        df['cluster'] = labels_all
+    return df
+
+
+def aesara_sed():
+    """
+    Function to create a aesara function to compute the euclidian distances efficiently
+    Returns:
+        aesara.compile.function_module.Function: Compiled function
+
+    """
+
+    aesara.config.compute_test_value = "ignore"
+
+    # Set symbolic variable as matrix (with the XYZ coords)
+    coord_T_x1 = T.dmatrix()
+    coord_T_x2 = T.dmatrix()
+
+    # Euclidian distances function
+    def squared_euclidean_distances(x_1, x_2):
+        sqd = T.sqrt(T.maximum(
+            (x_1 ** 2).sum(1).reshape((x_1.shape[0], 1)) +
+            (x_2 ** 2).sum(1).reshape((1, x_2.shape[0])) -
+            2 * x_1.dot(x_2.T), 0
+        ))
+        return sqd
+
+    # Compiling function
+    f = aesara.function([coord_T_x1, coord_T_x2],
+                        squared_euclidean_distances(coord_T_x1, coord_T_x2),
+                        allow_input_downcast=False)
+    return f
+
+
+# This is extremily ineficient. Try to vectorize it in aesara, it is possible to gain X100
+def compute_variogram(df, properties, euclidian_distances, tol=10, lags=np.logspace(0, 2.5, 100), plot=[]):
+    """
+    Compute the experimental variogram and cross variogram for a par of properties
+    Args:
+        df (pandas.core.frame.DataFrame): Dataframe with the properties and coordinates used in the experimental
+         variogram computation
+        properties (list): List of the two properties to compute the semivariogram.
+        euclidian_distances (numpy.array): Precomputed distances of the euclidian distances
+        tol (float): Tolerance
+        lags (list): List of lags to compute the experimental variogram
+        plot (bool): If true plot the experimental variogram after computed
+
+    Returns:
+        list: semvariance aor cross-semivariance
+    """
+
+    # Tiling the properties to a square matrix
+    element = (df[properties[0]].values.reshape(-1, 1) -
+               np.tile(df[properties[1]], (df[properties[1]].shape[0], 1))) ** 2
+
+    # Semivariance computation
+    semivariance_lag = []
+
+    # Looping every lag to compute the semivariance
+    for i in lags:
+        # Selecting the points at the given lag and tolerance
+        points_at_lag = ((euclidian_distances > i - tol) * (euclidian_distances < i + tol))
+
+        # Extracting the values of the properties of the selected lags
+        var_points = element[points_at_lag]
+
+        # Appending the semivariance
+        semivariance_lag = np.append(semivariance_lag, np.mean(var_points) / 2)
+
+    if "experimental" in plot:
+        # Visualizetion of the experimental variogram
+        plt.plot(lags, semivariance_lag, 'o')
+
+    return semivariance_lag
+
+
+def exp_lags(max_range, exp=2, n_lags=100):
+    """
+    Function to create a more specific exponential distance between the lags in case that log10 gives too much weight
+    to the smaller lags
+    Args:
+        max_range(float): Maximum distance
+        exp (float): Exponential degree
+        n_lags (int): Number of lags
+
+    Returns:
+        list: lags
+
+    """
+    lags = np.empty(0)
+    for i in range(n_lags):
+        lags = np.append(lags, i ** exp)
+    lags = lags / lags.max() * max_range
+    return lags
+
+
+def compute_crossvariogram(df, properties_names, euclidian_distances=None, **kwargs):
+    """
+    Compute the experimental crossvariogram of all properties given
+    Args:
+        df (pandas.core.frame.DataFrame): Dataframe with the properties and coordinates used in the experimental
+         variogram computation
+        properties_names (list str): List of strings with the properties to compute
+        euclidian_distances (numpy.array): Precomputed euclidian distances. If None they are computed inplace
+        Keyword Args:
+            - lag_exp: Degree of the exponential. If None log10
+            - lag_range: Maximum distance to compute a lag
+            - n_lags: Number of lags
+
+    Returns:
+        pandas.core.frame.DataFrame: Every experimental cross-variogram
+    """
+
+    lag_exp = kwargs.get('lag_exp', None)
+    lag_range = kwargs.get('lag_range', 500)
+    n_lags = kwargs.get('n_lags', 100)
+
+    # Choosing the lag array
+    if lag_exp is not None:
+        lags = exp_lags(lag_range, lag_exp, n_lags)
+    else:
+        lags = np.logspace(0, np.log10(lag_range), n_lags)
+
+    # Compute euclidian distance
+    if not euclidian_distances:
+        euclidian_distances = aesara_sed()(df[['X', 'Y', 'Z']], df[['X', 'Y', 'Z']])
+
+    # Init dataframe to store the results
+    experimental_variograms_frame = pn.DataFrame()
+
+    # This is extremily ineficient. Try to vectorize it in aesara, it is possible to gain X100
+    # Nested loop. DEPRECATED enumerate
+    for i in properties_names:
+        for j in properties_names:
+            col_name = i + '-' + j
+            values = compute_variogram(df, [i, j], euclidian_distances, lags=lags)
+            experimental_variograms_frame[col_name] = values
+
+    # Add lags column for plot mainly
+    experimental_variograms_frame['lags'] = lags
+
+    return experimental_variograms_frame
+
+
+class SGS(object):
+    """
+    Class that contains the necessary methods to perform a sequential gaurssian simmulation from experimental variograms
+    """
+    def __init__(self, exp_var, properties=None,  n_exp=2, n_gauss=2,
+                 data=None, grid=None, grid_to_inter=None, lithology=None, geomodel=None):
+        """
+
+        Args:
+            exp_var (pandas.core.frame.DataFrame): Dataframe with the experimental variograms. Columns are the variables
+            while raws the lags
+            properties (list strings): Variables to be used
+            n_exp (int): number of exponential basic functions
+            n_gauss (int): number of gaussian basic functions
+        """
+
+        # Analytical covariance
+        # ---------------------
+        self.exp_var_raw = exp_var
+        if not properties:
+            self.properties = exp_var.columns[['ppm' in i for i in exp_var.columns]]
+        else:
+            self.properties = properties
+        self.n_properties = len(self.properties)
+        self.lags = self.exp_var_raw['lags']
+        self.exp_var, self.nuggets = self.preprocess()
+
+        self.n_exp = n_exp
+        self.n_gauss = n_gauss
+        self.trace = None
+
+        # Kriging
+        # -------
+        self.data = data
+        self.data_to_inter = None
+        self.grid = grid
+        self.grid_to_inter = grid_to_inter
+        self.lithology = lithology
+        self.geomodel = geomodel
+
+        # aesara functions
+        # ----------------
+        self.SED_f = aesara_sed()
+
+        self._recursion_check = 0
+
+    def select_segmented_grid(self, grid=None, df=None, litho=None, block=None):
+        """
+        Extract from the full model the points belonging to a given domain (litho)
+        Args:
+            grid (numpy.arrau): Full model grid
+            df (pandas.core.frame.DataFrame): with all data
+            litho (str): Name of the lithology to interpolate
+            block (numpy.array): 3D block model generated by gempy
+
+        Returns:
+
+        """
+
+        # If we do not pass the attributes but are already a property of the object extract it
+        if grid is None:
+            grid = self.grid
+
+        if block is not None:
+            block = np.squeeze(block)
+        else:
+            block = self.geomodel
+
+        if df is None:
+            df = self.data
+
+        if litho is None:
+            litho = self.lithology
+
+        # Check that the attributes have value
+        assert all([any(block), ~df.empty, litho, np.any(grid)]), "Some of the attributes are not provided"
+        assert grid.shape[0] == block.shape[0], 'The grid you want to use for kriging and the grid used for the layers ' \
+                                                'segmentation are not the same'
+
+        # Translate lithology name to lithology number, i.e. the value of the lithology in the gempy block
+        litho_num = df['Lithology Number'][df["Lithology"] == litho].iloc[0]
+
+        # Extract from the grid the XYZ coordinates where the gempy block model is the given lithology
+        segm_grid = grid[block == litho_num]
+
+        # Set the segmented grid
+        self.grid_to_inter = segm_grid
+
+        return segm_grid
+
+    def choose_lithology_elements(self, df=None, litho=None, elem=None, coord=True):
+        """
+        Choose from the whole input data, those points which fall into the domain of interest
+        litho(str): Name of the lithology-domain
+        elem(list): List of strings with elements you want to analyze
+        """
+
+        # If we do not pass the attributes but are already a property of the object extract it
+        if not df:
+            df = self.data
+
+        if not litho:
+            litho = self.lithology
+
+        # Check that the attributes have value
+        assert all([~df.empty, litho]), "Some of the attributes are not provided"
+
+        # Choosing just one lithology
+        if elem is not None:
+            if coord:
+                domain = df[df['Lithology'] == litho][np.append(['X', 'Y', 'Z'], elem)]
+            else:
+                domain = df[df['Lithology'] == litho][elem]
+            # Drop negative values
+            domain = domain[(domain[elem] > 0).all(1)]
+        else:
+            domain = df[df['Lithology'] == litho][['X', 'Y', 'Z']]
+
+        # Set the segmented data
+        self.data_to_inter = domain
+
+        return domain
+
+    def set_data(self, data):
+        """
+        Data setter
+        Args:
+            data (pandas.core.frame.DataFrame): Dataframe with coordinates and values of the properties of interest
+        """
+        self.data = data
+
+    def set_grid_to_inter(self, grid):
+        """
+        Grid setter
+        Args:
+            grid (numpy.array): Grid object from gempy with the points of interest of the model
+        """
+        self.grid_to_inter = grid
+
+    def set_lithology(self, lithology):
+        """
+        Lithology setter
+        Args:
+            lithology (str): Name of the domain or lithology of interest
+        """
+        self.lithology = lithology
+
+    def set_geomodel(self, geomodel):
+        """
+        gempy model setter
+        Args:
+            geomodel (numpy.array): gempy block model
+        """
+        self.geomodel = geomodel
+
+    def set_trace(self, trace):
+        """
+        Analytical covarinace trace setter
+        Args:
+            trace (pymc3.trace): trace with the sill, range and weights of each property
+        """
+        self.trace = trace
+
+    def preprocess(self):
+        """
+        Normalization of data between 0 and 1 and subtraction of the nuggets
+        Returns:
+            pandas.core.frame.DataFrame: Dataframe containing the transformed data
+            pandas.core.frame.DataFrame: Containing the substracted nuggets
+
+        """
+        import sklearn.preprocessing as skp
+
+        # Normalization
+        scaled_data = pn.DataFrame(skp.minmax_scale(self.exp_var_raw[self.properties]), columns=self.properties)
+
+        # Nuggets
+        nuggets = scaled_data[self.properties].iloc[0]
+        processed_data = scaled_data - nuggets
+        return processed_data, nuggets
+
+    def plot_experimental(self, transformed=False):
+        """
+        Plotting the experimental data either transformed (see preprocess doc) or not
+        Args:
+            transformed (bool): if true plot the transformed data
+
+        Returns:
+            matplotlib.plot: plot of experimental variogram
+        """
+
+        if transformed:
+            plot = self.exp_var.plot(x=self.lags, y=self.properties, subplots=True, kind ='line',
+                                     style='.',
+                                     layout=(int(np.sqrt(self.n_properties)), int(np.sqrt(self.n_properties))),
+                                     figsize=(16, 8))
+        else:
+            plot = self.exp_var_raw.plot(x=self.lags, y=self.properties, subplots=True, kind='line',
+                                         style='.',
+                                         layout=(int(np.sqrt(self.n_properties)), int(np.sqrt(self.n_properties))),
+                                         figsize=(16, 8))
+        return plot
+
+    def fit_cross_cov(self, n_exp=2, n_gauss=2, range_mu=None):
+        """
+        Fit an analytical covariance to the experimental data.
+        Args:
+            n_exp (int): number of exponential basic functions
+            n_gauss (int): number of gaussian basic functions
+            range_mu: prior mean of the range. Default mean of the lags
+
+        Returns:
+            pymc.Model: PyMC3 model to be sampled using MCMC
+        """
+        self.n_exp = n_exp
+        self.n_gauss = n_gauss
+        n_var = self.n_properties
+        df = self.exp_var
+        lags = self.lags
+
+        # Prior standard deviation for the error of the regression
+        prior_std_reg = df.std(0).max() * 10
+
+        # Prior value for the mean of the ranges
+        if not range_mu:
+            range_mu = lags.mean()
+
+        # pymc3 Model
+        with pm.Model() as model:  # model specifications in PyMC3 are wrapped in a with-statement
+            # Define priors
+            sigma = pm.HalfCauchy('sigma', beta=prior_std_reg, testval=1., shape=n_var)
+
+            psill = pm.Normal('sill', prior_std_reg, sd=.5 * prior_std_reg, shape=(n_exp + n_gauss))
+            range_ = pm.Normal('range', range_mu, sd=range_mu * .3, shape=(n_exp + n_gauss))
+
+            lambda_ = pm.Uniform('weights', 0, 1, shape=(n_var * (n_exp + n_gauss)))
+
+            # Exponential covariance
+            exp = pm.Deterministic('exp',
+                                   # (lambda_[:n_exp*n_var]*
+                                   psill[:n_exp] *
+                                   (1. - T.exp(T.dot(-lags.values.reshape((len(lags), 1)),
+                                                     (range_[:n_exp].reshape((1, n_exp)) / 3.) ** -1))))
+
+            gauss = pm.Deterministic('gaus',
+                                     psill[n_exp:] *
+                                     (1. - T.exp(T.dot(-lags.values.reshape((len(lags), 1)) ** 2,
+                                                       (range_[n_exp:].reshape((1, n_gauss)) * 4 / 7.) ** -2))))
+
+            # We stack the basic functions in the same matrix and tile it to match the number of properties we have
+            func = pm.Deterministic('func', T.tile(T.horizontal_stack(exp, gauss), (n_var, 1, 1)))
+
+            # We weight each basic function and sum them
+            func_w = pm.Deterministic("func_w", T.sum(func * lambda_.reshape((n_var, 1, (n_exp + n_gauss))), axis=2))
+
+            for e, cross in enumerate(df.columns):
+                # Likelihoods
+                pm.Normal(cross + "_like", mu=func_w[e], sd=sigma[e], observed=df[cross].values)
+        return model
+
+    def plot_cross_variograms(self, iter_plot=200, trace=None, experimental=None):
+        """
+        Plot the analytical cross-variogram of a given MCMC inference
+        Args:
+            iter_plot (int): Number of traces to plot
+            trace (pymc3.trace): trace with the sill, range and weights of each property
+            experimental (bool): if True plot the experimental variogram as well
+
+        Returns:
+            None
+        """
+
+        if not trace:
+            trace = self.trace
+        assert trace, 'set the trace to the object'
+
+        n_exp = self.n_exp
+        n_gauss = self.n_gauss
+        lags = self.lags
+        # DEP- n_equations = trace['weights'].shape[1]
+        n_iter = trace['weights'].shape[0]
+        lags_tiled = np.tile(lags, (iter_plot, 1))
+        b_var = []
+        for i in range(0, self.n_properties):  # DEP- n_equations, (n_exp+n_gaus)):
+            # Init tensor
+            b = np.zeros((len(lags), n_iter, 0))
+            for i_exp in range(0, n_exp):
+
+                b = np.dstack((b, trace['weights'][:, i_exp + i * (n_exp + n_gauss)] *
+                               exp_vario(lags, trace['sill'][:, i_exp], trace['range'][:, i_exp])))
+            for i_gauss in range(n_exp, n_gauss + n_exp):
+                b = np.dstack((b, trace['weights'][:, i_gauss + i * (n_exp + n_gauss)] *
+                               gaus_vario(lags, trace['sill'][:, i_gauss], trace['range'][:, i_gauss])))
+
+            # Sum the contributins of each function
+            b_all = b.sum(axis=2)
+            # Append each variable
+            b_var.append(b_all[:, -iter_plot:].T)
+
+        # Bokeh code to plot this
+        p_all = []
+        for e, el in enumerate(self.properties):
+            p = bp.figure()#x_axis_type="log")
+            p.multi_line(list(lags_tiled), list(b_var[e]), color='olive', alpha=0.08)
+            if experimental:
+                p.scatter(self.lags, y=self.exp_var[el], color='navy', size=2)
+            p.title.text = el
+            p.xaxis.axis_label = "lags"
+            p.yaxis.axis_label = "Semivariance"
+
+            p_all = np.append(p_all, p)
+
+        grid = bl.gridplot(list(p_all), ncols=5, plot_width=250, plot_height=150)
+
+        show(grid)
+
+    def exp_vario(self, lags, sill, range_):
+        """
+        Vectorial computation of exponential variogram
+        Args:
+            lags (numpy.array): Distances
+            sill (numpy.array): Array of sills. The shape will be number of properties by number of exponential
+             basic functions
+            range_ (numpy.array): Array of ranges. The shape will be number of properties by number of exponential
+             basic functions
+
+        Returns:
+            numpy.array: Exponential variogram for every lag and every sill and range.
+        """
+        return sill * (1 - np.exp(np.dot(-lags.reshape(-1, 1) * 3, range_.reshape(1, -1) ** -1)))
+
+    def gaus_vario(self, lags, sill, range_):
+        """
+        Vectorial computation of gauss variogram
+        Args:
+            lags (numpy.array): Distances
+            sill (numpy.array): Array of sills. The shape will be number of properties by number of gauss
+             basic functions
+            range_ (numpy.array): Array of ranges. The shape will be number of properties by number of gauss
+             basic functions
+
+        Returns:
+            numpy.array: gauss variogram for every lag and every sill and range.
+        """
+        return sill * (1 - np.exp(np.dot(-lags.reshape(-1, 1) ** 2, (range_.reshape(1, -1) * 4 / 7) ** -2)))
+
+    def plot_cross_covariance(self, nuggets=False, iter_plot=200):
+        """
+        Plot the cross covariance for the given properties
+        Args:
+            nuggets (numpy.array): subtracted nuggets
+            iter_plot (int): number of traces to plot
+
+        Returns:
+            None
+        """
+        n_exp = self.n_exp
+        n_gauss = self.n_gauss
+        trace = self.trace
+        lags = self.lags
+
+        n_equations = trace['weights'].shape[1]
+        n_iter = trace['weights'].shape[0]
+        lags_tiled = np.tile(lags, (iter_plot, 1))
+        b_var = []
+        for i in range(0, self.n_properties):  # n_equations, (n_exp+n_gaus)):
+            # Init tensor
+            b = np.zeros((len(lags), n_iter, 0))
+            for i_exp in range(0, n_exp):
+                # print(i_exp, "exp")
+                b = np.dstack((b, trace['weights'][:, i_exp + i * (n_exp + n_gauss)] *
+                               exp_vario(lags, trace['sill'][:, i_exp], trace['range'][:, i_exp])))
+            for i_gaus in range(n_exp, n_gauss + n_exp):
+                # print(i_gaus)
+                b = np.dstack((b, trace['weights'][:, i_gaus + i * (n_exp + n_gauss)] *
+                               gaus_vario(lags, trace['sill'][:, i_gaus], trace['range'][:, i_gaus])))
+            # Sum the contributins of each function
+            if nuggets:
+                b_all = 1 - (b.sum(axis=2) + self.nuggets[i])
+            else:
+                b_all = 1 - (b.sum(axis=2))
+            # Append each variable
+            b_var.append(b_all[:, -iter_plot:].T)
+
+        p_all = []
+        for e, el in enumerate(self.properties):
+            p = bp.figure(x_axis_type="log")
+            p.multi_line(list(lags_tiled), list(b_var[e]), color='olive', alpha=0.08)
+
+            p.title.text = el
+            p.xaxis.axis_label = "lags"
+            p.yaxis.axis_label = "Semivariance"
+
+            p_all = np.append(p_all, p)
+
+        grid = bl.gridplot(list(p_all), ncols=5, plot_width=250, plot_height=150)
+
+        show(grid)
+
+    def solve_kriging(self, selection_A, selection_b, #selected_coord_data, selected_values_data, selected_grid_to_inter, trace,
+                      nuggets=None, n_var=1, n_exp=2, n_gauss=2):
+        """
+        Solve the kriging system for n given point of the grid_to_inter property selected by selection_b using n
+        points of data_to_inter given by selection_A
+        Args:
+            selection_A (bool): input points used in A matrix
+            selection_b (bool): points to interpolate from the grid
+            nuggets (numpy.array): Nugget effect of each cross variogram. If None take property
+            n_var: number of variables
+            n_exp (int): number of exponential basic functions
+            n_gauss (int): number of gaussian basic functions
+
+        Returns:
+
+        """
+
+        # Select input data and compute its euclidean distances
+        selected_coord_data = self.data_to_inter[selection_A][['X', 'Y', 'Z']]
+        selected_values_data = self.data_to_inter[selection_A][self.data_to_inter.columns.difference(['X', 'Y', 'Z'])].values
+        h_A = self.SED_f(selected_coord_data, selected_coord_data)
+
+        # Select points of grid to interpolate and compute the euclidean distances respect the input data
+        selected_grid_to_inter = self.grid_to_inter[selection_b]
+        h_b = self.SED_f(selected_coord_data, selected_grid_to_inter)
+
+        # Parameters for the covariances
+        trace = self.trace
+        nuggets = self.nuggets
+        n_var = int(np.sqrt(self.n_properties))
+        n_exp = self.n_exp
+        n_gauss = self.n_gauss
+
+        # Choose a random trace to conserve the covariance uncertainty of the regression
+        sample = np.random.randint(trace['weights'].shape[0] - 1000, trace['weights'].shape[0])
+
+       # Compute cross-covariances
+        cov_h = cross_covariance(trace, h_A, sample=sample,
+                                 nuggets=nuggets, n_var=n_var, n_exp=n_exp, n_gaus=n_gauss, ordinary=True)
+        cov_b = cross_covariance(trace, h_b, sample=sample, nuggets=nuggets, n_var=n_var, n_exp=n_exp,
+                                 n_gaus=n_gauss,
+                                 ordinary=True)
+
+        # Solve kriging system
+        k_weights = np.linalg.solve(cov_h, cov_b)
+
+        # Number of points to interpolate
+        npti = selected_grid_to_inter.shape[0]
+
+        # Repeat the input data for every point to interpolate
+        svd_tmp = np.tile(np.repeat(selected_values_data, npti, axis=1), (n_var, 1))
+
+        # Sol ordinary kriging mean
+        k_mean = (svd_tmp * k_weights[:-n_var]).sum(axis=0)
+
+        # Sol ordinary kriging std
+        k_std = svd_tmp.std(axis=0) - (k_weights * cov_b)[:-n_var].sum(axis=0) +\
+                (k_weights * cov_b)[-n_var:].sum(axis=0)
+
+        assert all(k_std) > -10, "A standard deviation of kringing is really off. Check nothing is wrong"
+        # Set negatives to 0
+        k_std[k_std < 0] = 0.1
+
+        # Check the results make sense else take another sample and recompute
+        import scipy
+        l_low, l_high = scipy.stats.norm.interval(.95, loc=np.mean(selected_values_data, axis=0),
+                                                  scale=np.std(selected_values_data, axis=0))
+
+        if not np.all((k_mean > l_low) * (k_mean < l_high)):
+
+            k_mean, k_std, cov_h, cov_b, k_weights, sample = self.solve_kriging(selection_A, selection_b)
+            self._recursion_check += 1
+            assert self._recursion_check<500, 'Too many recursions. Probably something goes wrong'
+
+        else:
+            self._recursion_check = 0
+            values_interp = np.random.normal(k_mean, k_std)
+
+        return k_mean, k_std, cov_h, cov_b, k_weights, sample  # , k_std# - svd_tmp.std(axis=0)
+
+
+def fit_cross_cov(df, lags, n_exp=2, n_gaus=2, range_mu=None):
+    n_var = df.columns.shape[0]
+    n_basis_f = n_var * (n_exp + n_gaus)
+    prior_std_reg = df.std(0).max() * 10
+    #
+    if not range_mu:
+        range_mu = lags.mean()
+
+    # Because is a experimental variogram I am not going to have outliers
+    nugget_max = df.values.max()
+    # print(n_basis_f, n_var*n_exp, nugget_max, range_mu, prior_std_reg)
+    # pymc3 Model
+    with pm.Model() as model:  # model specifications in PyMC3 are wrapped in a with-statement
+        # Define priors
+        sigma = pm.HalfCauchy('sigma', beta=prior_std_reg, testval=1., shape=n_var)
+
+        psill = pm.Normal('sill', prior_std_reg, sd=.5 * prior_std_reg, shape=(n_exp + n_gaus))
+        range_ = pm.Normal('range', range_mu, sd=range_mu * .3, shape=(n_exp + n_gaus))
+        #  nugget = pm.Uniform('nugget', 0, nugget_max, shape=n_var)
+
+        lambda_ = pm.Uniform('weights', 0, 1, shape=(n_var * (n_exp + n_gaus)))
+
+        # Exponential covariance
+        exp = pm.Deterministic('exp',
+                               # (lambda_[:n_exp*n_var]*
+                               psill[:n_exp] *
+                               (1. - T.exp(T.dot(-lags.values.reshape((len(lags), 1)),
+                                                 (range_[:n_exp].reshape((1, n_exp)) / 3.) ** -1))))
+
+        gaus = pm.Deterministic('gaus',
+                                psill[n_exp:] *
+                                (1. - T.exp(T.dot(-lags.values.reshape((len(lags), 1)) ** 2,
+                                                  (range_[n_exp:].reshape((1, n_gaus)) * 4 / 7.) ** -2))))
+
+        func = pm.Deterministic('func', T.tile(T.horizontal_stack(exp, gaus), (n_var, 1, 1)))
+
+        func_w = pm.Deterministic("func_w", T.sum(func * lambda_.reshape((n_var, 1, (n_exp + n_gaus))), axis=2))
+        #           nugget.reshape((n_var,1)))
+
+        for e, cross in enumerate(df.columns):
+            # Likelihoods
+            pm.Normal(cross + "_like", mu=func_w[e], sd=sigma[e], observed=df[cross].values)
+    return model
+
+
+def exp_vario(lags, sill, range_):
+    return sill * (1 - np.exp(np.dot(-lags.reshape(-1, 1) * 3, range_.reshape(1, -1) ** -1)))
+
+
+def gaus_vario(lags, sill, range_):
+    return sill * (1 - np.exp(np.dot(-lags.reshape(-1, 1) ** 2, (range_.reshape(1, -1) * 4 / 7) ** -2)))
+
+
+def plot_cross_variograms(trace, lags, df, n_exp=2, n_gaus=2, iter_plot=200, experimental=None):
+    n_equations = trace['weights'].shape[1]
+    n_iter = trace['weights'].shape[0]
+    lags_tiled = np.tile(lags, (iter_plot, 1))
+    b_var = []
+    for i in range(0, df.shape[1]):  # n_equations, (n_exp+n_gaus)):
+        # Init tensor
+        b = np.zeros((len(lags), n_iter, 0))
+        for i_exp in range(0, n_exp):
+            # print(i_exp, "exp")
+            b = np.dstack((b, trace['weights'][:, i_exp + i * (n_exp + n_gaus)] *
+                           exp_vario(lags, trace['sill'][:, i_exp], trace['range'][:, i_exp])))
+        for i_gaus in range(n_exp, n_gaus + n_exp):
+            # print(i_gaus)
+            b = np.dstack((b, trace['weights'][:, i_gaus + i * (n_exp + n_gaus)] *
+                           gaus_vario(lags, trace['sill'][:, i_gaus], trace['range'][:, i_gaus])))
+        # Sum the contributins of each function
+        b_all = b.sum(axis=2)
+        # Append each variable
+        b_var.append(b_all[:, -iter_plot:].T)
+
+    p_all = []
+    for e, el in enumerate(df.columns):
+        p = bp.figure(x_axis_type="log")
+        p.multi_line(list(lags_tiled), list(b_var[e]), color='olive', alpha=0.08)
+        if experimental is not None:
+            p.scatter(experimental['lags'], y=experimental[el], color='navy', size=2)
+        p.title.text = el
+        p.xaxis.axis_label = "lags"
+        p.yaxis.axis_label = "Semivariance"
+
+        p_all = np.append(p_all, p)
+
+    grid = bl.gridplot(list(p_all), ncols=5, plot_width=200, plot_height=150)
+
+    show(grid)
+
+
+def plot_cross_covariance(trace, lags, df, n_exp=2, n_gaus=2, nuggets=None, iter_plot=200):
+    n_equations = trace['weights'].shape[1]
+    n_iter = trace['weights'].shape[0]
+    lags_tiled = np.tile(lags, (iter_plot, 1))
+    b_var = []
+    for i in range(0, df.shape[1]):  # n_equations, (n_exp+n_gaus)):
+        # Init tensor
+        b = np.zeros((len(lags), n_iter, 0))
+        for i_exp in range(0, n_exp):
+            # print(i_exp, "exp")
+            b = np.dstack((b, trace['weights'][:, i_exp + i * (n_exp + n_gaus)] *
+                           exp_vario(lags, trace['sill'][:, i_exp], trace['range'][:, i_exp])))
+        for i_gaus in range(n_exp, n_gaus + n_exp):
+            # print(i_gaus)
+            b = np.dstack((b, trace['weights'][:, i_gaus + i * (n_exp + n_gaus)] *
+                           gaus_vario(lags, trace['sill'][:, i_gaus], trace['range'][:, i_gaus])))
+        # Sum the contributins of each function
+        if nuggets is not None:
+            b_all = 1 - (b.sum(axis=2) + nuggets[i])
+        else:
+            b_all = 1 - (b.sum(axis=2))
+        # Append each variable
+        b_var.append(b_all[:, -iter_plot:].T)
+
+    p_all = []
+    for e, el in enumerate(df.columns):
+        p = bp.figure(x_axis_type="log")
+        p.multi_line(list(lags_tiled), list(b_var[e]), color='olive', alpha=0.08)
+
+        p.title.text = el
+        p.xaxis.axis_label = "lags"
+        p.yaxis.axis_label = "Semivariance"
+
+        p_all = np.append(p_all, p)
+
+    grid = bl.gridplot(list(p_all), ncols=5, plot_width=250, plot_height=150)
+
+    show(grid)
+
+
+def cross_covariance(trace, sed, sample, nuggets=None, n_var=1, n_exp=2, n_gaus=2, ordinary=True):
+    """
+
+    Args:
+        trace:
+        sed:
+        nuggets:
+        n_var:
+        n_exp:
+        n_gaus:
+        ordinary:
+
+    Returns:
+
+    """
+    h = np.ravel(sed)
+    n_points = len(h)
+    n_points_r = sed.shape[0]
+    n_points_c = sed.shape[1]
+    #sample = np.random.randint(trace['weights'].shape[0]-200, trace['weights'].shape[0])
+    n_eq = trace['weights'].shape[1]
+    # Exp contribution
+    exp_cont = (np.tile(
+        exp_vario(h, trace['sill'][sample][:n_exp], trace['range'][sample][:n_exp]),
+        n_var**2
+    ) * trace['weights'][sample][np.linspace(0, n_eq-1, n_eq) % (n_exp + n_gaus) < n_exp]).reshape(n_points, n_exp, n_var**2, order="F")
+
+    # Gauss contribution
+    gaus_cont = (np.tile(
+        gaus_vario(h, trace['sill'][sample][n_exp:], trace['range'][sample][n_exp:]),
+        n_var**2
+    ) * trace['weights'][sample][np.linspace(0, n_eq-1, n_eq) % (n_exp + n_gaus) >= n_exp]).reshape(n_points, n_gaus, n_var**2, order="F")
+
+    # Stacking and summing
+    conts = np.hstack((exp_cont, gaus_cont)).sum(axis=1)
+
+    if nuggets is not None:
+        conts += nuggets
+
+    cov = 1 - conts
+
+    cov_str = np.zeros((0, n_points_c*n_var))
+
+    cov_aux = cov.reshape(n_points_r, n_points_c, n_var**2, order='F')
+
+    # This is a incredibly convoluted way to reshape the cross covariance but I did not find anything better
+    for i in range(n_var):
+        cov_str = np.vstack((cov_str,
+                             cov_aux[:, :, i*n_var:(i+1)*n_var].reshape(n_points_r, n_points_c*n_var, order='F')))
+
+    if ordinary:
+        ord = np.zeros((n_var, n_var*n_points_c+n_var))
+        for i in range(n_var):
+            ord[i, n_points_c * i:n_points_c * (i + 1)] = np.ones(n_points_c)
+        cov_str = np.vstack((cov_str, ord[:, :-n_var]))
+
+        # Stack the ordinary values to the C(h)
+        if n_points_r == n_points_c:
+             cov_str = np.hstack((cov_str, ord.T))
+
+    return cov_str
+
+
+def clustering_grid(grid_to_inter, n_clusters=50, plot=False):
+    from sklearn.cluster import KMeans
+    clust = KMeans(n_clusters=n_clusters).fit(grid_to_inter)
+    if plot:
+        fig = plt.figure()
+        ax = fig.add_subplot(111, projection='3d')
+
+        ax.scatter(clust.cluster_centers_[:, 0], clust.cluster_centers_[:, 1], clust.cluster_centers_[:, 2])
+
+        ax.set_xlabel('X Label')
+        ax.set_ylabel('Y Label')
+        ax.set_zlabel('Z Label')
+
+        plt.show()
+
+    return clust
+
+
+def select_points(df, grid_to_inter, cluster, SED_f = aesara_sed(), n_rep=10):
+
+    points_cluster = np.bincount(cluster.labels_)
+  #  SED_f = aesara_sed()
+
+    for i in range(n_rep):
+        for i_clust in range(cluster.n_clusters):
+            cluster_bool = cluster.labels_ == i_clust
+            cluster_grid = grid_to_inter[cluster_bool]
+            # Mix the values of each cluster
+            if i is 0:
+                np.random.shuffle(cluster_grid)
+
+            size_range = int(points_cluster[i_clust]/n_rep)
+            selected_cluster_grid = cluster_grid[i * size_range:(i + 1) * size_range]
+            dist = SED_f(df, selected_cluster_grid)
+
+            # Checking the radius of the simulation
+            for r in range(100, 1000, 100):
+                select = (dist < r).any(axis=1)
+                if select.sum() > 50:
+                    break
+
+            h_x0 = dist
+            yield (h_x0, select, selected_cluster_grid)
+
+
+def SGS_compute_points(selected_coord_data, selected_grid_to_inter, selected_values_data,
+                trace, nuggets=None, n_var=1, n_exp=2, n_gaus=2):
+    #SED_f = aesara_sed()
+
+
+    #SED = SED_f(selected_coord_data, selected_coord_data)
+
+    npti = selected_grid_to_inter.shape[1]
+
+    cov_h = cross_covariance(trace, selected_coord_data,
+                             nuggets=nuggets, n_var=n_var, n_exp=n_exp, n_gaus=n_gaus, ordinary=True)
+    cov_b = cross_covariance(trace, selected_grid_to_inter, nuggets=nuggets, n_var=n_var, n_exp=n_exp, n_gaus=n_gaus,
+                             ordinary=True)
+
+    k_weights = np.linalg.solve(cov_h, cov_b)
+    svd_tmp = np.tile(np.repeat(selected_values_data, npti, axis=1), (n_var, 1))
+
+    # Sol ordinary kriging mean
+    k_mean = (svd_tmp * k_weights[:-n_var]).sum(axis=0)
+
+    # Sol ordinary kriging std
+    k_std = svd_tmp.std(axis=0) - (k_weights * cov_b)[:-n_var].sum(axis=0) + (k_weights * cov_b)[-n_var:].sum(axis=0)
+
+    assert all(k_std) > -10, "A standard deviation of kringing is really off. Check nothing is wrong"
+
+    # Set negatives to 0
+    k_std[k_std < 0] = 0.1
+
+    values_interp = np.random.normal(k_mean, k_std)
+  #  for point in range(npti-1):
+   #     values_data = np.vstack((values_data, values_interp[point::npti]))
+
+    #coord_data = np.vstack((coord_data, grid_interpolating))
+    return values_interp#, k_std# - svd_tmp.std(axis=0)
+
+
+def SGS_run(df, grid_to_inter, cluster,
+            trace, nuggets=None, n_var=1, n_exp=2, n_gaus=2,
+            n_rep=10, verbose = 0):
+
+    points_cluster = np.bincount(cluster.labels_)
+    coord_data = df[['X', 'Y', 'Z']].values
+    values_data = df[df.columns.difference(['X', 'Y', 'Z'])].values
+
+    SED_f = aesara_sed()
+
+    for i in range(n_rep):
+        for i_clust in range(cluster.n_clusters):
+            cluster_bool = cluster.labels_ == i_clust
+            cluster_grid = grid_to_inter[cluster_bool]
+            # Mix the values of each cluster
+           # if i is 0:
+           #     np.random.shuffle(cluster_grid)
+
+            size_range = int(points_cluster[i_clust]/n_rep)
+
+            # Select points where interpolate
+            selected_cluster_grid = cluster_grid[i * size_range:(i + 1) * size_range]
+            npti = selected_cluster_grid.shape[0]
+
+            # Euclidiand distances
+            h_x0 = SED_f(coord_data, selected_cluster_grid)
+            # Drop any point already simulated
+            #print((h_x0==0).sum())
+          #  h_x0 = h_x0[~np.any(h_x0 == 0, axis=1)]
+            h_xi = SED_f(coord_data, coord_data)
+
+            # Checking the radius of the simulation
+            for r in range(50, 1000, 1):
+                select = (h_x0 < r).any(axis=1)
+                if select.sum() > 50:
+                    break
+            if verbose > 2:
+                print("sel", select.shape)
+                print("val", values_data.shape)
+            if verbose > 0:
+                print("Number of points used and number of points to interpolate", select.sum(), npti)
+            h_xi_sel = h_xi[select][:, select]
+            h_x0_sel = h_x0[select]
+            values_data_sel = values_data[select]
+
+            values_interpolated = SGS_compute(h_xi_sel, h_x0_sel, values_data_sel,
+                                              trace, nuggets, n_var, n_exp, n_gaus)
+
+            # Append the coordinates of the interpolated values to the values coord data since they will be interpolated
+            coord_data = np.vstack((coord_data, selected_cluster_grid))
+
+            # Setting negative values to 0
+            values_data[values_data < 0] = 0
+
+            # Append interpolated values to the initial values
+            for point in range(npti-1):
+                values_data = np.vstack((values_data, values_interpolated[point::npti]))
+
+    return coord_data, values_data
+
+# def SGS(coord_data, values_data, h_x0, select,
+#         trace, nuggets=None, n_var=1, n_exp=2, n_gaus=2):
+#     SED_f = aesara_sed()
+#
+#     #for h_x0, select, grid_interpolating in selector:
+#
+#     SED = SED_f(coord_data, coord_data)
+#
+#     values_interp, npti = SGS_compute(SED[select], h_x0[select], values_data[select],
+#                                       trace, nuggets, n_var, n_exp, n_gaus)
+#
+#     for point in range(npti-1):
+#         values_data = np.vstack((values_data, values_interp[point::npti]))
+#
+#     coord_data = np.vstack((coord_data, grid_interpolating))
+
```

### Comparing `gempy-2.2b10.dev1/gempy/assets/decision_making.py` & `gempy-2.3.0/gempy/assets/decision_making.py`

 * *Ordering differences only*

 * *Files 8% similar despite different names*

```diff
@@ -1,581 +1,581 @@
-"""
-    This file is part of gempy.
-
-    gempy is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    gempy is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
-
-
-@author: Fabian A. Stamm
-"""
-
-import numpy as np
-import scipy.optimize as sop
-from matplotlib import pyplot as plt
-
-import copy
-import matplotlib.pyplot as plt
-from matplotlib import cm
-
-import matplotlib.gridspec as gridspect
-
-# Create cmap
-from matplotlib.colors import ListedColormap
-import matplotlib.colors as colors
-import matplotlib.cm as cmx
-
-import numpy as np
-import pandas as pn
-import scipy.stats as stats
-import seaborn as sns
-
-def loss_abs(estimate_s, true_s, u=1,o=1,u_f=1,o_f=1, r=1):
-    """Absolute-error loss function.
-
-        Args:
-            estimate_s (int or float): Value estimate.
-            true_s (int, float or np.array): True value.
-            u (int or float, optional): Underestimation re-weighting factor.
-            o (int or float, optional): Overestimation re-weighting factor.
-            u_f (int or float, optional): Fatal underestimation re-weighting factor.
-            o_f (int or float, optional): Fatal overestimation re-weighting factor.
-            r (int or float, optional): Risk-affinity re-weighting factor.
-        Returns:
-            Loss incurred for an estimate given a true value.
-            Based on absolute-error loss, i.e. the absolute distance of the estimate
-            from the true value.
-
-            true_s can be either a single value or an array of possible true values,
-            the output will be a single determined absolute loss value or an array of determined
-            loss values, accordingly.
-
-            estimate_s has to be one single value.
-
-    """
-    true_s = np.array(true_s).astype(float)
-    loss_s = np.zeros_like(true_s)
-    underest = (estimate_s < true_s)
-    overest = (estimate_s > true_s)
-    loss_s[underest] = (true_s[underest] - estimate_s)  * (u * (r ** -0.5))
-    loss_s[overest] = (estimate_s - true_s[overest]) * (o * r)
-    if u_f != 1:
-        underest_fatal = (estimate_s <= 0) & (true_s > 0)
-        loss_s[underest_fatal] = (true_s[underest_fatal] - estimate_s) * (u_f * (r ** -0.5))
-    if o_f != 1:
-        overest_fatal = (estimate_s > 0) & (true_s <= 0)
-        loss_s[overest_fatal] = np.abs((true_s[overest_fatal] - estimate_s)) * (o_f * r)
-    return loss_s
-
-def loss_abs_given_values(estimate_s, true_s, u=1,o=1,u_f=1,o_f=1, r=1):
-    """Absolute-error loss function for the exclusive use with a single
-    given true value.
-
-            Args:
-                estimate_s (int or float): Value estimate.
-                true_s (int, float): True value.
-                u (int or float, optional): Underestimation re-weighting factor.
-                o (int or float, optional): Overestimation re-weighting factor.
-                u_f (int or float, optional): Fatal underestimation re-weighting factor.
-                o_f (int or float, optional): Fatal overestimation re-weighting factor.
-                r (int or float, optional): Risk-affinity re-weighting factor.
-            Returns:
-                Loss incurred for an estimate given one determined true value.
-                Based on absolute-error loss, i.e. the absolute distance of the estimate
-                from the true value.
-
-        """
-    if estimate_s < true_s:
-        if estimate_s <= 0 and true_s > 0:
-            loss_s = (true_s - estimate_s) * (u_f * (r ** -0.5))  # bad case of underestimation
-        else:
-            loss_s = (true_s - estimate_s) * (u * (r ** -0.5)) # normal underestimation
-    elif estimate_s > true_s:
-        if estimate_s > 0 and true_s <= 0:
-            loss_s = (estimate_s - true_s) * (o_f)  # bad case of overestimation
-        else:
-            loss_s = (estimate_s - true_s) * (o * r)  # normal overestimation
-    else:
-        loss_s = 0
-    return loss_s
-
-def loss_sqr(estimate_s, true_s, u=1,o=1,u_f=1,o_f=1, r=1):
-    """Squared-error loss function.
-
-        Args:
-            estimate_s (int or float): Value estimate.
-            true_s (int, float or np.array): True value.
-            u (int or float, optional): Underestimation re-weighting factor.
-            o (int or float, optional): Overestimation re-weighting factor.
-            u_f (int or float, optional): Fatal underestimation re-weighting factor.
-            o_f (int or float, optional): Fatal overestimation re-weighting factor.
-            r (int or float, optional): Risk-affinity re-weighting factor.
-        Returns:
-            Loss incurred for an estimate of the value given a true value.
-            Based on squared-error loss, i.e. the absolute distance of the estimate
-            from the true value squared.
-
-            true_s can be either a single value or an array of possible true values,
-            the output will be a single determined absolute loss value or an array of determined
-            loss values, accordingly.
-
-            estimate_s has to be one single value.
-
-    """
-    return np.square(loss_abs(estimate_s, true_s, u,o,u_f,o_f, r))
-
-def loss_sqr_given_values(estimate_s, true_s, u=1,o=1,u_f=1,o_f=1, r=1):
-    """Squared-error loss function for the exclusive use with a single
-        given true value.
-
-                Args:
-                    estimate_s (int or float): Value estimate.
-                    true_s (int, float): True value.
-                    u (int or float, optional): Underestimation re-weighting factor.
-                    o (int or float, optional): Overestimation re-weighting factor.
-                    u_f (int or float, optional): Fatal underestimation re-weighting factor.
-                    o_f (int or float, optional): Fatal overestimation re-weighting factor.
-                    r (int or float, optional): Risk-affinity re-weighting factor.
-                Returns:
-                    Loss incurred for an estimate given one determined true value.
-                    Based on squared-error loss, i.e. the absolute distance of the estimate
-                    from the true value squared.
-    """
-    return loss_abs_given_values(estimate_s, true_s, u,o,u_f,o_f, r)**2
-
-def expected_loss_for_estimate(estimate_s, true_s, function='absolute', u=1,o=1,u_f=1,o_f=1, r=1):
-    """Function to attain expected loss for an estimate
-    given a range of possible true values by taking the mean of all
-    possible loss realizations.
-
-        Args:
-            estimate_s (int or float): Value estimate.
-            true_s (int, float or np.array): True value.
-            function ('absolute'(default) or 'squared'): Use of absolute-error or
-                squared-error loss function.
-            u (int or float, optional): Underestimation re-weighting factor.
-            o (int or float, optional): Overestimation re-weighting factor.
-            u_f (int or float, optional): Fatal underestimation re-weighting factor.
-            o_f (int or float, optional): Fatal overestimation re-weighting factor.
-            r (int or float, optional): Risk-affinity re-weighting factor.
-        Returns:
-            Expected loss for a single estimate given a range of possible true values.
-
-            Note: If only one possible true value is passed, the expected loss equals
-            the actually incurred loss.
-
-    """
-
-    if function == 'absolute':
-        return loss_abs(estimate_s, true_s, u,o,u_f,o_f, r).mean()
-    elif function == 'squared':
-        return loss_sqr(estimate_s, true_s, u, o, u_f, o_f, r).mean()
-    else:
-        print('Error: Type of loss function not recognized. '
-              'Use "absolute" or "squared".')
-
-def expected_loss_for_range(estimate_range, true_s, function='absolute', u=1,o=1,u_f=1,o_f=1, r=1):
-    """Function to attain expected loss and Bayes action based on an absolute-error or
-           squared error-loss function for a defined range of estimates.
-
-                Args:
-                    estimate_range (np.array): Range of value estimates.
-                    true_s (np.array): Array of possible true value occurrences (from a probability distribution)
-                    u (int or float, optional): Underestimation re-weighting factor.
-                    o (int or float, optional): Overestimation re-weighting factor.
-                    u_f (int or float, optional): Fatal underestimation re-weighting factor.
-                    o_f (int or float, optional): Fatal overestimation re-weighting factor.
-                    r (int, float or np.array, optional): Risk-affinity re-weighting factor.
-                Returns:
-                    [0]: Expected loss for the range of estimates.
-                    [1]: Bayes action (estimate with minimal expected loss)
-                    [2]: Expected loss of Bayes action.
-        """
-    expected_loss_s = lambda estimate_s, r: expected_loss_for_estimate(estimate_s, true_s, function, u, o, u_f, o_f, r)
-    loss_e = [expected_loss_s(e, r) for e in estimate_range]
-    bayes_action = sop.fmin(expected_loss_s, -40, args=(r,), disp=False)
-    bayes_action_loss_e = expected_loss_s(bayes_action, r)
-    return loss_e, bayes_action, bayes_action_loss_e
-
-def expected_loss_plot(estimate_range, true_s, risk_range=1, function='absolute', u=1,o=1,u_f=1,o_f=1,
-                        verbose=False):
-    """Function to plot expected losses and the Bayes action for a range of estimates
-    relative to a distribution of possible true values.
-    It is possible to plot this for several risk factors at once.
-
-            Args:
-                estimate_range (np.array): Range of value estimates.
-                true_s (np.array): Array of possible true value occurrences (from a probability distribution)
-                u (int or float, optional): Underestimation re-weighting factor.
-                o (int or float, optional): Overestimation re-weighting factor.
-                u_f (int or float, optional): Fatal underestimation re-weighting factor.
-                o_f (int or float, optional): Fatal overestimation re-weighting factor.
-                r (int, float or np.array, optional): Risk-affinity re-weighting factor.
-            Returns:
-                Plot of expected losses for risk neutrality
-                or several risk factors.
-
-    """
-    ax = plt.subplot(111)
-    if isinstance(risk_range, (int,float)):
-        r_range=[risk_range]
-    else:
-        r_range=risk_range
-    for r in r_range:
-        loss_e, bayes_a, bayes_a_loss_e = expected_loss_for_range(estimate_range, true_s, function, u,o,u_f,o_f, r)
-        _color = next(ax._get_lines.prop_cycler)
-        plt.plot(estimate_range, loss_e, label="r =" + str(r), color=_color['color'])
-        plt.scatter(bayes_a, bayes_a_loss_e, s=70,
-                        color=_color['color'])  # , label = "Bayes action r "+str(r))
-        plt.vlines(bayes_a, 0, 10 * np.max(loss_e), color=_color['color'], linestyles="--")
-        if verbose == True:
-            print("Bayes action (minimum) at risk r %.2f: %.2f --- expected loss: %.2f"\
-                  % (r, bayes_a, bayes_a_loss_e))
-    plt.legend(loc="upper left", scatterpoints=1, title="Legend")
-    plt.xlabel("Estimate")
-    plt.ylabel("Expected loss")
-    plt.xlim(estimate_range[0], estimate_range[-1])
-    plt.ylim(0, 1.1 * np.max(loss_e))
-    plt.grid()
-    plt.show()
-
-def loss_for_estimate(estimate_s, true_s, function='absolute', u=1,o=1,u_f=1,o_f=1, r=1):
-    """Function to attain actually incurred loss for an estimate
-    given a single true value.
-
-        Args:
-            estimate_s (int or float): Value estimate.
-            true_s (int or float): True value.
-            function ('absolute'(default) or 'squared'): Use of absolute-error or
-                squared-error loss function.
-            u (int or float, optional): Underestimation re-weighting factor.
-            o (int or float, optional): Overestimation re-weighting factor.
-            u_f (int or float, optional): Fatal underestimation re-weighting factor.
-            o_f (int or float, optional): Fatal overestimation re-weighting factor.
-            r (int or float, optional): Risk-affinity re-weighting factor.
-        Returns:
-            Loss for a single estimate given a single determined true value.
-    """
-    if function == 'absolute':
-        return loss_abs_given_values(estimate_s, true_s, u,o,u_f,o_f, r)
-    elif function == 'squared':
-        return loss_sqr_given_values(estimate_s, true_s, u, o, u_f, o_f, r)
-    else:
-        print('Error: Type of loss function not recognized. '
-              'Use "absolute" or "squared".')
-
-def loss_for_range(estimate_range, true_s, function='absolute', u=1,o=1,u_f=1,o_f=1, r=1):
-    """Function to attain loss and Bayes action based on an absolute-error or
-               squared error-loss function for a defined range of estimates
-               given one single true value.
-
-                    Args:
-                        estimate_range (np.array): Range of value estimates.
-                        true_value (int or float): Array of possible true value occurrences (from a probability distribution)
-                        u (int or float, optional): Underestimation re-weighting factor.
-                        o (int or float, optional): Overestimation re-weighting factor.
-                        u_f (int or float, optional): Fatal underestimation re-weighting factor.
-                        o_f (int or float, optional): Fatal overestimation re-weighting factor.
-                        r (int, float or np.array, optional): Risk-affinity re-weighting factor.
-                    Returns:
-                        [0]: Loss for the range of estimates.
-                        [1]: Bayes action (estimate with minimal expected loss)
-                        [2]: Expected loss of Bayes action.
-
-                        Note: Since the is only one possible true value,
-                        the Bayes action will always equal this value.
-            """
-    incurred_loss = lambda estimate_s, r: loss_for_estimate(estimate_s, true_s, function, u, o, u_f, o_f, r)
-    loss_i = [incurred_loss(e, r) for e in estimate_range]
-    bayes_action = sop.fmin(incurred_loss, -40, args=(r,), disp=False)
-    bayes_action_loss = incurred_loss(bayes_action, r)
-    return loss_i, bayes_action, bayes_action_loss
-
-def loss_plot(estimate_range, true_s, risk_range=1, function='absolute', u=1,o=1,u_f=1,o_f=1,
-                        verbose=False):
-    """Function to plot losses for a range of estimates
-    relative to a single given true value.
-    It is possible to plot this for several risk factors at once.
-
-            Args:
-                estimate_range (np.array): Range of value estimates.
-                true_s (int or float): Array of possible true value occurrences (from a probability distribution)
-                u (int or float, optional): Underestimation re-weighting factor.
-                o (int or float, optional): Overestimation re-weighting factor.
-                u_f (int or float, optional): Fatal underestimation re-weighting factor.
-                o_f (int or float, optional): Fatal overestimation re-weighting factor.
-                r (int, float or np.array, optional): Risk-affinity re-weighting factor.
-            Returns:
-                Plot of losses for risk neutrality
-                or several risk factors given a single determined true value.
-
-    """
-    ax = plt.subplot(111)
-    if isinstance(risk_range, (int,float)):
-        r_range=[risk_range]
-    else:
-        r_range=risk_range
-    for r in r_range:
-        loss_i, bayes_a, bayes_a_loss = loss_for_range(estimate_range, true_s, function, u,o,u_f,o_f, r)
-        _color = next(ax._get_lines.prop_cycler)
-        plt.plot(estimate_range, loss_i, label="r =" + str(r), color=_color['color'])
-        plt.scatter(bayes_a, bayes_a_loss, s=70,
-                        color=_color['color'])  # , label = "Bayes action r "+str(r))
-        plt.vlines(bayes_a, 0, 10 * np.max(loss_i), color=_color['color'], linestyles="--")
-        if verbose == True:
-            print("Bayes action (minimum) at risk r %.2f: %.2f --- expected loss: %.2f"\
-                  % (r, bayes_a, bayes_a_loss))
-    plt.legend(loc="upper left", scatterpoints=1, title="Legend")
-    plt.xlabel("Estimate")
-    plt.ylabel("Expected loss")
-    plt.xlim(estimate_range[0], estimate_range[-1])
-    plt.ylim(0, 1.1 * np.max(loss_i))
-    plt.grid()
-    plt.show()
-
-
-def plot_multiple_loss():
-
-    def plot_axis(xvals, nor_l, loss, subplot_spec, e, depth=False):
-        grid = gridspect.GridSpecFromSubplotSpec(1, 1, subplot_spec=subplot_spec)
-        ax = fig.add_subplot(grid[:, :])
-        # ax0.yaxis.set_visible(False)
-        axr = ax.twinx()
-
-        labels = 'Thickness Score' if depth is True else None
-        c = default_red if depth is True else default_blue
-
-        ax.plot(xvals, nor_l, color=c, linewidth=.5, label=labels)
-        ax.fill_between(xvals, nor_l, 0, color=c, alpha=.8)
-        ax.set_ylabel('Likelihood')
-        ax.set_ylim(0, .16)
-        ax.set_xlim(-25+6, 6+25)
-
-        axr.set_ylim(0, 40)
-        axr.set_ylabel('Expected Loss')
-
-        ax.spines['top'].set_color('none')
-        ax.spines['left'].set_color('none')
-        if e == 0:
-            axr.plot(xvals, loss, linewidth=3, color='white')
-            axr.plot(xvals, loss, linewidth=2, color='#496155', label='Loss')
-            axr.legend(frameon=True, facecolor='white', framealpha=1)
-
-        else:
-            axr.plot(xvals, loss, linewidth=3, color='white')
-            axr.plot(xvals, loss, linewidth=2, color='#496155', label='Risk Neutral')
-        if e%2 == 0:
-
-            axr.yaxis.set_visible(False)
-           # axr.yaxis.label.set_visible(False)
-
-        else:
-
-            for tick in axr.get_yticklines():
-                tick.set_visible(False)
-           # axr.yaxis.label.set_visible(False)
-            ax.yaxis.set_visible(False)
-        ax.xaxis.set_visible(False)
-        axr.xaxis.set_visible(False)
-        if e>3:
-            ax.xaxis.set_visible(True)
-            axr.xaxis.set_visible(True)
-            ax.set_xlabel('Score')
-        return ax, axr
-
-    def res_score_loss(true_s, estimate_s, ov=1.25, uv_b=1.5, ov_b=2, risk_s=1):
-
-        underest = (estimate_s < true_s)
-        # loss_s = np.zeros((estimate_s.shape[0], true_s.shape[0]))
-        underest_bad = (estimate_s <= 0) & (true_s > 0)
-        overest = (estimate_s > true_s)
-        overest_bad = (estimate_s > 0) & (true_s <= 0)
-        a = underest * abs(true_s - estimate_s) * (risk_s ** -0.5)
-        b = underest_bad * abs(true_s - estimate_s) * (uv_b * (risk_s ** -0.5))
-        c = overest * abs(estimate_s - true_s) * (ov * risk_s)
-        d = overest_bad * abs(estimate_s - true_s) * (ov_b * risk_s)
-        loss_s = (a + b + c + d).mean(axis=1)
-        return loss_s, (a,b,c,d)
-
-    def abs_loss(true_s, estimate_s, ov=1, uv=1, risk_s=1, uv_b=1):
-        print('foooooo')
-        underest = (estimate_s < true_s)
-        # loss_s = np.zeros((estimate_s.shape[0], true_s.shape[0]))
-        underest_bad = 1# (estimate_s <= 0) & (true_s > 0)
-        overest = (estimate_s > true_s)
-        overest_bad = (estimate_s > 0) & (true_s <= 0)
-        b = 0
-        d = 0
-        a = underest * abs(true_s - estimate_s) * (uv * risk_s)
-      #  b = underest_bad * (true_s - estimate_s) * (uv_b * (risk_s))
-        c = overest * abs(estimate_s - true_s) * (ov * risk_s)
-        #d = overest_bad * (estimate_s - true_s) * (ov_b * risk_s)
-        loss_s = (a + b + c + d).mean(axis=1)
-        return loss_s, (a,b,c,d)
-
-    def compute_values(mu, sigma, loss_type, x_range=(-24+6, 6+24), risk=1, depth=False):
-        samples_size = 100000
-
-        if x_range is None:
-            x_max = mu + 5 * sigma
-            x_min = mu - 5 * sigma
-        else:
-            x_min, x_max = x_range
-       # xvals = np.linspace(-23+6, 6+23, 100)
-
-        xvals = np.linspace(x_min, x_max, 100)
-        nor_l = stats.norm.pdf(xvals, loc=mu, scale=sigma)
-        samples = np.random.normal(loc=mu, scale=sigma, size=samples_size)
-
-        if depth is True:
-            #xvals = np.linspace(0, 60, 100)
-            # nor_d = stats.norm.pdf(xvals, loc=30, scale=5)
-            samples_depth = np.random.normal(loc=30, scale=5, size=samples_size)
-            depth_score = samples_depth
-
-            # Transformation to cost
-            d_cost = - ((depth_score-depth_score.min()) / 8) ** 2.6
-            samples = samples + d_cost
-        elif depth is False:
-            pass
-
-        else:
-            samples = depth
-
-        if loss_type == 'abs':
-            loss, partial = abs_loss(samples, xvals.reshape(-1, 1), 1, 1, risk_s=risk)
-            #return xvals, nor_l, loss, partial
-        elif loss_type == 'custom':
-            loss, partial = res_score_loss(samples, xvals.reshape(-1, 1), risk_s=risk)
-
-        if depth is True:
-            return xvals, nor_l, loss, partial, samples, d_cost
-        else:
-            return xvals, nor_l, loss, partial
-
-    sns.set(style="white")  # , rc={"axes.facecolor": (0, 0, 0, 0)})
-    # Discrete cmap
-    pal_disc = sns.cubehelix_palette(10, rot=-.25, light=.7)
-    pal_disc_l = sns.cubehelix_palette(10)
-    my_cmap = ListedColormap(pal_disc)
-    my_cmap_l = ListedColormap(pal_disc_l)
-
-    # Continuous cmap
-    pal_cont = sns.cubehelix_palette(250, rot=-.25, light=.7)
-    pal_cont_l = sns.cubehelix_palette(250)
-
-    my_cmap_full = ListedColormap(pal_cont)
-    my_cmap_full_l = ListedColormap(pal_cont_l)
-
-    default_red = '#DA8886'
-    default_blue = pal_cont.as_hex()[4]
-    default_l = pal_disc_l.as_hex()[4]
-
-    # %matplotlib notebook
-    figsize = (12, 12)
-    fig, axes = plt.subplots(0, 0, figsize=figsize, constrained_layout=False)
-    sns.despine(left=True, bottom=True)
-
-    gs_0 = gridspect.GridSpec(3, 2, figure=fig, hspace=0.1, wspace=0.009)
-
-    axis = []
-
-    mu = [12]*6
-    sigma = [2.3, 2.3 ,4,4, 4, 4]
-    type = ['abs', 'custom', 'abs', 'custom', 'abs', 'custom']
-    for e, ax in enumerate(gs_0):
-
-        if e==0:
-            x, n, l, partial = compute_values(mu[e], sigma[e], type[e])
-            ax_, axr_ = plot_axis(x, n, l, ax, e)
-            ax_.vlines(mu[e], 0, 40, linestyles='--', alpha=.5)
-            ax_.vlines(0, 0, 40, linestyles='--', alpha=.5)
-            axr_.hlines(l.min(), -25, x[l.argmin()],
-                       linestyles='--', alpha=.5)
-
-        if e==1:
-            x, n, l, partial = compute_values(mu[e], sigma[e], type[e])
-            ax_, axr_ = plot_axis(x, n, l, ax, e)
-            ax_.vlines(mu[e], 0, 40, linestyles='--', alpha=.5)
-            ax_.vlines(0, 0, 40, linestyles='--', alpha=.5)
-            labels = ['Underes.', 'Crit. Underest.', 'Overest.', 'Crit. Overest.']
-            for i in range(4):
-                axr_.plot(x, partial[i].mean(axis=1), '--', linewidth=1, label=labels[i])
-
-            axr_.legend(loc=2, frameon=True, facecolor='white', framealpha=1)
-
-        if e==2 or e==3:
-            x, n, l, partial = compute_values(mu[e], sigma[e], type[e])
-            ax_, axr_ = plot_axis(x, n, l, ax, e)
-            axr_.plot(x[l.argmin()], 0, 'o',  color='#496155', markersize=12)
-            if e == 2:
-                axr_.hlines(l.min(), -25, x[l.argmin()],
-                            linestyles='--', alpha=.5)
-
-            x, n, l, partial = compute_values(mu[e], sigma[e], type[e], risk=.2)
-            axr_.plot(x, l, linewidth=3, color='white')
-            axr_.plot(x, l, linewidth=2, label='Risk Friendly')
-            axr_.plot(x[l.argmin()], 0, 'o',  color='b', markersize=12)
-
-            x, n, l, partial = compute_values(mu[e], sigma[e], type[e], risk=5)
-            axr_.plot(x, l, linewidth=3, color='white')
-            axr_.plot(x, l, linewidth=2, label='Risk Averse')
-            axr_.plot(x[l.argmin()], 0, 'o',  color='orange', markersize=12)
-
-            ax_.vlines(mu[e], 0, 40, linestyles='--', alpha=.5)
-            ax_.vlines(0, 0, 40, linestyles='--', alpha=.5)
-            if e==2:
-                axr_.legend(frameon=True, facecolor='white', framealpha=1)
-
-        if e > 3:
-            x, n, l, partial, ss, d_cost = compute_values(mu[e], sigma[e], type[e],
-                                                          x_range=(-24+6, 6+24),
-                                                          risk=1, depth=True)
-            ax_, axr_ = plot_axis(x, n, l, ax, e, depth=True)
-            axr_.plot(x[l.argmin()], 0, 'o',  color='#496155', markersize=12)
-
-            x_max = ss.mean() + 6 * ss.std()
-            x_min = ss.mean() - 6 * ss.std()
-            print(x_max, x_min, 'foo')
-            print(ss.mean(), d_cost.mean())
-            x, n, l, partial = compute_values(mu[e], sigma[e], type[e],
-                                                      x_range=(-24 + 6, 6 + 24),
-                                                      risk=.2, depth=ss)
-            #print(_1.mean(),  d_cost.mean())
-            axr_.plot(x, l, linewidth=3, color='white')
-            axr_.plot(x, l, linewidth=2, label='Risk Friendly')
-            axr_.plot(x[l.argmin()], 0, 'o',  color='b', markersize=12)
-
-            x, n, l, partial = compute_values(mu[e], sigma[e], type[e],
-                                                      x_range=(-24 + 6, 6 + 24),
-                                                      risk=5, depth=ss)
-          #  print(_1.mean(),  d_cost.mean())
-            axr_.plot(x, l, linewidth=3, color='white')
-            axr_.plot(x, l, linewidth=2, label='Risk Adverse')
-            axr_.plot(x[l.argmin()], 0, 'o',  color='orange', markersize=12)
-
-            k = sns.kdeplot(d_cost, ax=ax_, shade=True, label='Depth Score', color=default_red,
-                        alpha=.8,linewidth=.5)
-            #k.legend_.set_frame_on(True)
-            sns.kdeplot(ss, ax=ax_, label='Final Score', shade=True, color=default_blue,
-                        alpha=1, linewidth=.5)
-            k.legend_.set_frame_on(True)
-            k.legend_.set_alpha(1)
-
-            if e == 4:
-                k.legend_.set_visible(False)
-            # ax_.vlines(mu[e], 0, 40, linestyles='--', alpha=.5)
-            ax_.vlines(np.median(ss), 0, 40, linestyles='--', alpha=.5)
-            ax_.vlines(0, 0, 40, linestyles='--', alpha=.5)
-          #  ax_.legend(loc=2)
-
-        axis.append((ax_, axr_))
-    return k
+"""
+    This file is part of gempy.
+
+    gempy is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    gempy is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
+
+
+@author: Fabian A. Stamm
+"""
+
+import numpy as np
+import scipy.optimize as sop
+from matplotlib import pyplot as plt
+
+import copy
+import matplotlib.pyplot as plt
+from matplotlib import cm
+
+import matplotlib.gridspec as gridspect
+
+# Create cmap
+from matplotlib.colors import ListedColormap
+import matplotlib.colors as colors
+import matplotlib.cm as cmx
+
+import numpy as np
+import pandas as pn
+import scipy.stats as stats
+import seaborn as sns
+
+def loss_abs(estimate_s, true_s, u=1,o=1,u_f=1,o_f=1, r=1):
+    """Absolute-error loss function.
+
+        Args:
+            estimate_s (int or float): Value estimate.
+            true_s (int, float or np.array): True value.
+            u (int or float, optional): Underestimation re-weighting factor.
+            o (int or float, optional): Overestimation re-weighting factor.
+            u_f (int or float, optional): Fatal underestimation re-weighting factor.
+            o_f (int or float, optional): Fatal overestimation re-weighting factor.
+            r (int or float, optional): Risk-affinity re-weighting factor.
+        Returns:
+            Loss incurred for an estimate given a true value.
+            Based on absolute-error loss, i.e. the absolute distance of the estimate
+            from the true value.
+
+            true_s can be either a single value or an array of possible true values,
+            the output will be a single determined absolute loss value or an array of determined
+            loss values, accordingly.
+
+            estimate_s has to be one single value.
+
+    """
+    true_s = np.array(true_s).astype(float)
+    loss_s = np.zeros_like(true_s)
+    underest = (estimate_s < true_s)
+    overest = (estimate_s > true_s)
+    loss_s[underest] = (true_s[underest] - estimate_s)  * (u * (r ** -0.5))
+    loss_s[overest] = (estimate_s - true_s[overest]) * (o * r)
+    if u_f != 1:
+        underest_fatal = (estimate_s <= 0) & (true_s > 0)
+        loss_s[underest_fatal] = (true_s[underest_fatal] - estimate_s) * (u_f * (r ** -0.5))
+    if o_f != 1:
+        overest_fatal = (estimate_s > 0) & (true_s <= 0)
+        loss_s[overest_fatal] = np.abs((true_s[overest_fatal] - estimate_s)) * (o_f * r)
+    return loss_s
+
+def loss_abs_given_values(estimate_s, true_s, u=1,o=1,u_f=1,o_f=1, r=1):
+    """Absolute-error loss function for the exclusive use with a single
+    given true value.
+
+            Args:
+                estimate_s (int or float): Value estimate.
+                true_s (int, float): True value.
+                u (int or float, optional): Underestimation re-weighting factor.
+                o (int or float, optional): Overestimation re-weighting factor.
+                u_f (int or float, optional): Fatal underestimation re-weighting factor.
+                o_f (int or float, optional): Fatal overestimation re-weighting factor.
+                r (int or float, optional): Risk-affinity re-weighting factor.
+            Returns:
+                Loss incurred for an estimate given one determined true value.
+                Based on absolute-error loss, i.e. the absolute distance of the estimate
+                from the true value.
+
+        """
+    if estimate_s < true_s:
+        if estimate_s <= 0 and true_s > 0:
+            loss_s = (true_s - estimate_s) * (u_f * (r ** -0.5))  # bad case of underestimation
+        else:
+            loss_s = (true_s - estimate_s) * (u * (r ** -0.5)) # normal underestimation
+    elif estimate_s > true_s:
+        if estimate_s > 0 and true_s <= 0:
+            loss_s = (estimate_s - true_s) * (o_f)  # bad case of overestimation
+        else:
+            loss_s = (estimate_s - true_s) * (o * r)  # normal overestimation
+    else:
+        loss_s = 0
+    return loss_s
+
+def loss_sqr(estimate_s, true_s, u=1,o=1,u_f=1,o_f=1, r=1):
+    """Squared-error loss function.
+
+        Args:
+            estimate_s (int or float): Value estimate.
+            true_s (int, float or np.array): True value.
+            u (int or float, optional): Underestimation re-weighting factor.
+            o (int or float, optional): Overestimation re-weighting factor.
+            u_f (int or float, optional): Fatal underestimation re-weighting factor.
+            o_f (int or float, optional): Fatal overestimation re-weighting factor.
+            r (int or float, optional): Risk-affinity re-weighting factor.
+        Returns:
+            Loss incurred for an estimate of the value given a true value.
+            Based on squared-error loss, i.e. the absolute distance of the estimate
+            from the true value squared.
+
+            true_s can be either a single value or an array of possible true values,
+            the output will be a single determined absolute loss value or an array of determined
+            loss values, accordingly.
+
+            estimate_s has to be one single value.
+
+    """
+    return np.square(loss_abs(estimate_s, true_s, u,o,u_f,o_f, r))
+
+def loss_sqr_given_values(estimate_s, true_s, u=1,o=1,u_f=1,o_f=1, r=1):
+    """Squared-error loss function for the exclusive use with a single
+        given true value.
+
+                Args:
+                    estimate_s (int or float): Value estimate.
+                    true_s (int, float): True value.
+                    u (int or float, optional): Underestimation re-weighting factor.
+                    o (int or float, optional): Overestimation re-weighting factor.
+                    u_f (int or float, optional): Fatal underestimation re-weighting factor.
+                    o_f (int or float, optional): Fatal overestimation re-weighting factor.
+                    r (int or float, optional): Risk-affinity re-weighting factor.
+                Returns:
+                    Loss incurred for an estimate given one determined true value.
+                    Based on squared-error loss, i.e. the absolute distance of the estimate
+                    from the true value squared.
+    """
+    return loss_abs_given_values(estimate_s, true_s, u,o,u_f,o_f, r)**2
+
+def expected_loss_for_estimate(estimate_s, true_s, function='absolute', u=1,o=1,u_f=1,o_f=1, r=1):
+    """Function to attain expected loss for an estimate
+    given a range of possible true values by taking the mean of all
+    possible loss realizations.
+
+        Args:
+            estimate_s (int or float): Value estimate.
+            true_s (int, float or np.array): True value.
+            function ('absolute'(default) or 'squared'): Use of absolute-error or
+                squared-error loss function.
+            u (int or float, optional): Underestimation re-weighting factor.
+            o (int or float, optional): Overestimation re-weighting factor.
+            u_f (int or float, optional): Fatal underestimation re-weighting factor.
+            o_f (int or float, optional): Fatal overestimation re-weighting factor.
+            r (int or float, optional): Risk-affinity re-weighting factor.
+        Returns:
+            Expected loss for a single estimate given a range of possible true values.
+
+            Note: If only one possible true value is passed, the expected loss equals
+            the actually incurred loss.
+
+    """
+
+    if function == 'absolute':
+        return loss_abs(estimate_s, true_s, u,o,u_f,o_f, r).mean()
+    elif function == 'squared':
+        return loss_sqr(estimate_s, true_s, u, o, u_f, o_f, r).mean()
+    else:
+        print('Error: Type of loss function not recognized. '
+              'Use "absolute" or "squared".')
+
+def expected_loss_for_range(estimate_range, true_s, function='absolute', u=1,o=1,u_f=1,o_f=1, r=1):
+    """Function to attain expected loss and Bayes action based on an absolute-error or
+           squared error-loss function for a defined range of estimates.
+
+                Args:
+                    estimate_range (np.array): Range of value estimates.
+                    true_s (np.array): Array of possible true value occurrences (from a probability distribution)
+                    u (int or float, optional): Underestimation re-weighting factor.
+                    o (int or float, optional): Overestimation re-weighting factor.
+                    u_f (int or float, optional): Fatal underestimation re-weighting factor.
+                    o_f (int or float, optional): Fatal overestimation re-weighting factor.
+                    r (int, float or np.array, optional): Risk-affinity re-weighting factor.
+                Returns:
+                    [0]: Expected loss for the range of estimates.
+                    [1]: Bayes action (estimate with minimal expected loss)
+                    [2]: Expected loss of Bayes action.
+        """
+    expected_loss_s = lambda estimate_s, r: expected_loss_for_estimate(estimate_s, true_s, function, u, o, u_f, o_f, r)
+    loss_e = [expected_loss_s(e, r) for e in estimate_range]
+    bayes_action = sop.fmin(expected_loss_s, -40, args=(r,), disp=False)
+    bayes_action_loss_e = expected_loss_s(bayes_action, r)
+    return loss_e, bayes_action, bayes_action_loss_e
+
+def expected_loss_plot(estimate_range, true_s, risk_range=1, function='absolute', u=1,o=1,u_f=1,o_f=1,
+                        verbose=False):
+    """Function to plot expected losses and the Bayes action for a range of estimates
+    relative to a distribution of possible true values.
+    It is possible to plot this for several risk factors at once.
+
+            Args:
+                estimate_range (np.array): Range of value estimates.
+                true_s (np.array): Array of possible true value occurrences (from a probability distribution)
+                u (int or float, optional): Underestimation re-weighting factor.
+                o (int or float, optional): Overestimation re-weighting factor.
+                u_f (int or float, optional): Fatal underestimation re-weighting factor.
+                o_f (int or float, optional): Fatal overestimation re-weighting factor.
+                r (int, float or np.array, optional): Risk-affinity re-weighting factor.
+            Returns:
+                Plot of expected losses for risk neutrality
+                or several risk factors.
+
+    """
+    ax = plt.subplot(111)
+    if isinstance(risk_range, (int,float)):
+        r_range=[risk_range]
+    else:
+        r_range=risk_range
+    for r in r_range:
+        loss_e, bayes_a, bayes_a_loss_e = expected_loss_for_range(estimate_range, true_s, function, u,o,u_f,o_f, r)
+        _color = next(ax._get_lines.prop_cycler)
+        plt.plot(estimate_range, loss_e, label="r =" + str(r), color=_color['color'])
+        plt.scatter(bayes_a, bayes_a_loss_e, s=70,
+                        color=_color['color'])  # , label = "Bayes action r "+str(r))
+        plt.vlines(bayes_a, 0, 10 * np.max(loss_e), color=_color['color'], linestyles="--")
+        if verbose == True:
+            print("Bayes action (minimum) at risk r %.2f: %.2f --- expected loss: %.2f"\
+                  % (r, bayes_a, bayes_a_loss_e))
+    plt.legend(loc="upper left", scatterpoints=1, title="Legend")
+    plt.xlabel("Estimate")
+    plt.ylabel("Expected loss")
+    plt.xlim(estimate_range[0], estimate_range[-1])
+    plt.ylim(0, 1.1 * np.max(loss_e))
+    plt.grid()
+    plt.show()
+
+def loss_for_estimate(estimate_s, true_s, function='absolute', u=1,o=1,u_f=1,o_f=1, r=1):
+    """Function to attain actually incurred loss for an estimate
+    given a single true value.
+
+        Args:
+            estimate_s (int or float): Value estimate.
+            true_s (int or float): True value.
+            function ('absolute'(default) or 'squared'): Use of absolute-error or
+                squared-error loss function.
+            u (int or float, optional): Underestimation re-weighting factor.
+            o (int or float, optional): Overestimation re-weighting factor.
+            u_f (int or float, optional): Fatal underestimation re-weighting factor.
+            o_f (int or float, optional): Fatal overestimation re-weighting factor.
+            r (int or float, optional): Risk-affinity re-weighting factor.
+        Returns:
+            Loss for a single estimate given a single determined true value.
+    """
+    if function == 'absolute':
+        return loss_abs_given_values(estimate_s, true_s, u,o,u_f,o_f, r)
+    elif function == 'squared':
+        return loss_sqr_given_values(estimate_s, true_s, u, o, u_f, o_f, r)
+    else:
+        print('Error: Type of loss function not recognized. '
+              'Use "absolute" or "squared".')
+
+def loss_for_range(estimate_range, true_s, function='absolute', u=1,o=1,u_f=1,o_f=1, r=1):
+    """Function to attain loss and Bayes action based on an absolute-error or
+               squared error-loss function for a defined range of estimates
+               given one single true value.
+
+                    Args:
+                        estimate_range (np.array): Range of value estimates.
+                        true_value (int or float): Array of possible true value occurrences (from a probability distribution)
+                        u (int or float, optional): Underestimation re-weighting factor.
+                        o (int or float, optional): Overestimation re-weighting factor.
+                        u_f (int or float, optional): Fatal underestimation re-weighting factor.
+                        o_f (int or float, optional): Fatal overestimation re-weighting factor.
+                        r (int, float or np.array, optional): Risk-affinity re-weighting factor.
+                    Returns:
+                        [0]: Loss for the range of estimates.
+                        [1]: Bayes action (estimate with minimal expected loss)
+                        [2]: Expected loss of Bayes action.
+
+                        Note: Since the is only one possible true value,
+                        the Bayes action will always equal this value.
+            """
+    incurred_loss = lambda estimate_s, r: loss_for_estimate(estimate_s, true_s, function, u, o, u_f, o_f, r)
+    loss_i = [incurred_loss(e, r) for e in estimate_range]
+    bayes_action = sop.fmin(incurred_loss, -40, args=(r,), disp=False)
+    bayes_action_loss = incurred_loss(bayes_action, r)
+    return loss_i, bayes_action, bayes_action_loss
+
+def loss_plot(estimate_range, true_s, risk_range=1, function='absolute', u=1,o=1,u_f=1,o_f=1,
+                        verbose=False):
+    """Function to plot losses for a range of estimates
+    relative to a single given true value.
+    It is possible to plot this for several risk factors at once.
+
+            Args:
+                estimate_range (np.array): Range of value estimates.
+                true_s (int or float): Array of possible true value occurrences (from a probability distribution)
+                u (int or float, optional): Underestimation re-weighting factor.
+                o (int or float, optional): Overestimation re-weighting factor.
+                u_f (int or float, optional): Fatal underestimation re-weighting factor.
+                o_f (int or float, optional): Fatal overestimation re-weighting factor.
+                r (int, float or np.array, optional): Risk-affinity re-weighting factor.
+            Returns:
+                Plot of losses for risk neutrality
+                or several risk factors given a single determined true value.
+
+    """
+    ax = plt.subplot(111)
+    if isinstance(risk_range, (int,float)):
+        r_range=[risk_range]
+    else:
+        r_range=risk_range
+    for r in r_range:
+        loss_i, bayes_a, bayes_a_loss = loss_for_range(estimate_range, true_s, function, u,o,u_f,o_f, r)
+        _color = next(ax._get_lines.prop_cycler)
+        plt.plot(estimate_range, loss_i, label="r =" + str(r), color=_color['color'])
+        plt.scatter(bayes_a, bayes_a_loss, s=70,
+                        color=_color['color'])  # , label = "Bayes action r "+str(r))
+        plt.vlines(bayes_a, 0, 10 * np.max(loss_i), color=_color['color'], linestyles="--")
+        if verbose == True:
+            print("Bayes action (minimum) at risk r %.2f: %.2f --- expected loss: %.2f"\
+                  % (r, bayes_a, bayes_a_loss))
+    plt.legend(loc="upper left", scatterpoints=1, title="Legend")
+    plt.xlabel("Estimate")
+    plt.ylabel("Expected loss")
+    plt.xlim(estimate_range[0], estimate_range[-1])
+    plt.ylim(0, 1.1 * np.max(loss_i))
+    plt.grid()
+    plt.show()
+
+
+def plot_multiple_loss():
+
+    def plot_axis(xvals, nor_l, loss, subplot_spec, e, depth=False):
+        grid = gridspect.GridSpecFromSubplotSpec(1, 1, subplot_spec=subplot_spec)
+        ax = fig.add_subplot(grid[:, :])
+        # ax0.yaxis.set_visible(False)
+        axr = ax.twinx()
+
+        labels = 'Thickness Score' if depth is True else None
+        c = default_red if depth is True else default_blue
+
+        ax.plot(xvals, nor_l, color=c, linewidth=.5, label=labels)
+        ax.fill_between(xvals, nor_l, 0, color=c, alpha=.8)
+        ax.set_ylabel('Likelihood')
+        ax.set_ylim(0, .16)
+        ax.set_xlim(-25+6, 6+25)
+
+        axr.set_ylim(0, 40)
+        axr.set_ylabel('Expected Loss')
+
+        ax.spines['top'].set_color('none')
+        ax.spines['left'].set_color('none')
+        if e == 0:
+            axr.plot(xvals, loss, linewidth=3, color='white')
+            axr.plot(xvals, loss, linewidth=2, color='#496155', label='Loss')
+            axr.legend(frameon=True, facecolor='white', framealpha=1)
+
+        else:
+            axr.plot(xvals, loss, linewidth=3, color='white')
+            axr.plot(xvals, loss, linewidth=2, color='#496155', label='Risk Neutral')
+        if e%2 == 0:
+
+            axr.yaxis.set_visible(False)
+           # axr.yaxis.label.set_visible(False)
+
+        else:
+
+            for tick in axr.get_yticklines():
+                tick.set_visible(False)
+           # axr.yaxis.label.set_visible(False)
+            ax.yaxis.set_visible(False)
+        ax.xaxis.set_visible(False)
+        axr.xaxis.set_visible(False)
+        if e>3:
+            ax.xaxis.set_visible(True)
+            axr.xaxis.set_visible(True)
+            ax.set_xlabel('Score')
+        return ax, axr
+
+    def res_score_loss(true_s, estimate_s, ov=1.25, uv_b=1.5, ov_b=2, risk_s=1):
+
+        underest = (estimate_s < true_s)
+        # loss_s = np.zeros((estimate_s.shape[0], true_s.shape[0]))
+        underest_bad = (estimate_s <= 0) & (true_s > 0)
+        overest = (estimate_s > true_s)
+        overest_bad = (estimate_s > 0) & (true_s <= 0)
+        a = underest * abs(true_s - estimate_s) * (risk_s ** -0.5)
+        b = underest_bad * abs(true_s - estimate_s) * (uv_b * (risk_s ** -0.5))
+        c = overest * abs(estimate_s - true_s) * (ov * risk_s)
+        d = overest_bad * abs(estimate_s - true_s) * (ov_b * risk_s)
+        loss_s = (a + b + c + d).mean(axis=1)
+        return loss_s, (a,b,c,d)
+
+    def abs_loss(true_s, estimate_s, ov=1, uv=1, risk_s=1, uv_b=1):
+        print('foooooo')
+        underest = (estimate_s < true_s)
+        # loss_s = np.zeros((estimate_s.shape[0], true_s.shape[0]))
+        underest_bad = 1# (estimate_s <= 0) & (true_s > 0)
+        overest = (estimate_s > true_s)
+        overest_bad = (estimate_s > 0) & (true_s <= 0)
+        b = 0
+        d = 0
+        a = underest * abs(true_s - estimate_s) * (uv * risk_s)
+      #  b = underest_bad * (true_s - estimate_s) * (uv_b * (risk_s))
+        c = overest * abs(estimate_s - true_s) * (ov * risk_s)
+        #d = overest_bad * (estimate_s - true_s) * (ov_b * risk_s)
+        loss_s = (a + b + c + d).mean(axis=1)
+        return loss_s, (a,b,c,d)
+
+    def compute_values(mu, sigma, loss_type, x_range=(-24+6, 6+24), risk=1, depth=False):
+        samples_size = 100000
+
+        if x_range is None:
+            x_max = mu + 5 * sigma
+            x_min = mu - 5 * sigma
+        else:
+            x_min, x_max = x_range
+       # xvals = np.linspace(-23+6, 6+23, 100)
+
+        xvals = np.linspace(x_min, x_max, 100)
+        nor_l = stats.norm.pdf(xvals, loc=mu, scale=sigma)
+        samples = np.random.normal(loc=mu, scale=sigma, size=samples_size)
+
+        if depth is True:
+            #xvals = np.linspace(0, 60, 100)
+            # nor_d = stats.norm.pdf(xvals, loc=30, scale=5)
+            samples_depth = np.random.normal(loc=30, scale=5, size=samples_size)
+            depth_score = samples_depth
+
+            # Transformation to cost
+            d_cost = - ((depth_score-depth_score.min()) / 8) ** 2.6
+            samples = samples + d_cost
+        elif depth is False:
+            pass
+
+        else:
+            samples = depth
+
+        if loss_type == 'abs':
+            loss, partial = abs_loss(samples, xvals.reshape(-1, 1), 1, 1, risk_s=risk)
+            #return xvals, nor_l, loss, partial
+        elif loss_type == 'custom':
+            loss, partial = res_score_loss(samples, xvals.reshape(-1, 1), risk_s=risk)
+
+        if depth is True:
+            return xvals, nor_l, loss, partial, samples, d_cost
+        else:
+            return xvals, nor_l, loss, partial
+
+    sns.set(style="white")  # , rc={"axes.facecolor": (0, 0, 0, 0)})
+    # Discrete cmap
+    pal_disc = sns.cubehelix_palette(10, rot=-.25, light=.7)
+    pal_disc_l = sns.cubehelix_palette(10)
+    my_cmap = ListedColormap(pal_disc)
+    my_cmap_l = ListedColormap(pal_disc_l)
+
+    # Continuous cmap
+    pal_cont = sns.cubehelix_palette(250, rot=-.25, light=.7)
+    pal_cont_l = sns.cubehelix_palette(250)
+
+    my_cmap_full = ListedColormap(pal_cont)
+    my_cmap_full_l = ListedColormap(pal_cont_l)
+
+    default_red = '#DA8886'
+    default_blue = pal_cont.as_hex()[4]
+    default_l = pal_disc_l.as_hex()[4]
+
+    # %matplotlib notebook
+    figsize = (12, 12)
+    fig, axes = plt.subplots(0, 0, figsize=figsize, constrained_layout=False)
+    sns.despine(left=True, bottom=True)
+
+    gs_0 = gridspect.GridSpec(3, 2, figure=fig, hspace=0.1, wspace=0.009)
+
+    axis = []
+
+    mu = [12]*6
+    sigma = [2.3, 2.3 ,4,4, 4, 4]
+    type = ['abs', 'custom', 'abs', 'custom', 'abs', 'custom']
+    for e, ax in enumerate(gs_0):
+
+        if e==0:
+            x, n, l, partial = compute_values(mu[e], sigma[e], type[e])
+            ax_, axr_ = plot_axis(x, n, l, ax, e)
+            ax_.vlines(mu[e], 0, 40, linestyles='--', alpha=.5)
+            ax_.vlines(0, 0, 40, linestyles='--', alpha=.5)
+            axr_.hlines(l.min(), -25, x[l.argmin()],
+                       linestyles='--', alpha=.5)
+
+        if e==1:
+            x, n, l, partial = compute_values(mu[e], sigma[e], type[e])
+            ax_, axr_ = plot_axis(x, n, l, ax, e)
+            ax_.vlines(mu[e], 0, 40, linestyles='--', alpha=.5)
+            ax_.vlines(0, 0, 40, linestyles='--', alpha=.5)
+            labels = ['Underes.', 'Crit. Underest.', 'Overest.', 'Crit. Overest.']
+            for i in range(4):
+                axr_.plot(x, partial[i].mean(axis=1), '--', linewidth=1, label=labels[i])
+
+            axr_.legend(loc=2, frameon=True, facecolor='white', framealpha=1)
+
+        if e==2 or e==3:
+            x, n, l, partial = compute_values(mu[e], sigma[e], type[e])
+            ax_, axr_ = plot_axis(x, n, l, ax, e)
+            axr_.plot(x[l.argmin()], 0, 'o',  color='#496155', markersize=12)
+            if e == 2:
+                axr_.hlines(l.min(), -25, x[l.argmin()],
+                            linestyles='--', alpha=.5)
+
+            x, n, l, partial = compute_values(mu[e], sigma[e], type[e], risk=.2)
+            axr_.plot(x, l, linewidth=3, color='white')
+            axr_.plot(x, l, linewidth=2, label='Risk Friendly')
+            axr_.plot(x[l.argmin()], 0, 'o',  color='b', markersize=12)
+
+            x, n, l, partial = compute_values(mu[e], sigma[e], type[e], risk=5)
+            axr_.plot(x, l, linewidth=3, color='white')
+            axr_.plot(x, l, linewidth=2, label='Risk Averse')
+            axr_.plot(x[l.argmin()], 0, 'o',  color='orange', markersize=12)
+
+            ax_.vlines(mu[e], 0, 40, linestyles='--', alpha=.5)
+            ax_.vlines(0, 0, 40, linestyles='--', alpha=.5)
+            if e==2:
+                axr_.legend(frameon=True, facecolor='white', framealpha=1)
+
+        if e > 3:
+            x, n, l, partial, ss, d_cost = compute_values(mu[e], sigma[e], type[e],
+                                                          x_range=(-24+6, 6+24),
+                                                          risk=1, depth=True)
+            ax_, axr_ = plot_axis(x, n, l, ax, e, depth=True)
+            axr_.plot(x[l.argmin()], 0, 'o',  color='#496155', markersize=12)
+
+            x_max = ss.mean() + 6 * ss.std()
+            x_min = ss.mean() - 6 * ss.std()
+            print(x_max, x_min, 'foo')
+            print(ss.mean(), d_cost.mean())
+            x, n, l, partial = compute_values(mu[e], sigma[e], type[e],
+                                                      x_range=(-24 + 6, 6 + 24),
+                                                      risk=.2, depth=ss)
+            #print(_1.mean(),  d_cost.mean())
+            axr_.plot(x, l, linewidth=3, color='white')
+            axr_.plot(x, l, linewidth=2, label='Risk Friendly')
+            axr_.plot(x[l.argmin()], 0, 'o',  color='b', markersize=12)
+
+            x, n, l, partial = compute_values(mu[e], sigma[e], type[e],
+                                                      x_range=(-24 + 6, 6 + 24),
+                                                      risk=5, depth=ss)
+          #  print(_1.mean(),  d_cost.mean())
+            axr_.plot(x, l, linewidth=3, color='white')
+            axr_.plot(x, l, linewidth=2, label='Risk Adverse')
+            axr_.plot(x[l.argmin()], 0, 'o',  color='orange', markersize=12)
+
+            k = sns.kdeplot(d_cost, ax=ax_, shade=True, label='Depth Score', color=default_red,
+                        alpha=.8,linewidth=.5)
+            #k.legend_.set_frame_on(True)
+            sns.kdeplot(ss, ax=ax_, label='Final Score', shade=True, color=default_blue,
+                        alpha=1, linewidth=.5)
+            k.legend_.set_frame_on(True)
+            k.legend_.set_alpha(1)
+
+            if e == 4:
+                k.legend_.set_visible(False)
+            # ax_.vlines(mu[e], 0, 40, linestyles='--', alpha=.5)
+            ax_.vlines(np.median(ss), 0, 40, linestyles='--', alpha=.5)
+            ax_.vlines(0, 0, 40, linestyles='--', alpha=.5)
+          #  ax_.legend(loc=2)
+
+        axis.append((ax_, axr_))
+    return k
```

### Comparing `gempy-2.2b10.dev1/gempy/assets/geophysics.py` & `gempy-2.3.0/gempy/assets/geophysics.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,124 +1,124 @@
-"""
-    This file is part of gempy.
-
-    gempy is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    gempy is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
-"""
-
-import numpy as np
-import theano
-import theano.tensor as T
-from gempy.core.grid_modules.grid_types import CenteredGrid
-
-
-class GravityPreprocessing(CenteredGrid):
-    def __init__(self, centered_grid: CenteredGrid = None):
-
-        if centered_grid is None:
-            super().__init__()
-        elif isinstance(centered_grid, CenteredGrid):
-            self.kernel_centers = centered_grid.kernel_centers
-            self.kernel_dxyz_right = centered_grid.kernel_dxyz_right
-            self.kernel_dxyz_left = centered_grid.kernel_dxyz_left
-        self.tz = np.empty(0)
-
-    def set_tz_kernel(self, scale=True, **kwargs):
-        if self.kernel_centers.size == 0:
-            self.set_centered_kernel(**kwargs)
-
-        grid_values = self.kernel_centers
-
-        s_gr_x = grid_values[:, 0]
-        s_gr_y = grid_values[:, 1]
-        s_gr_z = grid_values[:, 2]
-
-        # getting the coordinates of the corners of the voxel...
-        x_cor = np.stack((s_gr_x - self.kernel_dxyz_left[:, 0], s_gr_x + self.kernel_dxyz_right[:, 0]), axis=1)
-        y_cor = np.stack((s_gr_y - self.kernel_dxyz_left[:, 1], s_gr_y + self.kernel_dxyz_right[:, 1]), axis=1)
-        z_cor = np.stack((s_gr_z - self.kernel_dxyz_left[:, 2], s_gr_z + self.kernel_dxyz_right[:, 2]), axis=1)
-
-        # ...and prepare them for a vectorial op
-        x_matrix = np.repeat(x_cor, 4, axis=1)
-        y_matrix = np.tile(np.repeat(y_cor, 2, axis=1), (1, 2))
-        z_matrix = np.tile(z_cor, (1, 4))
-
-        s_r = np.sqrt(x_matrix ** 2 + y_matrix ** 2 + z_matrix ** 2)
-
-        # This is the vector that determines the sign of the corner of the voxel
-        mu = np.array([1, -1, -1, 1, -1, 1, 1, -1])
-
-        if scale is True:
-            #
-            G = 6.674e-3 # ugal     cm3⋅g−1⋅s−26.67408e-2 -- 1 m/s^2 to milligal = 100000 milligal
-        else:
-            from scipy.constants import G
-
-        self.tz = (
-            G *
-            np.sum(- 1 *
-                   mu * (
-                           x_matrix * np.log(y_matrix + s_r) +
-                           y_matrix * np.log(x_matrix + s_r) -
-                           z_matrix * np.arctan(x_matrix * y_matrix / (z_matrix * s_r))),
-                   axis=1))
-
-        return self.tz
-
-
-class MagneticsPreprocessing(CenteredGrid):
-    """
-    @Nilgün Güdük
-
-    """
-    def __init__(self, centered_grid: CenteredGrid = None):
-
-        if centered_grid is None:
-            super().__init__()
-        elif isinstance(centered_grid, CenteredGrid):
-            self.kernel_centers = centered_grid.kernel_centers
-            self.kernel_dxyz_right = centered_grid.kernel_dxyz_right
-            self.kernel_dxyz_left = centered_grid.kernel_dxyz_left
-        self.V = np.empty(0)
-
-    def set_Vs_kernel(self, **kwargs):
-        if self.kernel_centers.size == 0:
-            self.set_centered_kernel(**kwargs)
-
-        grid_values = self.kernel_centers
-        s_gr_x = grid_values[:, 0]
-        s_gr_y = grid_values[:, 1]
-        s_gr_z = -1 * grid_values[:, 2]  # talwani takes x-axis positive downwards, and gempy negative downwards
-
-        # getting the coordinates of the corners of the voxel...
-        x_cor = np.stack((s_gr_x - self.kernel_dxyz_left[:, 0], s_gr_x + self.kernel_dxyz_right[:, 0]), axis=1)
-        y_cor = np.stack((s_gr_y - self.kernel_dxyz_left[:, 1], s_gr_y + self.kernel_dxyz_right[:, 1]), axis=1)
-        z_cor = np.stack((s_gr_z + self.kernel_dxyz_left[:, 2], s_gr_z - self.kernel_dxyz_right[:, 2]), axis=1)
-        # ...and prepare them for a vectorial op
-        x_matrix = np.repeat(x_cor, 4, axis=1)
-        y_matrix = np.tile(np.repeat(y_cor, 2, axis=1), (1, 2))
-        z_matrix = np.tile(z_cor, (1, 4))
-
-        R = np.sqrt(x_matrix ** 2 + y_matrix ** 2 + z_matrix ** 2)  # distance to each corner
-        s = np.array([-1, 1, 1, -1, 1, -1, -1, 1])  # gives the sign of each corner: depends on your coordinate system
-
-        # variables V1-6 represent integrals of volume for each voxel
-        V1 = np.sum(-1 * s * np.arctan2((y_matrix * z_matrix), (x_matrix * R)), axis=1)
-        V2 = np.sum(s * np.log(R + z_matrix), axis=1)
-        V3 = np.sum(s * np.log(R + y_matrix), axis=1)
-        V4 = np.sum(-1 * s * np.arctan2((x_matrix * z_matrix), (y_matrix * R)), axis=1)
-        V5 = np.sum(s * np.log(R + x_matrix), axis=1)
-        V6 = np.sum(-1 * s * np.arctan2((x_matrix * y_matrix), (z_matrix * R)), axis=1)
-
-        # contains all the volume integrals (6 x n_kernelvalues)
-        V = np.array([V1, V2, V3, V4, V5, V6])
-        return V
+"""
+    This file is part of gempy.
+
+    gempy is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    gempy is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
+"""
+
+import numpy as np
+import aesara
+import aesara.tensor  as T
+from gempy.core.grid_modules.grid_types import CenteredGrid
+
+
+class GravityPreprocessing(CenteredGrid):
+    def __init__(self, centered_grid: CenteredGrid = None):
+
+        if centered_grid is None:
+            super().__init__()
+        elif isinstance(centered_grid, CenteredGrid):
+            self.kernel_centers = centered_grid.kernel_centers
+            self.kernel_dxyz_right = centered_grid.kernel_dxyz_right
+            self.kernel_dxyz_left = centered_grid.kernel_dxyz_left
+        self.tz = np.empty(0)
+
+    def set_tz_kernel(self, scale=True, **kwargs):
+        if self.kernel_centers.size == 0:
+            self.set_centered_kernel(**kwargs)
+
+        grid_values = self.kernel_centers
+
+        s_gr_x = grid_values[:, 0]
+        s_gr_y = grid_values[:, 1]
+        s_gr_z = grid_values[:, 2]
+
+        # getting the coordinates of the corners of the voxel...
+        x_cor = np.stack((s_gr_x - self.kernel_dxyz_left[:, 0], s_gr_x + self.kernel_dxyz_right[:, 0]), axis=1)
+        y_cor = np.stack((s_gr_y - self.kernel_dxyz_left[:, 1], s_gr_y + self.kernel_dxyz_right[:, 1]), axis=1)
+        z_cor = np.stack((s_gr_z - self.kernel_dxyz_left[:, 2], s_gr_z + self.kernel_dxyz_right[:, 2]), axis=1)
+
+        # ...and prepare them for a vectorial op
+        x_matrix = np.repeat(x_cor, 4, axis=1)
+        y_matrix = np.tile(np.repeat(y_cor, 2, axis=1), (1, 2))
+        z_matrix = np.tile(z_cor, (1, 4))
+
+        s_r = np.sqrt(x_matrix ** 2 + y_matrix ** 2 + z_matrix ** 2)
+
+        # This is the vector that determines the sign of the corner of the voxel
+        mu = np.array([1, -1, -1, 1, -1, 1, 1, -1])
+
+        if scale is True:
+            #
+            G = 6.674e-3 # ugal     cm3⋅g−1⋅s−26.67408e-2 -- 1 m/s^2 to milligal = 100000 milligal
+        else:
+            from scipy.constants import G
+
+        self.tz = (
+            G *
+            np.sum(- 1 *
+                   mu * (
+                           x_matrix * np.log(y_matrix + s_r) +
+                           y_matrix * np.log(x_matrix + s_r) -
+                           z_matrix * np.arctan(x_matrix * y_matrix / (z_matrix * s_r))),
+                   axis=1))
+
+        return self.tz
+
+
+class MagneticsPreprocessing(CenteredGrid):
+    """
+    @Nilgün Güdük
+
+    """
+    def __init__(self, centered_grid: CenteredGrid = None):
+
+        if centered_grid is None:
+            super().__init__()
+        elif isinstance(centered_grid, CenteredGrid):
+            self.kernel_centers = centered_grid.kernel_centers
+            self.kernel_dxyz_right = centered_grid.kernel_dxyz_right
+            self.kernel_dxyz_left = centered_grid.kernel_dxyz_left
+        self.V = np.empty(0)
+
+    def set_Vs_kernel(self, **kwargs):
+        if self.kernel_centers.size == 0:
+            self.set_centered_kernel(**kwargs)
+
+        grid_values = self.kernel_centers
+        s_gr_x = grid_values[:, 0]
+        s_gr_y = grid_values[:, 1]
+        s_gr_z = -1 * grid_values[:, 2]  # talwani takes x-axis positive downwards, and gempy negative downwards
+
+        # getting the coordinates of the corners of the voxel...
+        x_cor = np.stack((s_gr_x - self.kernel_dxyz_left[:, 0], s_gr_x + self.kernel_dxyz_right[:, 0]), axis=1)
+        y_cor = np.stack((s_gr_y - self.kernel_dxyz_left[:, 1], s_gr_y + self.kernel_dxyz_right[:, 1]), axis=1)
+        z_cor = np.stack((s_gr_z + self.kernel_dxyz_left[:, 2], s_gr_z - self.kernel_dxyz_right[:, 2]), axis=1)
+        # ...and prepare them for a vectorial op
+        x_matrix = np.repeat(x_cor, 4, axis=1)
+        y_matrix = np.tile(np.repeat(y_cor, 2, axis=1), (1, 2))
+        z_matrix = np.tile(z_cor, (1, 4))
+
+        R = np.sqrt(x_matrix ** 2 + y_matrix ** 2 + z_matrix ** 2)  # distance to each corner
+        s = np.array([-1, 1, 1, -1, 1, -1, -1, 1])  # gives the sign of each corner: depends on your coordinate system
+
+        # variables V1-6 represent integrals of volume for each voxel
+        V1 = np.sum(-1 * s * np.arctan2((y_matrix * z_matrix), (x_matrix * R)), axis=1)
+        V2 = np.sum(s * np.log(R + z_matrix), axis=1)
+        V3 = np.sum(s * np.log(R + y_matrix), axis=1)
+        V4 = np.sum(-1 * s * np.arctan2((x_matrix * z_matrix), (y_matrix * R)), axis=1)
+        V5 = np.sum(s * np.log(R + x_matrix), axis=1)
+        V6 = np.sum(-1 * s * np.arctan2((x_matrix * y_matrix), (z_matrix * R)), axis=1)
+
+        # contains all the volume integrals (6 x n_kernelvalues)
+        V = np.array([V1, V2, V3, V4, V5, V6])
+        return V
```

### Comparing `gempy-2.2b10.dev1/gempy/assets/kriging.py` & `gempy-2.3.0/gempy/assets/kriging.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,572 +1,572 @@
-"""
-This file is part of gempy.
-
-Created on 07.08.2019
-
-@author: Jan von Harten
-"""
-
-import warnings
-try:
-    from scipy.spatial.distance import cdist
-except ImportError:
-    warnings.warn('scipy.spatial package is not installed.')
-
-import numpy as np
-import pandas as pd
-from gempy.plot import _visualization_2d, _plot, helpers
-import matplotlib.cm as cm
-import matplotlib.pyplot as plt
-from copy import deepcopy
-
-class domain(object):
-
-    def __init__(self, model, domain=None, data=None, set_mean=None):
-
-        # set model from a gempy solution
-        # TODO: Check if I actually need all this or if its easier to just get grid and lith of the solution
-        self.sol = model
-
-        # set kriging surfaces, basically in which lithologies to do all this, default is everything
-        # TODO: Maybe also allow to pass a gempy regular grid object
-        if domain is None:
-            domain = np.unique(self.sol.lith_block)
-        self.set_domain(domain)
-
-        # set data, default is None
-        # TODO: need to figure out a way to then set mean and variance for the SGS and SK
-        if data is None:
-            data = None  # why do you do this, data is none already if it is none?
-        self.set_data(data)
-
-        # basic statistics of data
-        # TODO: allow to set this  for SK ???
-        if set_mean is None:
-            set_mean = np.mean(data[:, 3])
-        self.inp_mean = set_mean
-
-        self.inp_var = np.var(data[:, 3])
-        self.inp_std = np.sqrt(self.inp_var)
-
-    def set_domain(self, domain):
-        """
-        Method to cut domain by array of surfaces. Simply masking the lith_block with array of input lithologies
-        applying mask to grid.
-        Args:
-            domain (np.array)(x,) = array containing all surfaces of interest from the gempy model that
-                                            the operation should be performed in
-        Returns:
-            ? Nothing cause of self - is this good practice?
-            """
-        # set domain to variable of class
-        self.domain = domain
-
-        # mask by array of input surfaces (by id, can be from different series)
-        self.mask = np.isin(self.sol.lith_block, self.domain)
-
-        # Apply mask to lith_block and grid
-        self.krig_lith = self.sol.lith_block[self.mask]
-        self.krig_grid = self.sol.grid.values[self.mask]
-
-    def set_data(self, data):
-        """
-        Method to set input data from csv or numpy array.
-        Args:
-            data (np.array)(x,4)  = array of input data (conditioning) with [:,0]=x coordinate, [:,1]=y coordinate
-                                            [:,2]=z coordinate and [:,3]=value of measured property
-        Returns:
-            ? Nothing cause of self - is this good practice?
-            """
-        # set domain to variable of class
-        self.data = data
-
-        # create dataframe of input data for calling
-        d = {'X': data[:, 0], 'Y': data[:, 1], 'Z': data[:, 2], 'property': data[:, 3]}
-        self.data_df = pd.DataFrame(data=d)
-
-
-class variogram_model(object):
-
-    # class containing all the variogram functionality
-
-    def __init__(self, theoretical_model=None, range_=1, sill=1, nugget=0):
-
-        if theoretical_model is None:
-            theoretical_model = 'exponential'
-        self.theoretical_model = theoretical_model
-
-        # default
-        self.range_ = range_
-        self.sill = sill
-        self.nugget = nugget
-
-    def calculate_semivariance(self, d):
-
-        if self.theoretical_model == 'exponential':
-            gamma = self.exponential_variogram_model(d)
-        elif self.theoretical_model == 'gaussian':
-            gamma = self.gaussian_variogram_model(d)
-        elif self.theoretical_model == 'spherical':
-            gamma = self.spherical_variogram_model(d)
-        else:
-            print('theoretical varigoram model not understood')
-        return gamma
-
-    def calculate_covariance(self, d):
-
-        if self.theoretical_model == 'exponential':
-            gamma = self.exponential_covariance_model(d)
-        elif self.theoretical_model == 'gaussian':
-            gamma = self.gaussian_covariance_model(d)
-        elif self.theoretical_model == 'spherical':
-            gamma = self.spherical_covariance_model(d)
-        else:
-            print('theoretical varigoram model not understood')
-        return gamma
-
-    # TODO: Add more options
-    # seems better now by changing psill in covariance model
-    def exponential_variogram_model(self, d):
-        '''Exponential variogram model, effective range approximately 3r, valid in R3'''
-        psill = self.sill - self.nugget
-        gamma = psill * (1. - np.exp(-(np.absolute(d) / (self.range_)))) + self.nugget
-        return gamma
-
-    def exponential_covariance_model(self, d):
-        '''Exponential covariance model, effective range approximately 3r, valid in R3'''
-        psill = self.sill - self.nugget
-        cov = psill * (np.exp(-(np.absolute(d) / (self.range_))))
-        return cov
-
-    def gaussian_variogram_model(self, d):
-        '''Gaussian variogram model, effective range approximately sqrt(3r),
-        deprecated due to reverse curvature near orgin, valid in R3'''
-        psill = self.sill - self.nugget
-        gamma = psill * (1. - np.exp(-d ** 2. / (self.range_) ** 2.)) + self.nugget
-        return gamma
-
-    def gaussian_covariance_model(self, d):
-        '''Gaussian covariance model, effective range approximately sqrt(3r),
-        deprecated due to reverse curvature near orgin, valid in R3'''
-        psill = self.sill - self.nugget
-        gamma = psill * (np.exp(-d ** 2. / (self.range_) ** 2.))
-        return gamma
-
-    def spherical_variogram_model(self, d):
-        '''Spherical variogram model, effective range equals range parameter, valid in R3'''
-        psill = self.sill - self.nugget
-        d = d.astype(float)
-        gamma = np.piecewise(d, [d <= self.range_, d > self.range_],
-                             [lambda d:
-                              psill * ((3. * d) / (2. * self.range_)
-                                       - (d ** 3.) / (2. * self.range_ ** 3.)) + self.nugget,
-                              lambda d: self.sill])
-        return gamma
-
-    def spherical_covariance_model(self, d):
-        '''Spherical covariance model, effective range equals range parameter, valid in R3'''
-        psill = self.sill - self.nugget
-        d = d.astype(float)
-        gamma = np.piecewise(d, [d <= self.range_, d > self.range_],
-                             [lambda d:
-                              psill * (1 - ((3. * d) / (2. * self.range_)
-                                            - (d ** 3.) / (2. * self.range_ ** 3.))),
-                              lambda d: 0])
-        return gamma
-
-    # TODO: Make this better and nicer and everything
-    # option for covariance
-    # display range, sill, nugget, practical range etc.
-    def plot(self, type_='variogram', show_parameters=True):
-
-        if show_parameters == True:
-            plt.axhline(self.sill, color='black', lw=1)
-            plt.text(self.range_*2, self.sill, 'sill', fontsize=12, va='center', ha='center', backgroundcolor='w')
-            plt.axvline(self.range_, color='black', lw=1)
-            plt.text(self.range_, self.sill/2, 'range', fontsize=12, va='center', ha='center', backgroundcolor='w')
-
-        if type_ == 'variogram':
-            d = np.arange(0, self.range_*4, self.range_/1000)
-            plt.plot(d, self.calculate_semivariance(d), label=self.theoretical_model + " variogram model")
-            plt.ylabel('semivariance')
-            plt.title('Variogram model')
-            plt.legend()
-
-        if type_ == 'covariance':
-            d = np.arange(0, self.range_*4, self.range_/1000)
-            plt.plot(d, self.calculate_covariance(d), label=self.theoretical_model + " covariance model")
-            plt.ylabel('covariance')
-            plt.title('Covariance model')
-            plt.legend()
-
-        if type_ == 'both':
-            d = np.arange(0, self.range_*4, self.range_/1000)
-            plt.plot(d, self.calculate_semivariance(d), label=self.theoretical_model + " variogram model")
-            plt.plot(d, self.calculate_covariance(d), label=self.theoretical_model + " covariance model")
-            plt.ylabel('semivariance/covariance')
-            plt.title('Models of spatial correlation')
-            plt.legend()
-
-        plt.xlabel('lag distance')
-        plt.ylim(0-self.sill/20, self.sill+self.sill/20)
-        plt.xlim(0, self.range_*4)
-
-
-
-class field_solution(object):
-
-    def __init__(self, domain, variogram_model, results, field_type):
-
-        self.results_df = results
-        self.variogram_model = deepcopy(variogram_model)
-        self.domain = deepcopy(domain)
-        self.field_type = field_type
-
-    def plot_results(self, geo_data, prop='val', direction='y', result='interpolation', cell_number=0, contour=False,
-                     cmap='viridis', alpha=0, legend=False, interpolation='nearest', show_data=True):
-        """
-        TODO WRITE DOCSTRING
-        Args:
-            geo_data:
-            prop: property that should be plotted - "val", "var" or "both"
-            direction: x, y or z
-            cell_number:
-            contour:
-            cmap:
-            alpha:
-            legend:
-
-        Returns:
-
-        """
-        a = np.full_like(self.domain.mask, np.nan, dtype=np.double) #array like lith_block but with nan if outside domain
-
-        est_vals = self.results_df['estimated value'].values
-        est_var = self.results_df['estimation variance'].values
-
-        # set values
-        if prop == 'val':
-            a[np.where(self.domain.mask == True)] = est_vals
-        elif prop == 'var':
-            a[np.where(self.domain.mask == True)] = est_var
-        elif prop == 'both':
-            a[np.where(self.domain.mask == True)] = est_vals
-            b = np.full_like(self.domain.mask, np.nan, dtype=np.double)
-            b[np.where(self.domain.mask == True)] = est_var
-        else:
-            print('prop must be val var or both')
-
-        #create plot object
-        p = _visualization_2d.PlotSolution(geo_data)
-        _a, _b, _c, extent_val, x, y = p._slice(direction, cell_number)[:-2]
-
-        #colors
-        cmap = cm.get_cmap(cmap)
-        cmap.set_bad(color='w', alpha=alpha) #define color and alpha for nan values
-
-        # plot
-        if prop is not 'both':
-            if show_data:
-                plt.scatter(self.domain.data_df[x].values, self.domain.data_df[y].values, marker='*', s=9, c='k')
-
-            _plot.plot_section(geo_data, direction=direction, cell_number=cell_number)
-            if contour == True:
-                im = plt.contourf(a.reshape(self.domain.sol.grid.regular_grid.resolution)[_a, _b, _c].T, cmap=cmap,
-                                  origin='lower', levels=25,
-                                  extent=extent_val, interpolation=interpolation)
-                if legend:
-                    ax = plt.gca()
-                    helpers.add_colorbar(axes=ax, label='prop', cs=im)
-            else:
-                im = plt.imshow(a.reshape(self.domain.sol.grid.regular_grid.resolution)[_a, _b, _c].T, cmap=cmap,
-                                origin='lower',
-                                extent=extent_val, interpolation=interpolation)
-                if legend:
-                    helpers.add_colorbar(im, label='property value', location='right')
-
-        else:
-            f, ax = plt.subplots(1, 2, sharex=True, sharey=True)
-            ax[0].title.set_text('Estimated value')
-            im1 = ax[0].imshow(a.reshape(self.domain.sol.grid.regular_grid.resolution)[_a, _b, _c].T, cmap=cmap,
-                               origin='lower', interpolation=interpolation,
-                               extent=self.domain.sol.grid.regular_grid.extent[[0, 1, 4, 5]])
-            helpers.add_colorbar(im1, label='property value')
-            ax[1].title.set_text('Variance')
-            im2 = ax[1].imshow(b.reshape(self.domain.sol.grid.regular_grid.resolution)[_a, _b, _c].T, cmap=cmap,
-                               origin='lower', interpolation=interpolation,
-                               extent=self.domain.sol.grid.regular_grid.extent[[0, 1, 4, 5]])
-            helpers.add_colorbar(im2, label='variance[]')
-            plt.tight_layout()
-
-# TODO: check with new ordianry kriging and nugget effect
-def simple_kriging(a, b, prop, var_mod, inp_mean):
-    '''
-    Method for simple kriging calculation.
-    Args:
-        a (np.array): distance matrix containing all distances between target point and moving neighbourhood
-        b (np.array): distance matrix containing all inter-point distances between locations in moving neighbourhood
-        prop (np.array): array containing scalar property values of locations in moving neighbourhood
-        var_mod: variogram model object
-    Returns:
-        result (float?): single scalar property value estimated for target location
-        std_ok (float?): single scalar variance value for estimate at target location
-    '''
-
-    # empty matrix building
-    shape = len(a)
-    C = np.zeros((shape, shape))
-    c = np.zeros((shape))
-    w = np.zeros((shape))
-
-    # Filling matrices with covariances based on calculated distances
-    C[:shape, :shape] = var_mod.calculate_covariance(b) #? cov or semiv
-    c[:shape] = var_mod.calculate_covariance(a) #? cov or semiv
-
-    # nugget effect for simple kriging - dont remember why i set this actively, should be the same
-    #np.fill_diagonal(C, self.sill)
-
-    # TODO: find way to check quality of matrix and solutions for instability
-    # Solve Kriging equations
-    w = np.linalg.solve(C, c)
-
-    # calculating estimate and variance for kriging
-    pred_var = var_mod.sill - np.sum(w * c)
-    # Note that here the input mean is required, if kriged mean equivalent to OK
-    result = inp_mean + np.sum(w * (prop - inp_mean))
-
-    return result, pred_var
-
-def ordinary_kriging(a, b, prop, var_mod):
-    '''
-    Method for ordinary kriging calculation.
-    Args:
-        a (np.array): distance matrix containing all distances between target point and moving neighbourhood
-        b (np.array): distance matrix containing all inter-point distances between locations in moving neighbourhood
-        prop (np.array): array containing scalar property values of locations in moving neighbourhood
-        var_mod: variogram model object
-    Returns:
-        result (float?): single scalar property value estimated for target location
-        std_ok (float?): single scalar variance value for estimate at target location
-    '''
-
-    # empty matrix building for OK
-    shape = len(a)
-    C = np.zeros((shape + 1, shape + 1))
-    c = np.zeros((shape + 1))
-    w = np.zeros((shape + 1))
-
-    # filling matirces based on model for spatial correlation
-    C[:shape, :shape] = var_mod.calculate_semivariance(b)
-    c[:shape] = var_mod.calculate_semivariance(a)
-
-    # matrix setup - compare pykrige, special for OK
-    np.fill_diagonal(C, 0)  # this needs to be done as semivariance for distance 0 is 0 by definition
-    C[shape, :] = 1.0
-    C[:, shape] = 1.0
-    C[shape, shape] = 0.0
-    c[shape] = 1.0
-
-    # This is if we want exact interpolator
-    # but be aware that it strictly forces estimates to go through data points
-    # c[c == self.nugget] = 0
-
-    # TODO: find way to check quality of matrix and solutions for instability
-    # Solve Kriging equations
-    w = np.linalg.solve(C, c)
-
-    # calculating estimate and variance for kriging
-    pred_var = w[shape] + np.sum(w[:shape] * c[:shape])
-    result = np.sum(w[:shape] * prop)
-
-    return result, pred_var
-
-def create_kriged_field(domain, variogram_model, distance_type='euclidian',
-                        moving_neighbourhood='all', kriging_type='OK', n_closest_points=20):
-    '''
-    Method to create a kriged field over the defined grid of the gempy solution depending on the defined
-    input data (conditioning).
-    Returns:
-        self.results_df (pandas dataframe):   Dataframe containing coordinates, kriging estimate
-                                                    and kriging variance for each grid point
-    '''
-    # empty arrays for results (estimated values and variances)
-    kriging_result_vals = np.zeros(len(domain.krig_grid))
-    kriging_result_vars = np.zeros(len(domain.krig_grid))
-
-    # Start with distance calculation
-    # 1) all grid points to all data points
-    # 2) all data points among each other
-    if distance_type == 'euclidian':
-        # calculate distances between all input data points
-        dist_all_to_all = cdist(domain.data[:, :3], domain.data[:, :3])
-        # calculate distances between all grid points and all input data points
-        dist_grid_to_all = cdist(domain.krig_grid, domain.data[:, :3])
-
-    # Main loop that goes through whole domain (grid)
-    for i in range(len(domain.krig_grid)):
-
-        # STEP 1: Multiple if elif conditions to define moving neighbourhood:
-        if moving_neighbourhood == 'all':
-            # cutting matrices and properties based on moving neighbourhood
-            a = dist_grid_to_all[i]
-            b = dist_all_to_all
-            prop = domain.data[:, 3]
-
-        elif moving_neighbourhood == 'n_closest':
-            # cutting matrices and properties based on moving neighbourhood
-            a = np.sort(dist_grid_to_all[i])
-            a = a[:n_closest_points]
-            aux = np.argsort(dist_grid_to_all[i])
-            prop = domain.data[:, 3][aux]
-            prop = prop[:n_closest_points]
-            aux = aux[:n_closest_points]
-            b = dist_all_to_all[np.ix_(aux, aux)]
-
-        elif moving_neighbourhood == 'range':
-            # cutting matrices and properties based on moving neighbourhood
-            aux = np.where(dist_grid_to_all[i] <= variogram_model.range_)[0]
-            a = dist_grid_to_all[i][aux]
-            prop = domain.data[:, 3][aux]
-            b = dist_all_to_all[np.ix_(aux, aux)]
-
-        else:
-            print("FATAL ERROR: Moving neighbourhood not understood")
-
-        # STEP 2: Multiple if elif conditions to calculate kriging at point
-        if kriging_type == 'OK':
-            val, var = ordinary_kriging(a, b, prop, variogram_model)
-        elif kriging_type == 'SK':
-            val, var = simple_kriging(a, b, prop, variogram_model, domain.inp_mean)
-        elif kriging_type == 'UK':
-            print("Universal Kriging not implemented")
-        else:
-            print("FATAL ERROR: Kriging type not understood")
-
-        # STEP 3: Save results
-        kriging_result_vals[i] = val
-        kriging_result_vars[i] = var
-
-    # create dataframe of results data for calling
-    d = {'X': domain.krig_grid[:, 0], 'Y': domain.krig_grid[:, 1], 'Z': domain.krig_grid[:, 2],
-        'estimated value': kriging_result_vals, 'estimation variance': kriging_result_vars}
-
-    results_df = pd.DataFrame(data=d)
-
-    return field_solution(domain, variogram_model, results_df, field_type='interpolation')
-
-def create_gaussian_field(domain, variogram_model, distance_type='euclidian',
-                        moving_neighbourhood='all', kriging_type='OK', n_closest_points=20):
-    '''
-    Method to create a kriged field over the defined grid of the gempy solution depending on the defined
-    input data (conditioning).
-    Returns:
-        self.results_df (pandas dataframe):   Dataframe containing coordinates, kriging estimate
-                                                        and kriging variance for each grid point
-    '''
-    # perform SGS with same options as kriging
-    # TODO: set options for no starting points (Gaussian field) - mean and variance
-
-    # set random path through all unknown locations
-    shuffled_grid = domain.krig_grid
-    np.random.shuffle(shuffled_grid)
-
-    # append shuffled grid to input locations
-    sgs_locations = np.vstack((domain.data[:,:3],shuffled_grid))
-    # create array for input properties
-    sgs_prop_updating = domain.data[:,3] # use this and then always stack new ant end
-
-    # container for estimation variances
-    estimation_var = np.zeros(len(shuffled_grid))
-
-    # - distance calculation (stays the same)
-    # 1) all points to all points in order of path
-    # 2) known locations at beginning?
-    if distance_type == 'euclidian':
-        # calculate distances between all input data points
-        dist_all_to_all = cdist(sgs_locations, sgs_locations)
-
-    # set counter og active data (start=input data, grwoing by 1 newly calcualted point each run)
-    active_data = len(sgs_prop_updating)
-
-    # Main loop that goes through whole domain (grid)
-    for i in range(len(domain.krig_grid)):
-        # STEP 1: cut update distance matrix to correct size
-        # HAVE TO CHECK IF THIS IS REALLY CORRECT
-        active_distance_matrix = dist_all_to_all[:active_data,:active_data]
-        active_distance_vector = dist_all_to_all[:,active_data] #basically next point to be simulated
-        active_distance_vector = active_distance_vector[:active_data] #cut to left or diagonal
-
-        # TODO: NEED PART FOR ZERO INPUT OR NO POINTS IN RANGE OR LESS THAN N POINTS
-
-        # STEP 2: Multiple if elif conditions to define moving neighbourhood:
-        if moving_neighbourhood == 'all':
-            # cutting matrices and properties based on moving neighbourhood
-            a = active_distance_vector
-            b = active_distance_matrix
-            prop = sgs_prop_updating
-
-        elif moving_neighbourhood == 'n_closest':
-            # cutting matrices and properties based on moving neighbourhood
-
-            # This seems to work
-            if len(sgs_prop_updating) <= n_closest_points:
-                a = active_distance_vector[:active_data]
-                b = active_distance_matrix[:active_data,:active_data]
-                prop = sgs_prop_updating
-
-            # this does not # DAMN THIS STILL HAS ITSELF RIGHT? PROBLEM!
-            else:
-                a = np.sort(active_distance_vector)
-                a = a[:n_closest_points]
-                aux = np.argsort(active_distance_vector)
-                prop = sgs_prop_updating[aux]
-                prop = prop[:n_closest_points]
-                aux = aux[:n_closest_points]
-                b = active_distance_matrix[np.ix_(aux, aux)]
-
-        elif moving_neighbourhood == 'range':
-            # cutting matrices and properties based on moving neighbourhood
-            aux = np.where(active_distance_vector <= variogram_model.range_)[0]
-            a = active_distance_vector[aux]
-            prop = sgs_prop_updating[aux]
-            b = active_distance_matrix[np.ix_(aux, aux)]
-
-        else:
-            print("FATAL ERROR: Moving neighbourhood not understood")
-
-        # STEP 3: Multiple if elif conditions to calculate kriging at point
-        # TODO: Cover case of data location and grid point coinciding
-        if kriging_type == 'OK':
-            val, var = ordinary_kriging(a, b, prop, variogram_model)
-        elif kriging_type == 'SK':
-            val, var = simple_kriging(a, b, prop, variogram_model, domain.inp_mean)
-        elif kriging_type == 'UK':
-            print("Universal Kriging not implemented")
-        else:
-            print("FATAL ERROR: Kriging type not understood")
-
-        # STEP 4: Draw from random distribution
-        std_ = np.sqrt(var)
-        estimate = np.random.normal(val, scale=std_)
-
-        # append to prop:
-        sgs_prop_updating = np.append(sgs_prop_updating, estimate)
-        estimation_var[i]= var
-
-        # at end of loop: include simulated point for next step
-        active_data += 1
-
-    # delete original input data from results
-    simulated_prop = sgs_prop_updating[len(domain.data[:,3]):] # check if this works like intended
-
-    # create dataframe of results data for calling
-    d = {'X': shuffled_grid[:, 0], 'Y': shuffled_grid[:, 1], 'Z': shuffled_grid[:, 2],
-         'estimated value': simulated_prop, 'estimation variance': estimation_var}
-
-    results_df = pd.DataFrame(data=d)
-    results_df = results_df.sort_values(['X','Y','Z'])
-
-    return field_solution(domain, variogram_model, results_df, field_type='simulation')
-
-
-
+"""
+This file is part of gempy.
+
+Created on 07.08.2019
+
+@author: Jan von Harten
+"""
+
+import warnings
+try:
+    from scipy.spatial.distance import cdist
+except ImportError:
+    warnings.warn('scipy.spatial package is not installed.')
+
+import numpy as np
+import pandas as pd
+from gempy.plot import _visualization_2d, _plot, helpers
+import matplotlib.cm as cm
+import matplotlib.pyplot as plt
+from copy import deepcopy
+
+class domain(object):
+
+    def __init__(self, model, domain=None, data=None, set_mean=None):
+
+        # set model from a gempy solution
+        # TODO: Check if I actually need all this or if its easier to just get grid and lith of the solution
+        self.sol = model
+
+        # set kriging surfaces, basically in which lithologies to do all this, default is everything
+        # TODO: Maybe also allow to pass a gempy regular grid object
+        if domain is None:
+            domain = np.unique(self.sol.lith_block)
+        self.set_domain(domain)
+
+        # set data, default is None
+        # TODO: need to figure out a way to then set mean and variance for the SGS and SK
+        if data is None:
+            data = None  # why do you do this, data is none already if it is none?
+        self.set_data(data)
+
+        # basic statistics of data
+        # TODO: allow to set this  for SK ???
+        if set_mean is None:
+            set_mean = np.mean(data[:, 3])
+        self.inp_mean = set_mean
+
+        self.inp_var = np.var(data[:, 3])
+        self.inp_std = np.sqrt(self.inp_var)
+
+    def set_domain(self, domain):
+        """
+        Method to cut domain by array of surfaces. Simply masking the lith_block with array of input lithologies
+        applying mask to grid.
+        Args:
+            domain (np.array)(x,) = array containing all surfaces of interest from the gempy model that
+                                            the operation should be performed in
+        Returns:
+            ? Nothing cause of self - is this good practice?
+            """
+        # set domain to variable of class
+        self.domain = domain
+
+        # mask by array of input surfaces (by id, can be from different series)
+        self.mask = np.isin(self.sol.lith_block, self.domain)
+
+        # Apply mask to lith_block and grid
+        self.krig_lith = self.sol.lith_block[self.mask]
+        self.krig_grid = self.sol.grid.values[self.mask]
+
+    def set_data(self, data):
+        """
+        Method to set input data from csv or numpy array.
+        Args:
+            data (np.array)(x,4)  = array of input data (conditioning) with [:,0]=x coordinate, [:,1]=y coordinate
+                                            [:,2]=z coordinate and [:,3]=value of measured property
+        Returns:
+            ? Nothing cause of self - is this good practice?
+            """
+        # set domain to variable of class
+        self.data = data
+
+        # create dataframe of input data for calling
+        d = {'X': data[:, 0], 'Y': data[:, 1], 'Z': data[:, 2], 'property': data[:, 3]}
+        self.data_df = pd.DataFrame(data=d)
+
+
+class variogram_model(object):
+
+    # class containing all the variogram functionality
+
+    def __init__(self, theoretical_model=None, range_=1, sill=1, nugget=0):
+
+        if theoretical_model is None:
+            theoretical_model = 'exponential'
+        self.theoretical_model = theoretical_model
+
+        # default
+        self.range_ = range_
+        self.sill = sill
+        self.nugget = nugget
+
+    def calculate_semivariance(self, d):
+
+        if self.theoretical_model == 'exponential':
+            gamma = self.exponential_variogram_model(d)
+        elif self.theoretical_model == 'gaussian':
+            gamma = self.gaussian_variogram_model(d)
+        elif self.theoretical_model == 'spherical':
+            gamma = self.spherical_variogram_model(d)
+        else:
+            print('theoretical varigoram model not understood')
+        return gamma
+
+    def calculate_covariance(self, d):
+
+        if self.theoretical_model == 'exponential':
+            gamma = self.exponential_covariance_model(d)
+        elif self.theoretical_model == 'gaussian':
+            gamma = self.gaussian_covariance_model(d)
+        elif self.theoretical_model == 'spherical':
+            gamma = self.spherical_covariance_model(d)
+        else:
+            print('theoretical varigoram model not understood')
+        return gamma
+
+    # TODO: Add more options
+    # seems better now by changing psill in covariance model
+    def exponential_variogram_model(self, d):
+        '''Exponential variogram model, effective range approximately 3r, valid in R3'''
+        psill = self.sill - self.nugget
+        gamma = psill * (1. - np.exp(-(np.absolute(d) / (self.range_)))) + self.nugget
+        return gamma
+
+    def exponential_covariance_model(self, d):
+        '''Exponential covariance model, effective range approximately 3r, valid in R3'''
+        psill = self.sill - self.nugget
+        cov = psill * (np.exp(-(np.absolute(d) / (self.range_))))
+        return cov
+
+    def gaussian_variogram_model(self, d):
+        '''Gaussian variogram model, effective range approximately sqrt(3r),
+        deprecated due to reverse curvature near orgin, valid in R3'''
+        psill = self.sill - self.nugget
+        gamma = psill * (1. - np.exp(-d ** 2. / (self.range_) ** 2.)) + self.nugget
+        return gamma
+
+    def gaussian_covariance_model(self, d):
+        '''Gaussian covariance model, effective range approximately sqrt(3r),
+        deprecated due to reverse curvature near orgin, valid in R3'''
+        psill = self.sill - self.nugget
+        gamma = psill * (np.exp(-d ** 2. / (self.range_) ** 2.))
+        return gamma
+
+    def spherical_variogram_model(self, d):
+        '''Spherical variogram model, effective range equals range parameter, valid in R3'''
+        psill = self.sill - self.nugget
+        d = d.astype(float)
+        gamma = np.piecewise(d, [d <= self.range_, d > self.range_],
+                             [lambda d:
+                              psill * ((3. * d) / (2. * self.range_)
+                                       - (d ** 3.) / (2. * self.range_ ** 3.)) + self.nugget,
+                              lambda d: self.sill])
+        return gamma
+
+    def spherical_covariance_model(self, d):
+        '''Spherical covariance model, effective range equals range parameter, valid in R3'''
+        psill = self.sill - self.nugget
+        d = d.astype(float)
+        gamma = np.piecewise(d, [d <= self.range_, d > self.range_],
+                             [lambda d:
+                              psill * (1 - ((3. * d) / (2. * self.range_)
+                                            - (d ** 3.) / (2. * self.range_ ** 3.))),
+                              lambda d: 0])
+        return gamma
+
+    # TODO: Make this better and nicer and everything
+    # option for covariance
+    # display range, sill, nugget, practical range etc.
+    def plot(self, type_='variogram', show_parameters=True):
+
+        if show_parameters == True:
+            plt.axhline(self.sill, color='black', lw=1)
+            plt.text(self.range_*2, self.sill, 'sill', fontsize=12, va='center', ha='center', backgroundcolor='w')
+            plt.axvline(self.range_, color='black', lw=1)
+            plt.text(self.range_, self.sill/2, 'range', fontsize=12, va='center', ha='center', backgroundcolor='w')
+
+        if type_ == 'variogram':
+            d = np.arange(0, self.range_*4, self.range_/1000)
+            plt.plot(d, self.calculate_semivariance(d), label=self.theoretical_model + " variogram model")
+            plt.ylabel('semivariance')
+            plt.title('Variogram model')
+            plt.legend()
+
+        if type_ == 'covariance':
+            d = np.arange(0, self.range_*4, self.range_/1000)
+            plt.plot(d, self.calculate_covariance(d), label=self.theoretical_model + " covariance model")
+            plt.ylabel('covariance')
+            plt.title('Covariance model')
+            plt.legend()
+
+        if type_ == 'both':
+            d = np.arange(0, self.range_*4, self.range_/1000)
+            plt.plot(d, self.calculate_semivariance(d), label=self.theoretical_model + " variogram model")
+            plt.plot(d, self.calculate_covariance(d), label=self.theoretical_model + " covariance model")
+            plt.ylabel('semivariance/covariance')
+            plt.title('Models of spatial correlation')
+            plt.legend()
+
+        plt.xlabel('lag distance')
+        plt.ylim(0-self.sill/20, self.sill+self.sill/20)
+        plt.xlim(0, self.range_*4)
+
+
+
+class field_solution(object):
+
+    def __init__(self, domain, variogram_model, results, field_type):
+
+        self.results_df = results
+        self.variogram_model = deepcopy(variogram_model)
+        self.domain = deepcopy(domain)
+        self.field_type = field_type
+
+    def plot_results(self, geo_data, prop='val', direction='y', result='interpolation', cell_number=0, contour=False,
+                     cmap='viridis', alpha=0, legend=False, interpolation='nearest', show_data=True):
+        """
+        TODO WRITE DOCSTRING
+        Args:
+            geo_data:
+            prop: property that should be plotted - "val", "var" or "both"
+            direction: x, y or z
+            cell_number:
+            contour:
+            cmap:
+            alpha:
+            legend:
+
+        Returns:
+
+        """
+        a = np.full_like(self.domain.mask, np.nan, dtype=np.double) #array like lith_block but with nan if outside domain
+
+        est_vals = self.results_df['estimated value'].values
+        est_var = self.results_df['estimation variance'].values
+
+        # set values
+        if prop == 'val':
+            a[np.where(self.domain.mask == True)] = est_vals
+        elif prop == 'var':
+            a[np.where(self.domain.mask == True)] = est_var
+        elif prop == 'both':
+            a[np.where(self.domain.mask == True)] = est_vals
+            b = np.full_like(self.domain.mask, np.nan, dtype=np.double)
+            b[np.where(self.domain.mask == True)] = est_var
+        else:
+            print('prop must be val var or both')
+
+        #create plot object
+        p = _visualization_2d.PlotSolution(geo_data)
+        _a, _b, _c, extent_val, x, y = p._slice(direction, cell_number)[:-2]
+
+        #colors
+        cmap = cm.get_cmap(cmap)
+        cmap.set_bad(color='w', alpha=alpha) #define color and alpha for nan values
+
+        # plot
+        if prop is not 'both':
+            if show_data:
+                plt.scatter(self.domain.data_df[x].values, self.domain.data_df[y].values, marker='*', s=9, c='k')
+
+            _plot.plot_section(geo_data, direction=direction, cell_number=cell_number)
+            if contour == True:
+                im = plt.contourf(a.reshape(self.domain.sol.grid.regular_grid.resolution)[_a, _b, _c].T, cmap=cmap,
+                                  origin='lower', levels=25,
+                                  extent=extent_val, interpolation=interpolation)
+                if legend:
+                    ax = plt.gca()
+                    helpers.add_colorbar(axes=ax, label='prop', cs=im)
+            else:
+                im = plt.imshow(a.reshape(self.domain.sol.grid.regular_grid.resolution)[_a, _b, _c].T, cmap=cmap,
+                                origin='lower',
+                                extent=extent_val, interpolation=interpolation)
+                if legend:
+                    helpers.add_colorbar(im, label='property value', location='right')
+
+        else:
+            f, ax = plt.subplots(1, 2, sharex=True, sharey=True)
+            ax[0].title.set_text('Estimated value')
+            im1 = ax[0].imshow(a.reshape(self.domain.sol.grid.regular_grid.resolution)[_a, _b, _c].T, cmap=cmap,
+                               origin='lower', interpolation=interpolation,
+                               extent=self.domain.sol.grid.regular_grid.extent[[0, 1, 4, 5]])
+            helpers.add_colorbar(im1, label='property value')
+            ax[1].title.set_text('Variance')
+            im2 = ax[1].imshow(b.reshape(self.domain.sol.grid.regular_grid.resolution)[_a, _b, _c].T, cmap=cmap,
+                               origin='lower', interpolation=interpolation,
+                               extent=self.domain.sol.grid.regular_grid.extent[[0, 1, 4, 5]])
+            helpers.add_colorbar(im2, label='variance[]')
+            plt.tight_layout()
+
+# TODO: check with new ordianry kriging and nugget effect
+def simple_kriging(a, b, prop, var_mod, inp_mean):
+    '''
+    Method for simple kriging calculation.
+    Args:
+        a (np.array): distance matrix containing all distances between target point and moving neighbourhood
+        b (np.array): distance matrix containing all inter-point distances between locations in moving neighbourhood
+        prop (np.array): array containing scalar property values of locations in moving neighbourhood
+        var_mod: variogram model object
+    Returns:
+        result (float?): single scalar property value estimated for target location
+        std_ok (float?): single scalar variance value for estimate at target location
+    '''
+
+    # empty matrix building
+    shape = len(a)
+    C = np.zeros((shape, shape))
+    c = np.zeros((shape))
+    w = np.zeros((shape))
+
+    # Filling matrices with covariances based on calculated distances
+    C[:shape, :shape] = var_mod.calculate_covariance(b) #? cov or semiv
+    c[:shape] = var_mod.calculate_covariance(a) #? cov or semiv
+
+    # nugget effect for simple kriging - dont remember why i set this actively, should be the same
+    #np.fill_diagonal(C, self.sill)
+
+    # TODO: find way to check quality of matrix and solutions for instability
+    # Solve Kriging equations
+    w = np.linalg.solve(C, c)
+
+    # calculating estimate and variance for kriging
+    pred_var = var_mod.sill - np.sum(w * c)
+    # Note that here the input mean is required, if kriged mean equivalent to OK
+    result = inp_mean + np.sum(w * (prop - inp_mean))
+
+    return result, pred_var
+
+def ordinary_kriging(a, b, prop, var_mod):
+    '''
+    Method for ordinary kriging calculation.
+    Args:
+        a (np.array): distance matrix containing all distances between target point and moving neighbourhood
+        b (np.array): distance matrix containing all inter-point distances between locations in moving neighbourhood
+        prop (np.array): array containing scalar property values of locations in moving neighbourhood
+        var_mod: variogram model object
+    Returns:
+        result (float?): single scalar property value estimated for target location
+        std_ok (float?): single scalar variance value for estimate at target location
+    '''
+
+    # empty matrix building for OK
+    shape = len(a)
+    C = np.zeros((shape + 1, shape + 1))
+    c = np.zeros((shape + 1))
+    w = np.zeros((shape + 1))
+
+    # filling matirces based on model for spatial correlation
+    C[:shape, :shape] = var_mod.calculate_semivariance(b)
+    c[:shape] = var_mod.calculate_semivariance(a)
+
+    # matrix setup - compare pykrige, special for OK
+    np.fill_diagonal(C, 0)  # this needs to be done as semivariance for distance 0 is 0 by definition
+    C[shape, :] = 1.0
+    C[:, shape] = 1.0
+    C[shape, shape] = 0.0
+    c[shape] = 1.0
+
+    # This is if we want exact interpolator
+    # but be aware that it strictly forces estimates to go through data points
+    # c[c == self.nugget] = 0
+
+    # TODO: find way to check quality of matrix and solutions for instability
+    # Solve Kriging equations
+    w = np.linalg.solve(C, c)
+
+    # calculating estimate and variance for kriging
+    pred_var = w[shape] + np.sum(w[:shape] * c[:shape])
+    result = np.sum(w[:shape] * prop)
+
+    return result, pred_var
+
+def create_kriged_field(domain, variogram_model, distance_type='euclidian',
+                        moving_neighbourhood='all', kriging_type='OK', n_closest_points=20):
+    '''
+    Method to create a kriged field over the defined grid of the gempy solution depending on the defined
+    input data (conditioning).
+    Returns:
+        self.results_df (pandas dataframe):   Dataframe containing coordinates, kriging estimate
+                                                    and kriging variance for each grid point
+    '''
+    # empty arrays for results (estimated values and variances)
+    kriging_result_vals = np.zeros(len(domain.krig_grid))
+    kriging_result_vars = np.zeros(len(domain.krig_grid))
+
+    # Start with distance calculation
+    # 1) all grid points to all data points
+    # 2) all data points among each other
+    if distance_type == 'euclidian':
+        # calculate distances between all input data points
+        dist_all_to_all = cdist(domain.data[:, :3], domain.data[:, :3])
+        # calculate distances between all grid points and all input data points
+        dist_grid_to_all = cdist(domain.krig_grid, domain.data[:, :3])
+
+    # Main loop that goes through whole domain (grid)
+    for i in range(len(domain.krig_grid)):
+
+        # STEP 1: Multiple if elif conditions to define moving neighbourhood:
+        if moving_neighbourhood == 'all':
+            # cutting matrices and properties based on moving neighbourhood
+            a = dist_grid_to_all[i]
+            b = dist_all_to_all
+            prop = domain.data[:, 3]
+
+        elif moving_neighbourhood == 'n_closest':
+            # cutting matrices and properties based on moving neighbourhood
+            a = np.sort(dist_grid_to_all[i])
+            a = a[:n_closest_points]
+            aux = np.argsort(dist_grid_to_all[i])
+            prop = domain.data[:, 3][aux]
+            prop = prop[:n_closest_points]
+            aux = aux[:n_closest_points]
+            b = dist_all_to_all[np.ix_(aux, aux)]
+
+        elif moving_neighbourhood == 'range':
+            # cutting matrices and properties based on moving neighbourhood
+            aux = np.where(dist_grid_to_all[i] <= variogram_model.range_)[0]
+            a = dist_grid_to_all[i][aux]
+            prop = domain.data[:, 3][aux]
+            b = dist_all_to_all[np.ix_(aux, aux)]
+
+        else:
+            print("FATAL ERROR: Moving neighbourhood not understood")
+
+        # STEP 2: Multiple if elif conditions to calculate kriging at point
+        if kriging_type == 'OK':
+            val, var = ordinary_kriging(a, b, prop, variogram_model)
+        elif kriging_type == 'SK':
+            val, var = simple_kriging(a, b, prop, variogram_model, domain.inp_mean)
+        elif kriging_type == 'UK':
+            print("Universal Kriging not implemented")
+        else:
+            print("FATAL ERROR: Kriging type not understood")
+
+        # STEP 3: Save results
+        kriging_result_vals[i] = val
+        kriging_result_vars[i] = var
+
+    # create dataframe of results data for calling
+    d = {'X': domain.krig_grid[:, 0], 'Y': domain.krig_grid[:, 1], 'Z': domain.krig_grid[:, 2],
+        'estimated value': kriging_result_vals, 'estimation variance': kriging_result_vars}
+
+    results_df = pd.DataFrame(data=d)
+
+    return field_solution(domain, variogram_model, results_df, field_type='interpolation')
+
+def create_gaussian_field(domain, variogram_model, distance_type='euclidian',
+                        moving_neighbourhood='all', kriging_type='OK', n_closest_points=20):
+    '''
+    Method to create a kriged field over the defined grid of the gempy solution depending on the defined
+    input data (conditioning).
+    Returns:
+        self.results_df (pandas dataframe):   Dataframe containing coordinates, kriging estimate
+                                                        and kriging variance for each grid point
+    '''
+    # perform SGS with same options as kriging
+    # TODO: set options for no starting points (Gaussian field) - mean and variance
+
+    # set random path through all unknown locations
+    shuffled_grid = domain.krig_grid
+    np.random.shuffle(shuffled_grid)
+
+    # append shuffled grid to input locations
+    sgs_locations = np.vstack((domain.data[:,:3],shuffled_grid))
+    # create array for input properties
+    sgs_prop_updating = domain.data[:,3] # use this and then always stack new ant end
+
+    # container for estimation variances
+    estimation_var = np.zeros(len(shuffled_grid))
+
+    # - distance calculation (stays the same)
+    # 1) all points to all points in order of path
+    # 2) known locations at beginning?
+    if distance_type == 'euclidian':
+        # calculate distances between all input data points
+        dist_all_to_all = cdist(sgs_locations, sgs_locations)
+
+    # set counter og active data (start=input data, grwoing by 1 newly calcualted point each run)
+    active_data = len(sgs_prop_updating)
+
+    # Main loop that goes through whole domain (grid)
+    for i in range(len(domain.krig_grid)):
+        # STEP 1: cut update distance matrix to correct size
+        # HAVE TO CHECK IF THIS IS REALLY CORRECT
+        active_distance_matrix = dist_all_to_all[:active_data,:active_data]
+        active_distance_vector = dist_all_to_all[:,active_data] #basically next point to be simulated
+        active_distance_vector = active_distance_vector[:active_data] #cut to left or diagonal
+
+        # TODO: NEED PART FOR ZERO INPUT OR NO POINTS IN RANGE OR LESS THAN N POINTS
+
+        # STEP 2: Multiple if elif conditions to define moving neighbourhood:
+        if moving_neighbourhood == 'all':
+            # cutting matrices and properties based on moving neighbourhood
+            a = active_distance_vector
+            b = active_distance_matrix
+            prop = sgs_prop_updating
+
+        elif moving_neighbourhood == 'n_closest':
+            # cutting matrices and properties based on moving neighbourhood
+
+            # This seems to work
+            if len(sgs_prop_updating) <= n_closest_points:
+                a = active_distance_vector[:active_data]
+                b = active_distance_matrix[:active_data,:active_data]
+                prop = sgs_prop_updating
+
+            # this does not # DAMN THIS STILL HAS ITSELF RIGHT? PROBLEM!
+            else:
+                a = np.sort(active_distance_vector)
+                a = a[:n_closest_points]
+                aux = np.argsort(active_distance_vector)
+                prop = sgs_prop_updating[aux]
+                prop = prop[:n_closest_points]
+                aux = aux[:n_closest_points]
+                b = active_distance_matrix[np.ix_(aux, aux)]
+
+        elif moving_neighbourhood == 'range':
+            # cutting matrices and properties based on moving neighbourhood
+            aux = np.where(active_distance_vector <= variogram_model.range_)[0]
+            a = active_distance_vector[aux]
+            prop = sgs_prop_updating[aux]
+            b = active_distance_matrix[np.ix_(aux, aux)]
+
+        else:
+            print("FATAL ERROR: Moving neighbourhood not understood")
+
+        # STEP 3: Multiple if elif conditions to calculate kriging at point
+        # TODO: Cover case of data location and grid point coinciding
+        if kriging_type == 'OK':
+            val, var = ordinary_kriging(a, b, prop, variogram_model)
+        elif kriging_type == 'SK':
+            val, var = simple_kriging(a, b, prop, variogram_model, domain.inp_mean)
+        elif kriging_type == 'UK':
+            print("Universal Kriging not implemented")
+        else:
+            print("FATAL ERROR: Kriging type not understood")
+
+        # STEP 4: Draw from random distribution
+        std_ = np.sqrt(var)
+        estimate = np.random.normal(val, scale=std_)
+
+        # append to prop:
+        sgs_prop_updating = np.append(sgs_prop_updating, estimate)
+        estimation_var[i]= var
+
+        # at end of loop: include simulated point for next step
+        active_data += 1
+
+    # delete original input data from results
+    simulated_prop = sgs_prop_updating[len(domain.data[:,3]):] # check if this works like intended
+
+    # create dataframe of results data for calling
+    d = {'X': shuffled_grid[:, 0], 'Y': shuffled_grid[:, 1], 'Z': shuffled_grid[:, 2],
+         'estimated value': simulated_prop, 'estimation variance': estimation_var}
+
+    results_df = pd.DataFrame(data=d)
+    results_df = results_df.sort_values(['X','Y','Z'])
+
+    return field_solution(domain, variogram_model, results_df, field_type='simulation')
+
+
+
```

### Comparing `gempy-2.2b10.dev1/gempy/assets/spill_analysis.py` & `gempy-2.3.0/gempy/assets/spill_analysis.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,444 +1,444 @@
-"""
-    This file is part of gempy.
-
-    gempy is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    gempy is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
-
-
-@author: Fabian A. Stamm
-"""
-
-import numpy as np
-from matplotlib import pyplot as plt
-from skimage import measure
-from scipy.spatial import distance
-
-def get_gradient_minima(geo_data, GX,GY,GZ=np.nan, direction='z', ref='x'):
-    """
-        Compute the shared minima of two gradient fields in 3D space.
-        The positions of minima are returned as surface vertices.
-
-        Args:
-            geo_data (:class:`gempy.data_management.InputData`)
-            GX (ndarray): Gradient field in x-direction.
-            GY (ndarray): Gradient field in y-direction.
-            GZ (ndarray, optional): Gradient field in z-direction. Only needed if
-                minima are relative to a different direction than 'z'.
-            direction (str, optional, default = 'z'): Direction to which the gradients refer to,
-                and to which the minima are related.
-                Default for standard topography is 'z'.
-            ref (str, optional, default='x'): Reference direction for
-                marching cubes to attain vertices. Default is 'x'.
-                'x' or 'y' should suffice and lead to the same results
-                in most cases.
-                If needed, ref can be declared as the 'mean' of both,
-                but this comes at high computational costs and is
-                not recommended in most cases.
-
-        Returns:
-            gradient minima vertices (coordinates in 3D space)
-        """
-    # for scaling from voxels up to original scale using the original extent
-    vox_size_x = np.abs(geo_data.extent[1]-geo_data.extent[0]) / geo_data.resolution[0]
-    vox_size_y = np.abs(geo_data.extent[3]-geo_data.extent[2]) / geo_data.resolution[1]
-    vox_size_z = np.abs(geo_data.extent[5]-geo_data.extent[4]) / geo_data.resolution[2]
-    vox_size_diag = np.sqrt(vox_size_x ** 2 + vox_size_y ** 2 + vox_size_z ** 2)
-
-    if direction == 'z':
-        gx = GX
-        gy = GY
-    elif direction == 'y':
-        gx = GY
-        gy = GZ
-    elif direction == 'x':
-        gx = GZ
-        gy = GY
-    else:
-        raise AttributeError(str(direction) + "must be a cartesian direction, i.e. xyz")
-
-    if ref == 'x':
-        v_gx0 = measure.marching_cubes_lewiner(gx, 0)[0]
-        v_gx = v_gx0
-        v_gx[:, 0] = (v_gx0[:, 0] * vox_size_x)+geo_data.extent[0]
-        v_gx[:, 1] = (v_gx0[:, 1] * vox_size_y)+geo_data.extent[2]
-        v_gx[:, 2] = (v_gx0[:, 2] * vox_size_z)+geo_data.extent[4]
-        return v_gx
-
-    elif ref == 'y':
-        v_gy0 = measure.marching_cubes_lewiner(gy, 0)[0]
-        v_gy = v_gy0
-        v_gy[:, 0] = (v_gy0[:, 0] * vox_size_x)+geo_data.extent[0]
-        v_gy[:, 1] = (v_gy0[:, 1] * vox_size_y)+geo_data.extent[2]
-        v_gy[:, 2] = (v_gy0[:, 2] * vox_size_z)+geo_data.extent[4]
-        return v_gy
-
-    elif ref == 'mean':
-        # using marching cubes to aquire surfaces (vertices, simplices) that align
-        # with the occurrence of zeros of the gradients (gradient minima)
-        v_gx0 = measure.marching_cubes_lewiner(gx, 0)[0]
-        v_gy0 = measure.marching_cubes_lewiner(gy, 0)[0]
-
-        v_gx = v_gx0
-        v_gx[:, 0] = (v_gx0[:, 0] * vox_size_x) + geo_data.extent[0]
-        v_gx[:, 1] = (v_gx0[:, 1] * vox_size_y) + geo_data.extent[2]
-        v_gx[:, 2] = (v_gx0[:, 2] * vox_size_z) + geo_data.extent[4]
-
-        v_gy = v_gy0
-        v_gy[:, 0] = (v_gy0[:, 0] * vox_size_x) + geo_data.extent[0]
-        v_gy[:, 1] = (v_gy0[:, 1] * vox_size_y) + geo_data.extent[2]
-        v_gy[:, 2] = (v_gy0[:, 2] * vox_size_z) + geo_data.extent[4]
-
-        # calculating this distance takes very long
-        # how cut we possibly simplify this?
-        dist_gxy = distance.cdist(v_gx, v_gy, 'euclidean')
-
-        # get distance minima and minima positions for both vertices groups
-        # this way we can pair 2 vertices from gx and gy based on their
-        # common distance which is to be minimal (smaller than to all other points)
-        minx = np.min(dist_gxy, axis=1)
-        miny = np.min(dist_gxy, axis=0)
-        minx_pos = np.argmin(dist_gxy, axis=1)
-        miny_pos = np.argmin(dist_gxy, axis=0)
-
-        # set a cut-off value for minimal distance (here: 3D-diagonal of a voxel/2)
-        gx_cut_bool = minx < (vox_size_diag/2)
-        gy_cut_bool = miny < (vox_size_diag/2)
-
-        # need to pair the vertices of one group to those of the other
-        # for this we actually only need the minima positions of one vertices group
-        ### pair the mins of the shorter array onto the longer array
-        if len(v_gy) >= len(v_gx):
-            vgy_paired = v_gy[minx_pos]
-            # limit (cut down) the vertices groups to only those
-            # below the defined distance threshold
-            vgx_cut = v_gx[gx_cut_bool]
-            vgy_cut = vgy_paired[gx_cut_bool]
-
-            V1 = vgx_cut
-            V2 = vgy_cut
-            V_mean = (V1 + V2) / 2
-        else:
-            vgx_paired = v_gx[miny_pos]
-            vgy_cut = v_gy[gy_cut_bool]
-            vgx_cut = vgx_paired[gy_cut_bool]
-
-            V1 = vgx_cut
-            V2 = vgy_cut
-            V_mean = (V1 + V2) / 2
-
-        return V_mean
-    else:
-        raise AttributeError(str(ref) + "must be 'x', 'y' or 'mean'")
-
-def get_gradmin_intersect(geo_data, surface_vertices, grad_minima):
-    """
-        Compute the intersection between gradient minima and a surface of
-        interest as vertices.
-
-        Args:
-            geo_data (:class:`gempy.data_management.InputData`)
-            surface_vertices (ndarray): Vertices of the surface of interest.
-            grad_minima (ndarray): Vertices of the gradient minima surface.
-
-        Returns:
-            intersection vertices (ndarray)
-
-
-        """
-    vox_size_x = np.abs(geo_data.extent[1] - geo_data.extent[0]) / geo_data.resolution[0]
-    vox_size_y = np.abs(geo_data.extent[3] - geo_data.extent[2]) / geo_data.resolution[1]
-    vox_size_z = np.abs(geo_data.extent[5] - geo_data.extent[4]) / geo_data.resolution[2]
-    vox_size_diag = np.sqrt(vox_size_x ** 2 + vox_size_y ** 2 + vox_size_z ** 2)
-
-    #v_l = np.array(surface_vertices[0])
-    v_l = np.array(surface_vertices)
-    l_dist = distance.cdist(grad_minima, v_l)
-    min_dist = np.min(l_dist, axis=0)
-    l_cut_bool = min_dist < (vox_size_diag/2)
-    intersect = v_l[l_cut_bool]
-    return intersect
-
-def get_voxel_extrema(GX, GY, GZ=np.nan, direction='z'):
-    """
-        Detects gradient extrema in voxels and classifies them as
-        minima, maxima or saddle point based on changes in sign of the
-        gradient.
-
-        Args:
-            GX (ndarray): Gradient field in x-direction.
-            GY (ndarray): Gradient field in y-direction.
-            GZ (ndarray, optional): Gradient field in z-direction. Only needed if
-                minima are relative to a different direction than 'z'.
-            direction (str, optional, default = 'z'): Direction to which the gradients refer to,
-                and to which the minima are related.
-                Default for standard topography is 'z'.
-
-        Returns:
-            All extrema are returned as 'True' or '1' in
-            boolean arrays accordingly.
-
-            [0]: minima voxels (ndarray)
-            [1]: maxima voxels (ndarray)
-            [2]: saddle voxels (ndarray)
-        """
-    if direction == 'z':
-        gx = GX
-        gy = GY
-    elif direction == 'y':
-        gx = GY
-        gy = GZ
-    elif direction == 'x':
-        gx = GZ
-        gy = GY
-    else:
-        raise AttributeError(str(direction) + "must be a cartesian direction, i.e. xyz")
-
-    # getting array with gradient signs (-1 for negative, 1 for positive and exactly 0)
-    gx_signs = np.sign(gx)
-    gy_signs = np.sign(gy)
-    # empty holder arrays for inserting minima and maxima
-    gx_maxima = np.zeros_like(gx)
-    gy_maxima = np.zeros_like(gy)
-    gx_minima = np.zeros_like(gx)
-    gy_minima = np.zeros_like(gy)
-
-    # create boolean arrays where signchange voxels are True
-    signchange_gx = ((np.roll(gx_signs, 1, axis=0) - gx_signs) != 0).astype(int)
-    # avoid border error from np.roll by setting relevant border to False
-    signchange_gx[0, :, :] = 0
-
-    signchange_gy = ((np.roll(gy_signs, 1, axis=1) - gy_signs) != 0).astype(int)
-    signchange_gy[:, 0] = 0
-
-    # conditions for a voxel to be recognized as maximum or minimum in given direction
-    gx_max_cond = (signchange_gx == 1) & (gx_signs == 1)
-    gy_max_cond = (signchange_gy == 1) & (gy_signs == 1)
-    gx_min_cond = (signchange_gx == 1) & (gx_signs == -1)
-    gy_min_cond = (signchange_gy == 1) & (gy_signs == -1)
-    # voxels which meet the conditions are marked as True
-    # for maxima and minima accordingly
-    # since signchange only identifies the next index AFTER the signchange,
-    # we include the voxel BEFORE the signchange by doing an according roll
-    gx_maxima[gx_max_cond] = 1
-    gx_maxima2 = np.roll(gx_maxima, -1, axis=0)
-    gx_max_final = gx_maxima + gx_maxima2
-    gy_maxima[gy_max_cond] = 1
-    gy_maxima2 = np.roll(gy_maxima, -1, axis=1)
-    gy_max_final = gy_maxima + gy_maxima2
-    # overall maxima in BOTH directions:
-    vox_maxima = np.logical_and(gx_max_final, gy_max_final)
-    # NOTE: 0 gives a POSITIVE sign! Might have to correct for this?
-    # analogous process for minima:
-    gx_minima[gx_min_cond] = 1
-    gx_minima2 = np.roll(gx_minima, -1, axis=0)
-    gx_min_final = gx_minima + gx_minima2
-    gy_minima[gy_min_cond] = 1
-    gy_minima2 = np.roll(gy_minima, -1, axis=1)
-    gy_min_final = gy_minima + gy_minima2
-    vox_minima = np.logical_and(gx_min_final, gy_min_final)
-    # saddle points as max in one and min in the other direction
-    vox_saddles = np.logical_or(np.logical_and(gx_min_final, gy_max_final),
-                                np.logical_and(gy_min_final, gx_max_final))
-
-    return vox_minima, vox_maxima, vox_saddles
-
-def get_surface_extrema(geo_data, surface_vertices, GX, GY, ref='x'):
-    """
-        Compute possible extrema (minima, maxima and saddle points)
-        for a surface of interest.
-        This works for standard non-extreme topographies,
-        but does not consider the presence of df.
-
-        Note: This will currently return various points and also
-        several points for one extrema. To attain single points,
-        further distinction and selection is required.
-
-        Args:
-            geo_data (:class:`gempy.data_management.InputData`)
-            GX (ndarray): Gradient field in x-direction.
-            GY (ndarray): Gradient field in y-direction.
-            surface_vertices (ndarray): Vertices of the surface of interest.
-            ref (str, optional, default='x'): Reference direction for
-                marching cubes to attain vertices. Default is 'x'.
-                'x' or 'y' should suffice and lead to the same results
-                in most cases.
-                If needed, ref can be defined as the 'mean' of both,
-                but this comes at high computational costs and is
-                not recommended in most cases.
-
-        Returns:
-            3D coordinates for possible extrema.
-
-            [0]: minima coordinates (ndarray)
-            [1]: maxima coordinates (ndarray)
-            [2]: saddle coordinates (ndarray)
-        """
-    vox_size_x = np.abs(geo_data.extent[1] - geo_data.extent[0]) / geo_data.resolution[0]
-    vox_size_y = np.abs(geo_data.extent[3] - geo_data.extent[2]) / geo_data.resolution[1]
-    vox_size_z = np.abs(geo_data.extent[5] - geo_data.extent[4]) / geo_data.resolution[2]
-    vox_size_diag = np.sqrt(vox_size_x ** 2 + vox_size_y ** 2 + vox_size_z ** 2)
-
-    grad_minima = get_gradient_minima(geo_data, GX,GY, ref)
-    intersect = get_gradmin_intersect(geo_data, surface_vertices, grad_minima)
-    vox_minima, vox_maxima, vox_saddles = get_voxel_extrema(GX, GY)
-
-    if np.any(vox_minima):
-        # get the coordinates for minima, maxima and saddles
-        MIN_coord0 = np.argwhere(vox_minima == True)
-        # rescale the coordinates to actual size of voxels
-        # to use combined with the intersection coordinates from above
-        MIN_coord = MIN_coord0
-        MIN_coord[:, 0] = (MIN_coord0[:, 0] * vox_size_x) + geo_data.extent[0] # + vox_size_x/2
-        MIN_coord[:, 1] = (MIN_coord0[:, 1] * vox_size_y) + geo_data.extent[2] # + vox_size_y/2
-        MIN_coord[:, 2] = (MIN_coord0[:, 2] * vox_size_z) + geo_data.extent[4] # + vox_size_z/2
-        # get distances between intersection and the according extrema coordinates
-        dist_MIN = distance.cdist(intersect, MIN_coord, 'euclidean')
-        # classify intersection extrema by limiting to distance to according voxel coordinates
-        # half a voxel-diagonal to get what is "inside" a voxel (best results, yet)
-        min_dist_MIN = np.min(dist_MIN, axis=1)
-        cut_bool_MIN = min_dist_MIN < (vox_size_diag / 2)
-        intersect_minima_all = intersect[cut_bool_MIN]
-    else:
-        print('No minima found for surface.')
-        intersect_minima_all = []
-
-    if np.any(vox_maxima):
-        MAX_coord0 = np.argwhere(vox_maxima == True)
-        MAX_coord = MAX_coord0
-        MAX_coord[:, 0] = (MAX_coord0[:, 0] * vox_size_x) + geo_data.extent[0] # + vox_size_x/2
-        MAX_coord[:, 1] = (MAX_coord0[:, 1] * vox_size_y) + geo_data.extent[2] # + vox_size_y/2
-        MAX_coord[:, 2] = (MAX_coord0[:, 2] * vox_size_z) + geo_data.extent[4] # + vox_size_z/2
-        dist_MAX = distance.cdist(intersect, MAX_coord, 'euclidean')
-        min_dist_MAX = np.min(dist_MAX, axis=1)
-        cut_bool_MAX = min_dist_MAX < (vox_size_diag / 2)
-        intersect_maxima_all = intersect[cut_bool_MAX]
-    else:
-        print('No maxima found for surface.')
-        intersect_maxima_all = []
-
-    if np.any(vox_saddles):
-        SADD_coord0 = np.argwhere(vox_saddles == True)
-        SADD_coord = SADD_coord0
-        SADD_coord[:, 0] = (SADD_coord0[:, 0] * vox_size_x) + geo_data.extent[0] # + vox_size_x/2
-        SADD_coord[:, 1] = (SADD_coord0[:, 1] * vox_size_y) + geo_data.extent[2] # + vox_size_y/2
-        SADD_coord[:, 2] = (SADD_coord0[:, 2] * vox_size_z) + geo_data.extent[4] # + vox_size_z/2
-        dist_SADD = distance.cdist(intersect, SADD_coord, 'euclidean')
-        min_dist_SADD = np.min(dist_SADD, axis=1)
-        cut_bool_SADD = min_dist_SADD < (vox_size_diag / 2)
-        intersect_saddles_all = intersect[cut_bool_SADD]
-    else:
-        print('No saddle points found for surface.')
-        intersect_saddles_all = []
-
-    return intersect_minima_all, intersect_maxima_all, intersect_saddles_all
-
-def get_highest_saddle_point(geo_data, surface_vertices, GX, GY, ref='x'):
-    """
-        Compute the maximum saddle point for a surface of interest.
-        Useful for simple models with only on main structure.
-
-        Args:
-            geo_data (:class:`gempy.data_management.InputData`)
-            surface_vertices (ndarray): Vertices of the surface of interest.
-            GX (ndarray): Gradient field in x-direction.
-            GY (ndarray): Gradient field in y-direction.
-            ref (str, optional, default='x'): Reference direction for
-                marching cubes to attain vertices. Default is 'x'.
-                'x' or 'y' should suffice and lead to the same results
-                in most cases.
-                If needed, ref can be defined as the 'mean' of both,
-                but this comes at high computational costs and is
-                not recommended in most cases.
-
-        Returns:
-            3D coordinates for the highest saddle point (ndarray).
-        """
-    intersect_saddles_all = get_surface_extrema(geo_data, surface_vertices, GX, GY, ref)[2]
-    if len(intersect_saddles_all) > 0:
-        max_SADD = intersect_saddles_all[np.argmax(intersect_saddles_all[:, 2])]
-    else:
-        max_SADD = []
-    return max_SADD
-
-def get_highest_max(geo_data, surface_vertices, GX, GY, ref='x'):
-    """
-        Compute the highest maximum for a surface of interest.
-        Useful for simple models with only on main structure.
-
-        Args:
-            geo_data (:class:`gempy.data_management.InputData`)
-            surface_vertices (ndarray): Vertices of the surface of interest.
-            GX (ndarray): Gradient field in x-direction.
-            GY (ndarray): Gradient field in y-direction.
-            ref (str, optional, default='x'): Reference direction for
-                marching cubes to attain vertices. Default is 'x'.
-                'x' or 'y' should suffice and lead to the same results
-                in most cases.
-                If needed, ref can be defined as the 'mean' of both,
-                but this comes at high computational costs and is
-                not recommended in most cases.
-
-        Returns:
-            3D coordinates for the highest maximum (ndarray).
-        """
-    intersect_maxima_all = get_surface_extrema(geo_data, surface_vertices, GX, GY, ref)[1]
-    if len(intersect_maxima_all) > 0:
-        it_final_MAX = intersect_maxima_all[np.argmax(intersect_maxima_all[:, 2])]
-    else:
-        it_final_MAX = []
-    return it_final_MAX
-
-def plot_surface_extrema(geo_data, surface_vertices, GX, GY, ref='x'):
-    """
-        Plot the surface of interest and detected extrema (blue= minima,
-        red = maxima, violet = saddle points).
-
-        Args:
-            geo_data (:class:`gempy.data_management.InputData`)
-            surface_vertices (ndarray): Vertices of the surface of interest.
-            GX (ndarray): Gradient field in x-direction.
-            GY (ndarray): Gradient field in y-direction.
-            ref (str, optional, default='x'): Reference direction for
-                marching cubes to attain vertices. Default is 'x'.
-                'x' or 'y' should suffice and lead to the same results
-                in most cases.
-                If needed, ref can be defined as the 'mean' of both,
-                but this comes at high computational costs and is
-                not recommended in most cases.
-
-        """
-    intersect_minima_all, intersect_maxima_all, intersect_saddles_all \
-        = get_surface_extrema(geo_data, surface_vertices, GX, GY, ref)
-    v_l = surface_vertices
-    fig = plt.figure()
-    ax = fig.add_subplot(111, projection='3d')
-    ax.scatter(v_l[:, 0], v_l[:, 1], v_l[:, 2], color='k', alpha=0.2)
-    #ax.scatter(gradmin[:, 0], gradmin[:, 1], gradmin[:, 2], color='k', alpha=0.2)
-    #ax.scatter(intersect[:, 0], intersect[:, 1], intersect[:, 2], color='b')
-    if len(intersect_minima_all) > 0:
-        ax.scatter(intersect_minima_all[:, 0], intersect_minima_all[:, 1], intersect_minima_all[:, 2], \
-                   color='blue',s=200, marker='o')
-    if len(intersect_maxima_all) > 0:
-        ax.scatter(intersect_maxima_all[:,0],intersect_maxima_all[:,1],intersect_maxima_all[:,2],\
-                   color='r', s=200, marker='o')
-    if len(intersect_saddles_all) > 0:
-        ax.scatter(intersect_saddles_all[:, 0], intersect_saddles_all[:, 1], intersect_saddles_all[:, 2], \
-                   color='violet',s=200, marker='o')
-
-    ax.set_xlim(geo_data.extent[0], geo_data.extent[1])
-    ax.set_ylim(geo_data.extent[2], geo_data.extent[3])
-    ax.set_zlim(geo_data.extent[4], geo_data.extent[5])
-    ax.set_xlabel('X [m]')
-    ax.set_ylabel('Y [m]')
-    ax.set_zlabel('Depth [m]')
+"""
+    This file is part of gempy.
+
+    gempy is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    gempy is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
+
+
+@author: Fabian A. Stamm
+"""
+
+import numpy as np
+from matplotlib import pyplot as plt
+from skimage import measure
+from scipy.spatial import distance
+
+def get_gradient_minima(geo_data, GX,GY,GZ=np.nan, direction='z', ref='x'):
+    """
+        Compute the shared minima of two gradient fields in 3D space.
+        The positions of minima are returned as surface vertices.
+
+        Args:
+            geo_data (:class:`gempy.data_management.InputData`)
+            GX (ndarray): Gradient field in x-direction.
+            GY (ndarray): Gradient field in y-direction.
+            GZ (ndarray, optional): Gradient field in z-direction. Only needed if
+                minima are relative to a different direction than 'z'.
+            direction (str, optional, default = 'z'): Direction to which the gradients refer to,
+                and to which the minima are related.
+                Default for standard topography is 'z'.
+            ref (str, optional, default='x'): Reference direction for
+                marching cubes to attain vertices. Default is 'x'.
+                'x' or 'y' should suffice and lead to the same results
+                in most cases.
+                If needed, ref can be declared as the 'mean' of both,
+                but this comes at high computational costs and is
+                not recommended in most cases.
+
+        Returns:
+            gradient minima vertices (coordinates in 3D space)
+        """
+    # for scaling from voxels up to original scale using the original extent
+    vox_size_x = np.abs(geo_data.extent[1]-geo_data.extent[0]) / geo_data.resolution[0]
+    vox_size_y = np.abs(geo_data.extent[3]-geo_data.extent[2]) / geo_data.resolution[1]
+    vox_size_z = np.abs(geo_data.extent[5]-geo_data.extent[4]) / geo_data.resolution[2]
+    vox_size_diag = np.sqrt(vox_size_x ** 2 + vox_size_y ** 2 + vox_size_z ** 2)
+
+    if direction == 'z':
+        gx = GX
+        gy = GY
+    elif direction == 'y':
+        gx = GY
+        gy = GZ
+    elif direction == 'x':
+        gx = GZ
+        gy = GY
+    else:
+        raise AttributeError(str(direction) + "must be a cartesian direction, i.e. xyz")
+
+    if ref == 'x':
+        v_gx0 = measure.marching_cubes_lewiner(gx, 0)[0]
+        v_gx = v_gx0
+        v_gx[:, 0] = (v_gx0[:, 0] * vox_size_x)+geo_data.extent[0]
+        v_gx[:, 1] = (v_gx0[:, 1] * vox_size_y)+geo_data.extent[2]
+        v_gx[:, 2] = (v_gx0[:, 2] * vox_size_z)+geo_data.extent[4]
+        return v_gx
+
+    elif ref == 'y':
+        v_gy0 = measure.marching_cubes_lewiner(gy, 0)[0]
+        v_gy = v_gy0
+        v_gy[:, 0] = (v_gy0[:, 0] * vox_size_x)+geo_data.extent[0]
+        v_gy[:, 1] = (v_gy0[:, 1] * vox_size_y)+geo_data.extent[2]
+        v_gy[:, 2] = (v_gy0[:, 2] * vox_size_z)+geo_data.extent[4]
+        return v_gy
+
+    elif ref == 'mean':
+        # using marching cubes to aquire surfaces (vertices, simplices) that align
+        # with the occurrence of zeros of the gradients (gradient minima)
+        v_gx0 = measure.marching_cubes_lewiner(gx, 0)[0]
+        v_gy0 = measure.marching_cubes_lewiner(gy, 0)[0]
+
+        v_gx = v_gx0
+        v_gx[:, 0] = (v_gx0[:, 0] * vox_size_x) + geo_data.extent[0]
+        v_gx[:, 1] = (v_gx0[:, 1] * vox_size_y) + geo_data.extent[2]
+        v_gx[:, 2] = (v_gx0[:, 2] * vox_size_z) + geo_data.extent[4]
+
+        v_gy = v_gy0
+        v_gy[:, 0] = (v_gy0[:, 0] * vox_size_x) + geo_data.extent[0]
+        v_gy[:, 1] = (v_gy0[:, 1] * vox_size_y) + geo_data.extent[2]
+        v_gy[:, 2] = (v_gy0[:, 2] * vox_size_z) + geo_data.extent[4]
+
+        # calculating this distance takes very long
+        # how cut we possibly simplify this?
+        dist_gxy = distance.cdist(v_gx, v_gy, 'euclidean')
+
+        # get distance minima and minima positions for both vertices groups
+        # this way we can pair 2 vertices from gx and gy based on their
+        # common distance which is to be minimal (smaller than to all other points)
+        minx = np.min(dist_gxy, axis=1)
+        miny = np.min(dist_gxy, axis=0)
+        minx_pos = np.argmin(dist_gxy, axis=1)
+        miny_pos = np.argmin(dist_gxy, axis=0)
+
+        # set a cut-off value for minimal distance (here: 3D-diagonal of a voxel/2)
+        gx_cut_bool = minx < (vox_size_diag/2)
+        gy_cut_bool = miny < (vox_size_diag/2)
+
+        # need to pair the vertices of one group to those of the other
+        # for this we actually only need the minima positions of one vertices group
+        ### pair the mins of the shorter array onto the longer array
+        if len(v_gy) >= len(v_gx):
+            vgy_paired = v_gy[minx_pos]
+            # limit (cut down) the vertices groups to only those
+            # below the defined distance threshold
+            vgx_cut = v_gx[gx_cut_bool]
+            vgy_cut = vgy_paired[gx_cut_bool]
+
+            V1 = vgx_cut
+            V2 = vgy_cut
+            V_mean = (V1 + V2) / 2
+        else:
+            vgx_paired = v_gx[miny_pos]
+            vgy_cut = v_gy[gy_cut_bool]
+            vgx_cut = vgx_paired[gy_cut_bool]
+
+            V1 = vgx_cut
+            V2 = vgy_cut
+            V_mean = (V1 + V2) / 2
+
+        return V_mean
+    else:
+        raise AttributeError(str(ref) + "must be 'x', 'y' or 'mean'")
+
+def get_gradmin_intersect(geo_data, surface_vertices, grad_minima):
+    """
+        Compute the intersection between gradient minima and a surface of
+        interest as vertices.
+
+        Args:
+            geo_data (:class:`gempy.data_management.InputData`)
+            surface_vertices (ndarray): Vertices of the surface of interest.
+            grad_minima (ndarray): Vertices of the gradient minima surface.
+
+        Returns:
+            intersection vertices (ndarray)
+
+
+        """
+    vox_size_x = np.abs(geo_data.extent[1] - geo_data.extent[0]) / geo_data.resolution[0]
+    vox_size_y = np.abs(geo_data.extent[3] - geo_data.extent[2]) / geo_data.resolution[1]
+    vox_size_z = np.abs(geo_data.extent[5] - geo_data.extent[4]) / geo_data.resolution[2]
+    vox_size_diag = np.sqrt(vox_size_x ** 2 + vox_size_y ** 2 + vox_size_z ** 2)
+
+    #v_l = np.array(surface_vertices[0])
+    v_l = np.array(surface_vertices)
+    l_dist = distance.cdist(grad_minima, v_l)
+    min_dist = np.min(l_dist, axis=0)
+    l_cut_bool = min_dist < (vox_size_diag/2)
+    intersect = v_l[l_cut_bool]
+    return intersect
+
+def get_voxel_extrema(GX, GY, GZ=np.nan, direction='z'):
+    """
+        Detects gradient extrema in voxels and classifies them as
+        minima, maxima or saddle point based on changes in sign of the
+        gradient.
+
+        Args:
+            GX (ndarray): Gradient field in x-direction.
+            GY (ndarray): Gradient field in y-direction.
+            GZ (ndarray, optional): Gradient field in z-direction. Only needed if
+                minima are relative to a different direction than 'z'.
+            direction (str, optional, default = 'z'): Direction to which the gradients refer to,
+                and to which the minima are related.
+                Default for standard topography is 'z'.
+
+        Returns:
+            All extrema are returned as 'True' or '1' in
+            boolean arrays accordingly.
+
+            [0]: minima voxels (ndarray)
+            [1]: maxima voxels (ndarray)
+            [2]: saddle voxels (ndarray)
+        """
+    if direction == 'z':
+        gx = GX
+        gy = GY
+    elif direction == 'y':
+        gx = GY
+        gy = GZ
+    elif direction == 'x':
+        gx = GZ
+        gy = GY
+    else:
+        raise AttributeError(str(direction) + "must be a cartesian direction, i.e. xyz")
+
+    # getting array with gradient signs (-1 for negative, 1 for positive and exactly 0)
+    gx_signs = np.sign(gx)
+    gy_signs = np.sign(gy)
+    # empty holder arrays for inserting minima and maxima
+    gx_maxima = np.zeros_like(gx)
+    gy_maxima = np.zeros_like(gy)
+    gx_minima = np.zeros_like(gx)
+    gy_minima = np.zeros_like(gy)
+
+    # create boolean arrays where signchange voxels are True
+    signchange_gx = ((np.roll(gx_signs, 1, axis=0) - gx_signs) != 0).astype(int)
+    # avoid border error from np.roll by setting relevant border to False
+    signchange_gx[0, :, :] = 0
+
+    signchange_gy = ((np.roll(gy_signs, 1, axis=1) - gy_signs) != 0).astype(int)
+    signchange_gy[:, 0] = 0
+
+    # conditions for a voxel to be recognized as maximum or minimum in given direction
+    gx_max_cond = (signchange_gx == 1) & (gx_signs == 1)
+    gy_max_cond = (signchange_gy == 1) & (gy_signs == 1)
+    gx_min_cond = (signchange_gx == 1) & (gx_signs == -1)
+    gy_min_cond = (signchange_gy == 1) & (gy_signs == -1)
+    # voxels which meet the conditions are marked as True
+    # for maxima and minima accordingly
+    # since signchange only identifies the next index AFTER the signchange,
+    # we include the voxel BEFORE the signchange by doing an according roll
+    gx_maxima[gx_max_cond] = 1
+    gx_maxima2 = np.roll(gx_maxima, -1, axis=0)
+    gx_max_final = gx_maxima + gx_maxima2
+    gy_maxima[gy_max_cond] = 1
+    gy_maxima2 = np.roll(gy_maxima, -1, axis=1)
+    gy_max_final = gy_maxima + gy_maxima2
+    # overall maxima in BOTH directions:
+    vox_maxima = np.logical_and(gx_max_final, gy_max_final)
+    # NOTE: 0 gives a POSITIVE sign! Might have to correct for this?
+    # analogous process for minima:
+    gx_minima[gx_min_cond] = 1
+    gx_minima2 = np.roll(gx_minima, -1, axis=0)
+    gx_min_final = gx_minima + gx_minima2
+    gy_minima[gy_min_cond] = 1
+    gy_minima2 = np.roll(gy_minima, -1, axis=1)
+    gy_min_final = gy_minima + gy_minima2
+    vox_minima = np.logical_and(gx_min_final, gy_min_final)
+    # saddle points as max in one and min in the other direction
+    vox_saddles = np.logical_or(np.logical_and(gx_min_final, gy_max_final),
+                                np.logical_and(gy_min_final, gx_max_final))
+
+    return vox_minima, vox_maxima, vox_saddles
+
+def get_surface_extrema(geo_data, surface_vertices, GX, GY, ref='x'):
+    """
+        Compute possible extrema (minima, maxima and saddle points)
+        for a surface of interest.
+        This works for standard non-extreme topographies,
+        but does not consider the presence of df.
+
+        Note: This will currently return various points and also
+        several points for one extrema. To attain single points,
+        further distinction and selection is required.
+
+        Args:
+            geo_data (:class:`gempy.data_management.InputData`)
+            GX (ndarray): Gradient field in x-direction.
+            GY (ndarray): Gradient field in y-direction.
+            surface_vertices (ndarray): Vertices of the surface of interest.
+            ref (str, optional, default='x'): Reference direction for
+                marching cubes to attain vertices. Default is 'x'.
+                'x' or 'y' should suffice and lead to the same results
+                in most cases.
+                If needed, ref can be defined as the 'mean' of both,
+                but this comes at high computational costs and is
+                not recommended in most cases.
+
+        Returns:
+            3D coordinates for possible extrema.
+
+            [0]: minima coordinates (ndarray)
+            [1]: maxima coordinates (ndarray)
+            [2]: saddle coordinates (ndarray)
+        """
+    vox_size_x = np.abs(geo_data.extent[1] - geo_data.extent[0]) / geo_data.resolution[0]
+    vox_size_y = np.abs(geo_data.extent[3] - geo_data.extent[2]) / geo_data.resolution[1]
+    vox_size_z = np.abs(geo_data.extent[5] - geo_data.extent[4]) / geo_data.resolution[2]
+    vox_size_diag = np.sqrt(vox_size_x ** 2 + vox_size_y ** 2 + vox_size_z ** 2)
+
+    grad_minima = get_gradient_minima(geo_data, GX,GY, ref)
+    intersect = get_gradmin_intersect(geo_data, surface_vertices, grad_minima)
+    vox_minima, vox_maxima, vox_saddles = get_voxel_extrema(GX, GY)
+
+    if np.any(vox_minima):
+        # get the coordinates for minima, maxima and saddles
+        MIN_coord0 = np.argwhere(vox_minima == True)
+        # rescale the coordinates to actual size of voxels
+        # to use combined with the intersection coordinates from above
+        MIN_coord = MIN_coord0
+        MIN_coord[:, 0] = (MIN_coord0[:, 0] * vox_size_x) + geo_data.extent[0] # + vox_size_x/2
+        MIN_coord[:, 1] = (MIN_coord0[:, 1] * vox_size_y) + geo_data.extent[2] # + vox_size_y/2
+        MIN_coord[:, 2] = (MIN_coord0[:, 2] * vox_size_z) + geo_data.extent[4] # + vox_size_z/2
+        # get distances between intersection and the according extrema coordinates
+        dist_MIN = distance.cdist(intersect, MIN_coord, 'euclidean')
+        # classify intersection extrema by limiting to distance to according voxel coordinates
+        # half a voxel-diagonal to get what is "inside" a voxel (best results, yet)
+        min_dist_MIN = np.min(dist_MIN, axis=1)
+        cut_bool_MIN = min_dist_MIN < (vox_size_diag / 2)
+        intersect_minima_all = intersect[cut_bool_MIN]
+    else:
+        print('No minima found for surface.')
+        intersect_minima_all = []
+
+    if np.any(vox_maxima):
+        MAX_coord0 = np.argwhere(vox_maxima == True)
+        MAX_coord = MAX_coord0
+        MAX_coord[:, 0] = (MAX_coord0[:, 0] * vox_size_x) + geo_data.extent[0] # + vox_size_x/2
+        MAX_coord[:, 1] = (MAX_coord0[:, 1] * vox_size_y) + geo_data.extent[2] # + vox_size_y/2
+        MAX_coord[:, 2] = (MAX_coord0[:, 2] * vox_size_z) + geo_data.extent[4] # + vox_size_z/2
+        dist_MAX = distance.cdist(intersect, MAX_coord, 'euclidean')
+        min_dist_MAX = np.min(dist_MAX, axis=1)
+        cut_bool_MAX = min_dist_MAX < (vox_size_diag / 2)
+        intersect_maxima_all = intersect[cut_bool_MAX]
+    else:
+        print('No maxima found for surface.')
+        intersect_maxima_all = []
+
+    if np.any(vox_saddles):
+        SADD_coord0 = np.argwhere(vox_saddles == True)
+        SADD_coord = SADD_coord0
+        SADD_coord[:, 0] = (SADD_coord0[:, 0] * vox_size_x) + geo_data.extent[0] # + vox_size_x/2
+        SADD_coord[:, 1] = (SADD_coord0[:, 1] * vox_size_y) + geo_data.extent[2] # + vox_size_y/2
+        SADD_coord[:, 2] = (SADD_coord0[:, 2] * vox_size_z) + geo_data.extent[4] # + vox_size_z/2
+        dist_SADD = distance.cdist(intersect, SADD_coord, 'euclidean')
+        min_dist_SADD = np.min(dist_SADD, axis=1)
+        cut_bool_SADD = min_dist_SADD < (vox_size_diag / 2)
+        intersect_saddles_all = intersect[cut_bool_SADD]
+    else:
+        print('No saddle points found for surface.')
+        intersect_saddles_all = []
+
+    return intersect_minima_all, intersect_maxima_all, intersect_saddles_all
+
+def get_highest_saddle_point(geo_data, surface_vertices, GX, GY, ref='x'):
+    """
+        Compute the maximum saddle point for a surface of interest.
+        Useful for simple models with only on main structure.
+
+        Args:
+            geo_data (:class:`gempy.data_management.InputData`)
+            surface_vertices (ndarray): Vertices of the surface of interest.
+            GX (ndarray): Gradient field in x-direction.
+            GY (ndarray): Gradient field in y-direction.
+            ref (str, optional, default='x'): Reference direction for
+                marching cubes to attain vertices. Default is 'x'.
+                'x' or 'y' should suffice and lead to the same results
+                in most cases.
+                If needed, ref can be defined as the 'mean' of both,
+                but this comes at high computational costs and is
+                not recommended in most cases.
+
+        Returns:
+            3D coordinates for the highest saddle point (ndarray).
+        """
+    intersect_saddles_all = get_surface_extrema(geo_data, surface_vertices, GX, GY, ref)[2]
+    if len(intersect_saddles_all) > 0:
+        max_SADD = intersect_saddles_all[np.argmax(intersect_saddles_all[:, 2])]
+    else:
+        max_SADD = []
+    return max_SADD
+
+def get_highest_max(geo_data, surface_vertices, GX, GY, ref='x'):
+    """
+        Compute the highest maximum for a surface of interest.
+        Useful for simple models with only on main structure.
+
+        Args:
+            geo_data (:class:`gempy.data_management.InputData`)
+            surface_vertices (ndarray): Vertices of the surface of interest.
+            GX (ndarray): Gradient field in x-direction.
+            GY (ndarray): Gradient field in y-direction.
+            ref (str, optional, default='x'): Reference direction for
+                marching cubes to attain vertices. Default is 'x'.
+                'x' or 'y' should suffice and lead to the same results
+                in most cases.
+                If needed, ref can be defined as the 'mean' of both,
+                but this comes at high computational costs and is
+                not recommended in most cases.
+
+        Returns:
+            3D coordinates for the highest maximum (ndarray).
+        """
+    intersect_maxima_all = get_surface_extrema(geo_data, surface_vertices, GX, GY, ref)[1]
+    if len(intersect_maxima_all) > 0:
+        it_final_MAX = intersect_maxima_all[np.argmax(intersect_maxima_all[:, 2])]
+    else:
+        it_final_MAX = []
+    return it_final_MAX
+
+def plot_surface_extrema(geo_data, surface_vertices, GX, GY, ref='x'):
+    """
+        Plot the surface of interest and detected extrema (blue= minima,
+        red = maxima, violet = saddle points).
+
+        Args:
+            geo_data (:class:`gempy.data_management.InputData`)
+            surface_vertices (ndarray): Vertices of the surface of interest.
+            GX (ndarray): Gradient field in x-direction.
+            GY (ndarray): Gradient field in y-direction.
+            ref (str, optional, default='x'): Reference direction for
+                marching cubes to attain vertices. Default is 'x'.
+                'x' or 'y' should suffice and lead to the same results
+                in most cases.
+                If needed, ref can be defined as the 'mean' of both,
+                but this comes at high computational costs and is
+                not recommended in most cases.
+
+        """
+    intersect_minima_all, intersect_maxima_all, intersect_saddles_all \
+        = get_surface_extrema(geo_data, surface_vertices, GX, GY, ref)
+    v_l = surface_vertices
+    fig = plt.figure()
+    ax = fig.add_subplot(111, projection='3d')
+    ax.scatter(v_l[:, 0], v_l[:, 1], v_l[:, 2], color='k', alpha=0.2)
+    #ax.scatter(gradmin[:, 0], gradmin[:, 1], gradmin[:, 2], color='k', alpha=0.2)
+    #ax.scatter(intersect[:, 0], intersect[:, 1], intersect[:, 2], color='b')
+    if len(intersect_minima_all) > 0:
+        ax.scatter(intersect_minima_all[:, 0], intersect_minima_all[:, 1], intersect_minima_all[:, 2], \
+                   color='blue',s=200, marker='o')
+    if len(intersect_maxima_all) > 0:
+        ax.scatter(intersect_maxima_all[:,0],intersect_maxima_all[:,1],intersect_maxima_all[:,2],\
+                   color='r', s=200, marker='o')
+    if len(intersect_saddles_all) > 0:
+        ax.scatter(intersect_saddles_all[:, 0], intersect_saddles_all[:, 1], intersect_saddles_all[:, 2], \
+                   color='violet',s=200, marker='o')
+
+    ax.set_xlim(geo_data.extent[0], geo_data.extent[1])
+    ax.set_ylim(geo_data.extent[2], geo_data.extent[3])
+    ax.set_zlim(geo_data.extent[4], geo_data.extent[5])
+    ax.set_xlabel('X [m]')
+    ax.set_ylabel('Y [m]')
+    ax.set_zlabel('Depth [m]')
     plt.show()
```

### Comparing `gempy-2.2b10.dev1/gempy/assets/topology.py` & `gempy-2.3.0/gempy/assets/topology.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,663 +1,675 @@
-"""
-    This file is part of gempy.
-
-    gempy is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    gempy is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
-
-
-@author: Alexander Schaaf
-"""
-import numpy as np
-from typing import List, Set, Tuple, Dict, Union, Optional
-import matplotlib.pyplot as plt
-
-
-def _get_nunconf(geo_model) -> int:
-    return np.count_nonzero(
-        geo_model._stack.df.BottomRelation == "Erosion"
-    ) - 2  # TODO -2 n other lith series
-
-
-def _get_nfaults(geo_model) -> int:
-    return np.count_nonzero(geo_model._faults.df.isFault)
-
-
-def _get_fb(geo_model) -> np.ndarray:
-    n_unconf = _get_nunconf(geo_model)
-    n_faults = _get_nfaults(geo_model)
-    return np.round(
-        geo_model.solutions.block_matrix[n_unconf:n_faults + n_unconf, 0, :]
-    ).astype(int).sum(axis=0).reshape(*geo_model._grid.regular_grid.resolution)
-
-
-def _get_lb(geo_model) -> np.ndarray:
-    return np.round(
-        geo_model.solutions.lith_block
-    ).astype(int).reshape(*geo_model._grid.regular_grid.resolution)
-
-
-def compute_topology(
-        geo_model,
-        cell_number: int = None,
-        direction: str = None,
-        n_shift: int = 1,
-        voxel_threshold: int = 1
-):
-    res = geo_model._grid.regular_grid.resolution
-    fb = _get_fb(geo_model)
-    lb = _get_lb(geo_model)
-    n_lith = len(np.unique(lb))  # ? quicker looking it up in geomodel?
-
-    if cell_number is None or direction is None:
-        direction = "None"
-    elif direction.capitalize() == "X":
-        lb = lb[cell_number, :, :]
-        fb = fb[cell_number, :, :]
-        res = (1, res[1], res[2])
-    elif direction.capitalize() == "Y":
-        lb = lb[:, cell_number, :]
-        fb = fb[:, cell_number, :]
-        res = (res[0], 1, res[2])
-    elif direction.capitalize() == "Z":
-        lb = lb[:, :, cell_number]
-        fb = fb[:, :, cell_number]
-        res = (res[0], res[1], 1)
-
-    edges, centroids = _analyze_topology(
-        fb.ravel(),
-        lb.ravel(),
-        n_lith,
-        res,
-        n_shift,
-        voxel_threshold,
-        direction
-    )
-
-    edges = set((n1, n2) for n1, n2 in edges)
-    edges = _filter_reverse_edges(edges)  # ? still necessary? would next line
-    # ? not be enough?
-    edges = _sort_edge_tuple_nodes(edges)
-    return edges, centroids
-
-
-def _filter_reverse_edges(edges: Set[Tuple[int, int]]) -> Set[Tuple[int, int]]:
-    """Filter reversed topology edge tuples to fix doubling of topology edges
-    like (1,5) (5,1).
-    
-    Source:
-        https://stackoverflow.com/a/9922322/8040299
-
-    Args:
-        edges (Set[Tuple[int, int]]): Set of topologyedge tuples.
-    
-    Returns:
-        Set[Tuple[int, int]]: Filtered set of topology edge tuples
-    """
-
-    edges_unique = set()
-    for e in edges:
-        if not (e in edges_unique or (e[1], e[0]) in edges_unique):
-            edges_unique.add(e)
-    return edges_unique
-
-
-def _sort_edge_tuple_nodes(edges: Set[Tuple[int, int]]) -> Set[Tuple[int, int]]:
-    """Sort nodes within edge tuples by ascending order.
-    
-    Args:
-        edges (Set[Tuple[int, int]]): Set of edge tuples.
-    
-    Returns:
-        Set[Tuple[int, int]]: Set of sorted edge tuples.
-    """
-    sorted_edges = set()
-    for n1, n2 in edges:
-        if n1 > n2:
-            sorted_edges.add((int(n2), int(n1)))
-        else:
-            sorted_edges.add((int(n1), int(n2)))
-    return sorted_edges
-
-
-def _analyze_topology(
-        fault_matrix_sum,
-        lith_matrix,
-        n_lith,
-        res,
-        n_shift,
-        voxel_threshold,
-        direction
-):
-    fault_shift = fault_matrix_sum.min()
-    fault_matrix_sum_shift = fault_matrix_sum - fault_shift
-
-    where = np.tile(lith_matrix, (n_lith, 1)) == np.unique(lith_matrix).reshape(
-        -1, 1)
-    lith_matrix_shift = np.sum(where * np.arange(n_lith).reshape(-1, 1),
-                               axis=0) + 1
-
-    topo_matrix = lith_matrix_shift + n_lith * fault_matrix_sum_shift
-    topo_matrix_3D = topo_matrix.reshape(*res)
-
-    # x direction
-    if direction.capitalize() != "X":
-        x_l = topo_matrix_3D[n_shift:, :, :]
-        x_r = topo_matrix_3D[:-n_shift, :, :]
-        x_edges, x_count = _get_edges(x_l, x_r)
-        x_edges = x_edges[:, x_count > voxel_threshold]
-    else:
-        x_edges = np.array([[], []])
-
-    # y direction
-    if direction.capitalize() != "Y":
-        y_l = topo_matrix_3D[:, n_shift:, :]
-        y_r = topo_matrix_3D[:, :-n_shift, :]
-        y_edges, y_count = _get_edges(y_l, y_r)
-        y_edges = y_edges[:, y_count > voxel_threshold]
-    else:
-        y_edges = np.array([[], []])
-
-    # z direction
-    if direction.capitalize() != "Z":
-        z_l = topo_matrix_3D[:, :, n_shift:]
-        z_r = topo_matrix_3D[:, :, :-n_shift]
-        z_edges, z_count = _get_edges(z_l, z_r)
-        z_edges = z_edges[:, z_count > voxel_threshold]
-    else:
-        z_edges = np.array([[], []])
-
-    edges = np.unique(
-        np.concatenate((x_edges.T, y_edges.T, z_edges.T), axis=0), axis=0
-    )
-
-    centroids = _get_centroids(topo_matrix_3D)
-
-    return edges, centroids
-
-
-def get_lot_node_to_lith_id(
-        geo_model,
-        centroids: Dict[int, np.ndarray]
-) -> Dict[int, int]:
-    """Get look-up table to translate topology node id's back into GemPy lith
-    id's.
-    
-    Args:
-        geo_model: GemPy geomodel instance with solutions.
-        centroids (Dict[int, Array[float, 3]]): Topology node centroids.
-    
-    Returns:
-        Dict[int, int]: Look-up table translating node id -> lith id.
-    """
-    lb = geo_model.solutions.lith_block.reshape(
-        geo_model._grid.regular_grid.resolution
-    ).astype(int)
-
-    lot = {}
-    for node, pos in centroids.items():
-        p = np.round(pos).astype(int)
-        lith_id = lb[p[0], p[1], p[2]]
-        lot[node] = lith_id
-    return lot
-
-
-def get_lot_lith_to_node_id(
-        lot: Dict[int, np.ndarray]
-) -> Dict[int, List[int]]:
-    """Get look-up table to translate lith id's back into topology node
-    id's.
-    
-    Args:
-        lot (Dict[int, Array[float, 3]]): Node to lith id look-up table. Can be
-        computed using the function 'get_lot_node_to_lith_id'.
-    
-    Returns:
-        Dict[int, List[int]]: Look-up table.
-    """
-    lot2 = {}
-    for k, v in lot.items():
-        if v not in lot2.keys():
-            lot2[v] = [k]
-        else:
-            lot2[v].append(k)
-    return lot2
-
-
-def get_lot_node_to_fault_block(
-        geo_model,
-        centroids: Dict[int, np.ndarray]
-) -> Dict[int, int]:
-    """Get a look-up table to access fault block id's for each topology node
-    id.
-    
-    Args:
-        geo_model: Geomodel instance.
-        centroids (Dict[int, Array[float, 3]]): Geomodel topology centroids.
-    
-    Returns:
-        Dict[int, int]: Look-up table.
-    """
-    n_lith = len(get_lith_ids(geo_model))
-    lot = {}
-    for node, _ in centroids.items():
-        lot[node] = (node - 0 - (node // n_lith)) // n_lith
-    return lot
-
-
-def get_fault_ids(geo_model) -> List[int]:
-    """Get fault id's of all faults in given geomodel.
-    
-    Args:
-        geo_model: Geomodel instance
-    
-    Returns:
-        List[int]: List of fault id's.
-    """
-    f_series_names = geo_model._faults.df[geo_model._faults.df.isFault].index
-    fault_ids = [0]
-    for fsn in f_series_names:
-        fid = geo_model._surfaces.df[
-                geo_model._surfaces.df.series == fsn].id.values[0]
-        fault_ids.append(fid)
-    return fault_ids
-
-
-def get_lith_ids(geo_model, basement: bool = True) -> List[int]:
-    """ Get lithology id's of all lithologies (except basement) in given
-     geomodel.
-    
-    Args:
-        geo_model: Geomodel instance.
-    
-    Returns:
-        List[int]: List of lithology id's.
-    """
-    fmt_series_names = geo_model._faults.df[~geo_model._faults.df.isFault].index
-    lith_ids = []
-    for fsn in fmt_series_names:
-        if not basement:
-            if fsn == "Basement":
-                continue
-        lids = geo_model._surfaces.df[
-            geo_model._surfaces.df.series == fsn].id.values
-        for lid in lids:
-            lith_ids.append(lid)
-    return lith_ids
-
-
-def get_detailed_labels(
-        geo_model,
-        edges: Set[Tuple[int, int]],
-        centroids: Dict[int, np.ndarray]
-) -> Tuple[Set[Tuple[str, str]], Dict[str, np.ndarray]]:
-    """Convert given edges and centroids data into more detailed labels with
-     pattern 'lithid_faultid'.
-    
-    Args:
-        geo_model: [description]
-        edges (Set[Tuple[int, int]]): Set of geomodel topology edges.
-        centroids (Dict[int, Array[float, 3]]): Geomodel topology centroids.
-    
-    Returns:
-        Tuple[Set[Tuple[str, str]], Dict[str, Array[float, 3]]]: Re-labeled
-            edges and centroids.
-    """
-    lot_lith = get_lot_node_to_lith_id(geo_model, centroids)
-    lot_fault = get_lot_node_to_fault_block(geo_model, centroids)
-
-    centroids_ = {}
-    for node, pos in centroids.items():
-        n = lot_lith.get(node), lot_fault.get(node)
-        n = str(n[0]) + "_" + str(n[1])
-        centroids_[n] = pos
-
-    edges_ = set()
-    for n1, n2 in edges:
-        edges_.add(
-            (
-                str(lot_lith.get(n1)) + "_" + str(lot_fault.get(n1)),
-                str(lot_lith.get(n2)) + "_" + str(lot_fault.get(n2))
-            )
-        )
-    return edges_, centroids_
-
-
-def _get_edges(
-        l: np.ndarray,
-        r: np.ndarray
-) -> Optional[np.ndarray]:
-    """Get edges from given shifted arrays.
-
-    Args:
-        l (Array): Topology labels array shifted to one direction.
-        r (Array): Topology labels array shifted to the other direction.
-
-    Returns:
-        Array: Topology edges.
-    """
-    shift = np.stack([l.ravel(), r.ravel()])
-    i1, i2 = np.nonzero(np.diff(shift, axis=0))
-    if len(i2) == 0:  # in case not edges are found (symmetric model along axis)
-        return np.array([[], []]), np.array([])
-    else:
-        return np.unique(shift[:, i2], axis=1, return_counts=True)
-
-
-def clean_unconformity_topology(
-        geo_model,
-        unconf_lith_id: int,
-        edges: np.ndarray,
-        centroids: Dict[int, np.ndarray]
-) -> Tuple[Set[Tuple[int, int]], Dict[int, np.ndarray]]:
-    """Clean unconformity topology edges and centroids. Needs to be run for
-    each unconformity separately.
-    
-    Args:
-        geo_model ([type]): [description]
-        unconf_lith_id (int): [description]
-        edges (Array[int, ..., 2]): [description]
-        centroids (Dict[int, Array[int, ..., 3]]): [description]
-    
-    Returns:
-        Tuple[Set[Tuple[int, int]], Dict[int, Array[int, ..., 3]]]: [description]
-    """
-    lot = get_lot_node_to_lith_id(geo_model, centroids)
-    lot2 = get_lot_lith_to_node_id(lot)
-    edges_clean = []
-
-    unconf_centroid = np.mean(
-        [centroids[i] for i in lot2[unconf_lith_id]], axis=0
-    )
-    for node_id in lot2[unconf_lith_id]:
-        centroids.pop(node_id)
-    centroids[lot2[unconf_lith_id][0]] = unconf_centroid
-
-    for n1, n2 in edges:
-        if n1 in lot2[unconf_lith_id]:
-            n1 = lot2[unconf_lith_id][0]
-        if n2 in lot2[unconf_lith_id]:
-            n2 = lot2[unconf_lith_id][0]
-        if n1 == n2:
-            continue
-        edges_clean.append((n1, n2))
-
-    return set(edges_clean), centroids
-
-
-def jaccard_index(
-        edges1: Set[Tuple[int, int]],
-        edges2: Set[Tuple[int, int]]
-) -> float:
-    """Jaccard index.
-    
-    Args:
-        edges1 (Set[Tuple[int, int]]): Set of topology edges.
-        edges2 (Set[Tuple[int, int]]): Set of topology edges.
-    
-    Returns:
-        float: Jaccard index.
-    """
-    intersection_cardinality = len(edges1.intersection(edges2))
-    union_cardinality = len(edges1.union(edges2))
-    return intersection_cardinality / union_cardinality
-
-
-def _get_centroids(labels: np.ndarray) -> dict:
-    """Get geobody node centroids in array coordinates.
-    
-    Args:
-        labels (Array[int, ..., ..., ...]): Uniquely labeled block.
-    
-    Returns:
-        dict: Geobody node keys yield centroid coordinate tuples in array
-            coordinates.
-    """
-    node_locs = []
-    ulabels = np.unique(labels)
-    for node in ulabels:
-        node_pos = np.argwhere(labels == node)
-        node_locs.append(node_pos.mean(axis=0))
-    centroids = {n: loc for n, loc in zip(ulabels, node_locs)}
-    # for k, v in centroids.items():
-    # debug(f"{k}: {v}")
-    return centroids
-
-
-def get_adjacency_matrix(
-        geo_model,
-        edges: Set[Tuple[int, int]],
-        centroids,
-) -> np.ndarray:
-    """[summary]
-    
-    Args:
-        geo_model ([type]): [description]
-        edges (Set[Tuple): [description]
-    
-    Returns:
-        Array[bool, ..., ...]: [description]
-    """
-    f_ids = get_fault_ids(geo_model)
-    lith_ids = get_lith_ids(geo_model)
-    n = len([(l, f) for f in f_ids for l in lith_ids])
-
-    M = np.zeros((n, n))
-    lith_lot = get_lot_node_to_lith_id(geo_model, centroids)
-    fault_lot = get_lot_node_to_fault_block(geo_model, centroids)
-    for e1, e2 in edges:
-        #     print("nodes:", e1, e2)
-        l1, l2 = lith_lot.get(e1), lith_lot.get(e2)
-        #     print("lith: ", l1, l2)
-        f1, f2 = fault_lot.get(e1), fault_lot.get(e2)
-        #     print("fault:", f1, f2)
-        lp1 = np.argwhere(lith_ids == l1)[0, 0]
-        lp2 = np.argwhere(lith_ids == l2)[0, 0]
-        #     print("lpos :", lp1, lp2)
-        p1 = lp1 + len(lith_ids) * f1
-        p2 = lp2 + len(lith_ids) * f2
-        #     print("pos  :", p1, p2)
-        M[p1, p2] = 1
-        M[p2, p1] = 1
-
-    M = np.flip(np.flip(M, axis=1), axis=0)
-    return M.astype(bool)
-
-
-def _get_adj_matrix_labels(geo_model):
-    f_ids = get_fault_ids(geo_model)
-    lith_ids = get_lith_ids(geo_model)
-    adj_matrix_labels = [(l, f) for f in f_ids for l in lith_ids]
-    adj_matrix_lith_labels = [l for f in f_ids for l in lith_ids]
-    adj_matrix_fault_labels = [f for f in f_ids for l in lith_ids]
-    return adj_matrix_labels, adj_matrix_lith_labels, adj_matrix_fault_labels
-
-
-def plot_adjacency_matrix(
-        geo_model,
-        adj_matrix: np.ndarray
-):
-    """
-
-    Args:
-        geo_model:
-        adj_matrix: Array[bool, ..., ...]
-
-    Returns:
-
-    """
-    f_ids = get_fault_ids(geo_model)
-    n_faults = len(f_ids) // 2
-    lith_ids = get_lith_ids(geo_model)
-    n_liths = len(lith_ids)
-    adj_matrix_labels, adj_matrix_lith_labels, adj_matrix_fault_labels = _get_adj_matrix_labels(
-        geo_model)
-    # ///////////////////////////////////////////////////////
-    n = len(adj_matrix_labels)
-    fig, ax = plt.subplots(figsize=(n // 2.5, n // 2.5))
-
-    ax.imshow(adj_matrix, cmap="Greys", alpha=1)
-    ax.set_xlim(-.5, n_liths * n_faults * 2 - 0.5)
-    ax.set_ylim(-.5, n_liths * n_faults * 2 - 0.5)
-
-    ax.set_title("Topology Adjacency Matrix")
-
-    # ///////////////////////////////////////////////////////
-    # lith tick labels
-    ax.set_xticks(np.arange(n))
-    ax.set_yticks(np.arange(n))
-    ax.set_xticklabels(adj_matrix_lith_labels[::1], rotation=0)
-    ax.set_yticklabels(adj_matrix_lith_labels[::1], rotation=0)
-
-    # ///////////////////////////////////////////////////////
-    # lith tick labels colors
-    colors = list(geo_model._surfaces.colors.colordict.values())
-    bboxkwargs = dict(
-        edgecolor='none',
-    )
-    for xticklabel, yticklabel, l in zip(ax.xaxis.get_ticklabels(),
-                                         ax.yaxis.get_ticklabels(),
-                                         adj_matrix_labels[::1]):
-        color = colors[l[0] - 1]
-
-        xticklabel.set_bbox(
-            dict(facecolor=color, **bboxkwargs)
-        )
-        xticklabel.set_color("white")
-
-        yticklabel.set_bbox(
-            dict(facecolor=color, **bboxkwargs)
-        )
-        yticklabel.set_color("white")
-
-    # ///////////////////////////////////////////////////////
-    # fault block tick labeling
-    newax = fig.add_axes(ax.get_position())
-    newax.patch.set_visible(False)
-
-    newax.spines['bottom'].set_position(('outward', 29))
-    newax.set_xlim(0, n_faults * 2)
-
-    newax.set_xticks(np.arange(1, n_faults * 2 + 1) - 0.5)
-    newax.set_xticklabels(["FB " + str(i + 1) for i in range(n_faults * 2)])
-
-    newax.spines['left'].set_position(('outward', 25))
-    newax.set_ylim(0, n_faults * 2)
-    newax.set_yticks(np.arange(1, n_faults * 2 + 1) - 0.5)
-    newax.set_yticklabels(
-        ["FB " + str(i + 1) for i in range(n_faults * 2)][::1])
-
-    # ///////////////////////////////////////////////////////
-    # (dotted) lines for fb's
-    dlinekwargs = dict(
-        color="black",
-        linestyle="dashed",
-        alpha=0.75,
-        linewidth=1
-    )
-    linekwargs = dict(
-        color="black",
-        linewidth=1
-    )
-    for i in range(0, n_faults * 2 + 1):
-        pos = i * n_liths - .5
-
-        if i != 0 and i != n_faults * 2:
-            ax.axvline(pos, **dlinekwargs)
-            ax.axhline(pos, **dlinekwargs)
-
-        # solid spines outside to separate fbs
-        line = ax.plot((-3.3, -.51), (pos, pos), **linekwargs)
-        line[0].set_clip_on(False)
-
-        line = ax.plot((pos, pos), (-3, -.51), **linekwargs)
-        line[0].set_clip_on(False)
-    # ///////////////////////////////////////////////////////
-    return
-
-
-def check_adjacency(
-        edges: set,
-        n1: Union[int, str],
-        n2: Union[int, str]
-) -> bool:
-    """Check if given nodes n1 and n2 are adjacent in given topology
-    edge set.
-    
-    Args:
-        edges (set): Topology edges.
-        n1 (Union[int, str]): Node 1 label.
-        n2 (Union[int, str]): Node 2 label
-    
-    Returns:
-        bool: True if adjacent, otherwise False.
-    """
-    if (n1, n2) in edges or (n2, n1) in edges:
-        return True
-    else:
-        return False
-
-
-def get_adjacencies(
-        edges: set,
-        node: Union[int, str]
-) -> set:
-    """Get node labels of all adjacent geobodies of geobody with given node
-     in given set of edges.
-    
-    Args:
-        edges (set): Topology edges.
-        node (Union[int, str]): Node label.
-    
-    Returns:
-        set: All adjacent geobody node labels.
-    """
-    adjacencies = set()
-    for n1, n2 in edges:
-        if node == n1:
-            adjacencies.add(n2)
-        elif node == n2:
-            adjacencies.add(n1)
-    return adjacencies
-
-
-def count_unique_topologies(edges: List[Set[Tuple[int, int]]]):
-    """Count unique topologie graphs in given list of edge sets.
-
-    Args:
-        edges: List of topology edge sets.
-            E.g. [{(0,1), (0,2), ...}, {(0,1), (0,2), ...}]
-
-    Returns:
-        unique edges
-        unique edges count
-        unique edges idx
-    """
-    unique_edges = [edges[0]]
-    unique_edges_count = [1]
-    unqiue_edges_idx = [0]
-    for _, topology in enumerate(edges[1:]):
-        skip = False
-        for b, utopology in enumerate(unique_edges):
-            if utopology == topology:
-                unique_edges_count[b] += 1
-                unqiue_edges_idx.append(b)
-                skip = True
-                break
-        if skip:
-            continue
-        unique_edges.append(topology)
-        unique_edges_count.append(1)
-        unqiue_edges_idx.append(len(unique_edges))
-
-    return unique_edges, np.array(unique_edges_count), np.array(
-        unqiue_edges_idx)
+"""
+    This file is part of gempy.
+
+    gempy is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    gempy is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
+
+
+@author: Alexander Schaaf
+"""
+import numpy as np
+from typing import List, Set, Tuple, Dict, Union, Optional
+import matplotlib.pyplot as plt
+
+
+def _get_nunconf(geo_model) -> int:
+    return np.count_nonzero(
+        geo_model._stack.df.BottomRelation == "Erosion"
+    ) - 2  # TODO -2 n other lith series
+
+
+def _get_nfaults(geo_model) -> int:
+    return np.count_nonzero(geo_model._faults.df.isFault)
+
+
+def _get_fb(geo_model) -> np.ndarray:
+    n_unconf = _get_nunconf(geo_model)
+    n_faults = _get_nfaults(geo_model)
+    return np.round(
+        geo_model.solutions.block_matrix[n_unconf:n_faults + n_unconf, 0, :]
+    ).astype(int).sum(axis=0).reshape(*geo_model._grid.regular_grid.resolution)
+
+
+def _get_lb(geo_model) -> np.ndarray:
+    return np.round(
+        geo_model.solutions.lith_block
+    ).astype(int).reshape(*geo_model._grid.regular_grid.resolution)
+
+
+def compute_topology(
+        geo_model,
+        cell_number: int = None,
+        direction: str = None,
+        n_shift: int = 1,
+        voxel_threshold: int = 1
+):
+    """Compute topology of a GemPy model
+
+    Args:
+        geo_model (Project): GemPy model project
+        cell_number (int, optional): Cell number in chosen direction. Defaults to None.
+        direction (str, optional): one of the model's dimensions, x, y, or z. Defaults to None.
+        n_shift (int, optional): number of voxels the model is shifted and then substracted for finding interfaces. Defaults to 1.
+        voxel_threshold (int, optional): amount of voxels which have to be connected to be considered into the topology calculation. Defaults to 1.
+
+    Returns:
+        edges, centroids [numpy array]: edges and centroids of the topology graph
+    """
+    res = geo_model._grid.regular_grid.resolution
+    fb = _get_fb(geo_model)
+    lb = _get_lb(geo_model)
+    n_lith = len(np.unique(lb))  # ? quicker looking it up in geomodel?
+
+    if cell_number is None or direction is None:
+        direction = "None"
+    elif direction.capitalize() == "X":
+        lb = lb[cell_number, :, :]
+        fb = fb[cell_number, :, :]
+        res = (1, res[1], res[2])
+    elif direction.capitalize() == "Y":
+        lb = lb[:, cell_number, :]
+        fb = fb[:, cell_number, :]
+        res = (res[0], 1, res[2])
+    elif direction.capitalize() == "Z":
+        lb = lb[:, :, cell_number]
+        fb = fb[:, :, cell_number]
+        res = (res[0], res[1], 1)
+
+    edges, centroids = _analyze_topology(
+        fb.ravel(),
+        lb.ravel(),
+        n_lith,
+        res,
+        n_shift,
+        voxel_threshold,
+        direction
+    )
+
+    edges = set((n1, n2) for n1, n2 in edges)
+    edges = _filter_reverse_edges(edges)  # ? still necessary? would next line
+    # ? not be enough?
+    edges = _sort_edge_tuple_nodes(edges)
+    return edges, centroids
+
+
+def _filter_reverse_edges(edges: Set[Tuple[int, int]]) -> Set[Tuple[int, int]]:
+    """Filter reversed topology edge tuples to fix doubling of topology edges
+    like (1,5) (5,1).
+    
+    Source:
+        https://stackoverflow.com/a/9922322/8040299
+
+    Args:
+        edges (Set[Tuple[int, int]]): Set of topologyedge tuples.
+    
+    Returns:
+        Set[Tuple[int, int]]: Filtered set of topology edge tuples
+    """
+
+    edges_unique = set()
+    for e in edges:
+        if not (e in edges_unique or (e[1], e[0]) in edges_unique):
+            edges_unique.add(e)
+    return edges_unique
+
+
+def _sort_edge_tuple_nodes(edges: Set[Tuple[int, int]]) -> Set[Tuple[int, int]]:
+    """Sort nodes within edge tuples by ascending order.
+    
+    Args:
+        edges (Set[Tuple[int, int]]): Set of edge tuples.
+    
+    Returns:
+        Set[Tuple[int, int]]: Set of sorted edge tuples.
+    """
+    sorted_edges = set()
+    for n1, n2 in edges:
+        if n1 > n2:
+            sorted_edges.add((int(n2), int(n1)))
+        else:
+            sorted_edges.add((int(n1), int(n2)))
+    return sorted_edges
+
+
+def _analyze_topology(
+        fault_matrix_sum,
+        lith_matrix,
+        n_lith,
+        res,
+        n_shift,
+        voxel_threshold,
+        direction
+):
+    fault_shift = fault_matrix_sum.min()
+    fault_matrix_sum_shift = fault_matrix_sum - fault_shift
+
+    where = np.tile(lith_matrix, (n_lith, 1)) == np.unique(lith_matrix).reshape(
+        -1, 1)
+    lith_matrix_shift = np.sum(where * np.arange(n_lith).reshape(-1, 1),
+                               axis=0) + 1
+
+    topo_matrix = lith_matrix_shift + n_lith * fault_matrix_sum_shift
+    topo_matrix_3D = topo_matrix.reshape(*res)
+
+    # x direction
+    if direction.capitalize() != "X":
+        x_l = topo_matrix_3D[n_shift:, :, :]
+        x_r = topo_matrix_3D[:-n_shift, :, :]
+        x_edges, x_count = _get_edges(x_l, x_r)
+        x_edges = x_edges[:, x_count > voxel_threshold]
+    else:
+        x_edges = np.array([[], []])
+
+    # y direction
+    if direction.capitalize() != "Y":
+        y_l = topo_matrix_3D[:, n_shift:, :]
+        y_r = topo_matrix_3D[:, :-n_shift, :]
+        y_edges, y_count = _get_edges(y_l, y_r)
+        y_edges = y_edges[:, y_count > voxel_threshold]
+    else:
+        y_edges = np.array([[], []])
+
+    # z direction
+    if direction.capitalize() != "Z":
+        z_l = topo_matrix_3D[:, :, n_shift:]
+        z_r = topo_matrix_3D[:, :, :-n_shift]
+        z_edges, z_count = _get_edges(z_l, z_r)
+        z_edges = z_edges[:, z_count > voxel_threshold]
+    else:
+        z_edges = np.array([[], []])
+
+    edges = np.unique(
+        np.concatenate((x_edges.T, y_edges.T, z_edges.T), axis=0), axis=0
+    )
+
+    centroids = _get_centroids(topo_matrix_3D)
+
+    return edges, centroids
+
+
+def get_lot_node_to_lith_id(
+        geo_model,
+        centroids: Dict[int, np.ndarray]
+) -> Dict[int, int]:
+    """Get look-up table to translate topology node id's back into GemPy lith
+    id's.
+    
+    Args:
+        geo_model: GemPy geomodel instance with solutions.
+        centroids (Dict[int, Array[float, 3]]): Topology node centroids.
+    
+    Returns:
+        Dict[int, int]: Look-up table translating node id -> lith id.
+    """
+    lb = geo_model.solutions.lith_block.reshape(
+        geo_model._grid.regular_grid.resolution
+    ).astype(int)
+
+    lot = {}
+    for node, pos in centroids.items():
+        p = np.round(pos).astype(int)
+        lith_id = lb[p[0], p[1], p[2]]
+        lot[node] = lith_id
+    return lot
+
+
+def get_lot_lith_to_node_id(
+        lot: Dict[int, np.ndarray]
+) -> Dict[int, List[int]]:
+    """Get look-up table to translate lith id's back into topology node
+    id's.
+    
+    Args:
+        lot (Dict[int, Array[float, 3]]): Node to lith id look-up table. Can be
+        computed using the function 'get_lot_node_to_lith_id'.
+    
+    Returns:
+        Dict[int, List[int]]: Look-up table.
+    """
+    lot2 = {}
+    for k, v in lot.items():
+        if v not in lot2.keys():
+            lot2[v] = [k]
+        else:
+            lot2[v].append(k)
+    return lot2
+
+
+def get_lot_node_to_fault_block(
+        geo_model,
+        centroids: Dict[int, np.ndarray]
+) -> Dict[int, int]:
+    """Get a look-up table to access fault block id's for each topology node
+    id.
+    
+    Args:
+        geo_model: Geomodel instance.
+        centroids (Dict[int, Array[float, 3]]): Geomodel topology centroids.
+    
+    Returns:
+        Dict[int, int]: Look-up table.
+    """
+    n_lith = len(get_lith_ids(geo_model))
+    lot = {}
+    for node, _ in centroids.items():
+        lot[node] = (node - 0 - (node // n_lith)) // n_lith
+    return lot
+
+
+def get_fault_ids(geo_model) -> List[int]:
+    """Get fault id's of all faults in given geomodel.
+    
+    Args:
+        geo_model: Geomodel instance
+    
+    Returns:
+        List[int]: List of fault id's.
+    """
+    f_series_names = geo_model._faults.df[geo_model._faults.df.isFault].index
+    fault_ids = [0]
+    for fsn in f_series_names:
+        fid = geo_model._surfaces.df[
+                geo_model._surfaces.df.series == fsn].id.values[0]
+        fault_ids.append(fid)
+    return fault_ids
+
+
+def get_lith_ids(geo_model, basement: bool = True) -> List[int]:
+    """ Get lithology id's of all lithologies (except basement) in given
+     geomodel.
+    
+    Args:
+        geo_model: Geomodel instance.
+    
+    Returns:
+        List[int]: List of lithology id's.
+    """
+    fmt_series_names = geo_model._faults.df[~geo_model._faults.df.isFault].index
+    lith_ids = []
+    for fsn in fmt_series_names:
+        if not basement:
+            if fsn == "Basement":
+                continue
+        lids = geo_model._surfaces.df[
+            geo_model._surfaces.df.series == fsn].id.values
+        for lid in lids:
+            lith_ids.append(lid)
+    return lith_ids
+
+
+def get_detailed_labels(
+        geo_model,
+        edges: Set[Tuple[int, int]],
+        centroids: Dict[int, np.ndarray]
+) -> Tuple[Set[Tuple[str, str]], Dict[str, np.ndarray]]:
+    """Convert given edges and centroids data into more detailed labels with
+     pattern 'lithid_faultid'.
+    
+    Args:
+        geo_model: [description]
+        edges (Set[Tuple[int, int]]): Set of geomodel topology edges.
+        centroids (Dict[int, Array[float, 3]]): Geomodel topology centroids.
+    
+    Returns:
+        Tuple[Set[Tuple[str, str]], Dict[str, Array[float, 3]]]: Re-labeled
+            edges and centroids.
+    """
+    lot_lith = get_lot_node_to_lith_id(geo_model, centroids)
+    lot_fault = get_lot_node_to_fault_block(geo_model, centroids)
+
+    centroids_ = {}
+    for node, pos in centroids.items():
+        n = lot_lith.get(node), lot_fault.get(node)
+        n = str(n[0]) + "_" + str(n[1])
+        centroids_[n] = pos
+
+    edges_ = set()
+    for n1, n2 in edges:
+        edges_.add(
+            (
+                str(lot_lith.get(n1)) + "_" + str(lot_fault.get(n1)),
+                str(lot_lith.get(n2)) + "_" + str(lot_fault.get(n2))
+            )
+        )
+    return edges_, centroids_
+
+
+def _get_edges(
+        l: np.ndarray,
+        r: np.ndarray
+) -> Optional[np.ndarray]:
+    """Get edges from given shifted arrays.
+
+    Args:
+        l (Array): Topology labels array shifted to one direction.
+        r (Array): Topology labels array shifted to the other direction.
+
+    Returns:
+        Array: Topology edges.
+    """
+    shift = np.stack([l.ravel(), r.ravel()])
+    i1, i2 = np.nonzero(np.diff(shift, axis=0))
+    if len(i2) == 0:  # in case not edges are found (symmetric model along axis)
+        return np.array([[], []]), np.array([])
+    else:
+        return np.unique(shift[:, i2], axis=1, return_counts=True)
+
+
+def clean_unconformity_topology(
+        geo_model,
+        unconf_lith_id: int,
+        edges: np.ndarray,
+        centroids: Dict[int, np.ndarray]
+) -> Tuple[Set[Tuple[int, int]], Dict[int, np.ndarray]]:
+    """Clean unconformity topology edges and centroids. Needs to be run for
+    each unconformity separately.
+    
+    Args:
+        geo_model ([type]): [description]
+        unconf_lith_id (int): [description]
+        edges (Array[int, ..., 2]): [description]
+        centroids (Dict[int, Array[int, ..., 3]]): [description]
+    
+    Returns:
+        Tuple[Set[Tuple[int, int]], Dict[int, Array[int, ..., 3]]]: [description]
+    """
+    lot = get_lot_node_to_lith_id(geo_model, centroids)
+    lot2 = get_lot_lith_to_node_id(lot)
+    edges_clean = []
+
+    unconf_centroid = np.mean(
+        [centroids[i] for i in lot2[unconf_lith_id]], axis=0
+    )
+    for node_id in lot2[unconf_lith_id]:
+        centroids.pop(node_id)
+    centroids[lot2[unconf_lith_id][0]] = unconf_centroid
+
+    for n1, n2 in edges:
+        if n1 in lot2[unconf_lith_id]:
+            n1 = lot2[unconf_lith_id][0]
+        if n2 in lot2[unconf_lith_id]:
+            n2 = lot2[unconf_lith_id][0]
+        if n1 == n2:
+            continue
+        edges_clean.append((n1, n2))
+
+    return set(edges_clean), centroids
+
+
+def jaccard_index(
+        edges1: Set[Tuple[int, int]],
+        edges2: Set[Tuple[int, int]]
+) -> float:
+    """Jaccard index.
+    
+    Args:
+        edges1 (Set[Tuple[int, int]]): Set of topology edges.
+        edges2 (Set[Tuple[int, int]]): Set of topology edges.
+    
+    Returns:
+        float: Jaccard index.
+    """
+    intersection_cardinality = len(edges1.intersection(edges2))
+    union_cardinality = len(edges1.union(edges2))
+    return intersection_cardinality / union_cardinality
+
+
+def _get_centroids(labels: np.ndarray) -> dict:
+    """Get geobody node centroids in array coordinates.
+    
+    Args:
+        labels (Array[int, ..., ..., ...]): Uniquely labeled block.
+    
+    Returns:
+        dict: Geobody node keys yield centroid coordinate tuples in array
+            coordinates.
+    """
+    node_locs = []
+    ulabels = np.unique(labels)
+    for node in ulabels:
+        node_pos = np.argwhere(labels == node)
+        node_locs.append(node_pos.mean(axis=0))
+    centroids = {n: loc for n, loc in zip(ulabels, node_locs)}
+    # for k, v in centroids.items():
+    # debug(f"{k}: {v}")
+    return centroids
+
+
+def get_adjacency_matrix(
+        geo_model,
+        edges: Set[Tuple[int, int]],
+        centroids,
+) -> np.ndarray:
+    """[summary]
+    
+    Args:
+        geo_model ([type]): [description]
+        edges (Set[Tuple): [description]
+    
+    Returns:
+        Array[bool, ..., ...]: [description]
+    """
+    f_ids = get_fault_ids(geo_model)
+    lith_ids = get_lith_ids(geo_model)
+    n = len([(l, f) for f in f_ids for l in lith_ids])
+
+    M = np.zeros((n, n))
+    lith_lot = get_lot_node_to_lith_id(geo_model, centroids)
+    fault_lot = get_lot_node_to_fault_block(geo_model, centroids)
+    for e1, e2 in edges:
+        #     print("nodes:", e1, e2)
+        l1, l2 = lith_lot.get(e1), lith_lot.get(e2)
+        #     print("lith: ", l1, l2)
+        f1, f2 = fault_lot.get(e1), fault_lot.get(e2)
+        #     print("fault:", f1, f2)
+        lp1 = np.argwhere(lith_ids == l1)[0, 0]
+        lp2 = np.argwhere(lith_ids == l2)[0, 0]
+        #     print("lpos :", lp1, lp2)
+        p1 = lp1 + len(lith_ids) * f1
+        p2 = lp2 + len(lith_ids) * f2
+        #     print("pos  :", p1, p2)
+        M[p1, p2] = 1
+        M[p2, p1] = 1
+
+    M = np.flip(np.flip(M, axis=1), axis=0)
+    return M.astype(bool)
+
+
+def _get_adj_matrix_labels(geo_model):
+    f_ids = get_fault_ids(geo_model)
+    lith_ids = get_lith_ids(geo_model)
+    adj_matrix_labels = [(l, f) for f in f_ids for l in lith_ids]
+    adj_matrix_lith_labels = [l for f in f_ids for l in lith_ids]
+    adj_matrix_fault_labels = [f for f in f_ids for l in lith_ids]
+    return adj_matrix_labels, adj_matrix_lith_labels, adj_matrix_fault_labels
+
+
+def plot_adjacency_matrix(
+        geo_model,
+        adj_matrix: np.ndarray
+):
+    """
+
+    Args:
+        geo_model:
+        adj_matrix: Array[bool, ..., ...]
+
+    Returns:
+
+    """
+    f_ids = get_fault_ids(geo_model)
+    n_faults = len(f_ids) // 2
+    lith_ids = get_lith_ids(geo_model)
+    n_liths = len(lith_ids)
+    adj_matrix_labels, adj_matrix_lith_labels, adj_matrix_fault_labels = _get_adj_matrix_labels(
+        geo_model)
+    # ///////////////////////////////////////////////////////
+    n = len(adj_matrix_labels)
+    fig, ax = plt.subplots(figsize=(n // 2.5, n // 2.5))
+
+    ax.imshow(adj_matrix, cmap="Greys", alpha=1)
+    ax.set_xlim(-.5, n_liths * n_faults * 2 - 0.5)
+    ax.set_ylim(-.5, n_liths * n_faults * 2 - 0.5)
+
+    ax.set_title("Topology Adjacency Matrix")
+
+    # ///////////////////////////////////////////////////////
+    # lith tick labels
+    ax.set_xticks(np.arange(n))
+    ax.set_yticks(np.arange(n))
+    ax.set_xticklabels(adj_matrix_lith_labels[::1], rotation=0)
+    ax.set_yticklabels(adj_matrix_lith_labels[::1], rotation=0)
+
+    # ///////////////////////////////////////////////////////
+    # lith tick labels colors
+    colors = list(geo_model._surfaces.colors.colordict.values())
+    bboxkwargs = dict(
+        edgecolor='none',
+    )
+    for xticklabel, yticklabel, l in zip(ax.xaxis.get_ticklabels(),
+                                         ax.yaxis.get_ticklabels(),
+                                         adj_matrix_labels[::1]):
+        color = colors[l[0] - 1]
+
+        xticklabel.set_bbox(
+            dict(facecolor=color, **bboxkwargs)
+        )
+        xticklabel.set_color("white")
+
+        yticklabel.set_bbox(
+            dict(facecolor=color, **bboxkwargs)
+        )
+        yticklabel.set_color("white")
+
+    # ///////////////////////////////////////////////////////
+    # fault block tick labeling
+    newax = fig.add_axes(ax.get_position())
+    newax.patch.set_visible(False)
+
+    newax.spines['bottom'].set_position(('outward', 29))
+    newax.set_xlim(0, n_faults * 2)
+
+    newax.set_xticks(np.arange(1, n_faults * 2 + 1) - 0.5)
+    newax.set_xticklabels(["FB " + str(i + 1) for i in range(n_faults * 2)])
+
+    newax.spines['left'].set_position(('outward', 25))
+    newax.set_ylim(0, n_faults * 2)
+    newax.set_yticks(np.arange(1, n_faults * 2 + 1) - 0.5)
+    newax.set_yticklabels(
+        ["FB " + str(i + 1) for i in range(n_faults * 2)][::1])
+
+    # ///////////////////////////////////////////////////////
+    # (dotted) lines for fb's
+    dlinekwargs = dict(
+        color="black",
+        linestyle="dashed",
+        alpha=0.75,
+        linewidth=1
+    )
+    linekwargs = dict(
+        color="black",
+        linewidth=1
+    )
+    for i in range(0, n_faults * 2 + 1):
+        pos = i * n_liths - .5
+
+        if i != 0 and i != n_faults * 2:
+            ax.axvline(pos, **dlinekwargs)
+            ax.axhline(pos, **dlinekwargs)
+
+        # solid spines outside to separate fbs
+        line = ax.plot((-3.3, -.51), (pos, pos), **linekwargs)
+        line[0].set_clip_on(False)
+
+        line = ax.plot((pos, pos), (-3, -.51), **linekwargs)
+        line[0].set_clip_on(False)
+    # ///////////////////////////////////////////////////////
+    return
+
+
+def check_adjacency(
+        edges: set,
+        n1: Union[int, str],
+        n2: Union[int, str]
+) -> bool:
+    """Check if given nodes n1 and n2 are adjacent in given topology
+    edge set.
+    
+    Args:
+        edges (set): Topology edges.
+        n1 (Union[int, str]): Node 1 label.
+        n2 (Union[int, str]): Node 2 label
+    
+    Returns:
+        bool: True if adjacent, otherwise False.
+    """
+    if (n1, n2) in edges or (n2, n1) in edges:
+        return True
+    else:
+        return False
+
+
+def get_adjacencies(
+        edges: set,
+        node: Union[int, str]
+) -> set:
+    """Get node labels of all adjacent geobodies of geobody with given node
+     in given set of edges.
+    
+    Args:
+        edges (set): Topology edges.
+        node (Union[int, str]): Node label.
+    
+    Returns:
+        set: All adjacent geobody node labels.
+    """
+    adjacencies = set()
+    for n1, n2 in edges:
+        if node == n1:
+            adjacencies.add(n2)
+        elif node == n2:
+            adjacencies.add(n1)
+    return adjacencies
+
+
+def count_unique_topologies(edges: List[Set[Tuple[int, int]]]):
+    """Count unique topologie graphs in given list of edge sets.
+
+    Args:
+        edges: List of topology edge sets.
+            E.g. [{(0,1), (0,2), ...}, {(0,1), (0,2), ...}]
+
+    Returns:
+        unique edges
+        unique edges count
+        unique edges idx
+    """
+    unique_edges = [edges[0]]
+    unique_edges_count = [1]
+    unqiue_edges_idx = [0]
+    for _, topology in enumerate(edges[1:]):
+        skip = False
+        for b, utopology in enumerate(unique_edges):
+            if utopology == topology:
+                unique_edges_count[b] += 1
+                unqiue_edges_idx.append(b)
+                skip = True
+                break
+        if skip:
+            continue
+        unique_edges.append(topology)
+        unique_edges_count.append(1)
+        unqiue_edges_idx.append(len(unique_edges))
+
+    return unique_edges, np.array(unique_edges_count), np.array(
+        unqiue_edges_idx)
```

### Comparing `gempy-2.2b10.dev1/gempy/bayesian/axes_utils.py` & `gempy-2.3.0/gempy/bayesian/axes_utils.py`

 * *Ordering differences only*

 * *Files 21% similar despite different names*

```diff
@@ -1,141 +1,141 @@
-try:
-    from pandas.plotting._tools import *
-except:
-    #TODO this is a quick fix for #38
-    from pandas.plotting._matplotlib.tools import *
-
-
-def _subplots(
-    naxes=None,
-    sharex=False,
-    sharey=False,
-    squeeze=True,
-    subplot_kw=None,
-    ax=None,
-    layout=None,
-    layout_type="box",
-    **fig_kw
-):
-    """Create a figure with a set of subplots already made.
-
-    This utility wrapper makes it convenient to create common layouts of
-    subplots, including the enclosing figure object, in a single call.
-
-    Keyword arguments:
-
-    naxes : int
-      Number of required axes. Exceeded axes are set invisible. Default is
-      nrows * ncols.
-
-    sharex : bool
-      If True, the X axis will be shared amongst all subplots.
-
-    sharey : bool
-      If True, the Y axis will be shared amongst all subplots.
-
-    squeeze : bool
-
-      If True, extra dimensions are squeezed out from the returned axis object:
-        - if only one subplot is constructed (nrows=ncols=1), the resulting
-        single Axis object is returned as a scalar.
-        - for Nx1 or 1xN subplots, the returned object is a 1-d numpy object
-        array of Axis objects are returned as numpy 1-d arrays.
-        - for NxM subplots with N>1 and M>1 are returned as a 2d array.
-
-      If False, no squeezing is done: the returned axis object is always
-      a 2-d array containing Axis instances, even if it ends up being 1x1.
-
-    subplot_kw : dict
-      Dict with keywords passed to the add_subplot() call used to create each
-      subplots.
-
-    ax : Matplotlib axis object, optional
-
-    layout : tuple
-      Number of rows and columns of the subplot grid.
-      If not specified, calculated from naxes and layout_type
-
-    layout_type : {'box', 'horizontal', 'vertical'}, default 'box'
-      Specify how to layout the subplot grid.
-
-    fig_kw : Other keyword arguments to be passed to the figure() call.
-        Note that all keywords not recognized above will be
-        automatically included here.
-
-    Returns:
-
-    fig, ax : tuple
-      - fig is the Matplotlib Figure object
-      - ax can be either a single axis object or an array of axis objects if
-      more than one subplot was created.  The dimensions of the resulting array
-      can be controlled with the squeeze keyword, see above.
-
-    **Examples:**
-
-    x = np.linspace(0, 2*np.pi, 400)
-    y = np.sin(x**2)
-
-    # Just a figure and one subplot
-    f, ax = plt.subplots()
-    ax.plot(x, y)
-    ax.set_title('Simple plot')
-
-    # Two subplots, unpack the output array immediately
-    f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)
-    ax1.plot(x, y)
-    ax1.set_title('Sharing Y axis')
-    ax2.scatter(x, y)
-
-    # Four polar axes
-    plt.subplots(2, 2, subplot_kw=dict(polar=True))
-    """
-    import matplotlib.pyplot as plt
-
-    nrows, ncols = _get_layout(naxes, layout=layout, layout_type=layout_type)
-    nplots = nrows * ncols
-
-    # Create empty object array to hold all axes.  It's easiest to make it 1-d
-    # so we can just append subplots upon creation, and then
-    axarr = np.empty(nplots, dtype=object)
-
-    # Create first subplot separately, so we can share it if requested
-    ax0 = fig.add_subplot(nrows, ncols, 1, **subplot_kw)
-
-    if sharex:
-        subplot_kw["sharex"] = ax0
-    if sharey:
-        subplot_kw["sharey"] = ax0
-    axarr[0] = ax0
-
-    # Note off-by-one counting because add_subplot uses the MATLAB 1-based
-    # convention.
-    for i in range(1, nplots):
-        kwds = subplot_kw.copy()
-        # Set sharex and sharey to None for blank/dummy axes, these can
-        # interfere with proper axis limits on the visible axes if
-        # they share axes e.g. issue #7528
-        if i >= naxes:
-            kwds["sharex"] = None
-            kwds["sharey"] = None
-        ax = fig.add_subplot(nrows, ncols, i + 1, **kwds)
-        axarr[i] = ax
-
-    if naxes != nplots:
-        for ax in axarr[naxes:]:
-            ax.set_visible(False)
-
-    _handle_shared_axes(axarr, nplots, naxes, nrows, ncols, sharex, sharey)
-
-    if squeeze:
-        # Reshape the array to have the final desired dimension (nrow,ncol),
-        # though discarding unneeded dimensions that equal 1.  If we only have
-        # one subplot, just return it instead of a 1-element array.
-        if nplots == 1:
-            axes = axarr[0]
-        else:
-            axes = axarr.reshape(nrows, ncols).squeeze()
-    else:
-        # returned axis array will be always 2-d, even if nrows=ncols=1
-        axes = axarr.reshape(nrows, ncols)
-
+try:
+    from pandas.plotting._tools import *
+except:
+    #TODO this is a quick fix for #38
+    from pandas.plotting._matplotlib.tools import *
+
+
+def _subplots(
+    naxes=None,
+    sharex=False,
+    sharey=False,
+    squeeze=True,
+    subplot_kw=None,
+    ax=None,
+    layout=None,
+    layout_type="box",
+    **fig_kw
+):
+    """Create a figure with a set of subplots already made.
+
+    This utility wrapper makes it convenient to create common layouts of
+    subplots, including the enclosing figure object, in a single call.
+
+    Keyword arguments:
+
+    naxes : int
+      Number of required axes. Exceeded axes are set invisible. Default is
+      nrows * ncols.
+
+    sharex : bool
+      If True, the X axis will be shared amongst all subplots.
+
+    sharey : bool
+      If True, the Y axis will be shared amongst all subplots.
+
+    squeeze : bool
+
+      If True, extra dimensions are squeezed out from the returned axis object:
+        - if only one subplot is constructed (nrows=ncols=1), the resulting
+        single Axis object is returned as a scalar.
+        - for Nx1 or 1xN subplots, the returned object is a 1-d numpy object
+        array of Axis objects are returned as numpy 1-d arrays.
+        - for NxM subplots with N>1 and M>1 are returned as a 2d array.
+
+      If False, no squeezing is done: the returned axis object is always
+      a 2-d array containing Axis instances, even if it ends up being 1x1.
+
+    subplot_kw : dict
+      Dict with keywords passed to the add_subplot() call used to create each
+      subplots.
+
+    ax : Matplotlib axis object, optional
+
+    layout : tuple
+      Number of rows and columns of the subplot grid.
+      If not specified, calculated from naxes and layout_type
+
+    layout_type : {'box', 'horizontal', 'vertical'}, default 'box'
+      Specify how to layout the subplot grid.
+
+    fig_kw : Other keyword arguments to be passed to the figure() call.
+        Note that all keywords not recognized above will be
+        automatically included here.
+
+    Returns:
+
+    fig, ax : tuple
+      - fig is the Matplotlib Figure object
+      - ax can be either a single axis object or an array of axis objects if
+      more than one subplot was created.  The dimensions of the resulting array
+      can be controlled with the squeeze keyword, see above.
+
+    **Examples:**
+
+    x = np.linspace(0, 2*np.pi, 400)
+    y = np.sin(x**2)
+
+    # Just a figure and one subplot
+    f, ax = plt.subplots()
+    ax.plot(x, y)
+    ax.set_title('Simple plot')
+
+    # Two subplots, unpack the output array immediately
+    f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)
+    ax1.plot(x, y)
+    ax1.set_title('Sharing Y axis')
+    ax2.scatter(x, y)
+
+    # Four polar axes
+    plt.subplots(2, 2, subplot_kw=dict(polar=True))
+    """
+    import matplotlib.pyplot as plt
+
+    nrows, ncols = _get_layout(naxes, layout=layout, layout_type=layout_type)
+    nplots = nrows * ncols
+
+    # Create empty object array to hold all axes.  It's easiest to make it 1-d
+    # so we can just append subplots upon creation, and then
+    axarr = np.empty(nplots, dtype=object)
+
+    # Create first subplot separately, so we can share it if requested
+    ax0 = fig.add_subplot(nrows, ncols, 1, **subplot_kw)
+
+    if sharex:
+        subplot_kw["sharex"] = ax0
+    if sharey:
+        subplot_kw["sharey"] = ax0
+    axarr[0] = ax0
+
+    # Note off-by-one counting because add_subplot uses the MATLAB 1-based
+    # convention.
+    for i in range(1, nplots):
+        kwds = subplot_kw.copy()
+        # Set sharex and sharey to None for blank/dummy axes, these can
+        # interfere with proper axis limits on the visible axes if
+        # they share axes e.g. issue #7528
+        if i >= naxes:
+            kwds["sharex"] = None
+            kwds["sharey"] = None
+        ax = fig.add_subplot(nrows, ncols, i + 1, **kwds)
+        axarr[i] = ax
+
+    if naxes != nplots:
+        for ax in axarr[naxes:]:
+            ax.set_visible(False)
+
+    _handle_shared_axes(axarr, nplots, naxes, nrows, ncols, sharex, sharey)
+
+    if squeeze:
+        # Reshape the array to have the final desired dimension (nrow,ncol),
+        # though discarding unneeded dimensions that equal 1.  If we only have
+        # one subplot, just return it instead of a 1-element array.
+        if nplots == 1:
+            axes = axarr[0]
+        else:
+            axes = axarr.reshape(nrows, ncols).squeeze()
+    else:
+        # returned axis array will be always 2-d, even if nrows=ncols=1
+        axes = axarr.reshape(nrows, ncols)
+
     return fig, axes
```

### Comparing `gempy-2.2b10.dev1/gempy/bayesian/fields.py` & `gempy-2.3.0/gempy/bayesian/fields.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,64 +1,64 @@
-import numpy as np
-
-from scipy.stats import entropy
-import warnings
-
-
-def compute_prob(blocks):
-    warnings.warn("This function is Deprecated, please use the probability function instead")
-    return probability(blocks)
-
-
-def probability(blocks: np.ndarray) -> np.ndarray:
-    """
-    compute the probabilities for the unique values in the array given
-    :param blocks: numpy array of different computed model results
-    :return:
-    """
-    blocks = np.round(blocks)
-    return np.mean([blocks == _ for _ in np.unique(blocks)], axis=1)
-
-
-def calculate_ie_masked(prob):
-    warnings.warn("This function is Deprecated, please use the information_entropy function instead")
-    return information_entropy(prob)
-
-
-def information_entropy(probabilities: np.ndarray, base=2) -> np.ndarray:
-    """
-    Calculate the Information Entropy of the provided probabilities array
-
-    Eq 2. from doi.org/10.1016/j.tecto.2011.05.001
-
-    but using scipy implementation for speed and simplicity
-
-    note the paper assumes base two everywhere
-
-    :param base: base for entropy, defaults to 2 as per paper
-    :param probabilities: probabilities array, first axis is for each possible layers (M, n cells)
-    :return: entropy of the probability array, flattens the first dimension
-    """
-    return entropy(probabilities, base=base)
-
-
-def fuzziness(probabilities: np.ndarray) -> float:
-    """
-    Return the fuzziness of the probability array
-
-    Eq 3. from doi.org/10.1016/j.tecto.2011.05.001
-    :param probabilities: probabilities array
-    :return: float of fuzziness
-    """
-    p = probabilities
-    fuzz = -np.mean(np.nan_to_num(p * np.log(p) + (1 - p) * np.log(1 - p)))
-    return fuzz
-
-
-def total_model_entropy(ie: np.ndarray) -> float:
-    """
-    Return the Total Model Information Entropy (the mean of the array)
-    Eq 4. from doi.org/10.1016/j.tecto.2011.05.001
-    :param ie: information entropy array
-    :return:
-    """
-    return float(np.mean(ie))
+import numpy as np
+
+from scipy.stats import entropy
+import warnings
+
+
+def compute_prob(blocks):
+    warnings.warn("This function is Deprecated, please use the probability function instead")
+    return probability(blocks)
+
+
+def probability(blocks: np.ndarray) -> np.ndarray:
+    """
+    compute the probabilities for the unique values in the array given
+    :param blocks: numpy array of different computed model results
+    :return:
+    """
+    blocks = np.round(blocks)
+    return np.mean([blocks == _ for _ in np.unique(blocks)], axis=1)
+
+
+def calculate_ie_masked(prob):
+    warnings.warn("This function is Deprecated, please use the information_entropy function instead")
+    return information_entropy(prob)
+
+
+def information_entropy(probabilities: np.ndarray, base=2) -> np.ndarray:
+    """
+    Calculate the Information Entropy of the provided probabilities array
+
+    Eq 2. from doi.org/10.1016/j.tecto.2011.05.001
+
+    but using scipy implementation for speed and simplicity
+
+    note the paper assumes base two everywhere
+
+    :param base: base for entropy, defaults to 2 as per paper
+    :param probabilities: probabilities array, first axis is for each possible layers (M, n cells)
+    :return: entropy of the probability array, flattens the first dimension
+    """
+    return entropy(probabilities, base=base)
+
+
+def fuzziness(probabilities: np.ndarray) -> float:
+    """
+    Return the fuzziness of the probability array
+
+    Eq 3. from doi.org/10.1016/j.tecto.2011.05.001
+    :param probabilities: probabilities array
+    :return: float of fuzziness
+    """
+    p = probabilities
+    fuzz = -np.mean(np.nan_to_num(p * np.log(p) + (1 - p) * np.log(1 - p)))
+    return fuzz
+
+
+def total_model_entropy(ie: np.ndarray) -> float:
+    """
+    Return the Total Model Information Entropy (the mean of the array)
+    Eq 4. from doi.org/10.1016/j.tecto.2011.05.001
+    :param ie: information entropy array
+    :return:
+    """
+    return float(np.mean(ie))
```

### Comparing `gempy-2.2b10.dev1/gempy/bayesian/joyplot.py` & `gempy-2.3.0/gempy/bayesian/joyplot.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,535 +1,535 @@
-"""Modified after https://github.com/sbebo/joypy"""
-
-
-import os
-import numpy as np
-from scipy.stats import gaussian_kde
-
-try:
-    from pandas.plotting._tools import (_subplots, _flatten)
-except:
-    #TODO this is a quick fix for #38
-     from pandas.plotting._matplotlib.tools import (create_subplots, flatten_axes)
-
-from pandas import (DataFrame, Series)
-from pandas.core.dtypes.common import is_number
-from pandas.core.groupby import DataFrameGroupBy
-from matplotlib import pyplot as plt
-from warnings import warn
-
-_DEBUG = False
-
-
-def _x_range(data, extra=0.2):
-    """ Compute the x_range, i.e., the values for which the
-        density will be computed. It should be slightly larger than
-        the max and min so that the plot actually reaches 0, and
-        also has a bit of a tail on both sides.
-    """
-    try:
-        sample_range = np.nanmax(data) - np.nanmin(data)
-    except ValueError:
-        return []
-    if sample_range < 1e-6:
-        return [np.nanmin(data), np.nanmax(data)]
-    return np.linspace(np.nanmin(data) - extra*sample_range,
-                       np.nanmax(data) + extra*sample_range, 1000)
-
-def _setup_axis(ax, x_range, col_name=None, grid=False, ylabelsize=None, yrot=None):
-    """ Setup the axis for the joyplot:
-        - add the y label if required (as an ytick)
-        - add y grid if required
-        - make the background transparent
-        - set the xlim according to the x_range
-        - hide the xaxis and the spines
-    """
-    if col_name is not None:
-        ax.set_yticks([0])
-        ax.set_yticklabels([col_name], fontsize=ylabelsize, rotation=yrot)
-        ax.yaxis.grid(grid)
-    else:
-        ax.yaxis.set_visible(False)
-    ax.patch.set_alpha(0)
-    ax.set_xlim([min(x_range), max(x_range)])
-    ax.tick_params(axis='both', which='both', length=0, pad=10)
-    ax.xaxis.set_visible(_DEBUG)
-    ax.set_frame_on(_DEBUG)
-
-def _is_numeric(x):
-    """ Whether the array x is numeric. """
-    return all(is_number(i) for i in x)
-
-def _get_alpha(i, n, start=0.4, end=1.0):
-    """ Compute alpha value at position i out of n """
-    return start + (1 + i)*(end - start)/n
-
-def _remove_na(l):
-    """ Remove NA values. Should work for lists, arrays, series. """
-    return Series(l).dropna().values
-
-def _moving_average(a, n=3, zero_padded=False):
-    """ Moving average of order n.
-        If zero padded, returns an array of the same size as
-        the input: the values before a[0] are considered to be 0.
-        Otherwise, returns an array of length len(a) - n + 1 """
-    ret = np.cumsum(a, dtype=float)
-    ret[n:] = ret[n:] - ret[:-n]
-    if zero_padded:
-        return ret / n
-    else:
-        return ret[n - 1:] / n
-
-def joyplot(data, column=None, by=None, grid=False,
-            xlabelsize=None, xrot=None, ylabelsize=None, yrot=None,
-            ax=None, figsize=None,
-            hist=False, bins=10,
-            fade=False, ylim='max',
-            fill=True, linecolor=None,
-            overlap=1, background=None,
-            labels=None, xlabels=True, ylabels=True,
-            range_style='all',
-            x_range=None,
-            title=None,
-            colormap=None, last_axis=True,
-            **kwds):
-    """
-    Draw joyplot of a DataFrame, or appropriately nested collection,
-    using matplotlib and pandas.
-
-    A joyplot is a stack of vertically aligned density plots / histograms.
-    By default, if 'data' is a DataFrame,
-    this function will plot a density plot for each column.
-
-    This wrapper method tries to convert whatever structure is given
-    to a nested collection of lists with additional information
-    on labels, and use the private _joyplot function to actually
-    draw theh plot.
-
-    Parameters
-    ----------
-    data : DataFrame, Series or nested collection
-    column : string or sequence
-        If passed, will be used to limit data to a subset of columns
-    by : object, optional
-        If passed, used to form separate plot groups
-    grid : boolean, default True
-        Whether to show axis grid lines
-    labels : boolean or list, default True.
-        If list, must be the same size of the de
-    xlabelsize : int, default None
-        If specified changes the x-axis label size
-    xrot : float, default None
-        rotation of x axis labels
-    ylabelsize : int, default None
-        If specified changes the y-axis label size
-    yrot : float, default None
-        rotation of y axis labels
-    ax : matplotlib axes object, default None
-    figsize : tuple
-        The size of the figure to create in inches by default
-    hist : boolean, default False
-    bins : integer, default 10
-        Number of histogram bins to be used
-    kwds : other plotting keyword arguments
-        To be passed to hist/kde plot function
-    """
-
-    if column is not None:
-        if not isinstance(column, (list, np.ndarray)):
-            column = [column]
-
-    def _grouped_df_to_standard(grouped, column):
-        converted = []
-        labels = []
-        for i, (key, group) in enumerate(grouped):
-            if column is not None:
-                group = group[column]
-            labels.append(key)
-            converted.append([_remove_na(group[c]) for c in group.columns if _is_numeric(group[c])])
-            if i == 0:
-                sublabels = [col for col in group.columns if _is_numeric(group[col])]
-        return converted, labels, sublabels
-
-    #################################################################
-    # GROUPED
-    # - given a grouped DataFrame, a group by key, or a dict of dicts of Series/lists/arrays
-    # - select the required columns/Series/lists/arrays
-    # - convert to standard format: list of lists of non-null arrays
-    #   + extra parameters (labels and sublabels)
-    #################################################################
-    if isinstance(data, DataFrameGroupBy):
-        grouped = data
-        converted, _labels, sublabels = _grouped_df_to_standard(grouped, column)
-        if labels is None:
-            labels = _labels
-    elif by is not None and isinstance(data, DataFrame):
-        grouped = data.groupby(by)
-        if column is None:
-            # Remove the groupby key. It's not automatically removed by pandas.
-            column = list(data.columns).remove(by)
-        converted, _labels, sublabels = _grouped_df_to_standard(grouped, column)
-        if labels is None:
-            labels = _labels
-        # If there is at least an element which is not a list of lists.. go on.
-    elif isinstance(data, dict) and all(isinstance(g, dict) for g in data.values()):
-        grouped = data
-        if labels is None:
-            labels = list(grouped.keys())
-        converted = []
-        for i, (key, group) in enumerate(grouped.items()):
-            if column is not None:
-                converted.append([_remove_na(g) for k,g in group.items() if _is_numeric(g) and k in column])
-                if i == 0:
-                    sublabels = [k for k,g in group.items() if _is_numeric(g)]
-            else:
-                converted.append([_remove_na(g) for k,g in group.items() if _is_numeric(g)])
-                if i == 0:
-                    sublabels = [k for k,g in group.items() if _is_numeric(g)]
-    #################################################################
-    # PLAIN:
-    # - given a DataFrame or list/dict of Series/lists/arrays
-    # - select the required columns/Series/lists/arrays
-    # - convert to standard format: list of lists of non-null arrays + extra parameter (labels)
-    #################################################################
-    elif isinstance(data, DataFrame):
-        if column is not None:
-            data = data[column]
-        converted = [[_remove_na(data[col])] for col in data.columns if _is_numeric(data[col])]
-        if labels is None:
-
-            labels = [col for col in data.columns if _is_numeric(data[col])]
-
-        sublabels = None
-    elif isinstance(data, dict):
-        if column is not None:
-            converted = [[_remove_na(g)] for k,g in data.items() if _is_numeric(g) and k in column]
-            labels = [k for k,g in data.items() if _is_numeric(g) and k in column]
-        else:
-            converted = [[_remove_na(g)] for k,g in data.items() if _is_numeric(g)]
-            labels = [k for k,g in data.items() if _is_numeric(g)]
-        sublabels = None
-    elif isinstance(data, list):
-        if column is not None:
-            converted = [[_remove_na(g)] for g in data if _is_numeric(g) and i in column]
-        else:
-            converted = [[_remove_na(g)] for g in data if _is_numeric(g)]
-        if labels and len(labels) != len(converted):
-            raise ValueError("The number of labels does not match the length of the list.")
-        sublabels = None
-    else:
-        raise TypeError("Unknown type for 'data': {!r}".format(type(data)))
-
-    if ylabels is False:
-        labels = None
-
-    if all(len(subg)==0 for g in converted for subg in g):
-        raise ValueError("No numeric values found. Joyplot requires at least a numeric column/group.")
-
-    if any(len(subg)==0 for g in converted for subg in g):
-        warn("At least a column/group has no numeric values.")
-
-
-    return _joyplot(converted, labels=labels, sublabels=sublabels,
-                    grid=grid,
-                    xlabelsize=xlabelsize, xrot=xrot, ylabelsize=ylabelsize, yrot=yrot,
-                    ax=ax, figsize=figsize,
-                    hist=hist, bins=bins,
-                    fade=fade, ylim=ylim,
-                    fill=fill, linecolor=linecolor,
-                    overlap=overlap, background=background,
-                    xlabels=xlabels,
-                    range_style=range_style, x_range=x_range,
-                    title=title,
-                    colormap=colormap, last_axis=last_axis,
-                    **kwds)
-
-###########################################
-
-def plot_density(ax, x_range, v, kind="kde", bw_method=None,
-                 bins=50,
-                 fill=False, linecolor=None, clip_on=True, **kwargs):
-    """ Draw a density plot given an axis, an array of values v and an array
-        of x positions where to return the estimated density.
-    """
-    v = _remove_na(v)
-    if len(v) == 0 or len(x_range) == 0:
-        return
-
-    if kind == "kde":
-        gkde = gaussian_kde(v, bw_method=bw_method)
-        y = gkde.evaluate(x_range)
-    elif kind == "counts":
-        y, bin_edges = np.histogram(v, bins=bins, range=(min(x_range), max(x_range)))
-        # np.histogram returns the edges of the bins.
-        # We compute here the middle of the bins.
-        x_range = _moving_average(bin_edges, 2)
-    elif kind == "normalized_counts":
-        y, bin_edges = np.histogram(v, bins=bins, density=False,
-                                    range=(min(x_range), max(x_range)))
-        # np.histogram returns the edges of the bins.
-        # We compute here the middle of the bins.
-        y = y / len(v)
-        x_range = _moving_average(bin_edges, 2)
-    elif kind == "values":
-        # Warning: to use values and get a meaningful visualization,
-        # x_range must also be manually set in the main function.
-        y = v
-        x_range = list(range(len(y)))
-    else:
-        raise NotImplementedError
-
-    if fill:
-        ax.fill_between(x_range, 0.0, y, clip_on=clip_on, **kwargs)
-
-        # Hack to have a border at the bottom at the fill patch
-        # (of the same color of the fill patch)
-        # so that the fill reaches the same bottom margin as the edge lines
-        # with y value = 0.0
-        kw = kwargs
-        kw["label"] = None
-        ax.plot(x_range, [0.0]*len(x_range), clip_on=clip_on, **kw)
-
-    if linecolor is not None:
-        kwargs["color"] = linecolor
-
-    # Remove the legend labels if we are plotting filled curve:
-    # we only want one entry per group in the legend (if shown).
-    if fill:
-        kwargs["label"] = None
-
-    ax.plot(x_range, y, clip_on=clip_on, **kwargs)
-
-###########################################
-
-def _joyplot(data,
-             grid=False,
-             labels=None, sublabels=None,
-             xlabels=True,
-             xlabelsize=None, xrot=None,
-             ylabelsize=None, yrot=None,
-             ax=None, figsize=None,
-             hist=False, bins=10,
-             fade=False,
-             xlim=None, ylim='max',
-             fill=True, linecolor=None,
-             overlap=1, background=None,
-             range_style='all', x_range=None, tails=0.2,
-             title=None,
-             legend=False, loc="upper right",
-             colormap=None, color=None, last_axis=True,
-             **kwargs):
-    """
-    Internal method.
-    Draw a joyplot from an appropriately nested collection of lists
-    using matplotlib and pandas.
-
-    Parameters
-    ----------
-    data : DataFrame, Series or nested collection
-    grid : boolean, default True
-        Whether to show axis grid lines
-    labels : boolean or list, default True.
-        If list, must be the same size of the de
-    xlabelsize : int, default None
-        If specified changes the x-axis label size
-    xrot : float, default None
-        rotation of x axis labels
-    ylabelsize : int, default None
-        If specified changes the y-axis label size
-    yrot : float, default None
-        rotation of y axis labels
-    ax : matplotlib axes object, default None
-    figsize : tuple
-        The size of the figure to create in inches by default
-    hist : boolean, default False
-    bins : integer, default 10
-        Number of histogram bins to be used
-    kwarg : other plotting keyword arguments
-        To be passed to hist/kde plot function
-    """
-
-    if fill is True and linecolor is None:
-        linecolor = "k"
-
-    if sublabels is None:
-        legend = False
-
-    def _get_color(i, num_axes, j, num_subgroups):
-        if isinstance(color, list):
-            try:
-                return color[i]
-            except IndexError:
-                pass
-        elif color is not None:
-            return color
-        elif isinstance(colormap, list):
-            return colormap[j](i/num_axes)
-        elif color is None and colormap is None:
-            return plt.rcParams['axes.prop_cycle'].by_key()['color'][j]
-        else:
-            return colormap(i/num_axes)
-
-    ygrid = (grid is True or grid == 'y' or grid == 'both')
-    xgrid = (grid is True or grid == 'x' or grid == 'both')
-
-    num_axes = len(data)
-
-    if x_range is None:
-        global_x_range = _x_range([v for g in data for sg in g for v in sg])
-    else:
-        global_x_range = _x_range(x_range, 0.0)
-    global_x_min, global_x_max = min(global_x_range), max(global_x_range)
-
-    # Each plot will have its own axis
-    fig, axes = create_subplots(naxes=num_axes, ax=ax, squeeze=False,
-                          sharex=False, sharey=False, figsize=figsize,
-                          layout_type='vertical')
-    _axes = flatten_axes(axes)
-
-    # The legend must be drawn in the last axis if we want it at the bottom.
-    if loc in (3, 4, 8) or 'lower' in str(loc):
-        legend_axis = num_axes - 1
-    else:
-        legend_axis = 0
-
-    # A couple of simple checks.
-    if labels is not None:
-        assert len(labels) == num_axes
-    if sublabels is not None:
-        assert all(len(g) == len(sublabels) for g in data)
-    #if isinstance(color, list):
-    #    assert all(len(g) == len(color) for g in data)
-    if isinstance(colormap, list):
-        assert all(len(g) == len(colormap) for g in data)
-
-    for i, group in enumerate(data):
-        a = _axes[i]
-        group_zorder = i
-        if fade:
-            kwargs['alpha'] = _get_alpha(i, num_axes)
-
-        num_subgroups = len(group)
-
-        if hist:
-            # matplotlib hist() already handles multiple subgroups in a histogram
-            a.hist(group, label=sublabels, bins=bins, color=color,
-                   range=[min(global_x_range), max(global_x_range)],
-                   edgecolor=linecolor, zorder=group_zorder, **kwargs)
-
-        else:
-            for j, subgroup in enumerate(group):
-
-                # Compute the x_range of the current plot
-                if range_style == 'all':
-                # All plots have the same range
-                    x_range = global_x_range
-                elif range_style == 'own':
-                # Each plot has its own range
-                    x_range = _x_range(subgroup, tails)
-                elif range_style == 'group':
-                # Each plot has a range that covers the whole group
-                    x_range = _x_range(group, tails)
-                elif isinstance(range_style, (list, np.ndarray)):
-                # All plots have exactly the range passed as argument
-                    x_range = _x_range(range_style, 0.0)
-                else:
-                    raise NotImplementedError("Unrecognized range style.")
-
-                if sublabels is None:
-                    sublabel = None
-                else:
-                    sublabel = sublabels[j]
-
-                element_zorder = group_zorder + j/(num_subgroups+1)
-                element_color = _get_color(i, num_axes, j, num_subgroups)
-
-                plot_density(a, x_range, subgroup,
-                             fill=fill, linecolor=linecolor, label=sublabel,
-                             zorder=element_zorder, color=element_color,
-                             bins=bins, **kwargs)
-
-
-        # Setup the current axis: transparency, labels, spines.
-        col_name = None if labels is None else labels[i]
-        _setup_axis(a, global_x_range, col_name=col_name, grid=ygrid,
-                ylabelsize=ylabelsize, yrot=yrot)
-
-        # When needed, draw the legend
-        if legend and i == legend_axis:
-            a.legend(loc=loc)
-            # Bypass alpha values, in case
-            for p in a.get_legend().get_patches():
-                p.set_facecolor(p.get_facecolor())
-                p.set_alpha(1.0)
-            for l in a.get_legend().get_lines():
-                l.set_alpha(1.0)
-
-
-    # Final adjustments
-
-    # Set the y limit for the density plots.
-    # Since the y range in the subplots can vary significantly,
-    # different options are available.
-    if ylim == 'max':
-        # Set all yaxis limit to the same value (max range among all)
-        max_ylim = max(a.get_ylim()[1] for a in _axes)
-        min_ylim = min(a.get_ylim()[0] for a in _axes)
-        for a in _axes:
-            a.set_ylim([min_ylim - 0.1*(max_ylim-min_ylim), max_ylim])
-
-    elif ylim == 'own':
-        # Do nothing, each axis keeps its own ylim
-        pass
-
-    else:
-        # Set all yaxis lim to the argument value ylim
-        try:
-            for a in _axes:
-                a.set_ylim(ylim)
-        except:
-            print("Warning: the value of ylim must be either 'max', 'own', or a tuple of length 2. The value you provided has no effect.")
-    if last_axis is True:
-        # Compute a final axis, used to apply global settings
-        last_axis = fig.add_subplot(1, 1, 1)
-
-        # Background color
-        if background is not None:
-            last_axis.patch.set_facecolor(background)
-
-        for side in ['top', 'bottom', 'left', 'right']:
-            last_axis.spines[side].set_visible(_DEBUG)
-
-        # This looks hacky, but all the axes share the x-axis,
-        # so they have the same lims and ticks
-        last_axis.set_xlim(_axes[0].get_xlim())
-        if xlabels is True:
-            last_axis.set_xticks(np.array(_axes[0].get_xticks()[1:-1]))
-            for t in last_axis.get_xticklabels():
-                t.set_visible(True)
-                t.set_fontsize(xlabelsize)
-                t.set_rotation(xrot)
-
-            # If grid is enabled, do not allow xticks (they are ugly)
-            if xgrid:
-                last_axis.tick_params(axis='both', which='both',length=0)
-        else:
-            last_axis.xaxis.set_visible(False)
-
-        last_axis.yaxis.set_visible(False)
-        last_axis.grid(xgrid)
-
-
-        # Last axis on the back
-        last_axis.zorder = min(a.zorder for a in _axes) - 1
-        _axes = list(_axes) + [last_axis]
-
-    if title is not None:
-        plt.title(title)
-
-
-    # The magic overlap happens here.
-    #h_pad = 5 + (- 5*(1 + overlap))
-    #fig.tight_layout(h_pad=h_pad)
-
-    return fig, _axes
-
+"""Modified after https://github.com/sbebo/joypy"""
+
+
+import os
+import numpy as np
+from scipy.stats import gaussian_kde
+
+try:
+    from pandas.plotting._tools import (_subplots, _flatten)
+except:
+    #TODO this is a quick fix for #38
+     from pandas.plotting._matplotlib.tools import (create_subplots, flatten_axes)
+
+from pandas import (DataFrame, Series)
+from pandas.core.dtypes.common import is_number
+from pandas.core.groupby import DataFrameGroupBy
+from matplotlib import pyplot as plt
+from warnings import warn
+
+_DEBUG = False
+
+
+def _x_range(data, extra=0.2):
+    """ Compute the x_range, i.e., the values for which the
+        density will be computed. It should be slightly larger than
+        the max and min so that the plot actually reaches 0, and
+        also has a bit of a tail on both sides.
+    """
+    try:
+        sample_range = np.nanmax(data) - np.nanmin(data)
+    except ValueError:
+        return []
+    if sample_range < 1e-6:
+        return [np.nanmin(data), np.nanmax(data)]
+    return np.linspace(np.nanmin(data) - extra*sample_range,
+                       np.nanmax(data) + extra*sample_range, 1000)
+
+def _setup_axis(ax, x_range, col_name=None, grid=False, ylabelsize=None, yrot=None):
+    """ Setup the axis for the joyplot:
+        - add the y label if required (as an ytick)
+        - add y grid if required
+        - make the background transparent
+        - set the xlim according to the x_range
+        - hide the xaxis and the spines
+    """
+    if col_name is not None:
+        ax.set_yticks([0])
+        ax.set_yticklabels([col_name], fontsize=ylabelsize, rotation=yrot)
+        ax.yaxis.grid(grid)
+    else:
+        ax.yaxis.set_visible(False)
+    ax.patch.set_alpha(0)
+    ax.set_xlim([min(x_range), max(x_range)])
+    ax.tick_params(axis='both', which='both', length=0, pad=10)
+    ax.xaxis.set_visible(_DEBUG)
+    ax.set_frame_on(_DEBUG)
+
+def _is_numeric(x):
+    """ Whether the array x is numeric. """
+    return all(is_number(i) for i in x)
+
+def _get_alpha(i, n, start=0.4, end=1.0):
+    """ Compute alpha value at position i out of n """
+    return start + (1 + i)*(end - start)/n
+
+def _remove_na(l):
+    """ Remove NA values. Should work for lists, arrays, series. """
+    return Series(l).dropna().values
+
+def _moving_average(a, n=3, zero_padded=False):
+    """ Moving average of order n.
+        If zero padded, returns an array of the same size as
+        the input: the values before a[0] are considered to be 0.
+        Otherwise, returns an array of length len(a) - n + 1 """
+    ret = np.cumsum(a, dtype=float)
+    ret[n:] = ret[n:] - ret[:-n]
+    if zero_padded:
+        return ret / n
+    else:
+        return ret[n - 1:] / n
+
+def joyplot(data, column=None, by=None, grid=False,
+            xlabelsize=None, xrot=None, ylabelsize=None, yrot=None,
+            ax=None, figsize=None,
+            hist=False, bins=10,
+            fade=False, ylim='max',
+            fill=True, linecolor=None,
+            overlap=1, background=None,
+            labels=None, xlabels=True, ylabels=True,
+            range_style='all',
+            x_range=None,
+            title=None,
+            colormap=None, last_axis=True,
+            **kwds):
+    """
+    Draw joyplot of a DataFrame, or appropriately nested collection,
+    using matplotlib and pandas.
+
+    A joyplot is a stack of vertically aligned density plots / histograms.
+    By default, if 'data' is a DataFrame,
+    this function will plot a density plot for each column.
+
+    This wrapper method tries to convert whatever structure is given
+    to a nested collection of lists with additional information
+    on labels, and use the private _joyplot function to actually
+    draw theh plot.
+
+    Parameters
+    ----------
+    data : DataFrame, Series or nested collection
+    column : string or sequence
+        If passed, will be used to limit data to a subset of columns
+    by : object, optional
+        If passed, used to form separate plot groups
+    grid : boolean, default True
+        Whether to show axis grid lines
+    labels : boolean or list, default True.
+        If list, must be the same size of the de
+    xlabelsize : int, default None
+        If specified changes the x-axis label size
+    xrot : float, default None
+        rotation of x axis labels
+    ylabelsize : int, default None
+        If specified changes the y-axis label size
+    yrot : float, default None
+        rotation of y axis labels
+    ax : matplotlib axes object, default None
+    figsize : tuple
+        The size of the figure to create in inches by default
+    hist : boolean, default False
+    bins : integer, default 10
+        Number of histogram bins to be used
+    kwds : other plotting keyword arguments
+        To be passed to hist/kde plot function
+    """
+
+    if column is not None:
+        if not isinstance(column, (list, np.ndarray)):
+            column = [column]
+
+    def _grouped_df_to_standard(grouped, column):
+        converted = []
+        labels = []
+        for i, (key, group) in enumerate(grouped):
+            if column is not None:
+                group = group[column]
+            labels.append(key)
+            converted.append([_remove_na(group[c]) for c in group.columns if _is_numeric(group[c])])
+            if i == 0:
+                sublabels = [col for col in group.columns if _is_numeric(group[col])]
+        return converted, labels, sublabels
+
+    #################################################################
+    # GROUPED
+    # - given a grouped DataFrame, a group by key, or a dict of dicts of Series/lists/arrays
+    # - select the required columns/Series/lists/arrays
+    # - convert to standard format: list of lists of non-null arrays
+    #   + extra parameters (labels and sublabels)
+    #################################################################
+    if isinstance(data, DataFrameGroupBy):
+        grouped = data
+        converted, _labels, sublabels = _grouped_df_to_standard(grouped, column)
+        if labels is None:
+            labels = _labels
+    elif by is not None and isinstance(data, DataFrame):
+        grouped = data.groupby(by)
+        if column is None:
+            # Remove the groupby key. It's not automatically removed by pandas.
+            column = list(data.columns).remove(by)
+        converted, _labels, sublabels = _grouped_df_to_standard(grouped, column)
+        if labels is None:
+            labels = _labels
+        # If there is at least an element which is not a list of lists.. go on.
+    elif isinstance(data, dict) and all(isinstance(g, dict) for g in data.values()):
+        grouped = data
+        if labels is None:
+            labels = list(grouped.keys())
+        converted = []
+        for i, (key, group) in enumerate(grouped.items()):
+            if column is not None:
+                converted.append([_remove_na(g) for k,g in group.items() if _is_numeric(g) and k in column])
+                if i == 0:
+                    sublabels = [k for k,g in group.items() if _is_numeric(g)]
+            else:
+                converted.append([_remove_na(g) for k,g in group.items() if _is_numeric(g)])
+                if i == 0:
+                    sublabels = [k for k,g in group.items() if _is_numeric(g)]
+    #################################################################
+    # PLAIN:
+    # - given a DataFrame or list/dict of Series/lists/arrays
+    # - select the required columns/Series/lists/arrays
+    # - convert to standard format: list of lists of non-null arrays + extra parameter (labels)
+    #################################################################
+    elif isinstance(data, DataFrame):
+        if column is not None:
+            data = data[column]
+        converted = [[_remove_na(data[col])] for col in data.columns if _is_numeric(data[col])]
+        if labels is None:
+
+            labels = [col for col in data.columns if _is_numeric(data[col])]
+
+        sublabels = None
+    elif isinstance(data, dict):
+        if column is not None:
+            converted = [[_remove_na(g)] for k,g in data.items() if _is_numeric(g) and k in column]
+            labels = [k for k,g in data.items() if _is_numeric(g) and k in column]
+        else:
+            converted = [[_remove_na(g)] for k,g in data.items() if _is_numeric(g)]
+            labels = [k for k,g in data.items() if _is_numeric(g)]
+        sublabels = None
+    elif isinstance(data, list):
+        if column is not None:
+            converted = [[_remove_na(g)] for g in data if _is_numeric(g) and i in column]
+        else:
+            converted = [[_remove_na(g)] for g in data if _is_numeric(g)]
+        if labels and len(labels) != len(converted):
+            raise ValueError("The number of labels does not match the length of the list.")
+        sublabels = None
+    else:
+        raise TypeError("Unknown type for 'data': {!r}".format(type(data)))
+
+    if ylabels is False:
+        labels = None
+
+    if all(len(subg)==0 for g in converted for subg in g):
+        raise ValueError("No numeric values found. Joyplot requires at least a numeric column/group.")
+
+    if any(len(subg)==0 for g in converted for subg in g):
+        warn("At least a column/group has no numeric values.")
+
+
+    return _joyplot(converted, labels=labels, sublabels=sublabels,
+                    grid=grid,
+                    xlabelsize=xlabelsize, xrot=xrot, ylabelsize=ylabelsize, yrot=yrot,
+                    ax=ax, figsize=figsize,
+                    hist=hist, bins=bins,
+                    fade=fade, ylim=ylim,
+                    fill=fill, linecolor=linecolor,
+                    overlap=overlap, background=background,
+                    xlabels=xlabels,
+                    range_style=range_style, x_range=x_range,
+                    title=title,
+                    colormap=colormap, last_axis=last_axis,
+                    **kwds)
+
+###########################################
+
+def plot_density(ax, x_range, v, kind="kde", bw_method=None,
+                 bins=50,
+                 fill=False, linecolor=None, clip_on=True, **kwargs):
+    """ Draw a density plot given an axis, an array of values v and an array
+        of x positions where to return the estimated density.
+    """
+    v = _remove_na(v)
+    if len(v) == 0 or len(x_range) == 0:
+        return
+
+    if kind == "kde":
+        gkde = gaussian_kde(v, bw_method=bw_method)
+        y = gkde.evaluate(x_range)
+    elif kind == "counts":
+        y, bin_edges = np.histogram(v, bins=bins, range=(min(x_range), max(x_range)))
+        # np.histogram returns the edges of the bins.
+        # We compute here the middle of the bins.
+        x_range = _moving_average(bin_edges, 2)
+    elif kind == "normalized_counts":
+        y, bin_edges = np.histogram(v, bins=bins, density=False,
+                                    range=(min(x_range), max(x_range)))
+        # np.histogram returns the edges of the bins.
+        # We compute here the middle of the bins.
+        y = y / len(v)
+        x_range = _moving_average(bin_edges, 2)
+    elif kind == "values":
+        # Warning: to use values and get a meaningful visualization,
+        # x_range must also be manually set in the main function.
+        y = v
+        x_range = list(range(len(y)))
+    else:
+        raise NotImplementedError
+
+    if fill:
+        ax.fill_between(x_range, 0.0, y, clip_on=clip_on, **kwargs)
+
+        # Hack to have a border at the bottom at the fill patch
+        # (of the same color of the fill patch)
+        # so that the fill reaches the same bottom margin as the edge lines
+        # with y value = 0.0
+        kw = kwargs
+        kw["label"] = None
+        ax.plot(x_range, [0.0]*len(x_range), clip_on=clip_on, **kw)
+
+    if linecolor is not None:
+        kwargs["color"] = linecolor
+
+    # Remove the legend labels if we are plotting filled curve:
+    # we only want one entry per group in the legend (if shown).
+    if fill:
+        kwargs["label"] = None
+
+    ax.plot(x_range, y, clip_on=clip_on, **kwargs)
+
+###########################################
+
+def _joyplot(data,
+             grid=False,
+             labels=None, sublabels=None,
+             xlabels=True,
+             xlabelsize=None, xrot=None,
+             ylabelsize=None, yrot=None,
+             ax=None, figsize=None,
+             hist=False, bins=10,
+             fade=False,
+             xlim=None, ylim='max',
+             fill=True, linecolor=None,
+             overlap=1, background=None,
+             range_style='all', x_range=None, tails=0.2,
+             title=None,
+             legend=False, loc="upper right",
+             colormap=None, color=None, last_axis=True,
+             **kwargs):
+    """
+    Internal method.
+    Draw a joyplot from an appropriately nested collection of lists
+    using matplotlib and pandas.
+
+    Parameters
+    ----------
+    data : DataFrame, Series or nested collection
+    grid : boolean, default True
+        Whether to show axis grid lines
+    labels : boolean or list, default True.
+        If list, must be the same size of the de
+    xlabelsize : int, default None
+        If specified changes the x-axis label size
+    xrot : float, default None
+        rotation of x axis labels
+    ylabelsize : int, default None
+        If specified changes the y-axis label size
+    yrot : float, default None
+        rotation of y axis labels
+    ax : matplotlib axes object, default None
+    figsize : tuple
+        The size of the figure to create in inches by default
+    hist : boolean, default False
+    bins : integer, default 10
+        Number of histogram bins to be used
+    kwarg : other plotting keyword arguments
+        To be passed to hist/kde plot function
+    """
+
+    if fill is True and linecolor is None:
+        linecolor = "k"
+
+    if sublabels is None:
+        legend = False
+
+    def _get_color(i, num_axes, j, num_subgroups):
+        if isinstance(color, list):
+            try:
+                return color[i]
+            except IndexError:
+                pass
+        elif color is not None:
+            return color
+        elif isinstance(colormap, list):
+            return colormap[j](i/num_axes)
+        elif color is None and colormap is None:
+            return plt.rcParams['axes.prop_cycle'].by_key()['color'][j]
+        else:
+            return colormap(i/num_axes)
+
+    ygrid = (grid is True or grid == 'y' or grid == 'both')
+    xgrid = (grid is True or grid == 'x' or grid == 'both')
+
+    num_axes = len(data)
+
+    if x_range is None:
+        global_x_range = _x_range([v for g in data for sg in g for v in sg])
+    else:
+        global_x_range = _x_range(x_range, 0.0)
+    global_x_min, global_x_max = min(global_x_range), max(global_x_range)
+
+    # Each plot will have its own axis
+    fig, axes = create_subplots(naxes=num_axes, ax=ax, squeeze=False,
+                          sharex=False, sharey=False, figsize=figsize,
+                          layout_type='vertical')
+    _axes = flatten_axes(axes)
+
+    # The legend must be drawn in the last axis if we want it at the bottom.
+    if loc in (3, 4, 8) or 'lower' in str(loc):
+        legend_axis = num_axes - 1
+    else:
+        legend_axis = 0
+
+    # A couple of simple checks.
+    if labels is not None:
+        assert len(labels) == num_axes
+    if sublabels is not None:
+        assert all(len(g) == len(sublabels) for g in data)
+    #if isinstance(color, list):
+    #    assert all(len(g) == len(color) for g in data)
+    if isinstance(colormap, list):
+        assert all(len(g) == len(colormap) for g in data)
+
+    for i, group in enumerate(data):
+        a = _axes[i]
+        group_zorder = i
+        if fade:
+            kwargs['alpha'] = _get_alpha(i, num_axes)
+
+        num_subgroups = len(group)
+
+        if hist:
+            # matplotlib hist() already handles multiple subgroups in a histogram
+            a.hist(group, label=sublabels, bins=bins, color=color,
+                   range=[min(global_x_range), max(global_x_range)],
+                   edgecolor=linecolor, zorder=group_zorder, **kwargs)
+
+        else:
+            for j, subgroup in enumerate(group):
+
+                # Compute the x_range of the current plot
+                if range_style == 'all':
+                # All plots have the same range
+                    x_range = global_x_range
+                elif range_style == 'own':
+                # Each plot has its own range
+                    x_range = _x_range(subgroup, tails)
+                elif range_style == 'group':
+                # Each plot has a range that covers the whole group
+                    x_range = _x_range(group, tails)
+                elif isinstance(range_style, (list, np.ndarray)):
+                # All plots have exactly the range passed as argument
+                    x_range = _x_range(range_style, 0.0)
+                else:
+                    raise NotImplementedError("Unrecognized range style.")
+
+                if sublabels is None:
+                    sublabel = None
+                else:
+                    sublabel = sublabels[j]
+
+                element_zorder = group_zorder + j/(num_subgroups+1)
+                element_color = _get_color(i, num_axes, j, num_subgroups)
+
+                plot_density(a, x_range, subgroup,
+                             fill=fill, linecolor=linecolor, label=sublabel,
+                             zorder=element_zorder, color=element_color,
+                             bins=bins, **kwargs)
+
+
+        # Setup the current axis: transparency, labels, spines.
+        col_name = None if labels is None else labels[i]
+        _setup_axis(a, global_x_range, col_name=col_name, grid=ygrid,
+                ylabelsize=ylabelsize, yrot=yrot)
+
+        # When needed, draw the legend
+        if legend and i == legend_axis:
+            a.legend(loc=loc)
+            # Bypass alpha values, in case
+            for p in a.get_legend().get_patches():
+                p.set_facecolor(p.get_facecolor())
+                p.set_alpha(1.0)
+            for l in a.get_legend().get_lines():
+                l.set_alpha(1.0)
+
+
+    # Final adjustments
+
+    # Set the y limit for the density plots.
+    # Since the y range in the subplots can vary significantly,
+    # different options are available.
+    if ylim == 'max':
+        # Set all yaxis limit to the same value (max range among all)
+        max_ylim = max(a.get_ylim()[1] for a in _axes)
+        min_ylim = min(a.get_ylim()[0] for a in _axes)
+        for a in _axes:
+            a.set_ylim([min_ylim - 0.1*(max_ylim-min_ylim), max_ylim])
+
+    elif ylim == 'own':
+        # Do nothing, each axis keeps its own ylim
+        pass
+
+    else:
+        # Set all yaxis lim to the argument value ylim
+        try:
+            for a in _axes:
+                a.set_ylim(ylim)
+        except:
+            print("Warning: the value of ylim must be either 'max', 'own', or a tuple of length 2. The value you provided has no effect.")
+    if last_axis is True:
+        # Compute a final axis, used to apply global settings
+        last_axis = fig.add_subplot(1, 1, 1)
+
+        # Background color
+        if background is not None:
+            last_axis.patch.set_facecolor(background)
+
+        for side in ['top', 'bottom', 'left', 'right']:
+            last_axis.spines[side].set_visible(_DEBUG)
+
+        # This looks hacky, but all the axes share the x-axis,
+        # so they have the same lims and ticks
+        last_axis.set_xlim(_axes[0].get_xlim())
+        if xlabels is True:
+            last_axis.set_xticks(np.array(_axes[0].get_xticks()[1:-1]))
+            for t in last_axis.get_xticklabels():
+                t.set_visible(True)
+                t.set_fontsize(xlabelsize)
+                t.set_rotation(xrot)
+
+            # If grid is enabled, do not allow xticks (they are ugly)
+            if xgrid:
+                last_axis.tick_params(axis='both', which='both',length=0)
+        else:
+            last_axis.xaxis.set_visible(False)
+
+        last_axis.yaxis.set_visible(False)
+        last_axis.grid(xgrid)
+
+
+        # Last axis on the back
+        last_axis.zorder = min(a.zorder for a in _axes) - 1
+        _axes = list(_axes) + [last_axis]
+
+    if title is not None:
+        plt.title(title)
+
+
+    # The magic overlap happens here.
+    #h_pad = 5 + (- 5*(1 + overlap))
+    #fig.tight_layout(h_pad=h_pad)
+
+    return fig, _axes
+
```

### Comparing `gempy-2.2b10.dev1/gempy/bayesian/plot_posterior.py` & `gempy-2.3.0/gempy/bayesian/plot_posterior.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,627 +1,627 @@
-import numpy as np
-import pandas as pn
-import scipy.stats as stats
-from .joyplot import joyplot
-
-from typing import Union
-import matplotlib.gridspec as gridspect
-
-# Create cmap
-from matplotlib.colors import ListedColormap
-import matplotlib.pyplot as plt
-import matplotlib.colors as colors
-import matplotlib.cm as cmx
-import seaborn as sns
-from arviz.plots.jointplot import *
-from arviz.plots.plot_utils import make_label, _scale_fig_size
-from arviz import plot_kde, plot_dist
-from arviz.plots.jointplot import _var_names
-from arviz.plots.kdeplot import _fast_kde_2d
-from arviz.stats import hpd
-import arviz
-
-
-# Seaborn style
-sns.set(style="white", rc={"axes.facecolor": (0, 0, 0, 0)})
-
-# Discrete cmap
-    # seaborn palette
-pal_disc = sns.cubehelix_palette(10, rot=-.25, light=.7)
-pal_disc_l = sns.cubehelix_palette(10)
-
-    # matplotlib cmap
-my_cmap = ListedColormap(pal_disc)
-my_cmap_l = ListedColormap(pal_disc_l)
-
-# Continuous cmap
-    # seaborn palette
-pal_cont_light = sns.cubehelix_palette(250, rot=-.25, light=1)
-pal_cont = sns.cubehelix_palette(250, rot=-.25, light=.7)
-
-pal_cont_l = sns.cubehelix_palette(250)
-pal_cont_l_light = sns.cubehelix_palette(250, light=1)
-
-    # matplotlib cmap
-my_cmap_full = ListedColormap(pal_cont)
-my_cmap_full_light = ListedColormap(pal_cont_light)
-
-my_cmap_full_l = ListedColormap(pal_cont_l)
-my_cmap_full_l_light = ListedColormap(pal_cont_l_light)
-
-# Default individual colors
-default_red = '#DA8886'
-default_blue = pal_cont[50]
-default_l = pal_disc_l.as_hex()[4]
-
-
-class PlotPosterior:
-    def __init__(self, data: arviz.data.inference_data.InferenceData = None):
-        self.data = data
-        self.iteration = 1
-        self.likelihood_axes = None
-        self.marginal_axes = None
-        self.joy = None
-
-    def create_figure(self, marginal=True, likelihood=True, joyplot=True,
-                      figsize=None, textsize=None,
-                      n_samples=11):
-
-        figsize, self.ax_labelsize, _, self.xt_labelsize, self.linewidth, _ = _scale_fig_size(figsize, textsize)
-        self.fig = plt.figure(figsize=figsize, constrained_layout=False)
-        gs_0 = gridspect.GridSpec(3, 6, figure=self.fig, hspace=.1)
-
-        if marginal is True:
-            # Testing
-            if likelihood is False:
-                self.marginal_axes = self._create_joint_axis(figure=self.fig, subplot_spec=gs_0[0:2, 0:4])
-            elif likelihood is False and joyplot is False:
-                self.marginal_axes = self._create_joint_axis(figure=self.fig, subplot_spec=gs_0[:, :])
-    
-            else:
-                self.marginal_axes = self._create_joint_axis(figure=self.fig, subplot_spec=gs_0[0:2, 0:3])
-
-        if likelihood is True:
-            if marginal is False:
-                self.likelihood_axes = self._create_likelihood_axis(figure=self.fig, subplot_spec=gs_0[0:2, 0:4])
-            elif joyplot is False:
-                self.likelihood_axes = self._create_likelihood_axis(figure=self.fig, subplot_spec=gs_0[0:2, 4:])
-            else:
-                self.likelihood_axes = self._create_likelihood_axis(figure=self.fig, subplot_spec=gs_0[0:1, 4:])
-
-        if joyplot is True:
-            self.n_samples = n_samples
-            if marginal is False and likelihood is False:
-                self.joy = self._create_joy_axis(self.fig, gs_0[:, :])
-            else:
-                self.joy = self._create_joy_axis(self.fig, gs_0[1:2, 4:])
-
-    def _create_joint_axis(self, figure=None, subplot_spec=None, figsize=None, textsize=None):
-        figsize, ax_labelsize, _, xt_labelsize, linewidth, _ = _scale_fig_size(figsize, textsize)
-        # Instantiate figure and grid
-
-        if figure is None:
-            fig = plt.figure(figsize=figsize, constrained_layout=True)
-        else:
-            fig = figure
-
-        if subplot_spec is None:
-            grid = plt.GridSpec(4, 4, hspace=0.1, wspace=0.1, figure=fig)
-        else:
-            grid = gridspect.GridSpecFromSubplotSpec(4, 4, subplot_spec=subplot_spec)
-
-        # Set up main plot
-        self.axjoin = fig.add_subplot(grid[1:, :-1])
-
-        # Set up top KDE
-        self.ax_hist_x = fig.add_subplot(grid[0, :-1], sharex=self.axjoin)
-        self.ax_hist_x.tick_params(labelleft=False, labelbottom=False)
-
-        # Set up right KDE
-        self.ax_hist_y = fig.add_subplot(grid[1:, -1], sharey=self.axjoin)
-        self.ax_hist_y.tick_params(labelleft=False, labelbottom=False)
-        sns.despine(left=True, bottom=True)
-
-        return self.axjoin, self.ax_hist_x, self.ax_hist_y
-
-    def _create_likelihood_axis(self, figure=None, subplot_spec=None, **kwargs):
-        # Making the axes:
-        if figure is None:
-            figsize = kwargs.get('figsize', None)
-            fig = plt.figure(figsize=figsize, constrained_layout=False)
-        else:
-            fig = figure
-
-        if subplot_spec is None:
-            grid = plt.GridSpec(1, 1, hspace=0.1, wspace=0.1, figure=fig)
-        else:
-            grid = gridspect.GridSpecFromSubplotSpec(1, 1, subplot_spec=subplot_spec)
-
-        ax_like = fig.add_subplot(grid[0, 0])
-        ax_like.spines['bottom'].set_position(('data', 0.0))
-        ax_like.yaxis.tick_right()
-
-        ax_like.spines['right'].set_position(('axes', 1.03))
-        ax_like.spines['top'].set_color('none')
-        ax_like.spines['left'].set_color('none')
-        ax_like.set_xlabel('Thickness Obs.')
-        ax_like.set_title('Likelihood')
-        return ax_like
-
-    def _create_joy_axis(self, figure=None, subplot_spec=None, n_samples=None, overlap=.85):
-        if n_samples is None:
-            n_samples = self.n_samples
-
-        grid = gridspect.GridSpecFromSubplotSpec(n_samples, 1, hspace=-overlap, subplot_spec=subplot_spec)
-        ax_joy = [figure.add_subplot(grid[i, 0]) for i in range(n_samples)]
-        ax_joy[0].set_title('Foo Likelihood')
-
-        return ax_joy
-
-    def create_color_map(self):
-        cNorm = colors.Normalize(0, self.y_max_like)
-        scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=my_cmap_full)
-        return scalarMap
-
-    def evaluate_cmap(self, cmap, draw_mu, draw_sigma, obs: Union[float, list] = None):
-        likelihood_at_observation = stats.norm.pdf(obs, loc=draw_mu, scale=draw_sigma)
-        color_fill = colors.to_hex(cmap.to_rgba(np.atleast_1d(likelihood_at_observation)[0]))
-        return color_fill
-
-    def plot_marginal_posterior(self, plotters, iteration=-1, **marginal_kwargs):
-        marginal_kwargs.setdefault("plot_kwargs", {})
-        marginal_kwargs["plot_kwargs"]["linewidth"] = self.linewidth
-        marginal_kwargs.setdefault('fill_kwargs', {})
-
-        marginal_kwargs["plot_kwargs"].setdefault('color', default_l)
-        marginal_kwargs['fill_kwargs'].setdefault('color', default_l)
-        marginal_kwargs['fill_kwargs'].setdefault('alpha', .8)
-
-        # Flatten data
-        x = plotters[0][2].flatten()[:iteration]
-        y = plotters[1][2].flatten()[:iteration]
-
-        for val, ax, rotate in ((x, self.ax_hist_x, False), (y, self.ax_hist_y, True)):
-            plot_dist(val, textsize=self.xt_labelsize, rotated=rotate, ax=ax, **marginal_kwargs)
-
-    def plot_joint_posterior(self, plotters, iteration=-1, kind='kde', **joint_kwargs):
-
-        # Set labels for axes
-        x_var_name = make_label(plotters[0][0], plotters[0][1])
-        y_var_name = make_label(plotters[1][0], plotters[1][1])
-
-        self.axjoin.set_xlabel(x_var_name, fontsize=self.ax_labelsize)
-        self.axjoin.set_ylabel(y_var_name, fontsize=self.ax_labelsize)
-        self.axjoin.tick_params(labelsize=self.xt_labelsize)
-
-        # Flatten data
-        x = plotters[0][2].flatten()[:iteration]
-        y = plotters[1][2].flatten()[:iteration]
-
-        if kind == "scatter":
-            self.axjoin.scatter(x, y, **joint_kwargs)
-        elif kind == "kde":
-            if False:
-                gridsize = (128, 128)# if contour else (256, 256)
-
-                density, xmin, xmax, ymin, ymax = _fast_kde_2d(x, y, gridsize=gridsize)
-
-             #   self.axjoin.scatter(x, y, density)
-                self.axjoin.imshow(density)
-            else:
-                if 'contour' not in joint_kwargs:
-                    joint_kwargs.setdefault('contour', True) 
-                fill_last = joint_kwargs.get('fill_last', False)
-                
-                try:
-                    self.foo = plot_kde(x, y, fill_last=fill_last, ax=self.axjoin, **joint_kwargs)
-                except ValueError:
-                    pass
-                except np.linalg.LinAlgError:
-                    pass
-        else:
-            gridsize = joint_kwargs.get('grid_size', 'auto')
-            if gridsize == "auto":
-                gridsize = int(len(x) ** 0.35)
-            self.axjoin.hexbin(x, y, mincnt=1, gridsize=gridsize, **joint_kwargs)
-            self.axjoin._grid(False)
-
-    def plot_trace(self, plotters, iteration, n_iterations=20):
-        i_0 = np.max([0, (iteration - n_iterations)])
-
-        theta1_val_trace = plotters[0][2].flatten()[i_0:iteration+1]
-        theta2_val_trace = plotters[1][2].flatten()[i_0:iteration+1]
-
-        theta1_val = theta1_val_trace[-1]
-        theta2_val = theta2_val_trace[-1]
-
-        # Plot point of the given iteration
-        self.axjoin.plot(theta1_val, theta2_val, 'bo', ms=6, color='k')
-
-        # Plot a trace of n_iterations
-        pair_x_array = np.vstack(
-            (theta1_val_trace[:-1], theta1_val_trace[1:])).T
-        pair_y_array = np.vstack((theta2_val_trace[:-1], theta2_val_trace[1:])).T
-        for i, pair_x in enumerate(pair_x_array):
-            alpha_val = i / pair_x_array.shape[0]
-            pair_y = pair_y_array[i]
-            self.axjoin.plot(pair_x, pair_y, linewidth=1, alpha=alpha_val, color='k')
-
-    def plot_marginal(self, var_names=None, data=None, iteration=-1,
-                      group='both',
-                      plot_trace=True, n_iterations=20,
-                      kind='kde',
-                      coords=None, credible_interval=.98,
-                      marginal_kwargs=None, marginal_kwargs_prior=None,
-                      joint_kwargs=None, joint_kwargs_prior=None):
-        
-        self.axjoin.clear()
-        self.ax_hist_x.clear()
-        self.ax_hist_y.clear()
-
-        if data is None:
-            data = self.data
-
-        valid_kinds = ["scatter", "kde", "hexbin"]
-        if kind not in valid_kinds:
-            raise ValueError(
-                ("Plot type {} not recognized." "Plot type must be in {}").format(kind, valid_kinds)
-            )
-
-        if coords is None:
-            coords = {}
-
-        if joint_kwargs is None:
-            joint_kwargs = {}
-
-        if marginal_kwargs is None:
-            marginal_kwargs = {}
-
-        data_0 = convert_to_dataset(data, group="posterior")
-        var_names = _var_names(var_names, data_0)
-
-        plotters = list(xarray_var_iter(get_coords(data_0, coords), var_names=var_names, combined=True))
-
-        if len(plotters) != 2:
-            raise Exception(
-                "Number of variables to be plotted must 2 (you supplied {})".format(len(plotters))
-            )
-
-        if kind == 'kde':
-            joint_kwargs.setdefault('contourf_kwargs', {})
-            joint_kwargs.setdefault('contour_kwargs', {})
-            joint_kwargs.setdefault('pcolormesh_kwargs', {})
-
-            joint_kwargs['contourf_kwargs'].setdefault('cmap', my_cmap_full_l_light)
-            joint_kwargs['contourf_kwargs'].setdefault('levels', 11)
-            joint_kwargs['contourf_kwargs'].setdefault('alpha', 1)
-            joint_kwargs['contour_kwargs'].setdefault('alpha', 0)
-
-            joint_kwargs['pcolormesh_kwargs'].setdefault('cmap', my_cmap_full_l_light)
-            joint_kwargs['pcolormesh_kwargs'].setdefault('alpha', 1)
-
-
-        marginal_kwargs.setdefault('fill_kwargs', {})
-        marginal_kwargs.setdefault("plot_kwargs", {})
-        marginal_kwargs["plot_kwargs"]["linewidth"] = self.linewidth
-
-        marginal_kwargs["plot_kwargs"].setdefault('color', default_l)
-        marginal_kwargs['fill_kwargs'].setdefault('color', default_l)
-        marginal_kwargs['fill_kwargs'].setdefault('alpha', .8)
-
-        if group == 'both' or group == 'posterior':
-
-            self.plot_joint_posterior(plotters, kind=kind, iteration=iteration, **joint_kwargs)
-            self.plot_marginal_posterior(plotters, iteration=iteration, **marginal_kwargs)
-
-        if group == 'both' or group == 'prior':
-            alpha_p = .8 if group == 'prior' else .5
-
-            if joint_kwargs_prior is None:
-                joint_kwargs_prior = {}
-
-            if marginal_kwargs_prior is None:
-                marginal_kwargs_prior = {}
-
-            marginal_kwargs_prior.setdefault('fill_kwargs', {})
-            marginal_kwargs_prior.setdefault("plot_kwargs", {})
-            marginal_kwargs_prior["plot_kwargs"]["linewidth"] = self.linewidth
-
-            if kind == 'kde':
-
-                joint_kwargs_prior.setdefault('contourf_kwargs', {})
-                joint_kwargs_prior.setdefault('contour_kwargs', {})
-                joint_kwargs_prior.setdefault('pcolormesh_kwargs', {})
-
-                joint_kwargs_prior['contourf_kwargs'].setdefault('cmap', my_cmap_full_light)
-                joint_kwargs_prior['contourf_kwargs'].setdefault('levels', 11)
-                joint_kwargs_prior['contourf_kwargs'].setdefault('alpha', alpha_p)
-                joint_kwargs_prior['contour_kwargs'].setdefault('alpha', 0)
-
-                joint_kwargs_prior['pcolormesh_kwargs'].setdefault('cmap', my_cmap_full_light)
-                joint_kwargs_prior['pcolormesh_kwargs'].setdefault('alpha', alpha_p)
-
-
-            marginal_kwargs_prior["plot_kwargs"].setdefault('color', default_blue)
-            marginal_kwargs_prior['fill_kwargs'].setdefault('color', default_blue)
-            marginal_kwargs_prior['fill_kwargs'].setdefault('alpha', alpha_p)
-
-            data_1 = convert_to_dataset(data, group="prior")
-            plotters_prior = list(xarray_var_iter(get_coords(data_1, coords), var_names=var_names, combined=True))
-
-            self.plot_joint_posterior(plotters_prior, kind=kind, **joint_kwargs_prior)
-            self.plot_marginal_posterior(plotters_prior, **marginal_kwargs_prior)
-
-            x_min, x_max, y_min, y_max = self.compute_hpd(plotters_prior, credible_interval=credible_interval)
-
-        else:
-            x_min, x_max, y_min, y_max = self.compute_hpd(plotters, iteration=iteration,
-                                                          credible_interval=credible_interval)
-        if plot_trace is True:
-            self.plot_trace(plotters, iteration, n_iterations)
-        
-        self.axjoin.set_xlim(x_min, x_max)
-        self.axjoin.set_ylim(y_min, y_max)
-        self.ax_hist_x.set_xlim(self.axjoin.get_xlim())
-        self.ax_hist_y.set_ylim(self.axjoin.get_ylim())
-
-        return self.axjoin, self.ax_hist_x, self.ax_hist_y
-
-    @staticmethod
-    def compute_hpd(plotters, iteration=-1, credible_interval=.98):
-        x = plotters[0][2].flatten()[:iteration]
-        y = plotters[1][2].flatten()[:iteration]
-        x_min, x_max = hpd(x, credible_interval=credible_interval)
-        y_min, y_max = hpd(y, credible_interval=credible_interval)
-        return x_min, x_max, y_min, y_max
-
-    def set_likelihood_limits(self, val, type):
-        val = np.repeat(np.atleast_1d(val), 1)
-
-        if type == 'x_max':
-            val = val + val * .2
-
-            try:
-                self._xma_list = np.append(self._xma_list[:25], val)
-                self.x_max_like = np.max(self._xma_list)
-            except AttributeError:
-                self._xma_list = val
-                self.x_max_like = np.max(self._xma_list)
-
-        if type == 'x_min':
-            val = val - val * .2
-
-            try:
-                self._xmi_list = np.append(self._xmi_list[:25], val)
-                self.x_min_like = np.min(self._xmi_list)
-            except AttributeError:
-                self._xmi_list = val
-                self.x_min_like = np.min(self._xmi_list)
-
-        if type == 'y_max':
-            try:
-                self._yma_list = np.append(self._yma_list[:25], val)
-                self.y_max_like = np.max(self._yma_list)
-            except AttributeError:
-                self._yma_list = val
-                self.y_max_like = np.max(self._yma_list)
-
-    def plot_normal_likelihood(self, mean:Union[str, float], std:Union[str, float], obs:Union[str, float],
-                               data=None, iteration=-1, x_range=None, color='auto', **kwargs):
-        self.likelihood_axes.clear()
-
-        x_limits = kwargs.get('x_limits', 4)
-
-        if data is None:
-            data = self.data
-
-        draw = data.posterior[{'chain':0, 'draw':iteration}]
-        draw_mu = draw[mean] if type(mean) is str else mean
-        draw_sigma = draw[std] if type(std) is str else std
-        obs = data.observed_data[obs] if type(obs) is str else obs
-
-        self.set_likelihood_limits(draw_mu + x_limits * draw_sigma, 'x_max')
-        self.set_likelihood_limits(draw_mu - x_limits * draw_sigma, 'x_min')
-
-        if x_range is not None:
-            thick_min = x_range[0]
-            thick_max = x_range[1]
-        else:
-            thick_max = self.x_max_like # draw_mu + 3 * draw_sigma
-            thick_min = self.x_min_like # draw_mu - 3 * draw_sigma
-
-        thick_vals = np.linspace(thick_min, thick_max, 100)
-        observation = np.asarray(obs)
-
-        thick_model = draw_mu
-        thick_std = draw_sigma
-
-        nor_l = stats.norm.pdf(thick_vals, loc=thick_model, scale=thick_std)
-        self.set_likelihood_limits(nor_l.max(), 'y_max')
-
-        likelihood_at_observation = stats.norm.pdf(observation, loc=thick_model, scale=thick_std)
-
-        if color == 'auto':
-            # This operations are for getting the same color in the likelihood plot as in the joy plot
-            self.cmap_l = self.create_color_map()
-            color_fill = self.evaluate_cmap(self.cmap_l, draw_mu, draw_sigma, obs)
-
-        elif color is None:
-            color_fill = default_l
-
-        else:
-            color_fill = color
-        y_min = (nor_l.min() - nor_l.max()) * .01
-        y_max = nor_l.max() + nor_l.max() * .05
-
-        # This is the bell
-
-        if not 'hide_bell' in kwargs:
-            self.likelihood_axes.plot(thick_vals, nor_l, color='#7eb1bc', linewidth=.5)
-            self.likelihood_axes.fill_between(thick_vals, nor_l, 0, color=color_fill, alpha=.8)
-
-        if not 'hide_bell' in kwargs and not 'hide_lines' in kwargs:
-            # This are the lines spawning from the observations
-            self.likelihood_axes.vlines(observation, 0.000000000001, likelihood_at_observation, linestyles='dashdot',
-                                        color='#DA8886', alpha=.5)
-
-            self.likelihood_axes.hlines(likelihood_at_observation, observation, thick_max,
-                                        linestyle='dashdot', color='#DA8886', alpha=.5)
-
-        # This are the observations         
-        observation_size = self.xt_labelsize * 3
-
-        self.likelihood_axes.scatter(observation, np.zeros_like(observation), s=observation_size, c='#DA8886')
-        self.likelihood_axes.set_ylim(y_min, y_max)
-        self.likelihood_axes.set_xlim(thick_min, thick_max)
-
-        # Make the axis sexy
-        self.likelihood_axes.spines['bottom'].set_position(('data', 0.0))
-        self.likelihood_axes.yaxis.tick_right()
-
-        self.likelihood_axes.spines['right'].set_position(('axes', 1.03))
-        self.likelihood_axes.spines['top'].set_color('none')
-        self.likelihood_axes.spines['left'].set_color('none')
-        self.likelihood_axes.set_xlabel('Thickness Obs.')
-        self.likelihood_axes.set_title('Likelihood')
-
-        # self.likelihood_axes.set_ylim(y_min, y_max)
-        self.likelihood_axes.set_xlim(thick_min, thick_max)
-
-       # self.likelihood_axes.set_xlim(self.x_min_like, self.x_max_like)
-        self.likelihood_axes.set_ylim(0, self.y_max_like)
-
-        return self.likelihood_axes, self.cmap_l
-
-    def plot_joy(self, var_names: tuple = None, obs: Union[str, float] = None,
-                 data=None, iteration=-1, samples_size=1000, cmap='auto'):
-        """
-
-        A0rgs:
-            var_names: mu and sigma of the likelihood!
-            obs:
-            data:
-            iteration:
-            samples_size:
-            cmap:
-
-        Returns:
-
-        """
-        try:
-            [i.clear() for i in self.joy]
-        except TypeError:
-            pass
-
-        n_iterations = self.n_samples
-        iteration_label = [None for i in range(self.n_samples)]
-
-        if data is None:
-            data = self.data
-
-        obs = data.observed_data[obs] if type(obs) is str else obs
-
-        data = convert_to_dataset(data, group="posterior")
-        coords = {}
-        var_names = _var_names(var_names, data)
-
-        plotters = list(
-            xarray_var_iter(get_coords(data, coords), var_names=var_names, combined=True))
-
-        x = plotters[0][2].flatten()
-        y = plotters[1][2].flatten()
-
-        n_data = x.shape[0]
-        # This is the special case if n_samples is smaller than the number of bells to plot
-        if iteration < self.n_samples / 2:
-            l_0 = 0
-            l_1 = int(self.n_samples)
-            iteration_label[-1] = 0
-            iteration_label[0] = l_1
-        elif iteration > n_data - self.n_samples/2:
-            l_0 = int(n_data - self.n_samples)
-            l_1 = n_data
-            iteration_label[-1] = l_0
-            iteration_label[0] = l_1
-        else:
-            l_0 = int(iteration - np.round(self.n_samples / 2)) + 1
-            l_1 = int(iteration + np.round(self.n_samples / 2))
-            iteration_label[-1] = l_0
-            iteration_label[int(np.round(self.n_samples / 2)) - 1] = iteration - 1
-            iteration_label[0] = l_1
-
-        x = x[l_0:l_1]
-        y = y[l_0:l_1]
-
-        self.set_likelihood_limits(x + 4 * y, 'x_max')
-        self.set_likelihood_limits(x - 4 * y, 'x_min')
-        df = pn.DataFrame()
-
-        color = []
-
-        for e in range(l_1-l_0):
-            e = -e - 1
-            num = np.random.normal(loc=x[e], scale=y[e], size=samples_size)
-            name = e + (iteration - int(n_iterations / 2))
-            df[name] = num
-
-            if obs is not None:
-                self.set_likelihood_limits(stats.norm.pdf(obs, loc=x[e], scale=y[e]), 'y_max')
-
-            if cmap is None:
-                color = default_blue
-            else:
-                if cmap == 'auto':
-                    if self.likelihood_axes is None:
-                        cmap = self.create_color_map()
-                    else:
-                        cmap = self.cmap_l
-
-                color.append(self.evaluate_cmap(cmap, x[e], y[e], obs))
-
-        if self.likelihood_axes is not None:
-            x_range = self.likelihood_axes.get_xlim()
-        else:
-            x_range = (self.x_min_like, self.x_max_like)
-        f, axes = joyplot(df, bw_method=1, labels=iteration_label, ax=self.joy,
-                          yrot=0,
-                          range_style='all', x_range=x_range,
-                          color=color,
-                          grid='y',
-                          fade=False, last_axis=False,
-                          linewidth=.1, alpha=1);
-
-        n_axes = len(axes[:-1])
-        if int(n_axes / 2) >= iteration:
-            ax_sel = axes[-iteration-1]
-            ax_sel.hlines(0, ax_sel.get_xlim()[0], ax_sel.get_xlim()[1], color='#DA8886', linewidth=3)
-        elif iteration > n_data - int(self.n_samples/2):
-            ax_sel = axes[-iteration-self.n_samples+n_data-1]
-            ax_sel.hlines(0, ax_sel.get_xlim()[0], ax_sel.get_xlim()[1], color='#DA8886', linewidth=3)
-        else:
-            ax_sel = axes[int(n_axes / 2)]
-            ax_sel.hlines(0, ax_sel.get_xlim()[0], ax_sel.get_xlim()[1], color='#DA8886', linewidth=3)
-
-        if obs is not None:
-            triangle_size = self.xt_labelsize*5
-
-            if self.likelihood_axes is None:
-                self.joy[0].scatter(obs, np.ones_like(obs) * self.joy[0].get_ylim()[1], marker='v',
-                                    s=triangle_size, c='#DA8886')
-            self.joy[-1].scatter(obs, np.ones_like(obs) * self.joy[-1].get_ylim()[0],
-                                 marker='^', s=triangle_size, c='#DA8886')
-
-        return axes
-
-    def plot_posterior(self, prior_var, like_var, obs, iteration=-1,
-                       marginal_kwargs=None, likelihood_kwargs=None, joy_kwargs = None):
-        if marginal_kwargs is None:
-            marginal_kwargs = {}
-        if likelihood_kwargs is None:
-            likelihood_kwargs = {}
-        if joy_kwargs is None:
-            joy_kwargs = {}
-
-        self.plot_marginal(prior_var, iteration=iteration, **marginal_kwargs)
-        _, cmap = self.plot_normal_likelihood(like_var[0], like_var[1], obs, iteration=iteration,
-                                                   **likelihood_kwargs)
-        self.plot_joy(like_var, obs=obs, iteration=iteration, **joy_kwargs)
+import numpy as np
+import pandas as pn
+import scipy.stats as stats
+from .joyplot import joyplot
+
+from typing import Union
+import matplotlib.gridspec as gridspect
+
+# Create cmap
+from matplotlib.colors import ListedColormap
+import matplotlib.pyplot as plt
+import matplotlib.colors as colors
+import matplotlib.cm as cmx
+import seaborn as sns
+from arviz.plots.jointplot import *
+from arviz.plots.plot_utils import make_label, _scale_fig_size
+from arviz import plot_kde, plot_dist
+from arviz.plots.jointplot import _var_names
+from arviz.plots.kdeplot import _fast_kde_2d
+from arviz.stats import hpd
+import arviz
+
+
+# Seaborn style
+sns.set(style="white", rc={"axes.facecolor": (0, 0, 0, 0)})
+
+# Discrete cmap
+    # seaborn palette
+pal_disc = sns.cubehelix_palette(10, rot=-.25, light=.7)
+pal_disc_l = sns.cubehelix_palette(10)
+
+    # matplotlib cmap
+my_cmap = ListedColormap(pal_disc)
+my_cmap_l = ListedColormap(pal_disc_l)
+
+# Continuous cmap
+    # seaborn palette
+pal_cont_light = sns.cubehelix_palette(250, rot=-.25, light=1)
+pal_cont = sns.cubehelix_palette(250, rot=-.25, light=.7)
+
+pal_cont_l = sns.cubehelix_palette(250)
+pal_cont_l_light = sns.cubehelix_palette(250, light=1)
+
+    # matplotlib cmap
+my_cmap_full = ListedColormap(pal_cont)
+my_cmap_full_light = ListedColormap(pal_cont_light)
+
+my_cmap_full_l = ListedColormap(pal_cont_l)
+my_cmap_full_l_light = ListedColormap(pal_cont_l_light)
+
+# Default individual colors
+default_red = '#DA8886'
+default_blue = pal_cont[50]
+default_l = pal_disc_l.as_hex()[4]
+
+
+class PlotPosterior:
+    def __init__(self, data: arviz.data.inference_data.InferenceData = None):
+        self.data = data
+        self.iteration = 1
+        self.likelihood_axes = None
+        self.marginal_axes = None
+        self.joy = None
+
+    def create_figure(self, marginal=True, likelihood=True, joyplot=True,
+                      figsize=None, textsize=None,
+                      n_samples=11):
+
+        figsize, self.ax_labelsize, _, self.xt_labelsize, self.linewidth, _ = _scale_fig_size(figsize, textsize)
+        self.fig = plt.figure(figsize=figsize, constrained_layout=False)
+        gs_0 = gridspect.GridSpec(3, 6, figure=self.fig, hspace=.1)
+
+        if marginal is True:
+            # Testing
+            if likelihood is False:
+                self.marginal_axes = self._create_joint_axis(figure=self.fig, subplot_spec=gs_0[0:2, 0:4])
+            elif likelihood is False and joyplot is False:
+                self.marginal_axes = self._create_joint_axis(figure=self.fig, subplot_spec=gs_0[:, :])
+    
+            else:
+                self.marginal_axes = self._create_joint_axis(figure=self.fig, subplot_spec=gs_0[0:2, 0:3])
+
+        if likelihood is True:
+            if marginal is False:
+                self.likelihood_axes = self._create_likelihood_axis(figure=self.fig, subplot_spec=gs_0[0:2, 0:4])
+            elif joyplot is False:
+                self.likelihood_axes = self._create_likelihood_axis(figure=self.fig, subplot_spec=gs_0[0:2, 4:])
+            else:
+                self.likelihood_axes = self._create_likelihood_axis(figure=self.fig, subplot_spec=gs_0[0:1, 4:])
+
+        if joyplot is True:
+            self.n_samples = n_samples
+            if marginal is False and likelihood is False:
+                self.joy = self._create_joy_axis(self.fig, gs_0[:, :])
+            else:
+                self.joy = self._create_joy_axis(self.fig, gs_0[1:2, 4:])
+
+    def _create_joint_axis(self, figure=None, subplot_spec=None, figsize=None, textsize=None):
+        figsize, ax_labelsize, _, xt_labelsize, linewidth, _ = _scale_fig_size(figsize, textsize)
+        # Instantiate figure and grid
+
+        if figure is None:
+            fig = plt.figure(figsize=figsize, constrained_layout=True)
+        else:
+            fig = figure
+
+        if subplot_spec is None:
+            grid = plt.GridSpec(4, 4, hspace=0.1, wspace=0.1, figure=fig)
+        else:
+            grid = gridspect.GridSpecFromSubplotSpec(4, 4, subplot_spec=subplot_spec)
+
+        # Set up main plot
+        self.axjoin = fig.add_subplot(grid[1:, :-1])
+
+        # Set up top KDE
+        self.ax_hist_x = fig.add_subplot(grid[0, :-1], sharex=self.axjoin)
+        self.ax_hist_x.tick_params(labelleft=False, labelbottom=False)
+
+        # Set up right KDE
+        self.ax_hist_y = fig.add_subplot(grid[1:, -1], sharey=self.axjoin)
+        self.ax_hist_y.tick_params(labelleft=False, labelbottom=False)
+        sns.despine(left=True, bottom=True)
+
+        return self.axjoin, self.ax_hist_x, self.ax_hist_y
+
+    def _create_likelihood_axis(self, figure=None, subplot_spec=None, **kwargs):
+        # Making the axes:
+        if figure is None:
+            figsize = kwargs.get('figsize', None)
+            fig = plt.figure(figsize=figsize, constrained_layout=False)
+        else:
+            fig = figure
+
+        if subplot_spec is None:
+            grid = plt.GridSpec(1, 1, hspace=0.1, wspace=0.1, figure=fig)
+        else:
+            grid = gridspect.GridSpecFromSubplotSpec(1, 1, subplot_spec=subplot_spec)
+
+        ax_like = fig.add_subplot(grid[0, 0])
+        ax_like.spines['bottom'].set_position(('data', 0.0))
+        ax_like.yaxis.tick_right()
+
+        ax_like.spines['right'].set_position(('axes', 1.03))
+        ax_like.spines['top'].set_color('none')
+        ax_like.spines['left'].set_color('none')
+        ax_like.set_xlabel('Observations')
+        ax_like.set_title('Likelihood')
+        return ax_like
+
+    def _create_joy_axis(self, figure=None, subplot_spec=None, n_samples=None, overlap=.85):
+        if n_samples is None:
+            n_samples = self.n_samples
+
+        grid = gridspect.GridSpecFromSubplotSpec(n_samples, 1, hspace=-overlap, subplot_spec=subplot_spec)
+        ax_joy = [figure.add_subplot(grid[i, 0]) for i in range(n_samples)]
+        ax_joy[0].set_title('Foo Likelihood')
+
+        return ax_joy
+
+    def create_color_map(self):
+        cNorm = colors.Normalize(0, self.y_max_like)
+        scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=my_cmap_full)
+        return scalarMap
+
+    def evaluate_cmap(self, cmap, draw_mu, draw_sigma, obs: Union[float, list] = None):
+        likelihood_at_observation = stats.norm.pdf(obs, loc=draw_mu, scale=draw_sigma)
+        color_fill = colors.to_hex(cmap.to_rgba(np.atleast_1d(likelihood_at_observation)[0]))
+        return color_fill
+
+    def plot_marginal_posterior(self, plotters, iteration=-1, **marginal_kwargs):
+        marginal_kwargs.setdefault("plot_kwargs", {})
+        marginal_kwargs["plot_kwargs"]["linewidth"] = self.linewidth
+        marginal_kwargs.setdefault('fill_kwargs', {})
+
+        marginal_kwargs["plot_kwargs"].setdefault('color', default_l)
+        marginal_kwargs['fill_kwargs'].setdefault('color', default_l)
+        marginal_kwargs['fill_kwargs'].setdefault('alpha', .8)
+
+        # Flatten data
+        x = plotters[0][2].flatten()[:iteration]
+        y = plotters[1][2].flatten()[:iteration]
+
+        for val, ax, rotate in ((x, self.ax_hist_x, False), (y, self.ax_hist_y, True)):
+            plot_dist(val, textsize=self.xt_labelsize, rotated=rotate, ax=ax, **marginal_kwargs)
+
+    def plot_joint_posterior(self, plotters, iteration=-1, kind='kde', **joint_kwargs):
+
+        # Set labels for axes
+        x_var_name = make_label(plotters[0][0], plotters[0][1])
+        y_var_name = make_label(plotters[1][0], plotters[1][1])
+
+        self.axjoin.set_xlabel(x_var_name, fontsize=self.ax_labelsize)
+        self.axjoin.set_ylabel(y_var_name, fontsize=self.ax_labelsize)
+        self.axjoin.tick_params(labelsize=self.xt_labelsize)
+
+        # Flatten data
+        x = plotters[0][2].flatten()[:iteration]
+        y = plotters[1][2].flatten()[:iteration]
+
+        if kind == "scatter":
+            self.axjoin.scatter(x, y, **joint_kwargs)
+        elif kind == "kde":
+            if False:
+                gridsize = (128, 128)# if contour else (256, 256)
+
+                density, xmin, xmax, ymin, ymax = _fast_kde_2d(x, y, gridsize=gridsize)
+
+             #   self.axjoin.scatter(x, y, density)
+                self.axjoin.imshow(density)
+            else:
+                if 'contour' not in joint_kwargs:
+                    joint_kwargs.setdefault('contour', True) 
+                fill_last = joint_kwargs.get('fill_last', False)
+                
+                try:
+                    self.foo = plot_kde(x, y, fill_last=fill_last, ax=self.axjoin, **joint_kwargs)
+                except ValueError:
+                    pass
+                except np.linalg.LinAlgError:
+                    pass
+        else:
+            gridsize = joint_kwargs.get('grid_size', 'auto')
+            if gridsize == "auto":
+                gridsize = int(len(x) ** 0.35)
+            self.axjoin.hexbin(x, y, mincnt=1, gridsize=gridsize, **joint_kwargs)
+            self.axjoin._grid(False)
+
+    def plot_trace(self, plotters, iteration, n_iterations=20):
+        i_0 = np.max([0, (iteration - n_iterations)])
+
+        theta1_val_trace = plotters[0][2].flatten()[i_0:iteration+1]
+        theta2_val_trace = plotters[1][2].flatten()[i_0:iteration+1]
+
+        theta1_val = theta1_val_trace[-1]
+        theta2_val = theta2_val_trace[-1]
+
+        # Plot point of the given iteration
+        self.axjoin.plot(theta1_val, theta2_val, 'bo', ms=6, color='k')
+
+        # Plot a trace of n_iterations
+        pair_x_array = np.vstack(
+            (theta1_val_trace[:-1], theta1_val_trace[1:])).T
+        pair_y_array = np.vstack((theta2_val_trace[:-1], theta2_val_trace[1:])).T
+        for i, pair_x in enumerate(pair_x_array):
+            alpha_val = i / pair_x_array.shape[0]
+            pair_y = pair_y_array[i]
+            self.axjoin.plot(pair_x, pair_y, linewidth=1, alpha=alpha_val, color='k')
+
+    def plot_marginal(self, var_names=None, data=None, iteration=-1,
+                      group='both',
+                      plot_trace=True, n_iterations=20,
+                      kind='kde',
+                      coords=None, credible_interval=.98,
+                      marginal_kwargs=None, marginal_kwargs_prior=None,
+                      joint_kwargs=None, joint_kwargs_prior=None):
+        
+        self.axjoin.clear()
+        self.ax_hist_x.clear()
+        self.ax_hist_y.clear()
+
+        if data is None:
+            data = self.data
+
+        valid_kinds = ["scatter", "kde", "hexbin"]
+        if kind not in valid_kinds:
+            raise ValueError(
+                ("Plot type {} not recognized." "Plot type must be in {}").format(kind, valid_kinds)
+            )
+
+        if coords is None:
+            coords = {}
+
+        if joint_kwargs is None:
+            joint_kwargs = {}
+
+        if marginal_kwargs is None:
+            marginal_kwargs = {}
+
+        data_0 = convert_to_dataset(data, group="posterior")
+        var_names = _var_names(var_names, data_0)
+
+        plotters = list(xarray_var_iter(get_coords(data_0, coords), var_names=var_names, combined=True))
+
+        if len(plotters) != 2:
+            raise Exception(
+                "Number of variables to be plotted must 2 (you supplied {})".format(len(plotters))
+            )
+
+        if kind == 'kde':
+            joint_kwargs.setdefault('contourf_kwargs', {})
+            joint_kwargs.setdefault('contour_kwargs', {})
+            joint_kwargs.setdefault('pcolormesh_kwargs', {})
+
+            joint_kwargs['contourf_kwargs'].setdefault('cmap', my_cmap_full_l_light)
+            joint_kwargs['contourf_kwargs'].setdefault('levels', 11)
+            joint_kwargs['contourf_kwargs'].setdefault('alpha', 1)
+            joint_kwargs['contour_kwargs'].setdefault('alpha', 0)
+
+            joint_kwargs['pcolormesh_kwargs'].setdefault('cmap', my_cmap_full_l_light)
+            joint_kwargs['pcolormesh_kwargs'].setdefault('alpha', 1)
+
+
+        marginal_kwargs.setdefault('fill_kwargs', {})
+        marginal_kwargs.setdefault("plot_kwargs", {})
+        marginal_kwargs["plot_kwargs"]["linewidth"] = self.linewidth
+
+        marginal_kwargs["plot_kwargs"].setdefault('color', default_l)
+        marginal_kwargs['fill_kwargs'].setdefault('color', default_l)
+        marginal_kwargs['fill_kwargs'].setdefault('alpha', .8)
+
+        if group == 'both' or group == 'posterior':
+
+            self.plot_joint_posterior(plotters, kind=kind, iteration=iteration, **joint_kwargs)
+            self.plot_marginal_posterior(plotters, iteration=iteration, **marginal_kwargs)
+
+        if group == 'both' or group == 'prior':
+            alpha_p = .8 if group == 'prior' else .5
+
+            if joint_kwargs_prior is None:
+                joint_kwargs_prior = {}
+
+            if marginal_kwargs_prior is None:
+                marginal_kwargs_prior = {}
+
+            marginal_kwargs_prior.setdefault('fill_kwargs', {})
+            marginal_kwargs_prior.setdefault("plot_kwargs", {})
+            marginal_kwargs_prior["plot_kwargs"]["linewidth"] = self.linewidth
+
+            if kind == 'kde':
+
+                joint_kwargs_prior.setdefault('contourf_kwargs', {})
+                joint_kwargs_prior.setdefault('contour_kwargs', {})
+                joint_kwargs_prior.setdefault('pcolormesh_kwargs', {})
+
+                joint_kwargs_prior['contourf_kwargs'].setdefault('cmap', my_cmap_full_light)
+                joint_kwargs_prior['contourf_kwargs'].setdefault('levels', 11)
+                joint_kwargs_prior['contourf_kwargs'].setdefault('alpha', alpha_p)
+                joint_kwargs_prior['contour_kwargs'].setdefault('alpha', 0)
+
+                joint_kwargs_prior['pcolormesh_kwargs'].setdefault('cmap', my_cmap_full_light)
+                joint_kwargs_prior['pcolormesh_kwargs'].setdefault('alpha', alpha_p)
+
+
+            marginal_kwargs_prior["plot_kwargs"].setdefault('color', default_blue)
+            marginal_kwargs_prior['fill_kwargs'].setdefault('color', default_blue)
+            marginal_kwargs_prior['fill_kwargs'].setdefault('alpha', alpha_p)
+
+            data_1 = convert_to_dataset(data, group="prior")
+            plotters_prior = list(xarray_var_iter(get_coords(data_1, coords), var_names=var_names, combined=True))
+
+            self.plot_joint_posterior(plotters_prior, kind=kind, **joint_kwargs_prior)
+            self.plot_marginal_posterior(plotters_prior, **marginal_kwargs_prior)
+
+            x_min, x_max, y_min, y_max = self.compute_hpd(plotters_prior, credible_interval=credible_interval)
+
+        else:
+            x_min, x_max, y_min, y_max = self.compute_hpd(plotters, iteration=iteration,
+                                                          credible_interval=credible_interval)
+        if plot_trace is True:
+            self.plot_trace(plotters, iteration, n_iterations)
+        
+        self.axjoin.set_xlim(x_min, x_max)
+        self.axjoin.set_ylim(y_min, y_max)
+        self.ax_hist_x.set_xlim(self.axjoin.get_xlim())
+        self.ax_hist_y.set_ylim(self.axjoin.get_ylim())
+
+        return self.axjoin, self.ax_hist_x, self.ax_hist_y
+
+    @staticmethod
+    def compute_hpd(plotters, iteration=-1, credible_interval=.98):
+        x = plotters[0][2].flatten()[:iteration]
+        y = plotters[1][2].flatten()[:iteration]
+        x_min, x_max = hpd(x, credible_interval=credible_interval)
+        y_min, y_max = hpd(y, credible_interval=credible_interval)
+        return x_min, x_max, y_min, y_max
+
+    def set_likelihood_limits(self, val, type):
+        val = np.repeat(np.atleast_1d(val), 1)
+
+        if type == 'x_max':
+            val = val + val * .2
+
+            try:
+                self._xma_list = np.append(self._xma_list[:25], val)
+                self.x_max_like = np.max(self._xma_list)
+            except AttributeError:
+                self._xma_list = val
+                self.x_max_like = np.max(self._xma_list)
+
+        if type == 'x_min':
+            val = val - val * .2
+
+            try:
+                self._xmi_list = np.append(self._xmi_list[:25], val)
+                self.x_min_like = np.min(self._xmi_list)
+            except AttributeError:
+                self._xmi_list = val
+                self.x_min_like = np.min(self._xmi_list)
+
+        if type == 'y_max':
+            try:
+                self._yma_list = np.append(self._yma_list[:25], val)
+                self.y_max_like = np.max(self._yma_list)
+            except AttributeError:
+                self._yma_list = val
+                self.y_max_like = np.max(self._yma_list)
+
+    def plot_normal_likelihood(self, mean:Union[str, float], std:Union[str, float], obs:Union[str, float],
+                               data=None, iteration=-1, x_range=None, color='auto', **kwargs):
+        self.likelihood_axes.clear()
+
+        x_limits = kwargs.get('x_limits', 4)
+
+        if data is None:
+            data = self.data
+
+        draw = data.posterior[{'chain':0, 'draw':iteration}]
+        draw_mu = draw[mean] if type(mean) is str else mean
+        draw_sigma = draw[std] if type(std) is str else std
+        obs = data.observed_data[obs] if type(obs) is str else obs
+
+        self.set_likelihood_limits(draw_mu + x_limits * draw_sigma, 'x_max')
+        self.set_likelihood_limits(draw_mu - x_limits * draw_sigma, 'x_min')
+
+        if x_range is not None:
+            thick_min = x_range[0]
+            thick_max = x_range[1]
+        else:
+            thick_max = self.x_max_like # draw_mu + 3 * draw_sigma
+            thick_min = self.x_min_like # draw_mu - 3 * draw_sigma
+
+        thick_vals = np.linspace(thick_min, thick_max, 100)
+        observation = np.asarray(obs)
+
+        thick_model = draw_mu
+        thick_std = draw_sigma
+
+        nor_l = stats.norm.pdf(thick_vals, loc=thick_model, scale=thick_std)
+        self.set_likelihood_limits(nor_l.max(), 'y_max')
+
+        likelihood_at_observation = stats.norm.pdf(observation, loc=thick_model, scale=thick_std)
+
+        if color == 'auto':
+            # This operations are for getting the same color in the likelihood plot as in the joy plot
+            self.cmap_l = self.create_color_map()
+            color_fill = self.evaluate_cmap(self.cmap_l, draw_mu, draw_sigma, obs)
+
+        elif color is None:
+            color_fill = default_l
+
+        else:
+            color_fill = color
+        y_min = (nor_l.min() - nor_l.max()) * .01
+        y_max = nor_l.max() + nor_l.max() * .05
+
+        # This is the bell
+
+        if not 'hide_bell' in kwargs:
+            self.likelihood_axes.plot(thick_vals, nor_l, color='#7eb1bc', linewidth=.5)
+            self.likelihood_axes.fill_between(thick_vals, nor_l, 0, color=color_fill, alpha=.8)
+
+        if not 'hide_bell' in kwargs and not 'hide_lines' in kwargs:
+            # This are the lines spawning from the observations
+            self.likelihood_axes.vlines(observation, 0.000000000001, likelihood_at_observation, linestyles='dashdot',
+                                        color='#DA8886', alpha=.5)
+
+            self.likelihood_axes.hlines(likelihood_at_observation, observation, thick_max,
+                                        linestyle='dashdot', color='#DA8886', alpha=.5)
+
+        # This are the observations         
+        observation_size = self.xt_labelsize * 3
+
+        self.likelihood_axes.scatter(observation, np.zeros_like(observation), s=observation_size, c='#DA8886')
+        self.likelihood_axes.set_ylim(y_min, y_max)
+        self.likelihood_axes.set_xlim(thick_min, thick_max)
+
+        # Make the axis sexy
+        self.likelihood_axes.spines['bottom'].set_position(('data', 0.0))
+        self.likelihood_axes.yaxis.tick_right()
+
+        self.likelihood_axes.spines['right'].set_position(('axes', 1.03))
+        self.likelihood_axes.spines['top'].set_color('none')
+        self.likelihood_axes.spines['left'].set_color('none')
+        self.likelihood_axes.set_xlabel('Observations')
+        self.likelihood_axes.set_title('Likelihood')
+
+        # self.likelihood_axes.set_ylim(y_min, y_max)
+        self.likelihood_axes.set_xlim(thick_min, thick_max)
+
+       # self.likelihood_axes.set_xlim(self.x_min_like, self.x_max_like)
+        self.likelihood_axes.set_ylim(0, self.y_max_like)
+
+        return self.likelihood_axes, self.cmap_l
+
+    def plot_joy(self, var_names: tuple = None, obs: Union[str, float] = None,
+                 data=None, iteration=-1, samples_size=1000, cmap='auto'):
+        """
+
+        A0rgs:
+            var_names: mu and sigma of the likelihood!
+            obs:
+            data:
+            iteration:
+            samples_size:
+            cmap:
+
+        Returns:
+
+        """
+        try:
+            [i.clear() for i in self.joy]
+        except TypeError:
+            pass
+
+        n_iterations = self.n_samples
+        iteration_label = [None for i in range(self.n_samples)]
+
+        if data is None:
+            data = self.data
+
+        obs = data.observed_data[obs] if type(obs) is str else obs
+
+        data = convert_to_dataset(data, group="posterior")
+        coords = {}
+        var_names = _var_names(var_names, data)
+
+        plotters = list(
+            xarray_var_iter(get_coords(data, coords), var_names=var_names, combined=True))
+
+        x = plotters[0][2].flatten()
+        y = plotters[1][2].flatten()
+
+        n_data = x.shape[0]
+        # This is the special case if n_samples is smaller than the number of bells to plot
+        if iteration < self.n_samples / 2:
+            l_0 = 0
+            l_1 = int(self.n_samples)
+            iteration_label[-1] = 0
+            iteration_label[0] = l_1
+        elif iteration > n_data - self.n_samples/2:
+            l_0 = int(n_data - self.n_samples)
+            l_1 = n_data
+            iteration_label[-1] = l_0
+            iteration_label[0] = l_1
+        else:
+            l_0 = int(iteration - np.round(self.n_samples / 2)) + 1
+            l_1 = int(iteration + np.round(self.n_samples / 2))
+            iteration_label[-1] = l_0
+            iteration_label[int(np.round(self.n_samples / 2)) - 1] = iteration - 1
+            iteration_label[0] = l_1
+
+        x = x[l_0:l_1]
+        y = y[l_0:l_1]
+
+        self.set_likelihood_limits(x + 4 * y, 'x_max')
+        self.set_likelihood_limits(x - 4 * y, 'x_min')
+        df = pn.DataFrame()
+
+        color = []
+
+        for e in range(l_1-l_0):
+            e = -e - 1
+            num = np.random.normal(loc=x[e], scale=y[e], size=samples_size)
+            name = e + (iteration - int(n_iterations / 2))
+            df[name] = num
+
+            if obs is not None:
+                self.set_likelihood_limits(stats.norm.pdf(obs, loc=x[e], scale=y[e]), 'y_max')
+
+            if cmap is None:
+                color = default_blue
+            else:
+                if cmap == 'auto':
+                    if self.likelihood_axes is None:
+                        cmap = self.create_color_map()
+                    else:
+                        cmap = self.cmap_l
+
+                color.append(self.evaluate_cmap(cmap, x[e], y[e], obs))
+
+        if self.likelihood_axes is not None:
+            x_range = self.likelihood_axes.get_xlim()
+        else:
+            x_range = (self.x_min_like, self.x_max_like)
+        f, axes = joyplot(df, bw_method=1, labels=iteration_label, ax=self.joy,
+                          yrot=0,
+                          range_style='all', x_range=x_range,
+                          color=color,
+                          grid='y',
+                          fade=False, last_axis=False,
+                          linewidth=.1, alpha=1);
+
+        n_axes = len(axes[:-1])
+        if int(n_axes / 2) >= iteration:
+            ax_sel = axes[-iteration-1]
+            ax_sel.hlines(0, ax_sel.get_xlim()[0], ax_sel.get_xlim()[1], color='#DA8886', linewidth=3)
+        elif iteration > n_data - int(self.n_samples/2):
+            ax_sel = axes[-iteration-self.n_samples+n_data-1]
+            ax_sel.hlines(0, ax_sel.get_xlim()[0], ax_sel.get_xlim()[1], color='#DA8886', linewidth=3)
+        else:
+            ax_sel = axes[int(n_axes / 2)]
+            ax_sel.hlines(0, ax_sel.get_xlim()[0], ax_sel.get_xlim()[1], color='#DA8886', linewidth=3)
+
+        if obs is not None:
+            triangle_size = self.xt_labelsize*5
+
+            if self.likelihood_axes is None:
+                self.joy[0].scatter(obs, np.ones_like(obs) * self.joy[0].get_ylim()[1], marker='v',
+                                    s=triangle_size, c='#DA8886')
+            self.joy[-1].scatter(obs, np.ones_like(obs) * self.joy[-1].get_ylim()[0],
+                                 marker='^', s=triangle_size, c='#DA8886')
+
+        return axes
+
+    def plot_posterior(self, prior_var, like_var, obs, iteration=-1,
+                       marginal_kwargs=None, likelihood_kwargs=None, joy_kwargs = None):
+        if marginal_kwargs is None:
+            marginal_kwargs = {}
+        if likelihood_kwargs is None:
+            likelihood_kwargs = {}
+        if joy_kwargs is None:
+            joy_kwargs = {}
+
+        self.plot_marginal(prior_var, iteration=iteration, **marginal_kwargs)
+        _, cmap = self.plot_normal_likelihood(like_var[0], like_var[1], obs, iteration=iteration,
+                                                   **likelihood_kwargs)
+        self.plot_joy(like_var, obs=obs, iteration=iteration, **joy_kwargs)
```

### Comparing `gempy-2.2b10.dev1/gempy/bayesian/posterior_analysis_elisa.py` & `gempy-2.3.0/gempy/bayesian/posterior_analysis_elisa.py`

 * *Ordering differences only*

 * *Files 17% similar despite different names*

```diff
@@ -1,206 +1,206 @@
-"""
-    This file is part of gempy.
-
-    gempy is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    gempy is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
-
-
-    @author: Elisa Heim, Alexander Schaaf, Miguel de la Varga
-    (I guess, copied some code from posterior_analysis_DEP.py)
-"""
-
-import warnings
-try:
-    import pymc
-except ImportError:
-    warnings.warn("pymc (v2) package is not installed. No support for stochastic simulation posterior analysis.")
-import numpy as np
-import pandas as pn
-import gempy as gp
-try:
-    import tqdm
-except ImportError:
-    warnings.warn("tqdm package not installed. No support for dynamic progress bars.")
-import matplotlib.pyplot as plt
-from mpl_toolkits import axes_grid1
-import matplotlib.colors
-
-
-class Posterior():
-    def __init__(self, dbname, model_type='map', entropy=False,
-                 topography=None, interpdata=None, geodata=None):
-
-        if entropy:
-            print('All post models are calculated. Based on the model complexity and the number of iterations, '
-                  'this could take a while')
-        # if topography:
-        self.topography = topography
-        # else:
-        # print('no topography defined. Methods that contain the word _map_ are not available')
-
-        self.interp_data = interpdata
-
-        self.geo_data = geodata
-        # self.verbose = verbose
-
-        self.db = pymc.database.hdf5.load(dbname)  # load database
-        self.n_iter = self.db.getstate()['sampler']['_iter'] - self.db.getstate()["sampler"]["_burn"]
-        self.trace_names = self.db.trace_names[0]
-        self.input_data = self.db.input_data.gettrace()
-
-        if entropy:
-            if topography and model_type == 'map':  # better resolution
-                self.all_maps = self.all_post_maps()
-                self.map_prob = self.compute_prob(np.round(self.all_maps).astype(int))
-                self.map_ie = self.calculate_ie_masked(self.map_prob)
-
-            elif model_type == 'model':
-                self.lbs, self.fbs = self.all_post_models()
-
-                if len(self.lbs) != 0:
-                    self.lith_prob = self.compute_prob(np.round(self.lbs).astype(int))
-                    self.lb_ie = self.calculate_ie_masked(self.lith_prob)
-
-                if len(self.fbs) != 0:
-                    self.fault_prob = self.compute_prob(np.round(self.fbs).astype(int))
-                    self.fb_ie = self.calculate_ie_masked(self.fault_prob)
-            else:
-                print('if there is no topography defined, model_type must be set to model')
-            # self.ie_total = self.calculate_ie_total()
-
-    def _change_input_data(self, i):
-        i = int(i)
-        # replace interface data
-        self.interp_data.geo_data_res.interfaces[["X", "Y", "Z"]] = self.input_data[i][0]
-        # replace foliation data
-        self.interp_data.geo_data_res._orientations[["G_x", "G_y", "G_z", "X", "Y", "Z", "dip", "azimuth", "polarity"]] = \
-            self.input_data[i][1]
-        self.interp_data.update_interpolator()
-        # if self.verbose:
-        # print("interp_data parameters changed.")
-        return self.interp_data
-
-    def all_post_maps(self):
-        all_maps = []
-        for i in range(0, self.n_iter):
-            # print(i)
-            self._change_input_data(i)
-            # geomap = self.topography.calculate_geomap(interpdata = self.interp_data, plot=True)
-            geomap, faultmap = gp.compute_model_at(self.topography.surface_coordinates[0], self.interp_data)
-            all_maps.insert(i, geomap[0])
-        return all_maps
-
-    def all_post_models(self):
-        lbs = []
-        fbs = []
-        for i in range(0, self.n_iter):
-            # print(i)
-            self._change_input_data(i)
-            lith_block, fault_block = gp.compute_model(self.interp_data)
-            if lith_block.shape[0] != 0:
-                lbs.insert(i, lith_block[0])
-            if fault_block.shape[0] != 0:
-                n = 0
-                while n < fault_block.shape[0]:
-                    # print(fault_block.shape[0])
-                    fbs.insert(i, fault_block[n])
-                    n += 2
-        return lbs, fbs
-
-    def compute_prob(self, blocks):
-        lith_id = np.unique(blocks)
-        # lith_count = np.zeros_like(lith_blocks[0:len(lith_id)])
-        count = np.zeros((len(np.unique(blocks)), blocks.shape[1]))
-        for i, l_id in enumerate(lith_id):
-            count[i] = np.sum(blocks == l_id, axis=0)
-        prob = count / len(blocks)
-        # print(lith_prob)
-        return prob
-
-    def calculate_ie_masked(self, prob):
-        ie = np.zeros_like(prob[0])
-        for l in prob:
-            pm = np.ma.masked_equal(l, 0)  # mask where prob is 0
-            ie -= (pm * np.ma.log2(pm)).filled(0)
-        return ie
-
-    def calculate_ie_total(self, ie, absolute=False):
-        if absolute:
-            return np.sum(ie)
-        else:
-            return np.sum(ie) / np.size(ie)
-
-        ##### plotting methods #####
-
-    def plot_section(self, iteration=1, block='lith', cell_number=3, **kwargs):
-        '''kwargs: gempy.plotting.plot_section keyword arguments'''
-        self._change_input_data(iteration)
-        lith_block, fault_block = gp.compute_model(self.interp_data)
-
-        if 'topography' not in kwargs:
-            if self.topography:
-                topography = self.topography
-            else:
-                topography = None
-            if block == 'lith':
-                gp.plot_section(self.geo_data, lith_block[0], cell_number=cell_number, topography=topography, **kwargs)
-            else:
-                gp.plot_section(self.geo_data, block, cell_number=cell_number, topography=topography, **kwargs)
-
-        else:
-            if block == 'lith':
-                gp.plot_section(self.geo_data, lith_block[0], cell_number=cell_number, **kwargs)
-            else:
-                gp.plot_section(self.geo_data, block, cell_number=cell_number, **kwargs)
-
-    def plot_map(self, iteration=1, **kwargs):
-        self._change_input_data(iteration)
-        # geomap = self.topography.calculate_geomap(interpdata = self.interp_data, plot=True)
-        geomap, faultmap = gp.compute_model_at(self.topography.surface_coordinates[0], self.interp_data)
-        # gp.plotting.plot_map(geomap)
-        gp.plotting.plot_map(self.geo_data, geomap=geomap[0].reshape(self.topography.dem_zval.shape), **kwargs)
-
-    def plot_map_ie(self, plot_data=False):
-        if plot_data:
-            gp.plotting.plot_data(geo_data, direction='z')
-            dist = 12
-        else:
-            dist = 1
-
-        im = plt.imshow(self.map_ie.reshape(self.topography.dem_zval.shape), extent=self.geo_data.extent[:4],
-                        cmap='viridis')
-        self.add_colorbar(im, pad_fraction=dist)
-        plt.title('Cell entropy of geological map')
-
-    def plot_section_ie(self, block='lith', cell_number=10, direction='y', **kwargs):
-        # for lithblock
-        if block == 'lith':
-            norm = matplotlib.colors.Normalize(self.lb_ie.min(), self.lb_ie.max())
-            gp.plotting.plot_section(geo_data, self.lb_ie, cell_number=cell_number, direction=direction, cmap='viridis',
-                                     norm=norm, **kwargs)
-            # self.add_colorbar(im)
-        elif block == 'fault':
-            norm = matplotlib.colors.Normalize(self.fb_ie.min(), self.fb_ie.max())
-            gp.plotting.plot_section(geo_data, self.fb_ie, cell_number=cell_number, direction=direction, cmap='viridis',
-                                     norm=norm, **kwargs)
-            # self.add_colorbar(im)
-
-    def add_colorbar(self, im, aspect=20, pad_fraction=1, **kwargs):
-        """Add a vertical color bar to an image plot. Source: stackoverflow"""
-        divider = axes_grid1.make_axes_locatable(im.axes)
-        width = axes_grid1.axes_size.AxesY(im.axes, aspect=2. / aspect)
-        pad = axes_grid1.axes_size.Fraction(pad_fraction, width)
-        current_ax = plt.gca()
-        cax = divider.append_axes("right", size=width, pad=pad)
-        plt.sca(current_ax)
-        return im.axes.figure.colorbar(im, cax=cax, **kwargs)
+"""
+    This file is part of gempy.
+
+    gempy is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    gempy is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
+
+
+    @author: Elisa Heim, Alexander Schaaf, Miguel de la Varga
+    (I guess, copied some code from posterior_analysis_DEP.py)
+"""
+
+import warnings
+try:
+    import pymc
+except ImportError:
+    warnings.warn("pymc (v2) package is not installed. No support for stochastic simulation posterior analysis.")
+import numpy as np
+import pandas as pn
+import gempy as gp
+try:
+    import tqdm
+except ImportError:
+    warnings.warn("tqdm package not installed. No support for dynamic progress bars.")
+import matplotlib.pyplot as plt
+from mpl_toolkits import axes_grid1
+import matplotlib.colors
+
+
+class Posterior():
+    def __init__(self, dbname, model_type='map', entropy=False,
+                 topography=None, interpdata=None, geodata=None):
+
+        if entropy:
+            print('All post models are calculated. Based on the model complexity and the number of iterations, '
+                  'this could take a while')
+        # if topography:
+        self.topography = topography
+        # else:
+        # print('no topography defined. Methods that contain the word _map_ are not available')
+
+        self.interp_data = interpdata
+
+        self.geo_data = geodata
+        # self.verbose = verbose
+
+        self.db = pymc.database.hdf5.load(dbname)  # load database
+        self.n_iter = self.db.getstate()['sampler']['_iter'] - self.db.getstate()["sampler"]["_burn"]
+        self.trace_names = self.db.trace_names[0]
+        self.input_data = self.db.input_data.gettrace()
+
+        if entropy:
+            if topography and model_type == 'map':  # better resolution
+                self.all_maps = self.all_post_maps()
+                self.map_prob = self.compute_prob(np.round(self.all_maps).astype(int))
+                self.map_ie = self.calculate_ie_masked(self.map_prob)
+
+            elif model_type == 'model':
+                self.lbs, self.fbs = self.all_post_models()
+
+                if len(self.lbs) != 0:
+                    self.lith_prob = self.compute_prob(np.round(self.lbs).astype(int))
+                    self.lb_ie = self.calculate_ie_masked(self.lith_prob)
+
+                if len(self.fbs) != 0:
+                    self.fault_prob = self.compute_prob(np.round(self.fbs).astype(int))
+                    self.fb_ie = self.calculate_ie_masked(self.fault_prob)
+            else:
+                print('if there is no topography defined, model_type must be set to model')
+            # self.ie_total = self.calculate_ie_total()
+
+    def _change_input_data(self, i):
+        i = int(i)
+        # replace interface data
+        self.interp_data.geo_data_res.interfaces[["X", "Y", "Z"]] = self.input_data[i][0]
+        # replace foliation data
+        self.interp_data.geo_data_res._orientations[["G_x", "G_y", "G_z", "X", "Y", "Z", "dip", "azimuth", "polarity"]] = \
+            self.input_data[i][1]
+        self.interp_data.update_interpolator()
+        # if self.verbose:
+        # print("interp_data parameters changed.")
+        return self.interp_data
+
+    def all_post_maps(self):
+        all_maps = []
+        for i in range(0, self.n_iter):
+            # print(i)
+            self._change_input_data(i)
+            # geomap = self.topography.calculate_geomap(interpdata = self.interp_data, plot=True)
+            geomap, faultmap = gp.compute_model_at(self.topography.surface_coordinates[0], self.interp_data)
+            all_maps.insert(i, geomap[0])
+        return all_maps
+
+    def all_post_models(self):
+        lbs = []
+        fbs = []
+        for i in range(0, self.n_iter):
+            # print(i)
+            self._change_input_data(i)
+            lith_block, fault_block = gp.compute_model(self.interp_data)
+            if lith_block.shape[0] != 0:
+                lbs.insert(i, lith_block[0])
+            if fault_block.shape[0] != 0:
+                n = 0
+                while n < fault_block.shape[0]:
+                    # print(fault_block.shape[0])
+                    fbs.insert(i, fault_block[n])
+                    n += 2
+        return lbs, fbs
+
+    def compute_prob(self, blocks):
+        lith_id = np.unique(blocks)
+        # lith_count = np.zeros_like(lith_blocks[0:len(lith_id)])
+        count = np.zeros((len(np.unique(blocks)), blocks.shape[1]))
+        for i, l_id in enumerate(lith_id):
+            count[i] = np.sum(blocks == l_id, axis=0)
+        prob = count / len(blocks)
+        # print(lith_prob)
+        return prob
+
+    def calculate_ie_masked(self, prob):
+        ie = np.zeros_like(prob[0])
+        for l in prob:
+            pm = np.ma.masked_equal(l, 0)  # mask where prob is 0
+            ie -= (pm * np.ma.log2(pm)).filled(0)
+        return ie
+
+    def calculate_ie_total(self, ie, absolute=False):
+        if absolute:
+            return np.sum(ie)
+        else:
+            return np.sum(ie) / np.size(ie)
+
+        ##### plotting methods #####
+
+    def plot_section(self, iteration=1, block='lith', cell_number=3, **kwargs):
+        '''kwargs: gempy.plotting.plot_section keyword arguments'''
+        self._change_input_data(iteration)
+        lith_block, fault_block = gp.compute_model(self.interp_data)
+
+        if 'topography' not in kwargs:
+            if self.topography:
+                topography = self.topography
+            else:
+                topography = None
+            if block == 'lith':
+                gp.plot_section(self.geo_data, lith_block[0], cell_number=cell_number, topography=topography, **kwargs)
+            else:
+                gp.plot_section(self.geo_data, block, cell_number=cell_number, topography=topography, **kwargs)
+
+        else:
+            if block == 'lith':
+                gp.plot_section(self.geo_data, lith_block[0], cell_number=cell_number, **kwargs)
+            else:
+                gp.plot_section(self.geo_data, block, cell_number=cell_number, **kwargs)
+
+    def plot_map(self, iteration=1, **kwargs):
+        self._change_input_data(iteration)
+        # geomap = self.topography.calculate_geomap(interpdata = self.interp_data, plot=True)
+        geomap, faultmap = gp.compute_model_at(self.topography.surface_coordinates[0], self.interp_data)
+        # gp.plotting.plot_map(geomap)
+        gp.plotting.plot_map(self.geo_data, geomap=geomap[0].reshape(self.topography.dem_zval.shape), **kwargs)
+
+    def plot_map_ie(self, plot_data=False):
+        if plot_data:
+            gp.plotting.plot_data(geo_data, direction='z')
+            dist = 12
+        else:
+            dist = 1
+
+        im = plt.imshow(self.map_ie.reshape(self.topography.dem_zval.shape), extent=self.geo_data.extent[:4],
+                        cmap='viridis')
+        self.add_colorbar(im, pad_fraction=dist)
+        plt.title('Cell entropy of geological map')
+
+    def plot_section_ie(self, block='lith', cell_number=10, direction='y', **kwargs):
+        # for lithblock
+        if block == 'lith':
+            norm = matplotlib.colors.Normalize(self.lb_ie.min(), self.lb_ie.max())
+            gp.plotting.plot_section(geo_data, self.lb_ie, cell_number=cell_number, direction=direction, cmap='viridis',
+                                     norm=norm, **kwargs)
+            # self.add_colorbar(im)
+        elif block == 'fault':
+            norm = matplotlib.colors.Normalize(self.fb_ie.min(), self.fb_ie.max())
+            gp.plotting.plot_section(geo_data, self.fb_ie, cell_number=cell_number, direction=direction, cmap='viridis',
+                                     norm=norm, **kwargs)
+            # self.add_colorbar(im)
+
+    def add_colorbar(self, im, aspect=20, pad_fraction=1, **kwargs):
+        """Add a vertical color bar to an image plot. Source: stackoverflow"""
+        divider = axes_grid1.make_axes_locatable(im.axes)
+        width = axes_grid1.axes_size.AxesY(im.axes, aspect=2. / aspect)
+        pad = axes_grid1.axes_size.Fraction(pad_fraction, width)
+        current_ax = plt.gca()
+        cax = divider.append_axes("right", size=width, pad=pad)
+        plt.sca(current_ax)
+        return im.axes.figure.colorbar(im, cax=cax, **kwargs)
```

### Comparing `gempy-2.2b10.dev1/gempy/core/checkers.py` & `gempy-2.3.0/gempy/core/checkers.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,54 +1,54 @@
-# TODO
-# - Check the basement layer is not in in SurfacePoints and Orientations
-
-import pandas as pn
-import numpy as np
-
-def check_for_nans(array_like):
-    if ~(pn.notnull(np.atleast_1d(array_like))).any():
-        array_like = None
-    return array_like
-
-
-def check_for_nans_input_theano():
-    pass
-
-
-def check_kriging():
-    # TODO check range and covariance are not 0
-    pass
-
-def check_faults_are_set():
-    pass
-
-def check_fault_relations(self):
-    # Method to check that only older df offset newer ones?
-    #
-    # try:
-    #     # Check if there is already a categories_df
-    #     self.df
-    #
-    #     try:
-    #         if any(self.df.columns != series.columns):
-    #             series_fault = self.count_faults()
-    #             self.df = pn.DataFrame(index=series.columns, columns=['isFault'])
-    #             self.df['isFault'] = self.df.index.isin(series_fault)
-    #     except ValueError:
-    #         series_fault = self.count_faults()
-    #         self.df = pn.DataFrame(index=series.columns, columns=['isFault'])
-    #         self.df['isFault'] = self.df.index.isin(series_fault)
-    #
-    #     if series_fault:
-    #         self.df['isFault'] = self.df.index.isin(series_fault)
-    #
-    # except AttributeError:
-    #
-    #     if not series_fault:
-    #         series_fault = self.count_faults()
-    #         self.df = pn.DataFrame(index=series.columns, columns=['isFault'])
-    #         self.df['isFault'] = self.df.index.isin(series_fault)
-
-    # self.surface_points.loc[:, 'isFault'] = self.surface_points['series'].isin(self.df.index[self.df['isFault']])
-    # self.orientations.loc[:, 'isFault'] = self.orientations['series'].isin(
-    #     self.df.index[self.df['isFault']])
+# TODO
+# - Check the basement layer is not in in SurfacePoints and Orientations
+
+import pandas as pn
+import numpy as np
+
+def check_for_nans(array_like):
+    if ~(pn.notnull(np.atleast_1d(array_like))).any():
+        array_like = None
+    return array_like
+
+
+def check_for_nans_input_aesara():
+    pass
+
+
+def check_kriging():
+    # TODO check range and covariance are not 0
+    pass
+
+def check_faults_are_set():
+    pass
+
+def check_fault_relations(self):
+    # Method to check that only older df offset newer ones?
+    #
+    # try:
+    #     # Check if there is already a categories_df
+    #     self.df
+    #
+    #     try:
+    #         if any(self.df.columns != series.columns):
+    #             series_fault = self.count_faults()
+    #             self.df = pn.DataFrame(index=series.columns, columns=['isFault'])
+    #             self.df['isFault'] = self.df.index.isin(series_fault)
+    #     except ValueError:
+    #         series_fault = self.count_faults()
+    #         self.df = pn.DataFrame(index=series.columns, columns=['isFault'])
+    #         self.df['isFault'] = self.df.index.isin(series_fault)
+    #
+    #     if series_fault:
+    #         self.df['isFault'] = self.df.index.isin(series_fault)
+    #
+    # except AttributeError:
+    #
+    #     if not series_fault:
+    #         series_fault = self.count_faults()
+    #         self.df = pn.DataFrame(index=series.columns, columns=['isFault'])
+    #         self.df['isFault'] = self.df.index.isin(series_fault)
+
+    # self.surface_points.loc[:, 'isFault'] = self.surface_points['series'].isin(self.df.index[self.df['isFault']])
+    # self.orientations.loc[:, 'isFault'] = self.orientations['series'].isin(
+    #     self.df.index[self.df['isFault']])
     pass
```

### Comparing `gempy-2.2b10.dev1/gempy/core/data.py` & `gempy-2.3.0/gempy/core/aesara_modules/aesara_export.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,1362 +1,1261 @@
-import re
-import sys
-import warnings
-from typing import Union, List
+"""
+    This file is part of gempy.
 
+    gempy is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    gempy is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
+
+
+DEP-- I need to update this string
+Function that generates the symbolic code to perform the interpolation. Calling this function creates
+ both the aesara functions for the potential field and the block.
+
+Returns:
+    aesara function for the potential field
+    aesara function for the block
+"""
+import aesara
+import aesara.tensor  as T
 import numpy as np
-import pandas as pn
-import seaborn as sns
-
-try:
-    import ipywidgets as widgets
-
-    ipywidgets_import = True
-except ModuleNotFoundError:
-    VTK_IMPORT = False
-
-# This is for sphenix to find the packages
-from gempy.core.grid_modules import grid_types
-from gempy.core.grid_modules import topography
-from gempy.utils.meta import _setdoc, _setdoc_pro
-import gempy.utils.docstring as ds
-from IPython.display import display
-
-pn.options.mode.chained_assignment = None
-
-
-class MetaData(object):
-    """Class containing metadata of the project.
-
-    Set of attributes and methods that are not related directly to the geological model but more with the project
-
-    Args:
-        project_name (str): Name of the project. This is used as the default value for some I/O actions
-
-    Attributes:
-        date (str): Time of the creation of the project
-        project_name (str): Name of the project. This is used as the default value for some I/O actions
-
-    """
-
-    def __init__(self, project_name='default_project'):
-        import datetime
-        now = datetime.datetime.now()
-        self.date = now.strftime(" %Y-%m-%d %H:%M")
-
-        if project_name == 'default_project':
-            project_name += self.date
-
-        self.project_name = project_name
-
-
-@_setdoc_pro([grid_types.RegularGrid.__doc__, grid_types.CustomGrid.__doc__])
-class Grid(object):
-    """ Class to generate grids.
-
-    This class is used to create points to evaluate the geological model. 
-    This class serves a container which transmits the XYZ coordinates to the
-    interpolator. There are several type of grid objects feeding into the Grid class
-
-    Args:
-         **kwargs: See below
-
-    Keyword Args:
-         regular (:class:`gempy.core.grid_modules.grid_types.RegularGrid`): [s0]
-         custom (:class:`gempy.core.grid_modules.grid_types.CustomGrid`): [s1]
-         topography (:class:`gempy.core.grid_modules.grid_types.Topography`): [s2]
-         sections (:class:`gempy.core.grid_modules.grid_types.Sections`): [s3]
-         gravity (:class:`gempy.core.grid_modules.grid_types.Gravity`):
-
-    Attributes:
-        values (np.ndarray): coordinates where the model is going to be evaluated. This is the coordinates
-         concatenation of all active grids.
-        values_r (np.ndarray): rescaled coordinates where the model is going to be evaluated
-        length (np.ndarray):I a array which contain the slicing index for each grid type in order. The first element will
-         be 0, the second the length of the regular grid; the third custom and so on. This can be used to slice the
-         solutions correspondent to each of the grids
-        grid_types(np.ndarray[str]): names of the current grids of GemPy
-        active_grids(np.ndarray[bool]): boolean array which controls which type of grid is going to be computed and
-         hence on the property `values`.
-        regular_grid (:class:`gempy.core.grid_modules.grid_types.RegularGrid`)
-        custom_grid (:class:`gempy.core.grid_modules.grid_types.CustomGrid`)
-        topography (:class:`gempy.core.grid_modules.grid_types.Topography`)
-        sections (:class:`gempy.core.grid_modules.grid_types.Sections`)
-        gravity_grid (:class:`gempy.core.grid_modules.grid_types.Gravity`)
-    """
-
-    def __init__(self, **kwargs):
-
-        self.values = np.empty((0, 3))
-        self.values_r = np.empty((0, 3))
-        self.length = np.empty(0)
-        self.grid_types = np.array(['regular', 'custom', 'topography', 'sections', 'centered'])
-        self.active_grids = np.zeros(5, dtype=bool)
-        # All grid types must have values
-
-        # Init optional grids
-        self.custom_grid = None
-        self.custom_grid_grid_active = False
-        self.topography = None
-        self.topography_grid_active = False
-        self.sections_grid_active = False
-        self.centered_grid = None
-        self.centered_grid_active = False
-
-        # Init basic grid empty
-        self.regular_grid = self.create_regular_grid(set_active=False, **kwargs)
-        self.regular_grid_active = False
-
-        # Init optional sections
-        self.sections = grid_types.Sections(regular_grid=self.regular_grid)
-
-        self.update_grid_values()
-
-    def __str__(self):
-        return 'Grid Object. Values: \n' + np.array2string(self.values)
-
-    def __repr__(self):
-        return 'Grid Object. Values: \n' + np.array_repr(self.values)
-
-    @_setdoc(grid_types.RegularGrid.__doc__)
-    def create_regular_grid(self, extent=None, resolution=None, set_active=True, *args, **kwargs):
-        """
-        Set a new regular grid and activate it.
-
-        Args:
-            extent (np.ndarray): [x_min, x_max, y_min, y_max, z_min, z_max]
-            resolution (np.ndarray): [nx, ny, nz]
-
-        RegularGrid Docs
-        """
-        self.regular_grid = grid_types.RegularGrid(extent, resolution, **kwargs)
-        if set_active is True:
-            self.set_active('regular')
-        return self.regular_grid
-
-    @_setdoc_pro(ds.coord)
-    def create_custom_grid(self, custom_grid: np.ndarray):
-        """
-        Set a new regular grid and activate it.
-
-        Args:
-            custom_grid (np.array): [s0]
-
-        """
-        self.custom_grid = grid_types.CustomGrid(custom_grid)
-        self.set_active('custom')
-
-    def create_topography(self, source='random', **kwargs):
-        """Create a topography grid and activate it.
-
-        Args:
-            source:
-                * 'gdal':  Load topography from a raster file.
-                * 'random': Generate random topography (based on a fractal grid).
-                * 'saved': Load topography that was saved with the topography.save() function.
-                  This is useful after loading and saving a heavy raster file with gdal once or after saving a
-                  random topography with the save() function. This .npy file can then be set as topography.
-
-        Keyword Args:
-            source = 'gdal':
-                * filepath:   path to raster file, e.g. '.tif', (for all file formats see
-                  https://gdal.org/drivers/raster/index.html)
-
-            source = 'random':
-                * fd:         fractal dimension, defaults to 2.0
-                * d_z:        maximum height difference. If none, last 20% of the model in z direction
-                * extent:     extent in xy direction. If none, geo_model.grid.extent
-                * resolution: desired resolution of the topography array. If none, geo_model.grid.resoution
-
-            source = 'saved':
-                * filepath:   path to the .npy file that was created using the topography.save() function
-
-        Returns:
-             :class:gempy.core.data.Topography
-        """
-        self.topography = topography.Topography(self.regular_grid)
-
-        if source == 'random':
-            self.topography.load_random_hills(**kwargs)
-        elif source == 'gdal':
-            filepath = kwargs.get('filepath', None)
-            if filepath is not None:
-                self.topography.load_from_gdal(filepath)
-            else:
-                print('to load a raster file, a path to the file must be provided')
-        elif source == 'saved':
-            filepath = kwargs.get('filepath', None)
-            if filepath is not None:
-                self.topography.load_from_saved(filepath)
-            else:
-                print('path to .npy file must be provided')
-        elif source == 'numpy':
-            array = kwargs.get('array', None)
-            self.topography.set_values(array)
-        else:
-            raise AttributeError('source must be random, gdal or saved')
-
-        self.set_active('topography')
-
-    @_setdoc(grid_types.Sections.__doc__)
-    def create_section_grid(self, section_dict):
-        self.sections = grid_types.Sections(regular_grid=self.regular_grid, section_dict=section_dict)
-        self.set_active('sections')
-        return self.sections
-
-    @_setdoc(grid_types.CenteredGrid.set_centered_grid.__doc__)
-    def create_centered_grid(self, centers, radius, resolution=None):
-        """Initialize gravity grid. Deactivate the rest of the grids"""
-        self.centered_grid = grid_types.CenteredGrid(centers, radius, resolution)
-        # self.active_grids = np.zeros(4, dtype=bool)
-        self.set_active('centered')
-
-    def deactivate_all_grids(self):
-        """
-        Deactivates the active grids array
-        :return:
-        """
-        self.active_grids = np.zeros(5, dtype=bool)
-        self.update_grid_values()
-        return self.active_grids
-
-    def set_active(self, grid_name: Union[str, np.ndarray]):
-        """
-        Set active a given or several grids
-        Args:
-            grid_name (str, list):
-
-        """
-        where = self.grid_types == grid_name
-        self.active_grids[where] = True
-        self.update_grid_values()
-        return self.active_grids
-
-    def set_inactive(self, grid_name: str):
-        where = self.grid_types == grid_name
-        self.active_grids *= ~where
-        self.update_grid_values()
-        return self.active_grids
-
-    def update_grid_values(self):
-        """
-        Copy XYZ coordinates from each specific grid to Grid.values for those which are active.
-
-        Returns:
-            values
-
-        """
-        self.length = np.empty(0)
-        self.values = np.empty((0, 3))
-        lengths = [0]
-        try:
-            for e, grid_types in enumerate(
-                    [self.regular_grid, self.custom_grid, self.topography, self.sections, self.centered_grid]):
-                if self.active_grids[e]:
-                    self.values = np.vstack((self.values, grid_types.values))
-                    lengths.append(grid_types.values.shape[0])
-                else:
-                    lengths.append(0)
-        except AttributeError:
-            raise AttributeError('Grid type does not exist yet. Set the grid before activating it.')
-
-        self.length = np.array(lengths).cumsum()
-        return self.values
-
-    def get_grid_args(self, grid_name: str):
-        assert type(grid_name) is str, 'Only one grid type can be retrieved'
-        assert grid_name in self.grid_types, 'possible grid types are ' + str(self.grid_types)
-        where = np.where(self.grid_types == grid_name)[0][0]
-        return self.length[where], self.length[where + 1]
-
-    def get_grid(self, grid_name: str):
-        assert type(grid_name) is str, 'Only one grid type can be retrieved'
-
-        l_0, l_1 = self.get_grid_args(grid_name)
-        return self.values[l_0:l_1]
-
-    def get_section_args(self, section_name: str):
-        # assert type(section_name) is str, 'Only one section type can be retrieved'
-        l0, l1 = self.get_grid_args('sections')
-        where = np.where(self.sections.names == section_name)[0][0]
-        return l0 + self.sections.length[where], l0 + self.sections.length[where + 1]
-
-
-class Colors:
-    """
-    Object that handles the color management in the model.
-    """
-    def __init__(self, surfaces):
-        self.surfaces = surfaces
-        self.colordict = None
-        self._hexcolors_soft = [
-            '#015482', '#9f0052', '#ffbe00', '#728f02', '#443988',
-            '#ff3f20', '#5DA629', '#b271d0', '#72e54a', '#583bd1',
-            '#d0e63d', '#b949e2', '#95ce4b', '#6d2b9f', '#60eb91',
-            '#d746be', '#52a22e', '#5e63d8', '#e5c339', '#371970',
-            '#d3dc76', '#4d478e', '#43b665', '#d14897', '#59e5b8',
-            '#e5421d', '#62dedb', '#df344e', '#9ce4a9', '#d94077',
-            '#99c573', '#842f74', '#578131', '#708de7', '#df872f',
-            '#5a73b1', '#ab912b', '#321f4d', '#e4bd7c', '#142932',
-            '#cd4f30', '#69aedd', '#892a23', '#aad6de', '#5c1a34',
-            '#cfddb4', '#381d29', '#5da37c', '#d8676e', '#52a2a3',
-            '#9b405c', '#346542', '#de91c9', '#555719', '#bbaed6',
-            '#945624', '#517c91', '#de8a68', '#3c4b64', '#9d8a4d',
-            '#825f7e', '#2c3821', '#ddadaa', '#5e3524', '#a3a68e',
-            '#a2706b', '#686d56'
-        ]  # source: https://medialab.github.io/iwanthue/
-
-    def generate_colordict(
-            self,
-            hex_colors: Union[List[str], str] = 'palettes',
-            palettes: List[str] = 'default',
-    ):
-        """Generates and sets color dictionary.
-
-        Args:
-           hex_colors (list[str], str): List of hex color values. In the future this could
-           accommodate the actual geological palettes. For example striplog has a quite
-           good set of palettes.
-                * palettes: If hexcolors='palettes' the colors will be chosen from the
-                   palettes arg
-                * soft: https://medialab.github.io/iwanthue/
-           palettes (list[str], optional): list with name of seaborn palettes. Defaults to 'default'.
-        """
-        if hex_colors == 'palettes':
-            hex_colors = []
-            if palettes == 'default':
-                # we predefine some 7 colors manually
-                hex_colors = ['#015482', '#9f0052', '#ffbe00', '#728f02', '#443988', '#ff3f20', '#5DA629']
-                # then we create a list of seaborn color palette names, as the user didn't provide any
-                palettes = ['muted', 'pastel', 'deep', 'bright', 'dark', 'colorblind']
-            for palette in palettes:  # for each palette
-                hex_colors += sns.color_palette(palette).as_hex()  # get all colors in palette and add to list
-                if len(hex_colors) >= len(self.surfaces.df):
-                    break
-        elif hex_colors == 'soft':
-            hex_colors = self._hexcolors_soft
-
-        surface_names = self.surfaces.df['surface'].values
-        n_surfaces = len(surface_names)
-
-        while n_surfaces > len(hex_colors):
-            hex_colors.append(self._random_hexcolor())
-
-        self.colordict = dict(
-            zip(surface_names, hex_colors[:n_surfaces])
-        )
+import sys
+from .aesara_graph import aesaraGeometry, aesaraOptions
 
-    @staticmethod
-    def _random_hexcolor() -> str:
-        """Generates a random hex color string."""
-        return "#"+str(hex(np.random.randint(0, 16777215))).lstrip("0x")
-
-    def change_colors(self, colordict: dict = None):
-        """Change the model colors either by providing a color dictionary or,
-        if not, by using a color pick widget.
+aesara.config.openmp_elemwise_minsize = 10000
+aesara.config.openmp = True
 
-        Args:
-            colordict (dict, optional): dict with surface names mapped to hex color codes, e.g. {'layer1':'#6b0318'}
-            if None: opens jupyter widget to change colors interactively. Defaults to None.
-        """
-        assert ipywidgets_import, 'ipywidgets not imported. Make sure the library is installed.'
+aesara.config.optimizer = 'fast_compile'
+aesara.config.floatX = 'float64'
+aesara.config.on_opt_error = 'ignore'
 
-        if colordict:
-            self.update_colors(colordict)
-        else:
-            items = [
-                widgets.ColorPicker(description=surface, value=color)
-                for surface, color in self.colordict.items()
-            ]
-            colbox = widgets.VBox(items)
-            print('Click to select new colors.')
-            display(colbox)
-
-            def on_change(v):
-                self.colordict[v['owner'].description] = v['new']  # update colordict
-                self._set_colors()
+aesara.config.exception_verbosity = 'high'
+aesara.config.compute_test_value = 'off'
+aesara.config.profile_memory = False
+aesara.config.scan.debug = False
+aesara.config.profile = False
 
-            for cols in colbox.children:
-                cols.observe(on_change, 'value')
 
-    def update_colors(self, colordict: dict = None):
-        """ Updates the colors in self.colordict and in surfaces_df.
+class aesaraExport(aesaraGeometry):
 
-        Args:
-            colordict (dict, optional): dict with surface names mapped to hex
-                color codes, e.g. {'layer1':'#6b0318'}. Defaults to None.
+    def __init__(self, weights_op = None, grid: np.ndarray=None, weights=None):
         """
-        if colordict is None:
-            self.generate_colordict()
-        else:
-            for surf, color in colordict.items():  # map new colors to surfaces
-                # assert this because user can set it manually
-                assert surf in list(self.surfaces.df['surface']), str(surf) + ' is not a model surface'
-                assert re.search(r'^#(?:[0-9a-fA-F]{3}){1,2}$', color), str(color) + ' is not a HEX color code'
-                self.colordict[surf] = color
-
-        self._set_colors()
-
-    def _add_colors(self):
-        """Assign a color to the last entry of surfaces df or check isnull and assign color there"""
-        self.generate_colordict()
-
-    def _set_colors(self):
-        """sets colordict in surfaces dataframe"""
-        for surf, color in self.colordict.items():
-            self.surfaces.df.loc[self.surfaces.df['surface'] == surf, 'color'] = color
-
-    def set_default_colors(self, surfaces=None):
-        if surfaces is not None:
-            self.colordict[surfaces] = self.colordict[surfaces]
-        self._set_colors()
-
-    def delete_colors(self, surfaces):
-        for surface in surfaces:
-            self.colordict.pop(surface, None)
-        self._set_colors()
-
-    def make_faults_black(self, series_fault):
-        faults_list = list(self.surfaces.df[self.surfaces.df.series.isin(series_fault)]['surface'])
-        for fault in faults_list:
-            if self.colordict[fault] == '#527682':
-                self.set_default_colors(fault)
-            else:
-                self.colordict[fault] = '#527682'
-                self._set_colors()
-
-    def reset_default_colors(self):
-        self.generate_colordict()
-        self._set_colors()
-        return self.surfaces
-
-
-# @_setdoc_pro(Series.__doc__)
-class Surfaces(object):
-    """
-    Class that contains the surfaces of the model and the values of each of them.
-
-    Args:
-        surface_names (list or np.ndarray): list containing the names of the surfaces
-        series (:class:`Series`): [s0]
-        values_array (np.ndarray): 2D array with the values of each surface
-        properties names (list or np.ndarray): list containing the names of each properties
-
-    Attributes:
-        df (:class:`pn.core.frame.DataFrames`): Pandas data frame containing the surface names mapped to series and
-            the value used for each voxel in the final model.
-        series (:class:`Series`)
-        colors (:class:`Colors`)
-
-    """
-
-    def __init__(self, series, surface_names=None, values_array=None, properties_names=None):
-
-        self._columns = ['surface', 'series', 'order_surfaces',
-                         'isBasement', 'isFault', 'isActive', 'hasData', 'color',
-                         'vertices', 'edges', 'sfai', 'id']
-
-        self._columns_vis_drop = ['vertices', 'edges', 'sfai', 'isBasement', 'isFault',
-                                  'isActive', 'hasData']
-        self._n_properties = len(self._columns) - 1
-        self.series = series
-        self.colors = Colors(self)
-
-        df_ = pn.DataFrame(columns=self._columns)
-        self.df = df_.astype({'surface': str, 'series': 'category',
-                              'order_surfaces': int,
-                              'isBasement': bool, 'isFault': bool, 'isActive': bool, 'hasData': bool,
-                              'color': bool, 'id': int, 'vertices': object, 'edges': object})
-
-        if (np.array(sys.version_info[:2]) <= np.array([3, 6])).all():
-            self.df: pn.DataFrame
-
-        self.df['series'].cat.add_categories(['Default series'], inplace=True)
-        if surface_names is not None:
-            self.set_surfaces_names(surface_names)
-
-        if values_array is not None:
-            self.set_surfaces_values(values_array=values_array,
-                                     properties_names=properties_names)
-
-    def __repr__(self):
-        c_ = self.df.columns[~(self.df.columns.isin(self._columns_vis_drop))]
-
-        return self.df[c_].to_string()
-
-    def _repr_html_(self):
-        c_ = self.df.columns[~(self.df.columns.isin(self._columns_vis_drop))]
-
-        return self.df[c_].style.applymap(self.background_color, subset=['color']).render()
-
-    @property
-    def properties_val(self):
-        all_col = self.df.columns
-        prop_cols = all_col.drop(self._columns)
-        return prop_cols.insert(0, 'id')
-
-    @property
-    def basement(self):
-        return self.df['surface'][self.df['isBasement']]
 
-    def update_id(self, id_list: list = None):
-        """
-        Set id of the layers (1 based)
         Args:
-            id_list (list):
-
-        Returns:
-             :class:`Surfaces`:
-
+            grid: if grid is passed it becomes constant
+            weights:
         """
-        self.map_faults()
-        if id_list is None:
-            # This id is necessary for the faults
-            id_unique = self.df.reset_index().index + 1
 
-        self.df['id'] = id_unique
+        super().__init__()
 
-        return self
+        # self.grid_val_T = aesara.shared(np.cast[dtype](np.zeros((2, 200))), 'Coordinates of the grid '
+        #                                                                     'points to interpolate')
 
-    def map_faults(self):
-        self.df['isFault'] = self.df['series'].map(self.series.faults.df['isFault'])
+        self.grid_val_T = T.matrix('Coordinates of the grid points to interpolate')
+        self.fault_matrix = T.matrix('Full block matrix for x_to_interpolate')
+        # TODO: This is either shared or aesaraOP
+       # if weights_op is None:
+       #     self.weights = aesara.shared(np.ones(10000), 'Weights to compute')
+       # else:
+       #     self.weights = weights_op(self.input_parameters_weights())
+       #  if weights_op is None:
+       #      self.weights = T.vector('kriging weights')
+       #  else:
+       #      self.weights_op = weights_op
+       #      self.weights = weights_op(*self.input_parameters_kriging())
 
-    @staticmethod
-    def background_color(value):
-        if isinstance(value, str):
-            return "background-color: %s" % value
+        #self.fault_matrix = T.zeros((0, self.grid_val_T.shape[0] + 2 * self.len_points))
 
-    # region set formation names
-    def set_surfaces_names(self, surfaces_list: list, update_df=True):
-        """
-         Method to set the names of the surfaces in order. This applies in the surface column of the df
+       # self.fault_drift = T.matrix('Block matrix at interface points')
+      #  self.fault_mask = T.zeros((0, self.grid_val_T.shape[0] + 2 * self.len_points))
 
-         Args:
-             surfaces_list (list[str]):  list of names of surfaces. They are ordered.
-             update_df (bool): Update Surfaces.df columns with the default values
+       # self.n_surface = aesara.shared(np.arange(1, 5, dtype='int32'), "ID of the surface")
+      #  self.n_surface_op = self.n_surface
+        #self.npf = aesara.shared(np.zeros(3, dtype='int32'), 'Number of points per surface accumulative')
 
-         Returns:
-             :class:`Surfaces`:
-         """
-        if isinstance(surfaces_list, (list, np.ndarray)):
-            surfaces_list = np.asarray(surfaces_list)
+        self.dot_version = False
 
+    def set_weights(self, weights_op = None):
+        if weights_op is None:
+            self.weights = T.vector('kriging weights')
         else:
-            raise AttributeError('list_names must be either array_like type')
-
-        # Deleting all columns if they exist
-        # TODO check if some of the names are in the df and not deleting them?
-        self.df.drop(self.df.index, inplace=True)
-        self.df['surface'] = surfaces_list
-
-        # Changing the name of the series is the only way to mutate the series object from surfaces
-        if update_df is True:
-            self.map_series()
-            self.update_id()
-            self.set_basement()
-            self.reset_order_surfaces()
-            self.colors.update_colors()
-        return self
-
-    def set_default_surface_name(self):
-        """
-        Set the minimum number of surfaces to compute a model i.e. surfaces_names: surface1 and basement
-
-        Returns:
-             :class:`Surfaces`:
+            self.weights_op = weights_op
+            self.weights = weights_op(*self.input_parameters_kriging())
 
-        """
-        if self.df.shape[0] == 0:
-            # TODO DEBUG: I am not sure that surfaces always has at least one entry. Check it
-            self.set_surfaces_names(['surface1', 'basement'])
-        return self
 
-    def set_surfaces_names_from_surface_points(self, surface_points):
+    def input_parameters_kriging(self):
         """
-        Set surfaces names from a :class:`Surface_points` object. This can be useful if the surface points are imported
-        from a table.
-
-        Args:
-            surface_points (:class:`Surface_points`):
+        Create a list with the symbolic variables to use when we compile the aesara function
 
         Returns:
-
+            list: [self.dips_position_all, self.dip_angles_all, self.azimuth_all, self.polarity_all,
+                   self.ref_layer_points_all, self.rest_layer_points_all]
         """
-        self.set_surfaces_names(surface_points.df['surface'].unique())
-        return self
-
-    def add_surface(self, surface_list: Union[str, list], update_df=True):
-        """ Add surface to the df.
-
-        Args:
-            surface_list (str, list): name or list of names of the surfaces to apply the functionality
-            update_df (bool): Update Surfaces.df columns with the default values
+        ipl = [self.dips_position_all, self.dip_angles_all, self.azimuth_all, self.polarity_all, self.surface_points_all,
+               self.fault_drift, self.number_of_points_per_surface_T_op]
+        # self.ref_layer_points_all, self.rest_layer_points_all]
+        return ipl
 
-        Returns:
-            :class:`gempy.core.data.Surfaces`
+    def input_parameters_export(self):
         """
-
-        surface_list = np.atleast_1d(surface_list)
-
-        # Remove from the list categories that already exist
-        surface_list = surface_list[~np.in1d(surface_list, self.df['surface'].values)]
-
-        for c in surface_list:
-            idx = self.df.index.max()
-            if idx is np.nan:
-                idx = -1
-            self.df.loc[idx + 1, 'surface'] = c
-
-        if update_df is True:
-            self.map_series()
-            self.update_id()
-            self.set_basement()
-            self.reset_order_surfaces()
-            self.colors.update_colors()
-        return self
-
-    @_setdoc_pro([update_id.__doc__, pn.DataFrame.drop.__doc__])
-    def delete_surface(self, indices: Union[int, str, list, np.ndarray], update_id=True):
-        """[s1]
-
-        Args:
-            indices (str, list): name or list of names of the series to apply the functionality
-            update_id (bool): if true [s0]
+        Create a list with the symbolic variables to use when we compile the aesara function
 
         Returns:
-             :class:`Surfaces`:
-
+            list:
         """
-        indices = np.atleast_1d(indices)
-        if indices.dtype == int:
-            self.df.drop(indices, inplace=True)
-        else:
-            self.df.drop(self.df.index[self.df['surface'].isin(indices)], inplace=True)
+        ipl = [self.dips_position_all, self.surface_points_all,
+               self.fault_drift, self.fault_matrix, self.weights, self.grid_val_T,
+               self.number_of_points_per_surface_T_op]
+        # self.ref_layer_points_all, self.rest_layer_points_all]
+        return ipl
 
-        if update_id is True:
-            self.update_id()
-            self.set_basement()
-            self.reset_order_surfaces()
-        return self
+    def input_parameters_export_kriging(self):
 
-    def rename_surfaces(self, to_replace: Union[str, list, dict], **kwargs):
-        """Replace values given in to_replace with value.
+        # ipl = [self.dips_position_all, self.dip_angles_all, self.azimuth_all, self.polarity_all,
+        #        self.surface_points_all,
+        #        self.fault_drift, self.number_of_points_per_surface_T_op]
+        #
+        # ipl = [self.dips_position_all, self.surface_points_all,
+        #        self.fault_drift, self.fault_matrix, self.grid_val_T,
+        #        self.number_of_points_per_surface_T_op]
 
-        Args:
-            to_replace (str, regex, list, dict, Series, int, float, or None) –
-             How to find the values that will be replaced.
-            **kwargs:
-
-        Returns:
-            :class:`gempy.core.data.Surfaces`
-
-        See Also:
-            :any:`pandas.Series.replace`
+        ipl = [self.dips_position_all, self.dip_angles_all, self.azimuth_all, self.polarity_all,
+               self.surface_points_all,
+               self.fault_drift,  self.fault_matrix, self.grid_val_T, self.number_of_points_per_surface_T_op]
 
-        """
-        if np.isin(to_replace, self.df['surface']).any():
-            print('Two surfaces cannot have the same name.')
-        else:
-            self.df['surface'].replace(to_replace, inplace=True, **kwargs)
-        return self
+        # self.ref_layer_points_all, self.rest_layer_points_all]
+        return ipl
 
-    def reset_order_surfaces(self):
-        self.df['order_surfaces'] = self.df.groupby('series').cumcount() + 1
-
-    def modify_order_surfaces(self, new_value: int, idx: int, series_name: str = None):
+    def x_to_interpolate(self, verbose=0):
         """
-        Replace to the new location the old series
-
-        Args:
-            new_value (int): New location
-            idx (int): Index of the surface to be moved
-            series_name (str): name of the series to be moved
+        here I add to the grid points also the references points(to check the value of the potential field at the
+        surface_points). Also here I will check what parts of the grid have been already computed in a previous series
+        to avoid to recompute.
 
         Returns:
-            :class:`gempy.core.data.Surfaces`
-
-        """
-        if series_name is None:
-            series_name = self.df.loc[idx, 'series']
-
-        group = self.df.groupby('series').get_group(series_name)['order_surfaces']
-        assert np.isin(new_value, group), 'new_value must exist already in the order_surfaces group.'
-        old_value = group[idx]
-        self.df.loc[group.index.astype('int'), 'order_surfaces'] = group.replace([new_value, old_value], [old_value, new_value])
-        self.sort_surfaces()
-        self.set_basement()
-        return self
-
-    def sort_surfaces(self):
-        """Sort surfaces by series and order_surfaces"""
-
-        self.df.sort_values(by=['series', 'order_surfaces'], inplace=True)
-        self.update_id()
-        return self.df
-
-    def set_basement(self):
+            aesara.tensor.matrix: The 3D points of the given grid plus the reference and rest points
         """
-        Set isBasement property to true to the last series of the df.
-
-        Returns:
-             :class:`Surfaces`:
 
-        """
+        grid_val = T.concatenate([self.grid_val_T, self.rest_layer_points_all,
+                                  self.ref_layer_points_all])
 
-        self.df['isBasement'] = False
-        idx = self.df.last_valid_index()
-        if idx is not None:
-            self.df.loc[idx, 'isBasement'] = True
+        if verbose > 1:
+            aesara.printing.pydotprint(grid_val, outfile="graphs/" + sys._getframe().f_code.co_name + ".png",
+                                       var_with_name_simple=True)
 
-        # TODO add functionality of passing the basement and calling reorder to push basement surface to the bottom
-        #  of the data frame
-        assert self.df['isBasement'].values.astype(bool).sum() <= 1, 'Only one surface can be basement'
-        return self
+        if 'grid_val' in self.verbose:
+            grid_val = aesara.printing.Print('Points to interpolate')(grid_val)
 
-    # endregion
+        return grid_val
 
-    # set_series
-    def map_series(self, mapping_object: Union[dict, pn.DataFrame] = None):
+    def extend_dual_kriging(self):
+        # TODO Think what object is worth to save to speed up computation
         """
-        Method to map which series every surface belongs to. This step is necessary to assign differenct tectonics
-        such as unconformities or faults.
-
-
-        Args:
-            mapping_object (dict, :class:`pn.DataFrame`):
-                * dict: keys are the series and values the surfaces belonging to that series
-
-                * pn.DataFrame: Dataframe with surfaces as index and a column series with the corresponding series name
-                  of each surface
+        Tile the dual kriging vector to cover all the points to interpolate.So far I just make a matrix with the
+        dimensions len(DK)x(grid) but in the future maybe I have to try to loop all this part so consume less memory
 
         Returns:
-             :class:`Surfaces`
-
+            aesara.tensor.matrix: Matrix with the Dk parameters repeated for all the points to interpolate
         """
 
-        # Updating surfaces['series'] categories
-        self.df['series'].cat.set_categories(self.series.df.index, inplace=True)
-        # TODO Fixing this. It is overriding the formations already mapped
-        if mapping_object is not None:
-            # If none is passed and series exists we will take the name of the first series as a default
-
-            if type(mapping_object) is dict:
-
-                s = []
-                f = []
-                for k, v in mapping_object.items():
-                    for form in np.atleast_1d(v):
-                        s.append(k)
-                        f.append(form)
-
-                new_series_mapping = pn.DataFrame([pn.Categorical(s, self.series.df.index)],
-                                                  f, columns=['series'])
-
-            elif isinstance(mapping_object, pn.Categorical):
-                # This condition is for the case we have surface on the index and in 'series' the category
-                # TODO Test this
-                new_series_mapping = mapping_object
-
-            else:
-                raise AttributeError(str(type(mapping_object)) + ' is not the right attribute type.')
-
-            # Checking which surfaces are on the list to be mapped
-            b = self.df['surface'].isin(new_series_mapping.index)
-            idx = self.df.index[b]
-
-            # Mapping
-            self.df.loc[idx, 'series'] = self.df.loc[idx, 'surface'].map(new_series_mapping['series'])
-
-        # Fill nans
-        self.df['series'].fillna(self.series.df.index.values[-1], inplace=True)
-
-        # Reorganize the pile
-        self.reset_order_surfaces()
-        self.sort_surfaces()
-        self.set_basement()
-        return self
+        grid_val = self.x_to_interpolate()
+        # if self.weights.get_value() is None:
+        #     DK_parameters = self.solve_kriging()
+        # else:
+        #     DK_parameters = self.weights
+        DK_parameters = self.weights
+        # Creation of a matrix of dimensions equal to the grid with the weights for every point (big 4D matrix in
+        # ravel form)
+        # TODO IMP: Change the tile by a simple dot op -> The DOT version in gpu is slower
+        DK_weights = T.tile(DK_parameters, (grid_val.shape[0], 1)).T
 
-    # endregion
+        if self.dot_version:
+            DK_weights = DK_parameters
 
-    # region update_id
+        return DK_weights
 
-    # endregion
 
-    def add_surfaces_values(self, values_array: Union[np.ndarray, list], properties_names: list = np.empty(0)):
-        """Add values to be interpolated for each surfaces.
+class aesaraExportGeo(aesaraExport):
 
-        Args:
-            values_array (np.ndarray, list): array-like of the same length as number of surfaces. This functionality
-             can be used to assign different geophysical properties to each layer
-            properties_names (list): list of names for each values_array columns. This must be of the same size as
-             values_array axis 1. By default properties will take the column name: 'value_X'.
-
-        Returns:
-            :class:`gempy.core.data.Surfaces`
+    # def __init__(self):
+    #
+    #     super().__init__()
 
+    def contribution_gradient_interface(self, grid_val=None, weights=None):
         """
-        values_array = np.atleast_2d(values_array)
-        properties_names = np.atleast_1d(properties_names)
-        if properties_names.shape[0] != values_array.shape[0]:
-            for i in range(values_array.shape[0]):
-                properties_names = np.append(properties_names, 'value_' + str(i))
-
-        for e, p_name in enumerate(properties_names):
-            try:
-                self.df.loc[:, p_name] = values_array[e]
-            except ValueError:
-                raise ValueError('value_array must have the same length in axis 0 as the number of surfaces')
-        return self
-
-    def delete_surface_values(self, properties_names: Union[str, list]):
-        """Delete a property or several properties column.
-
-        Args:
-            properties_names (str, list[str]): Name of the property to delete
+        Computation of the contribution of the foliations at every point to interpolate
 
         Returns:
-             :class:`gempy.core.data.Surfaces`
-
+            aesara.tensor.vector: Contribution of all foliations (input) at every point to interpolate
         """
+        if weights is None:
+            weights = self.extend_dual_kriging()
+        if grid_val is None:
+            grid_val = self.x_to_interpolate()
 
-        properties_names = np.asarray(properties_names)
-        self.df.drop(properties_names, axis=1, inplace=True)
-        return True
+        length_of_CG = self.matrices_shapes()[0]
 
-    def set_surfaces_values(self, values_array: Union[np.ndarray, list], properties_names: list = np.empty(0)):
-        """Set values to be interpolated for each surfaces. This method will delete the previous values.
+        # Cartesian distances between the point to simulate and the dips
+        hu_SimPoint = T.vertical_stack(
+            (self.dips_position[:, 0] - grid_val[:, 0].reshape((grid_val[:, 0].shape[0], 1))).T,
+            (self.dips_position[:, 1] - grid_val[:, 1].reshape((grid_val[:, 1].shape[0], 1))).T,
+            (self.dips_position[:, 2] - grid_val[:, 2].reshape((grid_val[:, 2].shape[0], 1))).T
+        )
 
-        Args:
-            values_array (np.ndarray, list): array-like of the same length as number of surfaces. This functionality
-             can be used to assign different geophysical properties to each layer
-            properties_names (list): list of names for each values_array columns. This must be of same size as
-             values_array axis 1. By default properties will take the column name: 'value_X'.
+        # Euclidian distances
+        sed_dips_SimPoint = self.squared_euclidean_distances(self.dips_position_tiled, grid_val)
+        # Gradient contribution
+        sigma_0_grad = T.sum(
+            (weights[:length_of_CG] *
+             self.gi_reescale *
+             (-hu_SimPoint *
+              (sed_dips_SimPoint < self.a_T) *  # first derivative
+              (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_SimPoint / self.a_T ** 3 -
+                               35 / 2 * sed_dips_SimPoint ** 3 / self.a_T ** 5 +
+                               21 / 4 * sed_dips_SimPoint ** 5 / self.a_T ** 7)))),
+            axis=0)
+
+        if self.dot_version:
+            sigma_0_grad = T.dot(
+                weights[:length_of_CG],
+                self.gi_reescale *
+                (-hu_SimPoint *
+                 (sed_dips_SimPoint < self.a_T) *  # first derivative
+                 (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_SimPoint / self.a_T ** 3 -
+                                  35 / 2 * sed_dips_SimPoint ** 3 / self.a_T ** 5 +
+                                  21 / 4 * sed_dips_SimPoint ** 5 / self.a_T ** 7))))
+
+        # Add name to the aesara node
+        sigma_0_grad.name = 'Contribution of the foliations to the potential field at every point of the grid'
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            sigma_0_grad = aesara.printing.Print('interface_gradient_contribution')(sigma_0_grad)
+
+        return sigma_0_grad
+
+    def contribution_interface(self, grid_val=None, weights=None):
+        """
+          Computation of the contribution of the surface_points at every point to interpolate
+
+          Returns:
+              aesara.tensor.vector: Contribution of all surface_points (input) at every point to interpolate
+          """
+
+        if weights is None:
+            weights = self.extend_dual_kriging()
+        if grid_val is None:
+            grid_val = self.x_to_interpolate()
+        length_of_CG, length_of_CGI = self.matrices_shapes()[:2]
+
+        # Euclidian distances
+        sed_rest_SimPoint = self.squared_euclidean_distances(self.rest_layer_points, grid_val)
+        sed_ref_SimPoint = self.squared_euclidean_distances(self.ref_layer_points, grid_val)
+
+        # Interface contribution
+        sigma_0_interf = (T.sum(
+            -weights[length_of_CG:length_of_CG + length_of_CGI, :] *
+            (self.c_o_T * self.i_reescale * (
+                    (sed_rest_SimPoint < self.a_T) *  # SimPoint - Rest Covariances Matrix
+                    (1 - 7 * (sed_rest_SimPoint / self.a_T) ** 2 +
+                     35 / 4 * (sed_rest_SimPoint / self.a_T) ** 3 -
+                     7 / 2 * (sed_rest_SimPoint / self.a_T) ** 5 +
+                     3 / 4 * (sed_rest_SimPoint / self.a_T) ** 7) -
+                    ((sed_ref_SimPoint < self.a_T) *  # SimPoint- Ref
+                     (1 - 7 * (sed_ref_SimPoint / self.a_T) ** 2 +
+                      35 / 4 * (sed_ref_SimPoint / self.a_T) ** 3 -
+                      7 / 2 * (sed_ref_SimPoint / self.a_T) ** 5 +
+                      3 / 4 * (sed_ref_SimPoint / self.a_T) ** 7)))), axis=0))
+
+        if self.dot_version:
+            sigma_0_interf = (
+                T.dot(-weights[length_of_CG:length_of_CG + length_of_CGI],
+                      (self.c_o_T * self.i_reescale * (
+                              (sed_rest_SimPoint < self.a_T) *  # SimPoint - Rest Covariances Matrix
+                              (1 - 7 * (sed_rest_SimPoint / self.a_T) ** 2 +
+                               35 / 4 * (sed_rest_SimPoint / self.a_T) ** 3 -
+                               7 / 2 * (sed_rest_SimPoint / self.a_T) ** 5 +
+                               3 / 4 * (sed_rest_SimPoint / self.a_T) ** 7) -
+                              ((sed_ref_SimPoint < self.a_T) *  # SimPoint- Ref
+                               (1 - 7 * (sed_ref_SimPoint / self.a_T) ** 2 +
+                                35 / 4 * (sed_ref_SimPoint / self.a_T) ** 3 -
+                                7 / 2 * (sed_ref_SimPoint / self.a_T) ** 5 +
+                                3 / 4 * (sed_ref_SimPoint / self.a_T) ** 7))))))
+
+        # Add name to the aesara node
+        sigma_0_interf.name = 'Contribution of the surface_points to the potential field at every point of the grid'
+
+        return sigma_0_interf
+
+    def contribution_universal_drift(self, grid_val=None, weights=None, a=0, b=100000000):
+        """
+        Computation of the contribution of the universal drift at every point to interpolate
+
+        Returns:
+            aesara.tensor.vector: Contribution of the universal drift (input) at every point to interpolate
+        """
+        if weights is None:
+            weights = self.extend_dual_kriging()
+        if grid_val is None:
+            grid_val = self.x_to_interpolate()
+
+        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C = self.matrices_shapes()
+
+        universal_grid_surface_points_matrix = T.horizontal_stack(
+            grid_val,
+            (grid_val ** 2),
+            T.stack((grid_val[:, 0] * grid_val[:, 1],
+                     grid_val[:, 0] * grid_val[:, 2],
+                     grid_val[:, 1] * grid_val[:, 2]), axis=1)).T
+
+        # These are the magic terms to get the same as geomodeller
+        i_rescale_aux = T.repeat(self.gi_reescale, 9)
+        i_rescale_aux = T.set_subtensor(i_rescale_aux[:3], 1)
+        _aux_magic_term = T.tile(i_rescale_aux[:self.n_universal_eq_T_op], (grid_val.shape[0], 1)).T
+
+        # Drif contribution
+        f_0 = (T.sum(
+            weights[
+            length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I] * self.gi_reescale * _aux_magic_term *
+            universal_grid_surface_points_matrix[:self.n_universal_eq_T_op]
+            , axis=0))
+
+        if self.dot_version:
+            f_0 = T.dot(
+                weights[length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I],
+                self.gi_reescale * _aux_magic_term *
+                universal_grid_surface_points_matrix[:self.n_universal_eq_T_op])
+
+        if not type(f_0) == int:
+            f_0.name = 'Contribution of the universal drift to the potential field at every point of the grid'
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            f_0 = aesara.printing.Print('Universal terms contribution')(f_0)
+
+        return f_0
+
+    def faults_contribution(self, weights=None, a=0, b=100000000):
+        """
+        Computation of the contribution of the df drift at every point to interpolate. To get these we need to
+        compute a whole block model with the df data
+
+        Returns:
+            aesara.tensor.vector: Contribution of the df drift (input) at every point to interpolate
+        """
+        if weights is None:
+            weights = self.extend_dual_kriging()
+        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C = self.matrices_shapes()
+
+        fault_matrix_selection_non_zero = self.fault_matrix[a:b] #* self.fault_mask[a:b] + 1
+
+        f_1 = T.sum(
+            weights[length_of_CG + length_of_CGI + length_of_U_I:, :] * fault_matrix_selection_non_zero, axis=0)
+
+        if self.dot_version:
+            f_1 = T.dot(
+                weights[length_of_CG + length_of_CGI + length_of_U_I:], fault_matrix_selection_non_zero)
+
+        # Add name to the aesara node
+        f_1.name = 'Faults contribution'
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            f_1 = aesara.printing.Print('Faults contribution')(f_1)
+
+        return f_1
+
+    def scalar_field_loop(self, a, b, Z_x, grid_val, weights):
+
+        sigma_0_grad = self.contribution_gradient_interface(grid_val[a:b], weights[:, a:b])
+        sigma_0_interf = self.contribution_interface(grid_val[a:b], weights[:, a:b])
+        f_0 = self.contribution_universal_drift(grid_val[a:b], weights[:, a:b], a, b)
+        f_1 = self.faults_contribution(weights[:, a:b], a, b)
+
+        # Add an arbitrary number at the potential field to get unique values for each of them
+        partial_Z_x = (sigma_0_grad + sigma_0_interf + f_0 + f_1)
+        Z_x = T.set_subtensor(Z_x[a:b], partial_Z_x)
+
+        return Z_x
+
+    def scalar_field_at_all(self, weights=None):
+        """
+        Compute the potential field at all the interpolation points, i.e. grid plus rest plus ref
+        Returns:
+            aesara.tensor.vector: Potential fields at all points
+
+        """
+        grid_val = self.x_to_interpolate()
+
+        if weights is None:
+            weights = self.extend_dual_kriging()
+
+        grid_shape = T.stack([grid_val.shape[0]], axis=0)
+        Z_x_init = T.zeros(grid_shape, dtype='float32')
+        if 'grid_shape' in self.verbose:
+            grid_shape = aesara.printing.Print('grid_shape')(grid_shape)
+
+        steps = 1e13 / self.matrices_shapes()[-1] / grid_shape
+        slices = T.concatenate((T.arange(0, grid_shape[0], steps[0], dtype='int64'), grid_shape))
+
+        if 'slices' in self.verbose:
+            slices = aesara.printing.Print('slices')(slices)
+
+        Z_x_loop, updates3 = aesara.scan(
+            fn=self.scalar_field_loop,
+            outputs_info=[Z_x_init],
+            sequences=[dict(input=slices, taps=[0, 1])],
+            non_sequences=[grid_val, weights],
+            profile=False,
+            name='Looping grid',
+            return_list=True)
+
+        self.Z_x = Z_x_loop[-1][-1]
+        self.Z_x.name = 'Value of the potential field at every point'
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            self.Z_x = aesara.printing.Print('Potential field at all points')(self.Z_x)
+
+        return self.Z_x
+    #
+    # def get_scalar_field_at_surface_points_values(self):
+    #
+    #     # self.Z_x = self.scalar_field_at_all()
+    #     self.scalar_field_at_surface_points_values = self.Z_x[-2*self.len_points: -self.len_points][self.npf]
+    #     return self.scalar_field_at_surface_points_values
+        # Z_x_grid = Z_x[:-2*self.len_points]
+        # Z_x_sp = Z_x[-2*self.len_points:]
+        # scalar_field_at_surface_points_values = Z_x_sp[: -self.len_points][self.npf]
+
+       # return [Z_x_grid, Z_x_sp, scalar_field_at_surface_points_values]
+
+
+class aesaraBlock(aesaraExport):
+    def __init__(self, Z_x_op = None):
+
+        if type(Z_x_op) == aesara.compile.builders.OpFromGraph:
+            super(aesaraBlock, self).__init__()
+            self.Z_x_op = Z_x_op
+            self.Z_x = Z_x_op(*self.input_parameters_export_kriging())
+            self.Z_x.name = 'Scalar op'
+        else:
+            self.Z_x = T.vector('Scalar')
+         #   self.grid_val_T = T.matrix('Coordinates of the grid points to interpolate')
+         #   self.weights = T.vector('kriging weights')
+
+        # elif Z_x is None:
+        #     self.Z_x = self.scalar_field_at_all
+
+        self.n_surface = aesara.shared(np.arange(1, 5000, dtype='int32'), "ID of the surface")
+        self.n_surface_op = self.n_surface
+
+        self.npf = aesara.shared(np.zeros(3, dtype='int32'), 'Number of points per surface accumulative')
+      #  self.npf_op = T.vector('Number of points per surface accumulative', dtype='int32')#self.npf[[0, -2]]
+      #  self.Z_x = T.vector('Value of the potential field at every x_to_intep point')
+        self.scalar_field_at_surface_points_values = self.Z_x[-2*self.len_points: -self.len_points][self.npf_op]
+
+       # self.scalar_field_at_surface_points_values = T.vector('')
+        #self.len_points = T.vector('Length of rest or ref surface points arrays')
+        self.is_finite = aesara.shared(np.zeros(3, dtype='int32'), 'The series (fault) is finite')
+        self.inf_factor = self.is_finite * 10
+        self.is_fault = aesara.shared(np.zeros(3, dtype='int32'), 'The series is fault')
+
+        # TODO shared or variable
+        self.values_properties_op = T.matrix('Values that the blocks are taking')
+
+    def input_parameters_block_formations(self):
+        ipl = [self.values_properties_op, self.Z_x,
+               self.number_of_points_per_surface_T_op,
+               self.surface_points_all]
+
+        # self.ref_layer_points_all, self.rest_layer_points_all]
+        return ipl
+
+    def input_parameters_block_faults(self):
+        ipl = [self.values_properties_op, self.Z_x,
+               self.number_of_points_per_surface_T_op,
+               self.surface_points_all, self.grid_val_T]
+
+        # self.ref_layer_points_all, self.rest_layer_points_all]
+        return ipl
+
+    def select_finite_faults(self):
+        fault_points = T.vertical_stack(T.stack([self.ref_layer_points[0]], axis=0), self.rest_layer_points).T
+        ctr = T.mean(fault_points, axis=1)
+        x = fault_points - ctr.reshape((-1, 1))
+        M = T.dot(x, x.T)
+        U = T.nlinalg.svd(M)[2]
+        rotated_x = T.dot(self.x_to_interpolate(), U)
+        rotated_fault_points = T.dot(fault_points.T, U)
+        rotated_ctr = T.mean(rotated_fault_points, axis=0)
+        a_radius = (rotated_fault_points[:, 0].max() - rotated_fault_points[:, 0].min()) / 2 + self.inf_factor[
+            self.n_surface_op[0] - 1]
+        b_radius = (rotated_fault_points[:, 1].max() - rotated_fault_points[:, 1].min()) / 2 + self.inf_factor[
+            self.n_surface_op[0] - 1]
+        sel = T.lt((rotated_x[:, 0] - rotated_ctr[0]) ** 2 / a_radius ** 2 + (
+                    rotated_x[:, 1] - rotated_ctr[1]) ** 2 / b_radius ** 2,
+                   1)
+
+        if "select_finite_faults" in self.verbose:
+            sel = aesara.printing.Print("scalar_field_iter")(sel)
+
+        return sel
+
+    def compare(self, a, b, slice_init, Z_x, l, n_surface, drift):
+        """
+        Treshold of the points to interpolate given 2 potential field values. TODO: This function is the one we
+        need to change for a sigmoid function
+
+        Args:
+            a (scalar): Upper limit of the potential field
+            b (scalar): Lower limit of the potential field
+            n_surface (scalar): Value given to the segmentation, i.e. lithology number
+            Zx (vector): Potential field values at all the interpolated points
+
+        Returns:
+            aesara.tensor.vector: segmented values
+        """
+
+        slice_init = slice_init
+        n_surface_0 = n_surface[:, slice_init:slice_init + 1]
+        n_surface_1 = n_surface[:, slice_init + 1:slice_init + 2]
+        drift = drift[:, slice_init:slice_init + 1]
+
+        if 'compare' in self.verbose:
+            a = aesara.printing.Print("a")(a)
+            b = aesara.printing.Print("b")(b)
+            # l = 200/ (a - b)
+            slice_init = aesara.printing.Print("slice_init")(slice_init)
+            n_surface_0 = aesara.printing.Print("n_surface_0")(n_surface_0)
+            n_surface_1 = aesara.printing.Print("n_surface_1")(n_surface_1)
+            drift = aesara.printing.Print("drift[slice_init:slice_init+1][0]")(drift)
+
+        # drift = T.switch(slice_init == 0, n_surface_1, n_surface_0)
+        #    drift = T.set_subtensor(n_surface[0], n_surface[1])
+
+        # The 5 rules the slope of the function
+        sigm = (-n_surface_0.reshape((-1, 1)) / (1 + T.exp(-l * (Z_x - a)))) - \
+               (n_surface_1.reshape((-1, 1)) / (1 + T.exp(l * (Z_x - b)))) + drift.reshape((-1, 1))
+        if 'sigma' in self.verbose:
+            sigm = aesara.printing.Print("middle point")(sigm)
+        #      n_surface = aesara.printing.Print("n_surface")(n_surface)
+        return sigm
+
+    def export_fault_block(self, Z_x = None, slope=50, offset_slope=5000):
+        """
+        Compute the part of the block model of a given series (dictated by the bool array yet to be computed)
+
+        Returns:
+            aesara.tensor.vector: Value of lithology at every interpolated point
+        """
+
+        if Z_x is None:
+            Z_x = self.Z_x
+
+        # Max and min values of the potential field.
+        # max_pot = T.max(Z_x) + 1
+        # min_pot = T.min(Z_x) - 1
+        # max_pot += max_pot * 0.1
+        # min_pot -= min_pot * 0.1
+
+        # Value of the potential field at the surface_points of the computed series
+        # TODO timeit
+        max_pot = T.max(Z_x)
+        # max_pot = aesara.printing.Print("max_pot")(max_pot)
+
+        min_pot = T.min(Z_x)
+        #     min_pot = aesara.printing.Print("min_pot")(min_pot)
+
+        # max_pot_sigm = 2 * max_pot - self.scalar_field_at_surface_points_values[0]
+        # min_pot_sigm = 2 * min_pot - self.scalar_field_at_surface_points_values[-1]
+
+        boundary_pad = (max_pot - min_pot) * 0.01
+        #l = slope / (max_pot - min_pot)  # (max_pot - min_pot)
+
+        # This is the different line with respect layers
+        l = T.switch(self.select_finite_faults(), offset_slope / (max_pot - min_pot), slope / (max_pot - min_pot))
+        #  l = aesara.printing.Print("l")(l)
+
+        # A tensor with the values to segment
+        scalar_field_iter = T.concatenate((
+            T.stack([max_pot + boundary_pad], axis=0),
+            self.scalar_field_at_surface_points_values,
+            T.stack([min_pot - boundary_pad], axis=0)
+        ))
+
+        if "scalar_field_iter" in self.verbose:
+            scalar_field_iter = aesara.printing.Print("scalar_field_iter")(scalar_field_iter)
+
+        # Here we just take the first element of values properties because at least so far we do not find a reason
+        # to populate fault blocks with anything else
+
+        n_surface_op_float_sigmoid = T.repeat(self.values_properties_op[[0], :], 2, axis=1)
+
+        # TODO: instead -1 at the border look for the average distance of the input!
+        # TODO I think should be -> n_surface_op_float_sigmoid[:, 2] - n_surface_op_float_sigmoid[:, 1]
+        n_surface_op_float_sigmoid = T.set_subtensor(n_surface_op_float_sigmoid[:, 1], -1)
+        # - T.sqrt(T.square(n_surface_op_float_sigmoid[0] - n_surface_op_float_sigmoid[2])))
+
+        n_surface_op_float_sigmoid = T.set_subtensor(n_surface_op_float_sigmoid[:, -1], -1)
+        # - T.sqrt(T.square(n_surface_op_float_sigmoid[3] - n_surface_op_float_sigmoid[-1])))
+
+        drift = T.set_subtensor(n_surface_op_float_sigmoid[:, 0], n_surface_op_float_sigmoid[:, 1])
+
+        if 'n_surface_op_float_sigmoid' in self.verbose:
+            n_surface_op_float_sigmoid = aesara.printing.Print("n_surface_op_float_sigmoid") \
+                (n_surface_op_float_sigmoid)
+
+        fault_block, updates2 = aesara.scan(
+            fn=self.compare,
+            outputs_info=None,
+            sequences=[dict(input=scalar_field_iter, taps=[0, 1]),
+                       T.arange(0, n_surface_op_float_sigmoid.shape[1], 2, dtype='int64')],
+            non_sequences=[Z_x, l, n_surface_op_float_sigmoid, drift],
+            name='Looping compare',
+            profile=False,
+            return_list=False)
+
+        # For every surface we get a vector so we need to sum compress them to one dimension
+        fault_block = fault_block.sum(axis=0)
+
+        # Add name to the aesara node
+        fault_block.name = 'The chunk of block model of a specific series'
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            fault_block = aesara.printing.Print(fault_block.name)(fault_block)
+
+        return fault_block
+
+    def export_formation_block(self, Z_x = None, slope=5000,weights=None):
+        """
+        Compute the part of the block model of a given series (dictated by the bool array yet to be computed)
+
+        Returns:
+            aesara.tensor.vector: Value of lithology at every interpolated point
+        """
+        # TODO: IMP set soft max in the borders
+
+        if Z_x is None:
+            Z_x = self.Z_x
+
+        max_pot = T.max(Z_x)
+        # max_pot = aesara.printing.Print("max_pot")(max_pot)
+
+        min_pot = T.min(Z_x)
+        #     min_pot = aesara.printing.Print("min_pot")(min_pot)
+
+        max_pot_sigm = 2 * max_pot - self.scalar_field_at_surface_points_values[0]
+        min_pot_sigm = 2 * min_pot - self.scalar_field_at_surface_points_values[-1]
+
+        boundary_pad = (max_pot - min_pot) * 0.01
+        l = slope / (max_pot - min_pot)
+
+        # A tensor with the values to segment
+        scalar_field_iter = T.concatenate((
+            T.stack([max_pot + boundary_pad], axis=0),
+            self.scalar_field_at_surface_points_values,
+            T.stack([min_pot - boundary_pad], axis=0)
+        ))
+
+        if "scalar_field_iter" in self.verbose:
+            scalar_field_iter = aesara.printing.Print("scalar_field_iter")(scalar_field_iter)
+
+        # Loop to segment the distinct lithologies
+
+        n_surface_op_float_sigmoid = T.repeat(self.values_properties_op, 2, axis=1)
+
+        # TODO: instead -1 at the border look for the average distance of the input!
+        n_surface_op_float_sigmoid = T.set_subtensor(n_surface_op_float_sigmoid[:, 0], -1)
+        # - T.sqrt(T.square(n_surface_op_float_sigmoid[0] - n_surface_op_float_sigmoid[2])))
+
+        n_surface_op_float_sigmoid = T.set_subtensor(n_surface_op_float_sigmoid[:, -1], -1)
+        # - T.sqrt(T.square(n_surface_op_float_sigmoid[3] - n_surface_op_float_sigmoid[-1])))
+
+        drift = T.set_subtensor(n_surface_op_float_sigmoid[:, 0], n_surface_op_float_sigmoid[:, 1])
+
+        if 'n_surface_op_float_sigmoid' in self.verbose:
+            n_surface_op_float_sigmoid = aesara.printing.Print("n_surface_op_float_sigmoid") \
+                (n_surface_op_float_sigmoid)
+
+        formations_block, updates2 = aesara.scan(
+            fn=self.compare,
+            outputs_info=None,
+            sequences=[dict(input=scalar_field_iter, taps=[0, 1]), T.arange(0, n_surface_op_float_sigmoid.shape[1],
+                                                                            2, dtype='int64')],
+            non_sequences=[self.Z_x, l, n_surface_op_float_sigmoid, drift],
+            name='Looping compare',
+            profile=False,
+            return_list=False)
+
+        # For every surface we get a vector so we need to sum compress them to one dimension
+        formations_block = formations_block.sum(axis=0)
+
+        # Add name to the aesara node
+        formations_block.name = 'The chunk of block model of a specific series'
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            formations_block = aesara.printing.Print(formations_block.name)(formations_block)
+
+        return formations_block
+
+
+class aesaraLoop(aesaraExportGeo):
+    def __init__(self, weights_op, Z_x_op, export_formation_op, export_fault_op):
+        super(aesaraLoop, self).__init__()
+
+        self.weights_op = weights_op
+        self.Z_x_op = Z_x_op
+        self.export_formation_op = export_formation_op
+        self.export_fault_op = export_fault_op
+
+        # FORMATIONS
+        # ----------
+        self.n_surface = aesara.shared(np.arange(2, 5, dtype='int32'), "ID of the surface")
+        self.n_surface_op = self.n_surface
+        self.surface_values = aesara.shared((np.arange(2, 4, dtype=float).reshape(2, -1)),
+                                            "Value of the surface to compute")
+        self.n_surface_op_float = self.surface_values
+
+        # FAULTS
+        # ------
+        # Init fault relation matrix
+        self.fault_relation = aesara.shared(np.array([[0, 1, 0, 1],
+                                                      [0, 0, 1, 1],
+                                                      [0, 0, 0, 1],
+                                                      [0, 0, 0, 0]]), 'fault relation matrix')
+
+        self.compute_weights = T.vector('Vector controlling if weights must be recomputed', dtype=bool)
+        self.compute_scalar = T.vector('Vector controlling if scalar matrix must be recomputed', dtype=bool)
+        self.compute_block = T.vector('Vector controlling if block matrix must be recomputed', dtype=bool)
+
+        self.inf_factor = aesara.shared(np.ones(200, dtype='int32') * 10, 'Arbitrary scalar to make df infinite')
+
+        # STRUCTURE
+        # ---------
+        # This parameters give me the shape of the different groups of data. I pass all data together and I threshold it
+        # using these values to the different potential fields and surfaces
+        #self.is_fault = is_fault
+        #self.is_lith = i
+        self.n_faults = aesara.shared(0, 'Number of faults')
+        self.n_surfaces_per_series = aesara.shared(np.arange(2, dtype='int32'), 'List with the number of surfaces')
+        self.n_universal_eq_T = aesara.shared(np.zeros(5, dtype='int32'), "Grade of the universal drift")
+
+
+
+        # This is not accumulative
+        self.number_of_points_per_surface_T = aesara.shared(np.zeros(3, dtype='int32'))  # TODO is DEP?
+        self.number_of_points_per_surface_T_op = self.number_of_points_per_surface_T
+        # This is accumulative
+        self.npf = aesara.shared(np.zeros(3, dtype='int32'), 'Number of points per surface accumulative')
+        self.npf_op = self.npf[[0, -2]]
+        self.len_series_i = aesara.shared(np.arange(2, dtype='int32'), 'Length of surface_points in every series')
+        self.len_series_f = aesara.shared(np.arange(2, dtype='int32'), 'Length of foliations in every series')
+
+        self.weights_matrix = aesara.shared(np.zeros((3, 10000)), 'Weights matrix')
+        self.scalar_fields_matrix = aesara.shared(np.zeros((3, 10000)), 'Scalar matrix')
+        self.block_matrix = aesara.shared(np.zeros((3,10000)), "block matrix")#T.zeros((self.n_surface.shape[0], self.grid_val_T.shape[0] + 2 * self.len_points))
+        #T.zeros((self.n_surface.shape[0], self.grid_val_T.shape[0] + 2 * self.len_points))
+        if 'initial matrices' in self.verbose:
+            self.block_matrix = aesara.printing.Print("block_matrix")(self.block_matrix)
+            self.scalar_fields_matrix = aesara.printing.Print("scalar_fields")(self.scalar_fields_matrix)
+
+    def compute_all_series(self):
+        # # Change the flag to extend the graph in the compute fault and compute series function
+        # lith_matrix = T.zeros((0, 0, self.grid_val_T.shape[0] + 2 * self.len_points))
+        #
+        # # Init to matrix which contains the block and scalar field of every fault
+        # self.fault_matrix = T.zeros((self.n_faults * 2, self.grid_val_T.shape[0] + 2 * self.len_points))
+        # self.fault_matrix_f = T.zeros((self.n_faults * 2, self.grid_val_T.shape[0] + 2 * self.len_points))
+        #
+        # self.final_scalar_field_at_surfaces_op = self.final_scalar_field_at_surfaces
+        # self.final_potential_field_at_faults_op = self.final_scalar_field_at_faults
+        #
+        # # Init df block. Here we store the block and potential field results of one iteration
+        # self.fault_block_init = T.zeros((2, self.grid_val_T.shape[0] + 2 * self.len_points))
+        # self.fault_block_init.name = 'final block of df init'
+        # self.yet_simulated = T.nonzero(T.eq(self.fault_block_init[0, :], 0))[0]
+
+
+
+        # Looping
+        series, updates1 = aesara.scan(
+            fn=self.compute_a_series,
+            outputs_info=[
+                dict(initial=self.weights_matrix, taps=[0]),
+                dict(initial=self.scalar_fields_matrix, taps=[0]),
+                dict(initial=self.block_matrix, taps=[0])
+                ],  # This line may be used for the df network
+            sequences=[dict(input=self.len_series_i, taps=[0, 1]),
+                       dict(input=self.len_series_f, taps=[0, 1]),
+                       dict(input=self.n_surfaces_per_series, taps=[0, 1]),
+                       dict(input=self.n_universal_eq_T, taps=[0]),
+                       dict(input=self.compute_weights, taps=[0]),
+                       dict(input=self.compute_scalar, taps=[0]),
+                       dict(input=self.compute_block, taps=[0])],
+           # non_sequences=self.fault_block_init,
+            name='Looping',
+            return_list=True,
+            profile=False
+        )
 
-        Returns:
-             :class:`gempy.core.data.Surfaces`
+        return series
 
+    def compute_a_series(self,
+                         len_i_0, len_i_1,
+                         len_f_0, len_f_1,
+                         n_form_per_serie_0, n_form_per_serie_1,
+                         u_grade_iter,
+                         weights_matrix, scalar_fields, block_matrix,
+                         compute_weight, compute_scalar, compute_block
+                         ):
         """
-        # Check if there are values columns already
-        old_prop_names = self.df.columns[~self.df.columns.isin(['surface', 'series', 'order_surfaces',
-                                                                'id', 'isBasement', 'color'])]
-        # Delete old
-        self.delete_surface_values(old_prop_names)
-
-        # Create new
-        self.add_surfaces_values(values_array, properties_names)
-        return self
-
-    def modify_surface_values(self, idx, properties_names, values):
-        """Method to modify values using loc of pandas.
+        Function that loops each fault, generating a potential field for each on them with the respective block model
 
         Args:
-            idx (int, list[int]):
-            properties_names (str, list[str]):
-            values (float, np.ndarray):
-
-        Returns:
-             :class:`gempy.core.data.Surfaces`
-
-        """
-        properties_names = np.atleast_1d(properties_names)
-        assert ~np.isin(properties_names, ['surface', 'series', 'order_surfaces', 'id', 'isBasement', 'color']), \
-            'only property names can be modified with this method'
-
-        self.df.loc[idx, properties_names] = values
-        return self
-
-
-# @_setdoc_pro([SurfacePoints.__doc__, Orientations.__doc__, Surfaces.__doc__, Faults.__doc__])
-class Structure(object):
-    """
-    The structure_data class analyses the different lengths of subset in the interface and orientations categories_df
-    to pass them to the theano function.
-
-    Attributes:
-        surface_points (:class:`SurfacePoints`): [s0]
-        orientations (:class:`Orientations`): [s1]
-        surfaces (:class:`Surfaces`): [s2]
-        faults (:class:`Faults`): [s3]
-        df (:class:`pn.DataFrame`):
-            * len surfaces surface_points (list): length of each surface/fault in surface_points
-            * len series surface_points (list) : length of each series in surface_points
-            * len series orientations (list) : length of each series in orientations
-            * number surfaces per series (list): number of surfaces per series
-            * ...
-    Args:
-        surface_points (:class:`SurfacePoints`): [s0]
-        orientations (:class:`Orientations`): [s1]
-        surfaces (:class:`Surfaces`): [s2]
-        faults (:class:`Faults`): [s3]
-
-    """
-
-    def __init__(self, surface_points, orientations, surfaces: Surfaces, faults):
-        self.surface_points = surface_points
-        self.orientations = orientations
-        self.surfaces = surfaces
-        self.faults = faults
-
-        df_ = pn.DataFrame(np.array(['False', 'False', -1, -1, -1, -1, -1, -1, -1], ).reshape(1, -1),
-                           index=['values'],
-                           columns=['isLith', 'isFault',
-                                    'number faults', 'number surfaces', 'number series',
-                                    'number surfaces per series',
-                                    'len surfaces surface_points', 'len series surface_points',
-                                    'len series orientations'])
-
-        self.df = df_.astype({'isLith': bool, 'isFault': bool, 'number faults': int,
-                              'number surfaces': int, 'number series': int})
-
-        self.update_structure_from_input()
-
-    def __repr__(self):
-        return self.df.T.to_string()
-
-    def _repr_html_(self):
-        return self.df.T.to_html()
-
-    def update_structure_from_input(self):
-        """
-        Update all fields dependent on the linked Data objects.
+            len_i_0: Lenght of rest of previous series
+            len_i_1: Lenght of rest for the computed series
+            len_f_0: Lenght of dips of previous series
+            len_f_1: Length of dips of the computed series
+            n_form_per_serie_0: Number of surfaces of previous series
+            n_form_per_serie_1: Number of surfaces of the computed series
 
         Returns:
-            bool: True
-        """
-        self.set_length_surfaces_i()
-        self.set_series_and_length_series_i()
-        self.set_length_series_o()
-        self.set_number_of_surfaces_per_series()
-        self.set_number_of_faults()
-        self.set_number_of_surfaces()
-        self.set_is_lith_is_fault()
-        return True
-
-    def set_length_surfaces_i(self):
+            aesara.tensor.matrix: block model derived from the df that afterwards is used as a drift for the "real"
+            data
         """
-        Set the length of each **surface** on `SurfacePoints` i.e. how many data points are related to each surface
-
-        Returns:
-            :class:`pn.DataFrame`: df where Structural data is stored
 
-        """
+        # THIS IS THE FAULTS BLOCK.
         # ==================
-        # Extracting lengths
+        # Preparing the data
         # ==================
-        # Array containing the size of every surface. SurfacePoints
-        lssp = self.surface_points.df.groupby('id')['order_series'].count().values
-        lssp_nonzero = lssp[np.nonzero(lssp)]
-
-        self.df.at['values', 'len surfaces surface_points'] = lssp_nonzero
-
-        return self.df
-
-    def set_series_and_length_series_i(self):
-        """
-        Set the length of each **series** on `SurfacePoints` i.e. how many data points are related to each series. Also
-        sets the number of series itself.
-
-        Returns:
-            :class:`pn.DataFrame`: df where Structural data is stored
-
-        """
-        len_series = self.surfaces.series.df.shape[0]
-
-        # Array containing the size of every series. SurfacePoints.
-        points_count = self.surface_points.df['order_series'].value_counts(sort=False)
-        len_series_i = np.zeros(len_series, dtype=int)
-        len_series_i[points_count.index.astype('int') - 1] = points_count.values
-
-        if len_series_i.shape[0] == 0:
-            len_series_i = np.insert(len_series_i, 0, 0)
-
-        self.df.at['values', 'len series surface_points'] = len_series_i
-        self.df['number series'] = len(len_series_i)
-        return self.df
-
-    def set_length_series_o(self):
-        """
-        Set the length of each **series** on `Orientations` i.e. how many orientations are related to each series.
-
-        Returns:
-            :class:`pn.DataFrame`: df where the Structural data is stored
-
-        """
-        # Array containing the size of every series. orientations.
-
-        len_series_o = np.zeros(self.surfaces.series.df.shape[0], dtype=int)
-        ori_count = self.orientations.df['order_series'].value_counts(sort=False)
-        len_series_o[ori_count.index.astype('int') - 1] = ori_count.values
-
-        self.df.at['values', 'len series orientations'] = len_series_o
-
-        return self.df
-
-    def set_number_of_surfaces_per_series(self):
-        """
-        Set number of surfaces for each series
 
-        Returns:
-            :class:`pn.DataFrame`: df where the Structural data is stored
-
-        """
-        len_sps = np.zeros(self.surfaces.series.df.shape[0], dtype=int)
-        surf_count = self.surface_points.df.groupby('order_series'). \
-            surface.nunique()
-
-        len_sps[surf_count.index.astype('int') - 1] = surf_count.values
-
-        self.df.at['values', 'number surfaces per series'] = len_sps
-        return self.df
-
-    def set_number_of_faults(self):
-        """
-        Set number of faults series. This method in gempy v2 is simply informative
-
-        Returns:
-            :class:`pn.DataFrame`: df where the Structural data is stored
-
-        """
-        # Number of faults existing in the surface_points df
-        self.df.at['values', 'number faults'] = self.faults.df['isFault'].sum()
-        return self.df
-
-    def set_number_of_surfaces(self):
-        """
-        Set the number of total surfaces
+        # compute the youngest fault and consecutively the others
 
-        Returns:
-            :class:`pn.DataFrame`: df where the Structural data is stored
+        # aesara shared
+        self.number_of_points_per_surface_T_op = self.number_of_points_per_surface_T[n_form_per_serie_0: n_form_per_serie_1]
+        self.n_surface_op = self.n_surface[n_form_per_serie_0: n_form_per_serie_1]
+        self.n_surface_op_float = self.surface_values[:, n_form_per_serie_0: n_form_per_serie_1 + 1]
+        self.npf_op = self.npf[n_form_per_serie_0: n_form_per_serie_1]
+        if 'n_surface' in self.verbose:
+            self.n_surface_op = aesara.printing.Print('n_surface_fault')(self.n_surface_op)
+
+        self.n_universal_eq_T_op = u_grade_iter
+
+        self.dips_position = self.dips_position_all[len_f_0: len_f_1, :]
+        self.dips_position_tiled = T.tile(self.dips_position, (self.n_dimensions, 1))
+
+        # # aesara Var
+        # self.dip_angles = self.dip_angles_all[len_f_0: len_f_1]
+        # self.azimuth = self.azimuth_all[len_f_0: len_f_1]
+        # self.polarity = self.polarity_all[len_f_0: len_f_1]
+
+        self.surface_points_op = self.surface_points[len_i_0: len_i_1, :]
+
+        self.weights_op = self.weights[len_i_0: len_i_1]
+        # self.ref_layer_points = self.ref_layer_points_all[len_i_0: len_i_1, :]
+        # self.rest_layer_points = self.rest_layer_points_all[len_i_0: len_i_1, :]
+
+        # Updating the interface points involved in the iteration. This is important for the fault drift
+        self.len_i_0 = len_i_0
+        self.len_i_1 = len_i_1
+
+        if 'lengths' in self.verbose:
+            self.len_i_0 = aesara.printing.Print('len_i_0')(self.len_i_0)
+            self.len_i_1 = aesara.printing.Print('len_i_1')(self.len_i_1)
+            self.len_points = aesara.printing.Print('len_points')(self.len_points)
+
+        # Extracting a the subset of the fault matrix to the scalar field of the current iterations
+        faults_relation_op = self.fault_relation[:, T.cast(self.n_surface_op-1, 'int8')]
+        faults_relation_rep = T.repeat(faults_relation_op, 1)
+
+        if 'faults_relation' in self.verbose:
+            faults_relation_rep = aesara.printing.Print('SELECT')(faults_relation_rep)
+        # if len(self.gradients) is not 0:
+        #     fault_matrix = block_matrix[::5][T.nonzero(T.cast(faults_relation_rep, "int8"))[0], :]
+        # else:
+
+        fault_matrix = block_matrix[T.nonzero(T.cast(faults_relation_rep, "int8"))[0], :]
+
+        if 'fault_matrix_loop' in self.verbose:
+            fault_matrix = aesara.printing.Print('self fault matrix')(self.fault_matrix)
+
+        # ================================
+        # Computing the fault scalar field
+        # ================================
+        Z_x = self.Z_x_op(self.dips_position_tiled, self.surface_points,
+                          self.fault_matrix[2 * self.len_points:], self.fault_matrix[:2 * self.len_points],
+                          self.weights_op, self.grid_val_T)
+
+        series_block = aesara.ifelse.ifelse(self.is_fault[T.cast(self.n_surface_op-1, 'int8')][0],
+                                            self.export_fault_block(),
+                                            self.export_formation_block(),
+                                            name="Is faults condition")
+
+        aux_ind = T.max(self.n_surface_op, 0)
+
+        block_matrix = T.set_subtensor(block_matrix[(aux_ind - 1), :], series_block[0])
+        scalar_fields = T.set_subtensor(scalar_fields[(aux_ind-1), :], Z_x)
+
+        return block_matrix, scalar_fields
+
+       #
+       #  potential_field_values, faults_matrix = self.block_fault(slope=1000)
+       #
+       #  # Update the block matrix
+       #  final_block = T.set_subtensor(
+       #              final_block[0, :],
+       #              faults_matrix[0])#T.cast(T.cast(faults_matrix, 'bool'), 'int8'))
+       #
+       #  # Update the potential field matrix
+       # # potential_field_values = self.scalar_field_at_all()
+       #
+       #  final_block = T.set_subtensor(
+       #              final_block[1, :],
+       #              potential_field_values)
+       #
+       #  # Store the potential field at the surface_points
+       #  self.final_potential_field_at_faults_op = T.set_subtensor(self.final_potential_field_at_faults_op[self.n_surface_op-1],
+       #                                                            self.scalar_field_at_surface_points_values)
+       #
+       #
+       #
+       #  if len(self.gradients) is not 0:
+       #      weights = self.extend_dual_kriging()
+       #      gradients = self.gradient_field_at_all(weights, self.gradients)
+       #      final_block = T.set_subtensor(
+       #          final_block[2:, :],
+       #          gradients)
+       #      # Setting the values of the fault matrix computed in the current iteration
+       #      fault_matrix = T.set_subtensor(fault_matrix[(aux_ind - 1) * 5:aux_ind * 5, :], final_block)
+       #
+       #  else:
+       #      # Setting the values of the fault matrix computed in the current iteration
+       #      fault_matrix = T.set_subtensor(fault_matrix[(aux_ind-1)*2:aux_ind*2, :], final_block)
+       #
+       #  return fault_matrix, self.final_potential_field_at_faults_op,
 
-        """
-        # Number of surfaces existing in the surface_points df
-        self.df.at['values', 'number surfaces'] = self.surface_points.df['surface'].nunique()
 
-        return self.df
 
-    def set_is_lith_is_fault(self):
-        """
-        Check if there are lithologies in the data and/or df. This method in gempy v2 is simply informative
 
-        Returns:
-            :class:`pn.DataFrame`: df where Structural data is stored
-        """
-        self.df['isLith'] = True if self.df.loc['values', 'number series'] >= self.df.loc['values', 'number faults'] \
-            else False
-        self.df['isFault'] = True if self.df.loc['values', 'number faults'] > 0 else False
 
-        return self.df
 
 
-class Options(object):
-    """The class options contains the auxiliary user editable flags mainly independent to the model.
+#
+# class aesaraMask(object):
+#     def __init__(self):
+#
+#         self.Z_x = T.vector('Value of the potential field at every x_to_intep point')
+#         self.is_onlap = aesara.shared(np.array([False, False], dtype=bool))
+#
+#         self.npf = aesara.shared(np.zeros(3, dtype='int32'), 'Number of points per surface accumulative')
+#         self.len_points = T.vector('Length of rest or ref surface points arrays')
+#
+#     def get_scalar_field_at_surface_points(self):
+#         self.scalar_field_at_surface_points_values = self.Z_x[-2*self.len_points: -self.len_points][self.npf]
+#
+#     def set_mask(self):
+#
+#
+#
+#         self.mask = T.nonzero(T.le(self.Z_x, self.scalar_field_at_surface_points_values]))[
+#             0]  # This -1 comes to get the last scalar field value (the bottom) of the previous series
+#         self.mask.name = 'Indices where the scalar field overprints'
 
-     Attributes:
-        df (:class:`pn.DataFrame`): df containing the flags. All fields are pandas categories allowing the user to
-         change among those categories.
 
-     """
+class aesaraExportGradient(aesaraExport):
 
     def __init__(self):
-        df_ = pn.DataFrame(np.array(['float32', 'geology', 'fast_compile', 'cpu', None]).reshape(1, -1),
-                           index=['values'],
-                           columns=['dtype', 'output', 'theano_optimizer', 'device', 'verbosity'])
-
-        self.df = df_.astype({'dtype': 'category', 'output': 'category',
-                              'theano_optimizer': 'category', 'device': 'category',
-                              'verbosity': object})
-
-        self.df['dtype'].cat.set_categories(['float32', 'float64'], inplace=True)
-        self.df['theano_optimizer'].cat.set_categories(['fast_run', 'fast_compile'], inplace=True)
-        self.df['device'].cat.set_categories(['cpu', 'cuda'], inplace=True)
-
-        self.default_options()
-
-    def __repr__(self):
-        return self.df.T.to_string()
-
-    def _repr_html_(self):
-        return self.df.T.to_html()
-
-    def modify_options(self, attribute, value):
-        """Method to modify a given field
-
-        Args:
-            attribute (str): Name of the field to modify
-            value: new value of the field. It will have to exist in the category in order for pandas to modify it.
-
-        Returns:
-            :class:`pandas.DataFrame`: df where options data is stored
-        """
-
-        assert np.isin(attribute, self.df.columns).all(), 'Valid properties are: ' + np.array2string(self.df.columns)
-        self.df.loc['values', attribute] = value
-        return self.df
-
-    def default_options(self):
-        """Set default options.
-
-        Returns:
-            bool: True
-        """
-        import theano
-        self.df.loc['values', 'device'] = theano.config.device
-
-        if self.df.loc['values', 'device'] == 'cpu':
-            self.df.loc['values', 'dtype'] = 'float64'
-        else:
-            self.df.loc['values', 'dtype'] = 'float32'
-
-        self.df.loc['values', 'theano_optimizer'] = 'fast_compile'
-        return True
-
-
-@_setdoc_pro([Grid.__doc__, Structure.__doc__])
-class KrigingParameters(object):
-    """
-    Class that stores and computes the default values for the kriging parameters used during the interpolation.
-    The default values will be computed from the :class:`Grid` and :class:`Structure` linked objects
-
-    Attributes:
-        grid (:class:`Grid`): [s0]
-        structure (:class:`Structure`): [s1]
-        df (:class:`pn.DataFrame`): df containing the kriging parameters.
-
-    Args:
-        grid (:class:`Grid`): [s0]
-        structure (:class:`Structure`): [s1]
-    """
-
-    def __init__(self, grid: Grid, structure: Structure):
-        self.structure = structure
-        self.grid = grid
-
-        df_ = pn.DataFrame(np.array([np.nan, np.nan, 3]).reshape(1, -1),
-                           index=['values'],
-                           columns=['range', '$C_o$', 'drift equations',
-                                    ])
-
-        self.df = df_.astype({'drift equations': object,
-                              'range': object,
-                              '$C_o$': object})
-        self.set_default_range()
-        self.set_default_c_o()
-        self.set_u_grade()
-
-    def __repr__(self):
-        return self.df.T.to_string()
-
-    def _repr_html_(self):
-        return self.df.T.to_html()
-
-    def modify_kriging_parameters(self, attribute: str, value, **kwargs):
-        """Method to modify a given field
-
-        Args:
-            attribute (str): Name of the field to modify
-            value: new value of the field. It will have to exist in the category in order for pandas to modify it.
-            kwargs:
-                * u_grade_sep (str): If drift equations values are `str`, symbol that separates the values.
-
-        Returns:
-            :class:`pandas.DataFrame`: df where options data is stored
-        """
-
-        u_grade_sep = kwargs.get('u_grade_sep', ',')
-
-        assert np.isin(attribute, self.df.columns).all(), 'Valid properties are: ' + np.array2string(self.df.columns)
-
-        if attribute == 'drift equations':
-            value = np.asarray(value)
-            print(value)
-
-            if type(value) is str:
-                value = np.fromstring(value[1:-1], sep=u_grade_sep, dtype=int)
-            try:
-                assert value.shape[0] is self.structure.df.loc['values', 'len series surface_points'].shape[0]
-                print(value, attribute)
-                self.df.at['values', attribute] = value
-                print(self.df)
-
-            except AssertionError:
-                print('u_grade length must be the same as the number of series')
-
-        else:
-            self.df = self.df.astype({'drift equations': object,
-                                  'range': object,
-                                  '$C_o$': object})
-
-            self.df.at['values', attribute] = value
-
-    def str2int_u_grade(self, **kwargs):
-        """
-        Convert u_grade to ints
-
-        Args:
-            **kwargs:
-                * u_grade_sep (str): If drift equations values are `str`, symbol that separates the values.
-
-        Returns:
-
-        """
-        u_grade_sep = kwargs.get('u_grade_sep', ',')
-        value = self.df.loc['values', 'drift equations']
-        if type(value) is str:
-            value = np.fromstring(value[1:-1], sep=u_grade_sep, dtype=int)
-        try:
-            assert value.shape[0] is self.structure.df.loc['values', 'len series surface_points'].shape[0]
-            self.df.at['values', 'drift equations'] = value
-
-        except AssertionError:
-            print('u_grade length must be the same as the number of series')
 
-        return self.df
+        super().__init__()
 
-    def set_default_range(self, extent=None):
+    def contribution_interface_gradient(self, direction='x', grid_val=None, weights=None):
         """
-        Set default kriging_data range
-
-        Args:
-            extent (Optional[float, np.array]): extent used to compute the default range--i.e. largest diagonal. If None
-             extent of the linked :class:`Grid` will be used.
-
-        Returns:
-
-        """
-        if extent is None:
-            extent = self.grid.regular_grid.extent
-            if np.sum(extent) == 0 and self.grid.values.shape[0] > 1:
-                extent = np.concatenate((np.min(self.grid.values, axis=0),
-                                         np.max(self.grid.values, axis=0)))[[0, 3, 1, 4, 2, 5]]
-
-        try:
-            range_var = np.sqrt(
-                (extent[0] - extent[1]) ** 2 +
-                (extent[2] - extent[3]) ** 2 +
-                (extent[4] - extent[5]) ** 2)
-        except TypeError:
-            warnings.warn('The extent passed or if None the extent of the grid object has some '
-                          'type of problem',
-                          TypeError)
-            range_var = np.array(np.nan)
-
-        self.df['range'] = np.atleast_1d(range_var)
-
-        return range_var
-
-    def set_default_c_o(self, range_var=None):
-        """
-        Set default covariance at 0.
-
-        Args:
-            range_var (Optional[float, np.array]): range used to compute the default c_0--i.e. largest diagonal. If None
-             the already computed range will be used.
+        Computation of the contribution of the foliations at every point to interpolate
 
         Returns:
-
-        """
-        if range_var is None:
-            range_var = self.df.loc['values', 'range']
-
-        if type(range_var) is list:
-            range_var = np.atleast_1d(range_var)
-
-        self.df.at['values', '$C_o$'] = range_var ** 2 / 14 / 3
-
-        return self.df['$C_o$']
-
-    def set_u_grade(self, u_grade: list = None):
+            aesara.tensor.vector: Contribution of all foliations (input) at every point to interpolate
         """
-         Set default universal grade. Transform polynomial grades to number of equations
-
-         Args:
-
-             u_grade (list):
-
-         Returns:
-
-         """
-        # =========================
-        # Choosing Universal drifts
-        # =========================
-        if u_grade is None:
-
-            len_series_i = self.structure.df.loc['values', 'len series surface_points']
-            u_grade = np.ones_like(len_series_i)
-            # u_grade[(len_series_i > 1)] = 1
 
+        if direction == 'x':
+            dir_val = 0
+        elif direction == 'y':
+            dir_val = 1
+        elif direction == 'z':
+            dir_val = 2
         else:
-            u_grade = np.array(u_grade)
-
-        # Transforming grade to number of equations
-        n_universal_eq = np.zeros_like(u_grade)
-        n_universal_eq[u_grade == 0] = 0
-        n_universal_eq[u_grade == 1] = 3
-        n_universal_eq[u_grade == 2] = 9
-
-        self.df.at['values', 'drift equations'] = n_universal_eq
-        return self.df['drift equations']
-
-
-class AdditionalData(object):
-    """
-    Container class that encapsulate :class:`Structure`, :class:`KrigingParameters`, :class:`Options` and
-     rescaling parameters
-
-    Args:
-        surface_points (:class:`SurfacePoints`): [s0]
-        orientations (:class:`Orientations`): [s1]
-        grid (:class:`Grid`): [s2]
-        faults (:class:`Faults`): [s4]
-        surfaces (:class:`Surfaces`): [s3]
-        rescaling (:class:`RescaledData`): [s5]
-
-    Attributes:
-        structure_data (:class:`Structure`): [s6]
-        options (:class:`Options`): [s8]
-        kriging_data (:class:`Structure`): [s7]
-        rescaling_data (:class:`RescaledData`):
-
-    """
-
-    def __init__(self, surface_points, orientations, grid: Grid,
-                 faults, surfaces: Surfaces, rescaling):
-        self.structure_data = Structure(surface_points, orientations, surfaces, faults)
-        self.options = Options()
-        self.kriging_data = KrigingParameters(grid, self.structure_data)
-        self.rescaling_data = rescaling
-
-    def __repr__(self):
-        concat_ = self.get_additional_data()
-        return concat_.to_string()
-
-    def _repr_html_(self):
-        concat_ = self.get_additional_data()
-        return concat_.to_html()
+            raise AttributeError('Directions muxt be x, y or z')
 
-    def get_additional_data(self):
-        """
-        Concatenate all linked data frames and transpose them for a nice visualization.
-
-        Returns:
-            pn.DataFrame: concatenated and transposed dataframe
-        """
-        concat_ = pn.concat([self.structure_data.df, self.options.df, self.kriging_data.df, self.rescaling_data.df],
-                            axis=1, keys=['Structure', 'Options', 'Kriging', 'Rescaling'])
-        return concat_.T
+        if weights is None:
+            weights = self.extend_dual_kriging()
+        if grid_val is None:
+            grid_val = self.x_to_interpolate()
+
+        length_of_CG, length_of_CGI = self.matrices_shapes()[:2]
+
+        # Cartesian distances between the point to simulate and the dips
+        hu_rest = (- self.rest_layer_points[:, dir_val] + grid_val[:, dir_val].reshape(
+            (grid_val[:, dir_val].shape[0], 1)))
+        hu_ref = (- self.ref_layer_points[:, dir_val] + grid_val[:, dir_val].reshape(
+            (grid_val[:, dir_val].shape[0], 1)))
+
+        # Euclidian distances
+
+        sed_grid_rest = self.squared_euclidean_distances(grid_val, self.rest_layer_points)
+        sed_grid_ref = self.squared_euclidean_distances(grid_val, self.ref_layer_points)
+
+        # Gradient contribution
+        self.gi_reescale = 2
+
+        sigma_0_grad = T.sum(
+            (weights[length_of_CG:length_of_CG + length_of_CGI] *
+             self.gi_reescale * (
+                     (hu_rest *
+                      (sed_grid_rest < self.a_T) *  # first derivative
+                      (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_grid_rest / self.a_T ** 3 -
+                                       35 / 2 * sed_grid_rest ** 3 / self.a_T ** 5 +
+                                       21 / 4 * sed_grid_rest ** 5 / self.a_T ** 7))) -
+                     (hu_ref *
+                      (sed_grid_ref < self.a_T) *  # first derivative
+                      (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_grid_ref / self.a_T ** 3 -
+                                       35 / 2 * sed_grid_ref ** 3 / self.a_T ** 5 +
+                                       21 / 4 * sed_grid_ref ** 5 / self.a_T ** 7)))).T),
+            axis=0)
+
+        return sigma_0_grad
+
+    def contribution_gradient(self, direction='x', grid_val=None, weights=None):
+
+        if direction == 'x':
+            direction_val = 0
+        if direction == 'y':
+            direction_val = 1
+        if direction == 'z':
+            direction_val = 2
+        self.gi_reescale = aesara.shared(1)
+
+        if weights is None:
+            weights = self.extend_dual_kriging()
+        if grid_val is None:
+            grid_val = self.x_to_interpolate()
+
+        length_of_CG = self.matrices_shapes()[0]
+
+        # Cartesian distances between the point to simulate and the dips
+        # TODO optimize to compute this only once?
+        # Euclidean distances
+        sed_dips_SimPoint = self.squared_euclidean_distances(grid_val, self.dips_position_tiled).T
+
+        if 'sed_dips_SimPoint' in self.verbose:
+            sed_dips_SimPoint = aesara.printing.Print('sed_dips_SimPoint')(sed_dips_SimPoint)
+
+        # Cartesian distances between dips positions
+        h_u = T.tile(self.dips_position[:, direction_val] - grid_val[:, direction_val].reshape(
+            (grid_val[:, direction_val].shape[0], 1)), 3)
+        h_v = T.horizontal_stack(
+            T.tile(self.dips_position[:, 0] - grid_val[:, 0].reshape((grid_val[:, 0].shape[0], 1)),
+                   1),
+            T.tile(self.dips_position[:, 1] - grid_val[:, 1].reshape((grid_val[:, 1].shape[0], 1)),
+                   1),
+            T.tile(self.dips_position[:, 2] - grid_val[:, 2].reshape((grid_val[:, 2].shape[0], 1)),
+                   1))
+
+        perpendicularity_vector = T.zeros(T.stack([length_of_CG], axis=0))
+        perpendicularity_vector = T.set_subtensor(
+            perpendicularity_vector[
+            self.dips_position.shape[0] * direction_val:self.dips_position.shape[0] * (direction_val + 1)], 1)
+
+        sigma_0_grad = T.sum(
+            (weights[:length_of_CG] * (
+                    ((-h_u * h_v).T / sed_dips_SimPoint ** 2) *
+                    ((
+                             (sed_dips_SimPoint < self.a_T) *  # first derivative
+                             (-self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_SimPoint / self.a_T ** 3 -
+                                             35 / 2 * sed_dips_SimPoint ** 3 / self.a_T ** 5 +
+                                             21 / 4 * sed_dips_SimPoint ** 5 / self.a_T ** 7))) +
+                     (sed_dips_SimPoint < self.a_T) *  # Second derivative
+                     self.c_o_T * 7 * (9 * sed_dips_SimPoint ** 5 - 20 * self.a_T ** 2 * sed_dips_SimPoint ** 3 +
+                                       15 * self.a_T ** 4 * sed_dips_SimPoint - 4 * self.a_T ** 5) / (
+                             2 * self.a_T ** 7)) -
+                    (perpendicularity_vector.reshape((-1, 1)) *
+                     ((sed_dips_SimPoint < self.a_T) *  # first derivative
+                      self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_SimPoint / self.a_T ** 3 -
+                                    35 / 2 * sed_dips_SimPoint ** 3 / self.a_T ** 5 +
+                                    21 / 4 * sed_dips_SimPoint ** 5 / self.a_T ** 7)))
+
+            ))
+            , axis=0)
+
+        return sigma_0_grad
+
+    def contribution_universal_drift_d(self, direction='x', grid_val=None, weights=None, a=0, b=100000000):
+        if weights is None:
+            weights = self.extend_dual_kriging()
+        if grid_val is None:
+            grid_val = self.x_to_interpolate()
+
+        self.gi_reescale = aesara.shared(2)
+
+        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C = self.matrices_shapes()
+
+        # These are the magic terms to get the same as geomodeller
+        i_rescale_aux = T.repeat(self.gi_reescale, 9)
+        i_rescale_aux = T.set_subtensor(i_rescale_aux[:3], 1)
+        _aux_magic_term = T.tile(i_rescale_aux[:self.n_universal_eq_T_op], (grid_val.shape[0], 1))
+
+        n = self.dips_position.shape[0]
+        n = grid_val.shape[0]
+        U_G = T.zeros((n, 9))
+
+        if direction == 'x':
+            # x
+            U_G = T.set_subtensor(U_G[:, 0], 1)
+            # x**2
+            U_G = T.set_subtensor(U_G[:, 3], 2 * self.gi_reescale * grid_val[:, 0])
+
+            # xy
+            U_G = T.set_subtensor(U_G[:, 6], self.gi_reescale * grid_val[:, 1])  # This is y
+            # xz
+            U_G = T.set_subtensor(U_G[:, 7], self.gi_reescale * grid_val[:, 2])  # This is z
+
+        if direction == 'y':
+            # y
+            U_G = T.set_subtensor(U_G[:, 1], 1)
+            # y**2
+            U_G = T.set_subtensor(U_G[:, 4], 2 * self.gi_reescale * grid_val[:, 1])
+            # xy
+            U_G = T.set_subtensor(U_G[:, 6], self.gi_reescale * grid_val[:, 0])  # This is x
+            # yz
+            U_G = T.set_subtensor(U_G[:, 8], self.gi_reescale * grid_val[:, 2])  # This is z
+
+        if direction == 'z':
+            # z
+            U_G = T.set_subtensor(U_G[:, 2], 1)
+
+            # z**2
+            U_G = T.set_subtensor(U_G[:, 5], 2 * self.gi_reescale * grid_val[:, 2])
+
+            # xz
+            U_G = T.set_subtensor(U_G[:, 7], self.gi_reescale * grid_val[:, 0])  # This is x
+
+            # yz
+            U_G = T.set_subtensor(U_G[:, 8], self.gi_reescale * grid_val[:, 1])  # This is y
+
+        # Drif contribution
+        f_0 = (T.sum(
+            weights[
+            length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I] *
+            U_G.T[:self.n_universal_eq_T_op]
+            , axis=0))
+
+        return f_0
+
+    def gradient_field_loop_x(self, a, b, Z_x, grid_val, weights, val):
+        direction = 'x'
+        sigma_0_grad = self.contribution_gradient(direction, grid_val[a:b], weights[:, a:b])
+        sigma_0_interf_gradient = self.contribution_interface_gradient(direction, grid_val[a:b], weights[:, a:b])
+        f_0 = self.contribution_universal_drift_d(direction, grid_val[a:b], weights[:, a:b], a, b)
+        #f_1 = self.faults_contribution(weights[:, a:b], a, b)
+
+        # Add an arbitrary number at the potential field to get unique values for each of them
+        partial_Z_x = (sigma_0_grad + sigma_0_interf_gradient + f_0)
+
+        Z_x = T.set_subtensor(Z_x[a:b], partial_Z_x)
+
+        return Z_x
+
+    def gradient_field_loop_y(self, a, b, Z_x, grid_val, weights, val):
+        direction = 'y'
+        sigma_0_grad = self.contribution_gradient(direction, grid_val[a:b], weights[:, a:b])
+        sigma_0_interf_gradient = self.contribution_interface_gradient(direction, grid_val[a:b], weights[:, a:b])
+        f_0 = self.contribution_universal_drift_d(direction, grid_val[a:b], weights[:, a:b], a, b)
+        #f_1 = self.faults_contribution(weights[:, a:b], a, b)
+
+        # Add an arbitrary number at the potential field to get unique values for each of them
+        partial_Z_x = (sigma_0_grad + sigma_0_interf_gradient + f_0)
+
+        Z_x = T.set_subtensor(Z_x[a:b], partial_Z_x)
+
+        return Z_x
+
+    def gradient_field_loop_z(self, a, b, Z_x, grid_val, weights, val):
+        direction = 'z'
+        sigma_0_grad = self.contribution_gradient(direction, grid_val[a:b], weights[:, a:b])
+        sigma_0_interf_gradient = self.contribution_interface_gradient(direction, grid_val[a:b], weights[:, a:b])
+        f_0 = self.contribution_universal_drift_d(direction, grid_val[a:b], weights[:, a:b], a, b)
+        #f_1 = self.faults_contribution(weights[:, a:b], a, b)
+
+        # Add an arbitrary number at the potential field to get unique values for each of them
+        partial_Z_x = (sigma_0_grad + sigma_0_interf_gradient + f_0)
+
+        Z_x = T.set_subtensor(Z_x[a:b], partial_Z_x)
+
+        return Z_x
+
+    def gradient_field_at_all(self, weights=None, gradients=[]):
+
+        grid_val = self.x_to_interpolate()
+        if weights is None:
+            weights = self.extend_dual_kriging()
+
+        grid_shape = T.stack([grid_val.shape[0]], axis=0)
+
+        Z_x_init = T.zeros(grid_shape, dtype='float32')
+        if 'grid_shape' in self.verbose:
+            grid_shape = aesara.printing.Print('grid_shape')(grid_shape)
+
+        steps = 1e13 / self.matrices_shapes()[-1] / grid_shape
+        slices = T.concatenate((T.arange(0, grid_shape[0], steps[0], dtype='int64'), grid_shape))
+
+        if 'slices' in self.verbose:
+            slices = aesara.printing.Print('slices')(slices)
+
+        G_field = T.zeros((3, self.grid_val_T.shape[0]))
+
+        if 'Gx' in gradients:
+            Gx_loop, updates5 = aesara.scan(
+                fn=self.gradient_field_loop_x,
+                outputs_info=[Z_x_init],
+                sequences=[dict(input=slices, taps=[0, 1])],
+                non_sequences=[grid_val, weights, self.n_surface_op],
+                profile=False,
+                name='Looping grid x',
+                return_list=True)
+
+            Gx = Gx_loop[-1][-1]
+            Gx.name = 'Value of the gradient field X at every point'
+            G_field = T.set_subtensor(G_field[0, :], Gx)
+
+        if 'Gy' in gradients:
+            Gy_loop, updates6 = aesara.scan(
+                fn=self.gradient_field_loop_y,
+                outputs_info=[Z_x_init],
+                sequences=[dict(input=slices, taps=[0, 1])],
+                non_sequences=[grid_val, weights, self.n_surface_op],
+                profile=False,
+                name='Looping grid y',
+                return_list=True)
+
+            Gy = Gy_loop[-1][-1]
+            Gy.name = 'Value of the gradient field X at every point'
+            G_field = T.set_subtensor(G_field[1, :], Gy)
+
+        if 'Gz' in gradients:
+            Gz_loop, updates7 = aesara.scan(
+                fn=self.gradient_field_loop_z,
+                outputs_info=[Z_x_init],
+                sequences=[dict(input=slices, taps=[0, 1])],
+                non_sequences=[grid_val, weights, self.n_surface_op],
+                profile=False,
+                name='Looping grid z',
+                return_list=True)
+
+            Gz = Gz_loop[-1][-1]
+            Gz.name = 'Value of the gradient field X at every point'
+            G_field = T.set_subtensor(G_field[2, :], Gz)
 
-    def update_default_kriging(self):
-        """
-        Update default kriging values.
-        """
-        self.kriging_data.set_default_range()
-        self.kriging_data.set_default_c_o()
-        self.kriging_data.set_u_grade()
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            Z_x = aesara.printing.Print('Potential field at all points')(Z_x)
 
-    def update_structure(self):
-        """
-        Update fields dependent on input data sucha as structure and universal kriging grade
-        """
-        self.structure_data.update_structure_from_input()
-        if len(self.kriging_data.df.loc['values', 'drift equations']) < \
-                self.structure_data.df.loc['values', 'number series']:
-            self.kriging_data.set_u_grade()
+        return G_field
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `gempy-2.2b10.dev1/gempy/core/grid_modules/create_topography.py` & `gempy-2.3.0/gempy/core/grid_modules/create_topography.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,286 +1,286 @@
-"""
-This file is part of gempy.
-
-Created on 16.04.2019
-
-@author: Elisa Heim
-"""
-
-import numpy as np
-from scipy import fftpack
-import pandas as pn
-import os
-
-try:
-    from osgeo import gdal
-    GDAL_IMPORT = True
-except ImportError as e:
-    GDAL_IMPORT = False
-    print(e)
-
-import matplotlib.pyplot as plt
-
-
-class LoadDEMGDAL:
-    """Class to include height elevation data (e.g. DEMs) with the geological grid
-    """
-
-    def __init__(self, path_dem, grid=None, extent=None, delete_temp=True):
-        """
-        Args:
-            path_dem: path where dem is stored. file format: GDAL raster formats
-            if grid: cropped to geomodel extent
-        """
-        if GDAL_IMPORT == False:
-            raise ImportError('Gdal package is not installed. No support for raster formats.')
-        self.dem = gdal.Open(path_dem)
-
-        if isinstance(self.dem, type(None)):
-            raise AttributeError('Raster file could not be opened {}. Check if the filepath is correct. If yes,'
-                                 'check if your file fits the requirements of GDALs raster file formats.'.format(
-                path_dem))
-
-        try:
-            self.dem_zval = self.dem.ReadAsArray()
-        except AttributeError:
-            raise AttributeError('Filepath seems to be wrong.')
-
-        self._get_raster_dimensions()
-
-        if extent is not None:
-            self.regular_grid_extent = extent
-            self.crop2grid()
-        elif grid is not None:
-            self.regular_grid_extent = grid.extent
-            self.crop2grid()
-        else:
-            print('pass geo_model to automatically crop the DEM to the grid extent')
-        print('depending on the size of the raster, this can take a while...')
-        self.convert2xyz()
-
-        if delete_temp is True:
-            self.dem = None
-            os.remove('topo.xyz')
-            if os.path.exists('_cropped_DEM.tif'):
-                os.remove('_cropped_DEM.tif')
-
-    def _get_raster_dimensions(self):
-        """calculates DEM extent, resolution, and max. z extent (d_z)"""
-        ulx, xres, xskew, uly, yskew, yres = self.dem.GetGeoTransform()
-        z = self.dem_zval
-        if np.any(np.array([xskew, yskew])) != 0:
-            print('DEM is not north-oriented.')
-        lrx = ulx + (self.dem.RasterXSize * xres)
-        lry = uly + (self.dem.RasterYSize * yres)
-        self.resolution = np.array([(uly - lry) / (-yres), (lrx - ulx) / xres]).astype(int)
-        self.extent = np.array([ulx, lrx, lry, uly]).astype(int)
-        self.d_z = np.array([z.min(), z.max()])
-
-    def get_values(self):
-        return self.values_3D
-
-    def info(self):
-        ulx, xres, xskew, uly, yskew, yres = self.dem.GetGeoTransform()
-        print('raster extent:  {}\n raster resolution: {}\n Pixel X size {}, Pixel Y size {}'.format(
-            self.extent, self.resolution, xres, yres))
-        plt.imshow(self.dem_zval, extent=self.extent)  # plot raster as image
-        plt.colorbar()
-
-    def crop2grid(self, delete_temp=True):
-        """
-        Crops raster to extent of the geomodel grid.
-        """
-        cornerpoints_geo = self._get_cornerpoints(self.regular_grid_extent)
-        cornerpoints_dtm = self._get_cornerpoints(self.extent)
-
-        # self.check()
-
-        if np.any(cornerpoints_geo[:2] - cornerpoints_dtm[:2]) != 0:
-            path_dest = '_cropped_DEM.tif'
-            new_bounds = (self.regular_grid_extent[[0, 2, 1, 3]])
-            gdal.Warp(path_dest, self.dem, options=gdal.WarpOptions(
-                options=['outputBounds'], outputBounds=new_bounds))
-
-            self.dem = gdal.Open(path_dest)
-            self.dem_zval = self.dem.ReadAsArray()
-            self._get_raster_dimensions()
-
-        print('Cropped raster to geo_model.grid.extent.')
-
-    def check(self):
-        # TODO make this usable
-        test = np.logical_and.reduce((self.regular_grid_extent[0] <= self.extent[0],
-                                      self.regular_grid_extent[1] >= self.extent[1],
-                                      self.regular_grid_extent[2] <= self.extent[2],
-                                      self.regular_grid_extent[3] >= self.extent[3]))
-        if test:
-            cornerpoints_geo = self._get_cornerpoints(self.regular_grid_extent)
-            cornerpoints_dtm = self._get_cornerpoints(self.extent)
-            plt.scatter(cornerpoints_geo[:, 0], cornerpoints_geo[:, 1], label='grid extent')
-            plt.scatter(cornerpoints_dtm[:, 0], cornerpoints_dtm[:, 1], label='raster extent')
-            plt.legend(frameon=True, loc='upper left')
-            raise AssertionError('The model extent is too different from the raster extent.')
-
-    def convert2xyz(self, del_temp=True):
-        """
-        Translates the gdal raster object to a numpy array of xyz coordinates.
-        """
-        path_dest = 'topo.xyz'
-        print('storing converted file...')
-        shape = self.dem_zval.shape
-        if len(shape) == 3:
-            shape = shape[1:]
-        gdal.Translate(path_dest, self.dem, options=gdal.TranslateOptions(options=['format'], format="XYZ"))
-
-        xyz = pn.read_csv(path_dest, header=None, sep=' ').values
-        self.values_3D = xyz.reshape((*shape, 3), order='C')
-
-        # This is for 3D going from xyz to ijk
-        self.values_3D = self.values_3D.swapaxes(0, 1)
-        self.values_3D = np.flip(self.values_3D, 1)
-
-        return self.values_3D
-
-    def _resize(self, resx, resy):
-        raise NotImplementedError
-
-    def resample(self, new_xres, new_yres, save_path):
-        """
-        Decrease the pixel size of the raster.
-
-        Args:
-            new_xres (int): desired resolution in x-direction
-            new_yres (int): desired resolution in y-direction
-            save_path (str): filepath to where the output file should be stored
-
-        Returns: Nothing, it writes a raster file with decreased resolution.
-
-        """
-        props = self.dem.GetGeoTransform()
-        print('current pixel xsize:', props[1], 'current pixel ysize:', -props[-1])
-        options = gdal.WarpOptions(options=['tr'], xRes=new_xres, yRes=new_yres)
-        newfile = gdal.Warp(save_path, self.dem, options=options)
-        newprops = newfile.GetGeoTransform()
-        print('new pixel xsize:', newprops[1], 'new pixel ysize:', -newprops[-1])
-        print('file saved in ' + save_path)
-
-    def _get_cornerpoints(self, extent):
-        """Get the coordinates of the bounding box.
-
-        Args:
-            extent: np.array([xmin, xmax, ymin, ymax)]
-
-        Returns: np.ndarray with corner coordinates
-
-        """
-        upleft = ([extent[0], extent[3]])
-        lowleft = ([extent[0], extent[2]])
-        upright = ([extent[1], extent[3]])
-        lowright = ([extent[1], extent[2]])
-        return np.array([upleft, lowleft, upright, lowright])
-
-
-class LoadDEMArtificial:
-
-    def __init__(self, grid=None, fd=2.0, extent=None, resolution=None, d_z=None):
-        """Class to create a random topography based on a fractal grid algorithm.
-
-        Args:
-            fd:         fractal dimension, defaults to 2.0
-            d_z:        maximum height difference. If none, last 20% of the model in z direction
-            extent:     extent in xy direction. If none, geo_model.grid.extent
-            resolution: desired resolution of the topography array. If none, geo_model.grid.resolution
-        """
-        self.values_2d = np.array([])
-
-        self.resolution = grid.resolution[:2] if resolution is None else resolution
-
-        assert all(np.asarray(self.resolution) >= 2), 'The regular grid needs to be at least of size 2 on all ' \
-                                                      'directions.'
-        self.extent = grid.extent if extent is None else extent
-
-        if d_z is None:
-            self.d_z = np.array(
-                [self.extent[5] - (self.extent[5] - self.extent[4]) * 1 / 5,
-                 self.extent[5]])
-            print(self.d_z)
-        else:
-            self.d_z = d_z
-
-        topo = self.fractalGrid(fd, n=self.resolution.max())
-        topo = np.interp(topo, (topo.min(), topo.max()), self.d_z)
-
-        self.dem_zval = topo[:self.resolution[0], :self.resolution[1]]  # crop fractal grid with resolution
-        self.create_topo_array()
-
-    def fractalGrid(self, fd, n=256):
-        """
-        Modified after https://github.com/samthiele/pycompass/blob/master/examples/3_Synthetic%20Examples.ipynb
-
-        Generate isotropic fractal surface image using
-        spectral synthesis method [1, p.]
-        References:
-        1. Yuval Fisher, Michael McGuire,
-        The Science of Fractal Images, 1988
-
-        (cf. http://shortrecipes.blogspot.com.au/2008/11/python-isotropic-fractal-surface.html)
-        **Arguments**:
-         -fd = the fractal dimension
-         -N = the size of the fractal surface/image
-
-        """
-        h = 1 - (fd - 2)
-        # X = np.zeros((N, N), complex)
-        a = np.zeros((n, n), complex)
-        powerr = -(h + 1.0) / 2.0
-
-        for i in range(int(n / 2) + 1):
-            for j in range(int(n / 2) + 1):
-                phase = 2 * np.pi * np.random.rand()
-
-                if i != 0 or j != 0:
-                    rad = (i * i + j * j) ** powerr * np.random.normal()
-                else:
-                    rad = 0.0
-
-                a[i, j] = complex(rad * np.cos(phase), rad * np.sin(phase))
-
-                if i == 0:
-                    i0 = 0
-                else:
-                    i0 = n - i
-
-                if j == 0:
-                    j0 = 0
-                else:
-                    j0 = n - j
-
-                a[i0, j0] = complex(rad * np.cos(phase), -rad * np.sin(phase))
-
-                a.imag[int(n / 2)][0] = 0.0
-                a.imag[0, int(n / 2)] = 0.0
-                a.imag[int(n / 2)][int(n / 2)] = 0.0
-
-        for i in range(1, int(n / 2)):
-            for j in range(1, int(n / 2)):
-                phase = 2 * np.pi * np.random.rand()
-                rad = (i * i + j * j) ** powerr * np.random.normal()
-                a[i, n - j] = complex(rad * np.cos(phase), rad * np.sin(phase))
-                a[n - i, j] = complex(rad * np.cos(phase), -rad * np.sin(phase))
-
-        itemp = fftpack.ifft2(a)
-        itemp = itemp - itemp.min()
-
-        return itemp.real / itemp.real.max()
-
-    def create_topo_array(self):
-        """for masking the lith block"""
-        x = np.linspace(self.extent[0], self.extent[1], self.resolution[0])
-        y = np.linspace(self.extent[2], self.extent[3], self.resolution[1])
-        self.x = x
-        self.y = y
-        xx, yy = np.meshgrid(x, y, indexing='ij')
-        self.values_2d = np.dstack([xx, yy, self.dem_zval])
-
-    def get_values(self):
-        return self.values_2d
+"""
+This file is part of gempy.
+
+Created on 16.04.2019
+
+@author: Elisa Heim
+"""
+
+import numpy as np
+from scipy import fftpack
+import pandas as pn
+import os
+
+try:
+    from osgeo import gdal
+    GDAL_IMPORT = True
+except ImportError as e:
+    GDAL_IMPORT = False
+    print(e)
+
+import matplotlib.pyplot as plt
+
+
+class LoadDEMGDAL:
+    """Class to include height elevation data (e.g. DEMs) with the geological grid
+    """
+
+    def __init__(self, path_dem, grid=None, extent=None, delete_temp=True):
+        """
+        Args:
+            path_dem: path where dem is stored. file format: GDAL raster formats
+            if grid: cropped to geomodel extent
+        """
+        if GDAL_IMPORT == False:
+            raise ImportError('Gdal package is not installed. No support for raster formats.')
+        self.dem = gdal.Open(path_dem)
+
+        if isinstance(self.dem, type(None)):
+            raise AttributeError('Raster file could not be opened {}. Check if the filepath is correct. If yes,'
+                                 'check if your file fits the requirements of GDALs raster file formats.'.format(
+                path_dem))
+
+        try:
+            self.dem_zval = self.dem.ReadAsArray()
+        except AttributeError:
+            raise AttributeError('Filepath seems to be wrong.')
+
+        self._get_raster_dimensions()
+
+        if extent is not None:
+            self.regular_grid_extent = extent
+            self.crop2grid()
+        elif grid is not None:
+            self.regular_grid_extent = grid.extent
+            self.crop2grid()
+        else:
+            print('pass geo_model to automatically crop the DEM to the grid extent')
+        print('depending on the size of the raster, this can take a while...')
+        self.convert2xyz()
+
+        if delete_temp is True:
+            self.dem = None
+            os.remove('topo.xyz')
+            if os.path.exists('_cropped_DEM.tif'):
+                os.remove('_cropped_DEM.tif')
+
+    def _get_raster_dimensions(self):
+        """calculates DEM extent, resolution, and max. z extent (d_z)"""
+        ulx, xres, xskew, uly, yskew, yres = self.dem.GetGeoTransform()
+        z = self.dem_zval
+        if np.any(np.array([xskew, yskew])) != 0:
+            print('DEM is not north-oriented.')
+        lrx = ulx + (self.dem.RasterXSize * xres)
+        lry = uly + (self.dem.RasterYSize * yres)
+        self.resolution = np.array([(uly - lry) / (-yres), (lrx - ulx) / xres]).astype(int)
+        self.extent = np.array([ulx, lrx, lry, uly]).astype(int)
+        self.d_z = np.array([z.min(), z.max()])
+
+    def get_values(self):
+        return self.values_3D
+
+    def info(self):
+        ulx, xres, xskew, uly, yskew, yres = self.dem.GetGeoTransform()
+        print('raster extent:  {}\n raster resolution: {}\n Pixel X size {}, Pixel Y size {}'.format(
+            self.extent, self.resolution, xres, yres))
+        plt.imshow(self.dem_zval, extent=self.extent)  # plot raster as image
+        plt.colorbar()
+
+    def crop2grid(self, delete_temp=True):
+        """
+        Crops raster to extent of the geomodel grid.
+        """
+        cornerpoints_geo = self._get_cornerpoints(self.regular_grid_extent)
+        cornerpoints_dtm = self._get_cornerpoints(self.extent)
+
+        # self.check()
+
+        if np.any(cornerpoints_geo[:2] - cornerpoints_dtm[:2]) != 0:
+            path_dest = '_cropped_DEM.tif'
+            new_bounds = (self.regular_grid_extent[[0, 2, 1, 3]])
+            gdal.Warp(path_dest, self.dem, options=gdal.WarpOptions(
+                options=['outputBounds'], outputBounds=new_bounds))
+
+            self.dem = gdal.Open(path_dest)
+            self.dem_zval = self.dem.ReadAsArray()
+            self._get_raster_dimensions()
+
+        print('Cropped raster to geo_model.grid.extent.')
+
+    def check(self):
+        # TODO make this usable
+        test = np.logical_and.reduce((self.regular_grid_extent[0] <= self.extent[0],
+                                      self.regular_grid_extent[1] >= self.extent[1],
+                                      self.regular_grid_extent[2] <= self.extent[2],
+                                      self.regular_grid_extent[3] >= self.extent[3]))
+        if test:
+            cornerpoints_geo = self._get_cornerpoints(self.regular_grid_extent)
+            cornerpoints_dtm = self._get_cornerpoints(self.extent)
+            plt.scatter(cornerpoints_geo[:, 0], cornerpoints_geo[:, 1], label='grid extent')
+            plt.scatter(cornerpoints_dtm[:, 0], cornerpoints_dtm[:, 1], label='raster extent')
+            plt.legend(frameon=True, loc='upper left')
+            raise AssertionError('The model extent is too different from the raster extent.')
+
+    def convert2xyz(self, del_temp=True):
+        """
+        Translates the gdal raster object to a numpy array of xyz coordinates.
+        """
+        path_dest = 'topo.xyz'
+        print('storing converted file...')
+        shape = self.dem_zval.shape
+        if len(shape) == 3:
+            shape = shape[1:]
+        gdal.Translate(path_dest, self.dem, options=gdal.TranslateOptions(options=['format'], format="XYZ"))
+
+        xyz = pn.read_csv(path_dest, header=None, sep=' ').values
+        self.values_3D = xyz.reshape((*shape, 3), order='C')
+
+        # This is for 3D going from xyz to ijk
+        self.values_3D = self.values_3D.swapaxes(0, 1)
+        self.values_3D = np.flip(self.values_3D, 1)
+
+        return self.values_3D
+
+    def _resize(self, resx, resy):
+        raise NotImplementedError
+
+    def resample(self, new_xres, new_yres, save_path):
+        """
+        Decrease the pixel size of the raster.
+
+        Args:
+            new_xres (int): desired resolution in x-direction
+            new_yres (int): desired resolution in y-direction
+            save_path (str): filepath to where the output file should be stored
+
+        Returns: Nothing, it writes a raster file with decreased resolution.
+
+        """
+        props = self.dem.GetGeoTransform()
+        print('current pixel xsize:', props[1], 'current pixel ysize:', -props[-1])
+        options = gdal.WarpOptions(options=['tr'], xRes=new_xres, yRes=new_yres)
+        newfile = gdal.Warp(save_path, self.dem, options=options)
+        newprops = newfile.GetGeoTransform()
+        print('new pixel xsize:', newprops[1], 'new pixel ysize:', -newprops[-1])
+        print('file saved in ' + save_path)
+
+    def _get_cornerpoints(self, extent):
+        """Get the coordinates of the bounding box.
+
+        Args:
+            extent: np.array([xmin, xmax, ymin, ymax)]
+
+        Returns: np.ndarray with corner coordinates
+
+        """
+        upleft = ([extent[0], extent[3]])
+        lowleft = ([extent[0], extent[2]])
+        upright = ([extent[1], extent[3]])
+        lowright = ([extent[1], extent[2]])
+        return np.array([upleft, lowleft, upright, lowright])
+
+
+class LoadDEMArtificial:
+
+    def __init__(self, grid=None, fd=2.0, extent=None, resolution=None, d_z=None):
+        """Class to create a random topography based on a fractal grid algorithm.
+
+        Args:
+            fd:         fractal dimension, defaults to 2.0
+            d_z:        maximum height difference. If none, last 20% of the model in z direction
+            extent:     extent in xy direction. If none, geo_model.grid.extent
+            resolution: desired resolution of the topography array. If none, geo_model.grid.resolution
+        """
+        self.values_2d = np.array([])
+
+        self.resolution = grid.resolution[:2] if resolution is None else resolution
+
+        assert all(np.asarray(self.resolution) >= 2), 'The regular grid needs to be at least of size 2 on all ' \
+                                                      'directions.'
+        self.extent = grid.extent if extent is None else extent
+
+        if d_z is None:
+            self.d_z = np.array(
+                [self.extent[5] - (self.extent[5] - self.extent[4]) * 1 / 5,
+                 self.extent[5]])
+            print(self.d_z)
+        else:
+            self.d_z = d_z
+
+        topo = self.fractalGrid(fd, n=self.resolution.max())
+        topo = np.interp(topo, (topo.min(), topo.max()), self.d_z)
+
+        self.dem_zval = topo[:self.resolution[0], :self.resolution[1]]  # crop fractal grid with resolution
+        self.create_topo_array()
+
+    def fractalGrid(self, fd, n=256):
+        """
+        Modified after https://github.com/samthiele/pycompass/blob/master/examples/3_Synthetic%20Examples.ipynb
+
+        Generate isotropic fractal surface image using
+        spectral synthesis method [1, p.]
+        References:
+        1. Yuval Fisher, Michael McGuire,
+        The Science of Fractal Images, 1988
+
+        (cf. http://shortrecipes.blogspot.com.au/2008/11/python-isotropic-fractal-surface.html)
+        **Arguments**:
+         -fd = the fractal dimension
+         -N = the size of the fractal surface/image
+
+        """
+        h = 1 - (fd - 2)
+        # X = np.zeros((N, N), complex)
+        a = np.zeros((n, n), complex)
+        powerr = -(h + 1.0) / 2.0
+
+        for i in range(int(n / 2) + 1):
+            for j in range(int(n / 2) + 1):
+                phase = 2 * np.pi * np.random.rand()
+
+                if i != 0 or j != 0:
+                    rad = (i * i + j * j) ** powerr * np.random.normal()
+                else:
+                    rad = 0.0
+
+                a[i, j] = complex(rad * np.cos(phase), rad * np.sin(phase))
+
+                if i == 0:
+                    i0 = 0
+                else:
+                    i0 = n - i
+
+                if j == 0:
+                    j0 = 0
+                else:
+                    j0 = n - j
+
+                a[i0, j0] = complex(rad * np.cos(phase), -rad * np.sin(phase))
+
+                a.imag[int(n / 2)][0] = 0.0
+                a.imag[0, int(n / 2)] = 0.0
+                a.imag[int(n / 2)][int(n / 2)] = 0.0
+
+        for i in range(1, int(n / 2)):
+            for j in range(1, int(n / 2)):
+                phase = 2 * np.pi * np.random.rand()
+                rad = (i * i + j * j) ** powerr * np.random.normal()
+                a[i, n - j] = complex(rad * np.cos(phase), rad * np.sin(phase))
+                a[n - i, j] = complex(rad * np.cos(phase), -rad * np.sin(phase))
+
+        itemp = fftpack.ifft2(a)
+        itemp = itemp - itemp.min()
+
+        return itemp.real / itemp.real.max()
+
+    def create_topo_array(self):
+        """for masking the lith block"""
+        x = np.linspace(self.extent[0], self.extent[1], self.resolution[0])
+        y = np.linspace(self.extent[2], self.extent[3], self.resolution[1])
+        self.x = x
+        self.y = y
+        xx, yy = np.meshgrid(x, y, indexing='ij')
+        self.values_2d = np.dstack([xx, yy, self.dem_zval])
+
+    def get_values(self):
+        return self.values_2d
```

### Comparing `gempy-2.2b10.dev1/gempy/core/grid_modules/diamond_square.py` & `gempy-2.3.0/gempy/core/grid_modules/diamond_square.py`

 * *Ordering differences only*

 * *Files 9% similar despite different names*

```diff
@@ -1,352 +1,352 @@
-"""Implementation of Diamond-Square algorithm
-
-This algorithm is often used for random topography generation, following Fournier et al., 1982
-see https://en.wikipedia.org/wiki/Diamond-square_algorithm.
-
-Fournier, Alain; Fussell, Don; Carpenter, Loren (June 1982). "Computer rendering of stochastic models".
-Communications of the ACM. 25 (6): 371–384.
-
-Here the description from the wikipedia page:
-
-+++ begin Wikipedia +++
-
-The diamond-square algorithm begins with a 2D square array of width and
-height 2n + 1. The four corner points of the array must first be set to initial values. The diamond and square steps
-are then performed alternately until all array values have been set.
-
-The diamond step: For each square in the array, set the midpoint of that square to be the average of the four corner
-points plus a random value.
-
-The square step: For each diamond in the array, set the midpoint of that diamond to be the average of the four corner
-points plus a random value.
-
-At each iteration, the magnitude of the random value should be reduced.
-
-During the square steps, points located on the edges of the array will have only three adjacent values set rather
-than four. There are a number of ways to handle this complication - the simplest being to take the average of just
-the three adjacent values. Another option is to 'wrap around', taking the fourth value from the other side of the
-array. When used with consistent initial corner values this method also allows generated fractals to be stitched
-together without discontinuities.
-
-+++ end Wikipedia +++
-
-The implementations (in Python) I could find online were either difficult to understand or had many case
-selections, especially at edges. Here is a fully vectorized implementation, using padding at edges, to avoid
-all these case selections for a more straight-forward implementation (I hope).
-
-This implementation is also adjusted to work on non-square start matrices, and on reduced hierarchies with
-more initial (internal) points.
-
-Created on 10.04.2020
-
-@author: Florian Wellmann
-
-"""
-import numpy as np
-import matplotlib.pyplot as plt
-
-
-class DiaomondSquare(object):
-
-    def __init__(self, size: tuple = (16, 16), roughness: float = 0.5, z_min: float = 0, z_max:
-                 float = 1, r_type: chr = 'default', **kwds):
-        """Implementation of vectorized Diaomnd-Square algorithm for random topography generation
-
-        Args:
-            size (int, int): shape of grid to interpolate; note: the standard diamond-square algorithm
-                operates on a square grid with side length 2**n+1. This implementation is adjusted to non-square
-                grids with (2**n+1, 2**m+1). If the input size (int, int) is not matching to the ideal dimension,
-                the next bigger size is taken and the grid finally cut (lower left corner is kept);
-            roughness: roughness parameter, [0,1]: 0: deterministic interpolation, 1: very rough and bumpy (in standard
-                randomisation method - other options available in self.random_func())
-            z_min: minimum height of surface
-            z_max: maximum height of surface
-            seed: seed for random function to enable reproducibility and testing
-            r_type: 'basic', 'level_scale' (See below for details)
-            
-        Options for the randomization function (self.r_type) are:
-        - 'default': standard reduction
-        - 'level_scale' : uniform distribution between z_min, z_max, scaled by (level + 1)
-
-        """
-        self.size = size
-        # Create mesh with optimal size (2**n+1, 2**m+1)
-        # If the input size `self.size` does not match to these dimensions, then the next larger suitable
-        # size is chosen.
-        self.n = np.ceil(np.log2(self.size[0] - 1)).astype('int8')
-        self.m = np.ceil(np.log2(self.size[1] - 1)).astype('int8')
-        self.grid = np.zeros((2 ** self.n + 1, 2 ** self.m + 1))
-        self.roughness = roughness
-        self.z_min = z_min
-        self.z_max = z_max
-        if 'seed' in kwds:
-            np.random.seed(kwds['seed'])
-        self.base_rand_range = 1
-        self.r_type = r_type
-
-    def random_func(self, i, level_shape):
-        """Define random function to adjust range for subsequent steps
-
-        The random function type is defined on class level (self.r_type)
-        """
-
-        if self.r_type == 'default':
-            if self.roughness > 0:
-                rand_range = self.base_rand_range * 2 ** (- (1 - self.roughness) * i)
-                return np.random.uniform(-rand_range, rand_range, level_shape)
-            else:
-                return 0.
-
-        if self.r_type == 'long_range':
-            if self.roughness > 0:
-                rand_range = self.base_rand_range * 16 ** (- (1 - self.roughness) * i)
-                return np.random.uniform(-rand_range, rand_range, level_shape)
-            else:
-                return 0.
-
-        elif self.r_type == 'level_scale':
-            if self.roughness > 0:
-                return np.random.uniform(self.z_min, self.z_max,
-                                         level_shape) / (1 + i)
-            else:
-                return 0.
-
-        elif self.r_type == 'deterministic':
-            # No randomization at all - deterministic interpolation result
-            return 0.
-
-        else:
-            raise NotImplementedError("Random function type %s not implemented" % self.r_type)
-
-    def random_initialization(self, level='highest', verbose: bool=False):
-        """Initialize cells on speicifc hierarchy with random values
-
-        Args:
-            level = 'hightest', int : hierarchy level for interpolation (default: highest)
-            verbose: verbose output (default: False)
-
-        With highest hierarchy, we refer here to the largest diamond-square step, i.e. the corner points
-        for a square grid; Or, more formally: the diamond points for `min(self.n, self.m)`
-        """
-        if level == 'highest':
-            m_pow_max = min(self.n, self.m)
-        else:
-            m_pow_max = level
-
-        step_size = int(2 ** m_pow_max)
-        if verbose:
-            print("Initialize on step size %d" % step_size)
-
-        level_shape = self.grid[::step_size, ::step_size].shape
-
-        self.grid[::step_size, ::step_size] = np.random.uniform(0, 1, level_shape)  # self.random_func(0, level_shape)
-
-    def interpolate(self, level='highest'):
-        """Perform diamond-square interpolation
-
-        Args:
-            level = 'hightest', int : hierarchy level for interpolation (default: highest)
-
-        This step follows the conventional procedure:
-        Iterate over hierarchies and repeat:
-        2) Perform Diamond interpolation step
-        3) Perform Square interpolation step
-        4) Reduce roughness factor
-        """
-        if level == 'highest':
-            # determine highest hierarchy level (determined by shorter rectangle side)
-            m_pow_max = min(self.n, self.m)
-        else:
-            m_pow_max = level
-
-        for i, m_pow in enumerate(np.arange(m_pow_max)[::-1]):
-            self.perform_diamond_step(i, m_pow)
-            self.perform_square_step(i, m_pow)
-
-    def reset_grid(self):
-        """Reset grid back to zero values"""
-        self.grid[:, :] = 0
-
-    def perform_diamond_step(self, i: int, m_pow: int):
-        """Perform one diamond interpolation step on hierarchy m_pow
-
-        Note: for more details on the vectorized selection, see self.get_selection_diamond()
-        """
-        step_size = int(2 ** m_pow)
-
-        # Diamond step
-        # ----------------
-
-        # get shape of this step
-        level_shape = self.grid[step_size::2 * step_size, step_size::2 * step_size].shape
-
-        self.grid[step_size::2 * step_size, step_size::2 * step_size] = \
-            (self.grid[:-2 * step_size:2 * step_size, :-2 * step_size:2 * step_size] +
-             self.grid[:-2 * step_size:2 * step_size, 2 * step_size::2 * step_size] +
-             self.grid[2 * step_size::2 * step_size, :-2 * step_size:2 * step_size] +
-             self.grid[2 * step_size::2 * step_size, 2 * step_size::2 * step_size]) / \
-            4. + \
-            self.random_func(i, level_shape)
-
-        # np.random.uniform(-rand_range, rand_range, level_shape)
-
-        # self.d * 2**()
-        # self.roughness ** i * (np.random.random(step_shape) - 0.5)
-
-        # (np.random.random(step_shape) - 0.5) * i * self.roughness
-
-    def perform_square_step(self, i: int, m_pow: int):
-        """Perform one square interpolation step on hierarchy m_pow
-
-        Note: for more details on the vectorized selection, see self.get_selection_square()
-        """
-        step_size = int(2 ** m_pow)
-
-        # pad cells with zero value
-        z_pad = np.pad(self.grid, step_size, mode='constant')
-
-        # also create a grid for division to divide only by 3 on borders
-        grid_div = np.ones_like(self.grid[1:-1, 1:-1]) * 4.
-        grid_div = np.pad(grid_div, step_size + 1, mode='constant', constant_values=3.)
-
-        # Checkerboard odd
-        # ----------------
-
-        # get shape of this step
-        level_shape = grid_div[step_size::2 * step_size, 2 * step_size:-2 * step_size:2 * step_size].shape
-
-        z_pad[step_size::2 * step_size, 2 * step_size:-2 * step_size:2 * step_size] = \
-            (z_pad[step_size::2 * step_size, step_size:-2 * step_size:2 * step_size] +
-             z_pad[step_size::2 * step_size, 3 * step_size:-step_size:2 * step_size] +
-             z_pad[:-step_size:2 * step_size, 2 * step_size:-2 * step_size:2 * step_size] +
-             z_pad[2 * step_size::2 * step_size, 2 * step_size:-2 * step_size:2 * step_size]) / \
-            grid_div[step_size::2 * step_size, 2 * step_size:-2 * step_size:2 * step_size] + \
-            self.random_func(i, level_shape)
-
-        # np.random.uniform(-rand_range, rand_range, level_shape)
-
-        #    self.roughness ** i * (np.random.random(step_shape) - 0.5)
-
-        # (np.random.random(step_shape) - 0.5) * i * self.roughness
-
-        # Checkerboard even
-        # -----------------
-
-        # get shape of this step
-        level_shape = z_pad[2 * step_size:-2 * step_size:2 * step_size, step_size:-step_size:2 * step_size].shape
-
-        # check-even, values to interpolate:
-        z_pad[2 * step_size:-2 * step_size:2 * step_size, step_size:-step_size:2 * step_size] = \
-            (z_pad[2 * step_size:-2 * step_size:2 * step_size, :-2 * step_size:2 * step_size] +
-             z_pad[2 * step_size:-2 * step_size:2 * step_size, 2 * step_size::2 * step_size] +
-             z_pad[step_size:-2 * step_size:2 * step_size, step_size:-step_size:2 * step_size] +
-             z_pad[3 * step_size::2 * step_size, step_size:-step_size:2 * step_size]) / \
-            grid_div[2 * step_size:-2 * step_size:2 * step_size, step_size:-step_size:2 * step_size] + \
-            self.random_func(i, level_shape)
-
-        # np.random.uniform(-rand_range, rand_range, level_shape)
-
-        # self.roughness ** i * (np.random.random(step_shape) - 0.5)
-
-        # (np.random.random(step_shape) - 0.5) * i * self.roughness
-
-        # assign results back to self.grid
-        self.grid = z_pad[step_size:-step_size, step_size:-step_size]
-
-    def get_selection_diamond(self, m_pow: int):
-        """get selected points for diamond step on grid z on hierarchy m
-
-        This method is mostly implemented for testing and visualization purposes.
-        """
-
-        step_size = int(2 ** m_pow)
-
-        z = np.zeros_like(self.grid, dtype='int8')
-
-        # points to interpolate
-        z[step_size::2 * step_size, step_size::2 * step_size] = 1
-
-        # top left
-        z[:-2 * step_size:2 * step_size, :-2 * step_size:2 * step_size] = 2
-
-        # top right
-        z[:-2 * step_size:2 * step_size, 2 * step_size::2 * step_size] = 2
-
-        # bottom left
-        z[2 * step_size::2 * step_size, :-2 * step_size:2 * step_size] = 2
-
-        # bottom right
-        z[2 * step_size::2 * step_size, 2 * step_size::2 * step_size] = 2
-
-        return z
-
-    def get_selection_square(self, m_pow: int):
-        """Plot selected points for square step on grid z on hierarchy m
-
-        This method is mostly implemented for testing and visualization purposes.
-        """
-        z = np.zeros_like(self.grid, dtype='int8')
-        step_size = int(2 ** m_pow)
-
-        # pad cells with zero value
-        z_pad = np.pad(z, step_size, mode='constant')
-
-        # Checkerboard odd
-        # ----------------
-
-        # check-odd, values to interpolate:
-        z_pad[step_size::2 * step_size, 2 * step_size:-2 * step_size:2 * step_size] = 1
-
-        # check-odd, left
-        z_pad[step_size::2 * step_size, step_size:-2 * step_size:2 * step_size] = 2
-
-        # check-odd, right
-        z_pad[step_size::2 * step_size, 3 * step_size:-step_size:2 * step_size] = 2
-
-        # check-odd, top
-        z_pad[:-step_size:2 * step_size, 2 * step_size:-2 * step_size:2 * step_size] = 2
-
-        # check-odd, bottom
-        z_pad[2 * step_size::2 * step_size, 2 * step_size:-2 * step_size:2 * step_size] = 2
-
-        # Checkerboard even
-        # -----------------
-
-        # check-even, values to interpolate:
-        z_pad[2 * step_size:-2 * step_size:2 * step_size, step_size:-step_size:2 * step_size] = 1
-
-        # check-even, left:
-        z_pad[2 * step_size:-2 * step_size:2 * step_size, :-2 * step_size:2 * step_size] = 2
-
-        # check-even, right:
-        z_pad[2 * step_size:-2 * step_size:2 * step_size, 2 * step_size::2 * step_size] = 2
-
-        # check-even, top:
-        z_pad[step_size:-2 * step_size:2 * step_size, step_size:-step_size:2 * step_size] = 2
-
-        # check-even, bottom:
-        z_pad[3 * step_size::2 * step_size, step_size:-step_size:2 * step_size] = 2
-
-        return z_pad
-
-    def plot_diamond_and_square(self, pad=False):
-        """Plot selected points for diamond and square step for all hierarchies side by side"""
-
-        m_pow_max = min(self.n, self.m)
-
-        shape_ratio = self.n / self.m
-
-        f, axes = plt.subplots(2, m_pow_max, figsize=(12, 12 * shape_ratio / m_pow_max * 2))
-
-        for i, m_pow in enumerate(np.arange(m_pow_max)[::-1]):
-            m = 2 ** m_pow
-            # z_zero = np.zeros_like(self.grid)
-            z_diamond = self.get_selection_diamond(m_pow)
-            z_square = self.get_selection_square(m_pow)
-            if pad:
-                z_pad = np.pad(z_diamond, m, mode='constant')
-                axes[0, i].imshow(z_pad, cmap='viridis', vmin=0, vmax=2)
-                axes[1, i].imshow(z_square, cmap='viridis', vmin=0, vmax=2)
-            else:
-                axes[0, i].imshow(z_diamond, cmap='viridis', vmin=0, vmax=2)
-                axes[1, i].imshow(z_square[m:-m, m:-m], cmap='viridis', vmin=0, vmax=2)
+"""Implementation of Diamond-Square algorithm
+
+This algorithm is often used for random topography generation, following Fournier et al., 1982
+see https://en.wikipedia.org/wiki/Diamond-square_algorithm.
+
+Fournier, Alain; Fussell, Don; Carpenter, Loren (June 1982). "Computer rendering of stochastic models".
+Communications of the ACM. 25 (6): 371–384.
+
+Here the description from the wikipedia page:
+
++++ begin Wikipedia +++
+
+The diamond-square algorithm begins with a 2D square array of width and
+height 2n + 1. The four corner points of the array must first be set to initial values. The diamond and square steps
+are then performed alternately until all array values have been set.
+
+The diamond step: For each square in the array, set the midpoint of that square to be the average of the four corner
+points plus a random value.
+
+The square step: For each diamond in the array, set the midpoint of that diamond to be the average of the four corner
+points plus a random value.
+
+At each iteration, the magnitude of the random value should be reduced.
+
+During the square steps, points located on the edges of the array will have only three adjacent values set rather
+than four. There are a number of ways to handle this complication - the simplest being to take the average of just
+the three adjacent values. Another option is to 'wrap around', taking the fourth value from the other side of the
+array. When used with consistent initial corner values this method also allows generated fractals to be stitched
+together without discontinuities.
+
++++ end Wikipedia +++
+
+The implementations (in Python) I could find online were either difficult to understand or had many case
+selections, especially at edges. Here is a fully vectorized implementation, using padding at edges, to avoid
+all these case selections for a more straight-forward implementation (I hope).
+
+This implementation is also adjusted to work on non-square start matrices, and on reduced hierarchies with
+more initial (internal) points.
+
+Created on 10.04.2020
+
+@author: Florian Wellmann
+
+"""
+import numpy as np
+import matplotlib.pyplot as plt
+
+
+class DiaomondSquare(object):
+
+    def __init__(self, size: tuple = (16, 16), roughness: float = 0.5, z_min: float = 0, z_max:
+                 float = 1, r_type: chr = 'default', **kwds):
+        """Implementation of vectorized Diaomnd-Square algorithm for random topography generation
+
+        Args:
+            size (int, int): shape of grid to interpolate; note: the standard diamond-square algorithm
+                operates on a square grid with side length 2**n+1. This implementation is adjusted to non-square
+                grids with (2**n+1, 2**m+1). If the input size (int, int) is not matching to the ideal dimension,
+                the next bigger size is taken and the grid finally cut (lower left corner is kept);
+            roughness: roughness parameter, [0,1]: 0: deterministic interpolation, 1: very rough and bumpy (in standard
+                randomisation method - other options available in self.random_func())
+            z_min: minimum height of surface
+            z_max: maximum height of surface
+            seed: seed for random function to enable reproducibility and testing
+            r_type: 'basic', 'level_scale' (See below for details)
+            
+        Options for the randomization function (self.r_type) are:
+        - 'default': standard reduction
+        - 'level_scale' : uniform distribution between z_min, z_max, scaled by (level + 1)
+
+        """
+        self.size = size
+        # Create mesh with optimal size (2**n+1, 2**m+1)
+        # If the input size `self.size` does not match to these dimensions, then the next larger suitable
+        # size is chosen.
+        self.n = np.ceil(np.log2(self.size[0] - 1)).astype('int8')
+        self.m = np.ceil(np.log2(self.size[1] - 1)).astype('int8')
+        self.grid = np.zeros((2 ** self.n + 1, 2 ** self.m + 1))
+        self.roughness = roughness
+        self.z_min = z_min
+        self.z_max = z_max
+        if 'seed' in kwds:
+            np.random.seed(kwds['seed'])
+        self.base_rand_range = 1
+        self.r_type = r_type
+
+    def random_func(self, i, level_shape):
+        """Define random function to adjust range for subsequent steps
+
+        The random function type is defined on class level (self.r_type)
+        """
+
+        if self.r_type == 'default':
+            if self.roughness > 0:
+                rand_range = self.base_rand_range * 2 ** (- (1 - self.roughness) * i)
+                return np.random.uniform(-rand_range, rand_range, level_shape)
+            else:
+                return 0.
+
+        if self.r_type == 'long_range':
+            if self.roughness > 0:
+                rand_range = self.base_rand_range * 16 ** (- (1 - self.roughness) * i)
+                return np.random.uniform(-rand_range, rand_range, level_shape)
+            else:
+                return 0.
+
+        elif self.r_type == 'level_scale':
+            if self.roughness > 0:
+                return np.random.uniform(self.z_min, self.z_max,
+                                         level_shape) / (1 + i)
+            else:
+                return 0.
+
+        elif self.r_type == 'deterministic':
+            # No randomization at all - deterministic interpolation result
+            return 0.
+
+        else:
+            raise NotImplementedError("Random function type %s not implemented" % self.r_type)
+
+    def random_initialization(self, level='highest', verbose: bool=False):
+        """Initialize cells on speicifc hierarchy with random values
+
+        Args:
+            level = 'hightest', int : hierarchy level for interpolation (default: highest)
+            verbose: verbose output (default: False)
+
+        With highest hierarchy, we refer here to the largest diamond-square step, i.e. the corner points
+        for a square grid; Or, more formally: the diamond points for `min(self.n, self.m)`
+        """
+        if level == 'highest':
+            m_pow_max = min(self.n, self.m)
+        else:
+            m_pow_max = level
+
+        step_size = int(2 ** m_pow_max)
+        if verbose:
+            print("Initialize on step size %d" % step_size)
+
+        level_shape = self.grid[::step_size, ::step_size].shape
+
+        self.grid[::step_size, ::step_size] = np.random.uniform(0, 1, level_shape)  # self.random_func(0, level_shape)
+
+    def interpolate(self, level='highest'):
+        """Perform diamond-square interpolation
+
+        Args:
+            level = 'hightest', int : hierarchy level for interpolation (default: highest)
+
+        This step follows the conventional procedure:
+        Iterate over hierarchies and repeat:
+        2) Perform Diamond interpolation step
+        3) Perform Square interpolation step
+        4) Reduce roughness factor
+        """
+        if level == 'highest':
+            # determine highest hierarchy level (determined by shorter rectangle side)
+            m_pow_max = min(self.n, self.m)
+        else:
+            m_pow_max = level
+
+        for i, m_pow in enumerate(np.arange(m_pow_max)[::-1]):
+            self.perform_diamond_step(i, m_pow)
+            self.perform_square_step(i, m_pow)
+
+    def reset_grid(self):
+        """Reset grid back to zero values"""
+        self.grid[:, :] = 0
+
+    def perform_diamond_step(self, i: int, m_pow: int):
+        """Perform one diamond interpolation step on hierarchy m_pow
+
+        Note: for more details on the vectorized selection, see self.get_selection_diamond()
+        """
+        step_size = int(2 ** m_pow)
+
+        # Diamond step
+        # ----------------
+
+        # get shape of this step
+        level_shape = self.grid[step_size::2 * step_size, step_size::2 * step_size].shape
+
+        self.grid[step_size::2 * step_size, step_size::2 * step_size] = \
+            (self.grid[:-2 * step_size:2 * step_size, :-2 * step_size:2 * step_size] +
+             self.grid[:-2 * step_size:2 * step_size, 2 * step_size::2 * step_size] +
+             self.grid[2 * step_size::2 * step_size, :-2 * step_size:2 * step_size] +
+             self.grid[2 * step_size::2 * step_size, 2 * step_size::2 * step_size]) / \
+            4. + \
+            self.random_func(i, level_shape)
+
+        # np.random.uniform(-rand_range, rand_range, level_shape)
+
+        # self.d * 2**()
+        # self.roughness ** i * (np.random.random(step_shape) - 0.5)
+
+        # (np.random.random(step_shape) - 0.5) * i * self.roughness
+
+    def perform_square_step(self, i: int, m_pow: int):
+        """Perform one square interpolation step on hierarchy m_pow
+
+        Note: for more details on the vectorized selection, see self.get_selection_square()
+        """
+        step_size = int(2 ** m_pow)
+
+        # pad cells with zero value
+        z_pad = np.pad(self.grid, step_size, mode='constant')
+
+        # also create a grid for division to divide only by 3 on borders
+        grid_div = np.ones_like(self.grid[1:-1, 1:-1]) * 4.
+        grid_div = np.pad(grid_div, step_size + 1, mode='constant', constant_values=3.)
+
+        # Checkerboard odd
+        # ----------------
+
+        # get shape of this step
+        level_shape = grid_div[step_size::2 * step_size, 2 * step_size:-2 * step_size:2 * step_size].shape
+
+        z_pad[step_size::2 * step_size, 2 * step_size:-2 * step_size:2 * step_size] = \
+            (z_pad[step_size::2 * step_size, step_size:-2 * step_size:2 * step_size] +
+             z_pad[step_size::2 * step_size, 3 * step_size:-step_size:2 * step_size] +
+             z_pad[:-step_size:2 * step_size, 2 * step_size:-2 * step_size:2 * step_size] +
+             z_pad[2 * step_size::2 * step_size, 2 * step_size:-2 * step_size:2 * step_size]) / \
+            grid_div[step_size::2 * step_size, 2 * step_size:-2 * step_size:2 * step_size] + \
+            self.random_func(i, level_shape)
+
+        # np.random.uniform(-rand_range, rand_range, level_shape)
+
+        #    self.roughness ** i * (np.random.random(step_shape) - 0.5)
+
+        # (np.random.random(step_shape) - 0.5) * i * self.roughness
+
+        # Checkerboard even
+        # -----------------
+
+        # get shape of this step
+        level_shape = z_pad[2 * step_size:-2 * step_size:2 * step_size, step_size:-step_size:2 * step_size].shape
+
+        # check-even, values to interpolate:
+        z_pad[2 * step_size:-2 * step_size:2 * step_size, step_size:-step_size:2 * step_size] = \
+            (z_pad[2 * step_size:-2 * step_size:2 * step_size, :-2 * step_size:2 * step_size] +
+             z_pad[2 * step_size:-2 * step_size:2 * step_size, 2 * step_size::2 * step_size] +
+             z_pad[step_size:-2 * step_size:2 * step_size, step_size:-step_size:2 * step_size] +
+             z_pad[3 * step_size::2 * step_size, step_size:-step_size:2 * step_size]) / \
+            grid_div[2 * step_size:-2 * step_size:2 * step_size, step_size:-step_size:2 * step_size] + \
+            self.random_func(i, level_shape)
+
+        # np.random.uniform(-rand_range, rand_range, level_shape)
+
+        # self.roughness ** i * (np.random.random(step_shape) - 0.5)
+
+        # (np.random.random(step_shape) - 0.5) * i * self.roughness
+
+        # assign results back to self.grid
+        self.grid = z_pad[step_size:-step_size, step_size:-step_size]
+
+    def get_selection_diamond(self, m_pow: int):
+        """get selected points for diamond step on grid z on hierarchy m
+
+        This method is mostly implemented for testing and visualization purposes.
+        """
+
+        step_size = int(2 ** m_pow)
+
+        z = np.zeros_like(self.grid, dtype='int8')
+
+        # points to interpolate
+        z[step_size::2 * step_size, step_size::2 * step_size] = 1
+
+        # top left
+        z[:-2 * step_size:2 * step_size, :-2 * step_size:2 * step_size] = 2
+
+        # top right
+        z[:-2 * step_size:2 * step_size, 2 * step_size::2 * step_size] = 2
+
+        # bottom left
+        z[2 * step_size::2 * step_size, :-2 * step_size:2 * step_size] = 2
+
+        # bottom right
+        z[2 * step_size::2 * step_size, 2 * step_size::2 * step_size] = 2
+
+        return z
+
+    def get_selection_square(self, m_pow: int):
+        """Plot selected points for square step on grid z on hierarchy m
+
+        This method is mostly implemented for testing and visualization purposes.
+        """
+        z = np.zeros_like(self.grid, dtype='int8')
+        step_size = int(2 ** m_pow)
+
+        # pad cells with zero value
+        z_pad = np.pad(z, step_size, mode='constant')
+
+        # Checkerboard odd
+        # ----------------
+
+        # check-odd, values to interpolate:
+        z_pad[step_size::2 * step_size, 2 * step_size:-2 * step_size:2 * step_size] = 1
+
+        # check-odd, left
+        z_pad[step_size::2 * step_size, step_size:-2 * step_size:2 * step_size] = 2
+
+        # check-odd, right
+        z_pad[step_size::2 * step_size, 3 * step_size:-step_size:2 * step_size] = 2
+
+        # check-odd, top
+        z_pad[:-step_size:2 * step_size, 2 * step_size:-2 * step_size:2 * step_size] = 2
+
+        # check-odd, bottom
+        z_pad[2 * step_size::2 * step_size, 2 * step_size:-2 * step_size:2 * step_size] = 2
+
+        # Checkerboard even
+        # -----------------
+
+        # check-even, values to interpolate:
+        z_pad[2 * step_size:-2 * step_size:2 * step_size, step_size:-step_size:2 * step_size] = 1
+
+        # check-even, left:
+        z_pad[2 * step_size:-2 * step_size:2 * step_size, :-2 * step_size:2 * step_size] = 2
+
+        # check-even, right:
+        z_pad[2 * step_size:-2 * step_size:2 * step_size, 2 * step_size::2 * step_size] = 2
+
+        # check-even, top:
+        z_pad[step_size:-2 * step_size:2 * step_size, step_size:-step_size:2 * step_size] = 2
+
+        # check-even, bottom:
+        z_pad[3 * step_size::2 * step_size, step_size:-step_size:2 * step_size] = 2
+
+        return z_pad
+
+    def plot_diamond_and_square(self, pad=False):
+        """Plot selected points for diamond and square step for all hierarchies side by side"""
+
+        m_pow_max = min(self.n, self.m)
+
+        shape_ratio = self.n / self.m
+
+        f, axes = plt.subplots(2, m_pow_max, figsize=(12, 12 * shape_ratio / m_pow_max * 2))
+
+        for i, m_pow in enumerate(np.arange(m_pow_max)[::-1]):
+            m = 2 ** m_pow
+            # z_zero = np.zeros_like(self.grid)
+            z_diamond = self.get_selection_diamond(m_pow)
+            z_square = self.get_selection_square(m_pow)
+            if pad:
+                z_pad = np.pad(z_diamond, m, mode='constant')
+                axes[0, i].imshow(z_pad, cmap='viridis', vmin=0, vmax=2)
+                axes[1, i].imshow(z_square, cmap='viridis', vmin=0, vmax=2)
+            else:
+                axes[0, i].imshow(z_diamond, cmap='viridis', vmin=0, vmax=2)
+                axes[1, i].imshow(z_square[m:-m, m:-m], cmap='viridis', vmin=0, vmax=2)
```

### Comparing `gempy-2.2b10.dev1/gempy/core/grid_modules/section_utils.py` & `gempy-2.3.0/gempy/core/grid_modules/section_utils.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,114 +1,114 @@
-from gempy.plot import visualization_2d as vv
-import numpy as np
-import matplotlib.patches as patches
-import matplotlib.pyplot as plt
-
-def _extract_boundaries(self, axes, section_name='topography'):
-    """
-    Should be part of viz 2d.
-    Args:
-        self:
-        axes:
-        section_name:
-
-    Returns:
-
-    """
-    cs = []
-
-    faults = list(self.model._faults.df[self.model._faults.df['isFault'] == True].index)
-
-    if section_name == 'topography':
-        shape = self.model._grid.topography.resolution
-        a = self.model.solutions.geological_map[1]
-        extent = [self.model._grid.topography.extent[0],
-                  self.model._grid.topography.extent[1],
-                  self.model._grid.topography.extent[2],
-                  self.model._grid.topography.extent[3]]
-    else:
-        l0, l1 = self.model._grid.sections.get_section_args(section_name)
-        j = np.where(self.model._grid.sections.names == section_name)[0][0]
-        shape = [self.model._grid.sections.resolution[j][0], self.model._grid.sections.resolution[j][1]]
-        a = self.model.solutions.sections[1][:, l0:l1]
-        # b = self.model.solutions.sections[0][:, l0:l1].reshape(shape).T
-        extent = [0, self.model._grid.sections.dist[j][0], self.model._grid.regular_grid.extent[4],
-                  self.model._grid.regular_grid.extent[5]]
-
-    zorder = 2
-    counter = a.shape[0]
-
-    counters = np.arange(0, counter, 1)
-    c_id = 0  # color id startpoint
-    colors = []
-    for f_id in counters:
-        block = a[f_id]
-        level = self.model.solutions.scalar_field_at_surface_points[f_id][np.where(
-            self.model.solutions.scalar_field_at_surface_points[f_id] != 0)]
-
-        levels = np.insert(level, 0, block.max())
-        c_id2 = c_id + len(level)
-        if f_id == counters.max():
-            levels = np.insert(levels, level.shape[0], block.min())
-            c_id2 = c_id + len(levels)  # color id endpoint
-        if section_name == 'topography':
-            block = block.reshape(shape)
-        else:
-            block = block.reshape(shape).T
-        zorder = zorder - (f_id + len(level))
-
-        if f_id >= len(faults):
-            color = self.cmap.colors[c_id:c_id2][::-1]
-            plot = axes.contourf(block, 0, levels=np.sort(levels), colors=color,
-                                 linestyles='solid', origin='lower',
-                                 extent=extent, zorder=zorder)
-        else:
-            color = self.cmap.colors[c_id:c_id2][0]
-            plot = axes.contour(block, 0, levels=np.sort(levels), colors=color,
-                                linestyles='solid', origin='lower',
-                                extent=extent, zorder=zorder)
-        c_id += len(level)
-        cs.append(plot)
-        if type(color) == str:
-            colors.append(color)
-        else:
-            for c in color:
-                colors.append(c)
-    return cs, colors, extent
-
-
-def get_polygon_dictionary(geo_model, section_name):
-    """
-
-    Args:
-        geo_model: the geological model
-        section_name: the section from which the polygons should be retrieved. Must be 'topography' or a predefined
-        section of model.grid.sections
-
-    Returns: [0]: pathdict. A dictionary of every surface with its corresponding polygon xy values.
-             [1]: color dictionary
-             [2]: extent of the section
-
-    """
-    p = vv.Plot2D(geo_model)
-    p.create_figure((13, 13))
-    t = p.add_section(section_name, ax_pos=111)
-
-    cs, colors, extent = _extract_boundaries(p, p.axes[0], section_name)
-    all_paths = []
-    for contour in cs:
-        for col in contour.collections:
-            all_paths.append(col.get_paths())
-
-    for p in all_paths:
-        if p == []:
-            all_paths.remove(p)
-
-    surflist = []
-    for color in colors:
-        surflist.append(geo_model._surfaces.df[geo_model._surfaces.df['color'] == color]['surface'].values[0])
-
-    pathdict = dict(zip(surflist, all_paths))
-    cdict = dict(zip(surflist, colors))
-
-    return pathdict, cdict, extent
-
+from gempy.plot import visualization_2d as vv
+import numpy as np
+import matplotlib.patches as patches
+import matplotlib.pyplot as plt
+
+def _extract_boundaries(self, axes, section_name='topography'):
+    """
+    Should be part of viz 2d.
+    Args:
+        self:
+        axes:
+        section_name:
+
+    Returns:
+
+    """
+    cs = []
+
+    faults = list(self.model._faults.df[self.model._faults.df['isFault'] == True].index)
+
+    if section_name == 'topography':
+        shape = self.model._grid.topography.resolution
+        a = self.model.solutions.geological_map[1]
+        extent = [self.model._grid.topography.extent[0],
+                  self.model._grid.topography.extent[1],
+                  self.model._grid.topography.extent[2],
+                  self.model._grid.topography.extent[3]]
+    else:
+        l0, l1 = self.model._grid.sections.get_section_args(section_name)
+        j = np.where(self.model._grid.sections.names == section_name)[0][0]
+        shape = [self.model._grid.sections.resolution[j][0], self.model._grid.sections.resolution[j][1]]
+        a = self.model.solutions.sections[1][:, l0:l1]
+        # b = self.model.solutions.sections[0][:, l0:l1].reshape(shape).T
+        extent = [0, self.model._grid.sections.dist[j][0], self.model._grid.regular_grid.extent[4],
+                  self.model._grid.regular_grid.extent[5]]
+
+    zorder = 2
+    counter = a.shape[0]
+
+    counters = np.arange(0, counter, 1)
+    c_id = 0  # color id startpoint
+    colors = []
+    for f_id in counters:
+        block = a[f_id]
+        level = self.model.solutions.scalar_field_at_surface_points[f_id][np.where(
+            self.model.solutions.scalar_field_at_surface_points[f_id] != 0)]
+
+        levels = np.insert(level, 0, block.max())
+        c_id2 = c_id + len(level)
+        if f_id == counters.max():
+            levels = np.insert(levels, level.shape[0], block.min())
+            c_id2 = c_id + len(levels)  # color id endpoint
+        if section_name == 'topography':
+            block = block.reshape(shape)
+        else:
+            block = block.reshape(shape).T
+        zorder = zorder - (f_id + len(level))
+
+        if f_id >= len(faults):
+            color = self.cmap.colors[c_id:c_id2][::-1]
+            plot = axes.contourf(block, 0, levels=np.sort(levels), colors=color,
+                                 linestyles='solid', origin='lower',
+                                 extent=extent, zorder=zorder)
+        else:
+            color = self.cmap.colors[c_id:c_id2][0]
+            plot = axes.contour(block, 0, levels=np.sort(levels), colors=color,
+                                linestyles='solid', origin='lower',
+                                extent=extent, zorder=zorder)
+        c_id += len(level)
+        cs.append(plot)
+        if type(color) == str:
+            colors.append(color)
+        else:
+            for c in color:
+                colors.append(c)
+    return cs, colors, extent
+
+
+def get_polygon_dictionary(geo_model, section_name):
+    """
+
+    Args:
+        geo_model: the geological model
+        section_name: the section from which the polygons should be retrieved. Must be 'topography' or a predefined
+        section of model.grid.sections
+
+    Returns: [0]: pathdict. A dictionary of every surface with its corresponding polygon xy values.
+             [1]: color dictionary
+             [2]: extent of the section
+
+    """
+    p = vv.Plot2D(geo_model)
+    p.create_figure((13, 13))
+    t = p.add_section(section_name, ax_pos=111)
+
+    cs, colors, extent = _extract_boundaries(p, p.axes[0], section_name)
+    all_paths = []
+    for contour in cs:
+        for col in contour.collections:
+            all_paths.append(col.get_paths())
+
+    for p in all_paths:
+        if p == []:
+            all_paths.remove(p)
+
+    surflist = []
+    for color in colors:
+        surflist.append(geo_model._surfaces.df[geo_model._surfaces.df['color'] == color]['surface'].values[0])
+
+    pathdict = dict(zip(surflist, all_paths))
+    cdict = dict(zip(surflist, colors))
+
+    return pathdict, cdict, extent
+
```

### Comparing `gempy-2.2b10.dev1/gempy/core/grid_modules/topography.py` & `gempy-2.3.0/gempy/core/grid_modules/topography.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,138 +1,138 @@
-import numpy as np
-from .create_topography import LoadDEMArtificial, LoadDEMGDAL
-import skimage
-
-
-class Topography:
-    """
-    Object to include topography in the model.
-
-    Notes:
-        This always assumes that the topography we pass fits perfectly the extent
-
-    """
-    def __init__(self, regular_grid=None, regular_grid_extent=None, regular_grid_resolution=None):
-
-        if regular_grid is None and (regular_grid_extent is None or regular_grid_resolution is None):
-            raise AttributeError('You need to pass either a regular grid or'
-                                 'extent and resolution')
-
-        # Set the extent and resolution of the grid
-        if regular_grid_resolution is None:
-            self.regular_grid_resolution = regular_grid.resolution[:2]
-        else:
-            self.regular_grid_resolution = regular_grid_resolution
-        assert all(np.asarray(self.regular_grid_resolution) >= 2), 'The regular grid needs to be at least of size 2 on all ' \
-                                                      'directions.'
-        self.extent = regular_grid.extent[:] if regular_grid_extent is None else regular_grid_extent
-
-        # Values (n, 3)
-        self.values = np.zeros((0, 3))
-
-        # Values (n, n, 3)
-        self.values_2d = np.zeros((0, 3))
-
-        # Shape original
-        self.raster_shape = tuple()
-
-        # Topography Resolution
-        self.resolution = np.zeros((0, 3))
-
-        # Source for the
-        self.source = None
-
-        # Coords
-        self._x = None
-        self._y = None
-
-    @property
-    def x(self):
-        if self._x is not None:
-            return self._x
-        else:
-            val = self.values[:, 0]
-            val.sort()
-            return np.unique(val)
-
-    @property
-    def y(self):
-        if self._y is not None:
-            return self._y
-        else:
-            val = self.values[:, 1]
-            val.sort()
-            return np.unique(val)
-
-    def set_values(self, values_2d: np.ndarray):
-        """General method to set topography
-
-        Args:
-            values_2d (numpy.ndarray[float,float, 3]): array with the XYZ values
-             in 2D
-
-        Returns:
-            :class:`gempy.core.grid_modules.topography.Topography`
-
-
-        """
-        # Original topography data
-        self.values_2d = values_2d
-        self.resolution = values_2d.shape[:2]
-
-        # n,3 array
-        self.values = values_2d.reshape((-1, 3), order='C')
-        return self
-
-    def crop_topography(self, extent):
-        """Crop the topography to a given extent.
-
-        This may be useful for example to mask the regular grid.
-
-        Args:
-            extent:
-
-        Returns:
-
-        """
-        raise NotImplementedError
-
-    def resize_topo(self):
-        regular_grid_topo = skimage.transform.resize(
-            self.values_2d,
-            (self.regular_grid_resolution[0], self.regular_grid_resolution[1]),
-            mode='constant',
-            anti_aliasing=False, preserve_range=True)
-
-        return regular_grid_topo
-
-    def load_random_hills(self, **kwargs):
-        if 'extent' in kwargs:
-            self.extent = kwargs.pop('extent')
-
-        if 'resolution' in kwargs:
-            self.regular_grid_resolution = kwargs.pop('resolution')
-
-        dem = LoadDEMArtificial(extent=self.extent,
-                                resolution=self.regular_grid_resolution, **kwargs)
-
-        self._x, self._y = dem.x, dem.y
-        self.set_values(dem.get_values())
-
-    def load_from_gdal(self, filepath):
-        dem = LoadDEMGDAL(filepath, extent=self.extent)
-        self._x, self._y = None, None
-        self.set_values(dem.get_values())
-        # self.source = 'gdal'
-
-    def save(self, path):
-        np.save(path, self.values_2d)
-
-    def load(self, path):
-        self.set_values(np.load(path))
-        self._x, self._y = None, None
-        return self.values
-
-    def load_from_saved(self, *args, **kwargs):
-        self.load(*args, **kwargs)
-
-
+import numpy as np
+from .create_topography import LoadDEMArtificial, LoadDEMGDAL
+import skimage
+
+
+class Topography:
+    """
+    Object to include topography in the model.
+
+    Notes:
+        This always assumes that the topography we pass fits perfectly the extent
+
+    """
+    def __init__(self, regular_grid=None, regular_grid_extent=None, regular_grid_resolution=None):
+
+        if regular_grid is None and (regular_grid_extent is None or regular_grid_resolution is None):
+            raise AttributeError('You need to pass either a regular grid or'
+                                 'extent and resolution')
+
+        # Set the extent and resolution of the grid
+        if regular_grid_resolution is None:
+            self.regular_grid_resolution = regular_grid.resolution[:2]
+        else:
+            self.regular_grid_resolution = regular_grid_resolution
+        assert all(np.asarray(self.regular_grid_resolution) >= 2), 'The regular grid needs to be at least of size 2 on all ' \
+                                                      'directions.'
+        self.extent = regular_grid.extent[:] if regular_grid_extent is None else regular_grid_extent
+
+        # Values (n, 3)
+        self.values = np.zeros((0, 3))
+
+        # Values (n, n, 3)
+        self.values_2d = np.zeros((0, 3))
+
+        # Shape original
+        self.raster_shape = tuple()
+
+        # Topography Resolution
+        self.resolution = np.zeros((0, 3))
+
+        # Source for the
+        self.source = None
+
+        # Coords
+        self._x = None
+        self._y = None
+
+    @property
+    def x(self):
+        if self._x is not None:
+            return self._x
+        else:
+            val = self.values[:, 0]
+            val.sort()
+            return np.unique(val)
+
+    @property
+    def y(self):
+        if self._y is not None:
+            return self._y
+        else:
+            val = self.values[:, 1]
+            val.sort()
+            return np.unique(val)
+
+    def set_values(self, values_2d: np.ndarray):
+        """General method to set topography
+
+        Args:
+            values_2d (numpy.ndarray[float,float, 3]): array with the XYZ values
+             in 2D
+
+        Returns:
+            :class:`gempy.core.grid_modules.topography.Topography`
+
+
+        """
+        # Original topography data
+        self.values_2d = values_2d
+        self.resolution = values_2d.shape[:2]
+
+        # n,3 array
+        self.values = values_2d.reshape((-1, 3), order='C')
+        return self
+
+    def crop_topography(self, extent):
+        """Crop the topography to a given extent.
+
+        This may be useful for example to mask the regular grid.
+
+        Args:
+            extent:
+
+        Returns:
+
+        """
+        raise NotImplementedError
+
+    def resize_topo(self):
+        regular_grid_topo = skimage.transform.resize(
+            self.values_2d,
+            (self.regular_grid_resolution[0], self.regular_grid_resolution[1]),
+            mode='constant',
+            anti_aliasing=False, preserve_range=True)
+
+        return regular_grid_topo
+
+    def load_random_hills(self, **kwargs):
+        if 'extent' in kwargs:
+            self.extent = kwargs.pop('extent')
+
+        if 'resolution' in kwargs:
+            self.regular_grid_resolution = kwargs.pop('resolution')
+
+        dem = LoadDEMArtificial(extent=self.extent,
+                                resolution=self.regular_grid_resolution, **kwargs)
+
+        self._x, self._y = dem.x, dem.y
+        self.set_values(dem.get_values())
+
+    def load_from_gdal(self, filepath):
+        dem = LoadDEMGDAL(filepath, extent=self.extent)
+        self._x, self._y = None, None
+        self.set_values(dem.get_values())
+        # self.source = 'gdal'
+
+    def save(self, path):
+        np.save(path, self.values_2d)
+
+    def load(self, path):
+        self.set_values(np.load(path))
+        self._x, self._y = None, None
+        return self.values
+
+    def load_from_saved(self, *args, **kwargs):
+        self.load(*args, **kwargs)
+
+
```

### Comparing `gempy-2.2b10.dev1/gempy/core/model.py` & `gempy-2.3.0/gempy/core/model.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,27 +1,28 @@
-import os
-import shutil
-import sys
-from abc import ABC
+import warnings
+from typing import Union, Iterable
 
 import numpy as np
 import pandas as pn
-from typing import Union, Iterable
-import warnings
+import sys
+
+from .data import AdditionalData, Options, KrigingParameters
+from .meta_data import MetaData
+from .data_modules.stack import Stack, Faults, Series
+from .interpolator import InterpolatorModel
+from .solution import Solution
+from ..plot.decorators import *
+from ..utils.meta import _setdoc, _setdoc_pro
+from ..utils.docstring import recompute_rf
+from .surfaces import Surfaces
+from .grid import Grid
+from .data_modules.surface_points import SurfacePoints
+from .data_modules.orientations import Orientations
+from .data_modules.scaling_system import ScalingSystem
 
-from gempy.core.data_modules.geometric_data import Orientations, SurfacePoints, \
-    ScalingSystem, Surfaces, Grid
-from gempy.core.data_modules.stack import Stack, Faults, Series
-from gempy.core.data import AdditionalData, MetaData, Options, Structure, \
-    KrigingParameters
-from gempy.core.solution import Solution
-from gempy.core.interpolator import InterpolatorModel, InterpolatorGravity
-from gempy.utils.meta import _setdoc, _setdoc_pro
-import gempy.utils.docstring as ds
-from gempy.plot.decorators import *
 
 pn.options.mode.chained_assignment = None
 
 
 class RestrictingWrapper(object):
     def __init__(self, w, accepted_members=['__repr__', '_repr_html_', '__str__']):
         self._w = w
@@ -33,30 +34,27 @@
     def __getattr__(self, item):
         if item in self._accepted_members:
             return getattr(self._w, item)
         else:
             raise AttributeError(item)
 
 
-@_setdoc_pro([Grid.__doc__, Faults.__doc__, Series.__doc__, Surfaces.__doc__,
-              SurfacePoints.__doc__,
-              Orientations.__doc__, ScalingSystem.__doc__, AdditionalData.__doc__,
-              InterpolatorModel.__doc__,
-              Solution.__doc__])
+@_setdoc_pro([Grid.__doc__, Faults.__doc__, Series.__doc__, Surfaces.__doc__, SurfacePoints.__doc__,Orientations.__doc__,
+              ScalingSystem.__doc__, AdditionalData.__doc__, InterpolatorModel.__doc__, Solution.__doc__])
 class ImplicitCoKriging(object):
     """This class handles all the mutation of the data objects of the model involved on the
      implicit cokriging ensuring the synchronization of all the members.
 
     Attributes:
-        _grid (:class:`gempy.core.data.Grid`): [s0]
-        _faults (:class:`gempy.core.data.Grid`): [s1]
+        _grid (:class:`gempy.Grid`): [s0]
+        _faults (:class:`gempy.Grid`): [s1]
         _stack (:class:`gempy.core.data_modules.stack.Stack`): [s2]
-        _surfaces (:class:`gempy.core.data.Surfaces`): [s3]
-        _surface_points (:class:`gempy.core.data_modules.geometric_data.SurfacePoints`): [s4]
-        _orientations (:class:`gempy.core.data_modules.geometric_data.Orientations`): [s5]
+        _surfaces (:class:`gempy.Surfaces`): [s3]
+        _surface_points (:class:`gempy.SurfacePoints`): [s4]
+        _orientations (:class:`gempy.Orientations`): [s5]
         _rescaling (:class:`gempy.core.data_modules.geometric_data.Rescaling`): [s6]
         _additional_data (:class:`gempy.core.data.AdditionalData`): [s7]
         _interpolator (:class:`gempy.core.interpolator.InterpolatorModel`): [s8]
         solutions (:class:`gempy.core.solutions.Solutions`): [s9]
 
 
      """
@@ -171,15 +169,15 @@
 
     @_setdoc_pro(InterpolatorModel.__doc__)
     @property
     def interpolator(self):
         """:class:`gempy.core.interpolator.InterpolatorModel` [s0]"""
         return RestrictingWrapper(self._interpolator,
                                   accepted_members=['__repr__', '_repr_html_',
-                                                    'theano_graph'])
+                                                    'aesara_graph'])
 
     def _add_valid_idx_s(self, idx):
         if idx is None:
             idx = self._surface_points.df.index.max()
             if idx is np.nan:
                 idx = 0
             else:
@@ -200,26 +198,26 @@
         else:
             assert isinstance(idx, (
                 int, list, np.ndarray)), 'idx must be an int or a list of ints'
 
         return idx
 
     @_setdoc_pro([AdditionalData.update_structure.__doc__,
-                  InterpolatorModel.set_theano_shared_structure.__doc__,
+                  InterpolatorModel.set_aesara_shared_structure.__doc__,
                   InterpolatorModel.modify_results_matrices_pro.__doc__,
                   InterpolatorModel.modify_results_weights.__doc__])
-    def update_structure(self, update_theano=None, update_series_is_active=True,
+    def update_structure(self, update_aesara=None, update_series_is_active=True,
                          update_surface_is_active=True):
-        """Update python and theano structure parameters.
+        """Update python and aesara structure parameters.
 
         [s0]
         [s1]
 
         Args:
-            update_theano (str{'matrices', 'weights'}):
+            update_aesara (str{'matrices', 'weights'}):
 
                 * matrices [s2]
 
                 * weights [s3]
 
         Returns:
             :class:`gempy.core.data.Structure`
@@ -243,50 +241,49 @@
             non_zero = np.intersect1d(non_zero_i, non_zero_o)
 
             bool_vec = np.zeros_like(self._stack.df['isActive'], dtype=bool)
             bool_vec[non_zero] = True
             self._stack.df['isActive'] = bool_vec
 
         if update_surface_is_active is True:
-            act_series = self._surfaces.df['series'].map(
-                self._stack.df['isActive']).astype(bool)
+            act_series = self._surfaces.df['series'].map(self._stack.df['isActive']).astype(bool)
             unique_surf_points = np.unique(self._surface_points.df['id'])
             if len(unique_surf_points) != 0:
                 bool_surf_points = np.zeros_like(act_series, dtype=bool)
                 bool_surf_points[unique_surf_points.astype('int') - 1] = True
 
                 # This is necessary to find the intersection between orientations
                 # (series) and  surface points
                 self._surfaces.df['isActive'] = (
-                    act_series & bool_surf_points) | self._surfaces.df['isBasement']
+                                                        act_series & bool_surf_points) | self._surfaces.df['isBasement']
                 self._surfaces.df['hasData'] = (
                         act_series | bool_surf_points)
 
-        if update_theano == 'matrices':
+        if update_aesara == 'matrices':
             self._interpolator.modify_results_matrices_pro()
-        elif update_theano == 'weights':
+        elif update_aesara == 'weights':
             self._interpolator.modify_results_weights()
 
-        self._interpolator.set_theano_shared_structure()
+        self._interpolator.set_aesara_shared_structure()
         return self._additional_data.structure_data
 
     # region Grid
     def update_from_grid(self):
         """Update objects dependent from the grid.
 
         """
         self._rescaling.rescale_data()
         self._interpolator.set_initial_results_matrices()
 
-        if 'gravity' in self._interpolator.theano_graph.output or 'magnetics' in self._interpolator.theano_graph.output:
-            self._interpolator.set_theano_shared_l0_l1()
+        if 'gravity' in self._interpolator.aesara_graph.output or 'magnetics' in self._interpolator.aesara_graph.output:
+            self._interpolator.set_aesara_shared_l0_l1()
 
         # Check if grid is shared
-        if hasattr(self._interpolator.theano_graph.grid_val_T, 'get_value'):
-            self._interpolator.theano_graph.grid_val_T.set_value(
+        if hasattr(self._interpolator.aesara_graph.grid_val_T, 'get_value'):
+            self._interpolator.aesara_graph.grid_val_T.set_value(
                 self._grid.values_r.astype(self._interpolator.dtype))
 
     def set_active_grid(self, grid_name: Union[str, Iterable[str]], reset=False):
         """Set active a given or several grids.
 
         Args:
             grid_name (str, list[str]): Name of the grid you want to activate. Options are
@@ -321,15 +318,15 @@
 
         """
         raise NotImplementedError
 
     # @_setdoc(Grid.create_regular_grid.__doc__)
     @_setdoc_pro()
     def set_regular_grid(self, extent, resolution):
-        """Set a regular grid, rescale data and initialize theano solutions.
+        """Set a regular grid, rescale data and initialize aesara solutions.
 
         Args:
             extent: [s_extent]
             resolution: [s_resolution]
 
         Returns:
             :class:`gempy.core.data.Grid`
@@ -353,15 +350,15 @@
 
         self.update_from_grid()
         print(f'Active grids: {self._grid.grid_types[self._grid.active_grids]}')
         return self._grid
 
     @_setdoc_pro()
     def set_custom_grid(self, custom_grid):
-        """Set custom grid, rescale gird and initialize theano solutions. foo
+        """Set custom grid, rescale gird and initialize aesara solutions. foo
 
         Args:
             custom_grid: [s_coord]
 
         Returns:
             :class:`gempy.core.data.Grid`
 
@@ -499,15 +496,15 @@
         raise NotImplementedError
 
     @_setdoc([Series.set_bottom_relation.__doc__], indent=False)
     def set_bottom_relation(self, series: Union[str, list],
                             bottom_relation: Union[str, list]):
         """"""
         self._stack.set_bottom_relation(series, bottom_relation)
-        self._interpolator.set_theano_shared_relations()
+        self._interpolator.set_aesara_shared_relations()
         return self._stack
 
     @_setdoc_pro(Stack.reset_order_series.__doc__)
     def add_features(self, features_list: Union[str, list], reset_order_series=True):
         """ Add series, update the categories dependent on them and reset the flow control.
 
         Args:
@@ -515,23 +512,21 @@
             reset_order_series: if true [s0]
 
         Returns:
             :class:`gempy.core.data_modules.stack.Stack`
 
         """
         self._stack.add_series(features_list, reset_order_series)
-        self._surfaces.df['series'].cat.add_categories(features_list, inplace=True)
-        self._surface_points.df['series'].cat.add_categories(features_list,
-                                                             inplace=True)
-        self._orientations.df['series'].cat.add_categories(features_list,
-                                                           inplace=True)
+        self._surfaces.df['series'] = self._surfaces.df['series'].cat.add_categories(features_list)
+        self._surface_points.df['series'] = self._surface_points.df['series'].cat.add_categories(features_list)
+        self._orientations.df['series'] = self._orientations.df['series'].cat.add_categories(features_list)
 
         self.update_structure()
         self._interpolator.set_flow_control()
-        self._interpolator.set_theano_shared_kriging()
+        self._interpolator.set_aesara_shared_kriging()
         return self._stack
 
     @_setdoc(Series.add_series.__doc__, indent=False)
     def add_series(self, series_list: Union[str, list], reset_order_series=True):
         warnings.warn('Series are getting renamed to Stack/features.'
                       'Please use add_features instead', DeprecationWarning, )
         return self.add_features(series_list, reset_order_series)
@@ -556,24 +551,23 @@
 
         if remove_surfaces is True:
             for s in indices:
                 self.delete_surfaces(
                     self._surfaces.df.groupby('series').get_group(s)['surface'],
                     remove_data=remove_data)
 
-        self._surfaces.df['series'].cat.remove_categories(indices, inplace=True)
-        self._surface_points.df['series'].cat.remove_categories(indices,
-                                                                inplace=True)
-        self._orientations.df['series'].cat.remove_categories(indices, inplace=True)
+        self._surfaces.df['series'] = self._surfaces.df['series'].cat.remove_categories(indices)
+        self._surface_points.df['series'] = self._surface_points.df['series'].cat.remove_categories(indices)
+        self._orientations.df['series'] = self._orientations.df['series'].cat.remove_categories(indices)
         self.map_geometric_data_df(self._surface_points.df)
         self.map_geometric_data_df(self._orientations.df)
 
         self.update_structure()
-        self._interpolator.set_theano_shared_relations()
-        self._interpolator.set_theano_shared_kriging()
+        self._interpolator.set_aesara_shared_relations()
+        self._interpolator.set_aesara_shared_kriging()
         self._interpolator.set_flow_control()
         return self._stack
 
     @_setdoc(delete_features.__doc__, indent=False)
     def delete_series(self, indices: Union[str, list], refactor_order_series=True,
                       remove_surfaces=False, remove_data=False):
 
@@ -597,20 +591,17 @@
 
         Returns:
             :class:`gempy.core.data_modules.stack.Stack`
 
 
         """
         self._stack.rename_series(new_categories)
-        self._surfaces.df['series'].cat.rename_categories(new_categories,
-                                                          inplace=True)
-        self._surface_points.df['series'].cat.rename_categories(new_categories,
-                                                                inplace=True)
-        self._orientations.df['series'].cat.rename_categories(new_categories,
-                                                              inplace=True)
+        self._surfaces.df['series'] = self._surfaces.df['series'].cat.rename_categories(new_categories)
+        self._surface_points.df['series'] = self._surface_points.df['series'].cat.rename_categories(new_categories)
+        self._orientations.df['series'] = self._orientations.df['series'].cat.rename_categories(new_categories)
         return self._stack
 
     @_setdoc(rename_features.__doc__, indent=False)
     def rename_series(self, new_categories: Union[dict, list]):
         warnings.warn('Series are getting renamed to Stack/features.'
                       'Please use rename_features instead', DeprecationWarning)
         self.rename_features(new_categories)
@@ -626,17 +617,16 @@
 
         Returns:
             :class:`gempy.core.data_modules.stack.Stack`
 
         """
         self._stack.modify_order_series(new_value, idx)
 
-        self._surfaces.df['series'].cat.reorder_categories(
-            np.asarray(self._stack.df.index),
-            ordered=False, inplace=True)
+        self._surfaces.df['series'] = self._surfaces.df['series'].cat.reorder_categories(
+            np.asarray(self._stack.df.index), ordered=False)
 
         self._surfaces.sort_surfaces()
         self._surfaces.set_basement()
 
         self.map_geometric_data_df(self._surface_points.df)
         self._surface_points.sort_table()
         self.map_geometric_data_df(self._orientations.df)
@@ -661,28 +651,28 @@
         Args:
            new_categories (list): list with all series names in the desired order.
 
         Returns:
             :class:`gempy.core.data_modules.stack.Stack`
         """
         self._stack.reorder_series(new_categories)
-        self._surfaces.df['series'].cat.reorder_categories(
+        self._surfaces.df['series'] = self._surfaces.df['series'].cat.reorder_categories(
             np.asarray(self._stack.df.index),
-            ordered=False, inplace=True)
+            ordered=False)
 
         self._surfaces.sort_surfaces()
         self._surfaces.set_basement()
 
         self.map_geometric_data_df(self._surface_points.df)
         self._surface_points.sort_table()
         self.map_geometric_data_df(self._orientations.df)
         self._orientations.sort_table()
 
         self._interpolator.set_flow_control()
-        self.update_structure(update_theano='weights')
+        self.update_structure(update_aesara='weights')
         return self._stack
 
     @_setdoc(reorder_features.__doc__, indent=False)
     def reorder_series(self, new_categories: Iterable[str]):
         warnings.warn('Series are getting renamed to Stack/features.'
                       'Please use reorder_features instead', DeprecationWarning)
         return self.reorder_features(new_categories)
@@ -730,53 +720,63 @@
                 assert aux_assert, \
                     'Having more than one fault in a series is generally rather bad. Better go' \
                     ' back to the function map_series_to_surfaces and give each fault its own' \
                     ' series. If you are really sure what you are doing, you can set twofins to' \
                     ' True to suppress this error.'
 
         self._faults.set_is_fault(feature_fault, toggle=toggle)
+        if change_color:
+            print(
+                'Fault colors changed. If you do not like this behavior, set change_color to False.')
+            self._surfaces.colors.make_faults_black(feature_fault)
 
         if toggle is True:
             already_fault = self._stack.df.loc[
                                 feature_fault, 'BottomRelation'] == 'Fault'
             self._stack.df.loc[
                 feature_fault[already_fault], 'BottomRelation'] = 'Erosion'
+            print(feature_fault[already_fault])
+            faults_list = list(self.surfaces.df[self.surfaces.df.series.isin(feature_fault[already_fault])]['surface'])
+            for fault in faults_list:
+                f_color = self._surfaces.df.index[self._surfaces.df['surface'] == fault][0]
+                self._surfaces.colors.colordict[fault] = self._surfaces.colors._hexcolors_soft[f_color]
+                self._surfaces.colors._set_colors()
             self._stack.df.loc[
                 feature_fault[~already_fault], 'BottomRelation'] = 'Fault'
         else:
             self._stack.df.loc[feature_fault, 'BottomRelation'] = 'Fault'
 
         self._additional_data.structure_data.set_number_of_faults()
-        self._interpolator.set_theano_shared_relations()
-        self._interpolator.set_theano_shared_loop()
+        self._interpolator.set_aesara_shared_relations()
+        self._interpolator.set_aesara_shared_loop()
         if change_color:
             print(
                 'Fault colors changed. If you do not like this behavior, set change_color to False.')
             self._surfaces.colors.make_faults_black(feature_fault)
         self.update_from_series(False, False, False)
-        self.update_structure(update_theano='matrices')
+        self.update_structure(update_aesara='matrices')
         return self._faults
 
     @_setdoc([Faults.set_is_finite_fault.__doc__], indent=False)
     def set_is_finite_fault(self, series_fault=None, toggle: bool = True):
         """"""
         s = self._faults.set_is_finite_fault(series_fault,
                                              toggle)  # change df in Fault obj
-        # change shared theano variable for infinite factor
-        self._interpolator.set_theano_shared_is_finite()
+        # change shared aesara variable for infinite factor
+        self._interpolator.set_aesara_shared_is_finite()
         return s
 
     @_setdoc([Faults.set_fault_relation.__doc__], indent=False)
     def set_fault_relation(self, rel_matrix):
         """"""
         self._faults.set_fault_relation(rel_matrix)
 
         # Updating
-        self._interpolator.set_theano_shared_fault_relation()
-        self._interpolator.set_theano_shared_weights()
+        self._interpolator.set_aesara_shared_fault_relation()
+        self._interpolator.set_aesara_shared_weights()
         return self._faults.faults_relations_df
 
     # endregion
 
     # region Surfaces
     def set_surfaces_object(self):
         """
@@ -785,18 +785,16 @@
 
         """
         raise NotImplementedError
 
     @_setdoc(Surfaces.add_surface.__doc__, indent=False)
     def add_surfaces(self, surface_list: Union[str, list], update_df=True):
         self._surfaces.add_surface(surface_list, update_df)
-        self._surface_points.df['surface'].cat.add_categories(surface_list,
-                                                              inplace=True)
-        self._orientations.df['surface'].cat.add_categories(surface_list,
-                                                            inplace=True)
+        self._surface_points.df['surface'] = self._surface_points.df['surface'].cat.add_categories(surface_list)
+        self._orientations.df['surface'] = self._orientations.df['surface'].cat.add_categories(surface_list)
         self.update_structure()
         return self._surfaces
 
     @_setdoc_pro([Surfaces.update_id.__doc__])
     def delete_surfaces(self, indices: Union[str, Iterable[str]], update_id=True,
                         remove_data=True):
         """
@@ -824,36 +822,32 @@
             self._surface_points.del_surface_points(
                 self._surface_points.df[
                     self._surface_points.df.surface.isin(surfaces_names)].index)
             self._orientations.del_orientation(
                 self._orientations.df[
                     self._orientations.df.surface.isin(surfaces_names)].index)
 
-        self._surface_points.df['surface'].cat.remove_categories(surfaces_names,
-                                                                 inplace=True)
-        self._orientations.df['surface'].cat.remove_categories(surfaces_names,
-                                                               inplace=True)
+        self._surface_points.df['surface'] = self._surface_points.df['surface'].cat.remove_categories(surfaces_names)
+        self._orientations.df['surface'] = self._orientations.df['surface'].cat.remove_categories(surfaces_names)
         self.map_geometric_data_df(self._surface_points.df)
         self.map_geometric_data_df(self._orientations.df)
         self._surfaces.colors.delete_colors(surfaces_names)
 
         if remove_data:
-            self.update_structure(update_theano='matrices')
-            self.update_structure(update_theano='weights')
+            self.update_structure(update_aesara='matrices')
+            self.update_structure(update_aesara='weights')
 
         return self._surfaces
 
     @_setdoc(Surfaces.rename_surfaces.__doc__, indent=False)
     def rename_surfaces(self, to_replace: Union[dict], **kwargs):
 
         self._surfaces.rename_surfaces(to_replace, **kwargs)
-        self._surface_points.df['surface'].cat.rename_categories(to_replace,
-                                                                 inplace=True)
-        self._orientations.df['surface'].cat.rename_categories(to_replace,
-                                                               inplace=True)
+        self._surface_points.df['surface'] = self._surface_points.df['surface'].cat.rename_categories(to_replace)
+        self._orientations.df['surface'] = self._orientations.df['surface'].cat.rename_categories(to_replace)
         return self._surfaces
 
     @_setdoc(Surfaces.modify_order_surfaces.__doc__, indent=False)
     def modify_order_surfaces(self, new_value: int, idx: int,
                               series_name: str = None):
         """"""
 
@@ -867,15 +861,15 @@
         self.update_structure()
         return self._surfaces
 
     @_setdoc(Surfaces.add_surfaces_values.__doc__, indent=False)
     def add_surface_values(self, values_array: Iterable,
                            properties_names: Iterable[str] = np.empty(0)):
         self._surfaces.add_surfaces_values(values_array, properties_names)
-        self.update_structure(update_theano='matrices')
+        self.update_structure(update_aesara='matrices')
         return self._surfaces
 
     @_setdoc(Surfaces.delete_surface_values.__doc__, indent=False)
     def delete_surface_values(self, properties_names: list):
         self.delete_surface_values(properties_names)
         return self._surfaces
 
@@ -930,15 +924,15 @@
                 raise AttributeError(
                     str(type(mapping_object)) + ' is not the right attribute type.')
 
         self._surfaces.map_series(mapping_object)
 
         # Here we remove the series that were not assigned to a surface
         if remove_unused_series is True:
-            self._surfaces.df['series'].cat.remove_unused_categories(inplace=True)
+            self._surfaces.df['series'] = self._surfaces.df['series'].cat.remove_unused_categories()
             unused_cat = self._stack.df.index[~self._stack.df.index.isin(
                 self._surfaces.df['series'].cat.categories)]
             self._stack.delete_series(unused_cat)
 
         self._stack.reset_order_series()
 
         self.update_from_surfaces()
@@ -992,29 +986,32 @@
         Keyword Args:
             bool add_basement: add a basement surface to the df.
 
         See Also:
             :class:`gempy.core.data_modules.geometric_data.SurfacePoints`
 
         """
-
+        if isinstance(table,pn.DataFrame):
+            table = table.reset_index(drop=True)
+        else:
+            raise ValueError('Input must be Pandas Dataframe')
         try:
             coord_x_name = kwargs.get('coord_x_name') if 'coord_x_name' in kwargs \
                 else self._check_possible_column_names(table, ['X', 'x'])
             coord_y_name = kwargs.get('coord_y_name') if 'coord_y_name' in kwargs \
                 else self._check_possible_column_names(table, ['Y', 'y'])
         except IndexError:
             raise ValueError('X and Y coordinates columns/values missing')
 
         try:
             coord_z_name = kwargs.get('coord_z_name') if 'coord_z_name' in kwargs \
                 else self._check_possible_column_names(table, ['Z', 'z'])
         except IndexError:
             raise ValueError('Z coordinates column/values missing')
-        
+
         surface_name = kwargs.get('surface_name') if 'surface_name' in kwargs \
             else self._check_possible_column_names(table,
                                                    ['surface', 'Surface', 'surfaces',
                                                     'surfaces', 'formations',
                                                     'formation'])
         update_surfaces = kwargs.get('update_surfaces', True)
 
@@ -1050,14 +1047,18 @@
         Returns:
             :class:`gempy.core.data_modules.geometric_data.Orientations`
 
         See Also:
             :class:`gempy.core.data_modules.geometric_data.Orientations`
 
         """
+        if isinstance(table,pn.DataFrame):
+            table = table.reset_index(drop=True)
+        else:
+            raise ValueError('Input must be Pandas Dataframe')
         g_x_name = kwargs.get('G_x_name', 'G_x')
         g_y_name = kwargs.get('G_y_name', 'G_y')
         g_z_name = kwargs.get('G_z_name', 'G_z')
         azimuth_name = kwargs.get('azimuth_name', 'azimuth')
         dip_name = kwargs.get('dip_name', 'dip')
         polarity_name = kwargs.get('polarity_name', 'polarity')
         update_surfaces = kwargs.get('update_surfaces', False)
@@ -1089,15 +1090,15 @@
 
         self.map_geometric_data_df(self._orientations.df)
         self._rescaling.rescale_data()
         self.update_structure()
 
         return self._orientations
 
-    @_setdoc_pro(ds.recompute_rf)
+    @_setdoc_pro(recompute_rf)
     @_setdoc(SurfacePoints.add_surface_points.__doc__, indent=False, position='beg')
     @plot_add_surface_points
     def add_surface_points(self, X, Y, Z, surface,
                            idx: Union[int, Iterable[int]] = None,
                            recompute_rescale_factor=False):
         """
         Args:
@@ -1112,28 +1113,28 @@
         surface = np.atleast_1d(surface)
         idx = self._add_valid_idx_s(idx)
         self._surface_points.add_surface_points(X, Y, Z, surface, idx)
 
         if recompute_rescale_factor is True or idx < 20:
             # This will rescale all data again
             self._rescaling.rescale_data()
-            self._interpolator.set_theano_shared_kriging()
+            self._interpolator.set_aesara_shared_kriging()
         else:
             # This branch only recompute the added point
             self._rescaling.set_rescaled_surface_points(idx)
-        self.update_structure(update_theano='matrices')
-        self._interpolator.set_theano_shared_nuggets()
+        self.update_structure(update_aesara='matrices')
+        self._interpolator.set_aesara_shared_nuggets()
 
         return self._surface_points, idx
 
     @_setdoc(SurfacePoints.del_surface_points.__doc__, indent=False, position='beg')
     @plot_delete_surface_points
     def delete_surface_points(self, idx: Union[int, Iterable[int]]):
         self._surface_points.del_surface_points(idx)
-        self.update_structure(update_theano='matrices')
+        self.update_structure(update_aesara='matrices')
         return self._surface_points
 
     def delete_surface_points_basement(self):
         """Delete surface points belonging to the basement layer if any"""
 
         basement_name = \
             self._surfaces.df['surface'][self._surfaces.df['isBasement']].values[0]
@@ -1174,26 +1175,26 @@
                 'Surface points cannot belong to Basement. Add a new surface.'
 
         self._surface_points.modify_surface_points(indices, **kwargs)
 
         if recompute_rescale_factor is True or np.atleast_1d(indices).shape[0] < 20:
             # This will rescale all data again
             self._rescaling.rescale_data()
-            self._interpolator.set_theano_shared_kriging()
+            self._interpolator.set_aesara_shared_kriging()
         else:
             # This branch only recompute the added point
             self._rescaling.set_rescaled_surface_points(indices)
 
         keys = list(kwargs.keys())
         is_surface = np.isin('surface', keys).all()
         if is_surface == True:
-            self.update_structure(update_theano='matrices')
+            self.update_structure(update_aesara='matrices')
 
         if 'smooth' in kwargs:
-            self._interpolator.set_theano_shared_nuggets()
+            self._interpolator.set_aesara_shared_nuggets()
 
         return self._surface_points
 
     # endregion
 
     # region Orientation
     def set_orientations_object(self, orientations: Orientations, update_model=True):
@@ -1217,73 +1218,73 @@
             recompute_rescale_factor: [s_recompute_rf]
 
         Returns:
             :class:`gempy.core.data_modules.geometric_data.Orientations`
 
         """
 
-        surface = np.atleast_1d(surface)
+        surface = list(np.atleast_1d(surface))
         idx = self._add_valid_idx_o(idx)
 
         self._orientations.add_orientation(X, Y, Z, surface, pole_vector=pole_vector,
                                            orientation=orientation, idx=idx)
         if recompute_rescale_factor is True or idx < 5:
             # This will rescale all data again
             self._rescaling.rescale_data()
         else:
             # This branch only recompute the added point
             self._rescaling.set_rescaled_orientations(idx)
-        self.update_structure(update_theano='weights')
-        self._interpolator.set_theano_shared_nuggets()
+        self.update_structure(update_aesara='weights')
+        self._interpolator.set_aesara_shared_nuggets()
 
         return self._orientations, idx
 
     @_setdoc(Orientations.del_orientation.__doc__, indent=False, position='beg')
     @plot_delete_orientations
     def delete_orientations(self, idx: Union[list, int]):
         self._orientations.del_orientation(idx)
-        self.update_structure(update_theano='weights')
+        self.update_structure(update_aesara='weights')
         return self._orientations
 
     @_setdoc(Orientations.modify_orientations.__doc__, indent=False, position='beg')
     @plot_move_orientations
     def modify_orientations(self, idx: list, **kwargs):
 
         idx = np.array(idx, ndmin=1)
         keys = list(kwargs.keys())
         is_surface = np.isin('surface', keys).all()
         self._orientations.modify_orientations(idx, **kwargs)
         self._rescaling.set_rescaled_orientations(idx)
 
         if is_surface:
-            self.update_structure(update_theano='weights')
+            self.update_structure(update_aesara='weights')
         if 'smooth' in kwargs:
-            self._interpolator.set_theano_shared_nuggets()
+            self._interpolator.set_aesara_shared_nuggets()
         return self._orientations
 
     # endregion
 
     # region Options
     @_setdoc(Options.modify_options.__doc__, indent=False, position='beg')
     def modify_options(self, attribute, value):
         self._additional_data.options.modify_options(attribute, value)
         warnings.warn(
-            'You need to recompile the Theano code to make it the changes in options.')
+            'You need to recompile the aesara code to make it the changes in options.')
 
         return self._additional_data.options
 
     # endregion
 
     # region Kriging
     @_setdoc(KrigingParameters.modify_kriging_parameters.__doc__, indent=False,
              position='beg')
     def modify_kriging_parameters(self, attribute, value, **kwargs):
         self._additional_data.kriging_data.modify_kriging_parameters(attribute,
                                                                      value, **kwargs)
-        self._interpolator.set_theano_shared_kriging()
+        self._interpolator.set_aesara_shared_kriging()
         if attribute == 'drift equations':
             self._interpolator.set_initial_results()
             self.update_structure()
         return self._additional_data.kriging_data
 
     # endregion
 
@@ -1376,24 +1377,24 @@
         This method is a bit of a legacy and has been substituted by :meth:`rename_series` and :meth:`reorder_series`,
         however is useful if you want to make sure all objects are up to date with the latest changes on series.
 
         Args:
 
             reorder_series (bool): if True reorder all pandas categories accordingly to the series.df
             sort_geometric_data (bool): It True sort the geometric data after mapping the new order
-            update_interpolator (bool): If True update the theano shared variables dependent on the structure
+            update_interpolator (bool): If True update the aesara shared variables dependent on the structure
 
         Returns:
             True
         """
 
         if reorder_series is True:
-            self._surfaces.df['series'].cat.reorder_categories(
+            self._surfaces.df['series'] = self._surfaces.df['series'].cat.reorder_categories(
                 np.asarray(self._stack.df.index),
-                ordered=False, inplace=True)
+                ordered=False)
             self._stack.df.index = self._stack.df.index.reorder_categories(
                 self._stack.df.index.array,
                 ordered=False)
             self._surfaces.sort_surfaces()
             self.update_from_surfaces(set_categories_from_series=False,
                                       set_categories_from_surfaces=True,
                                       map_surface_points=False,
@@ -1418,15 +1419,15 @@
             self._orientations.sort_table()
 
         self._additional_data.update_structure()
         # For the drift equations.
         self._additional_data.update_default_kriging()
 
         if update_interpolator is True:
-            self._interpolator.set_theano_shared_structure(reset_ctrl=True)
+            self._interpolator.set_aesara_shared_structure(reset_ctrl=True)
 
         return True
 
     def update_from_surfaces(self, set_categories_from_series=True,
                              set_categories_from_surfaces=True,
                              map_surface_points=True, map_orientations=True,
                              update_structural_data=True):
@@ -1464,41 +1465,40 @@
             self._orientations.map_data_from_surfaces(self._surfaces, 'id')
 
         if update_structural_data is True:
             self._additional_data.update_structure()
 
         return True
 
-    # region Theano interface
+    # region aesara interface
     @_setdoc(InterpolatorModel.__doc__)
-    def set_theano_graph(self, interpolator: InterpolatorModel,
+    def set_aesara_graph(self, interpolator: InterpolatorModel,
                          update_structure=True, update_kriging=True):
-        """ Pass a theano graph of a Interpolator instance other than the Model compose
+        """ Pass a aesara graph of a Interpolator instance other than the Model compose
 
         Use this method only if you know what are you doing!
 
         Args:
             interpolator (:class:`InterpolatorModel`): [s0]
 
         Returns:
              True """
-        warnings.warn(
-            'This function is going to be deprecated. Use Model.set_theano_function instead',
-            DeprecationWarning)
-        self._interpolator.theano_graph = interpolator.theano_graph
-        self._interpolator.theano_function = interpolator.theano_function
+        warnings.warn('This function is going to be deprecated. Use Model.set_aesara_function instead',
+                      DeprecationWarning)
+        self._interpolator.aesara_graph = interpolator.aesara_graph
+        self._interpolator.aesara_function = interpolator.aesara_function
         self.update_additional_data(update_structure=update_structure,
                                     update_kriging=update_kriging)
         self.update_to_interpolator()
         return True
 
     # @_setdoc(InterpolatorModel.__doc__)
-    def set_theano_function(self, interpolator: InterpolatorModel,
+    def set_aesara_function(self, interpolator: InterpolatorModel,
                             update_structure=True, update_kriging=True):
-        """Pass a theano function and its correspondent graph from an Interpolator
+        """Pass a aesara function and its correspondent graph from an Interpolator
          instance other than the Model compose
 
         Args:
             interpolator (:class:`gempy.core.interpolator.InterpolatorModel`): interpolator object
              with the compile graph.
             update_kriging (bool): if True update kriging parameters
             update_structure (bool): if Ture update structure
@@ -1506,25 +1506,25 @@
         Returns:
             bool: True
 
         See Also:
             :class:`gempy.core.interpolator.InterpolatorModel`
         """
 
-        self._interpolator.theano_graph = interpolator.theano_graph
-        self._interpolator.theano_function = interpolator.theano_function
+        self._interpolator.aesara_graph = interpolator.aesara_graph
+        self._interpolator.aesara_function = interpolator.aesara_function
         self.update_additional_data(update_structure=update_structure,
                                     update_kriging=update_kriging)
         self.update_to_interpolator()
 
         return True
 
     def update_additional_data(self, update_structure=True, update_kriging=True):
         if update_structure is True:
-            self.update_structure(update_theano='matrices')
+            self.update_structure(update_aesara='matrices')
 
         if update_kriging is True:
             print('Setting kriging parameters to their default values.')
             self._additional_data.update_default_kriging()
 
         return self._additional_data
 
@@ -1567,16 +1567,23 @@
         Order the surfaces respect the last computation. Therefore if you call this method,
         after sorting surface_points without recomputing you may get wrong results.
 
         Returns:
             Surfaces
         """
 
-        sfai_order = self.solutions.scalar_field_at_surface_points.sum(axis=0)
-        # Check if the order has changed
+        field_at_surface_points = self.solutions.scalar_field_at_surface_points
+        match type(field_at_surface_points):
+            case np.ndarray:
+                sfai_order = field_at_surface_points.sum(axis=0)
+            case list:
+                # concatenate
+                sfai_order = np.concatenate(field_at_surface_points, axis=0)
+
+                # Check if the order has changed
         if not np.array_equal(sfai_order, self._sfai_order_0):
             self._sfai_order_0 = sfai_order
             sel = self._surfaces.df['isActive'] & ~self._surfaces.df['isBasement']
             self._surfaces.df.loc[sel, 'sfai'] = sfai_order
             self._surfaces.df.sort_values(by=['series', 'sfai'], inplace=True,
                                           ascending=False)
             self._surfaces.reset_order_surfaces()
@@ -1595,15 +1602,15 @@
 def Model(project_name='default_project'):
     """ Container class of all objects that constitute a GemPy model.
 
       In addition the class provides the methods that act in more than one of this class. Model is a child class of
       :class:`DataMutation` and :class:`MetaData`.
 
       """
-    warnings.warn('This C;ass is going to be deprecated in GemPy 2.3. '
+    warnings.warn('This Class is going to be deprecated in GemPy 2.3. '
                   'Use Project instead.',
                   DeprecationWarning)
     return Project(project_name)
 
 
 class Project(ImplicitCoKriging):
     """Container class of all objects that constitute a GemPy model.
@@ -1667,21 +1674,22 @@
         import pickle
         with open(path, 'rb') as f:
             # The protocol version used is detected automatically, so we do not
             # have to specify it.
             model = pickle.load(f)
             return model
 
-    def save_model(self, name=None, path=None, compress=True):
+    def save_model(self, name=None, path=None, compress=True, save_solution=True):
         """
         Save model in new folder. Input data is saved as csv files. Solutions, extent and resolutions are saved as npy.
 
         Args:
             name (str): name of the newly created folder and the part of the files name
             path (str): path where save the model folder.
+            save_solution (bool): if True, save the solution
             compress (bool): If true create a zip
 
         Returns:
             True
         """
         if name is None or path is None:
             from gempy.api_modules.io import default_path_and_name
@@ -1704,21 +1712,29 @@
         # # save resolution and extent as npy
         np.save(f'{path}/{name}_extent.npy', self._grid.regular_grid.extent)
         np.save(f'{path}/{name}_resolution.npy', self._grid.regular_grid.resolution)
 
         if self._grid.topography is not None:
             self._grid.topography.save(f'{path}/{name}_topography.npy')
 
+        if self._grid.sections is not None:
+            self._grid.sections.df.to_csv(f'{path}/{name}_sections.csv')
+            np.save(f'{path}/{name}_sections.npy', self._grid.sections.values)
+
+        if save_solution:
+            self.save_solution(name, path)
+
         # if compress is True:
         #     shutil.make_archive(name, 'zip', path)
         #     shutil.rmtree(path)
         return True
 
-    def save_solution(self):
-        pass
+    def save_solution(self, name=None, path=None):
+        if self.solutions.lith_block is not None:
+            np.save(f'{path}/{name}_lith_block.npy', self.solutions.lith_block)
 
     def read_data(self, source_i=None, source_o=None, add_basement=True, **kwargs):
         """
         Read data from a csv, or directly supplied dataframes
 
         Args:
             source_i: Path to the data bases of surface_points. Default os.getcwd(), or direct pandas data frame
```

### Comparing `gempy-2.2b10.dev1/gempy/core/solution.py` & `gempy-2.3.0/gempy/core/solution.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,25 +1,27 @@
 import numpy as np
 from typing import Union
 import warnings
 from skimage import measure
-from gempy.utils.input_manipulation import find_interfaces_from_block_bottoms
-from gempy.core.data import Grid, Surfaces
-from gempy.core.data_modules.stack import Series, Stack
-from gempy.utils.meta import _setdoc_pro
+
+from ..utils.input_manipulation import find_interfaces_from_block_bottoms
+from .surfaces import Surfaces
+from .grid import Grid
+from .data_modules.stack import Series, Stack
+from ..utils.meta import _setdoc_pro
 import gempy.utils.docstring as ds
 
 try:
     from gempy.core.xsolution import XSolution
 
-    _xsolution_imported = True
+    xsolution_imported = True
     inheritance = XSolution
 except ImportError:
     inheritance = object
-    _xsolution_imported = False
+    xsolution_imported = False
 
 
 @_setdoc_pro(
     [Grid.__doc__, Surfaces.__doc__, Series.__doc__, ds.weights_vector, ds.sfai,
      ds.bai, ds.mai, ds.vai,
      ds.lith_block, ds.sfm, ds.bm, ds.mm, ds.vm, ds.vertices, ds.edges,
      ds.geological_map])
@@ -58,15 +60,15 @@
     """
 
     def __init__(self, grid: Grid = None,
                  surfaces: Surfaces = None,
                  series: Series = None,
                  ):
 
-        if _xsolution_imported:
+        if xsolution_imported:
             super().__init__(grid, surfaces, series)
 
         self.grid = grid
         self.stack = series
         self.surfaces = surfaces
 
         # Input data results
@@ -97,23 +99,23 @@
 
         # Center Grid
         self.fw_gravity = None
         self.fw_magnetics = None
 
     def __repr__(self):
         return '\nLithology ids \n  %s \n' \
-               % (np.array2string(self.lith_block))
+            % (np.array2string(self.lith_block))
 
     def set_solution_to_regular_grid(self, values: Union[list, np.ndarray],
                                      compute_mesh: bool = True,
                                      compute_mesh_options: dict = None):
         """If regular grid is active set all the solution objects dependent on them and compute mesh.
 
         Args:
-            values (list[np.array]): list with result of the theano evaluation (values returned by
+            values (list[np.array]): list with result of the aesara evaluation (values returned by
              :func:`gempy.compute_model` function):
 
                  - block_matrix
                  - weights_vector
                  - scalar_field_matrix
                  - scalar field at interfaces
                  - mask_matrix
@@ -157,76 +159,78 @@
         # Set gravity
         self.fw_gravity = sol[12]
 
         # TODO: [X] Set magnetcs and [ ] set topology @A.Schaaf probably it should
         #  populate the topology object?
         self.fw_magnetics = sol[13]
 
-        if _xsolution_imported and to_subsurface is True:
+        if xsolution_imported and to_subsurface is True:
             self.set_values(sol)
             if compute_mesh is True:
                 try:
                     self.set_meshes(self.surfaces)
                 except ValueError:
                     warnings.warn('Meshes are empty.')
         return self
 
     def set_solution_to_custom(self, values: Union[list, np.ndarray]):
         l0, l1 = self.grid.get_grid_args('custom')
-        self.custom = np.array(
-            [values[0][:, l0: l1], values[4][:, l0: l1].astype(float)])
+        self.custom = np.stack(  # * This has been changed recently. It could give problems how we slice the field
+            [values[0][:, l0: l1],
+             values[4][:, l0: l1].astype(float)]
+        )
 
     def set_solution_to_topography(self, values: Union[list, np.ndarray]):
         l0, l1 = self.grid.get_grid_args('topography')
-        self.geological_map = np.array(
-            [values[0][:, l0: l1], values[4][:, l0: l1].astype(float)])
+        self.geological_map = np.vstack(  # * This has been changed recently. It could give problems how we slice the field
+            [values[0][:, l0: l1],
+             values[4][:, l0: l1].astype(float)]
+        )
 
     def set_solution_to_sections(self, values: Union[list, np.ndarray]):
         l0, l1 = self.grid.get_grid_args('sections')
-        self.sections = np.array(
-            [values[0][:, l0: l1], values[4][:, l0: l1].astype(float)])
+        self.sections = np.vstack(  # * This has been changed recently. It could give problems how we slice the field
+            [values[0][:, l0: l1],
+             values[4][:, l0: l1].astype(float)]
+        )
 
     def set_values_to_regular_grid(self, values: Union[list, np.ndarray]):
         """Set all solution values to the correspondent attribute.
 
         Args:
             values (np.ndarray): values returned by `function: gempy.compute_model` function
             compute_mesh (bool): if true compute automatically the grid
 
         Returns:
             :class:`gempy.core.solutions.Solutions`
 
         """
-        regular_grid_length_l0, regular_grid_length_l1 = self.grid.get_grid_args(
-            'regular')
+        regular_grid_length_l0, regular_grid_length_l1 = self.grid.get_grid_args('regular')
 
         # Lithology final block
-        self.lith_block = values[0][0,
-                          regular_grid_length_l0: regular_grid_length_l1]
+        self.lith_block = values[0][0, regular_grid_length_l0: regular_grid_length_l1]
 
         # Properties
-        self.values_matrix = values[0][1:,
-                             regular_grid_length_l0: regular_grid_length_l1]
+        self.values_matrix = values[0][1:, regular_grid_length_l0: regular_grid_length_l1]
 
         # Axis 0 is the series. Axis 1 is the value
-        self.block_matrix = values[1][:, :,
-                            regular_grid_length_l0: regular_grid_length_l1]
 
+        self.block_matrix = values[1][:, :, regular_grid_length_l0: regular_grid_length_l1]
         self.fault_block = values[2]
-        # This here does not make any sense
-        self.weights_vector = values[3]
+        #self.block_matrix = values[1][:, :,
+        #                    regular_grid_length_l0: regular_grid_length_l1]
 
-        self.scalar_field_matrix = values[4][:,
-                                   regular_grid_length_l0: regular_grid_length_l1]
+        #self.fault_block = values[2][0,
+        #                  regular_grid_length_l0: regular_grid_length_l1]
 
-        self.mask_matrix = values[6][:,
-                           regular_grid_length_l0: regular_grid_length_l1]
-
-        self.fault_mask = values[7][:,
-                          regular_grid_length_l0: regular_grid_length_l1]
+        # This here does not make any sense
+        self.weights_vector = values[3]
+        self.scalar_field_matrix = values[4][:, regular_grid_length_l0: regular_grid_length_l1]
+        self.mask_matrix = values[6][:, regular_grid_length_l0: regular_grid_length_l1]
+        self.fault_mask = values[7][:, regular_grid_length_l0: regular_grid_length_l1]
 
         # TODO add topology solutions
 
         return self
 
     def set_values_to_surface_points(self, values):
         x_to_intep_length = self.grid.length[-1]
@@ -259,15 +263,17 @@
             :func:`skimage.measure.marching_cubes`
 
         """
         rg = self.grid.regular_grid
         spacing = self.grid.regular_grid.get_dx_dy_dz(rescale=rescale)
         vertices, simplices, normals, values = measure.marching_cubes(
             scalar_field.reshape(rg.resolution),
-            level, spacing=spacing, mask=mask_array, **kwargs)
+            level,
+            spacing=spacing,
+            mask=mask_array, **kwargs)
         idx = [0, 2, 4]
         loc_0 = rg.extent_r[idx] if rescale else rg.extent[idx]
         loc_0 = loc_0 + np.array(spacing) / 2
         vertices += np.array(loc_0).reshape(1, 3)
 
         return [vertices, simplices, normals, values]
 
@@ -282,19 +288,22 @@
         Returns:
               numpy.ndarray: masked regular grid
         """
 
         self.mask_matrix_pad = []
         series_type = self.stack.df['BottomRelation']
         for e, mask_series in enumerate(self.mask_matrix):
-            mask_series_reshape = mask_series.reshape(
-                self.grid.regular_grid.resolution)
+            mask_series_reshape = mask_series.reshape(self.grid.regular_grid.resolution)
 
-            mask_pad = (mask_series_reshape + find_interfaces_from_block_bottoms(
-                mask_series_reshape, True, shift=shift))
+            interfaces_from_block_bottoms = find_interfaces_from_block_bottoms(
+                block=mask_series_reshape,
+                value=True,
+                shift=shift
+            )
+            mask_pad = mask_series_reshape + interfaces_from_block_bottoms
 
             if series_type[e] == 'Fault':
                 mask_pad = np.invert(mask_pad)
 
             if mask_topography and self.grid.regular_grid.mask_topo.size != 0:
                 mask_pad *= np.invert(self.grid.regular_grid.mask_topo)
             self.mask_matrix_pad.append(mask_pad)
@@ -317,45 +326,40 @@
         self.edges = []
         mask_topography = kwargs.pop('mask_topography', True)
         masked_marching_cubes = kwargs.pop('masked_marching_cubes', True)
         self.mask_matrix_pad = self.padding_mask_matrix(
             mask_topography=mask_topography
         )
         series_type = self.stack.df['BottomRelation']
-        s_n = 0
+        series_number = 0
         active_indices = self.surfaces.df.groupby('isActive').groups[True]
         rescale = kwargs.pop('rescale', False)
 
         # We loop the scalar fields
         for e, scalar_field in enumerate(self.scalar_field_matrix):
-
             # Drop
-            mask_array, sfas = self.prepare_marching_cubes_args(e,
-                                                                masked_marching_cubes,
-                                                                series_type)
+            mask_array, sfas = self._prepare_marching_cubes_args(
+                stack_number=e,
+                masked_marching_cubes=masked_marching_cubes,
+                series_type=series_type
+            )
+            
             for level in sfas:
-                s, v = self.try_compute_marching_cubes_on_the_regular_grid(
-                    level,
-                    mask_array,
-                    rescale,
-                    s_n,
-                    scalar_field,
-                    kwargs
+                simpleces, vertices = self._try_compute_marching_cubes_on_the_regular_grid(
+                    level=level,
+                    mask_array=mask_array,
+                    rescale=rescale,
+                    s_n=series_number,
+                    scalar_field=scalar_field,
+                    kwargs=kwargs
                 )
-                s_n = self.set_vertices_edges(active_indices, s, s_n, v)
+                series_number = self.set_vertices_edges(active_indices, simpleces, series_number, vertices)
         return self.vertices, self.edges
 
-    def try_compute_marching_cubes_on_the_regular_grid(
-            self,
-            level,
-            mask_array,
-            rescale,
-            s_n,
-            scalar_field,
-            kwargs):
+    def _try_compute_marching_cubes_on_the_regular_grid(self, level, mask_array, rescale, s_n, scalar_field, kwargs):
         try:
             v, s, norm, val = self.compute_marching_cubes_regular_grid(
                 level, scalar_field, mask_array, rescale=rescale, **kwargs)
         except Exception as e:
             warnings.warn('Surfaces not computed due to: ' + str(
                 e) + '. The surface is: Series: ' + str(e) +
                           '; Surface Number:' + str(s_n))
@@ -368,20 +372,20 @@
         self.edges.append(s)
         idx = active_indices[s_n]
         self.surfaces.df.loc[idx, 'vertices'] = [v]
         self.surfaces.df.loc[idx, 'edges'] = [s]
         s_n += 1
         return s_n
 
-    def prepare_marching_cubes_args(self, e, masked_marching_cubes, series_type):
+    def _prepare_marching_cubes_args(self, stack_number, masked_marching_cubes, series_type):
 
-        sfas = self.scalar_field_at_surface_points[e]
+        sfas = self.scalar_field_at_surface_points[stack_number]
         sfas = sfas[np.nonzero(sfas)]
         if masked_marching_cubes is True:
-            if series_type[e - 1] == 'Onlap' and series_type[e - 2] == 'Erosion':
-                mask_array = self.mask_matrix_pad[e-1]
+            if series_type[stack_number - 1] == 'Onlap' and series_type[stack_number - 2] == 'Erosion':
+                mask_array = self.mask_matrix_pad[stack_number - 1]
             else:
-                mask_array = self.mask_matrix_pad[e]
+                mask_array = self.mask_matrix_pad[stack_number]
 
         else:
             mask_array = None
         return mask_array, sfas
```

### Comparing `gempy-2.2b10.dev1/gempy/core/theano_modules/theano_graph.py` & `gempy-2.3.0/gempy/core/aesara_modules/aesara_graph.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,2242 +1,2242 @@
-"""
-    This file is part of gempy.
-
-    gempy is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    gempy is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
-
-
-DEP-- I need to update this string
-Function that generates the symbolic code to perform the interpolation. Calling this function creates
- both the theano functions for the potential field and the block.
-
-Returns:
-    theano function for the potential field
-    theano function for the block
-"""
-import theano
-import theano.tensor as T
-import numpy as np
-import sys
-
-theano.config.openmp_elemwise_minsize = 10000
-theano.config.openmp = True
-
-theano.config.optimizer = 'fast_compile'
-theano.config.floatX = 'float64'
-theano.config.on_opt_error = 'ignore'
-
-theano.config.exception_verbosity = 'high'
-theano.config.compute_test_value = 'off'
-theano.config.profile_memory = False
-theano.config.scan.debug = False
-theano.config.profile = False
-
-
-class TheanoGraph(object):
-    """
-    This class is used to help to divide the construction of the graph into sensical parts. All its methods buildDEP2 a part
-    of the graph. Every method can be seen as a branch and collection of branches until the last method that will be the
-    whole tree. Every part of the graph could be compiled separately but as we increase the complexity the input of each
-    of these methods is more and more difficult to provide (if you are in a branch close to the trunk you need all the
-    results of the branches above)
-    """
-    def __init__(self, output='geology', optimizer='fast_compile', verbose=[0], dtype='float32',
-                 is_fault=None, is_lith=None):
-        """
-        In the init we need to create all the symbolic parameters that are used in the process. Most of the variables
-        are shared parameters initialized with random values. At this stage we only care about the type and shape of the
-        parameters. After we have the graph built we can update the value of these shared parameters to our data (in the
-        interpolatorClass).
-
-        Args:
-            u_grade: grade of the drift to compile the right graph. I found out that we can make a graph that takes this
-            as variable so this argument will be deprecated soon
-            verbose (list): name of the nodes you want to print
-            dtype (str): type of float either 32 or 64
-        """
-
-        # Pass the verbose list as property
-
-        # OPTIONS
-        # -------
-        if verbose is np.nan:
-            self.verbose = [None]
-        else:
-            self.verbose = verbose
-        self.dot_version = False
-
-        theano.config.floatX = dtype
-        theano.config.optimizer = optimizer
-
-        # Creation of symbolic parameters
-        # =============
-        # Constants
-        # =============
-
-        # They weight the contribution of the surface_points against the orientations.
-        self.i_reescale = theano.shared(np.cast[dtype](4.))
-        self.gi_reescale = theano.shared(np.cast[dtype](2.))
-
-        # Number of dimensions. Now it is not too variable anymore
-        self.n_dimensions = 3
-
-        self.len_i_0 = 0
-        self.len_i_1 = 1
-
-        # =================
-        # INITIALIZE SHARED
-        # =================
-
-        # SEMI-VARIABLES
-        # --------------
-        self.grid_val_T = theano.shared(np.cast[dtype](np.zeros((2, 200))), 'Coordinates of the grid '
-                                                                            'points to interpolate')
-        # Shape is 9x2, 9 drift funcitons and 2 points
-        self.universal_grid_matrix_T = theano.shared(np.cast[dtype](np.zeros((9, 9)))) #TODO future DEP
-
-        # FORMATIONS
-        # ----------
-        self.n_surface = theano.shared(np.arange(2, 5, dtype='int32'), "ID of the surface")
-        self.n_surface_op = self.n_surface
-        self.surface_values = theano.shared((np.arange(2, 4, dtype=dtype).reshape(2, -1)), "Value of the surface to compute")
-        self.n_surface_op_float = self.surface_values
-
-        # FAULTS
-        # ------
-        # Init fault relation matrix
-        self.fault_relation = theano.shared(np.array([[0, 1, 0, 1],
-                                                      [0, 0, 1, 1],
-                                                      [0, 0, 0, 1],
-                                                      [0, 0, 0, 0]]), 'fault relation matrix')
-
-        self.inf_factor = theano.shared(np.ones(200, dtype='int32') * 10, 'Arbitrary scalar to make df infinite')
-
-        # KRIGING
-        # -------
-        self.a_T = theano.shared(np.cast[dtype](-1.), "Range")
-        self.c_o_T = theano.shared(np.cast[dtype](-1.), 'Covariance at 0')
-        self.nugget_effect_grad_T = theano.shared(np.cast[dtype](-1), 'Nugget effect of gradients')
-        self.nugget_effect_scalar_T = theano.shared(np.cast[dtype](-1), 'Nugget effect of scalar')
-        self.n_universal_eq_T = theano.shared(np.zeros(5, dtype='int32'), "Grade of the universal drift")
-        self.n_universal_eq_T_op = theano.shared(3)
-
-        # STRUCTURE
-        # ---------
-        # This parameters give me the shape of the different groups of data. I pass all data together and I threshold it
-        # using these values to the different potential fields and surfaces
-        self.is_fault = is_fault
-        self.is_lith = is_lith
-        self.n_faults = theano.shared(0, 'Number of df')
-        self.n_surfaces_per_series = theano.shared(np.arange(2, dtype='int32'), 'List with the number of surfaces')
-
-        # This is not accumulative
-        self.number_of_points_per_surface_T = theano.shared(np.zeros(3, dtype='int32')) #TODO is DEP?
-        self.number_of_points_per_surface_T_op = self.number_of_points_per_surface_T
-        # This is accumulative
-        self.npf = theano.shared(np.zeros(3, dtype='int32'), 'Number of points per surface accumulative')
-        self.npf_op = self.npf[[0, -2]]
-        self.len_series_i = theano.shared(np.arange(2, dtype='int32'), 'Length of surface_points in every series')
-        self.len_series_f = theano.shared(np.arange(2, dtype='int32'), 'Length of foliations in every series')
-
-        # VARIABLES
-        # ---------
-        self.dips_position_all = T.matrix("Position of the dips")
-        self.dip_angles_all = T.vector("Angle of every dip")
-        self.azimuth_all = T.vector("Azimuth")
-        self.polarity_all = T.vector("Polarity")
-
-        self.surface_points = T.matrix("All the surface_points points at once")
-        #self.ref_layer_points_all = T.matrix("Reference points for every layer") # TODO: This should be DEP
-        #self.rest_layer_points_all = T.matrix("Rest of the points of the layers") # TODO: This should be DEP
-        self.len_points = self.surface_points.shape[0] - self.number_of_points_per_surface_T.shape[0]
-        # Tiling dips to the 3 spatial coordinations
-        self.dips_position = self.dips_position_all
-        self.dips_position_tiled = T.tile(self.dips_position, (self.n_dimensions, 1))
-
-        # These are subsets of the data for each series. I initialized them as the whole arrays but then they will take
-        # the data of every potential field
-        self.dip_angles = self.dip_angles_all
-        self.azimuth = self.azimuth_all
-        self.polarity = self.polarity_all
-
-        self.ref_layer_points_all = self.set_rest_ref_matrix()[0]
-        self.rest_layer_points_all = self.set_rest_ref_matrix()[1]
-
-        self.ref_layer_points = self.ref_layer_points_all
-        self.rest_layer_points = self.rest_layer_points_all
-
-        # SOLUTION
-        # --------
-        self.final_block = theano.shared(np.cast[dtype](np.zeros((1, 3))), "Final block computed")
-
-        self.final_scalar_field_at_surfaces = theano.shared(
-            np.zeros(self.n_surfaces_per_series.get_value().sum(), dtype=dtype))
-        self.final_scalar_field_at_faults = theano.shared(
-            np.zeros(self.n_surfaces_per_series.get_value().sum(), dtype=dtype))
-
-        self.final_scalar_field_at_surfaces_op = self.final_scalar_field_at_surfaces
-        self.final_potential_field_at_faults_op = self.final_scalar_field_at_faults
-
-        # Init Results
-        # Init lithology block. Here we store the block and potential field results
-        self.lith_block_init = T.zeros((2, self.grid_val_T.shape[0] + 2 * self.len_points))
-        self.lith_block_init.name = 'final block of lithologies init'
-
-        # Init df block. Here we store the block and potential field results of one iteration
-        self.fault_block_init = T.zeros((2, self.grid_val_T.shape[0] + 2 * self.len_points))
-        self.fault_block_init.name = 'final block of df init'
-        self.yet_simulated = T.nonzero(T.eq(self.fault_block_init[0, :], 0))[0]
-
-        # Init gradient block.
-        self.gradient_block_init = T.zeros((3, self.grid_val_T.shape[0] + 2 * self.len_points))
-        self.gradient_block_init.name = 'final block of gradient init'
-        self.gradients = []
-
-        # Here we store the value of the potential field at surface_points
-        self.pfai_fault = T.zeros((0, self.n_surfaces_per_series[-1]))
-        self.pfai_lith = T.zeros((0, self.n_surfaces_per_series[-1]))
-
-        self.fault_matrix = T.zeros((0, self.grid_val_T.shape[0] + 2 * self.len_points))
-
-        # GRAVITY
-        # -------
-        if output is 'gravity':
-            self.densities = theano.shared(np.cast[dtype](np.zeros(3)), "List with the densities")
-            self.tz = theano.shared(np.cast[dtype](np.zeros((1, 3))), "Component z")
-            self.select = theano.shared(np.cast['int8'](np.zeros(3)), "Select nearby cells")
-            # Init gray voxels for gravity
-            self.weigths_weigths = theano.shared(np.ones(0))
-            self.weigths_index = theano.shared(np.ones(0, dtype='int32'))
-
-        self.weights = theano.shared(None)
-
-    def set_rest_ref_matrix(self):
-        ref_positions = T.cumsum(T.concatenate((T.stack(0), self.number_of_points_per_surface_T[:-1] + 1)))
-        ref_points = T.repeat(self.surface_points[ref_positions], self.number_of_points_per_surface_T, axis=0)
-
-        rest_mask = T.ones(T.stack(self.surface_points.shape[0]), dtype='int16')
-        rest_mask = T.set_subtensor(rest_mask[ref_positions], 0)
-        rest_points = self.surface_points[T.nonzero(rest_mask)[0]]
-        return [ref_points, rest_points, rest_mask, T.nonzero(rest_mask)[0]]
-
-    def input_parameters_list(self):
-        """
-        Create a list with the symbolic variables to use when we compile the theano function
-
-        Returns:
-            list: [self.dips_position_all, self.dip_angles_all, self.azimuth_all, self.polarity_all,
-                   self.ref_layer_points_all, self.rest_layer_points_all]
-        """
-        ipl = [self.dips_position_all, self.dip_angles_all, self.azimuth_all, self.polarity_all, self.surface_points]
-               #self.ref_layer_points_all, self.rest_layer_points_all]
-        return ipl
-
-    @staticmethod
-    def squared_euclidean_distances(x_1, x_2):
-        """
-        Compute the euclidian distances in 3D between all the points in x_1 and x_2
-
-        Args:
-            x_1 (theano.tensor.matrix): shape n_points x number dimension
-            x_2 (theano.tensor.matrix): shape n_points x number dimension
-
-        Returns:
-            theano.tensor.matrix: Distancse matrix. shape n_points x n_points
-        """
-
-        # T.maximum avoid negative numbers increasing stability
-        sqd = T.sqrt(T.maximum(
-            (x_1**2).sum(1).reshape((x_1.shape[0], 1)) +
-            (x_2**2).sum(1).reshape((1, x_2.shape[0])) -
-            2 * x_1.dot(x_2.T), 1e-12
-        ))
-
-        if False:
-            sqd = theano.printing.Print('sed')(sqd)
-
-        return sqd
-
-    def matrices_shapes(self):
-        """
-        Get all the lengths of the matrices that form the covariance matrix
-
-        Returns:
-             length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C
-        """
-
-        # Calculating the dimensions of the
-        length_of_CG = self.dips_position_tiled.shape[0]
-        length_of_CGI = self.rest_layer_points.shape[0]
-        length_of_U_I = self.n_universal_eq_T_op
-
-        # Self fault matrix contains the block and the potential field (I am not able to split them). Therefore we need
-        # to divide it by 2
-        length_of_faults = T.cast(self.fault_matrix.shape[0], 'int32')
-        length_of_C = length_of_CG + length_of_CGI + length_of_U_I + length_of_faults
-
-        if 'matrices_shapes' in self.verbose:
-            length_of_CG = theano.printing.Print("length_of_CG")(length_of_CG)
-            length_of_CGI = theano.printing.Print("length_of_CGI")(length_of_CGI)
-            length_of_U_I = theano.printing.Print("length_of_U_I")(length_of_U_I)
-            length_of_faults = theano.printing.Print("length_of_faults")(length_of_faults)
-            length_of_C = theano.printing.Print("length_of_C")(length_of_C)
-
-        return length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C
-
-    def cov_surface_points(self):
-        """
-        Create covariance function for the surface_points
-
-        Returns:
-            theano.tensor.matrix: covariance of the surface_points. Shape number of points in rest x number of
-            points in rest
-
-        """
-
-        # Compute euclidian distances
-        sed_rest_rest = self.squared_euclidean_distances(self.rest_layer_points, self.rest_layer_points)
-        sed_ref_rest = self.squared_euclidean_distances(self.ref_layer_points, self.rest_layer_points)
-        sed_rest_ref = self.squared_euclidean_distances(self.rest_layer_points, self.ref_layer_points)
-        sed_ref_ref = self.squared_euclidean_distances(self.ref_layer_points, self.ref_layer_points)
-
-        # Covariance matrix for surface_points
-        C_I = (self.c_o_T * self.i_reescale * (
-            (sed_rest_rest < self.a_T) *  # Rest - Rest Covariances Matrix
-            (1 - 7 * (sed_rest_rest / self.a_T) ** 2 +
-             35 / 4 * (sed_rest_rest / self.a_T) ** 3 -
-             7 / 2 * (sed_rest_rest / self.a_T) ** 5 +
-             3 / 4 * (sed_rest_rest / self.a_T) ** 7) -
-            ((sed_ref_rest < self.a_T) *  # Reference - Rest
-             (1 - 7 * (sed_ref_rest / self.a_T) ** 2 +
-              35 / 4 * (sed_ref_rest / self.a_T) ** 3 -
-              7 / 2 * (sed_ref_rest / self.a_T) ** 5 +
-              3 / 4 * (sed_ref_rest / self.a_T) ** 7)) -
-            ((sed_rest_ref < self.a_T) *  # Rest - Reference
-             (1 - 7 * (sed_rest_ref / self.a_T) ** 2 +
-              35 / 4 * (sed_rest_ref / self.a_T) ** 3 -
-              7 / 2 * (sed_rest_ref / self.a_T) ** 5 +
-              3 / 4 * (sed_rest_ref / self.a_T) ** 7)) +
-            ((sed_ref_ref < self.a_T) *  # Reference - References
-             (1 - 7 * (sed_ref_ref / self.a_T) ** 2 +
-              35 / 4 * (sed_ref_ref / self.a_T) ** 3 -
-              7 / 2 * (sed_ref_ref / self.a_T) ** 5 +
-              3 / 4 * (sed_ref_ref / self.a_T) ** 7))))
-
-        C_I += T.eye(C_I.shape[0]) * 2 * self.nugget_effect_scalar_T
-        # Add name to the theano node
-        C_I.name = 'Covariance SurfacePoints'
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            C_I = theano.printing.Print('Cov surface_points')(C_I)
-
-        return C_I
-
-    def cov_gradients(self, verbose=0):
-        """
-         Create covariance function for the gradients
-
-         Returns:
-             theano.tensor.matrix: covariance of the gradients. Shape number of points in dip_pos x number of
-             points in dip_pos
-
-         """
-
-        # Euclidean distances
-        sed_dips_dips = self.squared_euclidean_distances(self.dips_position_tiled, self.dips_position_tiled)
-
-        if 'sed_dips_dips' in self.verbose:
-            sed_dips_dips = theano.printing.Print('sed_dips_dips')(sed_dips_dips)
-
-        # Cartesian distances between dips positions
-        h_u = T.vertical_stack(
-            T.tile(self.dips_position[:, 0] - self.dips_position[:, 0].reshape((self.dips_position[:, 0].shape[0], 1)),
-                   self.n_dimensions),
-            T.tile(self.dips_position[:, 1] - self.dips_position[:, 1].reshape((self.dips_position[:, 1].shape[0], 1)),
-                   self.n_dimensions),
-            T.tile(self.dips_position[:, 2] - self.dips_position[:, 2].reshape((self.dips_position[:, 2].shape[0], 1)),
-                   self.n_dimensions))
-
-        # Transpose
-        h_v = h_u.T
-
-        # Perpendicularity matrix. Boolean matrix to separate cross-covariance and
-        # every gradient direction covariance (block diagonal)
-        perpendicularity_matrix = T.zeros_like(sed_dips_dips)
-
-        # Cross-covariances of x
-        perpendicularity_matrix = T.set_subtensor(
-            perpendicularity_matrix[0:self.dips_position.shape[0], 0:self.dips_position.shape[0]], 1)
-
-        # Cross-covariances of y
-        perpendicularity_matrix = T.set_subtensor(
-            perpendicularity_matrix[self.dips_position.shape[0]:self.dips_position.shape[0] * 2,
-            self.dips_position.shape[0]:self.dips_position.shape[0] * 2], 1)
-
-        # Cross-covariances of z
-        perpendicularity_matrix = T.set_subtensor(
-            perpendicularity_matrix[self.dips_position.shape[0] * 2:self.dips_position.shape[0] * 3,
-            self.dips_position.shape[0] * 2:self.dips_position.shape[0] * 3], 1)
-
-        # Covariance matrix for gradients at every xyz direction and their cross-covariances
-        C_G = T.switch(
-            T.eq(sed_dips_dips, 0),  # This is the condition
-            0,  # If true it is equal to 0. This is how a direction affect another
-            (  # else, following Chiles book
-                (h_u * h_v / sed_dips_dips ** 2) *
-                ((
-                     (sed_dips_dips < self.a_T) *  # first derivative
-                     (-self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_dips / self.a_T ** 3 -
-                                     35 / 2 * sed_dips_dips ** 3 / self.a_T ** 5 +
-                                     21 / 4 * sed_dips_dips ** 5 / self.a_T ** 7))) +
-                 (sed_dips_dips < self.a_T) *  # Second derivative
-                 self.c_o_T * 7 * (9 * sed_dips_dips ** 5 - 20 * self.a_T ** 2 * sed_dips_dips ** 3 +
-                                   15 * self.a_T ** 4 * sed_dips_dips - 4 * self.a_T ** 5) / (2 * self.a_T ** 7)) -
-                (perpendicularity_matrix *
-                 (sed_dips_dips < self.a_T) *  # first derivative
-                 self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_dips / self.a_T ** 3 -
-                               35 / 2 * sed_dips_dips ** 3 / self.a_T ** 5 +
-                               21 / 4 * sed_dips_dips ** 5 / self.a_T ** 7)))
-        )
-
-        # Setting nugget effect of the gradients
-        # TODO: This function can be substitued by simply adding the nugget effect to the diag if I remove the condition
-        C_G += T.eye(C_G.shape[0])*self.nugget_effect_grad_T
-
-        # Add name to the theano node
-        C_G.name = 'Covariance Gradient'
-
-        if verbose > 1:
-            theano.printing.pydotprint(C_G, outfile="graphs/" + sys._getframe().f_code.co_name + ".png",
-                                       var_with_name_simple=True)
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            C_G = theano.printing.Print('Cov Gradients')(C_G)
-
-        return C_G
-
-    def cov_interface_gradients(self):
-        """
-        Create covariance function for the gradiens
-        Returns:
-            theano.tensor.matrix: covariance of the gradients. Shape number of points in rest x number of
-              points in dip_pos
-        """
-
-        # Euclidian distances
-        sed_dips_rest = self.squared_euclidean_distances(self.dips_position_tiled, self.rest_layer_points)
-        sed_dips_ref  = self.squared_euclidean_distances(self.dips_position_tiled, self.ref_layer_points)
-
-        # Cartesian distances between dips and interface points
-        # Rest
-        hu_rest = T.vertical_stack(
-            (self.dips_position[:, 0] - self.rest_layer_points[:, 0].reshape(
-                (self.rest_layer_points[:, 0].shape[0], 1))).T,
-            (self.dips_position[:, 1] - self.rest_layer_points[:, 1].reshape(
-                (self.rest_layer_points[:, 1].shape[0], 1))).T,
-            (self.dips_position[:, 2] - self.rest_layer_points[:, 2].reshape(
-                (self.rest_layer_points[:, 2].shape[0], 1))).T
-        )
-
-        # Reference point
-        hu_ref = T.vertical_stack(
-            (self.dips_position[:, 0] - self.ref_layer_points[:, 0].reshape(
-                (self.ref_layer_points[:, 0].shape[0], 1))).T,
-            (self.dips_position[:, 1] - self.ref_layer_points[:, 1].reshape(
-                (self.ref_layer_points[:, 1].shape[0], 1))).T,
-            (self.dips_position[:, 2] - self.ref_layer_points[:, 2].reshape(
-                (self.ref_layer_points[:, 2].shape[0], 1))).T
-        )
-
-        # Cross-Covariance gradients-surface_points
-        C_GI = self.gi_reescale * (
-            (hu_rest *
-             (sed_dips_rest < self.a_T) *  # first derivative
-             (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_rest / self.a_T ** 3 -
-                              35 / 2 * sed_dips_rest ** 3 / self.a_T ** 5 +
-                              21 / 4 * sed_dips_rest ** 5 / self.a_T ** 7))) -
-            (hu_ref *
-             (sed_dips_ref < self.a_T) *  # first derivative
-             (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_ref / self.a_T ** 3 -
-                              35 / 2 * sed_dips_ref ** 3 / self.a_T ** 5 +
-                              21 / 4 * sed_dips_ref ** 5 / self.a_T ** 7)))
-        ).T
-
-        # Add name to the theano node
-        C_GI.name = 'Covariance gradient interface'
-
-        if str(sys._getframe().f_code.co_name)+'_g' in self.verbose:
-            theano.printing.pydotprint(C_GI, outfile="graphs/" + sys._getframe().f_code.co_name + ".png",
-                                       var_with_name_simple=True)
-        return C_GI
-
-    def universal_matrix(self):
-        """
-        Create the drift matrices for the potential field and its gradient
-
-        Returns:
-            theano.tensor.matrix: Drift matrix for the surface_points. Shape number of points in rest x 3**degree drift
-            (except degree 0 that is 0)
-
-            theano.tensor.matrix: Drift matrix for the gradients. Shape number of points in dips x 3**degree drift
-            (except degree 0 that is 0)
-        """
-
-        # Condition of universality 2 degree
-        # Gradients
-
-        n = self.dips_position.shape[0]
-        U_G = T.zeros((n * self.n_dimensions, 3 * self.n_dimensions))
-        # x
-        U_G = T.set_subtensor(U_G[:n, 0], 1)
-        # y
-        U_G = T.set_subtensor(U_G[n * 1:n * 2, 1], 1)
-        # z
-        U_G = T.set_subtensor(U_G[n * 2: n * 3, 2], 1)
-        # x**2
-        U_G = T.set_subtensor(U_G[:n, 3], 2 * self.gi_reescale * self.dips_position[:, 0])
-        # y**2
-        U_G = T.set_subtensor(U_G[n * 1:n * 2, 4], 2 * self.gi_reescale * self.dips_position[:, 1])
-        # z**2
-        U_G = T.set_subtensor(U_G[n * 2: n * 3, 5], 2 * self.gi_reescale * self.dips_position[:, 2])
-        # xy
-        U_G = T.set_subtensor(U_G[:n, 6], self.gi_reescale * self.dips_position[:, 1])  # This is y
-        U_G = T.set_subtensor(U_G[n * 1:n * 2, 6], self.gi_reescale * self.dips_position[:, 0])  # This is x
-        # xz
-        U_G = T.set_subtensor(U_G[:n, 7], self.gi_reescale * self.dips_position[:, 2])  # This is z
-        U_G = T.set_subtensor(U_G[n * 2: n * 3, 7], self.gi_reescale * self.dips_position[:, 0])  # This is x
-        # yz
-        U_G = T.set_subtensor(U_G[n * 1:n * 2, 8], self.gi_reescale * self.dips_position[:, 2])  # This is z
-        U_G = T.set_subtensor(U_G[n * 2:n * 3, 8], self.gi_reescale * self.dips_position[:, 1])  # This is y
-
-        # Interface
-        U_I = - T.stack(
-            (self.gi_reescale * (self.rest_layer_points[:, 0] - self.ref_layer_points[:, 0]),
-             self.gi_reescale * (self.rest_layer_points[:, 1] - self.ref_layer_points[:, 1]),
-             self.gi_reescale * (self.rest_layer_points[:, 2] - self.ref_layer_points[:, 2]),
-             self.gi_reescale ** 2 * (self.rest_layer_points[:, 0] ** 2 - self.ref_layer_points[:, 0] ** 2),
-             self.gi_reescale ** 2 * (self.rest_layer_points[:, 1] ** 2 - self.ref_layer_points[:, 1] ** 2),
-             self.gi_reescale ** 2 * (self.rest_layer_points[:, 2] ** 2 - self.ref_layer_points[:, 2] ** 2),
-             self.gi_reescale ** 2 * (
-                 self.rest_layer_points[:, 0] * self.rest_layer_points[:, 1] - self.ref_layer_points[:, 0] *
-                 self.ref_layer_points[:, 1]),
-             self.gi_reescale ** 2 * (
-                 self.rest_layer_points[:, 0] * self.rest_layer_points[:, 2] - self.ref_layer_points[:, 0] *
-                 self.ref_layer_points[:, 2]),
-             self.gi_reescale ** 2 * (
-                 self.rest_layer_points[:, 1] * self.rest_layer_points[:, 2] - self.ref_layer_points[:, 1] *
-                 self.ref_layer_points[:, 2]),
-             )).T
-
-        if 'U_I' in self.verbose:
-            U_I = theano.printing.Print('U_I')(U_I)
-
-        if 'U_G' in self.verbose:
-            U_G = theano.printing.Print('U_G')(U_G)
-
-        if str(sys._getframe().f_code.co_name)+'_g' in self.verbose:
-            theano.printing.pydotprint(U_I, outfile="graphs/" + sys._getframe().f_code.co_name + "_i.png",
-                                       var_with_name_simple=True)
-
-            theano.printing.pydotprint(U_G, outfile="graphs/" + sys._getframe().f_code.co_name + "_g.png",
-                                       var_with_name_simple=True)
-
-        # Add name to the theano node
-        if U_I:
-            U_I.name = 'Drift surface_points'
-            U_G.name = 'Drift foliations'
-
-        return U_I[:, :self.n_universal_eq_T_op], U_G[:, :self.n_universal_eq_T_op]
-
-    def faults_matrix(self):
-        """
-        This function creates the part of the graph that generates the df function creating a "block model" at the
-        references and the rest of the points. Then this vector has to be appended to the covariance function
-
-        Returns:
-
-            list:
-
-            - theano.tensor.matrix: Drift matrix for the surface_points. Shape number of points in rest x n df. This drif
-              is a simple addition of an arbitrary number
-
-            - theano.tensor.matrix: Drift matrix for the gradients. Shape number of points in dips x n df. For
-              discrete values this matrix will be null since the derivative of a constant is 0
-        """
-
-        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults = self.matrices_shapes()[:4]
-
-        # self.fault_matrix contains the df volume of the grid and the rest and ref points. For the drift we need
-        # to make it relative to the reference point
-        if 'fault matrix' in self.verbose:
-            self.fault_matrix = theano.printing.Print('self.fault_matrix')(self.fault_matrix)
-        interface_loc = self.fault_matrix.shape[1] - 2 * self.len_points
-
-        fault_matrix_at_surface_points_rest = self.fault_matrix[:,
-                                          interface_loc + self.len_i_0: interface_loc + self.len_i_1]
-        fault_matrix_at_surface_points_ref = self.fault_matrix[:,
-                                         interface_loc + self.len_points + self.len_i_0: interface_loc + self.len_points + self.len_i_1]
-
-        F_I = (fault_matrix_at_surface_points_ref - fault_matrix_at_surface_points_rest)+0.0001
-
-        # As long as the drift is a constant F_G is null
-        F_G = T.zeros((length_of_faults, length_of_CG)) + 0.0001
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            F_I = theano.printing.Print('Faults surface_points matrix')(F_I)
-            F_G = theano.printing.Print('Faults gradients matrix')(F_G)
-
-        return F_I, F_G
-
-    def covariance_matrix(self):
-        """
-        Set all the previous covariances together in the universal cokriging matrix
-
-        Returns:
-            theano.tensor.matrix: Multivariate covariance
-        """
-
-        # Lengths
-        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C = self.matrices_shapes()
-
-        # Individual matrices
-        C_G = self.cov_gradients()
-        C_I = self.cov_surface_points()
-        C_GI = self.cov_interface_gradients()
-        U_I, U_G = self.universal_matrix()
-        F_I, F_G = self.faults_matrix()
-
-        # =================================
-        # Creation of the Covariance Matrix
-        # =================================
-        C_matrix = T.zeros((length_of_C, length_of_C))
-
-        # First row of matrices
-        # Set C_G
-        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG, 0:length_of_CG], C_G)
-        # Set CGI
-        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG, length_of_CG:length_of_CG + length_of_CGI], C_GI.T)
-        # Set UG
-        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG,
-                                   length_of_CG+length_of_CGI:length_of_CG+length_of_CGI+length_of_U_I], U_G)
-        # Set FG. I cannot use -index because when is -0 is equivalent to 0
-        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG, length_of_CG+length_of_CGI+length_of_U_I:], F_G.T)
-        # Second row of matrices
-        # Set C_IG
-        C_matrix = T.set_subtensor(C_matrix[length_of_CG:length_of_CG + length_of_CGI, 0:length_of_CG], C_GI)
-        # Set C_I
-        C_matrix = T.set_subtensor(C_matrix[length_of_CG:length_of_CG + length_of_CGI,
-                                   length_of_CG:length_of_CG + length_of_CGI], C_I)
-        # Set U_I
-        #if not self.u_grade_T.get_value() == 0:
-        C_matrix = T.set_subtensor(C_matrix[length_of_CG:length_of_CG + length_of_CGI,
-                                   length_of_CG+length_of_CGI:length_of_CG+length_of_CGI+length_of_U_I], U_I)
-        # Set F_I
-        C_matrix = T.set_subtensor(C_matrix[length_of_CG:length_of_CG + length_of_CGI, length_of_CG+length_of_CGI+length_of_U_I:], F_I.T)
-        # Third row of matrices
-        # Set U_G
-        C_matrix = T.set_subtensor(C_matrix[length_of_CG+length_of_CGI:length_of_CG+length_of_CGI+length_of_U_I, 0:length_of_CG], U_G.T)
-        # Set U_I
-        C_matrix = T.set_subtensor(C_matrix[length_of_CG+length_of_CGI:length_of_CG+length_of_CGI+length_of_U_I, length_of_CG:length_of_CG + length_of_CGI], U_I.T)
-        # Fourth row of matrices
-        # Set F_G
-        C_matrix = T.set_subtensor(C_matrix[length_of_CG+length_of_CGI+length_of_U_I:, 0:length_of_CG], F_G)
-        # Set F_I
-        C_matrix = T.set_subtensor(C_matrix[length_of_CG+length_of_CGI+length_of_U_I:, length_of_CG:length_of_CG + length_of_CGI], F_I)
-        # Add name to the theano node
-        C_matrix.name = 'Block Covariance Matrix'
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            C_matrix = theano.printing.Print('cov_function')(C_matrix)
-
-        return C_matrix
-
-    def b_vector(self):
-        """
-        Creation of the independent vector b to solve the kriging system
-
-        Args:
-            verbose: -deprecated-
-
-        Returns:
-            theano.tensor.vector: independent vector
-        """
-
-        length_of_C = self.matrices_shapes()[-1]
-        # =====================
-        # Creation of the gradients G vector
-        # Calculation of the cartesian components of the dips assuming the unit module
-        G_x = T.sin(T.deg2rad(self.dip_angles)) * T.sin(T.deg2rad(self.azimuth)) * self.polarity
-        G_y = T.sin(T.deg2rad(self.dip_angles)) * T.cos(T.deg2rad(self.azimuth)) * self.polarity
-        G_z = T.cos(T.deg2rad(self.dip_angles)) * self.polarity
-
-        G = T.concatenate((G_x, G_y, G_z))
-
-        # Creation of the Dual Kriging vector
-        b = T.zeros((length_of_C,))
-        b = T.set_subtensor(b[0:G.shape[0]], G)
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            b = theano.printing.Print('b vector')(b)
-
-        # Add name to the theano node
-        b.name = 'b vector'
-        return b
-
-    def solve_kriging(self):
-        """
-        Solve the kriging system. This has to get substituted by a more efficient and stable method QR
-        decomposition in all likelihood
-
-        Returns:
-            theano.tensor.vector: Dual kriging parameters
-
-        """
-        C_matrix = self.covariance_matrix()
-        b = self.b_vector()
-        # Solving the kriging system
-        import theano.tensor.slinalg
-        b2 = T.tile(b, (1, 1)).T
-        DK_parameters = theano.tensor.slinalg.solve(C_matrix, b2)
-        DK_parameters = DK_parameters.reshape((DK_parameters.shape[0],))
-
-        # Add name to the theano node
-        DK_parameters.name = 'Dual Kriging parameters'
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            DK_parameters = theano.printing.Print(DK_parameters.name)(DK_parameters)
-        return DK_parameters
-
-    def x_to_interpolate(self, verbose=0):
-        """
-        here I add to the grid points also the references points(to check the value of the potential field at the
-        surface_points). Also here I will check what parts of the grid have been already computed in a previous series
-        to avoid to recompute.
-
-        Returns:
-            theano.tensor.matrix: The 3D points of the given grid plus the reference and rest points
-        """
-
-        grid_val = T.concatenate([self.grid_val_T, self.rest_layer_points_all,
-                                  self.ref_layer_points_all])[self.yet_simulated, :]
-
-        if verbose > 1:
-            theano.printing.pydotprint(grid_val, outfile="graphs/" + sys._getframe().f_code.co_name + ".png",
-                                       var_with_name_simple=True)
-
-        if 'grid_val' in self.verbose:
-            grid_val = theano.printing.Print('Points to interpolate')(grid_val)
-
-        return grid_val
-
-    def extend_dual_kriging(self):
-        """
-        Tile the dual kriging vector to cover all the points to interpolate.So far I just make a matrix with the
-        dimensions len(DK)x(grid) but in the future maybe I have to try to loop all this part so consume less memory
-
-        Returns:
-            theano.tensor.matrix: Matrix with the Dk parameters repeated for all the points to interpolate
-        """
-
-        grid_val = self.x_to_interpolate()
-        if self.weights.get_value() is None:
-            DK_parameters = self.solve_kriging()
-        else:
-            DK_parameters = self.weights
-        # Creation of a matrix of dimensions equal to the grid with the weights for every point (big 4D matrix in
-        # ravel form)
-        # TODO IMP: Change the tile by a simple dot op -> The DOT version in gpu is slower
-        DK_weights = T.tile(DK_parameters, (grid_val.shape[0], 1)).T
-
-        if self.dot_version:
-            DK_weights = DK_parameters
-
-        return DK_weights
-
-    def contribution_gradient_interface(self, grid_val=None, weights=None):
-        """
-        Computation of the contribution of the foliations at every point to interpolate
-
-        Returns:
-            theano.tensor.vector: Contribution of all foliations (input) at every point to interpolate
-        """
-        if weights is None:
-            weights = self.extend_dual_kriging()
-        if grid_val is None:
-            grid_val = self.x_to_interpolate()
-
-        length_of_CG = self.matrices_shapes()[0]
-
-        # Cartesian distances between the point to simulate and the dips
-        hu_SimPoint = T.vertical_stack(
-            (self.dips_position[:, 0] - grid_val[:, 0].reshape((grid_val[:, 0].shape[0], 1))).T,
-            (self.dips_position[:, 1] - grid_val[:, 1].reshape((grid_val[:, 1].shape[0], 1))).T,
-            (self.dips_position[:, 2] - grid_val[:, 2].reshape((grid_val[:, 2].shape[0], 1))).T
-        )
-
-        # Euclidian distances
-        sed_dips_SimPoint = self.squared_euclidean_distances(self.dips_position_tiled, grid_val)
-        # Gradient contribution
-        sigma_0_grad = T.sum(
-            (weights[:length_of_CG] *
-             self.gi_reescale *
-             (-hu_SimPoint *
-              (sed_dips_SimPoint < self.a_T) *  # first derivative
-              (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_SimPoint / self.a_T ** 3 -
-                               35 / 2 * sed_dips_SimPoint ** 3 / self.a_T ** 5 +
-                               21 / 4 * sed_dips_SimPoint ** 5 / self.a_T ** 7)))),
-            axis=0)
-
-        if self.dot_version:
-            sigma_0_grad = T.dot(
-                weights[:length_of_CG] ,
-                 self.gi_reescale *
-                 (-hu_SimPoint *
-                  (sed_dips_SimPoint < self.a_T) *  # first derivative
-                  (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_SimPoint / self.a_T ** 3 -
-                                   35 / 2 * sed_dips_SimPoint ** 3 / self.a_T ** 5 +
-                                   21 / 4 * sed_dips_SimPoint ** 5 / self.a_T ** 7))))
-
-        # Add name to the theano node
-        sigma_0_grad.name = 'Contribution of the foliations to the potential field at every point of the grid'
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            sigma_0_grad = theano.printing.Print('interface_gradient_contribution')(sigma_0_grad)
-
-        return sigma_0_grad
-
-    def contribution_interface_gradient(self, direction='x', grid_val=None, weights=None):
-        """
-        Computation of the contribution of the foliations at every point to interpolate
-
-        Returns:
-            theano.tensor.vector: Contribution of all foliations (input) at every point to interpolate
-        """
-
-        if direction == 'x':
-            dir_val = 0
-        elif direction == 'y':
-            dir_val = 1
-        elif direction == 'z':
-            dir_val = 2
-        else:
-            raise AttributeError('Directions muxt be x, y or z')
-
-        if weights is None:
-            weights = self.extend_dual_kriging()
-        if grid_val is None:
-            grid_val = self.x_to_interpolate()
-
-        length_of_CG, length_of_CGI = self.matrices_shapes()[:2]
-
-        # Cartesian distances between the point to simulate and the dips
-        hu_rest = (- self.rest_layer_points[:, dir_val] + grid_val[:, dir_val].reshape((grid_val[:, dir_val].shape[0], 1)))
-        hu_ref = (- self.ref_layer_points[:, dir_val] + grid_val[:, dir_val].reshape((grid_val[:, dir_val].shape[0], 1)))
-
-        # Euclidian distances
-
-        sed_grid_rest = self.squared_euclidean_distances(grid_val, self.rest_layer_points)
-        sed_grid_ref = self.squared_euclidean_distances(grid_val, self.ref_layer_points)
-
-        # Gradient contribution
-        self.gi_reescale = 2
-
-        sigma_0_grad = T.sum(
-            (weights[length_of_CG:length_of_CG + length_of_CGI] *
-             self.gi_reescale * (
-                 (hu_rest *
-                  (sed_grid_rest < self.a_T) *  # first derivative
-                  (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_grid_rest / self.a_T ** 3 -
-                                   35 / 2 * sed_grid_rest ** 3 / self.a_T ** 5 +
-                                   21 / 4 * sed_grid_rest ** 5 / self.a_T ** 7))) -
-            (hu_ref *
-             (sed_grid_ref < self.a_T) *  # first derivative
-             (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_grid_ref / self.a_T ** 3 -
-                              35 / 2 * sed_grid_ref ** 3 / self.a_T ** 5 +
-                              21 / 4 * sed_grid_ref ** 5 / self.a_T ** 7)))).T),
-            axis=0)
-
-        return sigma_0_grad
-
-    def contribution_interface(self, grid_val=None, weights=None):
-        """
-          Computation of the contribution of the surface_points at every point to interpolate
-
-          Returns:
-              theano.tensor.vector: Contribution of all surface_points (input) at every point to interpolate
-          """
-
-        if weights is None:
-            weights = self.extend_dual_kriging()
-        if grid_val is None:
-            grid_val = self.x_to_interpolate()
-        length_of_CG, length_of_CGI = self.matrices_shapes()[:2]
-
-        # Euclidian distances
-        sed_rest_SimPoint = self.squared_euclidean_distances(self.rest_layer_points, grid_val)
-        sed_ref_SimPoint = self.squared_euclidean_distances(self.ref_layer_points, grid_val)
-
-        # Interface contribution
-        sigma_0_interf = (T.sum(
-            -weights[length_of_CG:length_of_CG + length_of_CGI, :] *
-            (self.c_o_T * self.i_reescale * (
-                    (sed_rest_SimPoint < self.a_T) *  # SimPoint - Rest Covariances Matrix
-                    (1 - 7 * (sed_rest_SimPoint / self.a_T) ** 2 +
-                     35 / 4 * (sed_rest_SimPoint / self.a_T) ** 3 -
-                     7 / 2 * (sed_rest_SimPoint / self.a_T) ** 5 +
-                     3 / 4 * (sed_rest_SimPoint / self.a_T) ** 7) -
-                    ((sed_ref_SimPoint < self.a_T) *  # SimPoint- Ref
-                     (1 - 7 * (sed_ref_SimPoint / self.a_T) ** 2 +
-                      35 / 4 * (sed_ref_SimPoint / self.a_T) ** 3 -
-                      7 / 2 * (sed_ref_SimPoint / self.a_T) ** 5 +
-                      3 / 4 * (sed_ref_SimPoint / self.a_T) ** 7)))), axis=0))
-
-        if self.dot_version:
-            sigma_0_interf = (
-                T.dot(-weights[length_of_CG:length_of_CG + length_of_CGI],
-                      (self.c_o_T * self.i_reescale * (
-                              (sed_rest_SimPoint < self.a_T) *  # SimPoint - Rest Covariances Matrix
-                              (1 - 7 * (sed_rest_SimPoint / self.a_T) ** 2 +
-                               35 / 4 * (sed_rest_SimPoint / self.a_T) ** 3 -
-                               7 / 2 * (sed_rest_SimPoint / self.a_T) ** 5 +
-                               3 / 4 * (sed_rest_SimPoint / self.a_T) ** 7) -
-                              ((sed_ref_SimPoint < self.a_T) *  # SimPoint- Ref
-                               (1 - 7 * (sed_ref_SimPoint / self.a_T) ** 2 +
-                                35 / 4 * (sed_ref_SimPoint / self.a_T) ** 3 -
-                                7 / 2 * (sed_ref_SimPoint / self.a_T) ** 5 +
-                                3 / 4 * (sed_ref_SimPoint / self.a_T) ** 7))))))
-
-        # Add name to the theano node
-        sigma_0_interf.name = 'Contribution of the surface_points to the potential field at every point of the grid'
-
-        return sigma_0_interf
-
-    def contribution_gradient(self, direction='x', grid_val=None, weights=None):
-
-        if direction == 'x':
-           direction_val = 0
-        if direction == 'y':
-            direction_val = 1
-        if direction == 'z':
-            direction_val = 2
-        self.gi_reescale = theano.shared(1)
-
-
-        if weights is None:
-            weights = self.extend_dual_kriging()
-        if grid_val is None:
-            grid_val = self.x_to_interpolate()
-
-        length_of_CG = self.matrices_shapes()[0]
-
-        # Cartesian distances between the point to simulate and the dips
-        # TODO optimize to compute this only once?
-        # Euclidean distances
-        sed_dips_SimPoint = self.squared_euclidean_distances(grid_val, self.dips_position_tiled).T
-
-        if 'sed_dips_SimPoint' in self.verbose:
-            sed_dips_SimPoint = theano.printing.Print('sed_dips_SimPoint')(sed_dips_SimPoint)
-
-        # Cartesian distances between dips positions
-        h_u = T.tile(self.dips_position[:, direction_val] - grid_val[:, direction_val].reshape((grid_val[:, direction_val].shape[0], 1)), 3)
-        h_v = T.horizontal_stack(
-            T.tile(self.dips_position[:, 0] - grid_val[:, 0].reshape((grid_val[:, 0].shape[0], 1)),
-                   1),
-            T.tile(self.dips_position[:, 1] - grid_val[:, 1].reshape((grid_val[:, 1].shape[0], 1)),
-                   1),
-            T.tile(self.dips_position[:, 2] - grid_val[:, 2].reshape((grid_val[:, 2].shape[0], 1)),
-                   1))
-
-        perpendicularity_vector = T.zeros(T.stack(length_of_CG))
-        perpendicularity_vector = T.set_subtensor(
-            perpendicularity_vector[self.dips_position.shape[0]*direction_val:self.dips_position.shape[0]*(direction_val+1)], 1)
-
-        sigma_0_grad = T.sum(
-            (weights[:length_of_CG] * (
-             ((-h_u * h_v).T/ sed_dips_SimPoint ** 2) *
-             ((
-                      (sed_dips_SimPoint < self.a_T) *  # first derivative
-                      (-self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_SimPoint / self.a_T ** 3 -
-                                      35 / 2 * sed_dips_SimPoint ** 3 / self.a_T ** 5 +
-                                      21 / 4 * sed_dips_SimPoint ** 5 / self.a_T ** 7))) +
-              (sed_dips_SimPoint < self.a_T) *  # Second derivative
-              self.c_o_T * 7 * (9 * sed_dips_SimPoint ** 5 - 20 * self.a_T ** 2 * sed_dips_SimPoint ** 3 +
-                                   15 * self.a_T ** 4 * sed_dips_SimPoint - 4 * self.a_T ** 5) / (2 * self.a_T ** 7)) -
-                (perpendicularity_vector.reshape((-1, 1)) *
-                                ((sed_dips_SimPoint < self.a_T) *  # first derivative
-                 self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_SimPoint / self.a_T ** 3 -
-                               35 / 2 * sed_dips_SimPoint ** 3 / self.a_T ** 5 +
-                               21 / 4 * sed_dips_SimPoint ** 5 / self.a_T ** 7)))
-
-              ))
-        , axis=0)
-
-        return sigma_0_grad
-
-    def contribution_universal_drift(self, grid_val=None, weights=None, a=0, b=100000000):
-        """
-        Computation of the contribution of the universal drift at every point to interpolate
-
-        Returns:
-            theano.tensor.vector: Contribution of the universal drift (input) at every point to interpolate
-        """
-        if weights is None:
-            weights = self.extend_dual_kriging()
-        if grid_val is None:
-            grid_val = self.x_to_interpolate()
-
-        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C = self.matrices_shapes()
-
-        # Universal drift contribution
-        # universal_grid_surface_points_matrix = self.universal_grid_matrix_T[:, self.fault_mask[a: b]]
-
-        # Universal drift contribution
-        # Universal terms used to calculate f0
-        # Here I create the universal terms for rest and ref. The universal terms for the grid are done in python
-        # and append here. The idea is that the grid is kind of constant so I do not have to recompute it every
-        # time
-        # _universal_terms_surface_points_rest = T.horizontal_stack(
-        #     self.rest_layer_points_all,
-        #     (self.rest_layer_points_all ** 2),
-        #     T.stack((self.rest_layer_points_all[:, 0] * self.rest_layer_points_all[:, 1],
-        #              self.rest_layer_points_all[:, 0] * self.rest_layer_points_all[:, 2],
-        #              self.rest_layer_points_all[:, 1] * self.rest_layer_points_all[:, 2]), axis=1))
-        #
-        # _universal_terms_surface_points_ref = T.horizontal_stack(
-        #     self.ref_layer_points_all,
-        #     (self.ref_layer_points_all ** 2),
-        #     T.stack((self.ref_layer_points_all[:, 0] * self.ref_layer_points_all[:, 1],
-        #              self.ref_layer_points_all[:, 0] * self.ref_layer_points_all[:, 2],
-        #              self.ref_layer_points_all[:, 1] * self.ref_layer_points_all[:, 2]), axis=1),
-        # )
-        #
-        # # I append rest and ref to grid
-        # # universal_grid_surface_points_matrix = T.horizontal_stack(
-        # #     (self.universal_grid_matrix_T * self.fault_mask).nonzero_values().reshape((9, -1)),
-        # #     T.vertical_stack(_universal_terms_surface_points_rest, _universal_terms_surface_points_ref).T)
-        #
-        # universal_grid_surface_points_matrix = T.horizontal_stack(
-        #     self.universal_grid_matrix_T.reshape((9, -1)),
-        #     T.vertical_stack(_universal_terms_surface_points_rest, _universal_terms_surface_points_ref).T)
-
-        universal_grid_surface_points_matrix = T.horizontal_stack(
-             grid_val,
-            (grid_val ** 2),
-            T.stack((grid_val[:, 0] * grid_val[:, 1],
-                     grid_val[:, 0] * grid_val[:, 2],
-                     grid_val[:, 1] * grid_val[:, 2]), axis=1)).T
-
-
-        # These are the magic terms to get the same as geomodeller
-        i_rescale_aux = T.repeat(self.gi_reescale, 9)
-        i_rescale_aux = T.set_subtensor(i_rescale_aux[:3], 1)
-        _aux_magic_term = T.tile(i_rescale_aux[:self.n_universal_eq_T_op], (grid_val.shape[0], 1)).T
-
-        # Drif contribution
-        f_0 = (T.sum(
-            weights[length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I] * self.gi_reescale * _aux_magic_term *
-            universal_grid_surface_points_matrix[:self.n_universal_eq_T_op]
-            , axis=0))
-
-        if self.dot_version:
-            f_0 = T.dot(
-                weights[length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I] , self.gi_reescale * _aux_magic_term *
-                universal_grid_surface_points_matrix[:self.n_universal_eq_T_op])
-
-        if not type(f_0) == int:
-            f_0.name = 'Contribution of the universal drift to the potential field at every point of the grid'
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            f_0 = theano.printing.Print('Universal terms contribution')(f_0)
-
-        return f_0
-
-    def contribution_universal_drift_d(self, direction='x', grid_val=None, weights=None, a=0, b=100000000):
-        if weights is None:
-            weights = self.extend_dual_kriging()
-        if grid_val is None:
-            grid_val = self.x_to_interpolate()
-
-        self.gi_reescale = theano.shared(2)
-
-        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C = self.matrices_shapes()
-
-        # These are the magic terms to get the same as geomodeller
-        i_rescale_aux = T.repeat(self.gi_reescale, 9)
-        i_rescale_aux = T.set_subtensor(i_rescale_aux[:3], 1)
-        _aux_magic_term = T.tile(i_rescale_aux[:self.n_universal_eq_T_op], (grid_val.shape[0], 1))
-
-        n = self.dips_position.shape[0]
-        n = grid_val.shape[0]
-        U_G = T.zeros((n, 9))
-
-        if direction == 'x':
-
-            # x
-            U_G = T.set_subtensor(U_G[:, 0], 1)
-            # x**2
-            U_G = T.set_subtensor(U_G[:, 3], 2 * self.gi_reescale * grid_val[:, 0])
-
-            # xy
-            U_G = T.set_subtensor(U_G[:, 6], self.gi_reescale * grid_val[:, 1])  # This is y
-            # xz
-            U_G = T.set_subtensor(U_G[:, 7], self.gi_reescale * grid_val[:, 2])  # This is z
-
-        if direction == 'y':
-
-            # y
-            U_G = T.set_subtensor(U_G[:, 1], 1)
-            # y**2
-            U_G = T.set_subtensor(U_G[:, 4], 2 * self.gi_reescale * grid_val[:, 1])
-            # xy
-            U_G = T.set_subtensor(U_G[:, 6], self.gi_reescale * grid_val[:, 0])  # This is x
-            # yz
-            U_G = T.set_subtensor(U_G[:, 8], self.gi_reescale * grid_val[:, 2])  # This is z
-
-        if direction == 'z':
-            # z
-            U_G = T.set_subtensor(U_G[:, 2], 1)
-
-            # z**2
-            U_G = T.set_subtensor(U_G[:, 5], 2 * self.gi_reescale * grid_val[:, 2])
-
-            #xz
-            U_G = T.set_subtensor(U_G[:, 7], self.gi_reescale * grid_val[:, 0])  # This is x
-
-            # yz
-            U_G = T.set_subtensor(U_G[:, 8], self.gi_reescale * grid_val[:, 1])  # This is y
-
-        # Drif contribution
-        f_0 = (T.sum(
-            weights[
-            length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I] *
-            U_G.T[:self.n_universal_eq_T_op]
-            , axis=0))
-
-        return f_0
-
-    def faults_contribution(self, weights=None, a=0, b=100000000):
-        """
-        Computation of the contribution of the df drift at every point to interpolate. To get these we need to
-        compute a whole block model with the df data
-
-        Returns:
-            theano.tensor.vector: Contribution of the df drift (input) at every point to interpolate
-        """
-        if weights is None:
-            weights = self.extend_dual_kriging()
-        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C = self.matrices_shapes()
-
-        fault_matrix_selection_non_zero = (self.fault_matrix[:, self.yet_simulated[a:b]]+1)
-
-        f_1 = T.sum(
-            weights[length_of_CG + length_of_CGI + length_of_U_I:, :] * fault_matrix_selection_non_zero, axis=0)
-
-        if self.dot_version:
-            f_1 = T.dot(
-                weights[length_of_CG + length_of_CGI + length_of_U_I:], fault_matrix_selection_non_zero)
-
-        # Add name to the theano node
-        f_1.name = 'Faults contribution'
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            f_1 = theano.printing.Print('Faults contribution')(f_1)
-
-        return f_1
-
-    def scalar_field_loop(self, a, b, Z_x, grid_val, weights, val):
-
-        sigma_0_grad = self.contribution_gradient_interface(grid_val[a:b], weights[:, a:b])
-        sigma_0_interf = self.contribution_interface(grid_val[a:b], weights[:, a:b])
-        f_0 = self.contribution_universal_drift(grid_val[a:b], weights[:, a:b], a, b)
-        f_1 = self.faults_contribution(weights[:, a:b], a, b)
-
-        # Add an arbitrary number at the potential field to get unique values for each of them
-        partial_Z_x = (sigma_0_grad + sigma_0_interf + f_0 + f_1 + 50 - (10 * val[0]))
-        Z_x = T.set_subtensor(Z_x[a:b], partial_Z_x)
-
-        return Z_x
-
-    def gradient_field_loop_x(self, a, b, Z_x, grid_val, weights, val):
-        direction = 'x'
-        sigma_0_grad = self.contribution_gradient(direction, grid_val[a:b], weights[:, a:b])
-        sigma_0_interf_gradient = self.contribution_interface_gradient(direction, grid_val[a:b], weights[:, a:b])
-        f_0 = self.contribution_universal_drift_d(direction, grid_val[a:b], weights[:, a:b], a, b)
-        #f_1 = self.faults_contribution(weights[:, a:b], a, b)
-
-        # Add an arbitrary number at the potential field to get unique values for each of them
-        partial_Z_x = (sigma_0_grad + sigma_0_interf_gradient + f_0)
-
-        Z_x = T.set_subtensor(Z_x[a:b], partial_Z_x)
-
-        return Z_x
-
-    def gradient_field_loop_y(self, a, b, Z_x, grid_val, weights, val):
-        direction = 'y'
-        sigma_0_grad = self.contribution_gradient(direction, grid_val[a:b], weights[:, a:b])
-        sigma_0_interf_gradient = self.contribution_interface_gradient(direction, grid_val[a:b], weights[:, a:b])
-        f_0 = self.contribution_universal_drift_d(direction, grid_val[a:b], weights[:, a:b], a, b)
-        #f_1 = self.faults_contribution(weights[:, a:b], a, b)
-
-        # Add an arbitrary number at the potential field to get unique values for each of them
-        partial_Z_x = (sigma_0_grad + sigma_0_interf_gradient + f_0)
-
-        Z_x = T.set_subtensor(Z_x[a:b], partial_Z_x)
-
-        return Z_x
-
-    def gradient_field_loop_z(self, a, b, Z_x, grid_val, weights, val):
-        direction = 'z'
-        sigma_0_grad = self.contribution_gradient(direction, grid_val[a:b], weights[:, a:b])
-        sigma_0_interf_gradient = self.contribution_interface_gradient(direction, grid_val[a:b], weights[:, a:b])
-        f_0 = self.contribution_universal_drift_d(direction, grid_val[a:b], weights[:, a:b], a, b)
-        #f_1 = self.faults_contribution(weights[:, a:b], a, b)
-
-        # Add an arbitrary number at the potential field to get unique values for each of them
-        partial_Z_x = (sigma_0_grad + sigma_0_interf_gradient + f_0)
-
-        Z_x = T.set_subtensor(Z_x[a:b], partial_Z_x)
-
-        return Z_x
-
-    def scalar_field_at_all(self, weights=None):
-        """
-        Compute the potential field at all the interpolation points, i.e. grid plus rest plus ref
-        Returns:
-            theano.tensor.vector: Potential fields at all points
-
-        """
-        grid_val = self.x_to_interpolate()
-
-        if weights is None:
-            weights = self.extend_dual_kriging()
-
-        grid_shape = T.stack(grid_val.shape[0])
-        Z_x_init = T.zeros(grid_shape, dtype='float32')
-        if 'grid_shape' in self.verbose:
-            grid_shape = theano.printing.Print('grid_shape')(grid_shape)
-
-        steps = 1e13/self.matrices_shapes()[-1]/grid_shape
-        slices = T.concatenate((T.arange(0, grid_shape[0], steps[0], dtype='int64'), grid_shape))
-
-        if 'slices' in self.verbose:
-            slices = theano.printing.Print('slices')(slices)
-
-        Z_x_loop, updates3 = theano.scan(
-            fn=self.scalar_field_loop,
-            outputs_info=[Z_x_init],
-            sequences=[dict(input=slices, taps=[0, 1])],
-            non_sequences=[grid_val, weights, self.n_surface_op],
-            profile=False,
-            name='Looping grid',
-            return_list=True)
-
-        Z_x = Z_x_loop[-1][-1]
-        Z_x.name = 'Value of the potential field at every point'
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            Z_x = theano.printing.Print('Potential field at all points')(Z_x)
-
-        return Z_x
-
-    def gradient_field_at_all(self, weights=None, gradients=[]):
-
-        grid_val = self.x_to_interpolate()
-        if weights is None:
-            weights = self.extend_dual_kriging()
-
-        grid_shape = T.stack(grid_val.shape[0])
-
-        Z_x_init = T.zeros(grid_shape, dtype='float32')
-        if 'grid_shape' in self.verbose:
-            grid_shape = theano.printing.Print('grid_shape')(grid_shape)
-
-        steps = 1e13 / self.matrices_shapes()[-1] / grid_shape
-        slices = T.concatenate((T.arange(0, grid_shape[0], steps[0], dtype='int64'), grid_shape))
-
-        if 'slices' in self.verbose:
-            slices = theano.printing.Print('slices')(slices)
-
-        G_field = T.zeros((3, self.grid_val_T.shape[0]))
-
-        if 'Gx' in gradients:
-            Gx_loop, updates5 = theano.scan(
-                fn=self.gradient_field_loop_x,
-                outputs_info=[Z_x_init],
-                sequences=[dict(input=slices, taps=[0, 1])],
-                non_sequences=[grid_val, weights, self.n_surface_op],
-                profile=False,
-                name='Looping grid x',
-                return_list=True)
-
-            Gx = Gx_loop[-1][-1]
-            Gx.name = 'Value of the gradient field X at every point'
-            G_field = T.set_subtensor(G_field[0, :], Gx)
-
-        if 'Gy' in gradients:
-            Gy_loop, updates6 = theano.scan(
-                fn=self.gradient_field_loop_y,
-                outputs_info=[Z_x_init],
-                sequences=[dict(input=slices, taps=[0, 1])],
-                non_sequences=[grid_val, weights, self.n_surface_op],
-                profile=False,
-                name='Looping grid y',
-                return_list=True)
-
-            Gy = Gy_loop[-1][-1]
-            Gy.name = 'Value of the gradient field X at every point'
-            G_field = T.set_subtensor(G_field[1, :], Gy)
-
-        if 'Gz' in gradients:
-            Gz_loop, updates7 = theano.scan(
-                fn=self.gradient_field_loop_z,
-                outputs_info=[Z_x_init],
-                sequences=[dict(input=slices, taps=[0, 1])],
-                non_sequences=[grid_val, weights, self.n_surface_op],
-                profile=False,
-                name='Looping grid z',
-                return_list=True)
-
-            Gz = Gz_loop[-1][-1]
-            Gz.name = 'Value of the gradient field X at every point'
-            G_field = T.set_subtensor(G_field[2, :], Gz)
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            Z_x = theano.printing.Print('Potential field at all points')(Z_x)
-
-        return G_field
-
-    def compare(self, a, b, slice_init, Z_x, l, n_surface, drift):
-        """
-        Treshold of the points to interpolate given 2 potential field values. TODO: This function is the one we
-        need to change for a sigmoid function
-
-        Args:
-            a (scalar): Upper limit of the potential field
-            b (scalar): Lower limit of the potential field
-            n_surface (scalar): Value given to the segmentation, i.e. lithology number
-            Zx (vector): Potential field values at all the interpolated points
-
-        Returns:
-            theano.tensor.vector: segmented values
-        """
-
-        if True:
-
-            slice_init = slice_init
-            n_surface_0 = n_surface[:, slice_init:slice_init + 1]
-            n_surface_1 = n_surface[:, slice_init + 1:slice_init + 2]
-            drift = drift[:, slice_init:slice_init + 1]
-
-            if 'compare' in self.verbose:
-                a = theano.printing.Print("a")(a)
-                b = theano.printing.Print("b")(b)
-                # l = 200/ (a - b)
-                slice_init = theano.printing.Print("slice_init")(slice_init)
-                n_surface_0 = theano.printing.Print("n_surface_0")(n_surface_0)
-                n_surface_1 = theano.printing.Print("n_surface_1")(n_surface_1)
-                drift = theano.printing.Print("drift[slice_init:slice_init+1][0]")(drift)
-
-            # drift = T.switch(slice_init == 0, n_surface_1, n_surface_0)
-            #    drift = T.set_subtensor(n_surface[0], n_surface[1])
-
-            # The 5 rules the slope of the function
-            sigm = (-n_surface_0.reshape((-1, 1)) / (1 + T.exp(-l * (Z_x - a)))) - \
-                   (n_surface_1.reshape((-1, 1)) / (1 + T.exp(l * (Z_x - b)))) + drift.reshape((-1, 1))
-            if False:
-                sigm = theano.printing.Print("middle point")(sigm)
-            #      n_surface = theano.printing.Print("n_surface")(n_surface)
-            return sigm
-
-        else:
-            return T.le(Zx, a) * T.ge(Zx, b) * n_surface_0
-
-    def select_finite_faults(self):
-        # get data points of fault
-        fault_points = T.vertical_stack(T.stack(self.ref_layer_points[0]), self.rest_layer_points).T
-        # compute centroid of fault points
-        centroid = T.mean(fault_points, axis=1)
-        # compute difference of fault points from centroid
-        x = fault_points - centroid.reshape((-1, 1))
-        M = T.dot(x, x.T)  # same as np.cov(x) * 2
-        U = T.nlinalg.svd(M)  # is this the normal of the plane?
-        # overall this looks like some sort of plane fit to me
-        rotated_x = T.dot(self.x_to_interpolate(), U[0])  # this rotates ALL grid points that need to be interpolated
-        # rotated_x = T.dot(rotated_x, U[-1])  # rotate them with both rotation matrices
-        rotated_fault_points = T.dot(fault_points.T, U[0])  # same with fault points
-        # rotated_fault_points = T.dot(rotated_fault_points, U[-1])  # same
-        rotated_ctr = T.mean(rotated_fault_points, axis=0)  # and compute centroid of rotated points
-        # a factor: horizontal vector of ellipse of normal fault
-        a_radius = (rotated_fault_points[:, 0].max() - rotated_fault_points[:, 0].min()) / 2 \
-                  + self.inf_factor[self.n_surface_op[0] - 1]
-        # b_factor: vertical vector of ellipse
-        b_radius = (rotated_fault_points[:, 1].max() - rotated_fault_points[:, 1].min()) / 2 \
-                  + self.inf_factor[self.n_surface_op[0] - 1]
-
-        # sel = T.lt((rotated_x[:, 0] - rotated_ctr[0])**2 / a_radio**2 +
-        #            (rotated_x[:, 1] - rotated_ctr[1])**2 / b_radio**2,
-        #            1)
-
-        # ellipse equation: (x, c_x)^2 / a^2 +  (y - c_y)^2 / b^2 <= 1 if in ellipse
-        ellipse_factor = (rotated_x[:,0] - rotated_ctr[0])**2 / a_radius**2 + \
-            (rotated_x[:, 1] - rotated_ctr[1])**2 / b_radius**2
-
-        if "select_finite_faults" in self.verbose:
-            ellipse_factor = theano.printing.Print("h")(ellipse_factor)
-
-        # h_factor = 1 - h
-        # if "select_finite_faults" in self.verbose:
-        #     h_factor = theano.printing.Print("h_factor")(h_factor)
-
-        # because we select all grid points as rotated_x, the selection here is
-        # a boolean for all grid points: True if in ellipse, False if outside ellipse
-
-        # if "select_finite_faults" in self.verbose:
-        #     sel = theano.printing.Print("scalar_field_iter")(sel)
-            # sum of boolean array sel is in my example: 38301
-            # so I guess this selects all grid points affected by this finite fault
-
-        return ellipse_factor  # sel
-
-    def block_series(self, slope=5000, weights=None):
-        """
-        Compute the part of the block model of a given series (dictated by the bool array yet to be computed)
-
-        Returns:
-            theano.tensor.vector: Value of lithology at every interpolated point
-        """
-        # TODO: IMP set soft max in the borders
-
-        # Graph to compute the potential field
-        Z_x = self.scalar_field_at_all(weights)
-
-        # Max and min values of the potential field.
-        # max_pot = T.max(Z_x) + 1
-        # min_pot = T.min(Z_x) - 1
-        # max_pot += max_pot * 0.1
-        # min_pot -= min_pot * 0.1
-
-        # Value of the potential field at the surface_points of the computed series
-        self.scalar_field_at_surface_points_values = Z_x[-2*self.len_points: -self.len_points][self.npf_op]
-
-        max_pot = T.max(Z_x)
-        #max_pot = theano.printing.Print("max_pot")(max_pot)
-
-        min_pot = T.min(Z_x)
-   #     min_pot = theano.printing.Print("min_pot")(min_pot)
-
-
-        max_pot_sigm = 2 * max_pot - self.scalar_field_at_surface_points_values[0]
-        min_pot_sigm = 2 * min_pot - self.scalar_field_at_surface_points_values[-1]
-
-        boundary_pad = (max_pot - min_pot)*0.01
-        l = slope / (max_pot - min_pot)
-
-        # A tensor with the values to segment
-        scalar_field_iter = T.concatenate((
-                                           T.stack([max_pot + boundary_pad]),
-                                           self.scalar_field_at_surface_points_values,
-                                           T.stack([min_pot - boundary_pad])
-                                            ))
-
-        if "scalar_field_iter" in self.verbose:
-            scalar_field_iter = theano.printing.Print("scalar_field_iter")(scalar_field_iter)
-
-        # Loop to segment the distinct lithologies
-
-        n_surface_op_float_sigmoid = T.repeat(self.n_surface_op_float, 2, axis=1)
-
-        # TODO: instead -1 at the border look for the average distance of the input!
-
-        # This -1 makes that after the last interfaces the gradient goes on upwards
-        n_formation_op_float_sigmoid = T.set_subtensor(n_formation_op_float_sigmoid[0], -1)
-                                                    #- T.sqrt(T.square(n_formation_op_float_sigmoid[0] - n_formation_op_float_sigmoid[2])))
-
-        n_surface_op_float_sigmoid = T.set_subtensor(n_surface_op_float_sigmoid[:, -1], -1)
-                                                    #- T.sqrt(T.square(n_surface_op_float_sigmoid[3] - n_surface_op_float_sigmoid[-1])))
-
-        drift = T.set_subtensor(n_surface_op_float_sigmoid[:, 0], n_surface_op_float_sigmoid[:, 1])
-
-        if 'n_surface_op_float_sigmoid' in self.verbose:
-            n_surface_op_float_sigmoid = theano.printing.Print("n_surface_op_float_sigmoid")\
-                (n_surface_op_float_sigmoid)
-
-        partial_block, updates2 = theano.scan(
-            fn=self.compare,
-            outputs_info=None,
-            sequences=[dict(input=scalar_field_iter, taps=[0, 1]), T.arange(0, n_surface_op_float_sigmoid.shape[1],
-                                                                            2, dtype='int64')],
-            non_sequences=[Z_x, l, n_surface_op_float_sigmoid, drift],
-            name='Looping compare',
-            profile=False,
-            return_list=False)
-
-        # For every surface we get a vector so we need to sum compress them to one dimension
-        partial_block = partial_block.sum(axis=0)
-
-        # Add name to the theano node
-        partial_block.name = 'The chunk of block model of a specific series'
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            partial_block = theano.printing.Print(partial_block.name)(partial_block)
-
-        return Z_x, partial_block
-
-    def block_fault(self, slope=50):  #
-        """
-        Compute the part of the block model of a given series (dictated by the bool array yet to be computed)
-
-        Returns:
-            theano.tensor.vector: Value of lithology at every interpolated point
-        """
-
-        # Graph to compute the potential field
-        Z_x = self.scalar_field_at_all()
-
-        # Max and min values of the potential field.
-        # max_pot = T.max(Z_x) + 1
-        # min_pot = T.min(Z_x) - 1
-        # max_pot += max_pot * 0.1
-        # min_pot -= min_pot * 0.1
-
-        # Value of the potential field at the surface_points of the computed series
-        self.scalar_field_at_surface_points_values = Z_x[-2 *(self.len_points): -self.len_points][self.npf_op]
-
-        max_pot = T.max(Z_x)
-        # max_pot = theano.printing.Print("max_pot")(max_pot)
-
-        min_pot = T.min(Z_x)
-        # min_pot = theano.printing.Print("min_pot")(min_pot)
-
-        # max_pot_sigm = 2 * max_pot - self.scalar_field_at_surface_points_values[0]
-        # min_pot_sigm = 2 * min_pot - self.scalar_field_at_surface_points_values[-1]
-
-        boundary_pad = (max_pot - min_pot) * 0.01
-        #l = slope / (max_pot - min_pot)  # (max_pot - min_pot)
-
-        ellipse_factor = self.select_finite_faults()
-        ellipse_factor_rectified = T.switch(ellipse_factor < 1., ellipse_factor, 1.)
-
-        if "select_finite_faults" in self.verbose:
-            ellipse_factor_rectified = theano.printing.Print("h_factor_rectified")(ellipse_factor_rectified)
-
-        if "select_finite_faults" in self.verbose:
-            min_pot = theano.printing.Print("min_pot")(min_pot)
-            max_pot = theano.printing.Print("max_pot")(max_pot)
-
-        self.not_l = theano.shared(50.)
-        self.ellipse_factor_exponent = theano.shared(2)
-        # sigmoid_slope = (self.not_l * (1 / ellipse_factor_rectified)**3) / (max_pot - min_pot)
-        sigmoid_slope = 950 - 950 * ellipse_factor_rectified ** self.ellipse_factor_exponent + self.not_l
-        # l = T.switch(self.select_finite_faults(), 5000 / (max_pot - min_pot), 50 / (max_pot - min_pot))
-
-        if "select_finite_faults" in self.verbose:
-            sigmoid_slope = theano.printing.Print("l")(sigmoid_slope)
-
-        # A tensor with the values to segment
-        scalar_field_iter = T.concatenate((
-            T.stack([max_pot + boundary_pad]),
-            self.scalar_field_at_surface_points_values,
-            T.stack([min_pot - boundary_pad])
-        ))
-
-        if "scalar_field_iter" in self.verbose:
-            scalar_field_iter = theano.printing.Print("scalar_field_iter")(scalar_field_iter)
-
-        n_surface_op_float_sigmoid = T.repeat(self.n_surface_op_float[[0], :], 2, axis=1)
-        # TODO: instead -1 at the border look for the average distance of the input!
-
-        n_surface_op_float_sigmoid = T.set_subtensor(n_surface_op_float_sigmoid[:, 1], -1)
-        # - T.sqrt(T.square(n_surface_op_float_sigmoid[0] - n_surface_op_float_sigmoid[2])))
-
-        n_surface_op_float_sigmoid = T.set_subtensor(n_surface_op_float_sigmoid[:, -1], -1)
-        # - T.sqrt(T.square(n_surface_op_float_sigmoid[3] - n_surface_op_float_sigmoid[-1])))
-
-        drift = T.set_subtensor(n_surface_op_float_sigmoid[:, 0], n_surface_op_float_sigmoid[:, 1])
-
-        if 'n_surface_op_float_sigmoid' in self.verbose:
-            n_surface_op_float_sigmoid = theano.printing.Print("n_surface_op_float_sigmoid") \
-                (n_surface_op_float_sigmoid)
-
-        partial_block, updates2 = theano.scan(
-            fn=self.compare,
-            outputs_info=None,
-            sequences=[dict(input=scalar_field_iter, taps=[0, 1]),
-                       T.arange(0, n_surface_op_float_sigmoid.shape[1], 2, dtype='int64')],
-            non_sequences=[Z_x, sigmoid_slope, n_surface_op_float_sigmoid, drift],
-            name='Looping compare',
-            profile=False,
-            return_list=False)
-
-        # For every surface we get a vector so we need to sum compress them to one dimension
-        partial_block = partial_block.sum(axis=0)
-
-        # Add name to the theano node
-        partial_block.name = 'The chunk of block model of a specific series'
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            partial_block = theano.printing.Print(partial_block.name)(partial_block)
-
-        return [Z_x, partial_block]
-
-    def compute_a_fault(self,
-                        len_i_0, len_i_1,
-                        len_f_0, len_f_1,
-                        n_form_per_serie_0, n_form_per_serie_1,
-                        u_grade_iter,
-                        fault_matrix, final_block
-                        ):
-        """
-        Function that loops each fault, generating a potential field for each on them with the respective block model
-
-        Args:
-            len_i_0: Lenght of rest of previous series
-            len_i_1: Lenght of rest for the computed series
-            len_f_0: Lenght of dips of previous series
-            len_f_1: Length of dips of the computed series
-            n_form_per_serie_0: Number of surfaces of previous series
-            n_form_per_serie_1: Number of surfaces of the computed series
-
-        Returns:
-            theano.tensor.matrix: block model derived from the df that afterwards is used as a drift for the "real"
-            data
-        """
-
-        # THIS IS THE FAULTS BLOCK.
-        # ==================
-        # Preparing the data
-        # ==================
-
-        # compute the youngest fault and consecutively the others
-
-        # Theano shared
-        self.number_of_points_per_surface_T_op = self.number_of_points_per_surface_T[n_form_per_serie_0: n_form_per_serie_1]
-        self.n_surface_op = self.n_surface[n_form_per_serie_0: n_form_per_serie_1]
-        self.n_surface_op_float = self.surface_values[:, n_form_per_serie_0: n_form_per_serie_1 + 1]
-        self.npf_op = self.npf[n_form_per_serie_0: n_form_per_serie_1]
-        if 'n_surface' in self.verbose:
-            self.n_surface_op = theano.printing.Print('n_surface_fault')(self.n_surface_op)
-
-        self.n_universal_eq_T_op = u_grade_iter
-
-        self.dips_position = self.dips_position_all[len_f_0: len_f_1, :]
-        self.dips_position_tiled = T.tile(self.dips_position, (self.n_dimensions, 1))
-
-        # Theano Var
-        self.dip_angles = self.dip_angles_all[len_f_0: len_f_1]
-        self.azimuth = self.azimuth_all[len_f_0: len_f_1]
-        self.polarity = self.polarity_all[len_f_0: len_f_1]
-
-        self.ref_layer_points = self.ref_layer_points_all[len_i_0: len_i_1, :]
-        self.rest_layer_points = self.rest_layer_points_all[len_i_0: len_i_1, :]
-
-        # Updating the interface points involved in the iteration. This is important for the fault drift
-        self.len_i_0 = len_i_0
-        self.len_i_1 = len_i_1
-
-        if 'lengths' in self.verbose:
-            self.len_i_0 = theano.printing.Print('len_i_0')(self.len_i_0)
-            self.len_i_1 = theano.printing.Print('len_i_1')(self.len_i_1)
-            self.len_points = theano.printing.Print('len_points')(self.len_points)
-
-        # Extracting a the subset of the fault matrix to the scalar field of the current iterations
-        faults_relation_op = self.fault_relation[:, T.cast(self.n_surface_op-1, 'int8')]
-        faults_relation_rep = T.repeat(faults_relation_op, 1)
-
-        if 'faults_relation' in self.verbose:
-            faults_relation_rep = theano.printing.Print('SELECT')(faults_relation_rep)
-        if len(self.gradients) is not 0:
-            self.fault_matrix = fault_matrix[::5][T.nonzero(T.cast(faults_relation_rep, "int8"))[0], :]
-        else:
-            self.fault_matrix = fault_matrix[::2][T.nonzero(T.cast(faults_relation_rep, "int8"))[0], :]
-
-        if 'fault_matrix_loop' in self.verbose:
-            self.fault_matrix = theano.printing.Print('self fault matrix')(self.fault_matrix)
-
-        # ================================
-        # Computing the fault scalar field
-        # ================================
-
-        potential_field_values, faults_matrix = self.block_fault(slope=1000)
-
-        # Update the block matrix
-        final_block = T.set_subtensor(
-                    final_block[0, :],
-                    faults_matrix[0])#T.cast(T.cast(faults_matrix, 'bool'), 'int8'))
-
-        # Update the potential field matrix
-       # potential_field_values = self.scalar_field_at_all()
-
-        final_block = T.set_subtensor(
-                    final_block[1, :],
-                    potential_field_values)
-
-        # Store the potential field at the surface_points
-        self.final_potential_field_at_faults_op = T.set_subtensor(self.final_potential_field_at_faults_op[self.n_surface_op-1],
-                                                                  self.scalar_field_at_surface_points_values)
-
-        aux_ind = T.max(self.n_surface_op, 0)
-
-        if len(self.gradients) is not 0:
-            weights = self.extend_dual_kriging()
-            gradients = self.gradient_field_at_all(weights, self.gradients)
-            final_block = T.set_subtensor(
-                final_block[2:, :],
-                gradients)
-            # Setting the values of the fault matrix computed in the current iteration
-            fault_matrix = T.set_subtensor(fault_matrix[(aux_ind - 1) * 5:aux_ind * 5, :], final_block)
-
-        else:
-            # Setting the values of the fault matrix computed in the current iteration
-            fault_matrix = T.set_subtensor(fault_matrix[(aux_ind-1)*2:aux_ind*2, :], final_block)
-
-        return fault_matrix, self.final_potential_field_at_faults_op,
-
-    def compute_a_series(self,
-                         len_i_0, len_i_1,
-                         len_f_0, len_f_1,
-                         n_form_per_serie_0, n_form_per_serie_1,
-                         u_grade_iter,
-                         final_block, scalar_field_at_form,
-                         #fault_block
-                         ):
-
-        """
-        Function that loops each series, generating a potential field for each on them with the respective block model
-
-        Args:
-             len_i_0: Lenght of rest of previous series
-             len_i_1: Lenght of rest for the computed series
-             len_f_0: Lenght of dips of previous series
-             len_f_1: Length of dips of the computed series
-             n_form_per_serie_0: Number of surfaces of previous series
-             n_form_per_serie_1: Number of surfaces of the computed series
-
-        Returns:
-             theano.tensor.matrix: final block model
-        """
-
-        # Setting the fault contribution to kriging from the previous loop
-       # self.fault_matrix = fault_block
-
-        # THIS IS THE FINAL BLOCK. (DO I NEED TO LOOP THE FAULTS FIRST? Yes you do)
-        # ==================
-        # Preparing the data
-        # ==================
-
-        # Vector that controls the points that have been simulated in previous iterations
-        self.yet_simulated = T.nonzero(T.le(final_block[1, :], scalar_field_at_form[n_form_per_serie_0 - 1]))[0] # This -1 comes to get the last scalar field value (the bottom) of the previous series
-        self.yet_simulated.name = 'Yet simulated LITHOLOGY node'
-        if 'fault_mask' in self.verbose:
-            self.yet_simulated = theano.printing.Print('fault_mask')(self.yet_simulated)
-            scalar_field_at_form = theano.printing.Print('scalar_field_at_form_out')(scalar_field_at_form)
-
-        # Theano shared
-        self.number_of_points_per_surface_T_op = self.number_of_points_per_surface_T[n_form_per_serie_0: n_form_per_serie_1]
-        self.n_surface_op = self.n_surface[n_form_per_serie_0: n_form_per_serie_1]
-        self.n_surface_op_float = self.surface_values[:, n_form_per_serie_0: (n_form_per_serie_1 + 1)]
-        self.npf_op = self.npf[n_form_per_serie_0: n_form_per_serie_1]
-
-        self.n_universal_eq_T_op = u_grade_iter
-
-        self.dips_position = self.dips_position_all[len_f_0: len_f_1, :]
-        self.dips_position_tiled = T.tile(self.dips_position, (self.n_dimensions, 1))
-
-        # Theano Var
-        self.dip_angles = self.dip_angles_all[len_f_0: len_f_1]
-        self.azimuth = self.azimuth_all[len_f_0: len_f_1]
-        self.polarity = self.polarity_all[len_f_0: len_f_1]
-
-        self.ref_layer_points = self.ref_layer_points_all[len_i_0: len_i_1, :]
-        self.rest_layer_points = self.rest_layer_points_all[len_i_0: len_i_1, :]
-
-        if 'rest_layer_points' in self.verbose:
-            self.rest_layer_points = theano.printing.Print('rest_layer_points')(self.rest_layer_points)
-
-        if 'ref_layer_points' in self.verbose:
-            self.ref_layer_points = theano.printing.Print('ref_layer_points')(self.ref_layer_points)
-
-        # For the contribution of the df I did not find a better way
-        self.len_i_0 = len_i_0
-        self.len_i_1 = len_i_1
-
-        # Printing
-        if 'n_surface' in self.verbose:
-            self.n_surface_op = theano.printing.Print('n_surface_series')(self.n_surface_op)
-
-        if 'lengths' in self.verbose:
-            self.len_i_0 = theano.printing.Print('len_i_0')(self.len_i_0)
-            self.len_i_1 = theano.printing.Print('len_i_1')(self.len_i_1)
-            self.len_points = theano.printing.Print('len_points')(self.len_points)
-        # ====================
-        # Computing the series
-        # ====================
-
-        weights = self.extend_dual_kriging()
-
-        scalar_field_values, scalar_field_contribution = self.block_series()
-
-        # Updating the block model with the lithology block
-
-        # Set model id
-        final_block = T.set_subtensor(
-            final_block[0, self.yet_simulated],
-            scalar_field_contribution[0])
-
-        final_block = T.set_subtensor(
-            final_block[0, -2*self.len_points:],
-            0)
-
-        #scalar_field_values = self.scalar_field_at_all()
-
-        # Set scalar field
-        final_block = T.set_subtensor(
-            final_block[1, self.yet_simulated],
-            scalar_field_values)
-
-        final_block = T.set_subtensor(
-            final_block[1, -2 * self.len_points:],
-            0)
-
-        # Set additional values
-        final_block = T.set_subtensor(
-            final_block[2:, self.yet_simulated],
-            scalar_field_contribution[1:])
-
-        # Reset scalar field at the surface_points to 0
-        # final_block = T.set_subtensor(
-        #     final_block[:, -2 * self.len_points:],
-        #     0)
-
-        # Store the potential field at the surface_points
-        self.final_scalar_field_at_surfaces_op = T.set_subtensor(
-            self.final_scalar_field_at_surfaces_op[self.n_surface_op - 1],
-            self.scalar_field_at_surface_points_values)
-
-        if len(self.gradients) is not 0:
-            gradients = self.gradient_field_at_all(weights, self.gradients)
-            final_block = T.set_subtensor(
-                final_block[2:, self.yet_simulated],
-                gradients)
-
-        return final_block, self.final_scalar_field_at_surfaces_op
-
-    def compute_geological_model(self, weights=None):
-
-        # Change the flag to extend the graph in the compute fault and compute series function
-        lith_matrix = T.zeros((0, 0, self.grid_val_T.shape[0] + 2 * self.len_points))
-
-        # Init to matrix which contains the block and scalar field of every fault
-        self.fault_matrix = T.zeros((self.n_faults * 2, self.grid_val_T.shape[0] + 2 * self.len_points))
-        self.fault_matrix_f = T.zeros((self.n_faults * 2, self.grid_val_T.shape[0] + 2 * self.len_points))
-
-        self.final_scalar_field_at_surfaces_op = self.final_scalar_field_at_surfaces
-        self.final_potential_field_at_faults_op = self.final_scalar_field_at_faults
-
-        # Init df block. Here we store the block and potential field results of one iteration
-        self.fault_block_init = T.zeros((2, self.grid_val_T.shape[0] + 2 * self.len_points))
-        self.fault_block_init.name = 'final block of df init'
-        self.yet_simulated = T.nonzero(T.eq(self.fault_block_init[0, :], 0))[0]
-
-        # Compute Faults
-        if self.n_faults.get_value() != 0 or self.is_fault:
-
-            # Looping
-            fault_loop, updates3 = theano.scan(
-                fn=self.compute_a_fault,
-                    outputs_info=[
-                              dict(initial=self.fault_matrix, taps=[-1]),
-                              None],  # This line may be used for the df network
-                sequences=[dict(input=self.len_series_i[:self.n_faults + 1], taps=[0, 1]),
-                           dict(input=self.len_series_f[:self.n_faults + 1], taps=[0, 1]),
-                           dict(input=self.n_surfaces_per_series[:self.n_faults + 1], taps=[0, 1]),
-                           dict(input=self.n_universal_eq_T[:self.n_faults + 1], taps=[0])],
-                non_sequences=self.fault_block_init,
-                name='Looping df',
-                return_list=True,
-                profile=False
-            )
-
-            # We return the last iteration of the fault matrix
-            self.fault_matrix_f = fault_loop[0][-1]
-            self.fault_matrix = self.fault_matrix_f[::2]
-            # fault_block = self.fault_matrix[:, :-2 * self.len_points]
-            # For this we return every iteration since is each potential field at interface
-            self.pfai_fault = fault_loop[1]
-
-        # Check if there are lithologies to compute
-        if len(self.len_series_f.get_value()) - 1 > self.n_faults.get_value() or self.is_lith:
-
-            # The +1 is due to the scalar field
-            self.lith_block_init = T.zeros((self.surface_values.shape[0] + 1,
-                                            self.grid_val_T.shape[0] + 2 * self.len_points))
-
-            # Compute Lithologies
-            lith_loop, updates2 = theano.scan(
-                 fn=self.compute_a_series,
-                 outputs_info=[self.lith_block_init, self.final_scalar_field_at_surfaces_op],
-                 sequences=[dict(input=self.len_series_i[self.n_faults:], taps=[0, 1]),
-                            dict(input=self.len_series_f[self.n_faults:], taps=[0, 1]),
-                            dict(input=self.n_surfaces_per_series[self.n_faults:], taps=[0, 1]),
-                            dict(input=self.n_universal_eq_T[self.n_faults:], taps=[0])],
-                # non_sequences=[self.fault_matrix],
-                 name='Looping surface_points',
-                 profile=False,
-                 return_list=True
-            )
-
-            lith_matrix = lith_loop[0][-1]
-            self.pfai_lith = lith_loop[1]
-
-        pfai = T.vertical_stack(self.pfai_fault, self.pfai_lith)
-        return [lith_matrix[:, :-2 * self.len_points], self.fault_matrix_f[:, :-2 * self.len_points], pfai]
-
-    def compute_geological_model_gradient(self, gradients = [], weights=None):
-        # TODO update it to several properties!!
-
-        self.gradients = ['Gx', 'Gy', 'Gz']#theano.shared(['Gx', 'Gy', 'Gz'])
-
-        # Change the flag to extend the graph in the compute fault and compute series function
-        lith_matrix = T.zeros((0, 0, self.grid_val_T.shape[0] + 2 * self.len_points))
-
-        # Init to matrix which contains the block and scalar field of every fault
-        self.fault_matrix = T.zeros((self.n_faults*5, self.grid_val_T.shape[0]))
-        self.fault_matrix_f = T.zeros((self.n_faults*5, self.grid_val_T.shape[0]))
-
-        # TODO I think I just have to change the size of the lith_block
-        self.lith_block_init = T.zeros((5, self.grid_val_T.shape[0]))
-        self.fault_block_init = T.zeros((5, self.grid_val_T.shape[0]))
-        self.fault_block_init.name = 'final block of df init'
-        # Compute Faults
-        if self.n_faults.get_value() != 0 or self.is_fault:
-
-            # Looping
-            fault_loop, updates3 = theano.scan(
-                fn=self.compute_a_fault,
-                    outputs_info=[
-                              dict(initial=self.fault_matrix, taps=[-1]),
-                              None],  # This line may be used for the df network
-                sequences=[dict(input=self.len_series_i[:self.n_faults + 1], taps=[0, 1]),
-                           dict(input=self.len_series_f[:self.n_faults + 1], taps=[0, 1]),
-                           dict(input=self.n_surfaces_per_series[:self.n_faults + 1], taps=[0, 1]),
-                           dict(input=self.n_universal_eq_T[:self.n_faults + 1], taps=[0])],
-                non_sequences=self.fault_block_init,
-                name='Looping df',
-                return_list=True,
-                profile=False
-            )
-
-            # We return the last iteration of the fault matrix
-            self.fault_matrix_f = fault_loop[0][-1]
-            self.fault_matrix = self.fault_matrix_f[::5]
-          #  fault_block = self.fault_matrix[:, :-2 * self.len_points]
-            # For this we return every iteration since is each potential field at interface
-            self.pfai_fault = fault_loop[1]
-
-        # Check if there are lithologies to compute
-        if len(self.len_series_f.get_value()) - 1 > self.n_faults.get_value() or self.is_lith:
-
-            # Compute Lithologies
-            lith_loop, updates2 = theano.scan(
-                 fn=self.compute_a_series,
-                 outputs_info=[self.lith_block_init, self.final_scalar_field_at_surfaces_op],
-                 sequences=[dict(input=self.len_series_i[self.n_faults:], taps=[0, 1]),
-                            dict(input=self.len_series_f[self.n_faults:], taps=[0, 1]),
-                            dict(input=self.n_surfaces_per_series[self.n_faults:], taps=[0, 1]),
-                            dict(input=self.n_universal_eq_T[self.n_faults:], taps=[0])],
-                # non_sequences=[self.fault_matrix],
-                 name='Looping surface_points',
-                 profile=False,
-                 return_list=True
-            )
-
-            lith_matrix = lith_loop[0][-1]
-            self.pfai_lith = lith_loop[1]
-
-        pfai = T.vertical_stack(self.pfai_fault, self.pfai_lith)
-        return [lith_matrix[:, :-2 * self.len_points], self.fault_matrix_f[:, :-2 * self.len_points], pfai]
-
-    # def compute_weights_op(self,
-    #                        len_i_0, len_i_1,
-    #                        len_f_0, len_f_1,
-    #                        n_form_per_serie_0, n_form_per_serie_1,
-    #                        u_grade_iter,
-    #                        weights):
-    #     # Theano shared
-    #     self.number_of_points_per_surface_T_op = self.number_of_points_per_surface_T[
-    #                                                n_form_per_serie_0: n_form_per_serie_1]
-    #     self.n_surface_op = self.n_surface[n_form_per_serie_0: n_form_per_serie_1]
-    #     self.n_surface_op_float = self.surface_values[n_form_per_serie_0: (n_form_per_serie_1 + 1)]
-    #     self.npf_op = self.npf[n_form_per_serie_0: n_form_per_serie_1]
-    #
-    #     self.n_universal_eq_T_op = u_grade_iter
-    #
-    #     self.dips_position = self.dips_position_all[len_f_0: len_f_1, :]
-    #     self.dips_position_tiled = T.tile(self.dips_position, (self.n_dimensions, 1))
-    #
-    #     # Theano Var
-    #     self.dip_angles = self.dip_angles_all[len_f_0: len_f_1]
-    #     self.azimuth = self.azimuth_all[len_f_0: len_f_1]
-    #     self.polarity = self.polarity_all[len_f_0: len_f_1]
-    #
-    #     self.ref_layer_points = self.ref_layer_points_all[len_i_0: len_i_1, :]
-    #     self.rest_layer_points = self.rest_layer_points_all[len_i_0: len_i_1, :]
-    #
-    #     # For the contribution of the df I did not find a better way
-    #     self.len_i_0 = len_i_0
-    #     self.len_i_1 = len_i_1
-    #
-    #     weights = T.set_subtensor(weights[:, len_i_0: len_i_1], self.solve_kriging())
-    #     return weights
-    #
-    # def compute_weights(self):
-    #     weights_init = T.zeros((1, self.len_points + self.dips_position_tiled.shape[0]))
-    #     # Compute Lithologies
-    #     weights_loop, updates2 = theano.scan(
-    #          fn=self.compute_weights_op,
-    #          outputs_info=[weights_init],
-    #          sequences=[dict(input=self.len_series_i, taps=[0, 1]),
-    #                     dict(input=self.len_series_f, taps=[0, 1]),
-    #                     dict(input=self.n_surfaces_per_series, taps=[0, 1]),
-    #                     dict(input=self.n_universal_eq_T, taps=[0])],
-    #         # non_sequences=[self.fault_matrix],
-    #          name='Looping surface_points',
-    #          profile=False,
-    #          return_list=True
-    #     )
-    #
-    #     return weights_loop
-
-    # ==================================
-    # Geophysics
-    # ==================================
-
-    def switch_densities(self, n_surface, density, density_block):
-
-        density_block = T.switch(T.eq(density_block, n_surface), density, density_block)
-        return density_block
-
-    def compute_forward_gravity(self): # densities, tz, select,
-
-        # TODO: Assert outside that densities is the same size as surfaces (minus df)
-        # Compute the geological model
-        lith_matrix, fault_matrix, pfai = self.compute_geological_model()
-
-        # if n_faults == 0:
-        #     surfaces = T.concatenate([self.n_surface[::-1], T.stack([0])])
-        # else:
-        #     surfaces = T.concatenate([self.n_surface[:n_faults-1:-1], T.stack([0])])
-        #
-        #     if False:
-        #         surfaces = theano.printing.Print('surfaces')(surfaces)
-        #
-        # # Substitue lithologies by its density
-        # density_block_loop, updates4 = theano.scan(self.switch_densities,
-        #                             outputs_info=[lith_matrix[0]],
-        #                              sequences=[surfaces, self.densities],
-        #                             return_list = True
-        # )
-
-        # if False:
-        #     density_block_loop_f = T.set_subtensor(density_block_loop[-1][-1][self.weigths_index], self.weigths_weigths)
-        #
-        # else:
-        density_block_loop_f = lith_matrix[0]
-
-
-        if 'density_block' in self.verbose:
-            density_block_loop_f = theano.printing.Print('density block')(density_block_loop_f)
-
-        n_measurements = self.tz.shape[0]
-        # Tiling the density block for each measurent and picking just the closer to them. This has to be possible to
-        # optimize
-
-        #densities_rep = T.tile(density_block_loop[-1][-1], n_measurements)
-        densities_rep = T.tile(density_block_loop_f, n_measurements)
-        densities_selected = densities_rep[T.nonzero(T.cast(self.select, "int8"))[0]]
-        densities_selected_reshaped = densities_selected.reshape((n_measurements, -1))
-        #
-        # # density times the component z of gravity
-        grav = densities_selected_reshaped * self.tz
-
-        #return [lith_matrix, self.fault_matrix, pfai, grav.sum(axis=1)]
-        return [lith_matrix, fault_matrix, grav.sum(axis=1), pfai]
-
-
-    def compute_grad(self, n_faults=None):
-        sol = self.block_series()
-        return theano.grad(sol.sum(), self.rest_layer_points_all)
-
-    # def compute_grad2(self, n_faults=None):
-    #     sol = self.compute_a_series(
-    #         self.len_series_i[n_faults:][0], self.len_series_i[n_faults:][-1],
-    #         self.len_series_f[n_faults:][0], self.len_series_f[n_faults:][-1],
-    #         self.n_surfaces_per_series[n_faults:][0], self.n_surfaces_per_series[n_faults:][-1],
-    #         self.n_universal_eq_T[n_faults:],
-    #         self.lith_block_init, self.final_scalar_field_at_surfaces,
-    #         self.fault_matrix
-    #     )
-    #     return theano.grad(sol[0].sum(), self.rest_layer_points_all)
-    #
-    # def compute_grad3(self, n_faults=None
-    #                   ):
-    #     lith_matrix, fault_matrix, pfai = self.compute_geological_model(n_faults=n_faults)
-    #     return theano.grad(lith_matrix[0].sum(), self.rest_layer_points_all)
-    #
-    #
-
-
-class TheanoOptions(object):
-    def __init__(self,  output='geology', optimizer='fast_compile', verbose=[0], dtype='float32',
-                 is_fault=None, is_lith=None):
-        # OPTIONS
-        # -------
-        if verbose is np.nan:
-            self.verbose = [None]
-        else:
-            self.verbose = verbose
-        self.dot_version = False
-
-        theano.config.floatX = dtype
-        theano.config.optimizer = optimizer
-
-
-class TheanoGeometry(TheanoOptions):
-    def __init__(self, output='geology', optimizer='fast_compile', verbose=[0], dtype='float32',
-                 is_fault=None, is_lith=None):
-
-        # # OPTIONS
-        # # -------
-        # if verbose is np.nan:
-        #     self.verbose = [None]
-        # else:
-        #     self.verbose = verbose
-        # self.dot_version = False
-        #
-        # theano.config.floatX = dtype
-        # theano.config.optimizer = optimizer
-        super(TheanoGeometry, self).__init__(optimizer='fast_compile', verbose=[0], dtype='float32',)
-
-        # Number of dimensions. Now it is not too variable anymore
-        self.n_dimensions = 3
-
-        # This is not accumulative
-        self.number_of_points_per_surface_T = theano.shared(np.zeros(3, dtype='int32')) #TODO is DEP?
-        self.number_of_points_per_surface_T_op = T.vector('Number of points per surface used to split rest-ref',
-                                                          dtype='int32')
-        self.npf_op = T.cumsum(T.concatenate((T.stack(0), self.number_of_points_per_surface_T_op[:-1])))
-
-        # # FORMATIONS
-        # # ----------
-        # self.n_surface = theano.shared(np.arange(2, 5, dtype='int32'), "ID of the surface")
-        # self.n_surface_op = self.n_surface
-        # self.surface_values = theano.shared((np.arange(2, 4, dtype=dtype).reshape(2, -1)), "Value of the surface to compute")
-        # self.n_surface_op_float = self.surface_values
-
-
-        # KRIGING
-        # -------
-        self.a_T = theano.shared(np.cast[dtype](-1.), "Range")
-        self.c_o_T = theano.shared(np.cast[dtype](-1.), 'Covariance at 0')
-        self.nugget_effect_grad_T = theano.shared(np.cast[dtype](-1), 'Nugget effect of gradients')
-        self.nugget_effect_scalar_T = theano.shared(np.cast[dtype](-1), 'Nugget effect of scalar')
-        self.n_universal_eq_T = theano.shared(np.zeros(5, dtype='int32'), "Grade of the universal drift")
-        self.n_universal_eq_T_op = theano.shared(3)
-
-        # They weight the contribution of the surface_points against the orientations.
-        self.i_reescale = theano.shared(np.cast[dtype](4.))
-        self.gi_reescale = theano.shared(np.cast[dtype](2.))
-
-        # VARIABLES
-        # ---------
-        self.dips_position_all = T.matrix("Position of the dips")
-        self.dip_angles_all = T.vector("Angle of every dip")
-        self.azimuth_all = T.vector("Azimuth")
-        self.polarity_all = T.vector("Polarity")
-
-        self.surface_points_all = T.matrix("All the surface_points points at once")
-        self.len_points = self.surface_points_all.shape[0] - self.number_of_points_per_surface_T_op.shape[0]
-        # Tiling dips to the 3 spatial coordinations
-        self.dips_position = self.dips_position_all
-        self.dips_position_tiled = T.tile(self.dips_position, (self.n_dimensions, 1))
-
-        # These are subsets of the data for each series. I initialized them as the whole arrays but then they will take
-        # the data of every potential field
-        self.dip_angles = self.dip_angles_all
-        self.azimuth = self.azimuth_all
-        self.polarity = self.polarity_all
-
-        self.ref_layer_points_all = self.set_rest_ref_matrix()[0]
-        self.rest_layer_points_all = self.set_rest_ref_matrix()[1]
-
-        self.ref_layer_points = self.ref_layer_points_all
-        self.rest_layer_points = self.rest_layer_points_all
-
-        self.fault_drift = T.matrix('Drift matrix due to faults')
-
-    def set_rest_ref_matrix(self):
-        ref_positions = T.cumsum(T.concatenate((T.stack(0), self.number_of_points_per_surface_T_op[:-1] + 1)))
-        ref_points = T.repeat(self.surface_points_all[ref_positions], self.number_of_points_per_surface_T_op, axis=0)
-
-        rest_mask = T.ones(T.stack(self.surface_points_all.shape[0]), dtype='int16')
-        rest_mask = T.set_subtensor(rest_mask[ref_positions], 0)
-        rest_points = self.surface_points_all[T.nonzero(rest_mask)[0]]
-        return [ref_points, rest_points, rest_mask, T.nonzero(rest_mask)[0]]
-
-    @staticmethod
-    def squared_euclidean_distances(x_1, x_2):
-        """
-        Compute the euclidian distances in 3D between all the points in x_1 and x_2
-
-        Args:
-            x_1 (theano.tensor.matrix): shape n_points x number dimension
-            x_2 (theano.tensor.matrix): shape n_points x number dimension
-
-        Returns:
-            theano.tensor.matrix: Distancse matrix. shape n_points x n_points
-        """
-
-        # T.maximum avoid negative numbers increasing stability
-        sqd = T.sqrt(T.maximum(
-            (x_1 ** 2).sum(1).reshape((x_1.shape[0], 1)) +
-            (x_2 ** 2).sum(1).reshape((1, x_2.shape[0])) -
-            2 * x_1.dot(x_2.T), 1e-12
-        ))
-
-        if False:
-            sqd = theano.printing.Print('sed')(sqd)
-
-        return sqd
-
-    def matrices_shapes(self):
-        """
-        Get all the lengths of the matrices that form the covariance matrix
-
-        Returns:
-             length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C
-        """
-
-        # Calculating the dimensions of the
-        length_of_CG = self.dips_position_tiled.shape[0]
-        length_of_CGI = self.rest_layer_points.shape[0]
-        length_of_U_I = self.n_universal_eq_T_op
-
-        # Self fault matrix contains the block and the potential field (I am not able to split them). Therefore we need
-        # to divide it by 2
-        length_of_faults = T.cast(self.fault_drift.shape[0], 'int32')
-        length_of_C = length_of_CG + length_of_CGI + length_of_U_I + length_of_faults
-
-        if 'matrices_shapes' in self.verbose:
-            length_of_CG = theano.printing.Print("length_of_CG")(length_of_CG)
-            length_of_CGI = theano.printing.Print("length_of_CGI")(length_of_CGI)
-            length_of_U_I = theano.printing.Print("length_of_U_I")(length_of_U_I)
-            length_of_faults = theano.printing.Print("length_of_faults")(length_of_faults)
-            length_of_C = theano.printing.Print("length_of_C")(length_of_C)
-
-        return length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C
+"""
+    This file is part of gempy.
+
+    gempy is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    gempy is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
+
+
+DEP-- I need to update this string
+Function that generates the symbolic code to perform the interpolation. Calling this function creates
+ both the aesara functions for the potential field and the block.
+
+Returns:
+    aesara function for the potential field
+    aesara function for the block
+"""
+import aesara
+import aesara.tensor as T
+import numpy as np
+import sys
+
+aesara.config.openmp_elemwise_minsize = 10000
+aesara.config.openmp = True
+
+aesara.config.optimizer = 'fast_compile'
+aesara.config.floatX = 'float64'
+aesara.config.on_opt_error = 'ignore'
+
+aesara.config.exception_verbosity = 'high'
+aesara.config.compute_test_value = 'off'
+aesara.config.profile_memory = False
+aesara.config.scan.debug = False
+aesara.config.profile = False
+
+
+class aesaraGraph(object):
+    """
+    This class is used to help to divide the construction of the graph into sensical parts. All its methods buildDEP2 a part
+    of the graph. Every method can be seen as a branch and collection of branches until the last method that will be the
+    whole tree. Every part of the graph could be compiled separately but as we increase the complexity the input of each
+    of these methods is more and more difficult to provide (if you are in a branch close to the trunk you need all the
+    results of the branches above)
+    """
+    def __init__(self, output='geology', optimizer='fast_compile', verbose=[0], dtype='float32',
+                 is_fault=None, is_lith=None):
+        """
+        In the init we need to create all the symbolic parameters that are used in the process. Most of the variables
+        are shared parameters initialized with random values. At this stage we only care about the type and shape of the
+        parameters. After we have the graph built we can update the value of these shared parameters to our data (in the
+        interpolatorClass).
+
+        Args:
+            u_grade: grade of the drift to compile the right graph. I found out that we can make a graph that takes this
+            as variable so this argument will be deprecated soon
+            verbose (list): name of the nodes you want to print
+            dtype (str): type of float either 32 or 64
+        """
+
+        # Pass the verbose list as property
+
+        # OPTIONS
+        # -------
+        if verbose is np.nan:
+            self.verbose = [None]
+        else:
+            self.verbose = verbose
+        self.dot_version = False
+
+        aesara.config.floatX = dtype
+        aesara.config.optimizer = optimizer
+
+        # Creation of symbolic parameters
+        # =============
+        # Constants
+        # =============
+
+        # They weight the contribution of the surface_points against the orientations.
+        self.i_reescale = aesara.shared(np.cast[dtype](4.))
+        self.gi_reescale = aesara.shared(np.cast[dtype](2.))
+
+        # Number of dimensions. Now it is not too variable anymore
+        self.n_dimensions = 3
+
+        self.len_i_0 = 0
+        self.len_i_1 = 1
+
+        # =================
+        # INITIALIZE SHARED
+        # =================
+
+        # SEMI-VARIABLES
+        # --------------
+        self.grid_val_T = aesara.shared(np.cast[dtype](np.zeros((2, 200))), 'Coordinates of the grid '
+                                                                            'points to interpolate')
+        # Shape is 9x2, 9 drift funcitons and 2 points
+        self.universal_grid_matrix_T = aesara.shared(np.cast[dtype](np.zeros((9, 9)))) #TODO future DEP
+
+        # FORMATIONS
+        # ----------
+        self.n_surface = aesara.shared(np.arange(2, 5, dtype='int32'), "ID of the surface")
+        self.n_surface_op = self.n_surface
+        self.surface_values = aesara.shared((np.arange(2, 4, dtype=dtype).reshape(2, -1)), "Value of the surface to compute")
+        self.n_surface_op_float = self.surface_values
+
+        # FAULTS
+        # ------
+        # Init fault relation matrix
+        self.fault_relation = aesara.shared(np.array([[0, 1, 0, 1],
+                                                      [0, 0, 1, 1],
+                                                      [0, 0, 0, 1],
+                                                      [0, 0, 0, 0]]), 'fault relation matrix')
+
+        self.inf_factor = aesara.shared(np.ones(200, dtype='int32') * 10, 'Arbitrary scalar to make df infinite')
+
+        # KRIGING
+        # -------
+        self.a_T = aesara.shared(np.cast[dtype](-1.), "Range")
+        self.c_o_T = aesara.shared(np.cast[dtype](-1.), 'Covariance at 0')
+        self.nugget_effect_grad_T = aesara.shared(np.cast[dtype](-1), 'Nugget effect of gradients')
+        self.nugget_effect_scalar_T = aesara.shared(np.cast[dtype](-1), 'Nugget effect of scalar')
+        self.n_universal_eq_T = aesara.shared(np.zeros(5, dtype='int32'), "Grade of the universal drift")
+        self.n_universal_eq_T_op = aesara.shared(3)
+
+        # STRUCTURE
+        # ---------
+        # This parameters give me the shape of the different groups of data. I pass all data together and I threshold it
+        # using these values to the different potential fields and surfaces
+        self.is_fault = is_fault
+        self.is_lith = is_lith
+        self.n_faults = aesara.shared(0, 'Number of df')
+        self.n_surfaces_per_series = aesara.shared(np.arange(2, dtype='int32'), 'List with the number of surfaces')
+
+        # This is not accumulative
+        self.number_of_points_per_surface_T = aesara.shared(np.zeros(3, dtype='int32')) #TODO is DEP?
+        self.number_of_points_per_surface_T_op = self.number_of_points_per_surface_T
+        # This is accumulative
+        self.npf = aesara.shared(np.zeros(3, dtype='int32'), 'Number of points per surface accumulative')
+        self.npf_op = self.npf[[0, -2]]
+        self.len_series_i = aesara.shared(np.arange(2, dtype='int32'), 'Length of surface_points in every series')
+        self.len_series_f = aesara.shared(np.arange(2, dtype='int32'), 'Length of foliations in every series')
+
+        # VARIABLES
+        # ---------
+        self.dips_position_all = T.matrix("Position of the dips")
+        self.dip_angles_all = T.vector("Angle of every dip")
+        self.azimuth_all = T.vector("Azimuth")
+        self.polarity_all = T.vector("Polarity")
+
+        self.surface_points = T.matrix("All the surface_points points at once")
+        #self.ref_layer_points_all = T.matrix("Reference points for every layer") # TODO: This should be DEP
+        #self.rest_layer_points_all = T.matrix("Rest of the points of the layers") # TODO: This should be DEP
+        self.len_points = self.surface_points.shape[0] - self.number_of_points_per_surface_T.shape[0]
+        # Tiling dips to the 3 spatial coordinations
+        self.dips_position = self.dips_position_all
+        self.dips_position_tiled = T.tile(self.dips_position, (self.n_dimensions, 1))
+
+        # These are subsets of the data for each series. I initialized them as the whole arrays but then they will take
+        # the data of every potential field
+        self.dip_angles = self.dip_angles_all
+        self.azimuth = self.azimuth_all
+        self.polarity = self.polarity_all
+
+        self.ref_layer_points_all = self.set_rest_ref_matrix()[0]
+        self.rest_layer_points_all = self.set_rest_ref_matrix()[1]
+
+        self.ref_layer_points = self.ref_layer_points_all
+        self.rest_layer_points = self.rest_layer_points_all
+
+        # SOLUTION
+        # --------
+        self.final_block = aesara.shared(np.cast[dtype](np.zeros((1, 3))), "Final block computed")
+
+        self.final_scalar_field_at_surfaces = aesara.shared(
+            np.zeros(self.n_surfaces_per_series.get_value().sum(), dtype=dtype))
+        self.final_scalar_field_at_faults = aesara.shared(
+            np.zeros(self.n_surfaces_per_series.get_value().sum(), dtype=dtype))
+
+        self.final_scalar_field_at_surfaces_op = self.final_scalar_field_at_surfaces
+        self.final_potential_field_at_faults_op = self.final_scalar_field_at_faults
+
+        # Init Results
+        # Init lithology block. Here we store the block and potential field results
+        self.lith_block_init = T.zeros((2, self.grid_val_T.shape[0] + 2 * self.len_points))
+        self.lith_block_init.name = 'final block of lithologies init'
+
+        # Init df block. Here we store the block and potential field results of one iteration
+        self.fault_block_init = T.zeros((2, self.grid_val_T.shape[0] + 2 * self.len_points))
+        self.fault_block_init.name = 'final block of df init'
+        self.yet_simulated = T.nonzero(T.eq(self.fault_block_init[0, :], 0))[0]
+
+        # Init gradient block.
+        self.gradient_block_init = T.zeros((3, self.grid_val_T.shape[0] + 2 * self.len_points))
+        self.gradient_block_init.name = 'final block of gradient init'
+        self.gradients = []
+
+        # Here we store the value of the potential field at surface_points
+        self.pfai_fault = T.zeros((0, self.n_surfaces_per_series[-1]))
+        self.pfai_lith = T.zeros((0, self.n_surfaces_per_series[-1]))
+
+        self.fault_matrix = T.zeros((0, self.grid_val_T.shape[0] + 2 * self.len_points))
+
+        # GRAVITY
+        # -------
+        if output is 'gravity':
+            self.densities = aesara.shared(np.cast[dtype](np.zeros(3)), "List with the densities")
+            self.tz = aesara.shared(np.cast[dtype](np.zeros((1, 3))), "Component z")
+            self.select = aesara.shared(np.cast['int8'](np.zeros(3)), "Select nearby cells")
+            # Init gray voxels for gravity
+            self.weigths_weigths = aesara.shared(np.ones(0))
+            self.weigths_index = aesara.shared(np.ones(0, dtype='int32'))
+
+        self.weights = aesara.shared(None)
+
+    def set_rest_ref_matrix(self):
+        ref_positions = T.cumsum(T.concatenate((T.stack(0), self.number_of_points_per_surface_T[:-1] + 1)))
+        ref_points = T.repeat(self.surface_points[ref_positions], self.number_of_points_per_surface_T, axis=0)
+
+        rest_mask = T.ones(T.stack(self.surface_points.shape[0]), dtype='int16')
+        rest_mask = T.set_subtensor(rest_mask[ref_positions], 0)
+        rest_points = self.surface_points[T.nonzero(rest_mask)[0]]
+        return [ref_points, rest_points, rest_mask, T.nonzero(rest_mask)[0]]
+
+    def input_parameters_list(self):
+        """
+        Create a list with the symbolic variables to use when we compile the aesara function
+
+        Returns:
+            list: [self.dips_position_all, self.dip_angles_all, self.azimuth_all, self.polarity_all,
+                   self.ref_layer_points_all, self.rest_layer_points_all]
+        """
+        ipl = [self.dips_position_all, self.dip_angles_all, self.azimuth_all, self.polarity_all, self.surface_points]
+               #self.ref_layer_points_all, self.rest_layer_points_all]
+        return ipl
+
+    @staticmethod
+    def squared_euclidean_distances(x_1, x_2):
+        """
+        Compute the euclidian distances in 3D between all the points in x_1 and x_2
+
+        Args:
+            x_1 (aesara.tensor.matrix): shape n_points x number dimension
+            x_2 (aesara.tensor.matrix): shape n_points x number dimension
+
+        Returns:
+            aesara.tensor.matrix: Distancse matrix. shape n_points x n_points
+        """
+
+        # T.maximum avoid negative numbers increasing stability
+        sqd = T.sqrt(T.maximum(
+            (x_1**2).sum(1).reshape((x_1.shape[0], 1)) +
+            (x_2**2).sum(1).reshape((1, x_2.shape[0])) -
+            2 * x_1.dot(x_2.T), 1e-12
+        ))
+
+        if False:
+            sqd = aesara.printing.Print('sed')(sqd)
+
+        return sqd
+
+    def matrices_shapes(self):
+        """
+        Get all the lengths of the matrices that form the covariance matrix
+
+        Returns:
+             length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C
+        """
+
+        # Calculating the dimensions of the
+        length_of_CG = self.dips_position_tiled.shape[0]
+        length_of_CGI = self.rest_layer_points.shape[0]
+        length_of_U_I = self.n_universal_eq_T_op
+
+        # Self fault matrix contains the block and the potential field (I am not able to split them). Therefore we need
+        # to divide it by 2
+        length_of_faults = T.cast(self.fault_matrix.shape[0], 'int32')
+        length_of_C = length_of_CG + length_of_CGI + length_of_U_I + length_of_faults
+
+        if 'matrices_shapes' in self.verbose:
+            length_of_CG = aesara.printing.Print("length_of_CG")(length_of_CG)
+            length_of_CGI = aesara.printing.Print("length_of_CGI")(length_of_CGI)
+            length_of_U_I = aesara.printing.Print("length_of_U_I")(length_of_U_I)
+            length_of_faults = aesara.printing.Print("length_of_faults")(length_of_faults)
+            length_of_C = aesara.printing.Print("length_of_C")(length_of_C)
+
+        return length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C
+
+    def cov_surface_points(self):
+        """
+        Create covariance function for the surface_points
+
+        Returns:
+            aesara.tensor.matrix: covariance of the surface_points. Shape number of points in rest x number of
+            points in rest
+
+        """
+
+        # Compute euclidian distances
+        sed_rest_rest = self.squared_euclidean_distances(self.rest_layer_points, self.rest_layer_points)
+        sed_ref_rest = self.squared_euclidean_distances(self.ref_layer_points, self.rest_layer_points)
+        sed_rest_ref = self.squared_euclidean_distances(self.rest_layer_points, self.ref_layer_points)
+        sed_ref_ref = self.squared_euclidean_distances(self.ref_layer_points, self.ref_layer_points)
+
+        # Covariance matrix for surface_points
+        C_I = (self.c_o_T * self.i_reescale * (
+            (sed_rest_rest < self.a_T) *  # Rest - Rest Covariances Matrix
+            (1 - 7 * (sed_rest_rest / self.a_T) ** 2 +
+             35 / 4 * (sed_rest_rest / self.a_T) ** 3 -
+             7 / 2 * (sed_rest_rest / self.a_T) ** 5 +
+             3 / 4 * (sed_rest_rest / self.a_T) ** 7) -
+            ((sed_ref_rest < self.a_T) *  # Reference - Rest
+             (1 - 7 * (sed_ref_rest / self.a_T) ** 2 +
+              35 / 4 * (sed_ref_rest / self.a_T) ** 3 -
+              7 / 2 * (sed_ref_rest / self.a_T) ** 5 +
+              3 / 4 * (sed_ref_rest / self.a_T) ** 7)) -
+            ((sed_rest_ref < self.a_T) *  # Rest - Reference
+             (1 - 7 * (sed_rest_ref / self.a_T) ** 2 +
+              35 / 4 * (sed_rest_ref / self.a_T) ** 3 -
+              7 / 2 * (sed_rest_ref / self.a_T) ** 5 +
+              3 / 4 * (sed_rest_ref / self.a_T) ** 7)) +
+            ((sed_ref_ref < self.a_T) *  # Reference - References
+             (1 - 7 * (sed_ref_ref / self.a_T) ** 2 +
+              35 / 4 * (sed_ref_ref / self.a_T) ** 3 -
+              7 / 2 * (sed_ref_ref / self.a_T) ** 5 +
+              3 / 4 * (sed_ref_ref / self.a_T) ** 7))))
+
+        C_I += T.eye(C_I.shape[0]) * 2 * self.nugget_effect_scalar_T
+        # Add name to the aesara node
+        C_I.name = 'Covariance SurfacePoints'
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            C_I = aesara.printing.Print('Cov surface_points')(C_I)
+
+        return C_I
+
+    def cov_gradients(self, verbose=0):
+        """
+         Create covariance function for the gradients
+
+         Returns:
+             aesara.tensor.matrix: covariance of the gradients. Shape number of points in dip_pos x number of
+             points in dip_pos
+
+         """
+
+        # Euclidean distances
+        sed_dips_dips = self.squared_euclidean_distances(self.dips_position_tiled, self.dips_position_tiled)
+
+        if 'sed_dips_dips' in self.verbose:
+            sed_dips_dips = aesara.printing.Print('sed_dips_dips')(sed_dips_dips)
+
+        # Cartesian distances between dips positions
+        h_u = T.vertical_stack(
+            T.tile(self.dips_position[:, 0] - self.dips_position[:, 0].reshape((self.dips_position[:, 0].shape[0], 1)),
+                   self.n_dimensions),
+            T.tile(self.dips_position[:, 1] - self.dips_position[:, 1].reshape((self.dips_position[:, 1].shape[0], 1)),
+                   self.n_dimensions),
+            T.tile(self.dips_position[:, 2] - self.dips_position[:, 2].reshape((self.dips_position[:, 2].shape[0], 1)),
+                   self.n_dimensions))
+
+        # Transpose
+        h_v = h_u.T
+
+        # Perpendicularity matrix. Boolean matrix to separate cross-covariance and
+        # every gradient direction covariance (block diagonal)
+        perpendicularity_matrix = T.zeros_like(sed_dips_dips)
+
+        # Cross-covariances of x
+        perpendicularity_matrix = T.set_subtensor(
+            perpendicularity_matrix[0:self.dips_position.shape[0], 0:self.dips_position.shape[0]], 1)
+
+        # Cross-covariances of y
+        perpendicularity_matrix = T.set_subtensor(
+            perpendicularity_matrix[self.dips_position.shape[0]:self.dips_position.shape[0] * 2,
+            self.dips_position.shape[0]:self.dips_position.shape[0] * 2], 1)
+
+        # Cross-covariances of z
+        perpendicularity_matrix = T.set_subtensor(
+            perpendicularity_matrix[self.dips_position.shape[0] * 2:self.dips_position.shape[0] * 3,
+            self.dips_position.shape[0] * 2:self.dips_position.shape[0] * 3], 1)
+
+        # Covariance matrix for gradients at every xyz direction and their cross-covariances
+        C_G = T.switch(
+            T.eq(sed_dips_dips, 0),  # This is the condition
+            0,  # If true it is equal to 0. This is how a direction affect another
+            (  # else, following Chiles book
+                (h_u * h_v / sed_dips_dips ** 2) *
+                ((
+                     (sed_dips_dips < self.a_T) *  # first derivative
+                     (-self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_dips / self.a_T ** 3 -
+                                     35 / 2 * sed_dips_dips ** 3 / self.a_T ** 5 +
+                                     21 / 4 * sed_dips_dips ** 5 / self.a_T ** 7))) +
+                 (sed_dips_dips < self.a_T) *  # Second derivative
+                 self.c_o_T * 7 * (9 * sed_dips_dips ** 5 - 20 * self.a_T ** 2 * sed_dips_dips ** 3 +
+                                   15 * self.a_T ** 4 * sed_dips_dips - 4 * self.a_T ** 5) / (2 * self.a_T ** 7)) -
+                (perpendicularity_matrix *
+                 (sed_dips_dips < self.a_T) *  # first derivative
+                 self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_dips / self.a_T ** 3 -
+                               35 / 2 * sed_dips_dips ** 3 / self.a_T ** 5 +
+                               21 / 4 * sed_dips_dips ** 5 / self.a_T ** 7)))
+        )
+
+        # Setting nugget effect of the gradients
+        # TODO: This function can be substitued by simply adding the nugget effect to the diag if I remove the condition
+        C_G += T.eye(C_G.shape[0])*self.nugget_effect_grad_T
+
+        # Add name to the aesara node
+        C_G.name = 'Covariance Gradient'
+
+        if verbose > 1:
+            aesara.printing.pydotprint(C_G, outfile="graphs/" + sys._getframe().f_code.co_name + ".png",
+                                       var_with_name_simple=True)
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            C_G = aesara.printing.Print('Cov Gradients')(C_G)
+
+        return C_G
+
+    def cov_interface_gradients(self):
+        """
+        Create covariance function for the gradiens
+        Returns:
+            aesara.tensor.matrix: covariance of the gradients. Shape number of points in rest x number of
+              points in dip_pos
+        """
+
+        # Euclidian distances
+        sed_dips_rest = self.squared_euclidean_distances(self.dips_position_tiled, self.rest_layer_points)
+        sed_dips_ref  = self.squared_euclidean_distances(self.dips_position_tiled, self.ref_layer_points)
+
+        # Cartesian distances between dips and interface points
+        # Rest
+        hu_rest = T.vertical_stack(
+            (self.dips_position[:, 0] - self.rest_layer_points[:, 0].reshape(
+                (self.rest_layer_points[:, 0].shape[0], 1))).T,
+            (self.dips_position[:, 1] - self.rest_layer_points[:, 1].reshape(
+                (self.rest_layer_points[:, 1].shape[0], 1))).T,
+            (self.dips_position[:, 2] - self.rest_layer_points[:, 2].reshape(
+                (self.rest_layer_points[:, 2].shape[0], 1))).T
+        )
+
+        # Reference point
+        hu_ref = T.vertical_stack(
+            (self.dips_position[:, 0] - self.ref_layer_points[:, 0].reshape(
+                (self.ref_layer_points[:, 0].shape[0], 1))).T,
+            (self.dips_position[:, 1] - self.ref_layer_points[:, 1].reshape(
+                (self.ref_layer_points[:, 1].shape[0], 1))).T,
+            (self.dips_position[:, 2] - self.ref_layer_points[:, 2].reshape(
+                (self.ref_layer_points[:, 2].shape[0], 1))).T
+        )
+
+        # Cross-Covariance gradients-surface_points
+        C_GI = self.gi_reescale * (
+            (hu_rest *
+             (sed_dips_rest < self.a_T) *  # first derivative
+             (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_rest / self.a_T ** 3 -
+                              35 / 2 * sed_dips_rest ** 3 / self.a_T ** 5 +
+                              21 / 4 * sed_dips_rest ** 5 / self.a_T ** 7))) -
+            (hu_ref *
+             (sed_dips_ref < self.a_T) *  # first derivative
+             (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_ref / self.a_T ** 3 -
+                              35 / 2 * sed_dips_ref ** 3 / self.a_T ** 5 +
+                              21 / 4 * sed_dips_ref ** 5 / self.a_T ** 7)))
+        ).T
+
+        # Add name to the aesara node
+        C_GI.name = 'Covariance gradient interface'
+
+        if str(sys._getframe().f_code.co_name)+'_g' in self.verbose:
+            aesara.printing.pydotprint(C_GI, outfile="graphs/" + sys._getframe().f_code.co_name + ".png",
+                                       var_with_name_simple=True)
+        return C_GI
+
+    def universal_matrix(self):
+        """
+        Create the drift matrices for the potential field and its gradient
+
+        Returns:
+            aesara.tensor.matrix: Drift matrix for the surface_points. Shape number of points in rest x 3**degree drift
+            (except degree 0 that is 0)
+
+            aesara.tensor.matrix: Drift matrix for the gradients. Shape number of points in dips x 3**degree drift
+            (except degree 0 that is 0)
+        """
+
+        # Condition of universality 2 degree
+        # Gradients
+
+        n = self.dips_position.shape[0]
+        U_G = T.zeros((n * self.n_dimensions, 3 * self.n_dimensions))
+        # x
+        U_G = T.set_subtensor(U_G[:n, 0], 1)
+        # y
+        U_G = T.set_subtensor(U_G[n * 1:n * 2, 1], 1)
+        # z
+        U_G = T.set_subtensor(U_G[n * 2: n * 3, 2], 1)
+        # x**2
+        U_G = T.set_subtensor(U_G[:n, 3], 2 * self.gi_reescale * self.dips_position[:, 0])
+        # y**2
+        U_G = T.set_subtensor(U_G[n * 1:n * 2, 4], 2 * self.gi_reescale * self.dips_position[:, 1])
+        # z**2
+        U_G = T.set_subtensor(U_G[n * 2: n * 3, 5], 2 * self.gi_reescale * self.dips_position[:, 2])
+        # xy
+        U_G = T.set_subtensor(U_G[:n, 6], self.gi_reescale * self.dips_position[:, 1])  # This is y
+        U_G = T.set_subtensor(U_G[n * 1:n * 2, 6], self.gi_reescale * self.dips_position[:, 0])  # This is x
+        # xz
+        U_G = T.set_subtensor(U_G[:n, 7], self.gi_reescale * self.dips_position[:, 2])  # This is z
+        U_G = T.set_subtensor(U_G[n * 2: n * 3, 7], self.gi_reescale * self.dips_position[:, 0])  # This is x
+        # yz
+        U_G = T.set_subtensor(U_G[n * 1:n * 2, 8], self.gi_reescale * self.dips_position[:, 2])  # This is z
+        U_G = T.set_subtensor(U_G[n * 2:n * 3, 8], self.gi_reescale * self.dips_position[:, 1])  # This is y
+
+        # Interface
+        U_I = - T.stack(
+            (self.gi_reescale * (self.rest_layer_points[:, 0] - self.ref_layer_points[:, 0]),
+             self.gi_reescale * (self.rest_layer_points[:, 1] - self.ref_layer_points[:, 1]),
+             self.gi_reescale * (self.rest_layer_points[:, 2] - self.ref_layer_points[:, 2]),
+             self.gi_reescale ** 2 * (self.rest_layer_points[:, 0] ** 2 - self.ref_layer_points[:, 0] ** 2),
+             self.gi_reescale ** 2 * (self.rest_layer_points[:, 1] ** 2 - self.ref_layer_points[:, 1] ** 2),
+             self.gi_reescale ** 2 * (self.rest_layer_points[:, 2] ** 2 - self.ref_layer_points[:, 2] ** 2),
+             self.gi_reescale ** 2 * (
+                 self.rest_layer_points[:, 0] * self.rest_layer_points[:, 1] - self.ref_layer_points[:, 0] *
+                 self.ref_layer_points[:, 1]),
+             self.gi_reescale ** 2 * (
+                 self.rest_layer_points[:, 0] * self.rest_layer_points[:, 2] - self.ref_layer_points[:, 0] *
+                 self.ref_layer_points[:, 2]),
+             self.gi_reescale ** 2 * (
+                 self.rest_layer_points[:, 1] * self.rest_layer_points[:, 2] - self.ref_layer_points[:, 1] *
+                 self.ref_layer_points[:, 2]),
+             )).T
+
+        if 'U_I' in self.verbose:
+            U_I = aesara.printing.Print('U_I')(U_I)
+
+        if 'U_G' in self.verbose:
+            U_G = aesara.printing.Print('U_G')(U_G)
+
+        if str(sys._getframe().f_code.co_name)+'_g' in self.verbose:
+            aesara.printing.pydotprint(U_I, outfile="graphs/" + sys._getframe().f_code.co_name + "_i.png",
+                                       var_with_name_simple=True)
+
+            aesara.printing.pydotprint(U_G, outfile="graphs/" + sys._getframe().f_code.co_name + "_g.png",
+                                       var_with_name_simple=True)
+
+        # Add name to the aesara node
+        if U_I:
+            U_I.name = 'Drift surface_points'
+            U_G.name = 'Drift foliations'
+
+        return U_I[:, :self.n_universal_eq_T_op], U_G[:, :self.n_universal_eq_T_op]
+
+    def faults_matrix(self):
+        """
+        This function creates the part of the graph that generates the df function creating a "block model" at the
+        references and the rest of the points. Then this vector has to be appended to the covariance function
+
+        Returns:
+
+            list:
+
+            - aesara.tensor.matrix: Drift matrix for the surface_points. Shape number of points in rest x n df. This drif
+              is a simple addition of an arbitrary number
+
+            - aesara.tensor.matrix: Drift matrix for the gradients. Shape number of points in dips x n df. For
+              discrete values this matrix will be null since the derivative of a constant is 0
+        """
+
+        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults = self.matrices_shapes()[:4]
+
+        # self.fault_matrix contains the df volume of the grid and the rest and ref points. For the drift we need
+        # to make it relative to the reference point
+        if 'fault matrix' in self.verbose:
+            self.fault_matrix = aesara.printing.Print('self.fault_matrix')(self.fault_matrix)
+        interface_loc = self.fault_matrix.shape[1] - 2 * self.len_points
+
+        fault_matrix_at_surface_points_rest = self.fault_matrix[:,
+                                          interface_loc + self.len_i_0: interface_loc + self.len_i_1]
+        fault_matrix_at_surface_points_ref = self.fault_matrix[:,
+                                         interface_loc + self.len_points + self.len_i_0: interface_loc + self.len_points + self.len_i_1]
+
+        F_I = (fault_matrix_at_surface_points_ref - fault_matrix_at_surface_points_rest)+0.0001
+
+        # As long as the drift is a constant F_G is null
+        F_G = T.zeros((length_of_faults, length_of_CG)) + 0.0001
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            F_I = aesara.printing.Print('Faults surface_points matrix')(F_I)
+            F_G = aesara.printing.Print('Faults gradients matrix')(F_G)
+
+        return F_I, F_G
+
+    def covariance_matrix(self):
+        """
+        Set all the previous covariances together in the universal cokriging matrix
+
+        Returns:
+            aesara.tensor.matrix: Multivariate covariance
+        """
+
+        # Lengths
+        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C = self.matrices_shapes()
+
+        # Individual matrices
+        C_G = self.cov_gradients()
+        C_I = self.cov_surface_points()
+        C_GI = self.cov_interface_gradients()
+        U_I, U_G = self.universal_matrix()
+        F_I, F_G = self.faults_matrix()
+
+        # =================================
+        # Creation of the Covariance Matrix
+        # =================================
+        C_matrix = T.zeros((length_of_C, length_of_C))
+
+        # First row of matrices
+        # Set C_G
+        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG, 0:length_of_CG], C_G)
+        # Set CGI
+        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG, length_of_CG:length_of_CG + length_of_CGI], C_GI.T)
+        # Set UG
+        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG,
+                                   length_of_CG+length_of_CGI:length_of_CG+length_of_CGI+length_of_U_I], U_G)
+        # Set FG. I cannot use -index because when is -0 is equivalent to 0
+        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG, length_of_CG+length_of_CGI+length_of_U_I:], F_G.T)
+        # Second row of matrices
+        # Set C_IG
+        C_matrix = T.set_subtensor(C_matrix[length_of_CG:length_of_CG + length_of_CGI, 0:length_of_CG], C_GI)
+        # Set C_I
+        C_matrix = T.set_subtensor(C_matrix[length_of_CG:length_of_CG + length_of_CGI,
+                                   length_of_CG:length_of_CG + length_of_CGI], C_I)
+        # Set U_I
+        #if not self.u_grade_T.get_value() == 0:
+        C_matrix = T.set_subtensor(C_matrix[length_of_CG:length_of_CG + length_of_CGI,
+                                   length_of_CG+length_of_CGI:length_of_CG+length_of_CGI+length_of_U_I], U_I)
+        # Set F_I
+        C_matrix = T.set_subtensor(C_matrix[length_of_CG:length_of_CG + length_of_CGI, length_of_CG+length_of_CGI+length_of_U_I:], F_I.T)
+        # Third row of matrices
+        # Set U_G
+        C_matrix = T.set_subtensor(C_matrix[length_of_CG+length_of_CGI:length_of_CG+length_of_CGI+length_of_U_I, 0:length_of_CG], U_G.T)
+        # Set U_I
+        C_matrix = T.set_subtensor(C_matrix[length_of_CG+length_of_CGI:length_of_CG+length_of_CGI+length_of_U_I, length_of_CG:length_of_CG + length_of_CGI], U_I.T)
+        # Fourth row of matrices
+        # Set F_G
+        C_matrix = T.set_subtensor(C_matrix[length_of_CG+length_of_CGI+length_of_U_I:, 0:length_of_CG], F_G)
+        # Set F_I
+        C_matrix = T.set_subtensor(C_matrix[length_of_CG+length_of_CGI+length_of_U_I:, length_of_CG:length_of_CG + length_of_CGI], F_I)
+        # Add name to the aesara node
+        C_matrix.name = 'Block Covariance Matrix'
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            C_matrix = aesara.printing.Print('cov_function')(C_matrix)
+
+        return C_matrix
+
+    def b_vector(self):
+        """
+        Creation of the independent vector b to solve the kriging system
+
+        Args:
+            verbose: -deprecated-
+
+        Returns:
+            aesara.tensor.vector: independent vector
+        """
+
+        length_of_C = self.matrices_shapes()[-1]
+        # =====================
+        # Creation of the gradients G vector
+        # Calculation of the cartesian components of the dips assuming the unit module
+        G_x = T.sin(T.deg2rad(self.dip_angles)) * T.sin(T.deg2rad(self.azimuth)) * self.polarity
+        G_y = T.sin(T.deg2rad(self.dip_angles)) * T.cos(T.deg2rad(self.azimuth)) * self.polarity
+        G_z = T.cos(T.deg2rad(self.dip_angles)) * self.polarity
+
+        G = T.concatenate((G_x, G_y, G_z))
+
+        # Creation of the Dual Kriging vector
+        b = T.zeros((length_of_C,))
+        b = T.set_subtensor(b[0:G.shape[0]], G)
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            b = aesara.printing.Print('b vector')(b)
+
+        # Add name to the aesara node
+        b.name = 'b vector'
+        return b
+
+    def solve_kriging(self):
+        """
+        Solve the kriging system. This has to get substituted by a more efficient and stable method QR
+        decomposition in all likelihood
+
+        Returns:
+            aesara.tensor.vector: Dual kriging parameters
+
+        """
+        C_matrix = self.covariance_matrix()
+        b = self.b_vector()
+        # Solving the kriging system
+        import aesara.tensor .slinalg
+        b2 = T.tile(b, (1, 1)).T
+        DK_parameters = aesara.tensor.slinalg.solve(C_matrix, b2)
+        DK_parameters = DK_parameters.reshape((DK_parameters.shape[0],))
+
+        # Add name to the aesara node
+        DK_parameters.name = 'Dual Kriging parameters'
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            DK_parameters = aesara.printing.Print(DK_parameters.name)(DK_parameters)
+        return DK_parameters
+
+    def x_to_interpolate(self, verbose=0):
+        """
+        here I add to the grid points also the references points(to check the value of the potential field at the
+        surface_points). Also here I will check what parts of the grid have been already computed in a previous series
+        to avoid to recompute.
+
+        Returns:
+            aesara.tensor.matrix: The 3D points of the given grid plus the reference and rest points
+        """
+
+        grid_val = T.concatenate([self.grid_val_T, self.rest_layer_points_all,
+                                  self.ref_layer_points_all])[self.yet_simulated, :]
+
+        if verbose > 1:
+            aesara.printing.pydotprint(grid_val, outfile="graphs/" + sys._getframe().f_code.co_name + ".png",
+                                       var_with_name_simple=True)
+
+        if 'grid_val' in self.verbose:
+            grid_val = aesara.printing.Print('Points to interpolate')(grid_val)
+
+        return grid_val
+
+    def extend_dual_kriging(self):
+        """
+        Tile the dual kriging vector to cover all the points to interpolate.So far I just make a matrix with the
+        dimensions len(DK)x(grid) but in the future maybe I have to try to loop all this part so consume less memory
+
+        Returns:
+            aesara.tensor.matrix: Matrix with the Dk parameters repeated for all the points to interpolate
+        """
+
+        grid_val = self.x_to_interpolate()
+        if self.weights.get_value() is None:
+            DK_parameters = self.solve_kriging()
+        else:
+            DK_parameters = self.weights
+        # Creation of a matrix of dimensions equal to the grid with the weights for every point (big 4D matrix in
+        # ravel form)
+        # TODO IMP: Change the tile by a simple dot op -> The DOT version in gpu is slower
+        DK_weights = T.tile(DK_parameters, (grid_val.shape[0], 1)).T
+
+        if self.dot_version:
+            DK_weights = DK_parameters
+
+        return DK_weights
+
+    def contribution_gradient_interface(self, grid_val=None, weights=None):
+        """
+        Computation of the contribution of the foliations at every point to interpolate
+
+        Returns:
+            aesara.tensor.vector: Contribution of all foliations (input) at every point to interpolate
+        """
+        if weights is None:
+            weights = self.extend_dual_kriging()
+        if grid_val is None:
+            grid_val = self.x_to_interpolate()
+
+        length_of_CG = self.matrices_shapes()[0]
+
+        # Cartesian distances between the point to simulate and the dips
+        hu_SimPoint = T.vertical_stack(
+            (self.dips_position[:, 0] - grid_val[:, 0].reshape((grid_val[:, 0].shape[0], 1))).T,
+            (self.dips_position[:, 1] - grid_val[:, 1].reshape((grid_val[:, 1].shape[0], 1))).T,
+            (self.dips_position[:, 2] - grid_val[:, 2].reshape((grid_val[:, 2].shape[0], 1))).T
+        )
+
+        # Euclidian distances
+        sed_dips_SimPoint = self.squared_euclidean_distances(self.dips_position_tiled, grid_val)
+        # Gradient contribution
+        sigma_0_grad = T.sum(
+            (weights[:length_of_CG] *
+             self.gi_reescale *
+             (-hu_SimPoint *
+              (sed_dips_SimPoint < self.a_T) *  # first derivative
+              (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_SimPoint / self.a_T ** 3 -
+                               35 / 2 * sed_dips_SimPoint ** 3 / self.a_T ** 5 +
+                               21 / 4 * sed_dips_SimPoint ** 5 / self.a_T ** 7)))),
+            axis=0)
+
+        if self.dot_version:
+            sigma_0_grad = T.dot(
+                weights[:length_of_CG] ,
+                 self.gi_reescale *
+                 (-hu_SimPoint *
+                  (sed_dips_SimPoint < self.a_T) *  # first derivative
+                  (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_SimPoint / self.a_T ** 3 -
+                                   35 / 2 * sed_dips_SimPoint ** 3 / self.a_T ** 5 +
+                                   21 / 4 * sed_dips_SimPoint ** 5 / self.a_T ** 7))))
+
+        # Add name to the aesara node
+        sigma_0_grad.name = 'Contribution of the foliations to the potential field at every point of the grid'
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            sigma_0_grad = aesara.printing.Print('interface_gradient_contribution')(sigma_0_grad)
+
+        return sigma_0_grad
+
+    def contribution_interface_gradient(self, direction='x', grid_val=None, weights=None):
+        """
+        Computation of the contribution of the foliations at every point to interpolate
+
+        Returns:
+            aesara.tensor.vector: Contribution of all foliations (input) at every point to interpolate
+        """
+
+        if direction == 'x':
+            dir_val = 0
+        elif direction == 'y':
+            dir_val = 1
+        elif direction == 'z':
+            dir_val = 2
+        else:
+            raise AttributeError('Directions muxt be x, y or z')
+
+        if weights is None:
+            weights = self.extend_dual_kriging()
+        if grid_val is None:
+            grid_val = self.x_to_interpolate()
+
+        length_of_CG, length_of_CGI = self.matrices_shapes()[:2]
+
+        # Cartesian distances between the point to simulate and the dips
+        hu_rest = (- self.rest_layer_points[:, dir_val] + grid_val[:, dir_val].reshape((grid_val[:, dir_val].shape[0], 1)))
+        hu_ref = (- self.ref_layer_points[:, dir_val] + grid_val[:, dir_val].reshape((grid_val[:, dir_val].shape[0], 1)))
+
+        # Euclidian distances
+
+        sed_grid_rest = self.squared_euclidean_distances(grid_val, self.rest_layer_points)
+        sed_grid_ref = self.squared_euclidean_distances(grid_val, self.ref_layer_points)
+
+        # Gradient contribution
+        self.gi_reescale = 2
+
+        sigma_0_grad = T.sum(
+            (weights[length_of_CG:length_of_CG + length_of_CGI] *
+             self.gi_reescale * (
+                 (hu_rest *
+                  (sed_grid_rest < self.a_T) *  # first derivative
+                  (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_grid_rest / self.a_T ** 3 -
+                                   35 / 2 * sed_grid_rest ** 3 / self.a_T ** 5 +
+                                   21 / 4 * sed_grid_rest ** 5 / self.a_T ** 7))) -
+            (hu_ref *
+             (sed_grid_ref < self.a_T) *  # first derivative
+             (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_grid_ref / self.a_T ** 3 -
+                              35 / 2 * sed_grid_ref ** 3 / self.a_T ** 5 +
+                              21 / 4 * sed_grid_ref ** 5 / self.a_T ** 7)))).T),
+            axis=0)
+
+        return sigma_0_grad
+
+    def contribution_interface(self, grid_val=None, weights=None):
+        """
+          Computation of the contribution of the surface_points at every point to interpolate
+
+          Returns:
+              aesara.tensor.vector: Contribution of all surface_points (input) at every point to interpolate
+          """
+
+        if weights is None:
+            weights = self.extend_dual_kriging()
+        if grid_val is None:
+            grid_val = self.x_to_interpolate()
+        length_of_CG, length_of_CGI = self.matrices_shapes()[:2]
+
+        # Euclidian distances
+        sed_rest_SimPoint = self.squared_euclidean_distances(self.rest_layer_points, grid_val)
+        sed_ref_SimPoint = self.squared_euclidean_distances(self.ref_layer_points, grid_val)
+
+        # Interface contribution
+        sigma_0_interf = (T.sum(
+            -weights[length_of_CG:length_of_CG + length_of_CGI, :] *
+            (self.c_o_T * self.i_reescale * (
+                    (sed_rest_SimPoint < self.a_T) *  # SimPoint - Rest Covariances Matrix
+                    (1 - 7 * (sed_rest_SimPoint / self.a_T) ** 2 +
+                     35 / 4 * (sed_rest_SimPoint / self.a_T) ** 3 -
+                     7 / 2 * (sed_rest_SimPoint / self.a_T) ** 5 +
+                     3 / 4 * (sed_rest_SimPoint / self.a_T) ** 7) -
+                    ((sed_ref_SimPoint < self.a_T) *  # SimPoint- Ref
+                     (1 - 7 * (sed_ref_SimPoint / self.a_T) ** 2 +
+                      35 / 4 * (sed_ref_SimPoint / self.a_T) ** 3 -
+                      7 / 2 * (sed_ref_SimPoint / self.a_T) ** 5 +
+                      3 / 4 * (sed_ref_SimPoint / self.a_T) ** 7)))), axis=0))
+
+        if self.dot_version:
+            sigma_0_interf = (
+                T.dot(-weights[length_of_CG:length_of_CG + length_of_CGI],
+                      (self.c_o_T * self.i_reescale * (
+                              (sed_rest_SimPoint < self.a_T) *  # SimPoint - Rest Covariances Matrix
+                              (1 - 7 * (sed_rest_SimPoint / self.a_T) ** 2 +
+                               35 / 4 * (sed_rest_SimPoint / self.a_T) ** 3 -
+                               7 / 2 * (sed_rest_SimPoint / self.a_T) ** 5 +
+                               3 / 4 * (sed_rest_SimPoint / self.a_T) ** 7) -
+                              ((sed_ref_SimPoint < self.a_T) *  # SimPoint- Ref
+                               (1 - 7 * (sed_ref_SimPoint / self.a_T) ** 2 +
+                                35 / 4 * (sed_ref_SimPoint / self.a_T) ** 3 -
+                                7 / 2 * (sed_ref_SimPoint / self.a_T) ** 5 +
+                                3 / 4 * (sed_ref_SimPoint / self.a_T) ** 7))))))
+
+        # Add name to the aesara node
+        sigma_0_interf.name = 'Contribution of the surface_points to the potential field at every point of the grid'
+
+        return sigma_0_interf
+
+    def contribution_gradient(self, direction='x', grid_val=None, weights=None):
+
+        if direction == 'x':
+           direction_val = 0
+        if direction == 'y':
+            direction_val = 1
+        if direction == 'z':
+            direction_val = 2
+        self.gi_reescale = aesara.shared(1)
+
+
+        if weights is None:
+            weights = self.extend_dual_kriging()
+        if grid_val is None:
+            grid_val = self.x_to_interpolate()
+
+        length_of_CG = self.matrices_shapes()[0]
+
+        # Cartesian distances between the point to simulate and the dips
+        # TODO optimize to compute this only once?
+        # Euclidean distances
+        sed_dips_SimPoint = self.squared_euclidean_distances(grid_val, self.dips_position_tiled).T
+
+        if 'sed_dips_SimPoint' in self.verbose:
+            sed_dips_SimPoint = aesara.printing.Print('sed_dips_SimPoint')(sed_dips_SimPoint)
+
+        # Cartesian distances between dips positions
+        h_u = T.tile(self.dips_position[:, direction_val] - grid_val[:, direction_val].reshape((grid_val[:, direction_val].shape[0], 1)), 3)
+        h_v = T.horizontal_stack(
+            T.tile(self.dips_position[:, 0] - grid_val[:, 0].reshape((grid_val[:, 0].shape[0], 1)),
+                   1),
+            T.tile(self.dips_position[:, 1] - grid_val[:, 1].reshape((grid_val[:, 1].shape[0], 1)),
+                   1),
+            T.tile(self.dips_position[:, 2] - grid_val[:, 2].reshape((grid_val[:, 2].shape[0], 1)),
+                   1))
+
+        perpendicularity_vector = T.zeros(T.stack(length_of_CG))
+        perpendicularity_vector = T.set_subtensor(
+            perpendicularity_vector[self.dips_position.shape[0]*direction_val:self.dips_position.shape[0]*(direction_val+1)], 1)
+
+        sigma_0_grad = T.sum(
+            (weights[:length_of_CG] * (
+             ((-h_u * h_v).T/ sed_dips_SimPoint ** 2) *
+             ((
+                      (sed_dips_SimPoint < self.a_T) *  # first derivative
+                      (-self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_SimPoint / self.a_T ** 3 -
+                                      35 / 2 * sed_dips_SimPoint ** 3 / self.a_T ** 5 +
+                                      21 / 4 * sed_dips_SimPoint ** 5 / self.a_T ** 7))) +
+              (sed_dips_SimPoint < self.a_T) *  # Second derivative
+              self.c_o_T * 7 * (9 * sed_dips_SimPoint ** 5 - 20 * self.a_T ** 2 * sed_dips_SimPoint ** 3 +
+                                   15 * self.a_T ** 4 * sed_dips_SimPoint - 4 * self.a_T ** 5) / (2 * self.a_T ** 7)) -
+                (perpendicularity_vector.reshape((-1, 1)) *
+                                ((sed_dips_SimPoint < self.a_T) *  # first derivative
+                 self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_SimPoint / self.a_T ** 3 -
+                               35 / 2 * sed_dips_SimPoint ** 3 / self.a_T ** 5 +
+                               21 / 4 * sed_dips_SimPoint ** 5 / self.a_T ** 7)))
+
+              ))
+        , axis=0)
+
+        return sigma_0_grad
+
+    def contribution_universal_drift(self, grid_val=None, weights=None, a=0, b=100000000):
+        """
+        Computation of the contribution of the universal drift at every point to interpolate
+
+        Returns:
+            aesara.tensor.vector: Contribution of the universal drift (input) at every point to interpolate
+        """
+        if weights is None:
+            weights = self.extend_dual_kriging()
+        if grid_val is None:
+            grid_val = self.x_to_interpolate()
+
+        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C = self.matrices_shapes()
+
+        # Universal drift contribution
+        # universal_grid_surface_points_matrix = self.universal_grid_matrix_T[:, self.fault_mask[a: b]]
+
+        # Universal drift contribution
+        # Universal terms used to calculate f0
+        # Here I create the universal terms for rest and ref. The universal terms for the grid are done in python
+        # and append here. The idea is that the grid is kind of constant so I do not have to recompute it every
+        # time
+        # _universal_terms_surface_points_rest = T.horizontal_stack(
+        #     self.rest_layer_points_all,
+        #     (self.rest_layer_points_all ** 2),
+        #     T.stack((self.rest_layer_points_all[:, 0] * self.rest_layer_points_all[:, 1],
+        #              self.rest_layer_points_all[:, 0] * self.rest_layer_points_all[:, 2],
+        #              self.rest_layer_points_all[:, 1] * self.rest_layer_points_all[:, 2]), axis=1))
+        #
+        # _universal_terms_surface_points_ref = T.horizontal_stack(
+        #     self.ref_layer_points_all,
+        #     (self.ref_layer_points_all ** 2),
+        #     T.stack((self.ref_layer_points_all[:, 0] * self.ref_layer_points_all[:, 1],
+        #              self.ref_layer_points_all[:, 0] * self.ref_layer_points_all[:, 2],
+        #              self.ref_layer_points_all[:, 1] * self.ref_layer_points_all[:, 2]), axis=1),
+        # )
+        #
+        # # I append rest and ref to grid
+        # # universal_grid_surface_points_matrix = T.horizontal_stack(
+        # #     (self.universal_grid_matrix_T * self.fault_mask).nonzero_values().reshape((9, -1)),
+        # #     T.vertical_stack(_universal_terms_surface_points_rest, _universal_terms_surface_points_ref).T)
+        #
+        # universal_grid_surface_points_matrix = T.horizontal_stack(
+        #     self.universal_grid_matrix_T.reshape((9, -1)),
+        #     T.vertical_stack(_universal_terms_surface_points_rest, _universal_terms_surface_points_ref).T)
+
+        universal_grid_surface_points_matrix = T.horizontal_stack(
+             grid_val,
+            (grid_val ** 2),
+            T.stack((grid_val[:, 0] * grid_val[:, 1],
+                     grid_val[:, 0] * grid_val[:, 2],
+                     grid_val[:, 1] * grid_val[:, 2]), axis=1)).T
+
+
+        # These are the magic terms to get the same as geomodeller
+        i_rescale_aux = T.repeat(self.gi_reescale, 9)
+        i_rescale_aux = T.set_subtensor(i_rescale_aux[:3], 1)
+        _aux_magic_term = T.tile(i_rescale_aux[:self.n_universal_eq_T_op], (grid_val.shape[0], 1)).T
+
+        # Drif contribution
+        f_0 = (T.sum(
+            weights[length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I] * self.gi_reescale * _aux_magic_term *
+            universal_grid_surface_points_matrix[:self.n_universal_eq_T_op]
+            , axis=0))
+
+        if self.dot_version:
+            f_0 = T.dot(
+                weights[length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I] , self.gi_reescale * _aux_magic_term *
+                universal_grid_surface_points_matrix[:self.n_universal_eq_T_op])
+
+        if not type(f_0) == int:
+            f_0.name = 'Contribution of the universal drift to the potential field at every point of the grid'
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            f_0 = aesara.printing.Print('Universal terms contribution')(f_0)
+
+        return f_0
+
+    def contribution_universal_drift_d(self, direction='x', grid_val=None, weights=None, a=0, b=100000000):
+        if weights is None:
+            weights = self.extend_dual_kriging()
+        if grid_val is None:
+            grid_val = self.x_to_interpolate()
+
+        self.gi_reescale = aesara.shared(2)
+
+        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C = self.matrices_shapes()
+
+        # These are the magic terms to get the same as geomodeller
+        i_rescale_aux = T.repeat(self.gi_reescale, 9)
+        i_rescale_aux = T.set_subtensor(i_rescale_aux[:3], 1)
+        _aux_magic_term = T.tile(i_rescale_aux[:self.n_universal_eq_T_op], (grid_val.shape[0], 1))
+
+        n = self.dips_position.shape[0]
+        n = grid_val.shape[0]
+        U_G = T.zeros((n, 9))
+
+        if direction == 'x':
+
+            # x
+            U_G = T.set_subtensor(U_G[:, 0], 1)
+            # x**2
+            U_G = T.set_subtensor(U_G[:, 3], 2 * self.gi_reescale * grid_val[:, 0])
+
+            # xy
+            U_G = T.set_subtensor(U_G[:, 6], self.gi_reescale * grid_val[:, 1])  # This is y
+            # xz
+            U_G = T.set_subtensor(U_G[:, 7], self.gi_reescale * grid_val[:, 2])  # This is z
+
+        if direction == 'y':
+
+            # y
+            U_G = T.set_subtensor(U_G[:, 1], 1)
+            # y**2
+            U_G = T.set_subtensor(U_G[:, 4], 2 * self.gi_reescale * grid_val[:, 1])
+            # xy
+            U_G = T.set_subtensor(U_G[:, 6], self.gi_reescale * grid_val[:, 0])  # This is x
+            # yz
+            U_G = T.set_subtensor(U_G[:, 8], self.gi_reescale * grid_val[:, 2])  # This is z
+
+        if direction == 'z':
+            # z
+            U_G = T.set_subtensor(U_G[:, 2], 1)
+
+            # z**2
+            U_G = T.set_subtensor(U_G[:, 5], 2 * self.gi_reescale * grid_val[:, 2])
+
+            #xz
+            U_G = T.set_subtensor(U_G[:, 7], self.gi_reescale * grid_val[:, 0])  # This is x
+
+            # yz
+            U_G = T.set_subtensor(U_G[:, 8], self.gi_reescale * grid_val[:, 1])  # This is y
+
+        # Drif contribution
+        f_0 = (T.sum(
+            weights[
+            length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I] *
+            U_G.T[:self.n_universal_eq_T_op]
+            , axis=0))
+
+        return f_0
+
+    def faults_contribution(self, weights=None, a=0, b=100000000):
+        """
+        Computation of the contribution of the df drift at every point to interpolate. To get these we need to
+        compute a whole block model with the df data
+
+        Returns:
+            aesara.tensor.vector: Contribution of the df drift (input) at every point to interpolate
+        """
+        if weights is None:
+            weights = self.extend_dual_kriging()
+        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C = self.matrices_shapes()
+
+        fault_matrix_selection_non_zero = (self.fault_matrix[:, self.yet_simulated[a:b]]+1)
+
+        f_1 = T.sum(
+            weights[length_of_CG + length_of_CGI + length_of_U_I:, :] * fault_matrix_selection_non_zero, axis=0)
+
+        if self.dot_version:
+            f_1 = T.dot(
+                weights[length_of_CG + length_of_CGI + length_of_U_I:], fault_matrix_selection_non_zero)
+
+        # Add name to the aesara node
+        f_1.name = 'Faults contribution'
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            f_1 = aesara.printing.Print('Faults contribution')(f_1)
+
+        return f_1
+
+    def scalar_field_loop(self, a, b, Z_x, grid_val, weights, val):
+
+        sigma_0_grad = self.contribution_gradient_interface(grid_val[a:b], weights[:, a:b])
+        sigma_0_interf = self.contribution_interface(grid_val[a:b], weights[:, a:b])
+        f_0 = self.contribution_universal_drift(grid_val[a:b], weights[:, a:b], a, b)
+        f_1 = self.faults_contribution(weights[:, a:b], a, b)
+
+        # Add an arbitrary number at the potential field to get unique values for each of them
+        partial_Z_x = (sigma_0_grad + sigma_0_interf + f_0 + f_1 + 50 - (10 * val[0]))
+        Z_x = T.set_subtensor(Z_x[a:b], partial_Z_x)
+
+        return Z_x
+
+    def gradient_field_loop_x(self, a, b, Z_x, grid_val, weights, val):
+        direction = 'x'
+        sigma_0_grad = self.contribution_gradient(direction, grid_val[a:b], weights[:, a:b])
+        sigma_0_interf_gradient = self.contribution_interface_gradient(direction, grid_val[a:b], weights[:, a:b])
+        f_0 = self.contribution_universal_drift_d(direction, grid_val[a:b], weights[:, a:b], a, b)
+        #f_1 = self.faults_contribution(weights[:, a:b], a, b)
+
+        # Add an arbitrary number at the potential field to get unique values for each of them
+        partial_Z_x = (sigma_0_grad + sigma_0_interf_gradient + f_0)
+
+        Z_x = T.set_subtensor(Z_x[a:b], partial_Z_x)
+
+        return Z_x
+
+    def gradient_field_loop_y(self, a, b, Z_x, grid_val, weights, val):
+        direction = 'y'
+        sigma_0_grad = self.contribution_gradient(direction, grid_val[a:b], weights[:, a:b])
+        sigma_0_interf_gradient = self.contribution_interface_gradient(direction, grid_val[a:b], weights[:, a:b])
+        f_0 = self.contribution_universal_drift_d(direction, grid_val[a:b], weights[:, a:b], a, b)
+        #f_1 = self.faults_contribution(weights[:, a:b], a, b)
+
+        # Add an arbitrary number at the potential field to get unique values for each of them
+        partial_Z_x = (sigma_0_grad + sigma_0_interf_gradient + f_0)
+
+        Z_x = T.set_subtensor(Z_x[a:b], partial_Z_x)
+
+        return Z_x
+
+    def gradient_field_loop_z(self, a, b, Z_x, grid_val, weights, val):
+        direction = 'z'
+        sigma_0_grad = self.contribution_gradient(direction, grid_val[a:b], weights[:, a:b])
+        sigma_0_interf_gradient = self.contribution_interface_gradient(direction, grid_val[a:b], weights[:, a:b])
+        f_0 = self.contribution_universal_drift_d(direction, grid_val[a:b], weights[:, a:b], a, b)
+        #f_1 = self.faults_contribution(weights[:, a:b], a, b)
+
+        # Add an arbitrary number at the potential field to get unique values for each of them
+        partial_Z_x = (sigma_0_grad + sigma_0_interf_gradient + f_0)
+
+        Z_x = T.set_subtensor(Z_x[a:b], partial_Z_x)
+
+        return Z_x
+
+    def scalar_field_at_all(self, weights=None):
+        """
+        Compute the potential field at all the interpolation points, i.e. grid plus rest plus ref
+        Returns:
+            aesara.tensor.vector: Potential fields at all points
+
+        """
+        grid_val = self.x_to_interpolate()
+
+        if weights is None:
+            weights = self.extend_dual_kriging()
+
+        grid_shape = T.stack(grid_val.shape[0])
+        Z_x_init = T.zeros(grid_shape, dtype='float32')
+        if 'grid_shape' in self.verbose:
+            grid_shape = aesara.printing.Print('grid_shape')(grid_shape)
+
+        steps = 1e13/self.matrices_shapes()[-1]/grid_shape
+        slices = T.concatenate((T.arange(0, grid_shape[0], steps[0], dtype='int64'), grid_shape))
+
+        if 'slices' in self.verbose:
+            slices = aesara.printing.Print('slices')(slices)
+
+        Z_x_loop, updates3 = aesara.scan(
+            fn=self.scalar_field_loop,
+            outputs_info=[Z_x_init],
+            sequences=[dict(input=slices, taps=[0, 1])],
+            non_sequences=[grid_val, weights, self.n_surface_op],
+            profile=False,
+            name='Looping grid',
+            return_list=True)
+
+        Z_x = Z_x_loop[-1][-1]
+        Z_x.name = 'Value of the potential field at every point'
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            Z_x = aesara.printing.Print('Potential field at all points')(Z_x)
+
+        return Z_x
+
+    def gradient_field_at_all(self, weights=None, gradients=[]):
+
+        grid_val = self.x_to_interpolate()
+        if weights is None:
+            weights = self.extend_dual_kriging()
+
+        grid_shape = T.stack(grid_val.shape[0])
+
+        Z_x_init = T.zeros(grid_shape, dtype='float32')
+        if 'grid_shape' in self.verbose:
+            grid_shape = aesara.printing.Print('grid_shape')(grid_shape)
+
+        steps = 1e13 / self.matrices_shapes()[-1] / grid_shape
+        slices = T.concatenate((T.arange(0, grid_shape[0], steps[0], dtype='int64'), grid_shape))
+
+        if 'slices' in self.verbose:
+            slices = aesara.printing.Print('slices')(slices)
+
+        G_field = T.zeros((3, self.grid_val_T.shape[0]))
+
+        if 'Gx' in gradients:
+            Gx_loop, updates5 = aesara.scan(
+                fn=self.gradient_field_loop_x,
+                outputs_info=[Z_x_init],
+                sequences=[dict(input=slices, taps=[0, 1])],
+                non_sequences=[grid_val, weights, self.n_surface_op],
+                profile=False,
+                name='Looping grid x',
+                return_list=True)
+
+            Gx = Gx_loop[-1][-1]
+            Gx.name = 'Value of the gradient field X at every point'
+            G_field = T.set_subtensor(G_field[0, :], Gx)
+
+        if 'Gy' in gradients:
+            Gy_loop, updates6 = aesara.scan(
+                fn=self.gradient_field_loop_y,
+                outputs_info=[Z_x_init],
+                sequences=[dict(input=slices, taps=[0, 1])],
+                non_sequences=[grid_val, weights, self.n_surface_op],
+                profile=False,
+                name='Looping grid y',
+                return_list=True)
+
+            Gy = Gy_loop[-1][-1]
+            Gy.name = 'Value of the gradient field X at every point'
+            G_field = T.set_subtensor(G_field[1, :], Gy)
+
+        if 'Gz' in gradients:
+            Gz_loop, updates7 = aesara.scan(
+                fn=self.gradient_field_loop_z,
+                outputs_info=[Z_x_init],
+                sequences=[dict(input=slices, taps=[0, 1])],
+                non_sequences=[grid_val, weights, self.n_surface_op],
+                profile=False,
+                name='Looping grid z',
+                return_list=True)
+
+            Gz = Gz_loop[-1][-1]
+            Gz.name = 'Value of the gradient field X at every point'
+            G_field = T.set_subtensor(G_field[2, :], Gz)
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            Z_x = aesara.printing.Print('Potential field at all points')(Z_x)
+
+        return G_field
+
+    def compare(self, a, b, slice_init, Z_x, l, n_surface, drift):
+        """
+        Treshold of the points to interpolate given 2 potential field values. TODO: This function is the one we
+        need to change for a sigmoid function
+
+        Args:
+            a (scalar): Upper limit of the potential field
+            b (scalar): Lower limit of the potential field
+            n_surface (scalar): Value given to the segmentation, i.e. lithology number
+            Zx (vector): Potential field values at all the interpolated points
+
+        Returns:
+            aesara.tensor.vector: segmented values
+        """
+
+        if True:
+
+            slice_init = slice_init
+            n_surface_0 = n_surface[:, slice_init:slice_init + 1]
+            n_surface_1 = n_surface[:, slice_init + 1:slice_init + 2]
+            drift = drift[:, slice_init:slice_init + 1]
+
+            if 'compare' in self.verbose:
+                a = aesara.printing.Print("a")(a)
+                b = aesara.printing.Print("b")(b)
+                # l = 200/ (a - b)
+                slice_init = aesara.printing.Print("slice_init")(slice_init)
+                n_surface_0 = aesara.printing.Print("n_surface_0")(n_surface_0)
+                n_surface_1 = aesara.printing.Print("n_surface_1")(n_surface_1)
+                drift = aesara.printing.Print("drift[slice_init:slice_init+1][0]")(drift)
+
+            # drift = T.switch(slice_init == 0, n_surface_1, n_surface_0)
+            #    drift = T.set_subtensor(n_surface[0], n_surface[1])
+
+            # The 5 rules the slope of the function
+            sigm = (-n_surface_0.reshape((-1, 1)) / (1 + T.exp(-l * (Z_x - a)))) - \
+                   (n_surface_1.reshape((-1, 1)) / (1 + T.exp(l * (Z_x - b)))) + drift.reshape((-1, 1))
+            if False:
+                sigm = aesara.printing.Print("middle point")(sigm)
+            #      n_surface = aesara.printing.Print("n_surface")(n_surface)
+            return sigm
+
+        else:
+            return T.le(Zx, a) * T.ge(Zx, b) * n_surface_0
+
+    def select_finite_faults(self):
+        # get data points of fault
+        fault_points = T.vertical_stack(T.stack(self.ref_layer_points[0]), self.rest_layer_points).T
+        # compute centroid of fault points
+        centroid = T.mean(fault_points, axis=1)
+        # compute difference of fault points from centroid
+        x = fault_points - centroid.reshape((-1, 1))
+        M = T.dot(x, x.T)  # same as np.cov(x) * 2
+        U = T.nlinalg.svd(M)  # is this the normal of the plane?
+        # overall this looks like some sort of plane fit to me
+        rotated_x = T.dot(self.x_to_interpolate(), U[0])  # this rotates ALL grid points that need to be interpolated
+        # rotated_x = T.dot(rotated_x, U[-1])  # rotate them with both rotation matrices
+        rotated_fault_points = T.dot(fault_points.T, U[0])  # same with fault points
+        # rotated_fault_points = T.dot(rotated_fault_points, U[-1])  # same
+        rotated_ctr = T.mean(rotated_fault_points, axis=0)  # and compute centroid of rotated points
+        # a factor: horizontal vector of ellipse of normal fault
+        a_radius = (rotated_fault_points[:, 0].max() - rotated_fault_points[:, 0].min()) / 2 \
+                  + self.inf_factor[self.n_surface_op[0] - 1]
+        # b_factor: vertical vector of ellipse
+        b_radius = (rotated_fault_points[:, 1].max() - rotated_fault_points[:, 1].min()) / 2 \
+                  + self.inf_factor[self.n_surface_op[0] - 1]
+
+        # sel = T.lt((rotated_x[:, 0] - rotated_ctr[0])**2 / a_radio**2 +
+        #            (rotated_x[:, 1] - rotated_ctr[1])**2 / b_radio**2,
+        #            1)
+
+        # ellipse equation: (x, c_x)^2 / a^2 +  (y - c_y)^2 / b^2 <= 1 if in ellipse
+        ellipse_factor = (rotated_x[:,0] - rotated_ctr[0])**2 / a_radius**2 + \
+            (rotated_x[:, 1] - rotated_ctr[1])**2 / b_radius**2
+
+        if "select_finite_faults" in self.verbose:
+            ellipse_factor = aesara.printing.Print("h")(ellipse_factor)
+
+        # h_factor = 1 - h
+        # if "select_finite_faults" in self.verbose:
+        #     h_factor = aesara.printing.Print("h_factor")(h_factor)
+
+        # because we select all grid points as rotated_x, the selection here is
+        # a boolean for all grid points: True if in ellipse, False if outside ellipse
+
+        # if "select_finite_faults" in self.verbose:
+        #     sel = aesara.printing.Print("scalar_field_iter")(sel)
+            # sum of boolean array sel is in my example: 38301
+            # so I guess this selects all grid points affected by this finite fault
+
+        return ellipse_factor  # sel
+
+    def block_series(self, slope=5000, weights=None):
+        """
+        Compute the part of the block model of a given series (dictated by the bool array yet to be computed)
+
+        Returns:
+            aesara.tensor.vector: Value of lithology at every interpolated point
+        """
+        # TODO: IMP set soft max in the borders
+
+        # Graph to compute the potential field
+        Z_x = self.scalar_field_at_all(weights)
+
+        # Max and min values of the potential field.
+        # max_pot = T.max(Z_x) + 1
+        # min_pot = T.min(Z_x) - 1
+        # max_pot += max_pot * 0.1
+        # min_pot -= min_pot * 0.1
+
+        # Value of the potential field at the surface_points of the computed series
+        self.scalar_field_at_surface_points_values = Z_x[-2*self.len_points: -self.len_points][self.npf_op]
+
+        max_pot = T.max(Z_x)
+        #max_pot = aesara.printing.Print("max_pot")(max_pot)
+
+        min_pot = T.min(Z_x)
+   #     min_pot = aesara.printing.Print("min_pot")(min_pot)
+
+
+        max_pot_sigm = 2 * max_pot - self.scalar_field_at_surface_points_values[0]
+        min_pot_sigm = 2 * min_pot - self.scalar_field_at_surface_points_values[-1]
+
+        boundary_pad = (max_pot - min_pot)*0.01
+        l = slope / (max_pot - min_pot)
+
+        # A tensor with the values to segment
+        scalar_field_iter = T.concatenate((
+                                           T.stack([max_pot + boundary_pad]),
+                                           self.scalar_field_at_surface_points_values,
+                                           T.stack([min_pot - boundary_pad])
+                                            ))
+
+        if "scalar_field_iter" in self.verbose:
+            scalar_field_iter = aesara.printing.Print("scalar_field_iter")(scalar_field_iter)
+
+        # Loop to segment the distinct lithologies
+
+        n_surface_op_float_sigmoid = T.repeat(self.n_surface_op_float, 2, axis=1)
+
+        # TODO: instead -1 at the border look for the average distance of the input!
+
+        # This -1 makes that after the last interfaces the gradient goes on upwards
+        n_formation_op_float_sigmoid = T.set_subtensor(n_formation_op_float_sigmoid[0], -1)
+                                                    #- T.sqrt(T.square(n_formation_op_float_sigmoid[0] - n_formation_op_float_sigmoid[2])))
+
+        n_surface_op_float_sigmoid = T.set_subtensor(n_surface_op_float_sigmoid[:, -1], -1)
+                                                    #- T.sqrt(T.square(n_surface_op_float_sigmoid[3] - n_surface_op_float_sigmoid[-1])))
+
+        drift = T.set_subtensor(n_surface_op_float_sigmoid[:, 0], n_surface_op_float_sigmoid[:, 1])
+
+        if 'n_surface_op_float_sigmoid' in self.verbose:
+            n_surface_op_float_sigmoid = aesara.printing.Print("n_surface_op_float_sigmoid")\
+                (n_surface_op_float_sigmoid)
+
+        partial_block, updates2 = aesara.scan(
+            fn=self.compare,
+            outputs_info=None,
+            sequences=[dict(input=scalar_field_iter, taps=[0, 1]), T.arange(0, n_surface_op_float_sigmoid.shape[1],
+                                                                            2, dtype='int64')],
+            non_sequences=[Z_x, l, n_surface_op_float_sigmoid, drift],
+            name='Looping compare',
+            profile=False,
+            return_list=False)
+
+        # For every surface we get a vector so we need to sum compress them to one dimension
+        partial_block = partial_block.sum(axis=0)
+
+        # Add name to the aesara node
+        partial_block.name = 'The chunk of block model of a specific series'
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            partial_block = aesara.printing.Print(partial_block.name)(partial_block)
+
+        return Z_x, partial_block
+
+    def block_fault(self, slope=50):  #
+        """
+        Compute the part of the block model of a given series (dictated by the bool array yet to be computed)
+
+        Returns:
+            aesara.tensor.vector: Value of lithology at every interpolated point
+        """
+
+        # Graph to compute the potential field
+        Z_x = self.scalar_field_at_all()
+
+        # Max and min values of the potential field.
+        # max_pot = T.max(Z_x) + 1
+        # min_pot = T.min(Z_x) - 1
+        # max_pot += max_pot * 0.1
+        # min_pot -= min_pot * 0.1
+
+        # Value of the potential field at the surface_points of the computed series
+        self.scalar_field_at_surface_points_values = Z_x[-2 *(self.len_points): -self.len_points][self.npf_op]
+
+        max_pot = T.max(Z_x)
+        # max_pot = aesara.printing.Print("max_pot")(max_pot)
+
+        min_pot = T.min(Z_x)
+        # min_pot = aesara.printing.Print("min_pot")(min_pot)
+
+        # max_pot_sigm = 2 * max_pot - self.scalar_field_at_surface_points_values[0]
+        # min_pot_sigm = 2 * min_pot - self.scalar_field_at_surface_points_values[-1]
+
+        boundary_pad = (max_pot - min_pot) * 0.01
+        #l = slope / (max_pot - min_pot)  # (max_pot - min_pot)
+
+        ellipse_factor = self.select_finite_faults()
+        ellipse_factor_rectified = T.switch(ellipse_factor < 1., ellipse_factor, 1.)
+
+        if "select_finite_faults" in self.verbose:
+            ellipse_factor_rectified = aesara.printing.Print("h_factor_rectified")(ellipse_factor_rectified)
+
+        if "select_finite_faults" in self.verbose:
+            min_pot = aesara.printing.Print("min_pot")(min_pot)
+            max_pot = aesara.printing.Print("max_pot")(max_pot)
+
+        self.not_l = aesara.shared(50.)
+        self.ellipse_factor_exponent = aesara.shared(2)
+        # sigmoid_slope = (self.not_l * (1 / ellipse_factor_rectified)**3) / (max_pot - min_pot)
+        sigmoid_slope = 950 - 950 * ellipse_factor_rectified ** self.ellipse_factor_exponent + self.not_l
+        # l = T.switch(self.select_finite_faults(), 5000 / (max_pot - min_pot), 50 / (max_pot - min_pot))
+
+        if "select_finite_faults" in self.verbose:
+            sigmoid_slope = aesara.printing.Print("l")(sigmoid_slope)
+
+        # A tensor with the values to segment
+        scalar_field_iter = T.concatenate((
+            T.stack([max_pot + boundary_pad]),
+            self.scalar_field_at_surface_points_values,
+            T.stack([min_pot - boundary_pad])
+        ))
+
+        if "scalar_field_iter" in self.verbose:
+            scalar_field_iter = aesara.printing.Print("scalar_field_iter")(scalar_field_iter)
+
+        n_surface_op_float_sigmoid = T.repeat(self.n_surface_op_float[[0], :], 2, axis=1)
+        # TODO: instead -1 at the border look for the average distance of the input!
+
+        n_surface_op_float_sigmoid = T.set_subtensor(n_surface_op_float_sigmoid[:, 1], -1)
+        # - T.sqrt(T.square(n_surface_op_float_sigmoid[0] - n_surface_op_float_sigmoid[2])))
+
+        n_surface_op_float_sigmoid = T.set_subtensor(n_surface_op_float_sigmoid[:, -1], -1)
+        # - T.sqrt(T.square(n_surface_op_float_sigmoid[3] - n_surface_op_float_sigmoid[-1])))
+
+        drift = T.set_subtensor(n_surface_op_float_sigmoid[:, 0], n_surface_op_float_sigmoid[:, 1])
+
+        if 'n_surface_op_float_sigmoid' in self.verbose:
+            n_surface_op_float_sigmoid = aesara.printing.Print("n_surface_op_float_sigmoid") \
+                (n_surface_op_float_sigmoid)
+
+        partial_block, updates2 = aesara.scan(
+            fn=self.compare,
+            outputs_info=None,
+            sequences=[dict(input=scalar_field_iter, taps=[0, 1]),
+                       T.arange(0, n_surface_op_float_sigmoid.shape[1], 2, dtype='int64')],
+            non_sequences=[Z_x, sigmoid_slope, n_surface_op_float_sigmoid, drift],
+            name='Looping compare',
+            profile=False,
+            return_list=False)
+
+        # For every surface we get a vector so we need to sum compress them to one dimension
+        partial_block = partial_block.sum(axis=0)
+
+        # Add name to the aesara node
+        partial_block.name = 'The chunk of block model of a specific series'
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            partial_block = aesara.printing.Print(partial_block.name)(partial_block)
+
+        return [Z_x, partial_block]
+
+    def compute_a_fault(self,
+                        len_i_0, len_i_1,
+                        len_f_0, len_f_1,
+                        n_form_per_serie_0, n_form_per_serie_1,
+                        u_grade_iter,
+                        fault_matrix, final_block
+                        ):
+        """
+        Function that loops each fault, generating a potential field for each on them with the respective block model
+
+        Args:
+            len_i_0: Lenght of rest of previous series
+            len_i_1: Lenght of rest for the computed series
+            len_f_0: Lenght of dips of previous series
+            len_f_1: Length of dips of the computed series
+            n_form_per_serie_0: Number of surfaces of previous series
+            n_form_per_serie_1: Number of surfaces of the computed series
+
+        Returns:
+            aesara.tensor.matrix: block model derived from the df that afterwards is used as a drift for the "real"
+            data
+        """
+
+        # THIS IS THE FAULTS BLOCK.
+        # ==================
+        # Preparing the data
+        # ==================
+
+        # compute the youngest fault and consecutively the others
+
+        # aesara shared
+        self.number_of_points_per_surface_T_op = self.number_of_points_per_surface_T[n_form_per_serie_0: n_form_per_serie_1]
+        self.n_surface_op = self.n_surface[n_form_per_serie_0: n_form_per_serie_1]
+        self.n_surface_op_float = self.surface_values[:, n_form_per_serie_0: n_form_per_serie_1 + 1]
+        self.npf_op = self.npf[n_form_per_serie_0: n_form_per_serie_1]
+        if 'n_surface' in self.verbose:
+            self.n_surface_op = aesara.printing.Print('n_surface_fault')(self.n_surface_op)
+
+        self.n_universal_eq_T_op = u_grade_iter
+
+        self.dips_position = self.dips_position_all[len_f_0: len_f_1, :]
+        self.dips_position_tiled = T.tile(self.dips_position, (self.n_dimensions, 1))
+
+        # aesara Var
+        self.dip_angles = self.dip_angles_all[len_f_0: len_f_1]
+        self.azimuth = self.azimuth_all[len_f_0: len_f_1]
+        self.polarity = self.polarity_all[len_f_0: len_f_1]
+
+        self.ref_layer_points = self.ref_layer_points_all[len_i_0: len_i_1, :]
+        self.rest_layer_points = self.rest_layer_points_all[len_i_0: len_i_1, :]
+
+        # Updating the interface points involved in the iteration. This is important for the fault drift
+        self.len_i_0 = len_i_0
+        self.len_i_1 = len_i_1
+
+        if 'lengths' in self.verbose:
+            self.len_i_0 = aesara.printing.Print('len_i_0')(self.len_i_0)
+            self.len_i_1 = aesara.printing.Print('len_i_1')(self.len_i_1)
+            self.len_points = aesara.printing.Print('len_points')(self.len_points)
+
+        # Extracting a the subset of the fault matrix to the scalar field of the current iterations
+        faults_relation_op = self.fault_relation[:, T.cast(self.n_surface_op-1, 'int8')]
+        faults_relation_rep = T.repeat(faults_relation_op, 1)
+
+        if 'faults_relation' in self.verbose:
+            faults_relation_rep = aesara.printing.Print('SELECT')(faults_relation_rep)
+        if len(self.gradients) is not 0:
+            self.fault_matrix = fault_matrix[::5][T.nonzero(T.cast(faults_relation_rep, "int8"))[0], :]
+        else:
+            self.fault_matrix = fault_matrix[::2][T.nonzero(T.cast(faults_relation_rep, "int8"))[0], :]
+
+        if 'fault_matrix_loop' in self.verbose:
+            self.fault_matrix = aesara.printing.Print('self fault matrix')(self.fault_matrix)
+
+        # ================================
+        # Computing the fault scalar field
+        # ================================
+
+        potential_field_values, faults_matrix = self.block_fault(slope=1000)
+
+        # Update the block matrix
+        final_block = T.set_subtensor(
+                    final_block[0, :],
+                    faults_matrix[0])#T.cast(T.cast(faults_matrix, 'bool'), 'int8'))
+
+        # Update the potential field matrix
+       # potential_field_values = self.scalar_field_at_all()
+
+        final_block = T.set_subtensor(
+                    final_block[1, :],
+                    potential_field_values)
+
+        # Store the potential field at the surface_points
+        self.final_potential_field_at_faults_op = T.set_subtensor(self.final_potential_field_at_faults_op[self.n_surface_op-1],
+                                                                  self.scalar_field_at_surface_points_values)
+
+        aux_ind = T.max(self.n_surface_op, 0)
+
+        if len(self.gradients) is not 0:
+            weights = self.extend_dual_kriging()
+            gradients = self.gradient_field_at_all(weights, self.gradients)
+            final_block = T.set_subtensor(
+                final_block[2:, :],
+                gradients)
+            # Setting the values of the fault matrix computed in the current iteration
+            fault_matrix = T.set_subtensor(fault_matrix[(aux_ind - 1) * 5:aux_ind * 5, :], final_block)
+
+        else:
+            # Setting the values of the fault matrix computed in the current iteration
+            fault_matrix = T.set_subtensor(fault_matrix[(aux_ind-1)*2:aux_ind*2, :], final_block)
+
+        return fault_matrix, self.final_potential_field_at_faults_op,
+
+    def compute_a_series(self,
+                         len_i_0, len_i_1,
+                         len_f_0, len_f_1,
+                         n_form_per_serie_0, n_form_per_serie_1,
+                         u_grade_iter,
+                         final_block, scalar_field_at_form,
+                         #fault_block
+                         ):
+
+        """
+        Function that loops each series, generating a potential field for each on them with the respective block model
+
+        Args:
+             len_i_0: Lenght of rest of previous series
+             len_i_1: Lenght of rest for the computed series
+             len_f_0: Lenght of dips of previous series
+             len_f_1: Length of dips of the computed series
+             n_form_per_serie_0: Number of surfaces of previous series
+             n_form_per_serie_1: Number of surfaces of the computed series
+
+        Returns:
+             aesara.tensor.matrix: final block model
+        """
+
+        # Setting the fault contribution to kriging from the previous loop
+       # self.fault_matrix = fault_block
+
+        # THIS IS THE FINAL BLOCK. (DO I NEED TO LOOP THE FAULTS FIRST? Yes you do)
+        # ==================
+        # Preparing the data
+        # ==================
+
+        # Vector that controls the points that have been simulated in previous iterations
+        self.yet_simulated = T.nonzero(T.le(final_block[1, :], scalar_field_at_form[n_form_per_serie_0 - 1]))[0] # This -1 comes to get the last scalar field value (the bottom) of the previous series
+        self.yet_simulated.name = 'Yet simulated LITHOLOGY node'
+        if 'fault_mask' in self.verbose:
+            self.yet_simulated = aesara.printing.Print('fault_mask')(self.yet_simulated)
+            scalar_field_at_form = aesara.printing.Print('scalar_field_at_form_out')(scalar_field_at_form)
+
+        # aesara shared
+        self.number_of_points_per_surface_T_op = self.number_of_points_per_surface_T[n_form_per_serie_0: n_form_per_serie_1]
+        self.n_surface_op = self.n_surface[n_form_per_serie_0: n_form_per_serie_1]
+        self.n_surface_op_float = self.surface_values[:, n_form_per_serie_0: (n_form_per_serie_1 + 1)]
+        self.npf_op = self.npf[n_form_per_serie_0: n_form_per_serie_1]
+
+        self.n_universal_eq_T_op = u_grade_iter
+
+        self.dips_position = self.dips_position_all[len_f_0: len_f_1, :]
+        self.dips_position_tiled = T.tile(self.dips_position, (self.n_dimensions, 1))
+
+        # aesara Var
+        self.dip_angles = self.dip_angles_all[len_f_0: len_f_1]
+        self.azimuth = self.azimuth_all[len_f_0: len_f_1]
+        self.polarity = self.polarity_all[len_f_0: len_f_1]
+
+        self.ref_layer_points = self.ref_layer_points_all[len_i_0: len_i_1, :]
+        self.rest_layer_points = self.rest_layer_points_all[len_i_0: len_i_1, :]
+
+        if 'rest_layer_points' in self.verbose:
+            self.rest_layer_points = aesara.printing.Print('rest_layer_points')(self.rest_layer_points)
+
+        if 'ref_layer_points' in self.verbose:
+            self.ref_layer_points = aesara.printing.Print('ref_layer_points')(self.ref_layer_points)
+
+        # For the contribution of the df I did not find a better way
+        self.len_i_0 = len_i_0
+        self.len_i_1 = len_i_1
+
+        # Printing
+        if 'n_surface' in self.verbose:
+            self.n_surface_op = aesara.printing.Print('n_surface_series')(self.n_surface_op)
+
+        if 'lengths' in self.verbose:
+            self.len_i_0 = aesara.printing.Print('len_i_0')(self.len_i_0)
+            self.len_i_1 = aesara.printing.Print('len_i_1')(self.len_i_1)
+            self.len_points = aesara.printing.Print('len_points')(self.len_points)
+        # ====================
+        # Computing the series
+        # ====================
+
+        weights = self.extend_dual_kriging()
+
+        scalar_field_values, scalar_field_contribution = self.block_series()
+
+        # Updating the block model with the lithology block
+
+        # Set model id
+        final_block = T.set_subtensor(
+            final_block[0, self.yet_simulated],
+            scalar_field_contribution[0])
+
+        final_block = T.set_subtensor(
+            final_block[0, -2*self.len_points:],
+            0)
+
+        #scalar_field_values = self.scalar_field_at_all()
+
+        # Set scalar field
+        final_block = T.set_subtensor(
+            final_block[1, self.yet_simulated],
+            scalar_field_values)
+
+        final_block = T.set_subtensor(
+            final_block[1, -2 * self.len_points:],
+            0)
+
+        # Set additional values
+        final_block = T.set_subtensor(
+            final_block[2:, self.yet_simulated],
+            scalar_field_contribution[1:])
+
+        # Reset scalar field at the surface_points to 0
+        # final_block = T.set_subtensor(
+        #     final_block[:, -2 * self.len_points:],
+        #     0)
+
+        # Store the potential field at the surface_points
+        self.final_scalar_field_at_surfaces_op = T.set_subtensor(
+            self.final_scalar_field_at_surfaces_op[self.n_surface_op - 1],
+            self.scalar_field_at_surface_points_values)
+
+        if len(self.gradients) is not 0:
+            gradients = self.gradient_field_at_all(weights, self.gradients)
+            final_block = T.set_subtensor(
+                final_block[2:, self.yet_simulated],
+                gradients)
+
+        return final_block, self.final_scalar_field_at_surfaces_op
+
+    def compute_geological_model(self, weights=None):
+
+        # Change the flag to extend the graph in the compute fault and compute series function
+        lith_matrix = T.zeros((0, 0, self.grid_val_T.shape[0] + 2 * self.len_points))
+
+        # Init to matrix which contains the block and scalar field of every fault
+        self.fault_matrix = T.zeros((self.n_faults * 2, self.grid_val_T.shape[0] + 2 * self.len_points))
+        self.fault_matrix_f = T.zeros((self.n_faults * 2, self.grid_val_T.shape[0] + 2 * self.len_points))
+
+        self.final_scalar_field_at_surfaces_op = self.final_scalar_field_at_surfaces
+        self.final_potential_field_at_faults_op = self.final_scalar_field_at_faults
+
+        # Init df block. Here we store the block and potential field results of one iteration
+        self.fault_block_init = T.zeros((2, self.grid_val_T.shape[0] + 2 * self.len_points))
+        self.fault_block_init.name = 'final block of df init'
+        self.yet_simulated = T.nonzero(T.eq(self.fault_block_init[0, :], 0))[0]
+
+        # Compute Faults
+        if self.n_faults.get_value() != 0 or self.is_fault:
+
+            # Looping
+            fault_loop, updates3 = aesara.scan(
+                fn=self.compute_a_fault,
+                    outputs_info=[
+                              dict(initial=self.fault_matrix, taps=[-1]),
+                              None],  # This line may be used for the df network
+                sequences=[dict(input=self.len_series_i[:self.n_faults + 1], taps=[0, 1]),
+                           dict(input=self.len_series_f[:self.n_faults + 1], taps=[0, 1]),
+                           dict(input=self.n_surfaces_per_series[:self.n_faults + 1], taps=[0, 1]),
+                           dict(input=self.n_universal_eq_T[:self.n_faults + 1], taps=[0])],
+                non_sequences=self.fault_block_init,
+                name='Looping df',
+                return_list=True,
+                profile=False
+            )
+
+            # We return the last iteration of the fault matrix
+            self.fault_matrix_f = fault_loop[0][-1]
+            self.fault_matrix = self.fault_matrix_f[::2]
+            # fault_block = self.fault_matrix[:, :-2 * self.len_points]
+            # For this we return every iteration since is each potential field at interface
+            self.pfai_fault = fault_loop[1]
+
+        # Check if there are lithologies to compute
+        if len(self.len_series_f.get_value()) - 1 > self.n_faults.get_value() or self.is_lith:
+
+            # The +1 is due to the scalar field
+            self.lith_block_init = T.zeros((self.surface_values.shape[0] + 1,
+                                            self.grid_val_T.shape[0] + 2 * self.len_points))
+
+            # Compute Lithologies
+            lith_loop, updates2 = aesara.scan(
+                 fn=self.compute_a_series,
+                 outputs_info=[self.lith_block_init, self.final_scalar_field_at_surfaces_op],
+                 sequences=[dict(input=self.len_series_i[self.n_faults:], taps=[0, 1]),
+                            dict(input=self.len_series_f[self.n_faults:], taps=[0, 1]),
+                            dict(input=self.n_surfaces_per_series[self.n_faults:], taps=[0, 1]),
+                            dict(input=self.n_universal_eq_T[self.n_faults:], taps=[0])],
+                # non_sequences=[self.fault_matrix],
+                 name='Looping surface_points',
+                 profile=False,
+                 return_list=True
+            )
+
+            lith_matrix = lith_loop[0][-1]
+            self.pfai_lith = lith_loop[1]
+
+        pfai = T.vertical_stack(self.pfai_fault, self.pfai_lith)
+        return [lith_matrix[:, :-2 * self.len_points], self.fault_matrix_f[:, :-2 * self.len_points], pfai]
+
+    def compute_geological_model_gradient(self, gradients = [], weights=None):
+        # TODO update it to several properties!!
+
+        self.gradients = ['Gx', 'Gy', 'Gz']#aesara.shared(['Gx', 'Gy', 'Gz'])
+
+        # Change the flag to extend the graph in the compute fault and compute series function
+        lith_matrix = T.zeros((0, 0, self.grid_val_T.shape[0] + 2 * self.len_points))
+
+        # Init to matrix which contains the block and scalar field of every fault
+        self.fault_matrix = T.zeros((self.n_faults*5, self.grid_val_T.shape[0]))
+        self.fault_matrix_f = T.zeros((self.n_faults*5, self.grid_val_T.shape[0]))
+
+        # TODO I think I just have to change the size of the lith_block
+        self.lith_block_init = T.zeros((5, self.grid_val_T.shape[0]))
+        self.fault_block_init = T.zeros((5, self.grid_val_T.shape[0]))
+        self.fault_block_init.name = 'final block of df init'
+        # Compute Faults
+        if self.n_faults.get_value() != 0 or self.is_fault:
+
+            # Looping
+            fault_loop, updates3 = aesara.scan(
+                fn=self.compute_a_fault,
+                    outputs_info=[
+                              dict(initial=self.fault_matrix, taps=[-1]),
+                              None],  # This line may be used for the df network
+                sequences=[dict(input=self.len_series_i[:self.n_faults + 1], taps=[0, 1]),
+                           dict(input=self.len_series_f[:self.n_faults + 1], taps=[0, 1]),
+                           dict(input=self.n_surfaces_per_series[:self.n_faults + 1], taps=[0, 1]),
+                           dict(input=self.n_universal_eq_T[:self.n_faults + 1], taps=[0])],
+                non_sequences=self.fault_block_init,
+                name='Looping df',
+                return_list=True,
+                profile=False
+            )
+
+            # We return the last iteration of the fault matrix
+            self.fault_matrix_f = fault_loop[0][-1]
+            self.fault_matrix = self.fault_matrix_f[::5]
+          #  fault_block = self.fault_matrix[:, :-2 * self.len_points]
+            # For this we return every iteration since is each potential field at interface
+            self.pfai_fault = fault_loop[1]
+
+        # Check if there are lithologies to compute
+        if len(self.len_series_f.get_value()) - 1 > self.n_faults.get_value() or self.is_lith:
+
+            # Compute Lithologies
+            lith_loop, updates2 = aesara.scan(
+                 fn=self.compute_a_series,
+                 outputs_info=[self.lith_block_init, self.final_scalar_field_at_surfaces_op],
+                 sequences=[dict(input=self.len_series_i[self.n_faults:], taps=[0, 1]),
+                            dict(input=self.len_series_f[self.n_faults:], taps=[0, 1]),
+                            dict(input=self.n_surfaces_per_series[self.n_faults:], taps=[0, 1]),
+                            dict(input=self.n_universal_eq_T[self.n_faults:], taps=[0])],
+                # non_sequences=[self.fault_matrix],
+                 name='Looping surface_points',
+                 profile=False,
+                 return_list=True
+            )
+
+            lith_matrix = lith_loop[0][-1]
+            self.pfai_lith = lith_loop[1]
+
+        pfai = T.vertical_stack(self.pfai_fault, self.pfai_lith)
+        return [lith_matrix[:, :-2 * self.len_points], self.fault_matrix_f[:, :-2 * self.len_points], pfai]
+
+    # def compute_weights_op(self,
+    #                        len_i_0, len_i_1,
+    #                        len_f_0, len_f_1,
+    #                        n_form_per_serie_0, n_form_per_serie_1,
+    #                        u_grade_iter,
+    #                        weights):
+    #     # aesara shared
+    #     self.number_of_points_per_surface_T_op = self.number_of_points_per_surface_T[
+    #                                                n_form_per_serie_0: n_form_per_serie_1]
+    #     self.n_surface_op = self.n_surface[n_form_per_serie_0: n_form_per_serie_1]
+    #     self.n_surface_op_float = self.surface_values[n_form_per_serie_0: (n_form_per_serie_1 + 1)]
+    #     self.npf_op = self.npf[n_form_per_serie_0: n_form_per_serie_1]
+    #
+    #     self.n_universal_eq_T_op = u_grade_iter
+    #
+    #     self.dips_position = self.dips_position_all[len_f_0: len_f_1, :]
+    #     self.dips_position_tiled = T.tile(self.dips_position, (self.n_dimensions, 1))
+    #
+    #     # aesara Var
+    #     self.dip_angles = self.dip_angles_all[len_f_0: len_f_1]
+    #     self.azimuth = self.azimuth_all[len_f_0: len_f_1]
+    #     self.polarity = self.polarity_all[len_f_0: len_f_1]
+    #
+    #     self.ref_layer_points = self.ref_layer_points_all[len_i_0: len_i_1, :]
+    #     self.rest_layer_points = self.rest_layer_points_all[len_i_0: len_i_1, :]
+    #
+    #     # For the contribution of the df I did not find a better way
+    #     self.len_i_0 = len_i_0
+    #     self.len_i_1 = len_i_1
+    #
+    #     weights = T.set_subtensor(weights[:, len_i_0: len_i_1], self.solve_kriging())
+    #     return weights
+    #
+    # def compute_weights(self):
+    #     weights_init = T.zeros((1, self.len_points + self.dips_position_tiled.shape[0]))
+    #     # Compute Lithologies
+    #     weights_loop, updates2 = aesara.scan(
+    #          fn=self.compute_weights_op,
+    #          outputs_info=[weights_init],
+    #          sequences=[dict(input=self.len_series_i, taps=[0, 1]),
+    #                     dict(input=self.len_series_f, taps=[0, 1]),
+    #                     dict(input=self.n_surfaces_per_series, taps=[0, 1]),
+    #                     dict(input=self.n_universal_eq_T, taps=[0])],
+    #         # non_sequences=[self.fault_matrix],
+    #          name='Looping surface_points',
+    #          profile=False,
+    #          return_list=True
+    #     )
+    #
+    #     return weights_loop
+
+    # ==================================
+    # Geophysics
+    # ==================================
+
+    def switch_densities(self, n_surface, density, density_block):
+
+        density_block = T.switch(T.eq(density_block, n_surface), density, density_block)
+        return density_block
+
+    def compute_forward_gravity(self): # densities, tz, select,
+
+        # TODO: Assert outside that densities is the same size as surfaces (minus df)
+        # Compute the geological model
+        lith_matrix, fault_matrix, pfai = self.compute_geological_model()
+
+        # if n_faults == 0:
+        #     surfaces = T.concatenate([self.n_surface[::-1], T.stack([0])])
+        # else:
+        #     surfaces = T.concatenate([self.n_surface[:n_faults-1:-1], T.stack([0])])
+        #
+        #     if False:
+        #         surfaces = aesara.printing.Print('surfaces')(surfaces)
+        #
+        # # Substitue lithologies by its density
+        # density_block_loop, updates4 = aesara.scan(self.switch_densities,
+        #                             outputs_info=[lith_matrix[0]],
+        #                              sequences=[surfaces, self.densities],
+        #                             return_list = True
+        # )
+
+        # if False:
+        #     density_block_loop_f = T.set_subtensor(density_block_loop[-1][-1][self.weigths_index], self.weigths_weigths)
+        #
+        # else:
+        density_block_loop_f = lith_matrix[0]
+
+
+        if 'density_block' in self.verbose:
+            density_block_loop_f = aesara.printing.Print('density block')(density_block_loop_f)
+
+        n_measurements = self.tz.shape[0]
+        # Tiling the density block for each measurent and picking just the closer to them. This has to be possible to
+        # optimize
+
+        #densities_rep = T.tile(density_block_loop[-1][-1], n_measurements)
+        densities_rep = T.tile(density_block_loop_f, n_measurements)
+        densities_selected = densities_rep[T.nonzero(T.cast(self.select, "int8"))[0]]
+        densities_selected_reshaped = densities_selected.reshape((n_measurements, -1))
+        #
+        # # density times the component z of gravity
+        grav = densities_selected_reshaped * self.tz
+
+        #return [lith_matrix, self.fault_matrix, pfai, grav.sum(axis=1)]
+        return [lith_matrix, fault_matrix, grav.sum(axis=1), pfai]
+
+
+    def compute_grad(self, n_faults=None):
+        sol = self.block_series()
+        return aesara.grad(sol.sum(), self.rest_layer_points_all)
+
+    # def compute_grad2(self, n_faults=None):
+    #     sol = self.compute_a_series(
+    #         self.len_series_i[n_faults:][0], self.len_series_i[n_faults:][-1],
+    #         self.len_series_f[n_faults:][0], self.len_series_f[n_faults:][-1],
+    #         self.n_surfaces_per_series[n_faults:][0], self.n_surfaces_per_series[n_faults:][-1],
+    #         self.n_universal_eq_T[n_faults:],
+    #         self.lith_block_init, self.final_scalar_field_at_surfaces,
+    #         self.fault_matrix
+    #     )
+    #     return aesara.grad(sol[0].sum(), self.rest_layer_points_all)
+    #
+    # def compute_grad3(self, n_faults=None
+    #                   ):
+    #     lith_matrix, fault_matrix, pfai = self.compute_geological_model(n_faults=n_faults)
+    #     return aesara.grad(lith_matrix[0].sum(), self.rest_layer_points_all)
+    #
+    #
+
+
+class aesaraOptions(object):
+    def __init__(self,  output='geology', optimizer='fast_compile', verbose=[0], dtype='float32',
+                 is_fault=None, is_lith=None):
+        # OPTIONS
+        # -------
+        if verbose is np.nan:
+            self.verbose = [None]
+        else:
+            self.verbose = verbose
+        self.dot_version = False
+
+        aesara.config.floatX = dtype
+        aesara.config.optimizer = optimizer
+
+
+class aesaraGeometry(aesaraOptions):
+    def __init__(self, output='geology', optimizer='fast_compile', verbose=[0], dtype='float32',
+                 is_fault=None, is_lith=None):
+
+        # # OPTIONS
+        # # -------
+        # if verbose is np.nan:
+        #     self.verbose = [None]
+        # else:
+        #     self.verbose = verbose
+        # self.dot_version = False
+        #
+        # aesara.config.floatX = dtype
+        # aesara.config.optimizer = optimizer
+        super(aesaraGeometry, self).__init__(optimizer='fast_compile', verbose=[0], dtype='float32',)
+
+        # Number of dimensions. Now it is not too variable anymore
+        self.n_dimensions = 3
+
+        # This is not accumulative
+        self.number_of_points_per_surface_T = aesara.shared(np.zeros(3, dtype='int32')) #TODO is DEP?
+        self.number_of_points_per_surface_T_op = T.vector('Number of points per surface used to split rest-ref',
+                                                          dtype='int32')
+        self.npf_op = T.cumsum(T.concatenate((T.stack(0), self.number_of_points_per_surface_T_op[:-1])))
+
+        # # FORMATIONS
+        # # ----------
+        # self.n_surface = aesara.shared(np.arange(2, 5, dtype='int32'), "ID of the surface")
+        # self.n_surface_op = self.n_surface
+        # self.surface_values = aesara.shared((np.arange(2, 4, dtype=dtype).reshape(2, -1)), "Value of the surface to compute")
+        # self.n_surface_op_float = self.surface_values
+
+
+        # KRIGING
+        # -------
+        self.a_T = aesara.shared(np.cast[dtype](-1.), "Range")
+        self.c_o_T = aesara.shared(np.cast[dtype](-1.), 'Covariance at 0')
+        self.nugget_effect_grad_T = aesara.shared(np.cast[dtype](-1), 'Nugget effect of gradients')
+        self.nugget_effect_scalar_T = aesara.shared(np.cast[dtype](-1), 'Nugget effect of scalar')
+        self.n_universal_eq_T = aesara.shared(np.zeros(5, dtype='int32'), "Grade of the universal drift")
+        self.n_universal_eq_T_op = aesara.shared(3)
+
+        # They weight the contribution of the surface_points against the orientations.
+        self.i_reescale = aesara.shared(np.cast[dtype](4.))
+        self.gi_reescale = aesara.shared(np.cast[dtype](2.))
+
+        # VARIABLES
+        # ---------
+        self.dips_position_all = T.matrix("Position of the dips")
+        self.dip_angles_all = T.vector("Angle of every dip")
+        self.azimuth_all = T.vector("Azimuth")
+        self.polarity_all = T.vector("Polarity")
+
+        self.surface_points_all = T.matrix("All the surface_points points at once")
+        self.len_points = self.surface_points_all.shape[0] - self.number_of_points_per_surface_T_op.shape[0]
+        # Tiling dips to the 3 spatial coordinations
+        self.dips_position = self.dips_position_all
+        self.dips_position_tiled = T.tile(self.dips_position, (self.n_dimensions, 1))
+
+        # These are subsets of the data for each series. I initialized them as the whole arrays but then they will take
+        # the data of every potential field
+        self.dip_angles = self.dip_angles_all
+        self.azimuth = self.azimuth_all
+        self.polarity = self.polarity_all
+
+        self.ref_layer_points_all = self.set_rest_ref_matrix()[0]
+        self.rest_layer_points_all = self.set_rest_ref_matrix()[1]
+
+        self.ref_layer_points = self.ref_layer_points_all
+        self.rest_layer_points = self.rest_layer_points_all
+
+        self.fault_drift = T.matrix('Drift matrix due to faults')
+
+    def set_rest_ref_matrix(self):
+        ref_positions = T.cumsum(T.concatenate((T.stack(0), self.number_of_points_per_surface_T_op[:-1] + 1)))
+        ref_points = T.repeat(self.surface_points_all[ref_positions], self.number_of_points_per_surface_T_op, axis=0)
+
+        rest_mask = T.ones(T.stack(self.surface_points_all.shape[0]), dtype='int16')
+        rest_mask = T.set_subtensor(rest_mask[ref_positions], 0)
+        rest_points = self.surface_points_all[T.nonzero(rest_mask)[0]]
+        return [ref_points, rest_points, rest_mask, T.nonzero(rest_mask)[0]]
+
+    @staticmethod
+    def squared_euclidean_distances(x_1, x_2):
+        """
+        Compute the euclidian distances in 3D between all the points in x_1 and x_2
+
+        Args:
+            x_1 (aesara.tensor.matrix): shape n_points x number dimension
+            x_2 (aesara.tensor.matrix): shape n_points x number dimension
+
+        Returns:
+            aesara.tensor.matrix: Distancse matrix. shape n_points x n_points
+        """
+
+        # T.maximum avoid negative numbers increasing stability
+        sqd = T.sqrt(T.maximum(
+            (x_1 ** 2).sum(1).reshape((x_1.shape[0], 1)) +
+            (x_2 ** 2).sum(1).reshape((1, x_2.shape[0])) -
+            2 * x_1.dot(x_2.T), 1e-12
+        ))
+
+        if False:
+            sqd = aesara.printing.Print('sed')(sqd)
+
+        return sqd
+
+    def matrices_shapes(self):
+        """
+        Get all the lengths of the matrices that form the covariance matrix
+
+        Returns:
+             length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C
+        """
+
+        # Calculating the dimensions of the
+        length_of_CG = self.dips_position_tiled.shape[0]
+        length_of_CGI = self.rest_layer_points.shape[0]
+        length_of_U_I = self.n_universal_eq_T_op
+
+        # Self fault matrix contains the block and the potential field (I am not able to split them). Therefore we need
+        # to divide it by 2
+        length_of_faults = T.cast(self.fault_drift.shape[0], 'int32')
+        length_of_C = length_of_CG + length_of_CGI + length_of_U_I + length_of_faults
+
+        if 'matrices_shapes' in self.verbose:
+            length_of_CG = aesara.printing.Print("length_of_CG")(length_of_CG)
+            length_of_CGI = aesara.printing.Print("length_of_CGI")(length_of_CGI)
+            length_of_U_I = aesara.printing.Print("length_of_U_I")(length_of_U_I)
+            length_of_faults = aesara.printing.Print("length_of_faults")(length_of_faults)
+            length_of_C = aesara.printing.Print("length_of_C")(length_of_C)
+
+        return length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C
```

### Comparing `gempy-2.2b10.dev1/gempy/core/theano_modules/theano_graph_pro.py` & `gempy-2.3.0/gempy/core/aesara_modules/aesara_graph_pro.py`

 * *Files 17% similar despite different names*

```diff
@@ -46,6721 +46,6699 @@
 000002d0: 670d 0a46 756e 6374 696f 6e20 7468 6174  g..Function that
 000002e0: 2067 656e 6572 6174 6573 2074 6865 2073   generates the s
 000002f0: 796d 626f 6c69 6320 636f 6465 2074 6f20  ymbolic code to 
 00000300: 7065 7266 6f72 6d20 7468 6520 696e 7465  perform the inte
 00000310: 7270 6f6c 6174 696f 6e2e 2043 616c 6c69  rpolation. Calli
 00000320: 6e67 2074 6869 7320 6675 6e63 7469 6f6e  ng this function
 00000330: 2063 7265 6174 6573 0d0a 2062 6f74 6820   creates.. both 
-00000340: 7468 6520 7468 6561 6e6f 2066 756e 6374  the theano funct
+00000340: 7468 6520 6165 7361 7261 2066 756e 6374  the aesara funct
 00000350: 696f 6e73 2066 6f72 2074 6865 2070 6f74  ions for the pot
 00000360: 656e 7469 616c 2066 6965 6c64 2061 6e64  ential field and
 00000370: 2074 6865 2062 6c6f 636b 2e0d 0a0d 0a52   the block.....R
-00000380: 6574 7572 6e73 3a0d 0a20 2020 2074 6865  eturns:..    the
-00000390: 616e 6f20 6675 6e63 7469 6f6e 2066 6f72  ano function for
+00000380: 6574 7572 6e73 3a0d 0a20 2020 2061 6573  eturns:..    aes
+00000390: 6172 6120 6675 6e63 7469 6f6e 2066 6f72  ara function for
 000003a0: 2074 6865 2070 6f74 656e 7469 616c 2066   the potential f
-000003b0: 6965 6c64 0d0a 2020 2020 7468 6561 6e6f  ield..    theano
+000003b0: 6965 6c64 0d0a 2020 2020 6165 7361 7261  ield..    aesara
 000003c0: 2066 756e 6374 696f 6e20 666f 7220 7468   function for th
 000003d0: 6520 626c 6f63 6b0d 0a22 2222 0d0a 0d0a  e block.."""....
-000003e0: 696d 706f 7274 2074 6865 616e 6f0d 0a66  import theano..f
-000003f0: 726f 6d20 7468 6561 6e6f 2069 6d70 6f72  rom theano impor
-00000400: 7420 7465 6e73 6f72 2061 7320 540d 0a66  t tensor as T..f
-00000410: 726f 6d20 7468 6561 6e6f 2069 6d70 6f72  rom theano impor
-00000420: 7420 7370 6172 7365 0d0a 0d0a 696d 706f  t sparse....impo
-00000430: 7274 2074 6865 616e 6f2e 6966 656c 7365  rt theano.ifelse
-00000440: 2061 7320 7469 660d 0a69 6d70 6f72 7420   as tif..import 
-00000450: 6e75 6d70 7920 6173 206e 700d 0a69 6d70  numpy as np..imp
-00000460: 6f72 7420 7379 730d 0a0d 0a23 2063 6865  ort sys....# che
-00000470: 636b 2069 6620 736b 6375 6461 2069 7320  ck if skcuda is 
-00000480: 696e 7374 616c 6c65 640d 0a74 7279 3a0d  installed..try:.
-00000490: 0a20 2020 2069 6d70 6f72 7420 736b 6375  .    import skcu
-000004a0: 6461 0d0a 0d0a 2020 2020 534b 4355 4441  da....    SKCUDA
-000004b0: 5f49 4d50 4f52 5420 3d20 5472 7565 0d0a  _IMPORT = True..
-000004c0: 6578 6365 7074 2049 6d70 6f72 7445 7272  except ImportErr
-000004d0: 6f72 3a0d 0a20 2020 2053 4b43 5544 415f  or:..    SKCUDA_
-000004e0: 494d 504f 5254 203d 2046 616c 7365 0d0a  IMPORT = False..
-000004f0: 0d0a 7468 6561 6e6f 2e63 6f6e 6669 672e  ..theano.config.
-00000500: 6f70 656e 6d70 5f65 6c65 6d77 6973 655f  openmp_elemwise_
-00000510: 6d69 6e73 697a 6520 3d20 3530 3030 300d  minsize = 50000.
-00000520: 0a74 6865 616e 6f2e 636f 6e66 6967 2e6f  .theano.config.o
-00000530: 7065 6e6d 7020 3d20 5472 7565 0d0a 0d0a  penmp = True....
-00000540: 7468 6561 6e6f 2e63 6f6e 6669 672e 6f70  theano.config.op
-00000550: 7469 6d69 7a65 7220 3d20 2766 6173 745f  timizer = 'fast_
-00000560: 636f 6d70 696c 6527 0d0a 7468 6561 6e6f  compile'..theano
-00000570: 2e63 6f6e 6669 672e 666c 6f61 7458 203d  .config.floatX =
-00000580: 2027 666c 6f61 7433 3227 0d0a 7468 6561   'float32'..thea
-00000590: 6e6f 2e63 6f6e 6669 672e 6f6e 5f6f 7074  no.config.on_opt
-000005a0: 5f65 7272 6f72 203d 2027 6967 6e6f 7265  _error = 'ignore
-000005b0: 270d 0a0d 0a74 6865 616e 6f2e 636f 6e66  '....theano.conf
-000005c0: 6967 2e65 7863 6570 7469 6f6e 5f76 6572  ig.exception_ver
-000005d0: 626f 7369 7479 203d 2027 6869 6768 270d  bosity = 'high'.
-000005e0: 0a74 6865 616e 6f2e 636f 6e66 6967 2e63  .theano.config.c
-000005f0: 6f6d 7075 7465 5f74 6573 745f 7661 6c75  ompute_test_valu
-00000600: 6520 3d20 276f 6666 270d 0a74 6865 616e  e = 'off'..thean
-00000610: 6f2e 636f 6e66 6967 2e70 726f 6669 6c65  o.config.profile
-00000620: 5f6d 656d 6f72 7920 3d20 4661 6c73 650d  _memory = False.
-00000630: 0a74 6865 616e 6f2e 636f 6e66 6967 2e73  .theano.config.s
-00000640: 6361 6e2e 6465 6275 6720 3d20 4661 6c73  can.debug = Fals
-00000650: 650d 0a74 6865 616e 6f2e 636f 6e66 6967  e..theano.config
-00000660: 2e70 726f 6669 6c65 203d 2046 616c 7365  .profile = False
-00000670: 0d0a 0d0a 0d0a 6465 6620 6173 5f73 7061  ......def as_spa
-00000680: 7273 655f 7661 7269 6162 6c65 2878 2c20  rse_variable(x, 
-00000690: 6e61 6d65 3d4e 6f6e 6529 3a0d 0a20 2020  name=None):..   
-000006a0: 2022 2222 0d0a 2020 2020 5772 6170 7065   """..    Wrappe
-000006b0: 7220 6172 6f75 6e64 2053 7061 7273 6556  r around SparseV
-000006c0: 6172 6961 626c 6520 636f 6e73 7472 7563  ariable construc
-000006d0: 746f 7220 746f 2063 6f6e 7374 7275 6374  tor to construct
-000006e0: 0d0a 2020 2020 6120 5661 7269 6162 6c65  ..    a Variable
-000006f0: 2077 6974 6820 6120 7370 6172 7365 206d   with a sparse m
-00000700: 6174 7269 7820 7769 7468 2074 6865 2073  atrix with the s
-00000710: 616d 6520 6474 7970 6520 616e 640d 0a20  ame dtype and.. 
-00000720: 2020 2066 6f72 6d61 742e 0d0a 2020 2020     format...    
-00000730: 5061 7261 6d65 7465 7273 0d0a 2020 2020  Parameters..    
-00000740: 2d2d 2d2d 2d2d 2d2d 2d2d 0d0a 2020 2020  ----------..    
-00000750: 780d 0a20 2020 2020 2020 2041 2073 7061  x..        A spa
-00000760: 7273 6520 6d61 7472 6978 2e0d 0a20 2020  rse matrix...   
-00000770: 2052 6574 7572 6e73 0d0a 2020 2020 2d2d   Returns..    --
-00000780: 2d2d 2d2d 2d0d 0a20 2020 206f 626a 6563  -----..    objec
-00000790: 740d 0a20 2020 2020 2020 2053 7061 7273  t..        Spars
-000007a0: 6556 6172 6961 626c 6520 7665 7273 696f  eVariable versio
-000007b0: 6e20 6f66 2060 7860 2e0d 0a20 2020 2022  n of `x`...    "
-000007c0: 2222 0d0a 0d0a 2020 2020 2320 544f 444f  ""....    # TODO
-000007d0: 0d0a 2020 2020 2320 5665 7269 6679 2074  ..    # Verify t
-000007e0: 6861 7420 7370 2069 7320 7375 6666 6963  hat sp is suffic
-000007f0: 6965 6e74 6c79 2073 7061 7273 652c 2061  iently sparse, a
-00000800: 6e64 2072 6169 7365 2061 0d0a 2020 2020  nd raise a..    
-00000810: 2320 7761 726e 696e 6720 6966 2069 7420  # warning if it 
-00000820: 6973 206e 6f74 0d0a 0d0a 2020 2020 6966  is not....    if
-00000830: 2069 7369 6e73 7461 6e63 6528 782c 2074   isinstance(x, t
-00000840: 6865 616e 6f2e 676f 662e 4170 706c 7929  heano.gof.Apply)
-00000850: 3a0d 0a20 2020 2020 2020 2069 6620 6c65  :..        if le
-00000860: 6e28 782e 6f75 7470 7574 7329 2021 3d20  n(x.outputs) != 
-00000870: 313a 0d0a 2020 2020 2020 2020 2020 2020  1:..            
-00000880: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
-00000890: 2822 4974 2069 7320 616d 6269 6775 6f75  ("It is ambiguou
-000008a0: 7320 7768 6963 6820 6f75 7470 7574 206f  s which output o
-000008b0: 6620 6120 220d 0a20 2020 2020 2020 2020  f a "..         
-000008c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000008d0: 2020 2020 226d 756c 7469 2d6f 7574 7075      "multi-outpu
-000008e0: 7420 4f70 2068 6173 2074 6f20 6265 2066  t Op has to be f
-000008f0: 6574 6368 6564 2e22 2c20 7829 0d0a 2020  etched.", x)..  
-00000900: 2020 2020 2020 656c 7365 3a0d 0a20 2020        else:..   
-00000910: 2020 2020 2020 2020 2078 203d 2078 2e6f           x = x.o
-00000920: 7574 7075 7473 5b30 5d0d 0a20 2020 2069  utputs[0]..    i
-00000930: 6620 6973 696e 7374 616e 6365 2878 2c20  f isinstance(x, 
-00000940: 7468 6561 6e6f 2e67 6f66 2e56 6172 6961  theano.gof.Varia
-00000950: 626c 6529 3a0d 0a20 2020 2020 2020 2069  ble):..        i
-00000960: 6620 6e6f 7420 6973 696e 7374 616e 6365  f not isinstance
-00000970: 2878 2e74 7970 652c 2074 6865 616e 6f2e  (x.type, theano.
-00000980: 7370 6172 7365 2e74 7970 652e 5370 6172  sparse.type.Spar
-00000990: 7365 5479 7065 293a 0d0a 2020 2020 2020  seType):..      
-000009a0: 2020 2020 2020 7261 6973 6520 5479 7065        raise Type
-000009b0: 4572 726f 7228 2256 6172 6961 626c 6520  Error("Variable 
-000009c0: 7479 7065 2066 6965 6c64 206d 7573 7420  type field must 
-000009d0: 6265 2061 2053 7061 7273 6554 7970 652e  be a SparseType.
-000009e0: 222c 2078 2c0d 0a20 2020 2020 2020 2020  ", x,..         
-000009f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000a00: 2020 2078 2e74 7970 6529 0d0a 2020 2020     x.type)..    
-00000a10: 2020 2020 7265 7475 726e 2078 0d0a 2020      return x..  
-00000a20: 2020 7472 793a 0d0a 2020 2020 2020 2020    try:..        
-00000a30: 7265 7475 726e 2074 6865 616e 6f2e 636f  return theano.co
-00000a40: 6e73 7461 6e74 2878 2c20 6e61 6d65 3d6e  nstant(x, name=n
-00000a50: 616d 6529 0d0a 2020 2020 6578 6365 7074  ame)..    except
-00000a60: 2054 7970 6545 7272 6f72 3a0d 0a20 2020   TypeError:..   
-00000a70: 2020 2020 2072 6169 7365 2054 7970 6545       raise TypeE
-00000a80: 7272 6f72 2822 4361 6e6e 6f74 2063 6f6e  rror("Cannot con
-00000a90: 7665 7274 2025 7320 746f 2053 7061 7273  vert %s to Spars
-00000aa0: 6554 7970 6522 2025 2078 2c20 7479 7065  eType" % x, type
-00000ab0: 2878 2929 0d0a 0d0a 0d0a 6173 5f73 7061  (x))......as_spa
-00000ac0: 7273 6520 3d20 6173 5f73 7061 7273 655f  rse = as_sparse_
-00000ad0: 7661 7269 6162 6c65 0d0a 0d0a 0d0a 636c  variable......cl
-00000ae0: 6173 7320 536f 6c76 6553 7061 7273 6528  ass SolveSparse(
-00000af0: 542e 4f70 293a 0d0a 2020 2020 2320 6974  T.Op):..    # it
-00000b00: 7970 6573 203d 205b 542e 6476 6563 746f  ypes = [T.dvecto
-00000b10: 725d 0d0a 2020 2020 2320 6f74 7970 6573  r]..    # otypes
-00000b20: 203d 205b 542e 6476 6563 746f 725d 0d0a   = [T.dvector]..
-00000b30: 0d0a 2020 2020 6465 6620 6d61 6b65 5f6e  ..    def make_n
-00000b40: 6f64 6528 7365 6c66 2c20 782c 2079 293a  ode(self, x, y):
-00000b50: 0d0a 2020 2020 2020 2020 782c 2079 203d  ..        x, y =
-00000b60: 2061 735f 7370 6172 7365 5f76 6172 6961   as_sparse_varia
-00000b70: 626c 6528 7829 2c20 6173 5f73 7061 7273  ble(x), as_spars
-00000b80: 655f 7661 7269 6162 6c65 2879 290d 0a20  e_variable(y).. 
-00000b90: 2020 2020 2020 2061 7373 6572 7420 782e         assert x.
-00000ba0: 666f 726d 6174 2069 6e20 5b22 6373 7222  format in ["csr"
-00000bb0: 2c20 2263 7363 225d 0d0a 2020 2020 2020  , "csc"]..      
-00000bc0: 2020 6173 7365 7274 2079 2e66 6f72 6d61    assert y.forma
-00000bd0: 7420 696e 205b 2263 7372 222c 2022 6373  t in ["csr", "cs
-00000be0: 6322 5d0d 0a20 2020 2020 2020 206f 7574  c"]..        out
-00000bf0: 5f64 7479 7065 203d 2074 6865 616e 6f2e  _dtype = theano.
-00000c00: 7363 616c 6172 2e75 7063 6173 7428 782e  scalar.upcast(x.
-00000c10: 7479 7065 2e64 7479 7065 2c20 792e 7479  type.dtype, y.ty
-00000c20: 7065 2e64 7479 7065 290d 0a20 2020 2020  pe.dtype)..     
-00000c30: 2020 2072 6574 7572 6e20 7468 6561 6e6f     return theano
-00000c40: 2e67 6f66 2e41 7070 6c79 2873 656c 662c  .gof.Apply(self,
-00000c50: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00000c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000c70: 2020 5b78 2c20 795d 2c0d 0a20 2020 2020    [x, y],..     
+000003e0: 696d 706f 7274 2061 6573 6172 610d 0a69  import aesara..i
+000003f0: 6d70 6f72 7420 6165 7361 7261 2e74 656e  mport aesara.ten
+00000400: 736f 7220 6173 2054 0d0a 6672 6f6d 2061  sor as T..from a
+00000410: 6573 6172 6120 696d 706f 7274 2073 7061  esara import spa
+00000420: 7273 650d 0a0d 0a69 6d70 6f72 7420 6165  rse....import ae
+00000430: 7361 7261 2e69 6665 6c73 6520 6173 2074  sara.ifelse as t
+00000440: 6966 0d0a 696d 706f 7274 206e 756d 7079  if..import numpy
+00000450: 2061 7320 6e70 0d0a 696d 706f 7274 2073   as np..import s
+00000460: 7973 0d0a 0d0a 2320 6368 6563 6b20 6966  ys....# check if
+00000470: 2073 6b63 7564 6120 6973 2069 6e73 7461   skcuda is insta
+00000480: 6c6c 6564 0d0a 7472 793a 0d0a 2020 2020  lled..try:..    
+00000490: 696d 706f 7274 2073 6b63 7564 610d 0a0d  import skcuda...
+000004a0: 0a20 2020 2053 4b43 5544 415f 494d 504f  .    SKCUDA_IMPO
+000004b0: 5254 203d 2054 7275 650d 0a65 7863 6570  RT = True..excep
+000004c0: 7420 496d 706f 7274 4572 726f 723a 0d0a  t ImportError:..
+000004d0: 2020 2020 534b 4355 4441 5f49 4d50 4f52      SKCUDA_IMPOR
+000004e0: 5420 3d20 4661 6c73 650d 0a0d 0a61 6573  T = False....aes
+000004f0: 6172 612e 636f 6e66 6967 2e6f 7065 6e6d  ara.config.openm
+00000500: 705f 656c 656d 7769 7365 5f6d 696e 7369  p_elemwise_minsi
+00000510: 7a65 203d 2035 3030 3030 0d0a 6165 7361  ze = 50000..aesa
+00000520: 7261 2e63 6f6e 6669 672e 6f70 656e 6d70  ra.config.openmp
+00000530: 203d 2054 7275 650d 0a0d 0a61 6573 6172   = True....aesar
+00000540: 612e 636f 6e66 6967 2e6f 7074 696d 697a  a.config.optimiz
+00000550: 6572 203d 2027 6661 7374 5f63 6f6d 7069  er = 'fast_compi
+00000560: 6c65 270d 0a61 6573 6172 612e 636f 6e66  le'..aesara.conf
+00000570: 6967 2e66 6c6f 6174 5820 3d20 2766 6c6f  ig.floatX = 'flo
+00000580: 6174 3332 270d 0a61 6573 6172 612e 636f  at32'..aesara.co
+00000590: 6e66 6967 2e6f 6e5f 6f70 745f 6572 726f  nfig.on_opt_erro
+000005a0: 7220 3d20 2769 676e 6f72 6527 0d0a 0d0a  r = 'ignore'....
+000005b0: 6165 7361 7261 2e63 6f6e 6669 672e 6578  aesara.config.ex
+000005c0: 6365 7074 696f 6e5f 7665 7262 6f73 6974  ception_verbosit
+000005d0: 7920 3d20 2768 6967 6827 0d0a 6165 7361  y = 'high'..aesa
+000005e0: 7261 2e63 6f6e 6669 672e 636f 6d70 7574  ra.config.comput
+000005f0: 655f 7465 7374 5f76 616c 7565 203d 2027  e_test_value = '
+00000600: 6f66 6627 0d0a 6165 7361 7261 2e63 6f6e  off'..aesara.con
+00000610: 6669 672e 7072 6f66 696c 655f 6d65 6d6f  fig.profile_memo
+00000620: 7279 203d 2046 616c 7365 0d0a 6165 7361  ry = False..aesa
+00000630: 7261 2e63 6f6e 6669 672e 7363 616e 2e64  ra.config.scan.d
+00000640: 6562 7567 203d 2046 616c 7365 0d0a 6165  ebug = False..ae
+00000650: 7361 7261 2e63 6f6e 6669 672e 7072 6f66  sara.config.prof
+00000660: 696c 6520 3d20 4661 6c73 650d 0a0d 0a0d  ile = False.....
+00000670: 0a64 6566 2061 735f 7370 6172 7365 5f76  .def as_sparse_v
+00000680: 6172 6961 626c 6528 782c 206e 616d 653d  ariable(x, name=
+00000690: 4e6f 6e65 293a 0d0a 2020 2020 2222 220d  None):..    """.
+000006a0: 0a20 2020 2057 7261 7070 6572 2061 726f  .    Wrapper aro
+000006b0: 756e 6420 5370 6172 7365 5661 7269 6162  und SparseVariab
+000006c0: 6c65 2063 6f6e 7374 7275 6374 6f72 2074  le constructor t
+000006d0: 6f20 636f 6e73 7472 7563 740d 0a20 2020  o construct..   
+000006e0: 2061 2056 6172 6961 626c 6520 7769 7468   a Variable with
+000006f0: 2061 2073 7061 7273 6520 6d61 7472 6978   a sparse matrix
+00000700: 2077 6974 6820 7468 6520 7361 6d65 2064   with the same d
+00000710: 7479 7065 2061 6e64 0d0a 2020 2020 666f  type and..    fo
+00000720: 726d 6174 2e0d 0a20 2020 2050 6172 616d  rmat...    Param
+00000730: 6574 6572 730d 0a20 2020 202d 2d2d 2d2d  eters..    -----
+00000740: 2d2d 2d2d 2d0d 0a20 2020 2078 0d0a 2020  -----..    x..  
+00000750: 2020 2020 2020 4120 7370 6172 7365 206d        A sparse m
+00000760: 6174 7269 782e 0d0a 2020 2020 5265 7475  atrix...    Retu
+00000770: 726e 730d 0a20 2020 202d 2d2d 2d2d 2d2d  rns..    -------
+00000780: 0d0a 2020 2020 6f62 6a65 6374 0d0a 2020  ..    object..  
+00000790: 2020 2020 2020 5370 6172 7365 5661 7269        SparseVari
+000007a0: 6162 6c65 2076 6572 7369 6f6e 206f 6620  able version of 
+000007b0: 6078 602e 0d0a 2020 2020 2222 220d 0a0d  `x`...    """...
+000007c0: 0a20 2020 2023 2054 4f44 4f0d 0a20 2020  .    # TODO..   
+000007d0: 2023 2056 6572 6966 7920 7468 6174 2073   # Verify that s
+000007e0: 7020 6973 2073 7566 6669 6369 656e 746c  p is sufficientl
+000007f0: 7920 7370 6172 7365 2c20 616e 6420 7261  y sparse, and ra
+00000800: 6973 6520 610d 0a20 2020 2023 2077 6172  ise a..    # war
+00000810: 6e69 6e67 2069 6620 6974 2069 7320 6e6f  ning if it is no
+00000820: 740d 0a0d 0a20 2020 2069 6620 6973 696e  t....    if isin
+00000830: 7374 616e 6365 2878 2c20 6165 7361 7261  stance(x, aesara
+00000840: 2e67 6f66 2e41 7070 6c79 293a 0d0a 2020  .gof.Apply):..  
+00000850: 2020 2020 2020 6966 206c 656e 2878 2e6f        if len(x.o
+00000860: 7574 7075 7473 2920 213d 2031 3a0d 0a20  utputs) != 1:.. 
+00000870: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00000880: 2056 616c 7565 4572 726f 7228 2249 7420   ValueError("It 
+00000890: 6973 2061 6d62 6967 756f 7573 2077 6869  is ambiguous whi
+000008a0: 6368 206f 7574 7075 7420 6f66 2061 2022  ch output of a "
+000008b0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000008c0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000008d0: 6d75 6c74 692d 6f75 7470 7574 204f 7020  multi-output Op 
+000008e0: 6861 7320 746f 2062 6520 6665 7463 6865  has to be fetche
+000008f0: 642e 222c 2078 290d 0a20 2020 2020 2020  d.", x)..       
+00000900: 2065 6c73 653a 0d0a 2020 2020 2020 2020   else:..        
+00000910: 2020 2020 7820 3d20 782e 6f75 7470 7574      x = x.output
+00000920: 735b 305d 0d0a 2020 2020 6966 2069 7369  s[0]..    if isi
+00000930: 6e73 7461 6e63 6528 782c 2061 6573 6172  nstance(x, aesar
+00000940: 612e 676f 662e 5661 7269 6162 6c65 293a  a.gof.Variable):
+00000950: 0d0a 2020 2020 2020 2020 6966 206e 6f74  ..        if not
+00000960: 2069 7369 6e73 7461 6e63 6528 782e 7479   isinstance(x.ty
+00000970: 7065 2c20 6165 7361 7261 2e73 7061 7273  pe, aesara.spars
+00000980: 652e 7479 7065 2e53 7061 7273 6554 7970  e.type.SparseTyp
+00000990: 6529 3a0d 0a20 2020 2020 2020 2020 2020  e):..           
+000009a0: 2072 6169 7365 2054 7970 6545 7272 6f72   raise TypeError
+000009b0: 2822 5661 7269 6162 6c65 2074 7970 6520  ("Variable type 
+000009c0: 6669 656c 6420 6d75 7374 2062 6520 6120  field must be a 
+000009d0: 5370 6172 7365 5479 7065 2e22 2c20 782c  SparseType.", x,
+000009e0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000009f0: 2020 2020 2020 2020 2020 2020 2020 782e                x.
+00000a00: 7479 7065 290d 0a20 2020 2020 2020 2072  type)..        r
+00000a10: 6574 7572 6e20 780d 0a20 2020 2074 7279  eturn x..    try
+00000a20: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
+00000a30: 6e20 6165 7361 7261 2e63 6f6e 7374 616e  n aesara.constan
+00000a40: 7428 782c 206e 616d 653d 6e61 6d65 290d  t(x, name=name).
+00000a50: 0a20 2020 2065 7863 6570 7420 5479 7065  .    except Type
+00000a60: 4572 726f 723a 0d0a 2020 2020 2020 2020  Error:..        
+00000a70: 7261 6973 6520 5479 7065 4572 726f 7228  raise TypeError(
+00000a80: 2243 616e 6e6f 7420 636f 6e76 6572 7420  "Cannot convert 
+00000a90: 2573 2074 6f20 5370 6172 7365 5479 7065  %s to SparseType
+00000aa0: 2220 2520 782c 2074 7970 6528 7829 290d  " % x, type(x)).
+00000ab0: 0a0d 0a0d 0a61 735f 7370 6172 7365 203d  .....as_sparse =
+00000ac0: 2061 735f 7370 6172 7365 5f76 6172 6961   as_sparse_varia
+00000ad0: 626c 650d 0a0d 0a0d 0a63 6c61 7373 2053  ble......class S
+00000ae0: 6f6c 7665 5370 6172 7365 2854 2e4f 7029  olveSparse(T.Op)
+00000af0: 3a0d 0a20 2020 2023 2069 7479 7065 7320  :..    # itypes 
+00000b00: 3d20 5b54 2e64 7665 6374 6f72 5d0d 0a20  = [T.dvector].. 
+00000b10: 2020 2023 206f 7479 7065 7320 3d20 5b54     # otypes = [T
+00000b20: 2e64 7665 6374 6f72 5d0d 0a0d 0a20 2020  .dvector]....   
+00000b30: 2064 6566 206d 616b 655f 6e6f 6465 2873   def make_node(s
+00000b40: 656c 662c 2078 2c20 7929 3a0d 0a20 2020  elf, x, y):..   
+00000b50: 2020 2020 2078 2c20 7920 3d20 6173 5f73       x, y = as_s
+00000b60: 7061 7273 655f 7661 7269 6162 6c65 2878  parse_variable(x
+00000b70: 292c 2061 735f 7370 6172 7365 5f76 6172  ), as_sparse_var
+00000b80: 6961 626c 6528 7929 0d0a 2020 2020 2020  iable(y)..      
+00000b90: 2020 6173 7365 7274 2078 2e66 6f72 6d61    assert x.forma
+00000ba0: 7420 696e 205b 2263 7372 222c 2022 6373  t in ["csr", "cs
+00000bb0: 6322 5d0d 0a20 2020 2020 2020 2061 7373  c"]..        ass
+00000bc0: 6572 7420 792e 666f 726d 6174 2069 6e20  ert y.format in 
+00000bd0: 5b22 6373 7222 2c20 2263 7363 225d 0d0a  ["csr", "csc"]..
+00000be0: 2020 2020 2020 2020 6f75 745f 6474 7970          out_dtyp
+00000bf0: 6520 3d20 6165 7361 7261 2e73 6361 6c61  e = aesara.scala
+00000c00: 722e 7570 6361 7374 2878 2e74 7970 652e  r.upcast(x.type.
+00000c10: 6474 7970 652c 2079 2e74 7970 652e 6474  dtype, y.type.dt
+00000c20: 7970 6529 0d0a 2020 2020 2020 2020 7265  ype)..        re
+00000c30: 7475 726e 2061 6573 6172 612e 676f 662e  turn aesara.gof.
+00000c40: 4170 706c 7928 7365 6c66 2c0d 0a20 2020  Apply(self,..   
+00000c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00000c60: 2020 2020 2020 2020 2020 2020 205b 782c               [x,
+00000c70: 2079 5d2c 0d0a 2020 2020 2020 2020 2020   y],..          
 00000c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000c90: 2020 2020 2020 2020 2020 205b 542e 7465             [T.te
-00000ca0: 6e73 6f72 286f 7574 5f64 7479 7065 2c20  nsor(out_dtype, 
-00000cb0: 6272 6f61 6463 6173 7461 626c 653d 2846  broadcastable=(F
-00000cc0: 616c 7365 2c29 295d 290d 0a20 2020 2020  alse,))])..     
-00000cd0: 2020 2023 2020 205b 7468 6561 6e6f 2e73     #   [theano.s
-00000ce0: 7061 7273 652e 7479 7065 2e53 7061 7273  parse.type.Spars
-00000cf0: 6554 7970 6528 6474 7970 653d 6f75 745f  eType(dtype=out_
-00000d00: 6474 7970 652c 0d0a 2020 2020 2020 2020  dtype,..        
-00000d10: 2320 2020 2020 2020 2020 2020 2020 2020  #               
-00000d20: 666f 726d 6174 3d78 2e74 7970 652e 666f  format=x.type.fo
-00000d30: 726d 6174 2928 295d 290d 0a0d 0a20 2020  rmat)()])....   
-00000d40: 2064 6566 2070 6572 666f 726d 2873 656c   def perform(sel
-00000d50: 662c 206e 6f64 652c 2069 6e70 7574 732c  f, node, inputs,
-00000d60: 206f 7574 7075 7473 293a 0d0a 2020 2020   outputs):..    
-00000d70: 2020 2020 6672 6f6d 2073 6369 7079 2e73      from scipy.s
-00000d80: 7061 7273 652e 6c69 6e61 6c67 2069 6d70  parse.linalg imp
-00000d90: 6f72 7420 7370 736f 6c76 650d 0a0d 0a20  ort spsolve.... 
-00000da0: 2020 2020 2020 2028 432c 2062 2920 3d20         (C, b) = 
-00000db0: 696e 7075 7473 0d0a 2020 2020 2020 2020  inputs..        
-00000dc0: 622e 6e64 696d 203d 2031 0d0a 2020 2020  b.ndim = 1..    
-00000dd0: 2020 2020 7765 6967 6874 7320 3d20 7370      weights = sp
-00000de0: 736f 6c76 6528 432c 2062 290d 0a20 2020  solve(C, b)..   
-00000df0: 2020 2020 206f 7574 7075 7473 5b30 5d5b       outputs[0][
-00000e00: 305d 203d 206e 702e 6172 7261 7928 7765  0] = np.array(we
-00000e10: 6967 6874 7329 0d0a 0d0a 0d0a 736f 6c76  ights)......solv
-00000e20: 203d 2053 6f6c 7665 5370 6172 7365 2829   = SolveSparse()
-00000e30: 0d0a 0d0a 0d0a 636c 6173 7320 5468 6561  ......class Thea
-00000e40: 6e6f 4772 6170 6850 726f 286f 626a 6563  noGraphPro(objec
-00000e50: 7429 3a0d 0a20 2020 2064 6566 205f 5f69  t):..    def __i
-00000e60: 6e69 745f 5f28 7365 6c66 2c20 6f70 7469  nit__(self, opti
-00000e70: 6d69 7a65 723d 2766 6173 745f 636f 6d70  mizer='fast_comp
-00000e80: 696c 6527 2c20 7665 7262 6f73 653d 4e6f  ile', verbose=No
-00000e90: 6e65 2c20 6474 7970 653d 4e6f 6e65 2c0d  ne, dtype=None,.
-00000ea0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00000eb0: 2020 6f75 7470 7574 3d4e 6f6e 652c 202a    output=None, *
-00000ec0: 2a6b 7761 7267 7329 3a0d 0a20 2020 2020  *kwargs):..     
-00000ed0: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-00000ee0: 436c 6173 7320 746f 2063 7265 6174 6520  Class to create 
-00000ef0: 7468 6520 7379 6d62 6f6c 6963 2074 6865  the symbolic the
-00000f00: 616e 6f20 6772 6170 6820 7769 7468 2061  ano graph with a
-00000f10: 6c6c 2074 6865 2069 6e74 6572 706f 6c61  ll the interpola
-00000f20: 7469 6f6e 2d46 5720 656e 6769 6e65 0d0a  tion-FW engine..
-00000f30: 0d0a 2020 2020 2020 2020 4172 6773 3a0d  ..        Args:.
-00000f40: 0a20 2020 2020 2020 2020 2020 206f 7074  .            opt
-00000f50: 696d 697a 6572 2028 7b66 6173 745f 636f  imizer ({fast_co
-00000f60: 6d70 696c 652c 2066 6173 745f 7275 6e7d  mpile, fast_run}
-00000f70: 293a 2054 6865 616e 6f20 6f70 7469 6d69  ): Theano optimi
-00000f80: 7a65 7220 6f70 7469 6f6e 2e20 5365 6520  zer option. See 
-00000f90: 7468 6561 6e6f 2064 6f63 730d 0a20 2020  theano docs..   
-00000fa0: 2020 2020 2020 2020 2076 6572 626f 7365           verbose
-00000fb0: 205b 6c69 7374 5d3a 206c 6973 7420 6f66   [list]: list of
-00000fc0: 206d 616e 7920 7061 7261 6d65 7465 7273   many parameters
-00000fd0: 2e20 4966 2074 6865 206e 616d 6520 6f66  . If the name of
-00000fe0: 2074 6865 2070 6172 616d 6574 6572 2069   the parameter i
-00000ff0: 7320 6f6e 2074 6865 206c 6973 7420 7468  s on the list th
-00001000: 6520 7661 6c75 6520 6f66 2074 6865 0d0a  e value of the..
-00001010: 2020 2020 2020 2020 2020 2020 2070 6172               par
-00001020: 616d 6574 6572 2077 696c 6c20 6265 2070  ameter will be p
-00001030: 7269 6e74 6564 2069 6e20 7275 6e20 7469  rinted in run ti
-00001040: 6d65 2e0d 0a20 2020 2020 2020 2020 2020  me...           
-00001050: 2064 7479 7065 205b 7b66 6c6f 6174 3634   dtype [{float64
-00001060: 2c20 666c 6f61 7433 327d 5d3a 2054 7970  , float32}]: Typ
-00001070: 6520 6f66 2066 6c6f 6174 0d0a 2020 2020  e of float..    
-00001080: 2020 2020 2020 2020 2a2a 206b 7761 7267          ** kwarg
-00001090: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
-000010a0: 2020 2020 2d20 6772 6164 6965 6e74 5b62      - gradient[b
-000010b0: 6f6f 6c5d 3a20 4966 2074 7275 6520 6164  ool]: If true ad
-000010c0: 6170 7420 7468 6520 6772 6170 6820 666f  apt the graph fo
-000010d0: 7220 4144 0d0a 2020 2020 2020 2020 2020  r AD..          
-000010e0: 2020 2020 2020 2d20 6d61 785f 7370 6565        - max_spee
-000010f0: 645b 696e 745d 3a20 4173 2074 6865 206e  d[int]: As the n
-00001100: 756d 6265 7220 6765 7473 2068 6967 6865  umber gets highe
-00001110: 7220 7472 7565 2067 7261 7068 2077 696c  r true graph wil
-00001120: 6c20 6265 2061 6461 7074 6564 2074 6f20  l be adapted to 
-00001130: 7265 7475 726e 206d 6561 6e69 6e67 6675  return meaningfu
-00001140: 6c0d 0a20 2020 2020 2020 2020 2020 2020  l..             
-00001150: 2020 2020 6772 6164 6965 6e74 7320 7769      gradients wi
-00001160: 7468 2041 440d 0a20 2020 2020 2020 2022  th AD..        "
-00001170: 2222 0d0a 2020 2020 2020 2020 7365 6c66  ""..        self
-00001180: 2e6c 656e 6768 745f 6f66 5f66 6175 6c74  .lenght_of_fault
-00001190: 7320 3d20 542e 6361 7374 2830 2c20 2769  s = T.cast(0, 'i
-000011a0: 6e74 3332 2729 0d0a 2020 2020 2020 2020  nt32')..        
-000011b0: 7365 6c66 2e70 6920 3d20 7468 6561 6e6f  self.pi = theano
-000011c0: 2e73 6861 7265 6428 332e 3134 3135 3932  .shared(3.141592
-000011d0: 3635 3335 392c 2027 7069 2729 0d0a 0d0a  65359, 'pi')....
-000011e0: 2020 2020 2020 2020 2320 4f50 5449 4f4e          # OPTION
-000011f0: 530d 0a20 2020 2020 2020 2023 202d 2d2d  S..        # ---
-00001200: 2d2d 2d2d 0d0a 2020 2020 2020 2020 6966  ----..        if
-00001210: 206f 7574 7075 7420 6973 204e 6f6e 653a   output is None:
-00001220: 0d0a 2020 2020 2020 2020 2020 2020 6f75  ..            ou
-00001230: 7470 7574 203d 205b 2767 656f 6c6f 6779  tput = ['geology
-00001240: 275d 0d0a 2020 2020 2020 2020 7365 6c66  ']..        self
-00001250: 2e6f 7574 7075 7420 3d20 6f75 7470 7574  .output = output
-00001260: 0d0a 0d0a 2020 2020 2020 2020 6966 2076  ....        if v
-00001270: 6572 626f 7365 2069 7320 4e6f 6e65 3a0d  erbose is None:.
-00001280: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-00001290: 662e 7665 7262 6f73 6520 3d20 5b4e 6f6e  f.verbose = [Non
-000012a0: 655d 0d0a 2020 2020 2020 2020 656c 7365  e]..        else
-000012b0: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
-000012c0: 656c 662e 7665 7262 6f73 6520 3d20 7665  elf.verbose = ve
-000012d0: 7262 6f73 650d 0a0d 0a20 2020 2020 2020  rbose....       
-000012e0: 2073 656c 662e 636f 6d70 7574 655f 7479   self.compute_ty
-000012f0: 7065 203d 206f 7574 7075 740d 0a0d 0a20  pe = output.... 
-00001300: 2020 2020 2020 2069 6620 6474 7970 6520         if dtype 
-00001310: 6973 204e 6f6e 653a 0d0a 2020 2020 2020  is None:..      
-00001320: 2020 2020 2020 6474 7970 6520 3d20 2766        dtype = 'f
-00001330: 6c6f 6174 3332 2720 6966 2074 6865 616e  loat32' if thean
-00001340: 6f2e 636f 6e66 6967 2e64 6576 6963 6520  o.config.device 
-00001350: 3d3d 2027 6375 6461 2720 656c 7365 2027  == 'cuda' else '
-00001360: 666c 6f61 7436 3427 0d0a 0d0a 2020 2020  float64'....    
-00001370: 2020 2020 7365 6c66 2e64 7479 7065 203d      self.dtype =
-00001380: 2064 7479 7065 0d0a 0d0a 2020 2020 2020   dtype....      
-00001390: 2020 2320 5472 6164 6520 7370 6565 6420    # Trade speed 
-000013a0: 666f 7220 6d65 6d6f 7279 2074 6869 7320  for memory this 
-000013b0: 7769 6c6c 2063 6f6e 7375 6d65 206d 6f72  will consume mor
-000013c0: 6520 6d65 6d6f 7279 0d0a 2020 2020 2020  e memory..      
-000013d0: 2020 7365 6c66 2e6d 6178 5f73 7065 6564    self.max_speed
-000013e0: 203d 206b 7761 7267 732e 6765 7428 276d   = kwargs.get('m
-000013f0: 6178 5f73 7065 6564 272c 2031 290d 0a20  ax_speed', 1).. 
-00001400: 2020 2020 2020 2073 656c 662e 7370 6172         self.spar
-00001410: 7365 5f76 6572 7369 6f6e 203d 206b 7761  se_version = kwa
-00001420: 7267 732e 6765 7428 2773 7061 7273 655f  rgs.get('sparse_
-00001430: 7665 7273 696f 6e27 2c20 4661 6c73 6529  version', False)
-00001440: 0d0a 0d0a 2020 2020 2020 2020 7365 6c66  ....        self
-00001450: 2e67 7261 6469 656e 7420 3d20 6b77 6172  .gradient = kwar
-00001460: 6773 2e67 6574 2827 6772 6164 6965 6e74  gs.get('gradient
-00001470: 272c 2046 616c 7365 290d 0a20 2020 2020  ', False)..     
-00001480: 2020 2073 656c 662e 6465 7669 6365 203d     self.device =
-00001490: 2074 6865 616e 6f2e 636f 6e66 6967 2e64   theano.config.d
-000014a0: 6576 6963 650d 0a20 2020 2020 2020 2074  evice..        t
-000014b0: 6865 616e 6f2e 636f 6e66 6967 2e66 6c6f  heano.config.flo
-000014c0: 6174 5820 3d20 6474 7970 650d 0a20 2020  atX = dtype..   
-000014d0: 2020 2020 2074 6865 616e 6f2e 636f 6e66       theano.conf
-000014e0: 6967 2e6f 7074 696d 697a 6572 203d 206f  ig.optimizer = o
-000014f0: 7074 696d 697a 6572 0d0a 0d0a 2020 2020  ptimizer....    
-00001500: 2020 2020 2320 434f 4e53 5441 4e54 2050      # CONSTANT P
-00001510: 4152 414d 4554 4552 5320 464f 5220 414c  ARAMETERS FOR AL
-00001520: 4c20 5345 5249 4553 0d0a 2020 2020 2020  L SERIES..      
-00001530: 2020 2320 4b52 4947 494e 470d 0a20 2020    # KRIGING..   
-00001540: 2020 2020 2023 202d 2d2d 2d2d 2d2d 0d0a       # -------..
-00001550: 0d0a 2020 2020 2020 2020 7365 6c66 2e61  ..        self.a
-00001560: 5f54 203d 2074 6865 616e 6f2e 7368 6172  _T = theano.shar
-00001570: 6564 286e 702e 6f6e 6573 2833 2c20 6474  ed(np.ones(3, dt
-00001580: 7970 653d 6474 7970 6529 2c20 2252 616e  ype=dtype), "Ran
-00001590: 6765 2229 0d0a 0d0a 2020 2020 2020 2020  ge")....        
-000015a0: 7365 6c66 2e61 5f54 5f73 6361 6c61 7220  self.a_T_scalar 
-000015b0: 3d20 7365 6c66 2e61 5f54 0d0a 2020 2020  = self.a_T..    
-000015c0: 2020 2020 7365 6c66 2e63 5f6f 5f54 203d      self.c_o_T =
-000015d0: 2074 6865 616e 6f2e 7368 6172 6564 286e   theano.shared(n
-000015e0: 702e 6f6e 6573 2833 2c20 6474 7970 653d  p.ones(3, dtype=
-000015f0: 6474 7970 6529 2c20 2743 6f76 6172 6961  dtype), 'Covaria
-00001600: 6e63 6520 6174 2030 2729 0d0a 2020 2020  nce at 0')..    
-00001610: 2020 2020 7365 6c66 2e63 5f6f 5f54 5f73      self.c_o_T_s
-00001620: 6361 6c61 7220 3d20 7365 6c66 2e63 5f6f  calar = self.c_o
-00001630: 5f54 0d0a 0d0a 2020 2020 2020 2020 7365  _T....        se
-00001640: 6c66 2e6e 5f75 6e69 7665 7273 616c 5f65  lf.n_universal_e
-00001650: 715f 5420 3d20 7468 6561 6e6f 2e73 6861  q_T = theano.sha
-00001660: 7265 6428 6e70 2e7a 6572 6f73 2835 2c20  red(np.zeros(5, 
-00001670: 6474 7970 653d 2769 6e74 3332 2729 2c0d  dtype='int32'),.
-00001680: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00000c90: 2020 2020 2020 5b54 2e74 656e 736f 7228        [T.tensor(
+00000ca0: 6f75 745f 6474 7970 652c 2062 726f 6164  out_dtype, broad
+00000cb0: 6361 7374 6162 6c65 3d28 4661 6c73 652c  castable=(False,
+00000cc0: 2929 5d29 0d0a 2020 2020 2020 2020 2320  ))])..        # 
+00000cd0: 2020 5b61 6573 6172 612e 7370 6172 7365    [aesara.sparse
+00000ce0: 2e74 7970 652e 5370 6172 7365 5479 7065  .type.SparseType
+00000cf0: 2864 7479 7065 3d6f 7574 5f64 7479 7065  (dtype=out_dtype
+00000d00: 2c0d 0a20 2020 2020 2020 2023 2020 2020  ,..        #    
+00000d10: 2020 2020 2020 2020 2020 2066 6f72 6d61             forma
+00000d20: 743d 782e 7479 7065 2e66 6f72 6d61 7429  t=x.type.format)
+00000d30: 2829 5d29 0d0a 0d0a 2020 2020 6465 6620  ()])....    def 
+00000d40: 7065 7266 6f72 6d28 7365 6c66 2c20 6e6f  perform(self, no
+00000d50: 6465 2c20 696e 7075 7473 2c20 6f75 7470  de, inputs, outp
+00000d60: 7574 7329 3a0d 0a20 2020 2020 2020 2066  uts):..        f
+00000d70: 726f 6d20 7363 6970 792e 7370 6172 7365  rom scipy.sparse
+00000d80: 2e6c 696e 616c 6720 696d 706f 7274 2073  .linalg import s
+00000d90: 7073 6f6c 7665 0d0a 0d0a 2020 2020 2020  psolve....      
+00000da0: 2020 2843 2c20 6229 203d 2069 6e70 7574    (C, b) = input
+00000db0: 730d 0a20 2020 2020 2020 2062 2e6e 6469  s..        b.ndi
+00000dc0: 6d20 3d20 310d 0a20 2020 2020 2020 2077  m = 1..        w
+00000dd0: 6569 6768 7473 203d 2073 7073 6f6c 7665  eights = spsolve
+00000de0: 2843 2c20 6229 0d0a 2020 2020 2020 2020  (C, b)..        
+00000df0: 6f75 7470 7574 735b 305d 5b30 5d20 3d20  outputs[0][0] = 
+00000e00: 6e70 2e61 7272 6179 2877 6569 6768 7473  np.array(weights
+00000e10: 290d 0a0d 0a0d 0a73 6f6c 7620 3d20 536f  )......solv = So
+00000e20: 6c76 6553 7061 7273 6528 290d 0a0d 0a0d  lveSparse().....
+00000e30: 0a63 6c61 7373 2061 6573 6172 6147 7261  .class aesaraGra
+00000e40: 7068 5072 6f28 6f62 6a65 6374 293a 0d0a  phPro(object):..
+00000e50: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
+00000e60: 2873 656c 662c 206f 7074 696d 697a 6572  (self, optimizer
+00000e70: 3d27 6661 7374 5f63 6f6d 7069 6c65 272c  ='fast_compile',
+00000e80: 2076 6572 626f 7365 3d4e 6f6e 652c 2064   verbose=None, d
+00000e90: 7479 7065 3d4e 6f6e 652c 0d0a 2020 2020  type=None,..    
+00000ea0: 2020 2020 2020 2020 2020 2020 206f 7574               out
+00000eb0: 7075 743d 4e6f 6e65 2c20 2a2a 6b77 6172  put=None, **kwar
+00000ec0: 6773 293a 0d0a 2020 2020 2020 2020 2222  gs):..        ""
+00000ed0: 220d 0a20 2020 2020 2020 2043 6c61 7373  "..        Class
+00000ee0: 2074 6f20 6372 6561 7465 2074 6865 2073   to create the s
+00000ef0: 796d 626f 6c69 6320 6165 7361 7261 2067  ymbolic aesara g
+00000f00: 7261 7068 2077 6974 6820 616c 6c20 7468  raph with all th
+00000f10: 6520 696e 7465 7270 6f6c 6174 696f 6e2d  e interpolation-
+00000f20: 4657 2065 6e67 696e 650d 0a0d 0a20 2020  FW engine....   
+00000f30: 2020 2020 2041 7267 733a 0d0a 2020 2020       Args:..    
+00000f40: 2020 2020 2020 2020 6f70 7469 6d69 7a65          optimize
+00000f50: 7220 287b 6661 7374 5f63 6f6d 7069 6c65  r ({fast_compile
+00000f60: 2c20 6661 7374 5f72 756e 7d29 3a20 6165  , fast_run}): ae
+00000f70: 7361 7261 206f 7074 696d 697a 6572 206f  sara optimizer o
+00000f80: 7074 696f 6e2e 2053 6565 2061 6573 6172  ption. See aesar
+00000f90: 6120 646f 6373 0d0a 2020 2020 2020 2020  a docs..        
+00000fa0: 2020 2020 7665 7262 6f73 6520 5b6c 6973      verbose [lis
+00000fb0: 745d 3a20 6c69 7374 206f 6620 6d61 6e79  t]: list of many
+00000fc0: 2070 6172 616d 6574 6572 732e 2049 6620   parameters. If 
+00000fd0: 7468 6520 6e61 6d65 206f 6620 7468 6520  the name of the 
+00000fe0: 7061 7261 6d65 7465 7220 6973 206f 6e20  parameter is on 
+00000ff0: 7468 6520 6c69 7374 2074 6865 2076 616c  the list the val
+00001000: 7565 206f 6620 7468 650d 0a20 2020 2020  ue of the..     
+00001010: 2020 2020 2020 2020 7061 7261 6d65 7465          paramete
+00001020: 7220 7769 6c6c 2062 6520 7072 696e 7465  r will be printe
+00001030: 6420 696e 2072 756e 2074 696d 652e 0d0a  d in run time...
+00001040: 2020 2020 2020 2020 2020 2020 6474 7970              dtyp
+00001050: 6520 5b7b 666c 6f61 7436 342c 2066 6c6f  e [{float64, flo
+00001060: 6174 3332 7d5d 3a20 5479 7065 206f 6620  at32}]: Type of 
+00001070: 666c 6f61 740d 0a20 2020 2020 2020 2020  float..         
+00001080: 2020 202a 2a20 6b77 6172 6773 3a0d 0a20     ** kwargs:.. 
+00001090: 2020 2020 2020 2020 2020 2020 2020 202d                 -
+000010a0: 2067 7261 6469 656e 745b 626f 6f6c 5d3a   gradient[bool]:
+000010b0: 2049 6620 7472 7565 2061 6461 7074 2074   If true adapt t
+000010c0: 6865 2067 7261 7068 2066 6f72 2041 440d  he graph for AD.
+000010d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000010e0: 202d 206d 6178 5f73 7065 6564 5b69 6e74   - max_speed[int
+000010f0: 5d3a 2041 7320 7468 6520 6e75 6d62 6572  ]: As the number
+00001100: 2067 6574 7320 6869 6768 6572 2074 7275   gets higher tru
+00001110: 6520 6772 6170 6820 7769 6c6c 2062 6520  e graph will be 
+00001120: 6164 6170 7465 6420 746f 2072 6574 7572  adapted to retur
+00001130: 6e20 6d65 616e 696e 6766 756c 0d0a 2020  n meaningful..  
+00001140: 2020 2020 2020 2020 2020 2020 2020 2067                 g
+00001150: 7261 6469 656e 7473 2077 6974 6820 4144  radients with AD
+00001160: 0d0a 2020 2020 2020 2020 2222 220d 0a20  ..        """.. 
+00001170: 2020 2020 2020 2073 656c 662e 6c65 6e67         self.leng
+00001180: 6874 5f6f 665f 6661 756c 7473 203d 2054  ht_of_faults = T
+00001190: 2e63 6173 7428 302c 2027 696e 7433 3227  .cast(0, 'int32'
+000011a0: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
+000011b0: 7069 203d 2061 6573 6172 612e 7368 6172  pi = aesara.shar
+000011c0: 6564 2833 2e31 3431 3539 3236 3533 3539  ed(3.14159265359
+000011d0: 2c20 2770 6927 290d 0a0d 0a20 2020 2020  , 'pi')....     
+000011e0: 2020 2023 204f 5054 494f 4e53 0d0a 2020     # OPTIONS..  
+000011f0: 2020 2020 2020 2320 2d2d 2d2d 2d2d 2d0d        # -------.
+00001200: 0a20 2020 2020 2020 2069 6620 6f75 7470  .        if outp
+00001210: 7574 2069 7320 4e6f 6e65 3a0d 0a20 2020  ut is None:..   
+00001220: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+00001230: 3d20 5b27 6765 6f6c 6f67 7927 5d0d 0a20  = ['geology'].. 
+00001240: 2020 2020 2020 2073 656c 662e 6f75 7470         self.outp
+00001250: 7574 203d 206f 7574 7075 740d 0a0d 0a20  ut = output.... 
+00001260: 2020 2020 2020 2069 6620 7665 7262 6f73         if verbos
+00001270: 6520 6973 204e 6f6e 653a 0d0a 2020 2020  e is None:..    
+00001280: 2020 2020 2020 2020 7365 6c66 2e76 6572          self.ver
+00001290: 626f 7365 203d 205b 4e6f 6e65 5d0d 0a20  bose = [None].. 
+000012a0: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
+000012b0: 2020 2020 2020 2020 2020 7365 6c66 2e76            self.v
+000012c0: 6572 626f 7365 203d 2076 6572 626f 7365  erbose = verbose
+000012d0: 0d0a 0d0a 2020 2020 2020 2020 7365 6c66  ....        self
+000012e0: 2e63 6f6d 7075 7465 5f74 7970 6520 3d20  .compute_type = 
+000012f0: 6f75 7470 7574 0d0a 0d0a 2020 2020 2020  output....      
+00001300: 2020 6966 2064 7479 7065 2069 7320 4e6f    if dtype is No
+00001310: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
+00001320: 2064 7479 7065 203d 2027 666c 6f61 7433   dtype = 'float3
+00001330: 3227 2069 6620 6165 7361 7261 2e63 6f6e  2' if aesara.con
+00001340: 6669 672e 6465 7669 6365 203d 3d20 2763  fig.device == 'c
+00001350: 7564 6127 2065 6c73 6520 2766 6c6f 6174  uda' else 'float
+00001360: 3634 270d 0a0d 0a20 2020 2020 2020 2073  64'....        s
+00001370: 656c 662e 6474 7970 6520 3d20 6474 7970  elf.dtype = dtyp
+00001380: 650d 0a0d 0a20 2020 2020 2020 2023 2054  e....        # T
+00001390: 7261 6465 2073 7065 6564 2066 6f72 206d  rade speed for m
+000013a0: 656d 6f72 7920 7468 6973 2077 696c 6c20  emory this will 
+000013b0: 636f 6e73 756d 6520 6d6f 7265 206d 656d  consume more mem
+000013c0: 6f72 790d 0a20 2020 2020 2020 2073 656c  ory..        sel
+000013d0: 662e 6d61 785f 7370 6565 6420 3d20 6b77  f.max_speed = kw
+000013e0: 6172 6773 2e67 6574 2827 6d61 785f 7370  args.get('max_sp
+000013f0: 6565 6427 2c20 3129 0d0a 2020 2020 2020  eed', 1)..      
+00001400: 2020 7365 6c66 2e73 7061 7273 655f 7665    self.sparse_ve
+00001410: 7273 696f 6e20 3d20 6b77 6172 6773 2e67  rsion = kwargs.g
+00001420: 6574 2827 7370 6172 7365 5f76 6572 7369  et('sparse_versi
+00001430: 6f6e 272c 2046 616c 7365 290d 0a0d 0a20  on', False).... 
+00001440: 2020 2020 2020 2073 656c 662e 6772 6164         self.grad
+00001450: 6965 6e74 203d 206b 7761 7267 732e 6765  ient = kwargs.ge
+00001460: 7428 2767 7261 6469 656e 7427 2c20 4661  t('gradient', Fa
+00001470: 6c73 6529 0d0a 2020 2020 2020 2020 7365  lse)..        se
+00001480: 6c66 2e64 6576 6963 6520 3d20 6165 7361  lf.device = aesa
+00001490: 7261 2e63 6f6e 6669 672e 6465 7669 6365  ra.config.device
+000014a0: 0d0a 2020 2020 2020 2020 6165 7361 7261  ..        aesara
+000014b0: 2e63 6f6e 6669 672e 666c 6f61 7458 203d  .config.floatX =
+000014c0: 2064 7479 7065 0d0a 2020 2020 2020 2020   dtype..        
+000014d0: 6165 7361 7261 2e63 6f6e 6669 672e 6f70  aesara.config.op
+000014e0: 7469 6d69 7a65 7220 3d20 6f70 7469 6d69  timizer = optimi
+000014f0: 7a65 720d 0a0d 0a20 2020 2020 2020 2023  zer....        #
+00001500: 2043 4f4e 5354 414e 5420 5041 5241 4d45   CONSTANT PARAME
+00001510: 5445 5253 2046 4f52 2041 4c4c 2053 4552  TERS FOR ALL SER
+00001520: 4945 530d 0a20 2020 2020 2020 2023 204b  IES..        # K
+00001530: 5249 4749 4e47 0d0a 2020 2020 2020 2020  RIGING..        
+00001540: 2320 2d2d 2d2d 2d2d 2d0d 0a0d 0a20 2020  # -------....   
+00001550: 2020 2020 2073 656c 662e 615f 5420 3d20       self.a_T = 
+00001560: 6165 7361 7261 2e73 6861 7265 6428 6e70  aesara.shared(np
+00001570: 2e6f 6e65 7328 332c 2064 7479 7065 3d64  .ones(3, dtype=d
+00001580: 7479 7065 292c 2022 5261 6e67 6522 290d  type), "Range").
+00001590: 0a0d 0a20 2020 2020 2020 2073 656c 662e  ...        self.
+000015a0: 615f 545f 7363 616c 6172 203d 2073 656c  a_T_scalar = sel
+000015b0: 662e 615f 540d 0a20 2020 2020 2020 2073  f.a_T..        s
+000015c0: 656c 662e 635f 6f5f 5420 3d20 6165 7361  elf.c_o_T = aesa
+000015d0: 7261 2e73 6861 7265 6428 6e70 2e6f 6e65  ra.shared(np.one
+000015e0: 7328 332c 2064 7479 7065 3d64 7479 7065  s(3, dtype=dtype
+000015f0: 292c 2027 436f 7661 7269 616e 6365 2061  ), 'Covariance a
+00001600: 7420 3027 290d 0a20 2020 2020 2020 2073  t 0')..        s
+00001610: 656c 662e 635f 6f5f 545f 7363 616c 6172  elf.c_o_T_scalar
+00001620: 203d 2073 656c 662e 635f 6f5f 540d 0a0d   = self.c_o_T...
+00001630: 0a20 2020 2020 2020 2073 656c 662e 6e5f  .        self.n_
+00001640: 756e 6976 6572 7361 6c5f 6571 5f54 203d  universal_eq_T =
+00001650: 2061 6573 6172 612e 7368 6172 6564 286e   aesara.shared(n
+00001660: 702e 7a65 726f 7328 352c 2064 7479 7065  p.zeros(5, dtype
+00001670: 3d27 696e 7433 3227 292c 0d0a 2020 2020  ='int32'),..    
+00001680: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00001690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000016a0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-000016b0: 4772 6164 6520 6f66 2074 6865 2075 6e69  Grade of the uni
-000016c0: 7665 7273 616c 2064 7269 6674 2229 0d0a  versal drift")..
-000016d0: 2020 2020 2020 2020 7365 6c66 2e6e 5f75          self.n_u
-000016e0: 6e69 7665 7273 616c 5f65 715f 545f 6f70  niversal_eq_T_op
-000016f0: 203d 2074 6865 616e 6f2e 7368 6172 6564   = theano.shared
-00001700: 2833 290d 0a0d 0a20 2020 2020 2020 2023  (3)....        #
-00001710: 2054 6865 7920 7765 6967 6874 2074 6865   They weight the
-00001720: 2063 6f6e 7472 6962 7574 696f 6e20 6f66   contribution of
-00001730: 2074 6865 2073 7572 6661 6365 5f70 6f69   the surface_poi
-00001740: 6e74 7320 6167 6169 6e73 7420 7468 6520  nts against the 
-00001750: 6f72 6965 6e74 6174 696f 6e73 2e0d 0a20  orientations... 
-00001760: 2020 2020 2020 2073 656c 662e 695f 7265         self.i_re
-00001770: 6573 6361 6c65 203d 2074 6865 616e 6f2e  escale = theano.
-00001780: 7368 6172 6564 286e 702e 6361 7374 5b64  shared(np.cast[d
-00001790: 7479 7065 5d28 342e 2929 0d0a 2020 2020  type](4.))..    
-000017a0: 2020 2020 7365 6c66 2e67 695f 7265 6573      self.gi_rees
-000017b0: 6361 6c65 203d 2074 6865 616e 6f2e 7368  cale = theano.sh
-000017c0: 6172 6564 286e 702e 6361 7374 5b64 7479  ared(np.cast[dty
-000017d0: 7065 5d28 322e 2929 0d0a 0d0a 2020 2020  pe](2.))....    
-000017e0: 2020 2020 2320 4e75 6d62 6572 206f 6620      # Number of 
-000017f0: 6469 6d65 6e73 696f 6e73 2e20 4e6f 7720  dimensions. Now 
-00001800: 6974 2069 7320 6e6f 7420 746f 6f20 7661  it is not too va
-00001810: 7269 6162 6c65 2061 6e79 6d6f 7265 0d0a  riable anymore..
-00001820: 2020 2020 2020 2020 7365 6c66 2e6e 5f64          self.n_d
-00001830: 696d 656e 7369 6f6e 7320 3d20 330d 0a0d  imensions = 3...
-00001840: 0a20 2020 2020 2020 2023 2054 6869 7320  .        # This 
-00001850: 6973 206e 6f74 2061 6363 756d 756c 6174  is not accumulat
-00001860: 6976 650d 0a20 2020 2020 2020 2073 656c  ive..        sel
-00001870: 662e 6e75 6d62 6572 5f6f 665f 706f 696e  f.number_of_poin
-00001880: 7473 5f70 6572 5f73 7572 6661 6365 5f54  ts_per_surface_T
-00001890: 203d 2074 6865 616e 6f2e 7368 6172 6564   = theano.shared
-000018a0: 280d 0a20 2020 2020 2020 2020 2020 206e  (..            n
-000018b0: 702e 7a65 726f 7328 332c 2064 7479 7065  p.zeros(3, dtype
-000018c0: 3d27 696e 7433 3227 292c 0d0a 2020 2020  ='int32'),..    
-000018d0: 2020 2020 2020 2020 274e 756d 6265 7220          'Number 
-000018e0: 6f66 2070 6f69 6e74 7320 7065 7220 7375  of points per su
-000018f0: 7266 6163 6520 7573 6564 2074 6f20 7370  rface used to sp
-00001900: 6c69 7420 7265 7374 2d72 6566 2729 0d0a  lit rest-ref')..
-00001910: 2020 2020 2020 2020 7365 6c66 2e6e 756d          self.num
-00001920: 6265 725f 6f66 5f70 6f69 6e74 735f 7065  ber_of_points_pe
-00001930: 725f 7375 7266 6163 655f 545f 6f70 203d  r_surface_T_op =
-00001940: 2054 2e76 6563 746f 7228 0d0a 2020 2020   T.vector(..    
-00001950: 2020 2020 2020 2020 274e 756d 6265 7220          'Number 
-00001960: 6f66 2070 6f69 6e74 7320 7065 7220 7375  of points per su
-00001970: 7266 6163 6520 7573 6564 2074 6f20 7370  rface used to sp
-00001980: 6c69 7420 7265 7374 2d72 6566 272c 0d0a  lit rest-ref',..
-00001990: 2020 2020 2020 2020 2020 2020 6474 7970              dtyp
-000019a0: 653d 2769 6e74 3332 2729 0d0a 2020 2020  e='int32')..    
-000019b0: 2020 2020 7365 6c66 2e6e 7066 203d 2054      self.npf = T
-000019c0: 2e63 756d 7375 6d28 0d0a 2020 2020 2020  .cumsum(..      
-000019d0: 2020 2020 2020 542e 636f 6e63 6174 656e        T.concaten
-000019e0: 6174 6528 2854 2e73 7461 636b 285b 305d  ate((T.stack([0]
-000019f0: 292c 2073 656c 662e 6e75 6d62 6572 5f6f  ), self.number_o
-00001a00: 665f 706f 696e 7473 5f70 6572 5f73 7572  f_points_per_sur
-00001a10: 6661 6365 5f54 5b3a 2d31 5d29 2929 0d0a  face_T[:-1])))..
-00001a20: 2020 2020 2020 2020 7365 6c66 2e6e 7066          self.npf
-00001a30: 5f6f 7020 3d20 7365 6c66 2e6e 7066 0d0a  _op = self.npf..
-00001a40: 2020 2020 2020 2020 7365 6c66 2e6e 7066          self.npf
-00001a50: 2e6e 616d 6520 3d20 274e 756d 6265 7220  .name = 'Number 
-00001a60: 6f66 2070 6f69 6e74 7320 7065 7220 7375  of points per su
-00001a70: 7266 6163 6573 2061 6674 6572 2072 6573  rfaces after res
-00001a80: 742d 7265 662e 2027 205c 0d0a 2020 2020  t-ref. ' \..    
-00001a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001aa0: 2020 2020 2754 6869 7320 6973 2075 7365      'This is use
-00001ab0: 6420 666f 7220 6669 6e64 696e 6720 7468  d for finding th
-00001ac0: 6520 6469 6666 6572 656e 7427 205c 0d0a  e different' \..
+000016a0: 2020 2020 2020 2020 2020 2247 7261 6465            "Grade
+000016b0: 206f 6620 7468 6520 756e 6976 6572 7361   of the universa
+000016c0: 6c20 6472 6966 7422 290d 0a20 2020 2020  l drift")..     
+000016d0: 2020 2073 656c 662e 6e5f 756e 6976 6572     self.n_univer
+000016e0: 7361 6c5f 6571 5f54 5f6f 7020 3d20 6165  sal_eq_T_op = ae
+000016f0: 7361 7261 2e73 6861 7265 6428 3329 0d0a  sara.shared(3)..
+00001700: 0d0a 2020 2020 2020 2020 2320 5468 6579  ..        # They
+00001710: 2077 6569 6768 7420 7468 6520 636f 6e74   weight the cont
+00001720: 7269 6275 7469 6f6e 206f 6620 7468 6520  ribution of the 
+00001730: 7375 7266 6163 655f 706f 696e 7473 2061  surface_points a
+00001740: 6761 696e 7374 2074 6865 206f 7269 656e  gainst the orien
+00001750: 7461 7469 6f6e 732e 0d0a 2020 2020 2020  tations...      
+00001760: 2020 7365 6c66 2e69 5f72 6565 7363 616c    self.i_reescal
+00001770: 6520 3d20 6165 7361 7261 2e73 6861 7265  e = aesara.share
+00001780: 6428 6e70 2e63 6173 745b 6474 7970 655d  d(np.cast[dtype]
+00001790: 2834 2e29 290d 0a20 2020 2020 2020 2073  (4.))..        s
+000017a0: 656c 662e 6769 5f72 6565 7363 616c 6520  elf.gi_reescale 
+000017b0: 3d20 6165 7361 7261 2e73 6861 7265 6428  = aesara.shared(
+000017c0: 6e70 2e63 6173 745b 6474 7970 655d 2832  np.cast[dtype](2
+000017d0: 2e29 290d 0a0d 0a20 2020 2020 2020 2023  .))....        #
+000017e0: 204e 756d 6265 7220 6f66 2064 696d 656e   Number of dimen
+000017f0: 7369 6f6e 732e 204e 6f77 2069 7420 6973  sions. Now it is
+00001800: 206e 6f74 2074 6f6f 2076 6172 6961 626c   not too variabl
+00001810: 6520 616e 796d 6f72 650d 0a20 2020 2020  e anymore..     
+00001820: 2020 2073 656c 662e 6e5f 6469 6d65 6e73     self.n_dimens
+00001830: 696f 6e73 203d 2033 0d0a 0d0a 2020 2020  ions = 3....    
+00001840: 2020 2020 2320 5468 6973 2069 7320 6e6f      # This is no
+00001850: 7420 6163 6375 6d75 6c61 7469 7665 0d0a  t accumulative..
+00001860: 2020 2020 2020 2020 7365 6c66 2e6e 756d          self.num
+00001870: 6265 725f 6f66 5f70 6f69 6e74 735f 7065  ber_of_points_pe
+00001880: 725f 7375 7266 6163 655f 5420 3d20 6165  r_surface_T = ae
+00001890: 7361 7261 2e73 6861 7265 6428 0d0a 2020  sara.shared(..  
+000018a0: 2020 2020 2020 2020 2020 6e70 2e7a 6572            np.zer
+000018b0: 6f73 2833 2c20 6474 7970 653d 2769 6e74  os(3, dtype='int
+000018c0: 3332 2729 2c0d 0a20 2020 2020 2020 2020  32'),..         
+000018d0: 2020 2027 4e75 6d62 6572 206f 6620 706f     'Number of po
+000018e0: 696e 7473 2070 6572 2073 7572 6661 6365  ints per surface
+000018f0: 2075 7365 6420 746f 2073 706c 6974 2072   used to split r
+00001900: 6573 742d 7265 6627 290d 0a20 2020 2020  est-ref')..     
+00001910: 2020 2073 656c 662e 6e75 6d62 6572 5f6f     self.number_o
+00001920: 665f 706f 696e 7473 5f70 6572 5f73 7572  f_points_per_sur
+00001930: 6661 6365 5f54 5f6f 7020 3d20 542e 7665  face_T_op = T.ve
+00001940: 6374 6f72 280d 0a20 2020 2020 2020 2020  ctor(..         
+00001950: 2020 2027 4e75 6d62 6572 206f 6620 706f     'Number of po
+00001960: 696e 7473 2070 6572 2073 7572 6661 6365  ints per surface
+00001970: 2075 7365 6420 746f 2073 706c 6974 2072   used to split r
+00001980: 6573 742d 7265 6627 2c0d 0a20 2020 2020  est-ref',..     
+00001990: 2020 2020 2020 2064 7479 7065 3d27 696e         dtype='in
+000019a0: 7433 3227 290d 0a20 2020 2020 2020 2073  t32')..        s
+000019b0: 656c 662e 6e70 6620 3d20 542e 6375 6d73  elf.npf = T.cums
+000019c0: 756d 280d 0a20 2020 2020 2020 2020 2020  um(..           
+000019d0: 2054 2e63 6f6e 6361 7465 6e61 7465 2828   T.concatenate((
+000019e0: 542e 7374 6163 6b28 5b30 5d29 2c20 7365  T.stack([0]), se
+000019f0: 6c66 2e6e 756d 6265 725f 6f66 5f70 6f69  lf.number_of_poi
+00001a00: 6e74 735f 7065 725f 7375 7266 6163 655f  nts_per_surface_
+00001a10: 545b 3a2d 315d 2929 290d 0a20 2020 2020  T[:-1])))..     
+00001a20: 2020 2073 656c 662e 6e70 665f 6f70 203d     self.npf_op =
+00001a30: 2073 656c 662e 6e70 660d 0a20 2020 2020   self.npf..     
+00001a40: 2020 2073 656c 662e 6e70 662e 6e61 6d65     self.npf.name
+00001a50: 203d 2027 4e75 6d62 6572 206f 6620 706f   = 'Number of po
+00001a60: 696e 7473 2070 6572 2073 7572 6661 6365  ints per surface
+00001a70: 7320 6166 7465 7220 7265 7374 2d72 6566  s after rest-ref
+00001a80: 2e20 2720 5c0d 0a20 2020 2020 2020 2020  . ' \..         
+00001a90: 2020 2020 2020 2020 2020 2020 2020 2027                 '
+00001aa0: 5468 6973 2069 7320 7573 6564 2066 6f72  This is used for
+00001ab0: 2066 696e 6469 6e67 2074 6865 2064 6966   finding the dif
+00001ac0: 6665 7265 6e74 2720 5c0d 0a20 2020 2020  ferent' \..     
 00001ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001ae0: 2020 2020 2020 2020 2773 7572 6661 6365          'surface
-00001af0: 2070 6f69 6e74 7320 7769 7468 696e 6720   points withing 
-00001b00: 6120 6c61 7965 722e 270d 0a0d 0a20 2020  a layer.'....   
-00001b10: 2020 2020 2073 656c 662e 6e75 6767 6574       self.nugget
-00001b20: 5f65 6666 6563 745f 6772 6164 5f54 203d  _effect_grad_T =
-00001b30: 2074 6865 616e 6f2e 7368 6172 6564 286e   theano.shared(n
-00001b40: 702e 6361 7374 5b64 7479 7065 5d28 6e70  p.cast[dtype](np
-00001b50: 2e6f 6e65 7328 3429 292c 0d0a 2020 2020  .ones(4)),..    
-00001b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001b80: 2020 2020 2020 2020 2020 2020 2020 274e                'N
-00001b90: 7567 6765 7420 6566 6665 6374 206f 6620  ugget effect of 
-00001ba0: 6772 6164 6965 6e74 7327 290d 0a20 2020  gradients')..   
-00001bb0: 2020 2020 2073 656c 662e 6e75 6767 6574       self.nugget
-00001bc0: 5f65 6666 6563 745f 7363 616c 6172 5f54  _effect_scalar_T
-00001bd0: 203d 2074 6865 616e 6f2e 7368 6172 6564   = theano.shared
-00001be0: 286e 702e 6361 7374 5b64 7479 7065 5d28  (np.cast[dtype](
-00001bf0: 6e70 2e6f 6e65 7328 3429 292c 0d0a 2020  np.ones(4)),..  
-00001c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001c30: 2020 274e 7567 6765 7420 6566 6665 6374    'Nugget effect
-00001c40: 206f 6620 7363 616c 6172 2729 0d0a 0d0a   of scalar')....
-00001c50: 2020 2020 2020 2020 7365 6c66 2e6e 7567          self.nug
-00001c60: 6765 745f 6566 6665 6374 5f67 7261 645f  get_effect_grad_
-00001c70: 545f 6f70 203d 2073 656c 662e 6e75 6767  T_op = self.nugg
-00001c80: 6574 5f65 6666 6563 745f 6772 6164 5f54  et_effect_grad_T
-00001c90: 0d0a 0d0a 2020 2020 2020 2020 2320 434f  ....        # CO
-00001ca0: 4d50 5554 4520 5745 4947 4854 530d 0a20  MPUTE WEIGHTS.. 
-00001cb0: 2020 2020 2020 2023 202d 2d2d 2d2d 2d2d         # -------
-00001cc0: 2d2d 0d0a 2020 2020 2020 2020 2320 5641  --..        # VA
-00001cd0: 5249 4142 4c45 530d 0a20 2020 2020 2020  RIABLES..       
-00001ce0: 2023 202d 2d2d 2d2d 2d2d 2d2d 0d0a 2020   # ---------..  
-00001cf0: 2020 2020 2020 7365 6c66 2e64 6970 735f        self.dips_
-00001d00: 706f 7369 7469 6f6e 5f61 6c6c 203d 2054  position_all = T
-00001d10: 2e6d 6174 7269 7828 2250 6f73 6974 696f  .matrix("Positio
-00001d20: 6e20 6f66 2074 6865 2064 6970 7322 290d  n of the dips").
-00001d30: 0a20 2020 2020 2020 2073 656c 662e 6469  .        self.di
-00001d40: 705f 616e 676c 6573 5f61 6c6c 203d 2054  p_angles_all = T
-00001d50: 2e76 6563 746f 7228 2241 6e67 6c65 206f  .vector("Angle o
-00001d60: 6620 6576 6572 7920 6469 7022 290d 0a20  f every dip").. 
-00001d70: 2020 2020 2020 2073 656c 662e 617a 696d         self.azim
-00001d80: 7574 685f 616c 6c20 3d20 542e 7665 6374  uth_all = T.vect
-00001d90: 6f72 2822 417a 696d 7574 6822 290d 0a20  or("Azimuth").. 
-00001da0: 2020 2020 2020 2073 656c 662e 706f 6c61         self.pola
-00001db0: 7269 7479 5f61 6c6c 203d 2054 2e76 6563  rity_all = T.vec
-00001dc0: 746f 7228 2250 6f6c 6172 6974 7922 290d  tor("Polarity").
-00001dd0: 0a0d 0a20 2020 2020 2020 2073 656c 662e  ...        self.
-00001de0: 7375 7266 6163 655f 706f 696e 7473 5f61  surface_points_a
-00001df0: 6c6c 203d 2054 2e6d 6174 7269 7828 2241  ll = T.matrix("A
-00001e00: 6c6c 2074 6865 2073 7572 6661 6365 5f70  ll the surface_p
-00001e10: 6f69 6e74 7320 706f 696e 7473 2061 7420  oints points at 
-00001e20: 6f6e 6365 2229 0d0a 0d0a 2020 2020 2020  once")....      
-00001e30: 2020 7365 6c66 2e6c 656e 5f70 6f69 6e74    self.len_point
-00001e40: 7320 3d20 7365 6c66 2e73 7572 6661 6365  s = self.surface
-00001e50: 5f70 6f69 6e74 735f 616c 6c2e 7368 6170  _points_all.shap
-00001e60: 655b 305d 202d 205c 0d0a 2020 2020 2020  e[0] - \..      
-00001e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001e80: 2020 2020 7365 6c66 2e6e 756d 6265 725f      self.number_
-00001e90: 6f66 5f70 6f69 6e74 735f 7065 725f 7375  of_points_per_su
-00001ea0: 7266 6163 655f 542e 7368 6170 655b 305d  rface_T.shape[0]
-00001eb0: 0d0a 0d0a 2020 2020 2020 2020 2320 5469  ....        # Ti
-00001ec0: 6c69 6e67 2064 6970 7320 746f 2074 6865  ling dips to the
-00001ed0: 2033 2073 7061 7469 616c 2063 6f6f 7264   3 spatial coord
-00001ee0: 696e 6174 696f 6e73 0d0a 2020 2020 2020  inations..      
-00001ef0: 2020 7365 6c66 2e64 6970 735f 706f 7369    self.dips_posi
-00001f00: 7469 6f6e 203d 2073 656c 662e 6469 7073  tion = self.dips
-00001f10: 5f70 6f73 6974 696f 6e5f 616c 6c0d 0a20  _position_all.. 
-00001f20: 2020 2020 2020 2073 656c 662e 6469 7073         self.dips
-00001f30: 5f70 6f73 6974 696f 6e5f 7469 6c65 6420  _position_tiled 
-00001f40: 3d20 542e 7469 6c65 2873 656c 662e 6469  = T.tile(self.di
-00001f50: 7073 5f70 6f73 6974 696f 6e2c 2028 7365  ps_position, (se
-00001f60: 6c66 2e6e 5f64 696d 656e 7369 6f6e 732c  lf.n_dimensions,
-00001f70: 2031 2929 0d0a 0d0a 2020 2020 2020 2020   1))....        
-00001f80: 2320 5468 6573 6520 6172 6520 7375 6273  # These are subs
-00001f90: 6574 7320 6f66 2074 6865 2064 6174 6120  ets of the data 
-00001fa0: 666f 7220 6561 6368 2073 6572 6965 732e  for each series.
-00001fb0: 2049 2069 6e69 7469 616c 697a 6564 2074   I initialized t
-00001fc0: 6865 6d20 6173 2074 6865 2077 686f 6c65  hem as the whole
-00001fd0: 2061 7272 6179 7320 6275 7420 7468 656e   arrays but then
-00001fe0: 2074 6865 7920 7769 6c6c 2074 616b 650d   they will take.
-00001ff0: 0a20 2020 2020 2020 2023 2074 6865 2064  .        # the d
-00002000: 6174 6120 6f66 2065 7665 7279 2070 6f74  ata of every pot
-00002010: 656e 7469 616c 2066 6965 6c64 0d0a 2020  ential field..  
-00002020: 2020 2020 2020 7365 6c66 2e64 6970 5f61        self.dip_a
-00002030: 6e67 6c65 7320 3d20 7365 6c66 2e64 6970  ngles = self.dip
-00002040: 5f61 6e67 6c65 735f 616c 6c0d 0a20 2020  _angles_all..   
-00002050: 2020 2020 2073 656c 662e 617a 696d 7574       self.azimut
-00002060: 6820 3d20 7365 6c66 2e61 7a69 6d75 7468  h = self.azimuth
-00002070: 5f61 6c6c 0d0a 2020 2020 2020 2020 7365  _all..        se
-00002080: 6c66 2e70 6f6c 6172 6974 7920 3d20 7365  lf.polarity = se
-00002090: 6c66 2e70 6f6c 6172 6974 795f 616c 6c0d  lf.polarity_all.
-000020a0: 0a0d 0a20 2020 2020 2020 2072 6573 745f  ...        rest_
-000020b0: 7265 665f 6175 7820 3d20 7365 6c66 2e73  ref_aux = self.s
-000020c0: 6574 5f72 6573 745f 7265 665f 6d61 7472  et_rest_ref_matr
-000020d0: 6978 2873 656c 662e 6e75 6d62 6572 5f6f  ix(self.number_o
-000020e0: 665f 706f 696e 7473 5f70 6572 5f73 7572  f_points_per_sur
-000020f0: 6661 6365 5f54 290d 0a20 2020 2020 2020  face_T)..       
-00002100: 2073 656c 662e 7265 665f 6c61 7965 725f   self.ref_layer_
-00002110: 706f 696e 7473 5f61 6c6c 203d 2072 6573  points_all = res
-00002120: 745f 7265 665f 6175 785b 305d 0d0a 2020  t_ref_aux[0]..  
-00002130: 2020 2020 2020 7365 6c66 2e72 6573 745f        self.rest_
-00002140: 6c61 7965 725f 706f 696e 7473 5f61 6c6c  layer_points_all
-00002150: 203d 2072 6573 745f 7265 665f 6175 785b   = rest_ref_aux[
-00002160: 315d 0d0a 0d0a 2020 2020 2020 2020 7365  1]....        se
-00002170: 6c66 2e6e 7567 6765 745f 6566 6665 6374  lf.nugget_effect
-00002180: 5f73 6361 6c61 725f 545f 7265 665f 7265  _scalar_T_ref_re
-00002190: 7374 203d 2073 656c 662e 7365 745f 6e75  st = self.set_nu
-000021a0: 6767 6574 5f73 7572 6661 6365 5f70 6f69  gget_surface_poi
-000021b0: 6e74 7328 0d0a 2020 2020 2020 2020 2020  nts(..          
-000021c0: 2020 7265 7374 5f72 6566 5f61 7578 5b32    rest_ref_aux[2
-000021d0: 5d2c 2072 6573 745f 7265 665f 6175 785b  ], rest_ref_aux[
-000021e0: 335d 2c0d 0a20 2020 2020 2020 2020 2020  3],..           
-000021f0: 2073 656c 662e 6e75 6d62 6572 5f6f 665f   self.number_of_
-00002200: 706f 696e 7473 5f70 6572 5f73 7572 6661  points_per_surfa
-00002210: 6365 5f54 290d 0a0d 0a20 2020 2020 2020  ce_T)....       
-00002220: 2073 656c 662e 6e75 6767 6574 5f65 6666   self.nugget_eff
-00002230: 6563 745f 7363 616c 6172 5f54 5f6f 7020  ect_scalar_T_op 
-00002240: 3d20 7365 6c66 2e6e 7567 6765 745f 6566  = self.nugget_ef
-00002250: 6665 6374 5f73 6361 6c61 725f 545f 7265  fect_scalar_T_re
-00002260: 665f 7265 7374 0d0a 0d0a 2020 2020 2020  f_rest....      
-00002270: 2020 7365 6c66 2e72 6566 5f6c 6179 6572    self.ref_layer
-00002280: 5f70 6f69 6e74 7320 3d20 7365 6c66 2e72  _points = self.r
-00002290: 6566 5f6c 6179 6572 5f70 6f69 6e74 735f  ef_layer_points_
-000022a0: 616c 6c0d 0a20 2020 2020 2020 2073 656c  all..        sel
-000022b0: 662e 7265 7374 5f6c 6179 6572 5f70 6f69  f.rest_layer_poi
-000022c0: 6e74 7320 3d20 7365 6c66 2e72 6573 745f  nts = self.rest_
-000022d0: 6c61 7965 725f 706f 696e 7473 5f61 6c6c  layer_points_all
-000022e0: 0d0a 0d0a 2020 2020 2020 2020 7365 6c66  ....        self
-000022f0: 2e66 6175 6c74 5f6d 6174 7269 7820 3d20  .fault_matrix = 
-00002300: 542e 6d61 7472 6978 280d 0a20 2020 2020  T.matrix(..     
-00002310: 2020 2020 2020 2027 4675 6c6c 2062 6c6f         'Full blo
-00002320: 636b 206d 6174 7269 7820 666f 7220 6661  ck matrix for fa
-00002330: 756c 7473 206f 7220 6472 6966 742e 2027  ults or drift. '
-00002340: 0d0a 2020 2020 2020 2020 2020 2020 2757  ..            'W
-00002350: 6520 7461 6b65 2032 2074 696d 6573 206c  e take 2 times l
-00002360: 656e 2070 6f69 6e74 7320 666f 7220 7468  en points for th
-00002370: 6520 6661 756c 7427 0d0a 2020 2020 2020  e fault'..      
-00002380: 2020 2020 2020 2764 7269 6674 2e27 290d        'drift.').
-00002390: 0a0d 0a20 2020 2020 2020 2073 656c 662e  ...        self.
-000023a0: 696e 7075 745f 7061 7261 6d65 7465 7273  input_parameters
-000023b0: 5f6b 7269 6769 6e67 203d 205b 7365 6c66  _kriging = [self
-000023c0: 2e64 6970 735f 706f 7369 7469 6f6e 5f61  .dips_position_a
-000023d0: 6c6c 2c20 7365 6c66 2e64 6970 5f61 6e67  ll, self.dip_ang
-000023e0: 6c65 735f 616c 6c2c 0d0a 2020 2020 2020  les_all,..      
-000023f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002410: 2020 2073 656c 662e 617a 696d 7574 685f     self.azimuth_
-00002420: 616c 6c2c 0d0a 2020 2020 2020 2020 2020  all,..          
-00002430: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002440: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00002450: 656c 662e 706f 6c61 7269 7479 5f61 6c6c  elf.polarity_all
-00002460: 2c20 7365 6c66 2e73 7572 6661 6365 5f70  , self.surface_p
-00002470: 6f69 6e74 735f 616c 6c2c 0d0a 2020 2020  oints_all,..    
-00002480: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000024a0: 2020 2020 2073 656c 662e 6661 756c 745f       self.fault_
-000024b0: 6d61 7472 6978 5d0d 0a0d 0a20 2020 2020  matrix]....     
-000024c0: 2020 2023 2043 4f4d 5055 5445 2053 4341     # COMPUTE SCA
-000024d0: 4c41 5220 4649 454c 4453 0d0a 2020 2020  LAR FIELDS..    
-000024e0: 2020 2020 2320 2d2d 2d2d 2d2d 2d2d 2d0d      # ---------.
-000024f0: 0a20 2020 2020 2020 2023 2056 4152 4941  .        # VARIA
-00002500: 424c 4553 0d0a 2020 2020 2020 2020 2320  BLES..        # 
-00002510: 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020 2020  ---------..     
-00002520: 2020 2073 656c 662e 6772 6964 5f76 616c     self.grid_val
-00002530: 5f54 203d 2054 2e6d 6174 7269 7828 2743  _T = T.matrix('C
-00002540: 6f6f 7264 696e 6174 6573 206f 6620 7468  oordinates of th
-00002550: 6520 6772 6964 2070 6f69 6e74 7320 746f  e grid points to
-00002560: 2069 6e74 6572 706f 6c61 7465 2729 0d0a   interpolate')..
-00002570: 2020 2020 2020 2020 7365 6c66 2e69 6e70          self.inp
-00002580: 7574 5f70 6172 616d 6574 6572 735f 6578  ut_parameters_ex
-00002590: 706f 7274 203d 205b 7365 6c66 2e64 6970  port = [self.dip
-000025a0: 735f 706f 7369 7469 6f6e 5f61 6c6c 2c0d  s_position_all,.
-000025b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000025c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000025d0: 2020 2020 2020 2020 2073 656c 662e 7375           self.su
-000025e0: 7266 6163 655f 706f 696e 7473 5f61 6c6c  rface_points_all
-000025f0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00002600: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002610: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00002620: 6661 756c 745f 6d61 7472 6978 2c0d 0a20  fault_matrix,.. 
-00002630: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002650: 2020 2020 2020 2073 656c 662e 6772 6964         self.grid
-00002660: 5f76 616c 5f54 5d0d 0a0d 0a20 2020 2020  _val_T]....     
-00002670: 2020 2073 656c 662e 696e 7075 745f 7061     self.input_pa
-00002680: 7261 6d65 7465 7273 5f6b 7269 6769 6e67  rameters_kriging
-00002690: 5f65 7870 6f72 7420 3d20 5b73 656c 662e  _export = [self.
-000026a0: 6469 7073 5f70 6f73 6974 696f 6e5f 616c  dips_position_al
-000026b0: 6c2c 0d0a 2020 2020 2020 2020 2020 2020  l,..            
-000026c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001ae0: 2020 2027 7375 7266 6163 6520 706f 696e     'surface poin
+00001af0: 7473 2077 6974 6869 6e67 2061 206c 6179  ts withing a lay
+00001b00: 6572 2e27 0d0a 0d0a 2020 2020 2020 2020  er.'....        
+00001b10: 7365 6c66 2e6e 7567 6765 745f 6566 6665  self.nugget_effe
+00001b20: 6374 5f67 7261 645f 5420 3d20 6165 7361  ct_grad_T = aesa
+00001b30: 7261 2e73 6861 7265 6428 6e70 2e63 6173  ra.shared(np.cas
+00001b40: 745b 6474 7970 655d 286e 702e 6f6e 6573  t[dtype](np.ones
+00001b50: 2834 2929 2c20 274e 7567 6765 7420 6566  (4)), 'Nugget ef
+00001b60: 6665 6374 206f 6620 6772 6164 6965 6e74  fect of gradient
+00001b70: 7327 290d 0a20 2020 2020 2020 2073 656c  s')..        sel
+00001b80: 662e 6e75 6767 6574 5f65 6666 6563 745f  f.nugget_effect_
+00001b90: 7363 616c 6172 5f54 203d 2061 6573 6172  scalar_T = aesar
+00001ba0: 612e 7368 6172 6564 286e 702e 6361 7374  a.shared(np.cast
+00001bb0: 5b64 7479 7065 5d28 6e70 2e6f 6e65 7328  [dtype](np.ones(
+00001bc0: 3429 292c 2027 4e75 6767 6574 2065 6666  4)), 'Nugget eff
+00001bd0: 6563 7420 6f66 2073 6361 6c61 7227 290d  ect of scalar').
+00001be0: 0a0d 0a20 2020 2020 2020 2073 656c 662e  ...        self.
+00001bf0: 6e75 6767 6574 5f65 6666 6563 745f 6772  nugget_effect_gr
+00001c00: 6164 5f54 5f6f 7020 3d20 7365 6c66 2e6e  ad_T_op = self.n
+00001c10: 7567 6765 745f 6566 6665 6374 5f67 7261  ugget_effect_gra
+00001c20: 645f 540d 0a0d 0a20 2020 2020 2020 2023  d_T....        #
+00001c30: 2043 4f4d 5055 5445 2057 4549 4748 5453   COMPUTE WEIGHTS
+00001c40: 0d0a 2020 2020 2020 2020 2320 2d2d 2d2d  ..        # ----
+00001c50: 2d2d 2d2d 2d0d 0a20 2020 2020 2020 2023  -----..        #
+00001c60: 2056 4152 4941 424c 4553 0d0a 2020 2020   VARIABLES..    
+00001c70: 2020 2020 2320 2d2d 2d2d 2d2d 2d2d 2d0d      # ---------.
+00001c80: 0a20 2020 2020 2020 2073 656c 662e 6469  .        self.di
+00001c90: 7073 5f70 6f73 6974 696f 6e5f 616c 6c20  ps_position_all 
+00001ca0: 3d20 542e 6d61 7472 6978 2822 506f 7369  = T.matrix("Posi
+00001cb0: 7469 6f6e 206f 6620 7468 6520 6469 7073  tion of the dips
+00001cc0: 2229 0d0a 2020 2020 2020 2020 7365 6c66  ")..        self
+00001cd0: 2e64 6970 5f61 6e67 6c65 735f 616c 6c20  .dip_angles_all 
+00001ce0: 3d20 542e 7665 6374 6f72 2822 416e 676c  = T.vector("Angl
+00001cf0: 6520 6f66 2065 7665 7279 2064 6970 2229  e of every dip")
+00001d00: 0d0a 2020 2020 2020 2020 7365 6c66 2e61  ..        self.a
+00001d10: 7a69 6d75 7468 5f61 6c6c 203d 2054 2e76  zimuth_all = T.v
+00001d20: 6563 746f 7228 2241 7a69 6d75 7468 2229  ector("Azimuth")
+00001d30: 0d0a 2020 2020 2020 2020 7365 6c66 2e70  ..        self.p
+00001d40: 6f6c 6172 6974 795f 616c 6c20 3d20 542e  olarity_all = T.
+00001d50: 7665 6374 6f72 2822 506f 6c61 7269 7479  vector("Polarity
+00001d60: 2229 0d0a 0d0a 2020 2020 2020 2020 7365  ")....        se
+00001d70: 6c66 2e73 7572 6661 6365 5f70 6f69 6e74  lf.surface_point
+00001d80: 735f 616c 6c20 3d20 542e 6d61 7472 6978  s_all = T.matrix
+00001d90: 2822 416c 6c20 7468 6520 7375 7266 6163  ("All the surfac
+00001da0: 655f 706f 696e 7473 2070 6f69 6e74 7320  e_points points 
+00001db0: 6174 206f 6e63 6522 290d 0a0d 0a20 2020  at once")....   
+00001dc0: 2020 2020 2073 656c 662e 6c65 6e5f 706f       self.len_po
+00001dd0: 696e 7473 203d 2073 656c 662e 7375 7266  ints = self.surf
+00001de0: 6163 655f 706f 696e 7473 5f61 6c6c 2e73  ace_points_all.s
+00001df0: 6861 7065 5b30 5d20 2d20 5c0d 0a20 2020  hape[0] - \..   
+00001e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001e10: 2020 2020 2020 2073 656c 662e 6e75 6d62         self.numb
+00001e20: 6572 5f6f 665f 706f 696e 7473 5f70 6572  er_of_points_per
+00001e30: 5f73 7572 6661 6365 5f54 2e73 6861 7065  _surface_T.shape
+00001e40: 5b30 5d0d 0a0d 0a20 2020 2020 2020 2023  [0]....        #
+00001e50: 2054 696c 696e 6720 6469 7073 2074 6f20   Tiling dips to 
+00001e60: 7468 6520 3320 7370 6174 6961 6c20 636f  the 3 spatial co
+00001e70: 6f72 6469 6e61 7469 6f6e 730d 0a20 2020  ordinations..   
+00001e80: 2020 2020 2073 656c 662e 6469 7073 5f70       self.dips_p
+00001e90: 6f73 6974 696f 6e20 3d20 7365 6c66 2e64  osition = self.d
+00001ea0: 6970 735f 706f 7369 7469 6f6e 5f61 6c6c  ips_position_all
+00001eb0: 0d0a 2020 2020 2020 2020 7365 6c66 2e64  ..        self.d
+00001ec0: 6970 735f 706f 7369 7469 6f6e 5f74 696c  ips_position_til
+00001ed0: 6564 203d 2054 2e74 696c 6528 7365 6c66  ed = T.tile(self
+00001ee0: 2e64 6970 735f 706f 7369 7469 6f6e 2c20  .dips_position, 
+00001ef0: 2873 656c 662e 6e5f 6469 6d65 6e73 696f  (self.n_dimensio
+00001f00: 6e73 2c20 3129 290d 0a0d 0a20 2020 2020  ns, 1))....     
+00001f10: 2020 2023 2054 6865 7365 2061 7265 2073     # These are s
+00001f20: 7562 7365 7473 206f 6620 7468 6520 6461  ubsets of the da
+00001f30: 7461 2066 6f72 2065 6163 6820 7365 7269  ta for each seri
+00001f40: 6573 2e20 4920 696e 6974 6961 6c69 7a65  es. I initialize
+00001f50: 6420 7468 656d 2061 7320 7468 6520 7768  d them as the wh
+00001f60: 6f6c 6520 6172 7261 7973 2062 7574 2074  ole arrays but t
+00001f70: 6865 6e20 7468 6579 2077 696c 6c20 7461  hen they will ta
+00001f80: 6b65 0d0a 2020 2020 2020 2020 2320 7468  ke..        # th
+00001f90: 6520 6461 7461 206f 6620 6576 6572 7920  e data of every 
+00001fa0: 706f 7465 6e74 6961 6c20 6669 656c 640d  potential field.
+00001fb0: 0a20 2020 2020 2020 2073 656c 662e 6469  .        self.di
+00001fc0: 705f 616e 676c 6573 203d 2073 656c 662e  p_angles = self.
+00001fd0: 6469 705f 616e 676c 6573 5f61 6c6c 0d0a  dip_angles_all..
+00001fe0: 2020 2020 2020 2020 7365 6c66 2e61 7a69          self.azi
+00001ff0: 6d75 7468 203d 2073 656c 662e 617a 696d  muth = self.azim
+00002000: 7574 685f 616c 6c0d 0a20 2020 2020 2020  uth_all..       
+00002010: 2073 656c 662e 706f 6c61 7269 7479 203d   self.polarity =
+00002020: 2073 656c 662e 706f 6c61 7269 7479 5f61   self.polarity_a
+00002030: 6c6c 0d0a 0d0a 2020 2020 2020 2020 7265  ll....        re
+00002040: 7374 5f72 6566 5f61 7578 203d 2073 656c  st_ref_aux = sel
+00002050: 662e 7365 745f 7265 7374 5f72 6566 5f6d  f.set_rest_ref_m
+00002060: 6174 7269 7828 7365 6c66 2e6e 756d 6265  atrix(self.numbe
+00002070: 725f 6f66 5f70 6f69 6e74 735f 7065 725f  r_of_points_per_
+00002080: 7375 7266 6163 655f 5429 0d0a 2020 2020  surface_T)..    
+00002090: 2020 2020 7365 6c66 2e72 6566 5f6c 6179      self.ref_lay
+000020a0: 6572 5f70 6f69 6e74 735f 616c 6c20 3d20  er_points_all = 
+000020b0: 7265 7374 5f72 6566 5f61 7578 5b30 5d0d  rest_ref_aux[0].
+000020c0: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
+000020d0: 7374 5f6c 6179 6572 5f70 6f69 6e74 735f  st_layer_points_
+000020e0: 616c 6c20 3d20 7265 7374 5f72 6566 5f61  all = rest_ref_a
+000020f0: 7578 5b31 5d0d 0a0d 0a20 2020 2020 2020  ux[1]....       
+00002100: 2073 656c 662e 6e75 6767 6574 5f65 6666   self.nugget_eff
+00002110: 6563 745f 7363 616c 6172 5f54 5f72 6566  ect_scalar_T_ref
+00002120: 5f72 6573 7420 3d20 7365 6c66 2e73 6574  _rest = self.set
+00002130: 5f6e 7567 6765 745f 7375 7266 6163 655f  _nugget_surface_
+00002140: 706f 696e 7473 280d 0a20 2020 2020 2020  points(..       
+00002150: 2020 2020 2072 6573 745f 7265 665f 6175       rest_ref_au
+00002160: 785b 325d 2c20 7265 7374 5f72 6566 5f61  x[2], rest_ref_a
+00002170: 7578 5b33 5d2c 0d0a 2020 2020 2020 2020  ux[3],..        
+00002180: 2020 2020 7365 6c66 2e6e 756d 6265 725f      self.number_
+00002190: 6f66 5f70 6f69 6e74 735f 7065 725f 7375  of_points_per_su
+000021a0: 7266 6163 655f 5429 0d0a 0d0a 2020 2020  rface_T)....    
+000021b0: 2020 2020 7365 6c66 2e6e 7567 6765 745f      self.nugget_
+000021c0: 6566 6665 6374 5f73 6361 6c61 725f 545f  effect_scalar_T_
+000021d0: 6f70 203d 2073 656c 662e 6e75 6767 6574  op = self.nugget
+000021e0: 5f65 6666 6563 745f 7363 616c 6172 5f54  _effect_scalar_T
+000021f0: 5f72 6566 5f72 6573 740d 0a0d 0a20 2020  _ref_rest....   
+00002200: 2020 2020 2073 656c 662e 7265 665f 6c61       self.ref_la
+00002210: 7965 725f 706f 696e 7473 203d 2073 656c  yer_points = sel
+00002220: 662e 7265 665f 6c61 7965 725f 706f 696e  f.ref_layer_poin
+00002230: 7473 5f61 6c6c 0d0a 2020 2020 2020 2020  ts_all..        
+00002240: 7365 6c66 2e72 6573 745f 6c61 7965 725f  self.rest_layer_
+00002250: 706f 696e 7473 203d 2073 656c 662e 7265  points = self.re
+00002260: 7374 5f6c 6179 6572 5f70 6f69 6e74 735f  st_layer_points_
+00002270: 616c 6c0d 0a0d 0a20 2020 2020 2020 2073  all....        s
+00002280: 656c 662e 6661 756c 745f 6d61 7472 6978  elf.fault_matrix
+00002290: 203d 2054 2e6d 6174 7269 7828 0d0a 2020   = T.matrix(..  
+000022a0: 2020 2020 2020 2020 2020 2746 756c 6c20            'Full 
+000022b0: 626c 6f63 6b20 6d61 7472 6978 2066 6f72  block matrix for
+000022c0: 2066 6175 6c74 7320 6f72 2064 7269 6674   faults or drift
+000022d0: 2e20 270d 0a20 2020 2020 2020 2020 2020  . '..           
+000022e0: 2027 5765 2074 616b 6520 3220 7469 6d65   'We take 2 time
+000022f0: 7320 6c65 6e20 706f 696e 7473 2066 6f72  s len points for
+00002300: 2074 6865 2066 6175 6c74 270d 0a20 2020   the fault'..   
+00002310: 2020 2020 2020 2020 2027 6472 6966 742e           'drift.
+00002320: 2729 0d0a 0d0a 2020 2020 2020 2020 7365  ')....        se
+00002330: 6c66 2e69 6e70 7574 5f70 6172 616d 6574  lf.input_paramet
+00002340: 6572 735f 6b72 6967 696e 6720 3d20 5b73  ers_kriging = [s
+00002350: 656c 662e 6469 7073 5f70 6f73 6974 696f  elf.dips_positio
+00002360: 6e5f 616c 6c2c 2073 656c 662e 6469 705f  n_all, self.dip_
+00002370: 616e 676c 6573 5f61 6c6c 2c0d 0a20 2020  angles_all,..   
+00002380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000023a0: 2020 2020 2020 7365 6c66 2e61 7a69 6d75        self.azimu
+000023b0: 7468 5f61 6c6c 2c0d 0a20 2020 2020 2020  th_all,..       
+000023c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000023d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000023e0: 2020 7365 6c66 2e70 6f6c 6172 6974 795f    self.polarity_
+000023f0: 616c 6c2c 2073 656c 662e 7375 7266 6163  all, self.surfac
+00002400: 655f 706f 696e 7473 5f61 6c6c 2c0d 0a20  e_points_all,.. 
+00002410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002420: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002430: 2020 2020 2020 2020 7365 6c66 2e66 6175          self.fau
+00002440: 6c74 5f6d 6174 7269 785d 0d0a 0d0a 2020  lt_matrix]....  
+00002450: 2020 2020 2020 2320 434f 4d50 5554 4520        # COMPUTE 
+00002460: 5343 414c 4152 2046 4945 4c44 530d 0a20  SCALAR FIELDS.. 
+00002470: 2020 2020 2020 2023 202d 2d2d 2d2d 2d2d         # -------
+00002480: 2d2d 0d0a 2020 2020 2020 2020 2320 5641  --..        # VA
+00002490: 5249 4142 4c45 530d 0a20 2020 2020 2020  RIABLES..       
+000024a0: 2023 202d 2d2d 2d2d 2d2d 2d2d 0d0a 2020   # ---------..  
+000024b0: 2020 2020 2020 7365 6c66 2e67 7269 645f        self.grid_
+000024c0: 7661 6c5f 5420 3d20 542e 6d61 7472 6978  val_T = T.matrix
+000024d0: 2827 436f 6f72 6469 6e61 7465 7320 6f66  ('Coordinates of
+000024e0: 2074 6865 2067 7269 6420 706f 696e 7473   the grid points
+000024f0: 2074 6f20 696e 7465 7270 6f6c 6174 6527   to interpolate'
+00002500: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
+00002510: 696e 7075 745f 7061 7261 6d65 7465 7273  input_parameters
+00002520: 5f65 7870 6f72 7420 3d20 5b73 656c 662e  _export = [self.
+00002530: 6469 7073 5f70 6f73 6974 696f 6e5f 616c  dips_position_al
+00002540: 6c2c 0d0a 2020 2020 2020 2020 2020 2020  l,..            
+00002550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002560: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00002570: 2e73 7572 6661 6365 5f70 6f69 6e74 735f  .surface_points_
+00002580: 616c 6c2c 0d0a 2020 2020 2020 2020 2020  all,..          
+00002590: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000025a0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+000025b0: 6c66 2e66 6175 6c74 5f6d 6174 7269 782c  lf.fault_matrix,
+000025c0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000025d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000025e0: 2020 2020 2020 2020 2020 7365 6c66 2e67            self.g
+000025f0: 7269 645f 7661 6c5f 545d 0d0a 0d0a 2020  rid_val_T]....  
+00002600: 2020 2020 2020 7365 6c66 2e69 6e70 7574        self.input
+00002610: 5f70 6172 616d 6574 6572 735f 6b72 6967  _parameters_krig
+00002620: 696e 675f 6578 706f 7274 203d 205b 7365  ing_export = [se
+00002630: 6c66 2e64 6970 735f 706f 7369 7469 6f6e  lf.dips_position
+00002640: 5f61 6c6c 2c0d 0a20 2020 2020 2020 2020  _all,..         
+00002650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002660: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002670: 2020 2020 2020 2073 656c 662e 6469 705f         self.dip_
+00002680: 616e 676c 6573 5f61 6c6c 2c0d 0a20 2020  angles_all,..   
+00002690: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000026a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000026b0: 2020 2020 2020 2020 2020 2020 2073 656c               sel
+000026c0: 662e 617a 696d 7574 685f 616c 6c2c 0d0a  f.azimuth_all,..
 000026d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000026e0: 2020 2020 7365 6c66 2e64 6970 5f61 6e67      self.dip_ang
-000026f0: 6c65 735f 616c 6c2c 0d0a 2020 2020 2020  les_all,..      
-00002700: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002720: 2020 2020 2020 2020 2020 7365 6c66 2e61            self.a
-00002730: 7a69 6d75 7468 5f61 6c6c 2c0d 0a20 2020  zimuth_all,..   
-00002740: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002760: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-00002770: 662e 706f 6c61 7269 7479 5f61 6c6c 2c0d  f.polarity_all,.
-00002780: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00002790: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000027a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000027b0: 2073 656c 662e 7375 7266 6163 655f 706f   self.surface_po
-000027c0: 696e 7473 5f61 6c6c 2c0d 0a20 2020 2020  ints_all,..     
+000026e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000026f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002700: 7365 6c66 2e70 6f6c 6172 6974 795f 616c  self.polarity_al
+00002710: 6c2c 0d0a 2020 2020 2020 2020 2020 2020  l,..            
+00002720: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002730: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002740: 2020 2020 7365 6c66 2e73 7572 6661 6365      self.surface
+00002750: 5f70 6f69 6e74 735f 616c 6c2c 0d0a 2020  _points_all,..  
+00002760: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002780: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00002790: 6c66 2e66 6175 6c74 5f6d 6174 7269 782c  lf.fault_matrix,
+000027a0: 2073 656c 662e 6772 6964 5f76 616c 5f54   self.grid_val_T
+000027b0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+000027c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000027d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000027e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000027f0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00002800: 6661 756c 745f 6d61 7472 6978 2c20 7365  fault_matrix, se
-00002810: 6c66 2e67 7269 645f 7661 6c5f 542c 0d0a  lf.grid_val_T,..
-00002820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002850: 5d0d 0a0d 0a20 2020 2020 2020 2023 2069  ]....        # i
-00002860: 6e74 6572 6661 6365 5f6c 6f63 203d 2073  nterface_loc = s
-00002870: 656c 662e 6661 756c 745f 6d61 7472 6978  elf.fault_matrix
-00002880: 2e73 6861 7065 5b31 5d20 2d20 3220 2a20  .shape[1] - 2 * 
-00002890: 7365 6c66 2e6c 656e 5f70 6f69 6e74 730d  self.len_points.
-000028a0: 0a20 2020 2020 2020 2069 6e74 6572 6661  .        interfa
-000028b0: 6365 5f6c 6f63 203d 2030 2020 2320 7365  ce_loc = 0  # se
-000028c0: 6c66 2e67 7269 645f 7661 6c5f 542e 7368  lf.grid_val_T.sh
-000028d0: 6170 655b 305d 0d0a 2020 2020 2020 2020  ape[0]..        
-000028e0: 7365 6c66 2e66 6175 6c74 5f64 7269 6674  self.fault_drift
-000028f0: 5f61 745f 7375 7266 6163 655f 706f 696e  _at_surface_poin
-00002900: 7473 5f72 6573 7420 3d20 7365 6c66 2e66  ts_rest = self.f
-00002910: 6175 6c74 5f6d 6174 7269 785b 0d0a 2020  ault_matrix[..  
-00002920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002930: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002950: 3a2c 0d0a 2020 2020 2020 2020 2020 2020  :,..            
-00002960: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002980: 2020 2020 2020 696e 7465 7266 6163 655f        interface_
-00002990: 6c6f 633a 2069 6e74 6572 6661 6365 5f6c  loc: interface_l
-000029a0: 6f63 202b 2073 656c 662e 6c65 6e5f 706f  oc + self.len_po
-000029b0: 696e 7473 5d0d 0a20 2020 2020 2020 2073  ints]..        s
-000029c0: 656c 662e 6661 756c 745f 6472 6966 745f  elf.fault_drift_
-000029d0: 6174 5f73 7572 6661 6365 5f70 6f69 6e74  at_surface_point
-000029e0: 735f 7265 6620 3d20 7365 6c66 2e66 6175  s_ref = self.fau
-000029f0: 6c74 5f6d 6174 7269 785b 0d0a 2020 2020  lt_matrix[..    
-00002a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002a20: 2020 2020 2020 2020 2020 2020 203a 2c0d               :,.
-00002a30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00002a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002a60: 2020 696e 7465 7266 6163 655f 6c6f 6320    interface_loc 
-00002a70: 2b20 7365 6c66 2e6c 656e 5f70 6f69 6e74  + self.len_point
-00002a80: 733a 5d0d 0a0d 0a20 2020 2020 2020 2023  s:]....        #
-00002a90: 2043 4f4d 5055 5445 2042 4c4f 434b 530d   COMPUTE BLOCKS.
-00002aa0: 0a20 2020 2020 2020 2023 202d 2d2d 2d2d  .        # -----
-00002ab0: 2d2d 2d2d 0d0a 2020 2020 2020 2020 2320  ----..        # 
-00002ac0: 5641 5249 4142 4c45 530d 0a20 2020 2020  VARIABLES..     
-00002ad0: 2020 2023 202d 2d2d 2d2d 2d2d 2d2d 0d0a     # ---------..
-00002ae0: 0d0a 2020 2020 2020 2020 6966 2073 656c  ..        if sel
-00002af0: 662e 6772 6164 6965 6e74 3a0d 0a20 2020  f.gradient:..   
-00002b00: 2020 2020 2020 2020 2073 656c 662e 7369           self.si
-00002b10: 675f 736c 6f70 6520 3d20 7468 6561 6e6f  g_slope = theano
-00002b20: 2e73 6861 7265 6428 6e70 2e61 7272 6179  .shared(np.array
-00002b30: 2835 302c 2064 7479 7065 3d64 7479 7065  (50, dtype=dtype
-00002b40: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
-00002b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002b60: 2020 2020 2020 2020 2020 2020 2020 2027                 '
-00002b70: 5369 676d 6f69 6420 736c 6f70 6520 666f  Sigmoid slope fo
-00002b80: 7220 6772 6164 6965 6e74 2729 0d0a 2020  r gradient')..  
-00002b90: 2020 2020 2020 656c 7365 3a0d 0a20 2020        else:..   
-00002ba0: 2020 2020 2020 2020 2073 656c 662e 7369           self.si
-00002bb0: 675f 736c 6f70 6520 3d20 7468 6561 6e6f  g_slope = theano
-00002bc0: 2e73 6861 7265 6428 6e70 2e61 7272 6179  .shared(np.array
-00002bd0: 2835 3030 3030 2c20 6474 7970 653d 6474  (50000, dtype=dt
-00002be0: 7970 6529 2c0d 0a20 2020 2020 2020 2020  ype),..         
-00002bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002c10: 2020 2753 6967 6d6f 6964 2073 6c6f 7065    'Sigmoid slope
-00002c20: 2729 0d0a 2020 2020 2020 2020 2020 2020  ')..            
-00002c30: 7365 6c66 2e6e 6f74 5f6c 203d 2074 6865  self.not_l = the
-00002c40: 616e 6f2e 7368 6172 6564 286e 702e 6172  ano.shared(np.ar
-00002c50: 7261 7928 3530 2e2c 2064 7479 7065 3d64  ray(50., dtype=d
-00002c60: 7479 7065 292c 2027 5369 676d 6f69 6420  type), 'Sigmoid 
-00002c70: 4f75 7473 6964 6527 290d 0a20 2020 2020  Outside')..     
-00002c80: 2020 2020 2020 2073 656c 662e 656c 6c69         self.elli
-00002c90: 7073 655f 6661 6374 6f72 5f65 7870 6f6e  pse_factor_expon
-00002ca0: 656e 7420 3d20 7468 6561 6e6f 2e73 6861  ent = theano.sha
-00002cb0: 7265 6428 6e70 2e61 7272 6179 2832 2e2c  red(np.array(2.,
-00002cc0: 2064 7479 7065 3d64 7479 7065 292c 0d0a   dtype=dtype),..
-00002cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002ce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002d00: 2020 2020 2020 2020 2027 4174 7465 6e75           'Attenu
-00002d10: 6174 696f 6e20 6661 6374 6f72 2729 0d0a  ation factor')..
-00002d20: 0d0a 2020 2020 2020 2020 2320 4974 2069  ..        # It i
-00002d30: 7320 6120 6d61 7472 6978 2062 6563 6175  s a matrix becau
-00002d40: 7365 206f 6620 7468 6520 7661 6c75 6573  se of the values
-00002d50: 3a20 706f 726f 7369 7479 2c20 7375 732c  : porosity, sus,
-00002d60: 2065 7463 0d0a 2020 2020 2020 2020 7365   etc..        se
-00002d70: 6c66 2e76 616c 7565 735f 7072 6f70 6572  lf.values_proper
-00002d80: 7469 6573 5f6f 7020 3d20 542e 6d61 7472  ties_op = T.matr
-00002d90: 6978 2827 5661 6c75 6573 2074 6861 7420  ix('Values that 
-00002da0: 7468 6520 626c 6f63 6b73 2061 7265 2074  the blocks are t
-00002db0: 616b 696e 6727 290d 0a0d 0a20 2020 2020  aking')....     
-00002dc0: 2020 2073 656c 662e 6e5f 7375 7266 6163     self.n_surfac
-00002dd0: 6520 3d20 542e 6172 616e 6765 2831 2c20  e = T.arange(1, 
-00002de0: 3530 3030 2c20 6474 7970 653d 2769 6e74  5000, dtype='int
-00002df0: 3332 2729 0d0a 2020 2020 2020 2020 7365  32')..        se
-00002e00: 6c66 2e6e 5f73 7572 6661 6365 2e6e 616d  lf.n_surface.nam
-00002e10: 6520 3d20 2749 4420 6f66 2073 7572 6661  e = 'ID of surfa
-00002e20: 6365 7327 0d0a 0d0a 2020 2020 2020 2020  ces'....        
-00002e30: 7365 6c66 2e69 6e70 7574 5f70 6172 616d  self.input_param
-00002e40: 6574 6572 735f 626c 6f63 6b20 3d20 5b73  eters_block = [s
-00002e50: 656c 662e 6469 7073 5f70 6f73 6974 696f  elf.dips_positio
-00002e60: 6e5f 616c 6c2c 2073 656c 662e 6469 705f  n_all, self.dip_
-00002e70: 616e 676c 6573 5f61 6c6c 2c0d 0a20 2020  angles_all,..   
-00002e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002ea0: 2020 2020 7365 6c66 2e61 7a69 6d75 7468      self.azimuth
-00002eb0: 5f61 6c6c 2c0d 0a20 2020 2020 2020 2020  _all,..         
-00002ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002ed0: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00002ee0: 6c66 2e70 6f6c 6172 6974 795f 616c 6c2c  lf.polarity_all,
-00002ef0: 2073 656c 662e 7375 7266 6163 655f 706f   self.surface_po
-00002f00: 696e 7473 5f61 6c6c 2c0d 0a20 2020 2020  ints_all,..     
-00002f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002f30: 2020 7365 6c66 2e66 6175 6c74 5f6d 6174    self.fault_mat
-00002f40: 7269 782c 2073 656c 662e 6772 6964 5f76  rix, self.grid_v
-00002f50: 616c 5f54 2c0d 0a20 2020 2020 2020 2020  al_T,..         
-00002f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002f70: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00002f80: 6c66 2e76 616c 7565 735f 7072 6f70 6572  lf.values_proper
-00002f90: 7469 6573 5f6f 705d 0d0a 2020 2020 2020  ties_op]..      
-00002fa0: 2020 2320 2d2d 2d2d 2d2d 0d0a 2020 2020    # ------..    
-00002fb0: 2020 2020 2320 5368 6172 6564 0d0a 2020      # Shared..  
-00002fc0: 2020 2020 2020 2320 2d2d 2d2d 2d2d 0d0a        # ------..
-00002fd0: 2020 2020 2020 2020 7365 6c66 2e69 735f          self.is_
-00002fe0: 6669 6e69 7465 5f63 7472 6c20 3d20 7468  finite_ctrl = th
-00002ff0: 6561 6e6f 2e73 6861 7265 6428 6e70 2e7a  eano.shared(np.z
-00003000: 6572 6f73 2833 2c20 6474 7970 653d 2769  eros(3, dtype='i
-00003010: 6e74 3332 2729 2c0d 0a20 2020 2020 2020  nt32'),..       
-00003020: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003030: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003040: 2020 2020 2027 5468 6520 7365 7269 6573       'The series
-00003050: 2028 6661 756c 7429 2069 7320 6669 6e69   (fault) is fini
-00003060: 7465 2729 0d0a 2020 2020 2020 2020 7365  te')..        se
-00003070: 6c66 2e69 6e66 5f66 6163 746f 7220 3d20  lf.inf_factor = 
-00003080: 300d 0a20 2020 2020 2020 2073 656c 662e  0..        self.
-00003090: 6973 5f66 6175 6c74 203d 2074 6865 616e  is_fault = thean
-000030a0: 6f2e 7368 6172 6564 286e 702e 7a65 726f  o.shared(np.zero
-000030b0: 7328 3530 3030 2c20 6474 7970 653d 626f  s(5000, dtype=bo
-000030c0: 6f6c 2929 0d0a 0d0a 2020 2020 2020 2020  ol))....        
-000030d0: 2320 434f 4d50 5554 4520 4c4f 4f50 0d0a  # COMPUTE LOOP..
-000030e0: 2020 2020 2020 2020 2320 2d2d 2d2d 2d2d          # ------
-000030f0: 0d0a 2020 2020 2020 2020 2320 5368 6172  ..        # Shar
-00003100: 6564 0d0a 2020 2020 2020 2020 2320 2d2d  ed..        # --
-00003110: 2d2d 2d2d 0d0a 2020 2020 2020 2020 2320  ----..        # 
-00003120: 496e 6974 2066 6175 6c74 2072 656c 6174  Init fault relat
-00003130: 696f 6e20 6d61 7472 6978 0d0a 2020 2020  ion matrix..    
-00003140: 2020 2020 7365 6c66 2e66 6175 6c74 5f72      self.fault_r
-00003150: 656c 6174 696f 6e20 3d20 7468 6561 6e6f  elation = theano
-00003160: 2e73 6861 7265 6428 6e70 2e61 7272 6179  .shared(np.array
-00003170: 285b 5b30 2c20 305d 2c0d 0a20 2020 2020  ([[0, 0],..     
-00003180: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003190: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000031a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000031b0: 205b 302c 2030 5d5d 292c 0d0a 2020 2020   [0, 0]]),..    
-000031c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000031d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000031e0: 2020 2020 2020 2020 2766 6175 6c74 2072          'fault r
-000031f0: 656c 6174 696f 6e20 6d61 7472 6978 2729  elation matrix')
-00003200: 0d0a 0d0a 2020 2020 2020 2020 2320 5374  ....        # St
-00003210: 7275 6374 7572 650d 0a20 2020 2020 2020  ructure..       
-00003220: 2073 656c 662e 6e5f 7375 7266 6163 6573   self.n_surfaces
-00003230: 5f70 6572 5f73 6572 6965 7320 3d20 7468  _per_series = th
-00003240: 6561 6e6f 2e73 6861 7265 6428 6e70 2e61  eano.shared(np.a
-00003250: 7261 6e67 6528 322c 2064 7479 7065 3d27  range(2, dtype='
-00003260: 696e 7433 3227 292c 0d0a 2020 2020 2020  int32'),..      
-00003270: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003280: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003290: 2020 2020 2020 2020 2020 2020 2027 4c69               'Li
-000032a0: 7374 2077 6974 6820 7468 6520 6e75 6d62  st with the numb
-000032b0: 6572 206f 6620 7375 7266 6163 6573 2729  er of surfaces')
-000032c0: 0d0a 2020 2020 2020 2020 7365 6c66 2e6c  ..        self.l
-000032d0: 656e 5f73 6572 6965 735f 6920 3d20 7468  en_series_i = th
-000032e0: 6561 6e6f 2e73 6861 7265 6428 6e70 2e61  eano.shared(np.a
-000032f0: 7261 6e67 6528 322c 2064 7479 7065 3d27  range(2, dtype='
-00003300: 696e 7433 3227 292c 0d0a 2020 2020 2020  int32'),..      
-00003310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003330: 2020 2020 274c 656e 6774 6820 6f66 2073      'Length of s
-00003340: 7572 6661 6365 5f70 6f69 6e74 7320 696e  urface_points in
-00003350: 2065 7665 7279 2073 6572 6965 7327 290d   every series').
-00003360: 0a20 2020 2020 2020 2073 656c 662e 6c65  .        self.le
-00003370: 6e5f 7365 7269 6573 5f6f 203d 2074 6865  n_series_o = the
-00003380: 616e 6f2e 7368 6172 6564 286e 702e 6172  ano.shared(np.ar
-00003390: 616e 6765 2832 2c20 6474 7970 653d 2769  ange(2, dtype='i
-000033a0: 6e74 3332 2729 2c0d 0a20 2020 2020 2020  nt32'),..       
-000033b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000033c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000033d0: 2020 2027 4c65 6e67 7468 206f 6620 666f     'Length of fo
-000033e0: 6c69 6174 696f 6e73 2069 6e20 6576 6572  liations in ever
-000033f0: 7920 7365 7269 6573 2729 0d0a 2020 2020  y series')..    
-00003400: 2020 2020 7365 6c66 2e6c 656e 5f73 6572      self.len_ser
-00003410: 6965 735f 7720 3d20 7468 6561 6e6f 2e73  ies_w = theano.s
-00003420: 6861 7265 6428 6e70 2e61 7261 6e67 6528  hared(np.arange(
-00003430: 322c 2064 7479 7065 3d27 696e 7433 3227  2, dtype='int32'
-00003440: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
-00003450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003460: 2020 2020 2020 2020 2020 2020 2020 274c                'L
-00003470: 656e 6774 6820 6f66 2077 6569 6768 7473  ength of weights
-00003480: 2069 6e20 6576 6572 7920 7365 7269 6573   in every series
-00003490: 2729 0d0a 0d0a 2020 2020 2020 2020 2320  ')....        # 
-000034a0: 436f 6e74 726f 6c20 666c 6f77 0d0a 2020  Control flow..  
-000034b0: 2020 2020 2020 7365 6c66 2e63 6f6d 7075        self.compu
-000034c0: 7465 5f77 6569 6768 7473 5f63 7472 6c20  te_weights_ctrl 
-000034d0: 3d20 542e 7665 6374 6f72 280d 0a20 2020  = T.vector(..   
-000034e0: 2020 2020 2020 2020 2027 5665 6374 6f72           'Vector
-000034f0: 2063 6f6e 7472 6f6c 6c69 6e67 2069 6620   controlling if 
-00003500: 7765 6967 6874 7320 6d75 7374 2062 6520  weights must be 
-00003510: 7265 636f 6d70 7574 6564 272c 2064 7479  recomputed', dty
-00003520: 7065 3d27 626f 6f6c 2729 0d0a 2020 2020  pe='bool')..    
-00003530: 2020 2020 7365 6c66 2e63 6f6d 7075 7465      self.compute
-00003540: 5f73 6361 6c61 725f 6374 726c 203d 2054  _scalar_ctrl = T
-00003550: 2e76 6563 746f 7228 0d0a 2020 2020 2020  .vector(..      
-00003560: 2020 2020 2020 2756 6563 746f 7220 636f        'Vector co
-00003570: 6e74 726f 6c6c 696e 6720 6966 2073 6361  ntrolling if sca
-00003580: 6c61 7220 6d61 7472 6978 206d 7573 7420  lar matrix must 
-00003590: 6265 2072 6563 6f6d 7075 7465 6427 2c20  be recomputed', 
-000035a0: 6474 7970 653d 2762 6f6f 6c27 290d 0a20  dtype='bool').. 
-000035b0: 2020 2020 2020 2073 656c 662e 636f 6d70         self.comp
-000035c0: 7574 655f 626c 6f63 6b5f 6374 726c 203d  ute_block_ctrl =
-000035d0: 2054 2e76 6563 746f 7228 0d0a 2020 2020   T.vector(..    
-000035e0: 2020 2020 2020 2020 2756 6563 746f 7220          'Vector 
-000035f0: 636f 6e74 726f 6c6c 696e 6720 6966 2062  controlling if b
-00003600: 6c6f 636b 206d 6174 7269 7820 6d75 7374  lock matrix must
-00003610: 2062 6520 7265 636f 6d70 7574 6564 272c   be recomputed',
-00003620: 2064 7479 7065 3d27 626f 6f6c 2729 0d0a   dtype='bool')..
-00003630: 2020 2020 2020 2020 7365 6c66 2e69 735f          self.is_
-00003640: 6669 6e69 7465 5f63 7472 6c20 3d20 7468  finite_ctrl = th
-00003650: 6561 6e6f 2e73 6861 7265 6428 6e70 2e7a  eano.shared(np.z
-00003660: 6572 6f73 2833 2c20 6474 7970 653d 2769  eros(3, dtype='i
-00003670: 6e74 3332 2729 2c0d 0a20 2020 2020 2020  nt32'),..       
-00003680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000036a0: 2020 2020 2027 5468 6520 7365 7269 6573       'The series
-000036b0: 2028 6661 756c 7429 2069 7320 6669 6e69   (fault) is fini
-000036c0: 7465 2729 0d0a 2020 2020 2020 2020 7365  te')..        se
-000036d0: 6c66 2e6f 6e6c 6170 5f65 726f 6465 5f63  lf.onlap_erode_c
-000036e0: 7472 6c20 3d20 7468 6561 6e6f 2e73 6861  trl = theano.sha
-000036f0: 7265 6428 6e70 2e7a 6572 6f73 2833 2c20  red(np.zeros(3, 
-00003700: 6474 7970 653d 2769 6e74 3332 2729 2c0d  dtype='int32'),.
-00003710: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003720: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003730: 2020 2020 2020 2020 2020 2020 2020 2027                 '
-00003740: 4f6e 6c61 7020 6572 6f64 6527 290d 0a0d  Onlap erode')...
-00003750: 0a20 2020 2020 2020 2073 656c 662e 696e  .        self.in
-00003760: 7075 745f 7061 7261 6d65 7465 7273 5f6c  put_parameters_l
-00003770: 6f6f 7020 3d20 5b73 656c 662e 6469 7073  oop = [self.dips
-00003780: 5f70 6f73 6974 696f 6e5f 616c 6c2c 2073  _position_all, s
-00003790: 656c 662e 6469 705f 616e 676c 6573 5f61  elf.dip_angles_a
-000037a0: 6c6c 2c0d 0a20 2020 2020 2020 2020 2020  ll,..           
-000037b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000037c0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-000037d0: 617a 696d 7574 685f 616c 6c2c 0d0a 2020  azimuth_all,..  
-000037e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000037f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003800: 2020 2020 7365 6c66 2e70 6f6c 6172 6974      self.polarit
-00003810: 795f 616c 6c2c 2073 656c 662e 7375 7266  y_all, self.surf
-00003820: 6163 655f 706f 696e 7473 5f61 6c6c 2c0d  ace_points_all,.
-00003830: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003850: 2020 2020 2020 2073 656c 662e 6661 756c         self.faul
-00003860: 745f 6d61 7472 6978 2c20 7365 6c66 2e67  t_matrix, self.g
-00003870: 7269 645f 7661 6c5f 542c 0d0a 2020 2020  rid_val_T,..    
-00003880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003890: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000038a0: 2020 7365 6c66 2e76 616c 7565 735f 7072    self.values_pr
-000038b0: 6f70 6572 7469 6573 5f6f 702c 0d0a 2020  operties_op,..  
-000038c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000038d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000038e0: 2020 2020 7365 6c66 2e63 6f6d 7075 7465      self.compute
-000038f0: 5f77 6569 6768 7473 5f63 7472 6c2c 0d0a  _weights_ctrl,..
-00003900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003920: 2020 2020 2020 7365 6c66 2e63 6f6d 7075        self.compu
-00003930: 7465 5f73 6361 6c61 725f 6374 726c 2c0d  te_scalar_ctrl,.
-00003940: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003960: 2020 2020 2020 2073 656c 662e 636f 6d70         self.comp
-00003970: 7574 655f 626c 6f63 6b5f 6374 726c 5d0d  ute_block_ctrl].
-00003980: 0a0d 0a20 2020 2020 2020 2073 656c 662e  ...        self.
-00003990: 6973 5f65 726f 7369 6f6e 203d 2074 6865  is_erosion = the
-000039a0: 616e 6f2e 7368 6172 6564 286e 702e 6172  ano.shared(np.ar
-000039b0: 7261 7928 5b31 2c20 305d 2929 0d0a 2020  ray([1, 0]))..  
-000039c0: 2020 2020 2020 7365 6c66 2e69 735f 6f6e        self.is_on
-000039d0: 6c61 7020 3d20 7468 6561 6e6f 2e73 6861  lap = theano.sha
-000039e0: 7265 6428 6e70 2e61 7272 6179 285b 302c  red(np.array([0,
-000039f0: 2031 5d29 290d 0a0d 0a20 2020 2020 2020   1]))....       
-00003a00: 2073 656c 662e 6f66 6673 6574 203d 2074   self.offset = t
-00003a10: 6865 616e 6f2e 7368 6172 6564 2831 302e  heano.shared(10.
-00003a20: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-00003a30: 7368 6966 7420 3d20 300d 0a0d 0a20 2020  shift = 0....   
-00003a40: 2020 2020 2069 6620 2767 7261 7669 7479       if 'gravity
-00003a50: 2720 696e 2073 656c 662e 636f 6d70 7574  ' in self.comput
-00003a60: 655f 7479 7065 3a0d 0a20 2020 2020 2020  e_type:..       
-00003a70: 2020 2020 2073 656c 662e 6c67 3020 3d20       self.lg0 = 
-00003a80: 7468 6561 6e6f 2e73 6861 7265 6428 6e70  theano.shared(np
-00003a90: 2e61 7272 6179 2830 2c20 6474 7970 653d  .array(0, dtype=
-00003aa0: 2769 6e74 3634 2729 2c0d 0a20 2020 2020  'int64'),..     
-00003ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003ad0: 2761 7267 5f30 206f 6620 7468 6520 6365  'arg_0 of the ce
-00003ae0: 6e74 6572 6564 2067 7269 6427 290d 0a20  ntered grid').. 
-00003af0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00003b00: 6c67 3120 3d20 7468 6561 6e6f 2e73 6861  lg1 = theano.sha
-00003b10: 7265 6428 6e70 2e61 7272 6179 2831 2c20  red(np.array(1, 
-00003b20: 6474 7970 653d 2769 6e74 3634 2729 2c0d  dtype='int64'),.
-00003b30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003b50: 2020 2020 2020 2761 7267 5f31 206f 6620        'arg_1 of 
-00003b60: 7468 6520 6365 6e74 6572 6564 2067 7269  the centered gri
-00003b70: 6427 290d 0a0d 0a20 2020 2020 2020 2020  d')....         
-00003b80: 2020 2073 656c 662e 747a 203d 2074 6865     self.tz = the
-00003b90: 616e 6f2e 7368 6172 6564 286e 702e 656d  ano.shared(np.em
-00003ba0: 7074 7928 302c 2064 7479 7065 3d73 656c  pty(0, dtype=sel
-00003bb0: 662e 6474 7970 6529 2c20 2774 7a20 636f  f.dtype), 'tz co
-00003bc0: 6d70 6f6e 656e 7427 290d 0a20 2020 2020  mponent')..     
-00003bd0: 2020 2020 2020 2073 656c 662e 706f 735f         self.pos_
-00003be0: 6465 6e73 6974 7920 3d20 7468 6561 6e6f  density = theano
-00003bf0: 2e73 6861 7265 6428 6e70 2e61 7272 6179  .shared(np.array
-00003c00: 2831 2c20 6474 7970 653d 2769 6e74 3634  (1, dtype='int64
-00003c10: 2729 2c0d 0a20 2020 2020 2020 2020 2020  '),..           
-00003c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003c40: 2020 2770 6f73 6974 696f 6e20 6f66 2074    'position of t
-00003c50: 6865 2064 656e 7369 7479 206f 6e20 7468  he density on th
-00003c60: 6520 7661 6c75 6573 206d 6174 7269 7827  e values matrix'
-00003c70: 290d 0a0d 0a20 2020 2020 2020 2069 6620  )....        if 
-00003c80: 276d 6167 6e65 7469 6373 2720 696e 2073  'magnetics' in s
-00003c90: 656c 662e 636f 6d70 7574 655f 7479 7065  elf.compute_type
-00003ca0: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
-00003cb0: 656c 662e 6c67 3020 3d20 7468 6561 6e6f  elf.lg0 = theano
-00003cc0: 2e73 6861 7265 6428 6e70 2e61 7272 6179  .shared(np.array
-00003cd0: 2830 2c20 6474 7970 653d 2769 6e74 3634  (0, dtype='int64
-00003ce0: 2729 2c0d 0a20 2020 2020 2020 2020 2020  '),..           
-00003cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003d00: 2020 2020 2020 2020 2020 2761 7267 5f30            'arg_0
-00003d10: 206f 6620 7468 6520 6365 6e74 6572 6564   of the centered
-00003d20: 2067 7269 6427 290d 0a20 2020 2020 2020   grid')..       
-00003d30: 2020 2020 2073 656c 662e 6c67 3120 3d20       self.lg1 = 
-00003d40: 7468 6561 6e6f 2e73 6861 7265 6428 6e70  theano.shared(np
-00003d50: 2e61 7272 6179 2831 2c20 6474 7970 653d  .array(1, dtype=
-00003d60: 2769 6e74 3634 2729 2c0d 0a20 2020 2020  'int64'),..     
-00003d70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000027e0: 2020 205d 0d0a 0d0a 2020 2020 2020 2020     ]....        
+000027f0: 2320 696e 7465 7266 6163 655f 6c6f 6320  # interface_loc 
+00002800: 3d20 7365 6c66 2e66 6175 6c74 5f6d 6174  = self.fault_mat
+00002810: 7269 782e 7368 6170 655b 315d 202d 2032  rix.shape[1] - 2
+00002820: 202a 2073 656c 662e 6c65 6e5f 706f 696e   * self.len_poin
+00002830: 7473 0d0a 2020 2020 2020 2020 696e 7465  ts..        inte
+00002840: 7266 6163 655f 6c6f 6320 3d20 3020 2023  rface_loc = 0  #
+00002850: 2073 656c 662e 6772 6964 5f76 616c 5f54   self.grid_val_T
+00002860: 2e73 6861 7065 5b30 5d0d 0a20 2020 2020  .shape[0]..     
+00002870: 2020 2073 656c 662e 6661 756c 745f 6472     self.fault_dr
+00002880: 6966 745f 6174 5f73 7572 6661 6365 5f70  ift_at_surface_p
+00002890: 6f69 6e74 735f 7265 7374 203d 2073 656c  oints_rest = sel
+000028a0: 662e 6661 756c 745f 6d61 7472 6978 5b0d  f.fault_matrix[.
+000028b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000028c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000028d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000028e0: 2020 203a 2c0d 0a20 2020 2020 2020 2020     :,..         
+000028f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002900: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002910: 2020 2020 2020 2020 2069 6e74 6572 6661           interfa
+00002920: 6365 5f6c 6f63 3a20 696e 7465 7266 6163  ce_loc: interfac
+00002930: 655f 6c6f 6320 2b20 7365 6c66 2e6c 656e  e_loc + self.len
+00002940: 5f70 6f69 6e74 735d 0d0a 2020 2020 2020  _points]..      
+00002950: 2020 7365 6c66 2e66 6175 6c74 5f64 7269    self.fault_dri
+00002960: 6674 5f61 745f 7375 7266 6163 655f 706f  ft_at_surface_po
+00002970: 696e 7473 5f72 6566 203d 2073 656c 662e  ints_ref = self.
+00002980: 6661 756c 745f 6d61 7472 6978 5b0d 0a20  fault_matrix[.. 
+00002990: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000029a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000029b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000029c0: 3a2c 0d0a 2020 2020 2020 2020 2020 2020  :,..            
+000029d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000029e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000029f0: 2020 2020 2069 6e74 6572 6661 6365 5f6c       interface_l
+00002a00: 6f63 202b 2073 656c 662e 6c65 6e5f 706f  oc + self.len_po
+00002a10: 696e 7473 3a5d 0d0a 0d0a 2020 2020 2020  ints:]....      
+00002a20: 2020 2320 434f 4d50 5554 4520 424c 4f43    # COMPUTE BLOC
+00002a30: 4b53 0d0a 2020 2020 2020 2020 2320 2d2d  KS..        # --
+00002a40: 2d2d 2d2d 2d2d 2d0d 0a20 2020 2020 2020  -------..       
+00002a50: 2023 2056 4152 4941 424c 4553 0d0a 2020   # VARIABLES..  
+00002a60: 2020 2020 2020 2320 2d2d 2d2d 2d2d 2d2d        # --------
+00002a70: 2d0d 0a0d 0a20 2020 2020 2020 2069 6620  -....        if 
+00002a80: 7365 6c66 2e67 7261 6469 656e 743a 0d0a  self.gradient:..
+00002a90: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00002aa0: 2e73 6967 5f73 6c6f 7065 203d 2061 6573  .sig_slope = aes
+00002ab0: 6172 612e 7368 6172 6564 286e 702e 6172  ara.shared(np.ar
+00002ac0: 7261 7928 3530 2c20 6474 7970 653d 6474  ray(50, dtype=dt
+00002ad0: 7970 6529 2c0d 0a20 2020 2020 2020 2020  ype),..         
+00002ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002b00: 2020 2753 6967 6d6f 6964 2073 6c6f 7065    'Sigmoid slope
+00002b10: 2066 6f72 2067 7261 6469 656e 7427 290d   for gradient').
+00002b20: 0a20 2020 2020 2020 2065 6c73 653a 0d0a  .        else:..
+00002b30: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00002b40: 2e73 6967 5f73 6c6f 7065 203d 2061 6573  .sig_slope = aes
+00002b50: 6172 612e 7368 6172 6564 286e 702e 6172  ara.shared(np.ar
+00002b60: 7261 7928 3530 3030 302c 2064 7479 7065  ray(50000, dtype
+00002b70: 3d64 7479 7065 292c 0d0a 2020 2020 2020  =dtype),..      
+00002b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002ba0: 2020 2020 2027 5369 676d 6f69 6420 736c       'Sigmoid sl
+00002bb0: 6f70 6527 290d 0a20 2020 2020 2020 2020  ope')..         
+00002bc0: 2020 2073 656c 662e 6e6f 745f 6c20 3d20     self.not_l = 
+00002bd0: 6165 7361 7261 2e73 6861 7265 6428 6e70  aesara.shared(np
+00002be0: 2e61 7272 6179 2835 302e 2c20 6474 7970  .array(50., dtyp
+00002bf0: 653d 6474 7970 6529 2c20 2753 6967 6d6f  e=dtype), 'Sigmo
+00002c00: 6964 204f 7574 7369 6465 2729 0d0a 2020  id Outside')..  
+00002c10: 2020 2020 2020 2020 2020 7365 6c66 2e65            self.e
+00002c20: 6c6c 6970 7365 5f66 6163 746f 725f 6578  llipse_factor_ex
+00002c30: 706f 6e65 6e74 203d 2061 6573 6172 612e  ponent = aesara.
+00002c40: 7368 6172 6564 286e 702e 6172 7261 7928  shared(np.array(
+00002c50: 322e 2c20 6474 7970 653d 6474 7970 6529  2., dtype=dtype)
+00002c60: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00002c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002c90: 2020 2020 2020 2020 2020 2020 2741 7474              'Att
+00002ca0: 656e 7561 7469 6f6e 2066 6163 746f 7227  enuation factor'
+00002cb0: 290d 0a0d 0a20 2020 2020 2020 2023 2049  )....        # I
+00002cc0: 7420 6973 2061 206d 6174 7269 7820 6265  t is a matrix be
+00002cd0: 6361 7573 6520 6f66 2074 6865 2076 616c  cause of the val
+00002ce0: 7565 733a 2070 6f72 6f73 6974 792c 2073  ues: porosity, s
+00002cf0: 7573 2c20 6574 630d 0a20 2020 2020 2020  us, etc..       
+00002d00: 2073 656c 662e 7661 6c75 6573 5f70 726f   self.values_pro
+00002d10: 7065 7274 6965 735f 6f70 203d 2054 2e6d  perties_op = T.m
+00002d20: 6174 7269 7828 2756 616c 7565 7320 7468  atrix('Values th
+00002d30: 6174 2074 6865 2062 6c6f 636b 7320 6172  at the blocks ar
+00002d40: 6520 7461 6b69 6e67 2729 0d0a 0d0a 2020  e taking')....  
+00002d50: 2020 2020 2020 7365 6c66 2e6e 5f73 7572        self.n_sur
+00002d60: 6661 6365 203d 2054 2e61 7261 6e67 6528  face = T.arange(
+00002d70: 312c 2035 3030 302c 2064 7479 7065 3d27  1, 5000, dtype='
+00002d80: 696e 7433 3227 290d 0a20 2020 2020 2020  int32')..       
+00002d90: 2073 656c 662e 6e5f 7375 7266 6163 652e   self.n_surface.
+00002da0: 6e61 6d65 203d 2027 4944 206f 6620 7375  name = 'ID of su
+00002db0: 7266 6163 6573 270d 0a0d 0a20 2020 2020  rfaces'....     
+00002dc0: 2020 2073 656c 662e 696e 7075 745f 7061     self.input_pa
+00002dd0: 7261 6d65 7465 7273 5f62 6c6f 636b 203d  rameters_block =
+00002de0: 205b 7365 6c66 2e64 6970 735f 706f 7369   [self.dips_posi
+00002df0: 7469 6f6e 5f61 6c6c 2c20 7365 6c66 2e64  tion_all, self.d
+00002e00: 6970 5f61 6e67 6c65 735f 616c 6c2c 0d0a  ip_angles_all,..
+00002e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002e30: 2020 2020 2020 2073 656c 662e 617a 696d         self.azim
+00002e40: 7574 685f 616c 6c2c 0d0a 2020 2020 2020  uth_all,..      
+00002e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002e70: 2073 656c 662e 706f 6c61 7269 7479 5f61   self.polarity_a
+00002e80: 6c6c 2c20 7365 6c66 2e73 7572 6661 6365  ll, self.surface
+00002e90: 5f70 6f69 6e74 735f 616c 6c2c 0d0a 2020  _points_all,..  
+00002ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002ec0: 2020 2020 2073 656c 662e 6661 756c 745f       self.fault_
+00002ed0: 6d61 7472 6978 2c20 7365 6c66 2e67 7269  matrix, self.gri
+00002ee0: 645f 7661 6c5f 542c 0d0a 2020 2020 2020  d_val_T,..      
+00002ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002f10: 2073 656c 662e 7661 6c75 6573 5f70 726f   self.values_pro
+00002f20: 7065 7274 6965 735f 6f70 5d0d 0a20 2020  perties_op]..   
+00002f30: 2020 2020 2023 202d 2d2d 2d2d 2d0d 0a20       # ------.. 
+00002f40: 2020 2020 2020 2023 2053 6861 7265 640d         # Shared.
+00002f50: 0a20 2020 2020 2020 2023 202d 2d2d 2d2d  .        # -----
+00002f60: 2d0d 0a20 2020 2020 2020 2073 656c 662e  -..        self.
+00002f70: 6973 5f66 696e 6974 655f 6374 726c 203d  is_finite_ctrl =
+00002f80: 2061 6573 6172 612e 7368 6172 6564 286e   aesara.shared(n
+00002f90: 702e 7a65 726f 7328 332c 2064 7479 7065  p.zeros(3, dtype
+00002fa0: 3d27 696e 7433 3227 292c 0d0a 2020 2020  ='int32'),..    
+00002fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002fd0: 2020 2020 2020 2020 2754 6865 2073 6572          'The ser
+00002fe0: 6965 7320 2866 6175 6c74 2920 6973 2066  ies (fault) is f
+00002ff0: 696e 6974 6527 290d 0a20 2020 2020 2020  inite')..       
+00003000: 2073 656c 662e 696e 665f 6661 6374 6f72   self.inf_factor
+00003010: 203d 2030 0d0a 2020 2020 2020 2020 7365   = 0..        se
+00003020: 6c66 2e69 735f 6661 756c 7420 3d20 6165  lf.is_fault = ae
+00003030: 7361 7261 2e73 6861 7265 6428 6e70 2e7a  sara.shared(np.z
+00003040: 6572 6f73 2835 3030 302c 2064 7479 7065  eros(5000, dtype
+00003050: 3d62 6f6f 6c29 290d 0a0d 0a20 2020 2020  =bool))....     
+00003060: 2020 2023 2043 4f4d 5055 5445 204c 4f4f     # COMPUTE LOO
+00003070: 500d 0a20 2020 2020 2020 2023 202d 2d2d  P..        # ---
+00003080: 2d2d 2d0d 0a20 2020 2020 2020 2023 2053  ---..        # S
+00003090: 6861 7265 640d 0a20 2020 2020 2020 2023  hared..        #
+000030a0: 202d 2d2d 2d2d 2d0d 0a20 2020 2020 2020   ------..       
+000030b0: 2023 2049 6e69 7420 6661 756c 7420 7265   # Init fault re
+000030c0: 6c61 7469 6f6e 206d 6174 7269 780d 0a20  lation matrix.. 
+000030d0: 2020 2020 2020 2073 656c 662e 6661 756c         self.faul
+000030e0: 745f 7265 6c61 7469 6f6e 203d 2061 6573  t_relation = aes
+000030f0: 6172 612e 7368 6172 6564 286e 702e 6172  ara.shared(np.ar
+00003100: 7261 7928 5b5b 302c 2030 5d2c 0d0a 2020  ray([[0, 0],..  
+00003110: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003120: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003140: 2020 2020 5b30 2c20 305d 5d29 2c0d 0a20      [0, 0]]),.. 
+00003150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003170: 2020 2020 2020 2020 2020 2027 6661 756c             'faul
+00003180: 7420 7265 6c61 7469 6f6e 206d 6174 7269  t relation matri
+00003190: 7827 290d 0a0d 0a20 2020 2020 2020 2023  x')....        #
+000031a0: 2053 7472 7563 7475 7265 0d0a 2020 2020   Structure..    
+000031b0: 2020 2020 7365 6c66 2e6e 5f73 7572 6661      self.n_surfa
+000031c0: 6365 735f 7065 725f 7365 7269 6573 203d  ces_per_series =
+000031d0: 2061 6573 6172 612e 7368 6172 6564 286e   aesara.shared(n
+000031e0: 702e 6172 616e 6765 2832 2c20 6474 7970  p.arange(2, dtyp
+000031f0: 653d 2769 6e74 3332 2729 2c0d 0a20 2020  e='int32'),..   
+00003200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003230: 274c 6973 7420 7769 7468 2074 6865 206e  'List with the n
+00003240: 756d 6265 7220 6f66 2073 7572 6661 6365  umber of surface
+00003250: 7327 290d 0a20 2020 2020 2020 2073 656c  s')..        sel
+00003260: 662e 6c65 6e5f 7365 7269 6573 5f69 203d  f.len_series_i =
+00003270: 2061 6573 6172 612e 7368 6172 6564 286e   aesara.shared(n
+00003280: 702e 6172 616e 6765 2832 2c20 6474 7970  p.arange(2, dtyp
+00003290: 653d 2769 6e74 3332 2729 2c0d 0a20 2020  e='int32'),..   
+000032a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000032b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000032c0: 2020 2020 2020 2027 4c65 6e67 7468 206f         'Length o
+000032d0: 6620 7375 7266 6163 655f 706f 696e 7473  f surface_points
+000032e0: 2069 6e20 6576 6572 7920 7365 7269 6573   in every series
+000032f0: 2729 0d0a 2020 2020 2020 2020 7365 6c66  ')..        self
+00003300: 2e6c 656e 5f73 6572 6965 735f 6f20 3d20  .len_series_o = 
+00003310: 6165 7361 7261 2e73 6861 7265 6428 6e70  aesara.shared(np
+00003320: 2e61 7261 6e67 6528 322c 2064 7479 7065  .arange(2, dtype
+00003330: 3d27 696e 7433 3227 292c 0d0a 2020 2020  ='int32'),..    
+00003340: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003350: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003360: 2020 2020 2020 274c 656e 6774 6820 6f66        'Length of
+00003370: 2066 6f6c 6961 7469 6f6e 7320 696e 2065   foliations in e
+00003380: 7665 7279 2073 6572 6965 7327 290d 0a20  very series').. 
+00003390: 2020 2020 2020 2073 656c 662e 6c65 6e5f         self.len_
+000033a0: 7365 7269 6573 5f77 203d 2061 6573 6172  series_w = aesar
+000033b0: 612e 7368 6172 6564 286e 702e 6172 616e  a.shared(np.aran
+000033c0: 6765 2832 2c20 6474 7970 653d 2769 6e74  ge(2, dtype='int
+000033d0: 3332 2729 2c0d 0a20 2020 2020 2020 2020  32'),..         
+000033e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000033f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003400: 2027 4c65 6e67 7468 206f 6620 7765 6967   'Length of weig
+00003410: 6874 7320 696e 2065 7665 7279 2073 6572  hts in every ser
+00003420: 6965 7327 290d 0a0d 0a20 2020 2020 2020  ies')....       
+00003430: 2023 2043 6f6e 7472 6f6c 2066 6c6f 770d   # Control flow.
+00003440: 0a20 2020 2020 2020 2073 656c 662e 636f  .        self.co
+00003450: 6d70 7574 655f 7765 6967 6874 735f 6374  mpute_weights_ct
+00003460: 726c 203d 2054 2e76 6563 746f 7228 0d0a  rl = T.vector(..
+00003470: 2020 2020 2020 2020 2020 2020 2756 6563              'Vec
+00003480: 746f 7220 636f 6e74 726f 6c6c 696e 6720  tor controlling 
+00003490: 6966 2077 6569 6768 7473 206d 7573 7420  if weights must 
+000034a0: 6265 2072 6563 6f6d 7075 7465 6427 2c20  be recomputed', 
+000034b0: 6474 7970 653d 2762 6f6f 6c27 290d 0a20  dtype='bool').. 
+000034c0: 2020 2020 2020 2073 656c 662e 636f 6d70         self.comp
+000034d0: 7574 655f 7363 616c 6172 5f63 7472 6c20  ute_scalar_ctrl 
+000034e0: 3d20 542e 7665 6374 6f72 280d 0a20 2020  = T.vector(..   
+000034f0: 2020 2020 2020 2020 2027 5665 6374 6f72           'Vector
+00003500: 2063 6f6e 7472 6f6c 6c69 6e67 2069 6620   controlling if 
+00003510: 7363 616c 6172 206d 6174 7269 7820 6d75  scalar matrix mu
+00003520: 7374 2062 6520 7265 636f 6d70 7574 6564  st be recomputed
+00003530: 272c 2064 7479 7065 3d27 626f 6f6c 2729  ', dtype='bool')
+00003540: 0d0a 2020 2020 2020 2020 7365 6c66 2e63  ..        self.c
+00003550: 6f6d 7075 7465 5f62 6c6f 636b 5f63 7472  ompute_block_ctr
+00003560: 6c20 3d20 542e 7665 6374 6f72 280d 0a20  l = T.vector(.. 
+00003570: 2020 2020 2020 2020 2020 2027 5665 6374             'Vect
+00003580: 6f72 2063 6f6e 7472 6f6c 6c69 6e67 2069  or controlling i
+00003590: 6620 626c 6f63 6b20 6d61 7472 6978 206d  f block matrix m
+000035a0: 7573 7420 6265 2072 6563 6f6d 7075 7465  ust be recompute
+000035b0: 6427 2c20 6474 7970 653d 2762 6f6f 6c27  d', dtype='bool'
+000035c0: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
+000035d0: 6973 5f66 696e 6974 655f 6374 726c 203d  is_finite_ctrl =
+000035e0: 2061 6573 6172 612e 7368 6172 6564 286e   aesara.shared(n
+000035f0: 702e 7a65 726f 7328 332c 2064 7479 7065  p.zeros(3, dtype
+00003600: 3d27 696e 7433 3227 292c 0d0a 2020 2020  ='int32'),..    
+00003610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003630: 2020 2020 2020 2020 2754 6865 2073 6572          'The ser
+00003640: 6965 7320 2866 6175 6c74 2920 6973 2066  ies (fault) is f
+00003650: 696e 6974 6527 290d 0a20 2020 2020 2020  inite')..       
+00003660: 2073 656c 662e 6f6e 6c61 705f 6572 6f64   self.onlap_erod
+00003670: 655f 6374 726c 203d 2061 6573 6172 612e  e_ctrl = aesara.
+00003680: 7368 6172 6564 286e 702e 7a65 726f 7328  shared(np.zeros(
+00003690: 332c 2064 7479 7065 3d27 696e 7433 3227  3, dtype='int32'
+000036a0: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
+000036b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000036c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000036d0: 2020 274f 6e6c 6170 2065 726f 6465 2729    'Onlap erode')
+000036e0: 0d0a 0d0a 2020 2020 2020 2020 7365 6c66  ....        self
+000036f0: 2e69 6e70 7574 5f70 6172 616d 6574 6572  .input_parameter
+00003700: 735f 6c6f 6f70 203d 205b 7365 6c66 2e64  s_loop = [self.d
+00003710: 6970 735f 706f 7369 7469 6f6e 5f61 6c6c  ips_position_all
+00003720: 2c20 7365 6c66 2e64 6970 5f61 6e67 6c65  , self.dip_angle
+00003730: 735f 616c 6c2c 0d0a 2020 2020 2020 2020  s_all,..        
+00003740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003750: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00003760: 6c66 2e61 7a69 6d75 7468 5f61 6c6c 2c0d  lf.azimuth_all,.
+00003770: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00003780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003790: 2020 2020 2020 2073 656c 662e 706f 6c61         self.pola
+000037a0: 7269 7479 5f61 6c6c 2c20 7365 6c66 2e73  rity_all, self.s
+000037b0: 7572 6661 6365 5f70 6f69 6e74 735f 616c  urface_points_al
+000037c0: 6c2c 0d0a 2020 2020 2020 2020 2020 2020  l,..            
+000037d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000037e0: 2020 2020 2020 2020 2020 7365 6c66 2e66            self.f
+000037f0: 6175 6c74 5f6d 6174 7269 782c 2073 656c  ault_matrix, sel
+00003800: 662e 6772 6964 5f76 616c 5f54 2c0d 0a20  f.grid_val_T,.. 
+00003810: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003820: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003830: 2020 2020 2073 656c 662e 7661 6c75 6573       self.values
+00003840: 5f70 726f 7065 7274 6965 735f 6f70 2c0d  _properties_op,.
+00003850: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00003860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003870: 2020 2020 2020 2073 656c 662e 636f 6d70         self.comp
+00003880: 7574 655f 7765 6967 6874 735f 6374 726c  ute_weights_ctrl
+00003890: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+000038a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000038b0: 2020 2020 2020 2020 2073 656c 662e 636f           self.co
+000038c0: 6d70 7574 655f 7363 616c 6172 5f63 7472  mpute_scalar_ctr
+000038d0: 6c2c 0d0a 2020 2020 2020 2020 2020 2020  l,..            
+000038e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000038f0: 2020 2020 2020 2020 2020 7365 6c66 2e63            self.c
+00003900: 6f6d 7075 7465 5f62 6c6f 636b 5f63 7472  ompute_block_ctr
+00003910: 6c5d 0d0a 0d0a 2020 2020 2020 2020 7365  l]....        se
+00003920: 6c66 2e69 735f 6572 6f73 696f 6e20 3d20  lf.is_erosion = 
+00003930: 6165 7361 7261 2e73 6861 7265 6428 6e70  aesara.shared(np
+00003940: 2e61 7272 6179 285b 312c 2030 5d29 290d  .array([1, 0])).
+00003950: 0a20 2020 2020 2020 2073 656c 662e 6973  .        self.is
+00003960: 5f6f 6e6c 6170 203d 2061 6573 6172 612e  _onlap = aesara.
+00003970: 7368 6172 6564 286e 702e 6172 7261 7928  shared(np.array(
+00003980: 5b30 2c20 315d 2929 0d0a 0d0a 2020 2020  [0, 1]))....    
+00003990: 2020 2020 7365 6c66 2e6f 6666 7365 7420      self.offset 
+000039a0: 3d20 6165 7361 7261 2e73 6861 7265 6428  = aesara.shared(
+000039b0: 3130 2e29 0d0a 2020 2020 2020 2020 7365  10.)..        se
+000039c0: 6c66 2e73 6869 6674 203d 2030 0d0a 0d0a  lf.shift = 0....
+000039d0: 2020 2020 2020 2020 6966 2027 6772 6176          if 'grav
+000039e0: 6974 7927 2069 6e20 7365 6c66 2e63 6f6d  ity' in self.com
+000039f0: 7075 7465 5f74 7970 653a 0d0a 2020 2020  pute_type:..    
+00003a00: 2020 2020 2020 2020 7365 6c66 2e6c 6730          self.lg0
+00003a10: 203d 2061 6573 6172 612e 7368 6172 6564   = aesara.shared
+00003a20: 286e 702e 6172 7261 7928 302c 2064 7479  (np.array(0, dty
+00003a30: 7065 3d27 696e 7436 3427 292c 0d0a 2020  pe='int64'),..  
+00003a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003a60: 2020 2027 6172 675f 3020 6f66 2074 6865     'arg_0 of the
+00003a70: 2063 656e 7465 7265 6420 6772 6964 2729   centered grid')
+00003a80: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
+00003a90: 6c66 2e6c 6731 203d 2061 6573 6172 612e  lf.lg1 = aesara.
+00003aa0: 7368 6172 6564 286e 702e 6172 7261 7928  shared(np.array(
+00003ab0: 312c 2064 7479 7065 3d27 696e 7436 3427  1, dtype='int64'
+00003ac0: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
+00003ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003ae0: 2020 2020 2020 2020 2027 6172 675f 3120           'arg_1 
+00003af0: 6f66 2074 6865 2063 656e 7465 7265 6420  of the centered 
+00003b00: 6772 6964 2729 0d0a 0d0a 2020 2020 2020  grid')....      
+00003b10: 2020 2020 2020 7365 6c66 2e74 7a20 3d20        self.tz = 
+00003b20: 6165 7361 7261 2e73 6861 7265 6428 6e70  aesara.shared(np
+00003b30: 2e65 6d70 7479 2830 2c20 6474 7970 653d  .empty(0, dtype=
+00003b40: 7365 6c66 2e64 7479 7065 292c 2027 747a  self.dtype), 'tz
+00003b50: 2063 6f6d 706f 6e65 6e74 2729 0d0a 2020   component')..  
+00003b60: 2020 2020 2020 2020 2020 7365 6c66 2e70            self.p
+00003b70: 6f73 5f64 656e 7369 7479 203d 2061 6573  os_density = aes
+00003b80: 6172 612e 7368 6172 6564 286e 702e 6172  ara.shared(np.ar
+00003b90: 7261 7928 312c 2064 7479 7065 3d27 696e  ray(1, dtype='in
+00003ba0: 7436 3427 292c 0d0a 2020 2020 2020 2020  t64'),..        
+00003bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003bd0: 2020 2020 2027 706f 7369 7469 6f6e 206f       'position o
+00003be0: 6620 7468 6520 6465 6e73 6974 7920 6f6e  f the density on
+00003bf0: 2074 6865 2076 616c 7565 7320 6d61 7472   the values matr
+00003c00: 6978 2729 0d0a 0d0a 2020 2020 2020 2020  ix')....        
+00003c10: 6966 2027 6d61 676e 6574 6963 7327 2069  if 'magnetics' i
+00003c20: 6e20 7365 6c66 2e63 6f6d 7075 7465 5f74  n self.compute_t
+00003c30: 7970 653a 0d0a 2020 2020 2020 2020 2020  ype:..          
+00003c40: 2020 7365 6c66 2e6c 6730 203d 2061 6573    self.lg0 = aes
+00003c50: 6172 612e 7368 6172 6564 286e 702e 6172  ara.shared(np.ar
+00003c60: 7261 7928 302c 2064 7479 7065 3d27 696e  ray(0, dtype='in
+00003c70: 7436 3427 292c 0d0a 2020 2020 2020 2020  t64'),..        
+00003c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003c90: 2020 2020 2020 2020 2020 2020 2027 6172               'ar
+00003ca0: 675f 3020 6f66 2074 6865 2063 656e 7465  g_0 of the cente
+00003cb0: 7265 6420 6772 6964 2729 0d0a 2020 2020  red grid')..    
+00003cc0: 2020 2020 2020 2020 7365 6c66 2e6c 6731          self.lg1
+00003cd0: 203d 2061 6573 6172 612e 7368 6172 6564   = aesara.shared
+00003ce0: 286e 702e 6172 7261 7928 312c 2064 7479  (np.array(1, dty
+00003cf0: 7065 3d27 696e 7436 3427 292c 0d0a 2020  pe='int64'),..  
+00003d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003d10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003d20: 2020 2027 6172 675f 3120 6f66 2074 6865     'arg_1 of the
+00003d30: 2063 656e 7465 7265 6420 6772 6964 2729   centered grid')
+00003d40: 0d0a 0d0a 2020 2020 2020 2020 2020 2020  ....            
+00003d50: 7365 6c66 2e42 5f65 7874 203d 2061 6573  self.B_ext = aes
+00003d60: 6172 612e 7368 6172 6564 2835 3065 2d36  ara.shared(50e-6
+00003d70: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
 00003d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003d90: 2761 7267 5f31 206f 6620 7468 6520 6365  'arg_1 of the ce
-00003da0: 6e74 6572 6564 2067 7269 6427 290d 0a0d  ntered grid')...
-00003db0: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-00003dc0: 662e 425f 6578 7420 3d20 7468 6561 6e6f  f.B_ext = theano
-00003dd0: 2e73 6861 7265 6428 3530 652d 362c 0d0a  .shared(50e-6,..
+00003d90: 2020 2020 2020 2020 2020 2745 7874 6572            'Exter
+00003da0: 6e61 6c20 6d61 676e 6574 6963 2066 6965  nal magnetic fie
+00003db0: 6c64 2069 6e20 5b54 5d2c 2069 6e20 6d61  ld in [T], in ma
+00003dc0: 676e 6574 6963 2073 7572 7665 7973 2074  gnetic surveys t
+00003dd0: 6869 7320 6973 2074 6865 270d 0a20 2020  his is the'..   
 00003de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00003df0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003e00: 2020 2020 2020 2027 4578 7465 726e 616c         'External
-00003e10: 206d 6167 6e65 7469 6320 6669 656c 6420   magnetic field 
-00003e20: 696e 205b 545d 2c20 696e 206d 6167 6e65  in [T], in magne
-00003e30: 7469 6320 7375 7276 6579 7320 7468 6973  tic surveys this
-00003e40: 2069 7320 7468 6527 0d0a 2020 2020 2020   is the'..      
-00003e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003e70: 2027 2067 656f 6d61 676e 6574 6963 2066   ' geomagnetic f
-00003e80: 6965 6c64 202d 2076 6172 6965 7320 7465  ield - varies te
-00003e90: 6d70 6f72 616c 792e 2729 0d0a 2020 2020  mporaly.')..    
-00003ea0: 2020 2020 2020 2020 7365 6c66 2e69 6e63          self.inc
-00003eb0: 6c20 3d20 7468 6561 6e6f 2e73 6861 7265  l = theano.share
-00003ec0: 6428 6e70 2e61 7272 6179 2831 2c20 6474  d(np.array(1, dt
-00003ed0: 7970 653d 6474 7970 6529 2c0d 0a20 2020  ype=dtype),..   
-00003ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003f00: 2020 2027 4469 7020 6f66 2074 6865 2067     'Dip of the g
-00003f10: 656f 6d61 676e 6574 6963 2066 6965 6c64  eomagnetic field
-00003f20: 2069 6e20 6465 6772 6565 732d 2076 6172   in degrees- var
-00003f30: 6965 7327 0d0a 2020 2020 2020 2020 2020  ies'..          
+00003e00: 2020 2020 2720 6765 6f6d 6167 6e65 7469      ' geomagneti
+00003e10: 6320 6669 656c 6420 2d20 7661 7269 6573  c field - varies
+00003e20: 2074 656d 706f 7261 6c79 2e27 290d 0a20   temporaly.').. 
+00003e30: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00003e40: 696e 636c 203d 2061 6573 6172 612e 7368  incl = aesara.sh
+00003e50: 6172 6564 286e 702e 6172 7261 7928 312c  ared(np.array(1,
+00003e60: 2064 7479 7065 3d64 7479 7065 292c 0d0a   dtype=dtype),..
+00003e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003e90: 2020 2020 2020 2744 6970 206f 6620 7468        'Dip of th
+00003ea0: 6520 6765 6f6d 6167 6e65 7469 6320 6669  e geomagnetic fi
+00003eb0: 656c 6420 696e 2064 6567 7265 6573 2d20  eld in degrees- 
+00003ec0: 7661 7269 6573 270d 0a20 2020 2020 2020  varies'..       
+00003ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003ee0: 2020 2020 2020 2020 2020 2020 2020 2027                 '
+00003ef0: 2073 7061 7469 616c 6c79 2729 0d0a 2020   spatially')..  
+00003f00: 2020 2020 2020 2020 2020 7365 6c66 2e64            self.d
+00003f10: 6563 6c20 3d20 6165 7361 7261 2e73 6861  ecl = aesara.sha
+00003f20: 7265 6428 6e70 2e61 7272 6179 2831 2c20  red(np.array(1, 
+00003f30: 6474 7970 653d 6474 7970 6529 2c0d 0a20  dtype=dtype),.. 
 00003f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003f50: 2020 2020 2020 2020 2020 2020 2720 7370              ' sp
-00003f60: 6174 6961 6c6c 7927 290d 0a20 2020 2020  atially')..     
-00003f70: 2020 2020 2020 2073 656c 662e 6465 636c         self.decl
-00003f80: 203d 2074 6865 616e 6f2e 7368 6172 6564   = theano.shared
-00003f90: 286e 702e 6172 7261 7928 312c 2064 7479  (np.array(1, dty
-00003fa0: 7065 3d64 7479 7065 292c 0d0a 2020 2020  pe=dtype),..    
+00003f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003f60: 2020 2020 2027 416e 676c 6520 6265 7477       'Angle betw
+00003f70: 6565 6e20 6d61 676e 6574 6963 2061 6e64  een magnetic and
+00003f80: 2074 7275 6520 4e6f 7274 6820 696e 2064   true North in d
+00003f90: 6567 7265 6573 202d 270d 0a20 2020 2020  egrees -'..     
+00003fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00003fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003fd0: 2020 2741 6e67 6c65 2062 6574 7765 656e    'Angle between
-00003fe0: 206d 6167 6e65 7469 6320 616e 6420 7472   magnetic and tr
-00003ff0: 7565 204e 6f72 7468 2069 6e20 6465 6772  ue North in degr
-00004000: 6565 7320 2d27 0d0a 2020 2020 2020 2020  ees -'..        
-00004010: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004020: 2020 2020 2020 2020 2020 2020 2020 2720                ' 
-00004030: 7661 7269 6573 2073 7061 7469 616c 6c79  varies spatially
-00004040: 2729 0d0a 2020 2020 2020 2020 2020 2020  ')..            
-00004050: 7365 6c66 2e70 6f73 5f6d 6167 6e65 7469  self.pos_magneti
-00004060: 6373 203d 2074 6865 616e 6f2e 7368 6172  cs = theano.shar
-00004070: 6564 286e 702e 6172 7261 7928 322c 2064  ed(np.array(2, d
-00004080: 7479 7065 3d27 696e 7436 3427 292c 0d0a  type='int64'),..
-00004090: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000040a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000040b0: 2020 2020 2020 2020 2020 2020 2020 2027                 '
-000040c0: 706f 7369 7469 6f6e 206f 6620 7375 732e  position of sus.
-000040d0: 206f 6e20 7468 6520 7661 6c75 6573 206d   on the values m
-000040e0: 6174 7269 782e 2729 0d0a 2020 2020 2020  atrix.')..      
-000040f0: 2020 2020 2020 7365 6c66 2e56 203d 2074        self.V = t
-00004100: 6865 616e 6f2e 7368 6172 6564 286e 702e  heano.shared(np.
-00004110: 6f6e 6573 2828 362c 2031 3029 2c20 6474  ones((6, 10), dt
-00004120: 7970 653d 7365 6c66 2e64 7479 7065 292c  ype=self.dtype),
-00004130: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00004140: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004150: 2020 2020 2027 536f 6c75 7469 6f6e 7320       'Solutions 
-00004160: 746f 2076 6f6c 756d 6520 696e 7465 6772  to volume integr
-00004170: 616c 7320 2d27 0d0a 2020 2020 2020 2020  als -'..        
-00004180: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004190: 2020 2020 2020 2020 2020 2027 2073 616d             ' sam
-000041a0: 6520 666f 7220 6561 6368 2064 6576 6963  e for each devic
-000041b0: 6527 290d 0a20 2020 2020 2020 2069 6620  e')..        if 
-000041c0: 2774 6f70 6f6c 6f67 7927 2069 6e20 7365  'topology' in se
-000041d0: 6c66 2e63 6f6d 7075 7465 5f74 7970 653a  lf.compute_type:
-000041e0: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
-000041f0: 546f 706f 6c6f 6779 0d0a 2020 2020 2020  Topology..      
-00004200: 2020 2020 2020 7365 6c66 2e6d 6178 5f6c        self.max_l
-00004210: 6974 6820 3d20 7468 6561 6e6f 2e73 6861  ith = theano.sha
-00004220: 7265 6428 6e70 2e61 7272 6179 2831 302c  red(np.array(10,
-00004230: 2064 7479 7065 3d27 696e 7427 292c 0d0a   dtype='int'),..
-00004240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004260: 2020 2020 2020 2020 2020 274d 6178 2069            'Max i
-00004270: 6420 6f66 2074 6865 206c 6974 686f 6c6f  d of the litholo
-00004280: 6769 6573 2729 0d0a 0d0a 2020 2020 2020  gies')....      
-00004290: 2020 2020 2020 2320 544f 444f 3a20 7468        # TODO: th
-000042a0: 6520 706f 7369 7469 6f6e 206f 6620 746f  e position of to
-000042b0: 706f 6c6f 6779 2069 7320 6e6f 7420 7072  pology is not pr
-000042c0: 6f70 6572 6c79 2069 6d70 6c65 6d65 6e74  operly implement
-000042d0: 6564 2079 6574 0d0a 2020 2020 2020 2020  ed yet..        
-000042e0: 2020 2020 7365 6c66 2e70 6f73 5f74 6f70      self.pos_top
-000042f0: 6f6c 6f67 795f 6964 203d 2074 6865 616e  ology_id = thean
-00004300: 6f2e 7368 6172 6564 286e 702e 6172 7261  o.shared(np.arra
-00004310: 7928 2d31 2c20 6474 7970 653d 2769 6e74  y(-1, dtype='int
-00004320: 2729 2c0d 0a20 2020 2020 2020 2020 2020  '),..           
+00003fc0: 2027 2076 6172 6965 7320 7370 6174 6961   ' varies spatia
+00003fd0: 6c6c 7927 290d 0a20 2020 2020 2020 2020  lly')..         
+00003fe0: 2020 2073 656c 662e 706f 735f 6d61 676e     self.pos_magn
+00003ff0: 6574 6963 7320 3d20 6165 7361 7261 2e73  etics = aesara.s
+00004000: 6861 7265 6428 6e70 2e61 7272 6179 2832  hared(np.array(2
+00004010: 2c20 6474 7970 653d 2769 6e74 3634 2729  , dtype='int64')
+00004020: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00004030: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004040: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004050: 2020 2770 6f73 6974 696f 6e20 6f66 2073    'position of s
+00004060: 7573 2e20 6f6e 2074 6865 2076 616c 7565  us. on the value
+00004070: 7320 6d61 7472 6978 2e27 290d 0a20 2020  s matrix.')..   
+00004080: 2020 2020 2020 2020 2073 656c 662e 5620           self.V 
+00004090: 3d20 6165 7361 7261 2e73 6861 7265 6428  = aesara.shared(
+000040a0: 6e70 2e6f 6e65 7328 2836 2c20 3130 292c  np.ones((6, 10),
+000040b0: 2064 7479 7065 3d73 656c 662e 6474 7970   dtype=self.dtyp
+000040c0: 6529 2c0d 0a20 2020 2020 2020 2020 2020  e),..           
+000040d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000040e0: 2020 2020 2020 2020 2753 6f6c 7574 696f          'Solutio
+000040f0: 6e73 2074 6f20 766f 6c75 6d65 2069 6e74  ns to volume int
+00004100: 6567 7261 6c73 202d 270d 0a20 2020 2020  egrals -'..     
+00004110: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004120: 2020 2020 2020 2020 2020 2020 2020 2720                ' 
+00004130: 7361 6d65 2066 6f72 2065 6163 6820 6465  same for each de
+00004140: 7669 6365 2729 0d0a 2020 2020 2020 2020  vice')..        
+00004150: 6966 2027 746f 706f 6c6f 6779 2720 696e  if 'topology' in
+00004160: 2073 656c 662e 636f 6d70 7574 655f 7479   self.compute_ty
+00004170: 7065 3a0d 0a20 2020 2020 2020 2020 2020  pe:..           
+00004180: 2023 2054 6f70 6f6c 6f67 790d 0a20 2020   # Topology..   
+00004190: 2020 2020 2020 2020 2073 656c 662e 6d61           self.ma
+000041a0: 785f 6c69 7468 203d 2061 6573 6172 612e  x_lith = aesara.
+000041b0: 7368 6172 6564 286e 702e 6172 7261 7928  shared(np.array(
+000041c0: 3130 2c20 6474 7970 653d 2769 6e74 2729  10, dtype='int')
+000041d0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+000041e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000041f0: 2020 2020 2020 2020 2020 2020 2027 4d61               'Ma
+00004200: 7820 6964 206f 6620 7468 6520 6c69 7468  x id of the lith
+00004210: 6f6c 6f67 6965 7327 290d 0a0d 0a20 2020  ologies')....   
+00004220: 2020 2020 2020 2020 2023 2054 4f44 4f3a           # TODO:
+00004230: 2074 6865 2070 6f73 6974 696f 6e20 6f66   the position of
+00004240: 2074 6f70 6f6c 6f67 7920 6973 206e 6f74   topology is not
+00004250: 2070 726f 7065 726c 7920 696d 706c 656d   properly implem
+00004260: 656e 7465 6420 7965 740d 0a20 2020 2020  ented yet..     
+00004270: 2020 2020 2020 2073 656c 662e 706f 735f         self.pos_
+00004280: 746f 706f 6c6f 6779 5f69 6420 3d20 6165  topology_id = ae
+00004290: 7361 7261 2e73 6861 7265 6428 6e70 2e61  sara.shared(np.a
+000042a0: 7272 6179 282d 312c 2064 7479 7065 3d27  rray(-1, dtype='
+000042b0: 696e 7427 292c 0d0a 2020 2020 2020 2020  int'),..        
+000042c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000042d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000042e0: 2020 2020 2020 2020 2027 506f 7369 7469           'Positi
+000042f0: 6f6e 206f 6620 7468 6520 7375 7266 6163  on of the surfac
+00004300: 6520 6461 7461 6672 616d 6520 7769 7468  e dataframe with
+00004310: 2074 6865 270d 0a20 2020 2020 2020 2020   the'..         
+00004320: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00004330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004350: 2020 2020 2020 2750 6f73 6974 696f 6e20        'Position 
-00004360: 6f66 2074 6865 2073 7572 6661 6365 2064  of the surface d
-00004370: 6174 6166 7261 6d65 2077 6974 6820 7468  ataframe with th
-00004380: 6527 0d0a 2020 2020 2020 2020 2020 2020  e'..            
+00004340: 2020 2020 2020 2020 2772 6967 6874 2074          'right t
+00004350: 6f70 6f6c 6f67 7920 6964 7320 746f 2062  opology ids to b
+00004360: 6520 6162 6c65 2074 6f20 6861 7665 2075  e able to have u
+00004370: 6e69 7175 6527 0d0a 2020 2020 2020 2020  nique'..        
+00004380: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00004390: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000043a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000043b0: 2020 2020 2027 7269 6768 7420 746f 706f       'right topo
-000043c0: 6c6f 6779 2069 6473 2074 6f20 6265 2061  logy ids to be a
-000043d0: 626c 6520 746f 2068 6176 6520 756e 6971  ble to have uniq
-000043e0: 7565 270d 0a20 2020 2020 2020 2020 2020  ue'..           
-000043f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004410: 2020 2020 2020 2769 6465 6e74 6966 6965        'identifie
-00004420: 7273 2729 0d0a 0d0a 2020 2020 2020 2020  rs')....        
-00004430: 2020 2020 7365 6c66 2e72 6567 756c 6172      self.regular
-00004440: 5f67 7269 645f 7265 7320 3d20 7468 6561  _grid_res = thea
-00004450: 6e6f 2e73 6861 7265 6428 6e70 2e6f 6e65  no.shared(np.one
-00004460: 7328 332c 2064 7479 7065 3d27 696e 7427  s(3, dtype='int'
-00004470: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
-00004480: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000044a0: 2020 2020 2020 2752 6573 6f6c 7574 696f        'Resolutio
-000044b0: 6e20 6f66 2074 6865 2072 6567 756c 6172  n of the regular
-000044c0: 2067 7269 6427 290d 0a20 2020 2020 2020   grid')..       
-000044d0: 2020 2020 2073 656c 662e 6478 6479 647a       self.dxdydz
-000044e0: 203d 2074 6865 616e 6f2e 7368 6172 6564   = theano.shared
-000044f0: 286e 702e 6f6e 6573 2833 2c20 6474 7970  (np.ones(3, dtyp
-00004500: 653d 6474 7970 6529 2c0d 0a20 2020 2020  e=dtype),..     
-00004510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004520: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004530: 2020 2027 5369 7a65 206f 6620 7468 6520     'Size of the 
-00004540: 766f 7865 6c73 2069 6e20 6561 6368 2064  voxels in each d
-00004550: 6972 6563 7469 6f6e 2e27 290d 0a0d 0a20  irection.').... 
-00004560: 2020 2020 2020 2023 2052 6573 756c 7473         # Results
-00004570: 206d 6174 7269 780d 0a20 2020 2020 2020   matrix..       
-00004580: 2073 656c 662e 7765 6967 6874 735f 7665   self.weights_ve
-00004590: 6374 6f72 203d 2074 6865 616e 6f2e 7368  ctor = theano.sh
-000045a0: 6172 6564 286e 702e 6361 7374 5b64 7479  ared(np.cast[dty
-000045b0: 7065 5d28 6e70 2e7a 6572 6f73 2831 3030  pe](np.zeros(100
-000045c0: 3030 2929 2c0d 0a20 2020 2020 2020 2020  00)),..         
-000045d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000045e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000045f0: 2020 2027 5765 6967 6874 7320 7665 6374     'Weights vect
-00004600: 6f72 2729 0d0a 2020 2020 2020 2020 7365  or')..        se
-00004610: 6c66 2e73 6361 6c61 725f 6669 656c 6473  lf.scalar_fields
-00004620: 5f6d 6174 7269 7820 3d20 7468 6561 6e6f  _matrix = theano
-00004630: 2e73 6861 7265 6428 0d0a 2020 2020 2020  .shared(..      
-00004640: 2020 2020 2020 6e70 2e63 6173 745b 6474        np.cast[dt
-00004650: 7970 655d 286e 702e 7a65 726f 7328 2833  ype](np.zeros((3
-00004660: 2c20 3130 3030 3029 2929 2c20 2753 6361  , 10000))), 'Sca
-00004670: 6c61 7220 6d61 7472 6978 2729 0d0a 2020  lar matrix')..  
-00004680: 2020 2020 2020 7365 6c66 2e62 6c6f 636b        self.block
-00004690: 5f6d 6174 7269 7820 3d20 7468 6561 6e6f  _matrix = theano
-000046a0: 2e73 6861 7265 6428 6e70 2e63 6173 745b  .shared(np.cast[
-000046b0: 6474 7970 655d 286e 702e 7a65 726f 7328  dtype](np.zeros(
-000046c0: 2833 2c20 332c 2031 3030 3030 2929 292c  (3, 3, 10000))),
-000046d0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-000046e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000046f0: 2020 2020 2020 2020 2020 2020 2262 6c6f              "blo
-00004700: 636b 206d 6174 7269 7822 290d 0a20 2020  ck matrix")..   
-00004710: 2020 2020 2073 656c 662e 6d61 736b 5f6d       self.mask_m
-00004720: 6174 7269 7820 3d20 7468 6561 6e6f 2e73  atrix = theano.s
-00004730: 6861 7265 6428 6e70 2e7a 6572 6f73 2828  hared(np.zeros((
-00004740: 332c 2031 3030 3030 292c 2064 7479 7065  3, 10000), dtype
-00004750: 3d27 626f 6f6c 2729 2c0d 0a20 2020 2020  ='bool'),..     
-00004760: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004770: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004780: 2020 2020 226d 6173 6b20 6d61 7472 6978      "mask matrix
-00004790: 2229 0d0a 2020 2020 2020 2020 7365 6c66  ")..        self
-000047a0: 2e73 6661 6920 3d20 542e 7a65 726f 7328  .sfai = T.zeros(
-000047b0: 0d0a 2020 2020 2020 2020 2020 2020 5b73  ..            [s
-000047c0: 656c 662e 6973 5f65 726f 7369 6f6e 2e73  elf.is_erosion.s
-000047d0: 6861 7065 5b30 5d2c 2073 656c 662e 6e5f  hape[0], self.n_
-000047e0: 7375 7266 6163 6573 5f70 6572 5f73 6572  surfaces_per_ser
-000047f0: 6965 735b 2d31 5d5d 290d 0a0d 0a20 2020  ies[-1]])....   
-00004800: 2020 2020 2073 656c 662e 6e65 775f 626c       self.new_bl
-00004810: 6f63 6b20 3d20 7365 6c66 2e62 6c6f 636b  ock = self.block
-00004820: 5f6d 6174 7269 780d 0a20 2020 2020 2020  _matrix..       
-00004830: 2073 656c 662e 6e65 775f 7765 6967 6874   self.new_weight
-00004840: 7320 3d20 7365 6c66 2e77 6569 6768 7473  s = self.weights
-00004850: 5f76 6563 746f 720d 0a20 2020 2020 2020  _vector..       
-00004860: 2073 656c 662e 6e65 775f 7363 616c 6172   self.new_scalar
-00004870: 203d 2073 656c 662e 7363 616c 6172 5f66   = self.scalar_f
-00004880: 6965 6c64 735f 6d61 7472 6978 0d0a 2020  ields_matrix..  
-00004890: 2020 2020 2020 7365 6c66 2e6e 6577 5f6d        self.new_m
-000048a0: 6173 6b20 3d20 7365 6c66 2e6d 6173 6b5f  ask = self.mask_
-000048b0: 6d61 7472 6978 0d0a 2020 2020 2020 2020  matrix..        
-000048c0: 7365 6c66 2e6e 6577 5f73 6661 6920 3d20  self.new_sfai = 
-000048d0: 7365 6c66 2e73 6661 690d 0a0d 0a20 2020  self.sfai....   
-000048e0: 2064 6566 2063 6f6d 7075 7465 5f77 6569   def compute_wei
-000048f0: 6768 7473 2873 656c 6629 3a0d 0a20 2020  ghts(self):..   
-00004900: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-00004910: 2e73 6f6c 7665 5f6b 7269 6769 6e67 2829  .solve_kriging()
-00004920: 0d0a 0d0a 2020 2020 6465 6620 636f 6d70  ....    def comp
-00004930: 7574 655f 7363 616c 6172 5f66 6965 6c64  ute_scalar_field
-00004940: 2873 656c 662c 2077 6569 6768 7473 2c20  (self, weights, 
-00004950: 6772 6964 2c20 6661 756c 745f 6d61 7472  grid, fault_matr
-00004960: 6978 293a 0d0a 2020 2020 2020 2020 6772  ix):..        gr
-00004970: 6964 5f76 616c 203d 2073 656c 662e 785f  id_val = self.x_
-00004980: 746f 5f69 6e74 6572 706f 6c61 7465 2867  to_interpolate(g
-00004990: 7269 6429 0d0a 2020 2020 2020 2020 7265  rid)..        re
-000049a0: 7475 726e 2073 656c 662e 7363 616c 6172  turn self.scalar
-000049b0: 5f66 6965 6c64 5f61 745f 616c 6c28 7765  _field_at_all(we
-000049c0: 6967 6874 732c 2067 7269 645f 7661 6c2c  ights, grid_val,
-000049d0: 2066 6175 6c74 5f6d 6174 7269 7829 0d0a   fault_matrix)..
-000049e0: 0d0a 2020 2020 6465 6620 636f 6d70 7574  ..    def comput
-000049f0: 655f 666f 726d 6174 696f 6e5f 626c 6f63  e_formation_bloc
-00004a00: 6b28 7365 6c66 2c20 5a5f 782c 2073 6361  k(self, Z_x, sca
-00004a10: 6c61 725f 6669 656c 645f 6174 5f73 7572  lar_field_at_sur
-00004a20: 6661 6365 5f70 6f69 6e74 732c 2076 616c  face_points, val
-00004a30: 7565 7329 3a0d 0a20 2020 2020 2020 2072  ues):..        r
-00004a40: 6574 7572 6e20 7365 6c66 2e65 7870 6f72  eturn self.expor
-00004a50: 745f 666f 726d 6174 696f 6e5f 626c 6f63  t_formation_bloc
-00004a60: 6b28 5a5f 782c 2073 6361 6c61 725f 6669  k(Z_x, scalar_fi
-00004a70: 656c 645f 6174 5f73 7572 6661 6365 5f70  eld_at_surface_p
-00004a80: 6f69 6e74 732c 0d0a 2020 2020 2020 2020  oints,..        
-00004a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004ab0: 2020 2076 616c 7565 7329 0d0a 0d0a 2020     values)....  
-00004ac0: 2020 6465 6620 636f 6d70 7574 655f 6661    def compute_fa
-00004ad0: 756c 745f 626c 6f63 6b28 7365 6c66 2c20  ult_block(self, 
-00004ae0: 5a5f 782c 2073 6361 6c61 725f 6669 656c  Z_x, scalar_fiel
-00004af0: 645f 6174 5f73 7572 6661 6365 5f70 6f69  d_at_surface_poi
-00004b00: 6e74 732c 2076 616c 7565 732c 0d0a 2020  nts, values,..  
-00004b10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004b20: 2020 2020 2020 2020 2020 6e5f 7365 7269            n_seri
-00004b30: 6573 2c20 6772 6964 293a 0d0a 2020 2020  es, grid):..    
-00004b40: 2020 2020 6772 6964 5f76 616c 203d 2073      grid_val = s
-00004b50: 656c 662e 785f 746f 5f69 6e74 6572 706f  elf.x_to_interpo
-00004b60: 6c61 7465 2867 7269 6429 0d0a 2020 2020  late(grid)..    
-00004b70: 2020 2020 6669 6e69 7465 5f66 6175 6c74      finite_fault
-00004b80: 735f 656c 6c69 7073 6520 3d20 7365 6c66  s_ellipse = self
-00004b90: 2e73 656c 6563 745f 6669 6e69 7465 5f66  .select_finite_f
-00004ba0: 6175 6c74 7328 6772 6964 5f76 616c 290d  aults(grid_val).
-00004bb0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00004bc0: 7365 6c66 2e65 7870 6f72 745f 6661 756c  self.export_faul
-00004bd0: 745f 626c 6f63 6b28 5a5f 782c 2073 6361  t_block(Z_x, sca
-00004be0: 6c61 725f 6669 656c 645f 6174 5f73 7572  lar_field_at_sur
-00004bf0: 6661 6365 5f70 6f69 6e74 732c 2076 616c  face_points, val
-00004c00: 7565 732c 0d0a 2020 2020 2020 2020 2020  ues,..          
-00004c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004c20: 2020 2020 2020 2020 2020 2020 2066 696e               fin
-00004c30: 6974 655f 6661 756c 7473 5f65 6c6c 6970  ite_faults_ellip
-00004c40: 7365 290d 0a0d 0a20 2020 2064 6566 2063  se)....    def c
-00004c50: 6f6d 7075 7465 5f66 696e 616c 5f62 6c6f  ompute_final_blo
-00004c60: 636b 2873 656c 662c 206d 6173 6b2c 2062  ck(self, mask, b
-00004c70: 6c6f 636b 293a 0d0a 0d0a 2020 2020 2020  lock):....      
-00004c80: 2020 2320 5765 2061 6464 2074 6865 2061    # We add the a
-00004c90: 7869 7320 3120 746f 2074 6865 206d 6173  xis 1 to the mas
-00004ca0: 6b2e 2041 7869 7320 3120 6973 2074 6865  k. Axis 1 is the
-00004cb0: 2070 726f 7065 7274 6965 7320 7661 6c75   properties valu
-00004cc0: 6573 2061 7869 730d 0a20 2020 2020 2020  es axis..       
-00004cd0: 2023 2054 6865 6e20 7765 2073 756d 206f   # Then we sum o
-00004ce0: 7665 7220 7468 6520 3020 6178 6973 2e20  ver the 0 axis. 
-00004cf0: 4178 6973 2030 2069 7320 7468 6520 7365  Axis 0 is the se
-00004d00: 7269 6573 0d0a 2020 2020 2020 2020 6669  ries..        fi
-00004d10: 6e61 6c5f 6d6f 6465 6c20 3d20 542e 7375  nal_model = T.su
-00004d20: 6d28 542e 7374 6163 6b28 5b6d 6173 6b5d  m(T.stack([mask]
-00004d30: 2c20 6178 6973 3d31 2920 2a20 626c 6f63  , axis=1) * bloc
-00004d40: 6b2c 2061 7869 733d 3029 0d0a 2020 2020  k, axis=0)..    
-00004d50: 2020 2020 7265 7475 726e 2066 696e 616c      return final
-00004d60: 5f6d 6f64 656c 0d0a 0d0a 2020 2020 6465  _model....    de
-00004d70: 6620 636f 6d70 7574 655f 7365 7269 6573  f compute_series
-00004d80: 2873 656c 662c 2067 7269 643d 4e6f 6e65  (self, grid=None
-00004d90: 2c20 7368 6966 743d 4e6f 6e65 293a 0d0a  , shift=None):..
-00004da0: 2020 2020 2020 2020 6966 2067 7269 6420          if grid 
-00004db0: 6973 204e 6f6e 653a 0d0a 2020 2020 2020  is None:..      
-00004dc0: 2020 2020 2020 6772 6964 203d 2073 656c        grid = sel
-00004dd0: 662e 6772 6964 5f76 616c 5f54 0d0a 2020  f.grid_val_T..  
-00004de0: 2020 2020 2020 6966 2073 6869 6674 2069        if shift i
-00004df0: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
-00004e00: 2020 2020 2073 6869 6674 203d 2073 656c       shift = sel
-00004e10: 662e 7368 6966 740d 0a0d 0a20 2020 2020  f.shift....     
-00004e20: 2020 2023 2054 4f44 4f20 4920 6861 7665     # TODO I have
-00004e30: 2074 6f20 7461 6b65 2074 6869 7320 6675   to take this fu
-00004e40: 6e63 7469 6f6e 2074 6f20 696e 7465 7270  nction to interp
-00004e50: 6f6c 6174 6f72 2061 6e64 206d 616b 696e  olator and makin
-00004e60: 6720 7468 6520 6265 6861 7669 6f75 7220  g the behaviour 
-00004e70: 7468 6520 7361 6d65 2061 7320 6d61 736b  the same as mask
-00004e80: 5f6d 6174 7269 780d 0a20 2020 2020 2020  _matrix..       
-00004e90: 2073 656c 662e 6d61 736b 5f6d 6174 7269   self.mask_matri
-00004ea0: 785f 6620 3d20 542e 7a65 726f 735f 6c69  x_f = T.zeros_li
-00004eb0: 6b65 2873 656c 662e 6d61 736b 5f6f 7032  ke(self.mask_op2
-00004ec0: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-00004ed0: 6661 756c 745f 6d61 7472 6978 203d 2054  fault_matrix = T
-00004ee0: 2e7a 6572 6f73 5f6c 696b 6528 7365 6c66  .zeros_like(self
-00004ef0: 2e62 6c6f 636b 5f6f 7029 0d0a 0d0a 2020  .block_op)....  
-00004f00: 2020 2020 2020 2320 4c6f 6f70 696e 670d        # Looping.
-00004f10: 0a20 2020 2020 2020 2073 6572 6965 732c  .        series,
-00004f20: 2073 656c 662e 7570 6461 7465 7331 203d   self.updates1 =
-00004f30: 2074 6865 616e 6f2e 7363 616e 280d 0a20   theano.scan(.. 
-00004f40: 2020 2020 2020 2020 2020 2066 6e3d 7365             fn=se
-00004f50: 6c66 2e63 6f6d 7075 7465 5f61 5f73 6572  lf.compute_a_ser
-00004f60: 6965 732c 0d0a 2020 2020 2020 2020 2020  ies,..          
-00004f70: 2020 6f75 7470 7574 735f 696e 666f 3d5b    outputs_info=[
-00004f80: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00004f90: 2020 6469 6374 2869 6e69 7469 616c 3d73    dict(initial=s
-00004fa0: 656c 662e 626c 6f63 6b5f 6f70 292c 0d0a  elf.block_op),..
-00004fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004fc0: 6469 6374 2869 6e69 7469 616c 3d73 656c  dict(initial=sel
-00004fd0: 662e 7765 6967 6874 735f 6f70 292c 0d0a  f.weights_op),..
-00004fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004ff0: 6469 6374 2869 6e69 7469 616c 3d73 656c  dict(initial=sel
-00005000: 662e 7363 616c 6172 5f6f 7029 2c0d 0a20  f.scalar_op),.. 
-00005010: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-00005020: 6963 7428 696e 6974 6961 6c3d 7365 6c66  ict(initial=self
-00005030: 2e73 6661 695f 6f70 292c 0d0a 2020 2020  .sfai_op),..    
-00005040: 2020 2020 2020 2020 2020 2020 6469 6374              dict
-00005050: 2869 6e69 7469 616c 3d73 656c 662e 6d61  (initial=self.ma
-00005060: 736b 5f6f 7032 292c 0d0a 2020 2020 2020  sk_op2),..      
-00005070: 2020 2020 2020 2020 2020 6469 6374 2869            dict(i
-00005080: 6e69 7469 616c 3d73 656c 662e 6d61 736b  nitial=self.mask
-00005090: 5f6d 6174 7269 785f 6629 2c0d 0a20 2020  _matrix_f),..   
-000050a0: 2020 2020 2020 2020 2020 2020 2064 6963               dic
-000050b0: 7428 696e 6974 6961 6c3d 7365 6c66 2e66  t(initial=self.f
-000050c0: 6175 6c74 5f6d 6174 7269 7829 2c0d 0a20  ault_matrix),.. 
-000050d0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-000050e0: 6963 7428 696e 6974 6961 6c3d 542e 6361  ict(initial=T.ca
-000050f0: 7374 2830 2c20 2769 6e74 3634 2729 290d  st(0, 'int64')).
-00005100: 0a0d 0a20 2020 2020 2020 2020 2020 205d  ...            ]
-00005110: 2c20 2023 2054 6869 7320 6c69 6e65 206d  ,  # This line m
-00005120: 6179 2062 6520 7573 6564 2066 6f72 2074  ay be used for t
-00005130: 6865 2064 6620 6e65 7477 6f72 6b0d 0a20  he df network.. 
-00005140: 2020 2020 2020 2020 2020 2073 6571 7565             seque
-00005150: 6e63 6573 3d5b 6469 6374 2869 6e70 7574  nces=[dict(input
-00005160: 3d73 656c 662e 6c65 6e5f 7365 7269 6573  =self.len_series
-00005170: 5f69 2c20 7461 7073 3d5b 302c 2031 5d29  _i, taps=[0, 1])
-00005180: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00005190: 2020 2020 2020 2020 2020 6469 6374 2869            dict(i
-000051a0: 6e70 7574 3d73 656c 662e 6c65 6e5f 7365  nput=self.len_se
-000051b0: 7269 6573 5f6f 2c20 7461 7073 3d5b 302c  ries_o, taps=[0,
-000051c0: 2031 5d29 2c0d 0a20 2020 2020 2020 2020   1]),..         
-000051d0: 2020 2020 2020 2020 2020 2020 2020 6469                di
-000051e0: 6374 2869 6e70 7574 3d73 656c 662e 6c65  ct(input=self.le
-000051f0: 6e5f 7365 7269 6573 5f77 2c20 7461 7073  n_series_w, taps
-00005200: 3d5b 302c 2031 5d29 2c0d 0a20 2020 2020  =[0, 1]),..     
-00005210: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005220: 2020 6469 6374 2869 6e70 7574 3d73 656c    dict(input=sel
-00005230: 662e 6e5f 7375 7266 6163 6573 5f70 6572  f.n_surfaces_per
-00005240: 5f73 6572 6965 732c 2074 6170 733d 5b30  _series, taps=[0
-00005250: 2c20 315d 292c 0d0a 2020 2020 2020 2020  , 1]),..        
-00005260: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-00005270: 6963 7428 696e 7075 743d 7365 6c66 2e6e  ict(input=self.n
-00005280: 5f75 6e69 7665 7273 616c 5f65 715f 542c  _universal_eq_T,
-00005290: 2074 6170 733d 5b30 5d29 2c0d 0a20 2020   taps=[0]),..   
-000052a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000052b0: 2020 2020 6469 6374 2869 6e70 7574 3d73      dict(input=s
-000052c0: 656c 662e 636f 6d70 7574 655f 7765 6967  elf.compute_weig
-000052d0: 6874 735f 6374 726c 2c20 7461 7073 3d5b  hts_ctrl, taps=[
-000052e0: 305d 292c 0d0a 2020 2020 2020 2020 2020  0]),..          
-000052f0: 2020 2020 2020 2020 2020 2020 2064 6963               dic
-00005300: 7428 696e 7075 743d 7365 6c66 2e63 6f6d  t(input=self.com
-00005310: 7075 7465 5f73 6361 6c61 725f 6374 726c  pute_scalar_ctrl
-00005320: 2c20 7461 7073 3d5b 305d 292c 0d0a 2020  , taps=[0]),..  
-00005330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005340: 2020 2020 2064 6963 7428 696e 7075 743d       dict(input=
-00005350: 7365 6c66 2e63 6f6d 7075 7465 5f62 6c6f  self.compute_blo
-00005360: 636b 5f63 7472 6c2c 2074 6170 733d 5b30  ck_ctrl, taps=[0
-00005370: 5d29 2c0d 0a20 2020 2020 2020 2020 2020  ]),..           
-00005380: 2020 2020 2020 2020 2020 2020 6469 6374              dict
-00005390: 2869 6e70 7574 3d73 656c 662e 6973 5f66  (input=self.is_f
-000053a0: 696e 6974 655f 6374 726c 2c20 7461 7073  inite_ctrl, taps
-000053b0: 3d5b 305d 292c 0d0a 2020 2020 2020 2020  =[0]),..        
-000053c0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-000053d0: 6963 7428 696e 7075 743d 7365 6c66 2e69  ict(input=self.i
-000053e0: 735f 6572 6f73 696f 6e2c 2074 6170 733d  s_erosion, taps=
-000053f0: 5b30 5d29 2c0d 0a20 2020 2020 2020 2020  [0]),..         
-00005400: 2020 2020 2020 2020 2020 2020 2020 6469                di
-00005410: 6374 2869 6e70 7574 3d73 656c 662e 6973  ct(input=self.is
-00005420: 5f6f 6e6c 6170 2c20 7461 7073 3d5b 305d  _onlap, taps=[0]
-00005430: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
-00005440: 2020 2020 2020 2020 2020 2064 6963 7428             dict(
-00005450: 696e 7075 743d 542e 6172 616e 6765 2830  input=T.arange(0
-00005460: 2c20 3530 3030 2c20 6474 7970 653d 2769  , 5000, dtype='i
-00005470: 6e74 3332 2729 2c20 7461 7073 3d5b 305d  nt32'), taps=[0]
-00005480: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
-00005490: 2020 2020 2020 2020 2020 2064 6963 7428             dict(
-000054a0: 696e 7075 743d 7365 6c66 2e61 5f54 2c20  input=self.a_T, 
-000054b0: 7461 7073 3d5b 305d 292c 0d0a 2020 2020  taps=[0]),..    
-000054c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000054d0: 2020 2064 6963 7428 696e 7075 743d 7365     dict(input=se
-000054e0: 6c66 2e63 5f6f 5f54 5f73 6361 6c61 722c  lf.c_o_T_scalar,
-000054f0: 2074 6170 733d 5b30 5d29 0d0a 2020 2020   taps=[0])..    
-00005500: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005510: 2020 205d 2c0d 0a20 2020 2020 2020 2020     ],..         
-00005520: 2020 206e 6f6e 5f73 6571 7565 6e63 6573     non_sequences
-00005530: 3d5b 6772 6964 2c20 7368 6966 745d 2c0d  =[grid, shift],.
-00005540: 0a20 2020 2020 2020 2020 2020 206e 616d  .            nam
-00005550: 653d 274c 6f6f 7069 6e67 272c 0d0a 2020  e='Looping',..  
-00005560: 2020 2020 2020 2020 2020 7265 7475 726e            return
-00005570: 5f6c 6973 743d 5472 7565 2c0d 0a20 2020  _list=True,..   
-00005580: 2020 2020 2020 2020 2070 726f 6669 6c65           profile
-00005590: 3d46 616c 7365 0d0a 2020 2020 2020 2020  =False..        
-000055a0: 290d 0a0d 0a20 2020 2020 2020 2073 656c  )....        sel
-000055b0: 662e 626c 6f63 6b5f 6f70 203d 2073 6572  f.block_op = ser
-000055c0: 6965 735b 305d 5b2d 315d 0d0a 2020 2020  ies[0][-1]..    
-000055d0: 2020 2020 7365 6c66 2e77 6569 6768 7473      self.weights
-000055e0: 5f6f 7020 3d20 7365 7269 6573 5b31 5d5b  _op = series[1][
-000055f0: 2d31 5d0d 0a20 2020 2020 2020 2073 656c  -1]..        sel
-00005600: 662e 7363 616c 6172 5f6f 7020 3d20 7365  f.scalar_op = se
-00005610: 7269 6573 5b32 5d5b 2d31 5d0d 0a20 2020  ries[2][-1]..   
-00005620: 2020 2020 2073 656c 662e 7366 6169 5f6f       self.sfai_o
-00005630: 7020 3d20 7365 7269 6573 5b33 5d5b 2d31  p = series[3][-1
-00005640: 5d0d 0a0d 0a20 2020 2020 2020 206d 6173  ]....        mas
-00005650: 6b20 3d20 7365 7269 6573 5b34 5d5b 2d31  k = series[4][-1
-00005660: 5d0d 0a20 2020 2020 2020 206d 6173 6b5f  ]..        mask_
-00005670: 7265 765f 6375 6d70 726f 6420 3d20 542e  rev_cumprod = T.
-00005680: 7665 7274 6963 616c 5f73 7461 636b 286d  vertical_stack(m
-00005690: 6173 6b5b 5b2d 315d 5d2c 0d0a 2020 2020  ask[[-1]],..    
-000056a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000056b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000056c0: 2020 2020 2020 2020 542e 6375 6d70 726f          T.cumpro
-000056d0: 6428 542e 696e 7665 7274 286d 6173 6b5b  d(T.invert(mask[
-000056e0: 3a2d 315d 292c 2061 7869 733d 3029 290d  :-1]), axis=0)).
-000056f0: 0a20 2020 2020 2020 2073 656c 662e 6d61  .        self.ma
-00005700: 736b 5f6f 7032 203d 206d 6173 6b5f 7265  sk_op2 = mask_re
-00005710: 765f 6375 6d70 726f 640d 0a20 2020 2020  v_cumprod..     
-00005720: 2020 2062 6c6f 636b 5f6d 6173 6b20 3d20     block_mask = 
-00005730: 6d61 736b 202a 206d 6173 6b5f 7265 765f  mask * mask_rev_
-00005740: 6375 6d70 726f 640d 0a0d 0a20 2020 2020  cumprod....     
-00005750: 2020 2066 6175 6c74 5f6d 6173 6b20 3d20     fault_mask = 
-00005760: 7365 7269 6573 5b35 5d5b 2d31 5d0d 0a0d  series[5][-1]...
-00005770: 0a20 2020 2020 2020 2066 6175 6c74 5f62  .        fault_b
-00005780: 6c6f 636b 203d 2073 656c 662e 636f 6d70  lock = self.comp
-00005790: 7574 655f 6669 6e61 6c5f 626c 6f63 6b28  ute_final_block(
-000057a0: 6661 756c 745f 6d61 736b 2c20 7365 6c66  fault_mask, self
-000057b0: 2e62 6c6f 636b 5f6f 7029 0d0a 2020 2020  .block_op)..    
-000057c0: 2020 2020 6669 6e61 6c5f 6d6f 6465 6c20      final_model 
-000057d0: 3d20 7365 6c66 2e63 6f6d 7075 7465 5f66  = self.compute_f
-000057e0: 696e 616c 5f62 6c6f 636b 2862 6c6f 636b  inal_block(block
-000057f0: 5f6d 6173 6b2c 2073 656c 662e 626c 6f63  _mask, self.bloc
-00005800: 6b5f 6f70 290d 0a0d 0a20 2020 2020 2020  k_op)....       
-00005810: 2072 6574 7572 6e20 5b66 696e 616c 5f6d   return [final_m
-00005820: 6f64 656c 2c20 7365 6c66 2e62 6c6f 636b  odel, self.block
-00005830: 5f6f 702c 2066 6175 6c74 5f62 6c6f 636b  _op, fault_block
-00005840: 2c20 7365 6c66 2e77 6569 6768 7473 5f6f  , self.weights_o
-00005850: 702c 0d0a 2020 2020 2020 2020 2020 2020  p,..            
-00005860: 2020 2020 7365 6c66 2e73 6361 6c61 725f      self.scalar_
-00005870: 6f70 2c0d 0a20 2020 2020 2020 2020 2020  op,..           
-00005880: 2020 2020 2073 656c 662e 7366 6169 5f6f       self.sfai_o
-00005890: 702c 2062 6c6f 636b 5f6d 6173 6b2c 2066  p, block_mask, f
-000058a0: 6175 6c74 5f6d 6173 6b5d 0d0a 0d0a 2020  ault_mask]....  
-000058b0: 2020 6465 6620 6372 6561 7465 5f6f 6374    def create_oct
-000058c0: 5f76 6f78 656c 7328 7365 6c66 2c20 7879  _voxels(self, xy
-000058d0: 7a2c 206c 6576 656c 3d31 293a 0d0a 2020  z, level=1):..  
-000058e0: 2020 2020 2020 785f 203d 2054 2e72 6570        x_ = T.rep
-000058f0: 6561 7428 542e 7374 6163 6b28 2878 797a  eat(T.stack((xyz
-00005900: 5b3a 2c20 305d 202d 2073 656c 662e 6478  [:, 0] - self.dx
-00005910: 6479 647a 5b30 5d20 2f20 6c65 7665 6c20  dydz[0] / level 
-00005920: 2f20 342c 0d0a 2020 2020 2020 2020 2020  / 4,..          
-00005930: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005940: 2020 2020 2078 797a 5b3a 2c20 305d 202b       xyz[:, 0] +
-00005950: 2073 656c 662e 6478 6479 647a 5b30 5d20   self.dxdydz[0] 
-00005960: 2f20 6c65 7665 6c20 2f20 3429 2c20 6178  / level / 4), ax
-00005970: 6973 3d31 292c 2034 2c0d 0a20 2020 2020  is=1), 4,..     
-00005980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005990: 2061 7869 733d 3129 0d0a 2020 2020 2020   axis=1)..      
-000059a0: 2020 795f 203d 2054 2e74 696c 6528 542e    y_ = T.tile(T.
-000059b0: 7265 7065 6174 2854 2e73 7461 636b 2828  repeat(T.stack((
-000059c0: 7879 7a5b 3a2c 2031 5d20 2d20 7365 6c66  xyz[:, 1] - self
-000059d0: 2e64 7864 7964 7a5b 315d 202f 206c 6576  .dxdydz[1] / lev
-000059e0: 656c 202f 2034 2c0d 0a20 2020 2020 2020  el / 4,..       
-000059f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005a00: 2020 2020 2020 2020 2020 2020 2020 2078                 x
-00005a10: 797a 5b3a 2c20 315d 202b 2073 656c 662e  yz[:, 1] + self.
-00005a20: 6478 6479 647a 5b31 5d20 2f20 6c65 7665  dxdydz[1] / leve
-00005a30: 6c20 2f20 3429 2c0d 0a20 2020 2020 2020  l / 4),..       
-00005a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005a50: 2020 2020 2020 2020 2020 2020 2020 6178                ax
-00005a60: 6973 3d31 292c 0d0a 2020 2020 2020 2020  is=1),..        
-00005a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005a80: 2020 2020 2032 2c20 6178 6973 3d31 292c       2, axis=1),
-00005a90: 2028 312c 2032 2929 0d0a 0d0a 2020 2020   (1, 2))....    
-00005aa0: 2020 2020 7a5f 203d 2054 2e74 696c 6528      z_ = T.tile(
-00005ab0: 542e 7374 6163 6b28 2878 797a 5b3a 2c20  T.stack((xyz[:, 
-00005ac0: 325d 202d 2073 656c 662e 6478 6479 647a  2] - self.dxdydz
-00005ad0: 5b32 5d20 2f20 6c65 7665 6c20 2f20 342c  [2] / level / 4,
-00005ae0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00005af0: 2020 2020 2020 2020 2020 2020 2020 2078                 x
-00005b00: 797a 5b3a 2c20 325d 202b 2073 656c 662e  yz[:, 2] + self.
-00005b10: 6478 6479 647a 5b32 5d20 2f20 6c65 7665  dxdydz[2] / leve
-00005b20: 6c20 2f20 3429 2c20 6178 6973 3d31 292c  l / 4), axis=1),
-00005b30: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00005b40: 2020 2020 2020 2831 2c20 3429 290d 0a0d        (1, 4))...
-00005b50: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00005b60: 542e 7374 6163 6b28 2878 5f2e 7261 7665  T.stack((x_.rave
-00005b70: 6c28 292c 2079 5f2e 7261 7665 6c28 292c  l(), y_.ravel(),
-00005b80: 207a 5f2e 7261 7665 6c28 2929 292e 540d   z_.ravel())).T.
-00005b90: 0a0d 0a20 2020 2064 6566 2063 7265 6174  ...    def creat
-00005ba0: 655f 6f63 745f 6c65 7665 6c5f 6465 6e73  e_oct_level_dens
-00005bb0: 6528 7365 6c66 2c20 756e 6971 7565 5f76  e(self, unique_v
-00005bc0: 616c 2c20 6772 6964 293a 0d0a 0d0a 2020  al, grid):....  
-00005bd0: 2020 2020 2020 7576 5f33 6420 3d20 542e        uv_3d = T.
-00005be0: 6361 7374 2854 2e72 6f75 6e64 2875 6e69  cast(T.round(uni
-00005bf0: 7175 655f 7661 6c5b 302c 203a 542e 7072  que_val[0, :T.pr
-00005c00: 6f64 2873 656c 662e 7265 6775 6c61 725f  od(self.regular_
-00005c10: 6772 6964 5f72 6573 295d 2e72 6573 6861  grid_res)].resha
-00005c20: 7065 280d 0a20 2020 2020 2020 2020 2020  pe(..           
-00005c30: 2073 656c 662e 7265 6775 6c61 725f 6772   self.regular_gr
-00005c40: 6964 5f72 6573 2c20 6e64 696d 3d33 2929  id_res, ndim=3))
-00005c50: 2c0d 0a20 2020 2020 2020 2020 2020 2027  ,..            '
-00005c60: 696e 7433 3227 290d 0a0d 0a20 2020 2020  int32')....     
-00005c70: 2020 206e 6577 5f73 6861 7065 203d 2054     new_shape = T
-00005c80: 2e63 6f6e 6361 7465 6e61 7465 285b 7365  .concatenate([se
-00005c90: 6c66 2e72 6567 756c 6172 5f67 7269 645f  lf.regular_grid_
-00005ca0: 7265 732c 2054 2e73 7461 636b 285b 335d  res, T.stack([3]
-00005cb0: 295d 290d 0a20 2020 2020 2020 2078 797a  )])..        xyz
-00005cc0: 203d 2067 7269 645b 3a54 2e70 726f 6428   = grid[:T.prod(
-00005cd0: 7365 6c66 2e72 6567 756c 6172 5f67 7269  self.regular_gri
-00005ce0: 645f 7265 7329 5d2e 7265 7368 6170 6528  d_res)].reshape(
-00005cf0: 6e65 775f 7368 6170 652c 206e 6469 6d3d  new_shape, ndim=
-00005d00: 3429 0d0a 0d0a 2020 2020 2020 2020 7368  4)....        sh
-00005d10: 6966 745f 7820 3d20 7576 5f33 645b 313a  ift_x = uv_3d[1:
-00005d20: 2c20 3a2c 203a 5d20 2d20 7576 5f33 645b  , :, :] - uv_3d[
-00005d30: 3a2d 312c 203a 2c20 3a5d 0d0a 2020 2020  :-1, :, :]..    
-00005d40: 2020 2020 7368 6966 745f 785f 7365 6c65      shift_x_sele
-00005d50: 6374 203d 2054 2e6e 6571 2873 6869 6674  ct = T.neq(shift
-00005d60: 5f78 2c20 3029 0d0a 2020 2020 2020 2020  _x, 0)..        
-00005d70: 785f 6564 6720 3d20 2878 797a 5b3a 2d31  x_edg = (xyz[:-1
-00005d80: 2c20 3a2c 203a 5d5b 7368 6966 745f 785f  , :, :][shift_x_
-00005d90: 7365 6c65 6374 5d20 2b20 7879 7a5b 313a  select] + xyz[1:
-00005da0: 2c20 3a2c 203a 5d5b 7368 6966 745f 785f  , :, :][shift_x_
-00005db0: 7365 6c65 6374 5d29 202f 2032 0d0a 0d0a  select]) / 2....
-00005dc0: 2020 2020 2020 2020 7368 6966 745f 7920          shift_y 
-00005dd0: 3d20 7576 5f33 645b 3a2c 2031 3a2c 203a  = uv_3d[:, 1:, :
-00005de0: 5d20 2d20 7576 5f33 645b 3a2c 203a 2d31  ] - uv_3d[:, :-1
-00005df0: 2c20 3a5d 0d0a 2020 2020 2020 2020 7368  , :]..        sh
-00005e00: 6966 745f 795f 7365 6c65 6374 203d 2054  ift_y_select = T
-00005e10: 2e6e 6571 2873 6869 6674 5f79 2c20 3029  .neq(shift_y, 0)
-00005e20: 0d0a 2020 2020 2020 2020 795f 6564 6720  ..        y_edg 
-00005e30: 3d20 2878 797a 5b3a 2c20 3a2d 312c 203a  = (xyz[:, :-1, :
-00005e40: 5d5b 7368 6966 745f 795f 7365 6c65 6374  ][shift_y_select
-00005e50: 5d20 2b20 7879 7a5b 3a2c 2031 3a2c 203a  ] + xyz[:, 1:, :
-00005e60: 5d5b 7368 6966 745f 795f 7365 6c65 6374  ][shift_y_select
-00005e70: 5d29 202f 2032 0d0a 0d0a 2020 2020 2020  ]) / 2....      
-00005e80: 2020 7368 6966 745f 7a20 3d20 7576 5f33    shift_z = uv_3
-00005e90: 645b 3a2c 203a 2c20 313a 5d20 2d20 7576  d[:, :, 1:] - uv
-00005ea0: 5f33 645b 3a2c 203a 2c20 3a2d 315d 0d0a  _3d[:, :, :-1]..
-00005eb0: 2020 2020 2020 2020 7368 6966 745f 7a5f          shift_z_
-00005ec0: 7365 6c65 6374 203d 2054 2e6e 6571 2873  select = T.neq(s
-00005ed0: 6869 6674 5f7a 2c20 3029 0d0a 2020 2020  hift_z, 0)..    
-00005ee0: 2020 2020 7a5f 6564 6720 3d20 2878 797a      z_edg = (xyz
-00005ef0: 5b3a 2c20 3a2c 203a 2d31 5d5b 7368 6966  [:, :, :-1][shif
-00005f00: 745f 7a5f 7365 6c65 6374 5d20 2b20 7879  t_z_select] + xy
-00005f10: 7a5b 3a2c 203a 2c20 313a 5d5b 7368 6966  z[:, :, 1:][shif
-00005f20: 745f 7a5f 7365 6c65 6374 5d29 202f 2032  t_z_select]) / 2
-00005f30: 0d0a 2020 2020 2020 2020 6e65 775f 7879  ..        new_xy
-00005f40: 7a5f 6564 6720 3d20 542e 7665 7274 6963  z_edg = T.vertic
-00005f50: 616c 5f73 7461 636b 2878 5f65 6467 2c20  al_stack(x_edg, 
-00005f60: 795f 6564 672c 207a 5f65 6467 290d 0a0d  y_edg, z_edg)...
-00005f70: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00005f80: 7365 6c66 2e63 7265 6174 655f 6f63 745f  self.create_oct_
-00005f90: 766f 7865 6c73 286e 6577 5f78 797a 5f65  voxels(new_xyz_e
-00005fa0: 6467 290d 0a0d 0a20 2020 2064 6566 2063  dg)....    def c
-00005fb0: 7265 6174 655f 6f63 745f 6c65 7665 6c5f  reate_oct_level_
-00005fc0: 7370 6172 7365 2873 656c 662c 2075 6e69  sparse(self, uni
-00005fd0: 7175 655f 7661 6c2c 2067 7269 6429 3a0d  que_val, grid):.
-00005fe0: 0a20 2020 2020 2020 2078 797a 5f38 203d  .        xyz_8 =
-00005ff0: 2067 7269 642e 7265 7368 6170 6528 282d   grid.reshape((-
-00006000: 312c 2038 2c20 3329 290d 0a20 2020 2020  1, 8, 3))..     
-00006010: 2020 2023 2075 765f 3820 3d20 542e 726f     # uv_8 = T.ro
-00006020: 756e 6428 756e 6971 7565 5f76 616c 5b30  und(unique_val[0
-00006030: 2c20 3a2d 3220 2a20 7365 6c66 2e6c 656e  , :-2 * self.len
-00006040: 5f70 6f69 6e74 735d 2e72 6573 6861 7065  _points].reshape
-00006050: 2828 2d31 2c20 3829 2929 0d0a 0d0a 2020  ((-1, 8)))....  
-00006060: 2020 2020 2020 7576 5f38 203d 2054 2e72        uv_8 = T.r
-00006070: 6f75 6e64 2875 6e69 7175 655f 7661 6c5b  ound(unique_val[
-00006080: 302c 203a 5d2e 7265 7368 6170 6528 282d  0, :].reshape((-
-00006090: 312c 2038 2929 290d 0a0d 0a20 2020 2020  1, 8)))....     
-000060a0: 2020 2073 6869 6674 5f78 203d 2075 765f     shift_x = uv_
-000060b0: 385b 3a2c 203a 345d 202d 2075 765f 385b  8[:, :4] - uv_8[
-000060c0: 3a2c 2034 3a5d 0d0a 2020 2020 2020 2020  :, 4:]..        
-000060d0: 7368 6966 745f 785f 7365 6c65 6374 203d  shift_x_select =
-000060e0: 2054 2e6e 6571 2873 6869 6674 5f78 2c20   T.neq(shift_x, 
-000060f0: 3029 0d0a 2020 2020 2020 2020 785f 6564  0)..        x_ed
-00006100: 6720 3d20 2878 797a 5f38 5b3a 2c20 3a34  g = (xyz_8[:, :4
-00006110: 2c20 3a5d 5b73 6869 6674 5f78 5f73 656c  , :][shift_x_sel
-00006120: 6563 745d 202b 2078 797a 5f38 5b3a 2c20  ect] + xyz_8[:, 
-00006130: 343a 2c20 3a5d 5b0d 0a20 2020 2020 2020  4:, :][..       
-00006140: 2020 2020 2073 6869 6674 5f78 5f73 656c       shift_x_sel
-00006150: 6563 745d 2920 2f20 320d 0a0d 0a20 2020  ect]) / 2....   
-00006160: 2020 2020 2073 6869 6674 5f79 203d 2075       shift_y = u
-00006170: 765f 385b 3a2c 205b 302c 2031 2c20 342c  v_8[:, [0, 1, 4,
-00006180: 2035 5d5d 202d 2075 765f 385b 3a2c 205b   5]] - uv_8[:, [
-00006190: 322c 2033 2c20 362c 2037 5d5d 0d0a 2020  2, 3, 6, 7]]..  
-000061a0: 2020 2020 2020 7368 6966 745f 795f 7365        shift_y_se
-000061b0: 6c65 6374 203d 2054 2e6e 6571 2873 6869  lect = T.neq(shi
-000061c0: 6674 5f79 2c20 3029 0d0a 2020 2020 2020  ft_y, 0)..      
-000061d0: 2020 795f 6564 6720 3d20 2878 797a 5f38    y_edg = (xyz_8
-000061e0: 5b3a 2c20 5b30 2c20 312c 2034 2c20 355d  [:, [0, 1, 4, 5]
-000061f0: 2c20 3a5d 5b73 6869 6674 5f79 5f73 656c  , :][shift_y_sel
-00006200: 6563 745d 202b 0d0a 2020 2020 2020 2020  ect] +..        
-00006210: 2020 2020 2020 2020 2078 797a 5f38 5b3a           xyz_8[:
-00006220: 2c20 5b32 2c20 332c 2036 2c20 375d 2c20  , [2, 3, 6, 7], 
-00006230: 3a5d 5b73 6869 6674 5f79 5f73 656c 6563  :][shift_y_selec
-00006240: 745d 2920 2f20 320d 0a0d 0a20 2020 2020  t]) / 2....     
-00006250: 2020 2073 6869 6674 5f7a 203d 2075 765f     shift_z = uv_
-00006260: 385b 3a2c 203a 3a32 5d20 2d20 7576 5f38  8[:, ::2] - uv_8
-00006270: 5b3a 2c20 313a 3a32 5d0d 0a20 2020 2020  [:, 1::2]..     
-00006280: 2020 2073 6869 6674 5f7a 5f73 656c 6563     shift_z_selec
-00006290: 7420 3d20 542e 6e65 7128 7368 6966 745f  t = T.neq(shift_
-000062a0: 7a2c 2030 290d 0a20 2020 2020 2020 207a  z, 0)..        z
-000062b0: 5f65 6467 203d 2028 7879 7a5f 385b 3a2c  _edg = (xyz_8[:,
-000062c0: 203a 3a32 2c20 3a5d 5b73 6869 6674 5f7a   ::2, :][shift_z
-000062d0: 5f73 656c 6563 745d 202b 2078 797a 5f38  _select] + xyz_8
-000062e0: 5b3a 2c20 313a 3a32 2c20 3a5d 5b0d 0a20  [:, 1::2, :][.. 
-000062f0: 2020 2020 2020 2020 2020 2073 6869 6674             shift
-00006300: 5f7a 5f73 656c 6563 745d 2920 2f20 320d  _z_select]) / 2.
-00006310: 0a0d 0a20 2020 2020 2020 206e 6577 5f78  ...        new_x
-00006320: 797a 5f65 6467 203d 2054 2e76 6572 7469  yz_edg = T.verti
-00006330: 6361 6c5f 7374 6163 6b28 785f 6564 672c  cal_stack(x_edg,
-00006340: 2079 5f65 6467 2c20 7a5f 6564 6729 0d0a   y_edg, z_edg)..
-00006350: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-00006360: 656c 662e 6372 6561 7465 5f6f 6374 5f76  elf.create_oct_v
-00006370: 6f78 656c 7328 6e65 775f 7879 7a5f 6564  oxels(new_xyz_ed
-00006380: 672c 206c 6576 656c 3d32 290d 0a0d 0a20  g, level=2).... 
-00006390: 2020 2064 6566 2063 6f6d 7075 7465 5f73     def compute_s
-000063a0: 6572 6965 735f 6f63 7428 7365 6c66 2c20  eries_oct(self, 
-000063b0: 6e5f 6c65 7665 6c73 3d33 293a 0d0a 2020  n_levels=3):..  
-000063c0: 2020 2020 2020 2320 7365 6c66 2e73 6869        # self.shi
-000063d0: 6674 203d 2030 0d0a 0d0a 2020 2020 2020  ft = 0....      
-000063e0: 2020 736f 6c75 7469 6f6e 7320 3d20 7365    solutions = se
-000063f0: 6c66 2e63 6f6d 7075 7465 5f73 6572 6965  lf.compute_serie
-00006400: 7328 7365 6c66 2e67 7269 645f 7661 6c5f  s(self.grid_val_
-00006410: 5429 0d0a 2020 2020 2020 2020 756e 6971  T)..        uniq
-00006420: 7565 5f76 616c 203d 2073 6f6c 7574 696f  ue_val = solutio
-00006430: 6e73 5b30 5d20 2b20 7365 6c66 2e6d 6178  ns[0] + self.max
-00006440: 5f6c 6974 6820 2a20 736f 6c75 7469 6f6e  _lith * solution
-00006450: 735b 325d 0d0a 0d0a 2020 2020 2020 2020  s[2]....        
-00006460: 2320 2320 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  # # ------------
-00006470: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00006480: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00006490: 2d2d 2d2d 2d2d 2d2d 2d2d 0d0a 2020 2020  ----------..    
-000064a0: 2020 2020 7368 6966 7420 3d20 7365 6c66      shift = self
-000064b0: 2e67 7269 645f 7661 6c5f 542e 7368 6170  .grid_val_T.shap
-000064c0: 655b 305d 202b 2073 656c 662e 7368 6966  e[0] + self.shif
-000064d0: 740d 0a0d 0a20 2020 2020 2020 2067 203d  t....        g =
-000064e0: 2073 656c 662e 6372 6561 7465 5f6f 6374   self.create_oct
-000064f0: 5f6c 6576 656c 5f64 656e 7365 2873 6f6c  _level_dense(sol
-00006500: 7574 696f 6e73 5b30 5d2c 2073 656c 662e  utions[0], self.
-00006510: 6772 6964 5f76 616c 5f54 290d 0a0d 0a20  grid_val_T).... 
-00006520: 2020 2020 2020 2023 2049 206e 6565 6420         # I need 
-00006530: 746f 2069 6e69 7420 7468 6520 736f 6c75  to init the solu
-00006540: 7469 6f6e 206d 6174 7269 6365 730d 0a20  tion matrices.. 
-00006550: 2020 2020 2020 206f 6374 5f73 6f6c 203d         oct_sol =
-00006560: 2073 656c 662e 636f 6d70 7574 655f 7365   self.compute_se
-00006570: 7269 6573 2867 2c20 7368 6966 7429 0d0a  ries(g, shift)..
-00006580: 0d0a 2020 2020 2020 2020 736f 6c75 7469  ..        soluti
-00006590: 6f6e 732e 6170 7065 6e64 2867 290d 0a20  ons.append(g).. 
-000065a0: 2020 2020 2020 2073 6f6c 7574 696f 6e73         solutions
-000065b0: 2e61 7070 656e 6428 6f63 745f 736f 6c5b  .append(oct_sol[
-000065c0: 305d 290d 0a0d 0a20 2020 2020 2020 2023  0])....        #
-000065d0: 202d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d   ---------------
-000065e0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-000065f0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00006600: 2d2d 2d2d 2d2d 0d0a 2020 2020 2020 2020  ------..        
-00006610: 756e 6971 7565 5f76 616c 203d 206f 6374  unique_val = oct
-00006620: 5f73 6f6c 5b30 5d20 2b20 7365 6c66 2e6d  _sol[0] + self.m
-00006630: 6178 5f6c 6974 6820 2a20 6f63 745f 736f  ax_lith * oct_so
-00006640: 6c5b 325d 0d0a 0d0a 2020 2020 2020 2020  l[2]....        
-00006650: 6731 203d 2073 656c 662e 6372 6561 7465  g1 = self.create
-00006660: 5f6f 6374 5f6c 6576 656c 5f73 7061 7273  _oct_level_spars
-00006670: 6528 756e 6971 7565 5f76 616c 5b3a 2c20  e(unique_val[:, 
-00006680: 7368 6966 743a 2067 2e73 6861 7065 5b30  shift: g.shape[0
-00006690: 5d20 2b20 7368 6966 745d 2c0d 0a20 2020  ] + shift],..   
-000066a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000066b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000066c0: 2020 2020 2020 2067 290d 0a20 2020 2020         g)..     
-000066d0: 2020 2073 6869 6674 3220 3d20 672e 7368     shift2 = g.sh
-000066e0: 6170 655b 305d 202b 2073 6869 6674 0d0a  ape[0] + shift..
-000066f0: 0d0a 2020 2020 2020 2020 6f63 745f 736f  ..        oct_so
-00006700: 6c5f 3220 3d20 7365 6c66 2e63 6f6d 7075  l_2 = self.compu
-00006710: 7465 5f73 6572 6965 7328 6731 2c20 7368  te_series(g1, sh
-00006720: 6966 7432 290d 0a0d 0a20 2020 2020 2020  ift2)....       
-00006730: 2073 6f6c 7574 696f 6e73 2e61 7070 656e   solutions.appen
-00006740: 6428 6731 290d 0a20 2020 2020 2020 2073  d(g1)..        s
-00006750: 6f6c 7574 696f 6e73 2e61 7070 656e 6428  olutions.append(
-00006760: 6f63 745f 736f 6c5f 325b 305d 290d 0a0d  oct_sol_2[0])...
-00006770: 0a20 2020 2020 2020 2073 656c 662e 6e65  .        self.ne
-00006780: 775f 626c 6f63 6b20 3d20 7365 6c66 2e62  w_block = self.b
-00006790: 6c6f 636b 5f6f 700d 0a20 2020 2020 2020  lock_op..       
-000067a0: 2073 656c 662e 6e65 775f 7765 6967 6874   self.new_weight
-000067b0: 7320 3d20 7365 6c66 2e77 6569 6768 7473  s = self.weights
-000067c0: 5f6f 700d 0a20 2020 2020 2020 2073 656c  _op..        sel
-000067d0: 662e 6e65 775f 7363 616c 6172 203d 2073  f.new_scalar = s
-000067e0: 656c 662e 7363 616c 6172 5f6f 700d 0a20  elf.scalar_op.. 
-000067f0: 2020 2020 2020 2073 656c 662e 6e65 775f         self.new_
-00006800: 7366 6169 203d 2073 656c 662e 7366 6169  sfai = self.sfai
-00006810: 5f6f 700d 0a20 2020 2020 2020 2073 656c  _op..        sel
-00006820: 662e 6e65 775f 6d61 736b 203d 2073 656c  f.new_mask = sel
-00006830: 662e 6d61 736b 5f6f 7032 0d0a 0d0a 2020  f.mask_op2....  
-00006840: 2020 2020 2020 7265 7475 726e 2073 6f6c        return sol
-00006850: 7574 696f 6e73 0d0a 0d0a 2020 2020 6465  utions....    de
-00006860: 6620 7468 6561 6e6f 5f6f 7574 7075 7428  f theano_output(
-00006870: 7365 6c66 293a 0d0a 2020 2020 2020 2020  self):..        
-00006880: 2320 4372 6561 7465 2074 6865 2073 6f6c  # Create the sol
-00006890: 7574 696f 6e73 206f 700d 0a20 2020 2020  utions op..     
-000068a0: 2020 2073 656c 662e 626c 6f63 6b5f 6f70     self.block_op
-000068b0: 203d 2073 656c 662e 626c 6f63 6b5f 6d61   = self.block_ma
-000068c0: 7472 6978 0d0a 2020 2020 2020 2020 7365  trix..        se
-000068d0: 6c66 2e77 6569 6768 7473 5f6f 7020 3d20  lf.weights_op = 
-000068e0: 7365 6c66 2e77 6569 6768 7473 5f76 6563  self.weights_vec
-000068f0: 746f 720d 0a20 2020 2020 2020 2073 656c  tor..        sel
-00006900: 662e 7363 616c 6172 5f6f 7020 3d20 7365  f.scalar_op = se
-00006910: 6c66 2e73 6361 6c61 725f 6669 656c 6473  lf.scalar_fields
-00006920: 5f6d 6174 7269 780d 0a20 2020 2020 2020  _matrix..       
-00006930: 2073 656c 662e 6d61 736b 5f6f 7032 203d   self.mask_op2 =
-00006940: 2073 656c 662e 6d61 736b 5f6d 6174 7269   self.mask_matri
-00006950: 780d 0a20 2020 2020 2020 2073 656c 662e  x..        self.
-00006960: 7366 6169 5f6f 7020 3d20 7365 6c66 2e73  sfai_op = self.s
-00006970: 6661 690d 0a0d 0a20 2020 2020 2020 2073  fai....        s
-00006980: 6f6c 7574 696f 6e73 203d 205b 7468 6561  olutions = [thea
-00006990: 6e6f 2e73 6861 7265 6428 6e70 2e6e 616e  no.shared(np.nan
-000069a0: 295d 202a 2031 350d 0a20 2020 2020 2020  )] * 15..       
-000069b0: 2073 6f6c 7574 696f 6e73 5b30 5d20 3d20   solutions[0] = 
-000069c0: 7468 6561 6e6f 2e73 6861 7265 6428 6e70  theano.shared(np
-000069d0: 2e7a 6572 6f73 2828 322c 2032 2929 290d  .zeros((2, 2))).
-000069e0: 0a20 2020 2020 2020 2023 2073 656c 662e  .        # self.
-000069f0: 636f 6d70 7574 655f 7479 7065 203d 205b  compute_type = [
-00006a00: 276c 6974 686f 6c6f 6779 272c 2027 746f  'lithology', 'to
-00006a10: 706f 6c6f 6779 275d 0d0a 2020 2020 2020  pology']..      
-00006a20: 2020 6966 2027 6765 6f6c 6f67 7927 2069    if 'geology' i
+000043a0: 2020 2020 2020 2020 2027 6964 656e 7469           'identi
+000043b0: 6669 6572 7327 290d 0a0d 0a20 2020 2020  fiers')....     
+000043c0: 2020 2020 2020 2073 656c 662e 7265 6775         self.regu
+000043d0: 6c61 725f 6772 6964 5f72 6573 203d 2061  lar_grid_res = a
+000043e0: 6573 6172 612e 7368 6172 6564 286e 702e  esara.shared(np.
+000043f0: 6f6e 6573 2833 2c20 6474 7970 653d 2769  ones(3, dtype='i
+00004400: 6e74 2729 2c0d 0a20 2020 2020 2020 2020  nt'),..         
+00004410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004420: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004430: 2020 2020 2020 2020 2027 5265 736f 6c75           'Resolu
+00004440: 7469 6f6e 206f 6620 7468 6520 7265 6775  tion of the regu
+00004450: 6c61 7220 6772 6964 2729 0d0a 2020 2020  lar grid')..    
+00004460: 2020 2020 2020 2020 7365 6c66 2e64 7864          self.dxd
+00004470: 7964 7a20 3d20 6165 7361 7261 2e73 6861  ydz = aesara.sha
+00004480: 7265 6428 6e70 2e6f 6e65 7328 332c 2064  red(np.ones(3, d
+00004490: 7479 7065 3d64 7479 7065 292c 0d0a 2020  type=dtype),..  
+000044a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000044b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000044c0: 2020 2020 2020 2753 697a 6520 6f66 2074        'Size of t
+000044d0: 6865 2076 6f78 656c 7320 696e 2065 6163  he voxels in eac
+000044e0: 6820 6469 7265 6374 696f 6e2e 2729 0d0a  h direction.')..
+000044f0: 0d0a 2020 2020 2020 2020 2320 5265 7375  ..        # Resu
+00004500: 6c74 7320 6d61 7472 6978 0d0a 2020 2020  lts matrix..    
+00004510: 2020 2020 7365 6c66 2e77 6569 6768 7473      self.weights
+00004520: 5f76 6563 746f 7220 3d20 6165 7361 7261  _vector = aesara
+00004530: 2e73 6861 7265 6428 6e70 2e63 6173 745b  .shared(np.cast[
+00004540: 6474 7970 655d 286e 702e 7a65 726f 7328  dtype](np.zeros(
+00004550: 3130 3030 3029 292c 0d0a 2020 2020 2020  10000)),..      
+00004560: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004580: 2020 2020 2020 2757 6569 6768 7473 2076        'Weights v
+00004590: 6563 746f 7227 290d 0a20 2020 2020 2020  ector')..       
+000045a0: 2073 656c 662e 7363 616c 6172 5f66 6965   self.scalar_fie
+000045b0: 6c64 735f 6d61 7472 6978 203d 2061 6573  lds_matrix = aes
+000045c0: 6172 612e 7368 6172 6564 280d 0a20 2020  ara.shared(..   
+000045d0: 2020 2020 2020 2020 206e 702e 6361 7374           np.cast
+000045e0: 5b64 7479 7065 5d28 6e70 2e7a 6572 6f73  [dtype](np.zeros
+000045f0: 2828 332c 2031 3030 3030 2929 292c 2027  ((3, 10000))), '
+00004600: 5363 616c 6172 206d 6174 7269 7827 290d  Scalar matrix').
+00004610: 0a20 2020 2020 2020 2073 656c 662e 626c  .        self.bl
+00004620: 6f63 6b5f 6d61 7472 6978 203d 2061 6573  ock_matrix = aes
+00004630: 6172 612e 7368 6172 6564 286e 702e 6361  ara.shared(np.ca
+00004640: 7374 5b64 7479 7065 5d28 6e70 2e7a 6572  st[dtype](np.zer
+00004650: 6f73 2828 332c 2033 2c20 3130 3030 3029  os((3, 3, 10000)
+00004660: 2929 2c0d 0a20 2020 2020 2020 2020 2020  )),..           
+00004670: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004680: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00004690: 626c 6f63 6b20 6d61 7472 6978 2229 0d0a  block matrix")..
+000046a0: 2020 2020 2020 2020 7365 6c66 2e6d 6173          self.mas
+000046b0: 6b5f 6d61 7472 6978 203d 2061 6573 6172  k_matrix = aesar
+000046c0: 612e 7368 6172 6564 286e 702e 7a65 726f  a.shared(np.zero
+000046d0: 7328 2833 2c20 3130 3030 3029 2c20 6474  s((3, 10000), dt
+000046e0: 7970 653d 2762 6f6f 6c27 292c 0d0a 2020  ype='bool'),..  
+000046f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004700: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004710: 2020 2020 2020 2022 6d61 736b 206d 6174         "mask mat
+00004720: 7269 7822 290d 0a20 2020 2020 2020 2073  rix")..        s
+00004730: 656c 662e 7366 6169 203d 2054 2e7a 6572  elf.sfai = T.zer
+00004740: 6f73 280d 0a20 2020 2020 2020 2020 2020  os(..           
+00004750: 205b 7365 6c66 2e69 735f 6572 6f73 696f   [self.is_erosio
+00004760: 6e2e 7368 6170 655b 305d 2c20 7365 6c66  n.shape[0], self
+00004770: 2e6e 5f73 7572 6661 6365 735f 7065 725f  .n_surfaces_per_
+00004780: 7365 7269 6573 5b2d 315d 5d29 0d0a 0d0a  series[-1]])....
+00004790: 2020 2020 2020 2020 7365 6c66 2e6e 6577          self.new
+000047a0: 5f62 6c6f 636b 203d 2073 656c 662e 626c  _block = self.bl
+000047b0: 6f63 6b5f 6d61 7472 6978 0d0a 2020 2020  ock_matrix..    
+000047c0: 2020 2020 7365 6c66 2e6e 6577 5f77 6569      self.new_wei
+000047d0: 6768 7473 203d 2073 656c 662e 7765 6967  ghts = self.weig
+000047e0: 6874 735f 7665 6374 6f72 0d0a 2020 2020  hts_vector..    
+000047f0: 2020 2020 7365 6c66 2e6e 6577 5f73 6361      self.new_sca
+00004800: 6c61 7220 3d20 7365 6c66 2e73 6361 6c61  lar = self.scala
+00004810: 725f 6669 656c 6473 5f6d 6174 7269 780d  r_fields_matrix.
+00004820: 0a20 2020 2020 2020 2073 656c 662e 6e65  .        self.ne
+00004830: 775f 6d61 736b 203d 2073 656c 662e 6d61  w_mask = self.ma
+00004840: 736b 5f6d 6174 7269 780d 0a20 2020 2020  sk_matrix..     
+00004850: 2020 2073 656c 662e 6e65 775f 7366 6169     self.new_sfai
+00004860: 203d 2073 656c 662e 7366 6169 0d0a 0d0a   = self.sfai....
+00004870: 2020 2020 6465 6620 636f 6d70 7574 655f      def compute_
+00004880: 7765 6967 6874 7328 7365 6c66 293a 0d0a  weights(self):..
+00004890: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+000048a0: 656c 662e 736f 6c76 655f 6b72 6967 696e  elf.solve_krigin
+000048b0: 6728 290d 0a0d 0a20 2020 2064 6566 2063  g()....    def c
+000048c0: 6f6d 7075 7465 5f73 6361 6c61 725f 6669  ompute_scalar_fi
+000048d0: 656c 6428 7365 6c66 2c20 7765 6967 6874  eld(self, weight
+000048e0: 732c 2067 7269 642c 2066 6175 6c74 5f6d  s, grid, fault_m
+000048f0: 6174 7269 7829 3a0d 0a20 2020 2020 2020  atrix):..       
+00004900: 2067 7269 645f 7661 6c20 3d20 7365 6c66   grid_val = self
+00004910: 2e78 5f74 6f5f 696e 7465 7270 6f6c 6174  .x_to_interpolat
+00004920: 6528 6772 6964 290d 0a20 2020 2020 2020  e(grid)..       
+00004930: 2072 6574 7572 6e20 7365 6c66 2e73 6361   return self.sca
+00004940: 6c61 725f 6669 656c 645f 6174 5f61 6c6c  lar_field_at_all
+00004950: 2877 6569 6768 7473 2c20 6772 6964 5f76  (weights, grid_v
+00004960: 616c 2c20 6661 756c 745f 6d61 7472 6978  al, fault_matrix
+00004970: 290d 0a0d 0a20 2020 2064 6566 2063 6f6d  )....    def com
+00004980: 7075 7465 5f66 6f72 6d61 7469 6f6e 5f62  pute_formation_b
+00004990: 6c6f 636b 2873 656c 662c 205a 5f78 2c20  lock(self, Z_x, 
+000049a0: 7363 616c 6172 5f66 6965 6c64 5f61 745f  scalar_field_at_
+000049b0: 7375 7266 6163 655f 706f 696e 7473 2c20  surface_points, 
+000049c0: 7661 6c75 6573 293a 0d0a 2020 2020 2020  values):..      
+000049d0: 2020 7265 7475 726e 2073 656c 662e 6578    return self.ex
+000049e0: 706f 7274 5f66 6f72 6d61 7469 6f6e 5f62  port_formation_b
+000049f0: 6c6f 636b 285a 5f78 2c20 7363 616c 6172  lock(Z_x, scalar
+00004a00: 5f66 6965 6c64 5f61 745f 7375 7266 6163  _field_at_surfac
+00004a10: 655f 706f 696e 7473 2c0d 0a20 2020 2020  e_points,..     
+00004a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004a30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004a40: 2020 2020 2020 7661 6c75 6573 290d 0a0d        values)...
+00004a50: 0a20 2020 2064 6566 2063 6f6d 7075 7465  .    def compute
+00004a60: 5f66 6175 6c74 5f62 6c6f 636b 2873 656c  _fault_block(sel
+00004a70: 662c 205a 5f78 2c20 7363 616c 6172 5f66  f, Z_x, scalar_f
+00004a80: 6965 6c64 5f61 745f 7375 7266 6163 655f  ield_at_surface_
+00004a90: 706f 696e 7473 2c20 7661 6c75 6573 2c0d  points, values,.
+00004aa0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00004ab0: 2020 2020 2020 2020 2020 2020 206e 5f73               n_s
+00004ac0: 6572 6965 732c 2067 7269 6429 3a0d 0a20  eries, grid):.. 
+00004ad0: 2020 2020 2020 2067 7269 645f 7661 6c20         grid_val 
+00004ae0: 3d20 7365 6c66 2e78 5f74 6f5f 696e 7465  = self.x_to_inte
+00004af0: 7270 6f6c 6174 6528 6772 6964 290d 0a20  rpolate(grid).. 
+00004b00: 2020 2020 2020 2066 696e 6974 655f 6661         finite_fa
+00004b10: 756c 7473 5f65 6c6c 6970 7365 203d 2073  ults_ellipse = s
+00004b20: 656c 662e 7365 6c65 6374 5f66 696e 6974  elf.select_finit
+00004b30: 655f 6661 756c 7473 2867 7269 645f 7661  e_faults(grid_va
+00004b40: 6c29 0d0a 2020 2020 2020 2020 7265 7475  l)..        retu
+00004b50: 726e 2073 656c 662e 6578 706f 7274 5f66  rn self.export_f
+00004b60: 6175 6c74 5f62 6c6f 636b 285a 5f78 2c20  ault_block(Z_x, 
+00004b70: 7363 616c 6172 5f66 6965 6c64 5f61 745f  scalar_field_at_
+00004b80: 7375 7266 6163 655f 706f 696e 7473 2c20  surface_points, 
+00004b90: 7661 6c75 6573 2c0d 0a20 2020 2020 2020  values,..       
+00004ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004bc0: 6669 6e69 7465 5f66 6175 6c74 735f 656c  finite_faults_el
+00004bd0: 6c69 7073 6529 0d0a 0d0a 2020 2020 6465  lipse)....    de
+00004be0: 6620 636f 6d70 7574 655f 6669 6e61 6c5f  f compute_final_
+00004bf0: 626c 6f63 6b28 7365 6c66 2c20 6d61 736b  block(self, mask
+00004c00: 2c20 626c 6f63 6b29 3a0d 0a0d 0a20 2020  , block):....   
+00004c10: 2020 2020 2023 2057 6520 6164 6420 7468       # We add th
+00004c20: 6520 6178 6973 2031 2074 6f20 7468 6520  e axis 1 to the 
+00004c30: 6d61 736b 2e20 4178 6973 2031 2069 7320  mask. Axis 1 is 
+00004c40: 7468 6520 7072 6f70 6572 7469 6573 2076  the properties v
+00004c50: 616c 7565 7320 6178 6973 0d0a 2020 2020  alues axis..    
+00004c60: 2020 2020 2320 5468 656e 2077 6520 7375      # Then we su
+00004c70: 6d20 6f76 6572 2074 6865 2030 2061 7869  m over the 0 axi
+00004c80: 732e 2041 7869 7320 3020 6973 2074 6865  s. Axis 0 is the
+00004c90: 2073 6572 6965 730d 0a20 2020 2020 2020   series..       
+00004ca0: 2066 696e 616c 5f6d 6f64 656c 203d 2054   final_model = T
+00004cb0: 2e73 756d 2854 2e73 7461 636b 285b 6d61  .sum(T.stack([ma
+00004cc0: 736b 5d2c 2061 7869 733d 3129 202a 2062  sk], axis=1) * b
+00004cd0: 6c6f 636b 2c20 6178 6973 3d30 290d 0a20  lock, axis=0).. 
+00004ce0: 2020 2020 2020 2072 6574 7572 6e20 6669         return fi
+00004cf0: 6e61 6c5f 6d6f 6465 6c0d 0a0d 0a20 2020  nal_model....   
+00004d00: 2064 6566 2063 6f6d 7075 7465 5f73 6572   def compute_ser
+00004d10: 6965 7328 7365 6c66 2c20 6772 6964 3d4e  ies(self, grid=N
+00004d20: 6f6e 652c 2073 6869 6674 3d4e 6f6e 6529  one, shift=None)
+00004d30: 3a0d 0a20 2020 2020 2020 2069 6620 6772  :..        if gr
+00004d40: 6964 2069 7320 4e6f 6e65 3a0d 0a20 2020  id is None:..   
+00004d50: 2020 2020 2020 2020 2067 7269 6420 3d20           grid = 
+00004d60: 7365 6c66 2e67 7269 645f 7661 6c5f 540d  self.grid_val_T.
+00004d70: 0a20 2020 2020 2020 2069 6620 7368 6966  .        if shif
+00004d80: 7420 6973 204e 6f6e 653a 0d0a 2020 2020  t is None:..    
+00004d90: 2020 2020 2020 2020 7368 6966 7420 3d20          shift = 
+00004da0: 7365 6c66 2e73 6869 6674 0d0a 0d0a 2020  self.shift....  
+00004db0: 2020 2020 2020 2320 544f 444f 2049 2068        # TODO I h
+00004dc0: 6176 6520 746f 2074 616b 6520 7468 6973  ave to take this
+00004dd0: 2066 756e 6374 696f 6e20 746f 2069 6e74   function to int
+00004de0: 6572 706f 6c61 746f 7220 616e 6420 6d61  erpolator and ma
+00004df0: 6b69 6e67 2074 6865 2062 6568 6176 696f  king the behavio
+00004e00: 7572 2074 6865 2073 616d 6520 6173 206d  ur the same as m
+00004e10: 6173 6b5f 6d61 7472 6978 0d0a 2020 2020  ask_matrix..    
+00004e20: 2020 2020 7365 6c66 2e6d 6173 6b5f 6d61      self.mask_ma
+00004e30: 7472 6978 5f66 203d 2054 2e7a 6572 6f73  trix_f = T.zeros
+00004e40: 5f6c 696b 6528 7365 6c66 2e6d 6173 6b5f  _like(self.mask_
+00004e50: 6f70 3229 0d0a 2020 2020 2020 2020 7365  op2)..        se
+00004e60: 6c66 2e66 6175 6c74 5f6d 6174 7269 7820  lf.fault_matrix 
+00004e70: 3d20 542e 7a65 726f 735f 6c69 6b65 2873  = T.zeros_like(s
+00004e80: 656c 662e 626c 6f63 6b5f 6f70 290d 0a0d  elf.block_op)...
+00004e90: 0a20 2020 2020 2020 2023 204c 6f6f 7069  .        # Loopi
+00004ea0: 6e67 0d0a 2020 2020 2020 2020 7365 7269  ng..        seri
+00004eb0: 6573 2c20 7365 6c66 2e75 7064 6174 6573  es, self.updates
+00004ec0: 3120 3d20 6165 7361 7261 2e73 6361 6e28  1 = aesara.scan(
+00004ed0: 0d0a 2020 2020 2020 2020 2020 2020 666e  ..            fn
+00004ee0: 3d73 656c 662e 636f 6d70 7574 655f 615f  =self.compute_a_
+00004ef0: 7365 7269 6573 2c0d 0a20 2020 2020 2020  series,..       
+00004f00: 2020 2020 206f 7574 7075 7473 5f69 6e66       outputs_inf
+00004f10: 6f3d 5b0d 0a20 2020 2020 2020 2020 2020  o=[..           
+00004f20: 2020 2020 2064 6963 7428 696e 6974 6961       dict(initia
+00004f30: 6c3d 7365 6c66 2e62 6c6f 636b 5f6f 7029  l=self.block_op)
+00004f40: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00004f50: 2020 2064 6963 7428 696e 6974 6961 6c3d     dict(initial=
+00004f60: 7365 6c66 2e77 6569 6768 7473 5f6f 7029  self.weights_op)
+00004f70: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00004f80: 2020 2064 6963 7428 696e 6974 6961 6c3d     dict(initial=
+00004f90: 7365 6c66 2e73 6361 6c61 725f 6f70 292c  self.scalar_op),
+00004fa0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00004fb0: 2020 6469 6374 2869 6e69 7469 616c 3d73    dict(initial=s
+00004fc0: 656c 662e 7366 6169 5f6f 7029 2c0d 0a20  elf.sfai_op),.. 
+00004fd0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+00004fe0: 6963 7428 696e 6974 6961 6c3d 7365 6c66  ict(initial=self
+00004ff0: 2e6d 6173 6b5f 6f70 3229 2c0d 0a20 2020  .mask_op2),..   
+00005000: 2020 2020 2020 2020 2020 2020 2064 6963               dic
+00005010: 7428 696e 6974 6961 6c3d 7365 6c66 2e6d  t(initial=self.m
+00005020: 6173 6b5f 6d61 7472 6978 5f66 292c 0d0a  ask_matrix_f),..
+00005030: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005040: 6469 6374 2869 6e69 7469 616c 3d73 656c  dict(initial=sel
+00005050: 662e 6661 756c 745f 6d61 7472 6978 292c  f.fault_matrix),
+00005060: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00005070: 2020 6469 6374 2869 6e69 7469 616c 3d54    dict(initial=T
+00005080: 2e63 6173 7428 302c 2027 696e 7436 3427  .cast(0, 'int64'
+00005090: 2929 0d0a 0d0a 2020 2020 2020 2020 2020  ))....          
+000050a0: 2020 5d2c 2020 2320 5468 6973 206c 696e    ],  # This lin
+000050b0: 6520 6d61 7920 6265 2075 7365 6420 666f  e may be used fo
+000050c0: 7220 7468 6520 6466 206e 6574 776f 726b  r the df network
+000050d0: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
+000050e0: 7175 656e 6365 733d 5b64 6963 7428 696e  quences=[dict(in
+000050f0: 7075 743d 7365 6c66 2e6c 656e 5f73 6572  put=self.len_ser
+00005100: 6965 735f 692c 2074 6170 733d 5b30 2c20  ies_i, taps=[0, 
+00005110: 315d 292c 0d0a 2020 2020 2020 2020 2020  1]),..          
+00005120: 2020 2020 2020 2020 2020 2020 2064 6963               dic
+00005130: 7428 696e 7075 743d 7365 6c66 2e6c 656e  t(input=self.len
+00005140: 5f73 6572 6965 735f 6f2c 2074 6170 733d  _series_o, taps=
+00005150: 5b30 2c20 315d 292c 0d0a 2020 2020 2020  [0, 1]),..      
+00005160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005170: 2064 6963 7428 696e 7075 743d 7365 6c66   dict(input=self
+00005180: 2e6c 656e 5f73 6572 6965 735f 772c 2074  .len_series_w, t
+00005190: 6170 733d 5b30 2c20 315d 292c 0d0a 2020  aps=[0, 1]),..  
+000051a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000051b0: 2020 2020 2064 6963 7428 696e 7075 743d       dict(input=
+000051c0: 7365 6c66 2e6e 5f73 7572 6661 6365 735f  self.n_surfaces_
+000051d0: 7065 725f 7365 7269 6573 2c20 7461 7073  per_series, taps
+000051e0: 3d5b 302c 2031 5d29 2c0d 0a20 2020 2020  =[0, 1]),..     
+000051f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005200: 2020 6469 6374 2869 6e70 7574 3d73 656c    dict(input=sel
+00005210: 662e 6e5f 756e 6976 6572 7361 6c5f 6571  f.n_universal_eq
+00005220: 5f54 2c20 7461 7073 3d5b 305d 292c 0d0a  _T, taps=[0]),..
+00005230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005240: 2020 2020 2020 2064 6963 7428 696e 7075         dict(inpu
+00005250: 743d 7365 6c66 2e63 6f6d 7075 7465 5f77  t=self.compute_w
+00005260: 6569 6768 7473 5f63 7472 6c2c 2074 6170  eights_ctrl, tap
+00005270: 733d 5b30 5d29 2c0d 0a20 2020 2020 2020  s=[0]),..       
+00005280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005290: 6469 6374 2869 6e70 7574 3d73 656c 662e  dict(input=self.
+000052a0: 636f 6d70 7574 655f 7363 616c 6172 5f63  compute_scalar_c
+000052b0: 7472 6c2c 2074 6170 733d 5b30 5d29 2c0d  trl, taps=[0]),.
+000052c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000052d0: 2020 2020 2020 2020 6469 6374 2869 6e70          dict(inp
+000052e0: 7574 3d73 656c 662e 636f 6d70 7574 655f  ut=self.compute_
+000052f0: 626c 6f63 6b5f 6374 726c 2c20 7461 7073  block_ctrl, taps
+00005300: 3d5b 305d 292c 0d0a 2020 2020 2020 2020  =[0]),..        
+00005310: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+00005320: 6963 7428 696e 7075 743d 7365 6c66 2e69  ict(input=self.i
+00005330: 735f 6669 6e69 7465 5f63 7472 6c2c 2074  s_finite_ctrl, t
+00005340: 6170 733d 5b30 5d29 2c0d 0a20 2020 2020  aps=[0]),..     
+00005350: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005360: 2020 6469 6374 2869 6e70 7574 3d73 656c    dict(input=sel
+00005370: 662e 6973 5f65 726f 7369 6f6e 2c20 7461  f.is_erosion, ta
+00005380: 7073 3d5b 305d 292c 0d0a 2020 2020 2020  ps=[0]),..      
+00005390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000053a0: 2064 6963 7428 696e 7075 743d 7365 6c66   dict(input=self
+000053b0: 2e69 735f 6f6e 6c61 702c 2074 6170 733d  .is_onlap, taps=
+000053c0: 5b30 5d29 2c0d 0a20 2020 2020 2020 2020  [0]),..         
+000053d0: 2020 2020 2020 2020 2020 2020 2020 6469                di
+000053e0: 6374 2869 6e70 7574 3d54 2e61 7261 6e67  ct(input=T.arang
+000053f0: 6528 302c 2035 3030 302c 2064 7479 7065  e(0, 5000, dtype
+00005400: 3d27 696e 7433 3227 292c 2074 6170 733d  ='int32'), taps=
+00005410: 5b30 5d29 2c0d 0a20 2020 2020 2020 2020  [0]),..         
+00005420: 2020 2020 2020 2020 2020 2020 2020 6469                di
+00005430: 6374 2869 6e70 7574 3d73 656c 662e 615f  ct(input=self.a_
+00005440: 542c 2074 6170 733d 5b30 5d29 2c0d 0a20  T, taps=[0]),.. 
+00005450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005460: 2020 2020 2020 6469 6374 2869 6e70 7574        dict(input
+00005470: 3d73 656c 662e 635f 6f5f 545f 7363 616c  =self.c_o_T_scal
+00005480: 6172 2c20 7461 7073 3d5b 305d 290d 0a20  ar, taps=[0]).. 
+00005490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000054a0: 2020 2020 2020 5d2c 0d0a 2020 2020 2020        ],..      
+000054b0: 2020 2020 2020 6e6f 6e5f 7365 7175 656e        non_sequen
+000054c0: 6365 733d 5b67 7269 642c 2073 6869 6674  ces=[grid, shift
+000054d0: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+000054e0: 6e61 6d65 3d27 4c6f 6f70 696e 6727 2c0d  name='Looping',.
+000054f0: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+00005500: 7572 6e5f 6c69 7374 3d54 7275 652c 0d0a  urn_list=True,..
+00005510: 2020 2020 2020 2020 2020 2020 7072 6f66              prof
+00005520: 696c 653d 4661 6c73 650d 0a20 2020 2020  ile=False..     
+00005530: 2020 2029 0d0a 0d0a 2020 2020 2020 2020     )....        
+00005540: 7365 6c66 2e62 6c6f 636b 5f6f 7020 3d20  self.block_op = 
+00005550: 7365 7269 6573 5b30 5d5b 2d31 5d0d 0a20  series[0][-1].. 
+00005560: 2020 2020 2020 2073 656c 662e 7765 6967         self.weig
+00005570: 6874 735f 6f70 203d 2073 6572 6965 735b  hts_op = series[
+00005580: 315d 5b2d 315d 0d0a 2020 2020 2020 2020  1][-1]..        
+00005590: 7365 6c66 2e73 6361 6c61 725f 6f70 203d  self.scalar_op =
+000055a0: 2073 6572 6965 735b 325d 5b2d 315d 0d0a   series[2][-1]..
+000055b0: 2020 2020 2020 2020 7365 6c66 2e73 6661          self.sfa
+000055c0: 695f 6f70 203d 2073 6572 6965 735b 335d  i_op = series[3]
+000055d0: 5b2d 315d 0d0a 0d0a 2020 2020 2020 2020  [-1]....        
+000055e0: 6d61 736b 203d 2073 6572 6965 735b 345d  mask = series[4]
+000055f0: 5b2d 315d 0d0a 2020 2020 2020 2020 6d61  [-1]..        ma
+00005600: 736b 5f72 6576 5f63 756d 7072 6f64 203d  sk_rev_cumprod =
+00005610: 2054 2e76 6572 7469 6361 6c5f 7374 6163   T.vertical_stac
+00005620: 6b28 6d61 736b 5b5b 2d31 5d5d 2c20 542e  k(mask[[-1]], T.
+00005630: 6375 6d70 726f 6428 542e 696e 7665 7274  cumprod(T.invert
+00005640: 286d 6173 6b5b 3a2d 315d 292c 2061 7869  (mask[:-1]), axi
+00005650: 733d 3029 290d 0a20 2020 2020 2020 2073  s=0))..        s
+00005660: 656c 662e 6d61 736b 5f6f 7032 203d 206d  elf.mask_op2 = m
+00005670: 6173 6b5f 7265 765f 6375 6d70 726f 640d  ask_rev_cumprod.
+00005680: 0a20 2020 2020 2020 2062 6c6f 636b 5f6d  .        block_m
+00005690: 6173 6b20 3d20 6d61 736b 202a 206d 6173  ask = mask * mas
+000056a0: 6b5f 7265 765f 6375 6d70 726f 640d 0a0d  k_rev_cumprod...
+000056b0: 0a20 2020 2020 2020 2066 6175 6c74 5f6d  .        fault_m
+000056c0: 6173 6b20 3d20 7365 7269 6573 5b35 5d5b  ask = series[5][
+000056d0: 2d31 5d0d 0a0d 0a20 2020 2020 2020 2066  -1]....        f
+000056e0: 6175 6c74 5f62 6c6f 636b 203d 2073 656c  ault_block = sel
+000056f0: 662e 636f 6d70 7574 655f 6669 6e61 6c5f  f.compute_final_
+00005700: 626c 6f63 6b28 6661 756c 745f 6d61 736b  block(fault_mask
+00005710: 2c20 7365 6c66 2e62 6c6f 636b 5f6f 7029  , self.block_op)
+00005720: 0d0a 2020 2020 2020 2020 6669 6e61 6c5f  ..        final_
+00005730: 6d6f 6465 6c20 3d20 7365 6c66 2e63 6f6d  model = self.com
+00005740: 7075 7465 5f66 696e 616c 5f62 6c6f 636b  pute_final_block
+00005750: 2862 6c6f 636b 5f6d 6173 6b2c 2073 656c  (block_mask, sel
+00005760: 662e 626c 6f63 6b5f 6f70 290d 0a0d 0a20  f.block_op).... 
+00005770: 2020 2020 2020 2072 6574 7572 6e20 5b66         return [f
+00005780: 696e 616c 5f6d 6f64 656c 2c20 7365 6c66  inal_model, self
+00005790: 2e62 6c6f 636b 5f6f 702c 2066 6175 6c74  .block_op, fault
+000057a0: 5f62 6c6f 636b 2c20 7365 6c66 2e77 6569  _block, self.wei
+000057b0: 6768 7473 5f6f 702c 0d0a 2020 2020 2020  ghts_op,..      
+000057c0: 2020 2020 2020 2020 2020 7365 6c66 2e73            self.s
+000057d0: 6361 6c61 725f 6f70 2c0d 0a20 2020 2020  calar_op,..     
+000057e0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+000057f0: 7366 6169 5f6f 702c 2062 6c6f 636b 5f6d  sfai_op, block_m
+00005800: 6173 6b2c 2066 6175 6c74 5f6d 6173 6b5d  ask, fault_mask]
+00005810: 0d0a 0d0a 2020 2020 6465 6620 6372 6561  ....    def crea
+00005820: 7465 5f6f 6374 5f76 6f78 656c 7328 7365  te_oct_voxels(se
+00005830: 6c66 2c20 7879 7a2c 206c 6576 656c 3d31  lf, xyz, level=1
+00005840: 293a 0d0a 2020 2020 2020 2020 785f 203d  ):..        x_ =
+00005850: 2054 2e72 6570 6561 7428 542e 7374 6163   T.repeat(T.stac
+00005860: 6b28 2878 797a 5b3a 2c20 305d 202d 2073  k((xyz[:, 0] - s
+00005870: 656c 662e 6478 6479 647a 5b30 5d20 2f20  elf.dxdydz[0] / 
+00005880: 6c65 7665 6c20 2f20 342c 0d0a 2020 2020  level / 4,..    
+00005890: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000058a0: 2020 2020 2020 2020 2020 2078 797a 5b3a             xyz[:
+000058b0: 2c20 305d 202b 2073 656c 662e 6478 6479  , 0] + self.dxdy
+000058c0: 647a 5b30 5d20 2f20 6c65 7665 6c20 2f20  dz[0] / level / 
+000058d0: 3429 2c20 6178 6973 3d31 292c 2034 2c0d  4), axis=1), 4,.
+000058e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000058f0: 2020 2020 2020 2061 7869 733d 3129 0d0a         axis=1)..
+00005900: 2020 2020 2020 2020 795f 203d 2054 2e74          y_ = T.t
+00005910: 696c 6528 542e 7265 7065 6174 2854 2e73  ile(T.repeat(T.s
+00005920: 7461 636b 2828 7879 7a5b 3a2c 2031 5d20  tack((xyz[:, 1] 
+00005930: 2d20 7365 6c66 2e64 7864 7964 7a5b 315d  - self.dxdydz[1]
+00005940: 202f 206c 6576 656c 202f 2034 2c0d 0a20   / level / 4,.. 
+00005950: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005970: 2020 2020 2078 797a 5b3a 2c20 315d 202b       xyz[:, 1] +
+00005980: 2073 656c 662e 6478 6479 647a 5b31 5d20   self.dxdydz[1] 
+00005990: 2f20 6c65 7665 6c20 2f20 3429 2c0d 0a20  / level / 4),.. 
+000059a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000059b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000059c0: 2020 2020 6178 6973 3d31 292c 0d0a 2020      axis=1),..  
+000059d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000059e0: 2020 2020 2020 2020 2020 2032 2c20 6178             2, ax
+000059f0: 6973 3d31 292c 2028 312c 2032 2929 0d0a  is=1), (1, 2))..
+00005a00: 0d0a 2020 2020 2020 2020 7a5f 203d 2054  ..        z_ = T
+00005a10: 2e74 696c 6528 542e 7374 6163 6b28 2878  .tile(T.stack((x
+00005a20: 797a 5b3a 2c20 325d 202d 2073 656c 662e  yz[:, 2] - self.
+00005a30: 6478 6479 647a 5b32 5d20 2f20 6c65 7665  dxdydz[2] / leve
+00005a40: 6c20 2f20 342c 0d0a 2020 2020 2020 2020  l / 4,..        
+00005a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005a60: 2020 2020 2078 797a 5b3a 2c20 325d 202b       xyz[:, 2] +
+00005a70: 2073 656c 662e 6478 6479 647a 5b32 5d20   self.dxdydz[2] 
+00005a80: 2f20 6c65 7665 6c20 2f20 3429 2c20 6178  / level / 4), ax
+00005a90: 6973 3d31 292c 0d0a 2020 2020 2020 2020  is=1),..        
+00005aa0: 2020 2020 2020 2020 2020 2020 2831 2c20              (1, 
+00005ab0: 3429 290d 0a0d 0a20 2020 2020 2020 2072  4))....        r
+00005ac0: 6574 7572 6e20 542e 7374 6163 6b28 2878  eturn T.stack((x
+00005ad0: 5f2e 7261 7665 6c28 292c 2079 5f2e 7261  _.ravel(), y_.ra
+00005ae0: 7665 6c28 292c 207a 5f2e 7261 7665 6c28  vel(), z_.ravel(
+00005af0: 2929 292e 540d 0a0d 0a20 2020 2064 6566  ))).T....    def
+00005b00: 2063 7265 6174 655f 6f63 745f 6c65 7665   create_oct_leve
+00005b10: 6c5f 6465 6e73 6528 7365 6c66 2c20 756e  l_dense(self, un
+00005b20: 6971 7565 5f76 616c 2c20 6772 6964 293a  ique_val, grid):
+00005b30: 0d0a 0d0a 2020 2020 2020 2020 7576 5f33  ....        uv_3
+00005b40: 6420 3d20 542e 6361 7374 2854 2e72 6f75  d = T.cast(T.rou
+00005b50: 6e64 2875 6e69 7175 655f 7661 6c5b 302c  nd(unique_val[0,
+00005b60: 203a 542e 7072 6f64 2873 656c 662e 7265   :T.prod(self.re
+00005b70: 6775 6c61 725f 6772 6964 5f72 6573 295d  gular_grid_res)]
+00005b80: 2e72 6573 6861 7065 280d 0a20 2020 2020  .reshape(..     
+00005b90: 2020 2020 2020 2073 656c 662e 7265 6775         self.regu
+00005ba0: 6c61 725f 6772 6964 5f72 6573 2c20 6e64  lar_grid_res, nd
+00005bb0: 696d 3d33 2929 2c0d 0a20 2020 2020 2020  im=3)),..       
+00005bc0: 2020 2020 2027 696e 7433 3227 290d 0a0d       'int32')...
+00005bd0: 0a20 2020 2020 2020 206e 6577 5f73 6861  .        new_sha
+00005be0: 7065 203d 2054 2e63 6f6e 6361 7465 6e61  pe = T.concatena
+00005bf0: 7465 285b 7365 6c66 2e72 6567 756c 6172  te([self.regular
+00005c00: 5f67 7269 645f 7265 732c 2054 2e73 7461  _grid_res, T.sta
+00005c10: 636b 285b 335d 295d 290d 0a20 2020 2020  ck([3])])..     
+00005c20: 2020 2078 797a 203d 2067 7269 645b 3a54     xyz = grid[:T
+00005c30: 2e70 726f 6428 7365 6c66 2e72 6567 756c  .prod(self.regul
+00005c40: 6172 5f67 7269 645f 7265 7329 5d2e 7265  ar_grid_res)].re
+00005c50: 7368 6170 6528 6e65 775f 7368 6170 652c  shape(new_shape,
+00005c60: 206e 6469 6d3d 3429 0d0a 0d0a 2020 2020   ndim=4)....    
+00005c70: 2020 2020 7368 6966 745f 7820 3d20 7576      shift_x = uv
+00005c80: 5f33 645b 313a 2c20 3a2c 203a 5d20 2d20  _3d[1:, :, :] - 
+00005c90: 7576 5f33 645b 3a2d 312c 203a 2c20 3a5d  uv_3d[:-1, :, :]
+00005ca0: 0d0a 2020 2020 2020 2020 7368 6966 745f  ..        shift_
+00005cb0: 785f 7365 6c65 6374 203d 2054 2e6e 6571  x_select = T.neq
+00005cc0: 2873 6869 6674 5f78 2c20 3029 0d0a 2020  (shift_x, 0)..  
+00005cd0: 2020 2020 2020 785f 6564 6720 3d20 2878        x_edg = (x
+00005ce0: 797a 5b3a 2d31 2c20 3a2c 203a 5d5b 7368  yz[:-1, :, :][sh
+00005cf0: 6966 745f 785f 7365 6c65 6374 5d20 2b20  ift_x_select] + 
+00005d00: 7879 7a5b 313a 2c20 3a2c 203a 5d5b 7368  xyz[1:, :, :][sh
+00005d10: 6966 745f 785f 7365 6c65 6374 5d29 202f  ift_x_select]) /
+00005d20: 2032 0d0a 0d0a 2020 2020 2020 2020 7368   2....        sh
+00005d30: 6966 745f 7920 3d20 7576 5f33 645b 3a2c  ift_y = uv_3d[:,
+00005d40: 2031 3a2c 203a 5d20 2d20 7576 5f33 645b   1:, :] - uv_3d[
+00005d50: 3a2c 203a 2d31 2c20 3a5d 0d0a 2020 2020  :, :-1, :]..    
+00005d60: 2020 2020 7368 6966 745f 795f 7365 6c65      shift_y_sele
+00005d70: 6374 203d 2054 2e6e 6571 2873 6869 6674  ct = T.neq(shift
+00005d80: 5f79 2c20 3029 0d0a 2020 2020 2020 2020  _y, 0)..        
+00005d90: 795f 6564 6720 3d20 2878 797a 5b3a 2c20  y_edg = (xyz[:, 
+00005da0: 3a2d 312c 203a 5d5b 7368 6966 745f 795f  :-1, :][shift_y_
+00005db0: 7365 6c65 6374 5d20 2b20 7879 7a5b 3a2c  select] + xyz[:,
+00005dc0: 2031 3a2c 203a 5d5b 7368 6966 745f 795f   1:, :][shift_y_
+00005dd0: 7365 6c65 6374 5d29 202f 2032 0d0a 0d0a  select]) / 2....
+00005de0: 2020 2020 2020 2020 7368 6966 745f 7a20          shift_z 
+00005df0: 3d20 7576 5f33 645b 3a2c 203a 2c20 313a  = uv_3d[:, :, 1:
+00005e00: 5d20 2d20 7576 5f33 645b 3a2c 203a 2c20  ] - uv_3d[:, :, 
+00005e10: 3a2d 315d 0d0a 2020 2020 2020 2020 7368  :-1]..        sh
+00005e20: 6966 745f 7a5f 7365 6c65 6374 203d 2054  ift_z_select = T
+00005e30: 2e6e 6571 2873 6869 6674 5f7a 2c20 3029  .neq(shift_z, 0)
+00005e40: 0d0a 2020 2020 2020 2020 7a5f 6564 6720  ..        z_edg 
+00005e50: 3d20 2878 797a 5b3a 2c20 3a2c 203a 2d31  = (xyz[:, :, :-1
+00005e60: 5d5b 7368 6966 745f 7a5f 7365 6c65 6374  ][shift_z_select
+00005e70: 5d20 2b20 7879 7a5b 3a2c 203a 2c20 313a  ] + xyz[:, :, 1:
+00005e80: 5d5b 7368 6966 745f 7a5f 7365 6c65 6374  ][shift_z_select
+00005e90: 5d29 202f 2032 0d0a 2020 2020 2020 2020  ]) / 2..        
+00005ea0: 6e65 775f 7879 7a5f 6564 6720 3d20 542e  new_xyz_edg = T.
+00005eb0: 7665 7274 6963 616c 5f73 7461 636b 2878  vertical_stack(x
+00005ec0: 5f65 6467 2c20 795f 6564 672c 207a 5f65  _edg, y_edg, z_e
+00005ed0: 6467 290d 0a0d 0a20 2020 2020 2020 2072  dg)....        r
+00005ee0: 6574 7572 6e20 7365 6c66 2e63 7265 6174  eturn self.creat
+00005ef0: 655f 6f63 745f 766f 7865 6c73 286e 6577  e_oct_voxels(new
+00005f00: 5f78 797a 5f65 6467 290d 0a0d 0a20 2020  _xyz_edg)....   
+00005f10: 2064 6566 2063 7265 6174 655f 6f63 745f   def create_oct_
+00005f20: 6c65 7665 6c5f 7370 6172 7365 2873 656c  level_sparse(sel
+00005f30: 662c 2075 6e69 7175 655f 7661 6c2c 2067  f, unique_val, g
+00005f40: 7269 6429 3a0d 0a20 2020 2020 2020 2078  rid):..        x
+00005f50: 797a 5f38 203d 2067 7269 642e 7265 7368  yz_8 = grid.resh
+00005f60: 6170 6528 282d 312c 2038 2c20 3329 290d  ape((-1, 8, 3)).
+00005f70: 0a20 2020 2020 2020 2023 2075 765f 3820  .        # uv_8 
+00005f80: 3d20 542e 726f 756e 6428 756e 6971 7565  = T.round(unique
+00005f90: 5f76 616c 5b30 2c20 3a2d 3220 2a20 7365  _val[0, :-2 * se
+00005fa0: 6c66 2e6c 656e 5f70 6f69 6e74 735d 2e72  lf.len_points].r
+00005fb0: 6573 6861 7065 2828 2d31 2c20 3829 2929  eshape((-1, 8)))
+00005fc0: 0d0a 0d0a 2020 2020 2020 2020 7576 5f38  ....        uv_8
+00005fd0: 203d 2054 2e72 6f75 6e64 2875 6e69 7175   = T.round(uniqu
+00005fe0: 655f 7661 6c5b 302c 203a 5d2e 7265 7368  e_val[0, :].resh
+00005ff0: 6170 6528 282d 312c 2038 2929 290d 0a0d  ape((-1, 8)))...
+00006000: 0a20 2020 2020 2020 2073 6869 6674 5f78  .        shift_x
+00006010: 203d 2075 765f 385b 3a2c 203a 345d 202d   = uv_8[:, :4] -
+00006020: 2075 765f 385b 3a2c 2034 3a5d 0d0a 2020   uv_8[:, 4:]..  
+00006030: 2020 2020 2020 7368 6966 745f 785f 7365        shift_x_se
+00006040: 6c65 6374 203d 2054 2e6e 6571 2873 6869  lect = T.neq(shi
+00006050: 6674 5f78 2c20 3029 0d0a 2020 2020 2020  ft_x, 0)..      
+00006060: 2020 785f 6564 6720 3d20 2878 797a 5f38    x_edg = (xyz_8
+00006070: 5b3a 2c20 3a34 2c20 3a5d 5b73 6869 6674  [:, :4, :][shift
+00006080: 5f78 5f73 656c 6563 745d 202b 2078 797a  _x_select] + xyz
+00006090: 5f38 5b3a 2c20 343a 2c20 3a5d 5b0d 0a20  _8[:, 4:, :][.. 
+000060a0: 2020 2020 2020 2020 2020 2073 6869 6674             shift
+000060b0: 5f78 5f73 656c 6563 745d 2920 2f20 320d  _x_select]) / 2.
+000060c0: 0a0d 0a20 2020 2020 2020 2073 6869 6674  ...        shift
+000060d0: 5f79 203d 2075 765f 385b 3a2c 205b 302c  _y = uv_8[:, [0,
+000060e0: 2031 2c20 342c 2035 5d5d 202d 2075 765f   1, 4, 5]] - uv_
+000060f0: 385b 3a2c 205b 322c 2033 2c20 362c 2037  8[:, [2, 3, 6, 7
+00006100: 5d5d 0d0a 2020 2020 2020 2020 7368 6966  ]]..        shif
+00006110: 745f 795f 7365 6c65 6374 203d 2054 2e6e  t_y_select = T.n
+00006120: 6571 2873 6869 6674 5f79 2c20 3029 0d0a  eq(shift_y, 0)..
+00006130: 2020 2020 2020 2020 795f 6564 6720 3d20          y_edg = 
+00006140: 2878 797a 5f38 5b3a 2c20 5b30 2c20 312c  (xyz_8[:, [0, 1,
+00006150: 2034 2c20 355d 2c20 3a5d 5b73 6869 6674   4, 5], :][shift
+00006160: 5f79 5f73 656c 6563 745d 202b 0d0a 2020  _y_select] +..  
+00006170: 2020 2020 2020 2020 2020 2020 2020 2078                 x
+00006180: 797a 5f38 5b3a 2c20 5b32 2c20 332c 2036  yz_8[:, [2, 3, 6
+00006190: 2c20 375d 2c20 3a5d 5b73 6869 6674 5f79  , 7], :][shift_y
+000061a0: 5f73 656c 6563 745d 2920 2f20 320d 0a0d  _select]) / 2...
+000061b0: 0a20 2020 2020 2020 2073 6869 6674 5f7a  .        shift_z
+000061c0: 203d 2075 765f 385b 3a2c 203a 3a32 5d20   = uv_8[:, ::2] 
+000061d0: 2d20 7576 5f38 5b3a 2c20 313a 3a32 5d0d  - uv_8[:, 1::2].
+000061e0: 0a20 2020 2020 2020 2073 6869 6674 5f7a  .        shift_z
+000061f0: 5f73 656c 6563 7420 3d20 542e 6e65 7128  _select = T.neq(
+00006200: 7368 6966 745f 7a2c 2030 290d 0a20 2020  shift_z, 0)..   
+00006210: 2020 2020 207a 5f65 6467 203d 2028 7879       z_edg = (xy
+00006220: 7a5f 385b 3a2c 203a 3a32 2c20 3a5d 5b73  z_8[:, ::2, :][s
+00006230: 6869 6674 5f7a 5f73 656c 6563 745d 202b  hift_z_select] +
+00006240: 2078 797a 5f38 5b3a 2c20 313a 3a32 2c20   xyz_8[:, 1::2, 
+00006250: 3a5d 5b0d 0a20 2020 2020 2020 2020 2020  :][..           
+00006260: 2073 6869 6674 5f7a 5f73 656c 6563 745d   shift_z_select]
+00006270: 2920 2f20 320d 0a0d 0a20 2020 2020 2020  ) / 2....       
+00006280: 206e 6577 5f78 797a 5f65 6467 203d 2054   new_xyz_edg = T
+00006290: 2e76 6572 7469 6361 6c5f 7374 6163 6b28  .vertical_stack(
+000062a0: 785f 6564 672c 2079 5f65 6467 2c20 7a5f  x_edg, y_edg, z_
+000062b0: 6564 6729 0d0a 2020 2020 2020 2020 7265  edg)..        re
+000062c0: 7475 726e 2073 656c 662e 6372 6561 7465  turn self.create
+000062d0: 5f6f 6374 5f76 6f78 656c 7328 6e65 775f  _oct_voxels(new_
+000062e0: 7879 7a5f 6564 672c 206c 6576 656c 3d32  xyz_edg, level=2
+000062f0: 290d 0a0d 0a20 2020 2064 6566 2063 6f6d  )....    def com
+00006300: 7075 7465 5f73 6572 6965 735f 6f63 7428  pute_series_oct(
+00006310: 7365 6c66 2c20 6e5f 6c65 7665 6c73 3d33  self, n_levels=3
+00006320: 293a 0d0a 2020 2020 2020 2020 2320 7365  ):..        # se
+00006330: 6c66 2e73 6869 6674 203d 2030 0d0a 0d0a  lf.shift = 0....
+00006340: 2020 2020 2020 2020 736f 6c75 7469 6f6e          solution
+00006350: 7320 3d20 7365 6c66 2e63 6f6d 7075 7465  s = self.compute
+00006360: 5f73 6572 6965 7328 7365 6c66 2e67 7269  _series(self.gri
+00006370: 645f 7661 6c5f 5429 0d0a 2020 2020 2020  d_val_T)..      
+00006380: 2020 756e 6971 7565 5f76 616c 203d 2073    unique_val = s
+00006390: 6f6c 7574 696f 6e73 5b30 5d20 2b20 7365  olutions[0] + se
+000063a0: 6c66 2e6d 6178 5f6c 6974 6820 2a20 736f  lf.max_lith * so
+000063b0: 6c75 7469 6f6e 735b 325d 0d0a 0d0a 2020  lutions[2]....  
+000063c0: 2020 2020 2020 2320 2320 2d2d 2d2d 2d2d        # # ------
+000063d0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+000063e0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+000063f0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00006400: 0d0a 2020 2020 2020 2020 7368 6966 7420  ..        shift 
+00006410: 3d20 7365 6c66 2e67 7269 645f 7661 6c5f  = self.grid_val_
+00006420: 542e 7368 6170 655b 305d 202b 2073 656c  T.shape[0] + sel
+00006430: 662e 7368 6966 740d 0a0d 0a20 2020 2020  f.shift....     
+00006440: 2020 2067 203d 2073 656c 662e 6372 6561     g = self.crea
+00006450: 7465 5f6f 6374 5f6c 6576 656c 5f64 656e  te_oct_level_den
+00006460: 7365 2873 6f6c 7574 696f 6e73 5b30 5d2c  se(solutions[0],
+00006470: 2073 656c 662e 6772 6964 5f76 616c 5f54   self.grid_val_T
+00006480: 290d 0a0d 0a20 2020 2020 2020 2023 2049  )....        # I
+00006490: 206e 6565 6420 746f 2069 6e69 7420 7468   need to init th
+000064a0: 6520 736f 6c75 7469 6f6e 206d 6174 7269  e solution matri
+000064b0: 6365 730d 0a20 2020 2020 2020 206f 6374  ces..        oct
+000064c0: 5f73 6f6c 203d 2073 656c 662e 636f 6d70  _sol = self.comp
+000064d0: 7574 655f 7365 7269 6573 2867 2c20 7368  ute_series(g, sh
+000064e0: 6966 7429 0d0a 0d0a 2020 2020 2020 2020  ift)....        
+000064f0: 736f 6c75 7469 6f6e 732e 6170 7065 6e64  solutions.append
+00006500: 2867 290d 0a20 2020 2020 2020 2073 6f6c  (g)..        sol
+00006510: 7574 696f 6e73 2e61 7070 656e 6428 6f63  utions.append(oc
+00006520: 745f 736f 6c5b 305d 290d 0a0d 0a20 2020  t_sol[0])....   
+00006530: 2020 2020 2023 202d 2d2d 2d2d 2d2d 2d2d       # ---------
+00006540: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00006550: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00006560: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 0d0a 2020  ------------..  
+00006570: 2020 2020 2020 756e 6971 7565 5f76 616c        unique_val
+00006580: 203d 206f 6374 5f73 6f6c 5b30 5d20 2b20   = oct_sol[0] + 
+00006590: 7365 6c66 2e6d 6178 5f6c 6974 6820 2a20  self.max_lith * 
+000065a0: 6f63 745f 736f 6c5b 325d 0d0a 0d0a 2020  oct_sol[2]....  
+000065b0: 2020 2020 2020 6731 203d 2073 656c 662e        g1 = self.
+000065c0: 6372 6561 7465 5f6f 6374 5f6c 6576 656c  create_oct_level
+000065d0: 5f73 7061 7273 6528 756e 6971 7565 5f76  _sparse(unique_v
+000065e0: 616c 5b3a 2c20 7368 6966 743a 2067 2e73  al[:, shift: g.s
+000065f0: 6861 7065 5b30 5d20 2b20 7368 6966 745d  hape[0] + shift]
+00006600: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00006610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006620: 2020 2020 2020 2020 2020 2020 2067 290d               g).
+00006630: 0a20 2020 2020 2020 2073 6869 6674 3220  .        shift2 
+00006640: 3d20 672e 7368 6170 655b 305d 202b 2073  = g.shape[0] + s
+00006650: 6869 6674 0d0a 0d0a 2020 2020 2020 2020  hift....        
+00006660: 6f63 745f 736f 6c5f 3220 3d20 7365 6c66  oct_sol_2 = self
+00006670: 2e63 6f6d 7075 7465 5f73 6572 6965 7328  .compute_series(
+00006680: 6731 2c20 7368 6966 7432 290d 0a0d 0a20  g1, shift2).... 
+00006690: 2020 2020 2020 2073 6f6c 7574 696f 6e73         solutions
+000066a0: 2e61 7070 656e 6428 6731 290d 0a20 2020  .append(g1)..   
+000066b0: 2020 2020 2073 6f6c 7574 696f 6e73 2e61       solutions.a
+000066c0: 7070 656e 6428 6f63 745f 736f 6c5f 325b  ppend(oct_sol_2[
+000066d0: 305d 290d 0a0d 0a20 2020 2020 2020 2073  0])....        s
+000066e0: 656c 662e 6e65 775f 626c 6f63 6b20 3d20  elf.new_block = 
+000066f0: 7365 6c66 2e62 6c6f 636b 5f6f 700d 0a20  self.block_op.. 
+00006700: 2020 2020 2020 2073 656c 662e 6e65 775f         self.new_
+00006710: 7765 6967 6874 7320 3d20 7365 6c66 2e77  weights = self.w
+00006720: 6569 6768 7473 5f6f 700d 0a20 2020 2020  eights_op..     
+00006730: 2020 2073 656c 662e 6e65 775f 7363 616c     self.new_scal
+00006740: 6172 203d 2073 656c 662e 7363 616c 6172  ar = self.scalar
+00006750: 5f6f 700d 0a20 2020 2020 2020 2073 656c  _op..        sel
+00006760: 662e 6e65 775f 7366 6169 203d 2073 656c  f.new_sfai = sel
+00006770: 662e 7366 6169 5f6f 700d 0a20 2020 2020  f.sfai_op..     
+00006780: 2020 2073 656c 662e 6e65 775f 6d61 736b     self.new_mask
+00006790: 203d 2073 656c 662e 6d61 736b 5f6f 7032   = self.mask_op2
+000067a0: 0d0a 0d0a 2020 2020 2020 2020 7265 7475  ....        retu
+000067b0: 726e 2073 6f6c 7574 696f 6e73 0d0a 0d0a  rn solutions....
+000067c0: 2020 2020 6465 6620 6165 7361 7261 5f6f      def aesara_o
+000067d0: 7574 7075 7428 7365 6c66 293a 0d0a 2020  utput(self):..  
+000067e0: 2020 2020 2020 2320 4372 6561 7465 2074        # Create t
+000067f0: 6865 2073 6f6c 7574 696f 6e73 206f 700d  he solutions op.
+00006800: 0a20 2020 2020 2020 2073 656c 662e 626c  .        self.bl
+00006810: 6f63 6b5f 6f70 203d 2073 656c 662e 626c  ock_op = self.bl
+00006820: 6f63 6b5f 6d61 7472 6978 0d0a 2020 2020  ock_matrix..    
+00006830: 2020 2020 7365 6c66 2e77 6569 6768 7473      self.weights
+00006840: 5f6f 7020 3d20 7365 6c66 2e77 6569 6768  _op = self.weigh
+00006850: 7473 5f76 6563 746f 720d 0a20 2020 2020  ts_vector..     
+00006860: 2020 2073 656c 662e 7363 616c 6172 5f6f     self.scalar_o
+00006870: 7020 3d20 7365 6c66 2e73 6361 6c61 725f  p = self.scalar_
+00006880: 6669 656c 6473 5f6d 6174 7269 780d 0a20  fields_matrix.. 
+00006890: 2020 2020 2020 2073 656c 662e 6d61 736b         self.mask
+000068a0: 5f6f 7032 203d 2073 656c 662e 6d61 736b  _op2 = self.mask
+000068b0: 5f6d 6174 7269 780d 0a20 2020 2020 2020  _matrix..       
+000068c0: 2073 656c 662e 7366 6169 5f6f 7020 3d20   self.sfai_op = 
+000068d0: 7365 6c66 2e73 6661 690d 0a0d 0a20 2020  self.sfai....   
+000068e0: 2020 2020 2073 6f6c 7574 696f 6e73 203d       solutions =
+000068f0: 205b 6165 7361 7261 2e73 6861 7265 6428   [aesara.shared(
+00006900: 6e70 2e6e 616e 295d 202a 2031 350d 0a20  np.nan)] * 15.. 
+00006910: 2020 2020 2020 2073 6f6c 7574 696f 6e73         solutions
+00006920: 5b30 5d20 3d20 6165 7361 7261 2e73 6861  [0] = aesara.sha
+00006930: 7265 6428 6e70 2e7a 6572 6f73 2828 322c  red(np.zeros((2,
+00006940: 2032 2929 290d 0a20 2020 2020 2020 2023   2)))..        #
+00006950: 2073 656c 662e 636f 6d70 7574 655f 7479   self.compute_ty
+00006960: 7065 203d 205b 276c 6974 686f 6c6f 6779  pe = ['lithology
+00006970: 272c 2027 746f 706f 6c6f 6779 275d 0d0a  ', 'topology']..
+00006980: 2020 2020 2020 2020 6966 2027 6765 6f6c          if 'geol
+00006990: 6f67 7927 2069 6e20 7365 6c66 2e63 6f6d  ogy' in self.com
+000069a0: 7075 7465 5f74 7970 653a 0d0a 2020 2020  pute_type:..    
+000069b0: 2020 2020 2020 2020 736f 6c75 7469 6f6e          solution
+000069c0: 735b 3a39 5d20 3d20 7365 6c66 2e63 6f6d  s[:9] = self.com
+000069d0: 7075 7465 5f73 6572 6965 7328 290d 0a20  pute_series().. 
+000069e0: 2020 2020 2020 2020 2020 2023 2073 6f6c             # sol
+000069f0: 7574 696f 6e73 5b3a 3132 5d20 3d20 7365  utions[:12] = se
+00006a00: 6c66 2e63 6f6d 7075 7465 5f73 6572 6965  lf.compute_serie
+00006a10: 735f 6f63 7428 290d 0a20 2020 2020 2020  s_oct()..       
+00006a20: 2069 6620 2774 6f70 6f6c 6f67 7927 2069   if 'topology' i
 00006a30: 6e20 7365 6c66 2e63 6f6d 7075 7465 5f74  n self.compute_t
 00006a40: 7970 653a 0d0a 2020 2020 2020 2020 2020  ype:..          
-00006a50: 2020 736f 6c75 7469 6f6e 735b 3a39 5d20    solutions[:9] 
-00006a60: 3d20 7365 6c66 2e63 6f6d 7075 7465 5f73  = self.compute_s
-00006a70: 6572 6965 7328 290d 0a20 2020 2020 2020  eries()..       
-00006a80: 2020 2020 2023 2073 6f6c 7574 696f 6e73       # solutions
-00006a90: 5b3a 3132 5d20 3d20 7365 6c66 2e63 6f6d  [:12] = self.com
-00006aa0: 7075 7465 5f73 6572 6965 735f 6f63 7428  pute_series_oct(
-00006ab0: 290d 0a20 2020 2020 2020 2069 6620 2774  )..        if 't
-00006ac0: 6f70 6f6c 6f67 7927 2069 6e20 7365 6c66  opology' in self
-00006ad0: 2e63 6f6d 7075 7465 5f74 7970 653a 0d0a  .compute_type:..
-00006ae0: 2020 2020 2020 2020 2020 2020 2320 5468              # Th
-00006af0: 6973 206e 6565 6473 206e 6577 2064 6174  is needs new dat
-00006b00: 612c 2072 6573 6f6c 7574 696f 6e20 6f66  a, resolution of
-00006b10: 2074 6865 2072 6567 756c 6172 2067 7269   the regular gri
-00006b20: 642c 2076 616c 7565 206d 6178 0d0a 2020  d, value max..  
-00006b30: 2020 2020 2020 2020 2020 756e 6971 7565            unique
-00006b40: 5f76 616c 203d 2073 6f6c 7574 696f 6e73  _val = solutions
-00006b50: 5b30 5d5b 7365 6c66 2e70 6f73 5f74 6f70  [0][self.pos_top
-00006b60: 6f6c 6f67 795f 6964 5d20 2b20 5c0d 0a20  ology_id] + \.. 
-00006b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006b80: 2020 2020 2020 2020 7365 6c66 2e6d 6178          self.max
-00006b90: 5f6c 6974 6820 2a20 736f 6c75 7469 6f6e  _lith * solution
-00006ba0: 735b 325d 5b73 656c 662e 706f 735f 746f  s[2][self.pos_to
-00006bb0: 706f 6c6f 6779 5f69 645d 0d0a 0d0a 2020  pology_id]....  
-00006bc0: 2020 2020 2020 2020 2020 736f 6c75 7469            soluti
-00006bd0: 6f6e 735b 393a 3132 5d20 3d20 7365 6c66  ons[9:12] = self
-00006be0: 2e63 6f6d 7075 7465 5f74 6f70 6f6c 6f67  .compute_topolog
-00006bf0: 7928 756e 6971 7565 5f76 616c 290d 0a0d  y(unique_val)...
-00006c00: 0a20 2020 2020 2020 2069 6620 2767 7261  .        if 'gra
-00006c10: 7669 7479 2720 696e 2073 656c 662e 636f  vity' in self.co
-00006c20: 6d70 7574 655f 7479 7065 3a0d 0a20 2020  mpute_type:..   
-00006c30: 2020 2020 2020 2020 2064 656e 7369 7469           densiti
-00006c40: 6573 203d 2073 6f6c 7574 696f 6e73 5b30  es = solutions[0
-00006c50: 5d5b 7365 6c66 2e70 6f73 5f64 656e 7369  ][self.pos_densi
-00006c60: 7479 2c20 7365 6c66 2e6c 6730 3a73 656c  ty, self.lg0:sel
-00006c70: 662e 6c67 315d 0d0a 2020 2020 2020 2020  f.lg1]..        
-00006c80: 2020 2020 736f 6c75 7469 6f6e 735b 3132      solutions[12
-00006c90: 5d20 3d20 7365 6c66 2e63 6f6d 7075 7465  ] = self.compute
-00006ca0: 5f66 6f72 7761 7264 5f67 7261 7669 7479  _forward_gravity
-00006cb0: 5f70 726f 2864 656e 7369 7469 6573 290d  _pro(densities).
-00006cc0: 0a0d 0a20 2020 2020 2020 2069 6620 276d  ...        if 'm
-00006cd0: 6167 6e65 7469 6373 2720 696e 2073 656c  agnetics' in sel
-00006ce0: 662e 636f 6d70 7574 655f 7479 7065 3a0d  f.compute_type:.
-00006cf0: 0a20 2020 2020 2020 2020 2020 206b 5f76  .            k_v
-00006d00: 616c 7320 3d20 736f 6c75 7469 6f6e 735b  als = solutions[
-00006d10: 305d 5b73 656c 662e 706f 735f 6d61 676e  0][self.pos_magn
-00006d20: 6574 6963 732c 2073 656c 662e 6c67 303a  etics, self.lg0:
-00006d30: 7365 6c66 2e6c 6731 5d0d 0a20 2020 2020  self.lg1]..     
-00006d40: 2020 2020 2020 2073 6f6c 7574 696f 6e73         solutions
-00006d50: 5b31 335d 203d 2073 656c 662e 636f 6d70  [13] = self.comp
-00006d60: 7574 655f 666f 7277 6172 645f 6d61 676e  ute_forward_magn
-00006d70: 6574 6963 7328 6b5f 7661 6c73 290d 0a20  etics(k_vals).. 
-00006d80: 2020 2020 2020 2072 6574 7572 6e20 736f         return so
-00006d90: 6c75 7469 6f6e 730d 0a0d 0a20 2020 2064  lutions....    d
-00006da0: 6566 2063 6f6d 7075 7465 5f74 6f70 6f6c  ef compute_topol
-00006db0: 6f67 7928 7365 6c66 2c20 756e 6971 7565  ogy(self, unique
-00006dc0: 5f76 616c 293a 0d0a 2020 2020 2020 2020  _val):..        
-00006dd0: 7576 5f33 6420 3d20 542e 6361 7374 2854  uv_3d = T.cast(T
-00006de0: 2e72 6f75 6e64 2875 6e69 7175 655f 7661  .round(unique_va
-00006df0: 6c5b 3a54 2e70 726f 6428 7365 6c66 2e72  l[:T.prod(self.r
-00006e00: 6567 756c 6172 5f67 7269 645f 7265 7329  egular_grid_res)
-00006e10: 5d2e 7265 7368 6170 6528 0d0a 2020 2020  ].reshape(..    
-00006e20: 2020 2020 2020 2020 7365 6c66 2e72 6567          self.reg
-00006e30: 756c 6172 5f67 7269 645f 7265 732c 206e  ular_grid_res, n
-00006e40: 6469 6d3d 3329 292c 0d0a 2020 2020 2020  dim=3)),..      
-00006e50: 2020 2020 2020 2769 6e74 3332 2729 0d0a        'int32')..
-00006e60: 0d0a 2020 2020 2020 2020 7576 5f6c 203d  ..        uv_l =
-00006e70: 2054 2e68 6f72 697a 6f6e 7461 6c5f 7374   T.horizontal_st
-00006e80: 6163 6b28 7576 5f33 645b 313a 2c20 3a2c  ack(uv_3d[1:, :,
-00006e90: 203a 5d2e 7265 7368 6170 6528 2831 2c20   :].reshape((1, 
-00006ea0: 2d31 2929 2c0d 0a20 2020 2020 2020 2020  -1)),..         
-00006eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006ec0: 2020 2020 2020 2020 2075 765f 3364 5b3a           uv_3d[:
-00006ed0: 2c20 313a 2c20 3a5d 2e72 6573 6861 7065  , 1:, :].reshape
-00006ee0: 2828 312c 202d 3129 292c 0d0a 2020 2020  ((1, -1)),..    
+00006a50: 2020 2320 5468 6973 206e 6565 6473 206e    # This needs n
+00006a60: 6577 2064 6174 612c 2072 6573 6f6c 7574  ew data, resolut
+00006a70: 696f 6e20 6f66 2074 6865 2072 6567 756c  ion of the regul
+00006a80: 6172 2067 7269 642c 2076 616c 7565 206d  ar grid, value m
+00006a90: 6178 0d0a 2020 2020 2020 2020 2020 2020  ax..            
+00006aa0: 756e 6971 7565 5f76 616c 203d 2073 6f6c  unique_val = sol
+00006ab0: 7574 696f 6e73 5b30 5d5b 7365 6c66 2e70  utions[0][self.p
+00006ac0: 6f73 5f74 6f70 6f6c 6f67 795f 6964 5d20  os_topology_id] 
+00006ad0: 2b20 5c0d 0a20 2020 2020 2020 2020 2020  + \..           
+00006ae0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00006af0: 6c66 2e6d 6178 5f6c 6974 6820 2a20 736f  lf.max_lith * so
+00006b00: 6c75 7469 6f6e 735b 325d 5b73 656c 662e  lutions[2][self.
+00006b10: 706f 735f 746f 706f 6c6f 6779 5f69 645d  pos_topology_id]
+00006b20: 0d0a 0d0a 2020 2020 2020 2020 2020 2020  ....            
+00006b30: 736f 6c75 7469 6f6e 735b 393a 3132 5d20  solutions[9:12] 
+00006b40: 3d20 7365 6c66 2e63 6f6d 7075 7465 5f74  = self.compute_t
+00006b50: 6f70 6f6c 6f67 7928 756e 6971 7565 5f76  opology(unique_v
+00006b60: 616c 290d 0a0d 0a20 2020 2020 2020 2069  al)....        i
+00006b70: 6620 2767 7261 7669 7479 2720 696e 2073  f 'gravity' in s
+00006b80: 656c 662e 636f 6d70 7574 655f 7479 7065  elf.compute_type
+00006b90: 3a0d 0a20 2020 2020 2020 2020 2020 2064  :..            d
+00006ba0: 656e 7369 7469 6573 203d 2073 6f6c 7574  ensities = solut
+00006bb0: 696f 6e73 5b30 5d5b 7365 6c66 2e70 6f73  ions[0][self.pos
+00006bc0: 5f64 656e 7369 7479 2c20 7365 6c66 2e6c  _density, self.l
+00006bd0: 6730 3a73 656c 662e 6c67 315d 0d0a 2020  g0:self.lg1]..  
+00006be0: 2020 2020 2020 2020 2020 736f 6c75 7469            soluti
+00006bf0: 6f6e 735b 3132 5d20 3d20 7365 6c66 2e63  ons[12] = self.c
+00006c00: 6f6d 7075 7465 5f66 6f72 7761 7264 5f67  ompute_forward_g
+00006c10: 7261 7669 7479 5f70 726f 2864 656e 7369  ravity_pro(densi
+00006c20: 7469 6573 290d 0a0d 0a20 2020 2020 2020  ties)....       
+00006c30: 2069 6620 276d 6167 6e65 7469 6373 2720   if 'magnetics' 
+00006c40: 696e 2073 656c 662e 636f 6d70 7574 655f  in self.compute_
+00006c50: 7479 7065 3a0d 0a20 2020 2020 2020 2020  type:..         
+00006c60: 2020 206b 5f76 616c 7320 3d20 736f 6c75     k_vals = solu
+00006c70: 7469 6f6e 735b 305d 5b73 656c 662e 706f  tions[0][self.po
+00006c80: 735f 6d61 676e 6574 6963 732c 2073 656c  s_magnetics, sel
+00006c90: 662e 6c67 303a 7365 6c66 2e6c 6731 5d0d  f.lg0:self.lg1].
+00006ca0: 0a20 2020 2020 2020 2020 2020 2073 6f6c  .            sol
+00006cb0: 7574 696f 6e73 5b31 335d 203d 2073 656c  utions[13] = sel
+00006cc0: 662e 636f 6d70 7574 655f 666f 7277 6172  f.compute_forwar
+00006cd0: 645f 6d61 676e 6574 6963 7328 6b5f 7661  d_magnetics(k_va
+00006ce0: 6c73 290d 0a20 2020 2020 2020 2072 6574  ls)..        ret
+00006cf0: 7572 6e20 736f 6c75 7469 6f6e 730d 0a0d  urn solutions...
+00006d00: 0a20 2020 2064 6566 2063 6f6d 7075 7465  .    def compute
+00006d10: 5f74 6f70 6f6c 6f67 7928 7365 6c66 2c20  _topology(self, 
+00006d20: 756e 6971 7565 5f76 616c 293a 0d0a 2020  unique_val):..  
+00006d30: 2020 2020 2020 7576 5f33 6420 3d20 542e        uv_3d = T.
+00006d40: 6361 7374 2854 2e72 6f75 6e64 2875 6e69  cast(T.round(uni
+00006d50: 7175 655f 7661 6c5b 3a54 2e70 726f 6428  que_val[:T.prod(
+00006d60: 7365 6c66 2e72 6567 756c 6172 5f67 7269  self.regular_gri
+00006d70: 645f 7265 7329 5d2e 7265 7368 6170 6528  d_res)].reshape(
+00006d80: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
+00006d90: 6c66 2e72 6567 756c 6172 5f67 7269 645f  lf.regular_grid_
+00006da0: 7265 732c 206e 6469 6d3d 3329 292c 0d0a  res, ndim=3)),..
+00006db0: 2020 2020 2020 2020 2020 2020 2769 6e74              'int
+00006dc0: 3332 2729 0d0a 0d0a 2020 2020 2020 2020  32')....        
+00006dd0: 7576 5f6c 203d 2054 2e68 6f72 697a 6f6e  uv_l = T.horizon
+00006de0: 7461 6c5f 7374 6163 6b28 7576 5f33 645b  tal_stack(uv_3d[
+00006df0: 313a 2c20 3a2c 203a 5d2e 7265 7368 6170  1:, :, :].reshap
+00006e00: 6528 2831 2c20 2d31 2929 2c0d 0a20 2020  e((1, -1)),..   
+00006e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006e20: 2020 2020 2020 2020 2020 2020 2020 2075                 u
+00006e30: 765f 3364 5b3a 2c20 313a 2c20 3a5d 2e72  v_3d[:, 1:, :].r
+00006e40: 6573 6861 7065 2828 312c 202d 3129 292c  eshape((1, -1)),
+00006e50: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00006e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006e70: 2020 2020 7576 5f33 645b 3a2c 203a 2c20      uv_3d[:, :, 
+00006e80: 313a 5d2e 7265 7368 6170 6528 2831 2c20  1:].reshape((1, 
+00006e90: 2d31 2929 290d 0a0d 0a20 2020 2020 2020  -1)))....       
+00006ea0: 2075 765f 7220 3d20 542e 686f 7269 7a6f   uv_r = T.horizo
+00006eb0: 6e74 616c 5f73 7461 636b 2875 765f 3364  ntal_stack(uv_3d
+00006ec0: 5b3a 2d31 2c20 3a2c 203a 5d2e 7265 7368  [:-1, :, :].resh
+00006ed0: 6170 6528 2831 2c20 2d31 2929 2c0d 0a20  ape((1, -1)),.. 
+00006ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00006ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006f00: 2020 2020 2020 2020 2020 2020 2020 7576                uv
-00006f10: 5f33 645b 3a2c 203a 2c20 313a 5d2e 7265  _3d[:, :, 1:].re
-00006f20: 7368 6170 6528 2831 2c20 2d31 2929 290d  shape((1, -1))).
-00006f30: 0a0d 0a20 2020 2020 2020 2075 765f 7220  ...        uv_r 
-00006f40: 3d20 542e 686f 7269 7a6f 6e74 616c 5f73  = T.horizontal_s
-00006f50: 7461 636b 2875 765f 3364 5b3a 2d31 2c20  tack(uv_3d[:-1, 
-00006f60: 3a2c 203a 5d2e 7265 7368 6170 6528 2831  :, :].reshape((1
-00006f70: 2c20 2d31 2929 2c0d 0a20 2020 2020 2020  , -1)),..       
-00006f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006f90: 2020 2020 2020 2020 2020 2075 765f 3364             uv_3d
-00006fa0: 5b3a 2c20 3a2d 312c 203a 5d2e 7265 7368  [:, :-1, :].resh
-00006fb0: 6170 6528 2831 2c20 2d31 2929 2c0d 0a20  ape((1, -1)),.. 
-00006fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006fd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006fe0: 2075 765f 3364 5b3a 2c20 3a2c 203a 2d31   uv_3d[:, :, :-1
-00006ff0: 5d2e 7265 7368 6170 6528 2831 2c20 2d31  ].reshape((1, -1
-00007000: 2929 290d 0a0d 0a20 2020 2020 2020 2073  )))....        s
-00007010: 6869 6674 203d 2075 765f 6c20 2d20 7576  hift = uv_l - uv
-00007020: 5f72 0d0a 2020 2020 2020 2020 7365 6c65  _r..        sele
-00007030: 6374 5f65 6467 6573 203d 2054 2e6e 6571  ct_edges = T.neq
-00007040: 2873 6869 6674 2e72 6573 6861 7065 2828  (shift.reshape((
-00007050: 312c 202d 3129 292c 2030 290d 0a20 2020  1, -1)), 0)..   
-00007060: 2020 2020 2073 656c 6563 745f 6564 6765       select_edge
-00007070: 735f 6469 7220 3d20 7365 6c65 6374 5f65  s_dir = select_e
-00007080: 6467 6573 2e72 6573 6861 7065 2828 332c  dges.reshape((3,
-00007090: 202d 3129 290d 0a0d 0a20 2020 2020 2020   -1))....       
-000070a0: 2073 656c 6563 745f 766f 7865 6c73 203d   select_voxels =
-000070b0: 2054 2e7a 6572 6f73 5f6c 696b 6528 7576   T.zeros_like(uv
-000070c0: 5f33 6429 0d0a 2020 2020 2020 2020 7365  _3d)..        se
-000070d0: 6c65 6374 5f76 6f78 656c 7320 3d20 542e  lect_voxels = T.
-000070e0: 696e 635f 7375 6274 656e 736f 7228 0d0a  inc_subtensor(..
-000070f0: 2020 2020 2020 2020 2020 2020 7365 6c65              sele
-00007100: 6374 5f76 6f78 656c 735b 313a 2c20 3a2c  ct_voxels[1:, :,
-00007110: 203a 5d2c 0d0a 2020 2020 2020 2020 2020   :],..          
-00007120: 2020 7365 6c65 6374 5f65 6467 6573 5f64    select_edges_d
-00007130: 6972 5b30 5d2e 7265 7368 6170 6528 280d  ir[0].reshape((.
-00007140: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007150: 2020 2020 2073 656c 662e 7265 6775 6c61       self.regula
-00007160: 725f 6772 6964 5f72 6573 202d 206e 702e  r_grid_res - np.
-00007170: 6172 7261 7928 5b31 2c20 302c 2030 5d29  array([1, 0, 0])
-00007180: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
-00007190: 2020 2020 6e64 696d 3d33 2929 0d0a 2020      ndim=3))..  
-000071a0: 2020 2020 2020 7365 6c65 6374 5f76 6f78        select_vox
-000071b0: 656c 7320 3d20 542e 696e 635f 7375 6274  els = T.inc_subt
-000071c0: 656e 736f 7228 7365 6c65 6374 5f76 6f78  ensor(select_vox
-000071d0: 656c 735b 3a2d 312c 203a 2c20 3a5d 2c0d  els[:-1, :, :],.
+00006f00: 2075 765f 3364 5b3a 2c20 3a2d 312c 203a   uv_3d[:, :-1, :
+00006f10: 5d2e 7265 7368 6170 6528 2831 2c20 2d31  ].reshape((1, -1
+00006f20: 2929 2c0d 0a20 2020 2020 2020 2020 2020  )),..           
+00006f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006f40: 2020 2020 2020 2075 765f 3364 5b3a 2c20         uv_3d[:, 
+00006f50: 3a2c 203a 2d31 5d2e 7265 7368 6170 6528  :, :-1].reshape(
+00006f60: 2831 2c20 2d31 2929 290d 0a0d 0a20 2020  (1, -1)))....   
+00006f70: 2020 2020 2073 6869 6674 203d 2075 765f       shift = uv_
+00006f80: 6c20 2d20 7576 5f72 0d0a 2020 2020 2020  l - uv_r..      
+00006f90: 2020 7365 6c65 6374 5f65 6467 6573 203d    select_edges =
+00006fa0: 2054 2e6e 6571 2873 6869 6674 2e72 6573   T.neq(shift.res
+00006fb0: 6861 7065 2828 312c 202d 3129 292c 2030  hape((1, -1)), 0
+00006fc0: 290d 0a20 2020 2020 2020 2073 656c 6563  )..        selec
+00006fd0: 745f 6564 6765 735f 6469 7220 3d20 7365  t_edges_dir = se
+00006fe0: 6c65 6374 5f65 6467 6573 2e72 6573 6861  lect_edges.resha
+00006ff0: 7065 2828 332c 202d 3129 290d 0a0d 0a20  pe((3, -1)).... 
+00007000: 2020 2020 2020 2073 656c 6563 745f 766f         select_vo
+00007010: 7865 6c73 203d 2054 2e7a 6572 6f73 5f6c  xels = T.zeros_l
+00007020: 696b 6528 7576 5f33 6429 0d0a 2020 2020  ike(uv_3d)..    
+00007030: 2020 2020 7365 6c65 6374 5f76 6f78 656c      select_voxel
+00007040: 7320 3d20 542e 696e 635f 7375 6274 656e  s = T.inc_subten
+00007050: 736f 7228 0d0a 2020 2020 2020 2020 2020  sor(..          
+00007060: 2020 7365 6c65 6374 5f76 6f78 656c 735b    select_voxels[
+00007070: 313a 2c20 3a2c 203a 5d2c 0d0a 2020 2020  1:, :, :],..    
+00007080: 2020 2020 2020 2020 7365 6c65 6374 5f65          select_e
+00007090: 6467 6573 5f64 6972 5b30 5d2e 7265 7368  dges_dir[0].resh
+000070a0: 6170 6528 280d 0a20 2020 2020 2020 2020  ape((..         
+000070b0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+000070c0: 7265 6775 6c61 725f 6772 6964 5f72 6573  regular_grid_res
+000070d0: 202d 206e 702e 6172 7261 7928 5b31 2c20   - np.array([1, 
+000070e0: 302c 2030 5d29 292c 0d0a 2020 2020 2020  0, 0])),..      
+000070f0: 2020 2020 2020 2020 2020 6e64 696d 3d33            ndim=3
+00007100: 2929 0d0a 2020 2020 2020 2020 7365 6c65  ))..        sele
+00007110: 6374 5f76 6f78 656c 7320 3d20 542e 696e  ct_voxels = T.in
+00007120: 635f 7375 6274 656e 736f 7228 7365 6c65  c_subtensor(sele
+00007130: 6374 5f76 6f78 656c 735b 3a2d 312c 203a  ct_voxels[:-1, :
+00007140: 2c20 3a5d 2c0d 0a20 2020 2020 2020 2020  , :],..         
+00007150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007160: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00007170: 656c 6563 745f 6564 6765 735f 6469 725b  elect_edges_dir[
+00007180: 305d 2e72 6573 6861 7065 2828 0d0a 2020  0].reshape((..  
+00007190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000071a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000071b0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+000071c0: 6c66 2e72 6567 756c 6172 5f67 7269 645f  lf.regular_grid_
+000071d0: 7265 7320 2d20 6e70 2e61 7272 6179 280d  res - np.array(.
 000071e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
 000071f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007200: 2020 2020 2020 2020 2073 656c 6563 745f           select_
-00007210: 6564 6765 735f 6469 725b 305d 2e72 6573  edges_dir[0].res
-00007220: 6861 7065 2828 0d0a 2020 2020 2020 2020  hape((..        
+00007200: 2020 2020 2020 2020 2020 2020 205b 312c               [1,
+00007210: 2030 2c0d 0a20 2020 2020 2020 2020 2020   0,..           
+00007220: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00007230: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007250: 2020 2020 2020 2020 7365 6c66 2e72 6567          self.reg
-00007260: 756c 6172 5f67 7269 645f 7265 7320 2d20  ular_grid_res - 
-00007270: 6e70 2e61 7272 6179 280d 0a20 2020 2020  np.array(..     
-00007280: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000072a0: 2020 2020 2020 205b 312c 2030 2c0d 0a20         [1, 0,.. 
-000072b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000072c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000072d0: 2020 2020 2020 2020 2020 2020 305d 2929              0]))
-000072e0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-000072f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007300: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-00007310: 6469 6d3d 3329 290d 0a0d 0a20 2020 2020  dim=3))....     
-00007320: 2020 2073 656c 6563 745f 766f 7865 6c73     select_voxels
-00007330: 203d 2054 2e69 6e63 5f73 7562 7465 6e73   = T.inc_subtens
-00007340: 6f72 2873 656c 6563 745f 766f 7865 6c73  or(select_voxels
-00007350: 5b3a 2c20 313a 2c20 3a5d 2c0d 0a20 2020  [:, 1:, :],..   
+00007240: 2020 305d 2929 2c0d 0a20 2020 2020 2020    0])),..       
+00007250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007270: 2020 2020 206e 6469 6d3d 3329 290d 0a0d       ndim=3))...
+00007280: 0a20 2020 2020 2020 2073 656c 6563 745f  .        select_
+00007290: 766f 7865 6c73 203d 2054 2e69 6e63 5f73  voxels = T.inc_s
+000072a0: 7562 7465 6e73 6f72 2873 656c 6563 745f  ubtensor(select_
+000072b0: 766f 7865 6c73 5b3a 2c20 313a 2c20 3a5d  voxels[:, 1:, :]
+000072c0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+000072d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000072e0: 2020 2020 2020 2020 2020 2073 656c 6563             selec
+000072f0: 745f 6564 6765 735f 6469 725b 315d 2e72  t_edges_dir[1].r
+00007300: 6573 6861 7065 2828 0d0a 2020 2020 2020  eshape((..      
+00007310: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007320: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007330: 2020 2020 2020 2020 2020 7365 6c66 2e72            self.r
+00007340: 6567 756c 6172 5f67 7269 645f 7265 7320  egular_grid_res 
+00007350: 2d20 6e70 2e61 7272 6179 280d 0a20 2020  - np.array(..   
 00007360: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00007370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007380: 2020 2020 2073 656c 6563 745f 6564 6765       select_edge
-00007390: 735f 6469 725b 315d 2e72 6573 6861 7065  s_dir[1].reshape
-000073a0: 2828 0d0a 2020 2020 2020 2020 2020 2020  ((..            
-000073b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000073c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000073d0: 2020 2020 7365 6c66 2e72 6567 756c 6172      self.regular
-000073e0: 5f67 7269 645f 7265 7320 2d20 6e70 2e61  _grid_res - np.a
-000073f0: 7272 6179 280d 0a20 2020 2020 2020 2020  rray(..         
-00007400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007410: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007420: 2020 205b 302c 2031 2c0d 0a20 2020 2020     [0, 1,..     
-00007430: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007380: 2020 2020 2020 2020 205b 302c 2031 2c0d           [0, 1,.
+00007390: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000073a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000073b0: 2020 2020 2020 2020 2020 2020 2020 305d                0]
+000073c0: 2929 2c0d 0a20 2020 2020 2020 2020 2020  )),..           
+000073d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000073e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000073f0: 206e 6469 6d3d 3329 290d 0a20 2020 2020   ndim=3))..     
+00007400: 2020 2073 656c 6563 745f 766f 7865 6c73     select_voxels
+00007410: 203d 2054 2e69 6e63 5f73 7562 7465 6e73   = T.inc_subtens
+00007420: 6f72 2873 656c 6563 745f 766f 7865 6c73  or(select_voxels
+00007430: 5b3a 2c20 3a2d 312c 203a 5d2c 0d0a 2020  [:, :-1, :],..  
 00007440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007450: 2020 2020 2020 2020 305d 2929 2c0d 0a20          0])),.. 
-00007460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007470: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007480: 2020 2020 2020 2020 2020 206e 6469 6d3d             ndim=
-00007490: 3329 290d 0a20 2020 2020 2020 2073 656c  3))..        sel
-000074a0: 6563 745f 766f 7865 6c73 203d 2054 2e69  ect_voxels = T.i
-000074b0: 6e63 5f73 7562 7465 6e73 6f72 2873 656c  nc_subtensor(sel
-000074c0: 6563 745f 766f 7865 6c73 5b3a 2c20 3a2d  ect_voxels[:, :-
-000074d0: 312c 203a 5d2c 0d0a 2020 2020 2020 2020  1, :],..        
+00007450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007460: 2020 2020 2020 7365 6c65 6374 5f65 6467        select_edg
+00007470: 6573 5f64 6972 5b31 5d2e 7265 7368 6170  es_dir[1].reshap
+00007480: 6528 280d 0a20 2020 2020 2020 2020 2020  e((..           
+00007490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000074a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000074b0: 2020 2020 2073 656c 662e 7265 6775 6c61       self.regula
+000074c0: 725f 6772 6964 5f72 6573 202d 206e 702e  r_grid_res - np.
+000074d0: 6172 7261 7928 0d0a 2020 2020 2020 2020  array(..        
 000074e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000074f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007500: 7365 6c65 6374 5f65 6467 6573 5f64 6972  select_edges_dir
-00007510: 5b31 5d2e 7265 7368 6170 6528 280d 0a20  [1].reshape((.. 
+00007500: 2020 2020 5b30 2c20 312c 0d0a 2020 2020      [0, 1,..    
+00007510: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00007520: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007530: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007540: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00007550: 656c 662e 7265 6775 6c61 725f 6772 6964  elf.regular_grid
-00007560: 5f72 6573 202d 206e 702e 6172 7261 7928  _res - np.array(
-00007570: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00007580: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007590: 2020 2020 2020 2020 2020 2020 2020 5b30                [0
-000075a0: 2c20 312c 0d0a 2020 2020 2020 2020 2020  , 1,..          
-000075b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007530: 2020 2020 2020 2020 2030 5d29 292c 0d0a           0])),..
+00007540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007560: 2020 2020 2020 2020 2020 2020 6e64 696d              ndim
+00007570: 3d33 2929 0d0a 0d0a 2020 2020 2020 2020  =3))....        
+00007580: 7365 6c65 6374 5f76 6f78 656c 7320 3d20  select_voxels = 
+00007590: 542e 696e 635f 7375 6274 656e 736f 7228  T.inc_subtensor(
+000075a0: 7365 6c65 6374 5f76 6f78 656c 735b 3a2c  select_voxels[:,
+000075b0: 203a 2c20 313a 5d2c 0d0a 2020 2020 2020   :, 1:],..      
 000075c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000075d0: 2020 2030 5d29 292c 0d0a 2020 2020 2020     0])),..      
-000075e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000075f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007600: 2020 2020 2020 6e64 696d 3d33 2929 0d0a        ndim=3))..
-00007610: 0d0a 2020 2020 2020 2020 7365 6c65 6374  ..        select
-00007620: 5f76 6f78 656c 7320 3d20 542e 696e 635f  _voxels = T.inc_
-00007630: 7375 6274 656e 736f 7228 7365 6c65 6374  subtensor(select
-00007640: 5f76 6f78 656c 735b 3a2c 203a 2c20 313a  _voxels[:, :, 1:
-00007650: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+000075d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000075e0: 2020 7365 6c65 6374 5f65 6467 6573 5f64    select_edges_d
+000075f0: 6972 5b32 5d2e 7265 7368 6170 6528 280d  ir[2].reshape((.
+00007600: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007630: 2073 656c 662e 7265 6775 6c61 725f 6772   self.regular_gr
+00007640: 6964 5f72 6573 202d 206e 702e 6172 7261  id_res - np.arra
+00007650: 7928 0d0a 2020 2020 2020 2020 2020 2020  y(..            
 00007660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007670: 2020 2020 2020 2020 2020 2020 7365 6c65              sele
-00007680: 6374 5f65 6467 6573 5f64 6972 5b32 5d2e  ct_edges_dir[2].
-00007690: 7265 7368 6170 6528 280d 0a20 2020 2020  reshape((..     
+00007670: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007680: 5b30 2c20 302c 0d0a 2020 2020 2020 2020  [0, 0,..        
+00007690: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000076a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000076b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000076c0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-000076d0: 7265 6775 6c61 725f 6772 6964 5f72 6573  regular_grid_res
-000076e0: 202d 206e 702e 6172 7261 7928 0d0a 2020   - np.array(..  
-000076f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007700: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007710: 2020 2020 2020 2020 2020 5b30 2c20 302c            [0, 0,
-00007720: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00007730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007740: 2020 2020 2020 2020 2020 2020 2020 2031                 1
-00007750: 5d29 292c 0d0a 2020 2020 2020 2020 2020  ])),..          
-00007760: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007770: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007780: 2020 6e64 696d 3d33 2929 0d0a 2020 2020    ndim=3))..    
-00007790: 2020 2020 7365 6c65 6374 5f76 6f78 656c      select_voxel
-000077a0: 7320 3d20 542e 696e 635f 7375 6274 656e  s = T.inc_subten
-000077b0: 736f 7228 7365 6c65 6374 5f76 6f78 656c  sor(select_voxel
-000077c0: 735b 3a2c 203a 2c20 3a2d 315d 2c0d 0a20  s[:, :, :-1],.. 
+000076b0: 2020 2020 2031 5d29 292c 0d0a 2020 2020       1])),..    
+000076c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000076d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000076e0: 2020 2020 2020 2020 6e64 696d 3d33 2929          ndim=3))
+000076f0: 0d0a 2020 2020 2020 2020 7365 6c65 6374  ..        select
+00007700: 5f76 6f78 656c 7320 3d20 542e 696e 635f  _voxels = T.inc_
+00007710: 7375 6274 656e 736f 7228 7365 6c65 6374  subtensor(select
+00007720: 5f76 6f78 656c 735b 3a2c 203a 2c20 3a2d  _voxels[:, :, :-
+00007730: 315d 2c0d 0a20 2020 2020 2020 2020 2020  1],..           
+00007740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007750: 2020 2020 2020 2020 2020 2020 2073 656c               sel
+00007760: 6563 745f 6564 6765 735f 6469 725b 325d  ect_edges_dir[2]
+00007770: 2e72 6573 6861 7065 2828 0d0a 2020 2020  .reshape((..    
+00007780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000077a0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+000077b0: 2e72 6567 756c 6172 5f67 7269 645f 7265  .regular_grid_re
+000077c0: 7320 2d20 6e70 2e61 7272 6179 280d 0a20  s - np.array(.. 
 000077d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000077e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000077f0: 2020 2020 2020 2073 656c 6563 745f 6564         select_ed
-00007800: 6765 735f 6469 725b 325d 2e72 6573 6861  ges_dir[2].resha
-00007810: 7065 2828 0d0a 2020 2020 2020 2020 2020  pe((..          
+000077f0: 2020 2020 2020 2020 2020 205b 302c 2030             [0, 0
+00007800: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00007810: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00007820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007840: 2020 2020 2020 7365 6c66 2e72 6567 756c        self.regul
-00007850: 6172 5f67 7269 645f 7265 7320 2d20 6e70  ar_grid_res - np
-00007860: 2e61 7272 6179 280d 0a20 2020 2020 2020  .array(..       
-00007870: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007890: 2020 2020 205b 302c 2030 2c0d 0a20 2020       [0, 0,..   
-000078a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000078b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000078c0: 2020 2020 2020 2020 2020 315d 2929 2c0d            1])),.
-000078d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000078e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000078f0: 2020 2020 2020 2020 2020 2020 206e 6469               ndi
-00007900: 6d3d 3329 290d 0a0d 0a20 2020 2020 2020  m=3))....       
-00007910: 2075 765f 6c72 203d 2054 2e76 6572 7469   uv_lr = T.verti
-00007920: 6361 6c5f 7374 6163 6b28 7576 5f6c 2e72  cal_stack(uv_l.r
-00007930: 6573 6861 7065 2828 312c 202d 3129 292c  eshape((1, -1)),
-00007940: 2075 765f 722e 7265 7368 6170 6528 2831   uv_r.reshape((1
-00007950: 2c20 2d31 2929 290d 0a20 2020 2020 2020  , -1)))..       
-00007960: 2075 765f 6c72 5f62 6f75 6e64 6172 6965   uv_lr_boundarie
-00007970: 7320 3d20 7576 5f6c 725b 0d0a 2020 2020  s = uv_lr[..    
-00007980: 2020 2020 2020 2020 542e 7469 6c65 2873          T.tile(s
-00007990: 656c 6563 745f 6564 6765 732e 7265 7368  elect_edges.resh
-000079a0: 6170 6528 2831 2c20 2d31 2929 2c20 2832  ape((1, -1)), (2
-000079b0: 2c20 3129 295d 2e72 6573 6861 7065 2828  , 1))].reshape((
-000079c0: 322c 202d 3129 292e 540d 0a0d 0a20 2020  2, -1)).T....   
-000079d0: 2020 2020 2023 2061 203d 2054 2e62 696e       # a = T.bin
-000079e0: 636f 756e 7428 7576 5f6c 725f 626f 756e  count(uv_lr_boun
-000079f0: 6461 7269 6573 290d 0a20 2020 2020 2020  daries)..       
-00007a00: 2065 6467 6573 5f69 642c 2063 6f75 6e74   edges_id, count
-00007a10: 5f65 6467 6573 203d 2054 2e65 7874 7261  _edges = T.extra
-00007a20: 5f6f 7073 2e55 6e69 7175 6528 7265 7475  _ops.Unique(retu
-00007a30: 726e 5f63 6f75 6e74 733d 5472 7565 2c20  rn_counts=True, 
-00007a40: 6178 6973 3d30 2928 0d0a 2020 2020 2020  axis=0)(..      
-00007a50: 2020 2020 2020 7576 5f6c 725f 626f 756e        uv_lr_boun
-00007a60: 6461 7269 6573 290d 0a20 2020 2020 2020  daries)..       
-00007a70: 2072 6574 7572 6e20 7365 6c65 6374 5f76   return select_v
-00007a80: 6f78 656c 732c 2065 6467 6573 5f69 642c  oxels, edges_id,
-00007a90: 2063 6f75 6e74 5f65 6467 6573 0d0a 0d0a   count_edges....
-00007aa0: 2020 2020 6465 6620 6765 745f 626f 756e      def get_boun
-00007ab0: 6461 7279 5f76 6f78 656c 7328 7365 6c66  dary_voxels(self
-00007ac0: 2c20 756e 6971 7565 5f76 616c 293a 0d0a  , unique_val):..
-00007ad0: 2020 2020 2020 2020 7576 5f33 6420 3d20          uv_3d = 
-00007ae0: 542e 6361 7374 2854 2e72 6f75 6e64 2875  T.cast(T.round(u
-00007af0: 6e69 7175 655f 7661 6c5b 302c 203a 542e  nique_val[0, :T.
-00007b00: 7072 6f64 2873 656c 662e 7265 6775 6c61  prod(self.regula
-00007b10: 725f 6772 6964 5f72 6573 295d 2e72 6573  r_grid_res)].res
-00007b20: 6861 7065 280d 0a20 2020 2020 2020 2020  hape(..         
-00007b30: 2020 2073 656c 662e 7265 6775 6c61 725f     self.regular_
-00007b40: 6772 6964 5f72 6573 2c20 6e64 696d 3d33  grid_res, ndim=3
-00007b50: 2929 2c0d 0a20 2020 2020 2020 2020 2020  )),..           
-00007b60: 2027 696e 7433 3227 290d 0a0d 0a20 2020   'int32')....   
-00007b70: 2020 2020 2075 765f 6c20 3d20 542e 686f       uv_l = T.ho
-00007b80: 7269 7a6f 6e74 616c 5f73 7461 636b 2875  rizontal_stack(u
-00007b90: 765f 3364 5b31 3a2c 203a 2c20 3a5d 2e72  v_3d[1:, :, :].r
-00007ba0: 6573 6861 7065 2828 312c 202d 3129 292c  eshape((1, -1)),
-00007bb0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00007bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007bd0: 2020 2020 7576 5f33 645b 3a2c 2031 3a2c      uv_3d[:, 1:,
-00007be0: 203a 5d2e 7265 7368 6170 6528 2831 2c20   :].reshape((1, 
-00007bf0: 2d31 2929 2c0d 0a20 2020 2020 2020 2020  -1)),..         
-00007c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007c10: 2020 2020 2020 2020 2075 765f 3364 5b3a           uv_3d[:
-00007c20: 2c20 3a2c 2031 3a5d 2e72 6573 6861 7065  , :, 1:].reshape
-00007c30: 2828 312c 202d 3129 2929 0d0a 0d0a 2020  ((1, -1)))....  
-00007c40: 2020 2020 2020 7576 5f72 203d 2054 2e68        uv_r = T.h
-00007c50: 6f72 697a 6f6e 7461 6c5f 7374 6163 6b28  orizontal_stack(
-00007c60: 7576 5f33 645b 3a2d 312c 203a 2c20 3a5d  uv_3d[:-1, :, :]
-00007c70: 2e72 6573 6861 7065 2828 312c 202d 3129  .reshape((1, -1)
-00007c80: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
-00007c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007ca0: 2020 2020 2020 7576 5f33 645b 3a2c 203a        uv_3d[:, :
-00007cb0: 2d31 2c20 3a5d 2e72 6573 6861 7065 2828  -1, :].reshape((
-00007cc0: 312c 202d 3129 292c 0d0a 2020 2020 2020  1, -1)),..      
-00007cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007ce0: 2020 2020 2020 2020 2020 2020 7576 5f33              uv_3
-00007cf0: 645b 3a2c 203a 2c20 3a2d 315d 2e72 6573  d[:, :, :-1].res
-00007d00: 6861 7065 2828 312c 202d 3129 2929 0d0a  hape((1, -1)))..
-00007d10: 0d0a 2020 2020 2020 2020 7368 6966 7420  ..        shift 
-00007d20: 3d20 7576 5f6c 202d 2075 765f 720d 0a20  = uv_l - uv_r.. 
-00007d30: 2020 2020 2020 2073 656c 6563 745f 6564         select_ed
-00007d40: 6765 7320 3d20 542e 6e65 7128 7368 6966  ges = T.neq(shif
-00007d50: 742e 7265 7368 6170 6528 2831 2c20 2d31  t.reshape((1, -1
-00007d60: 2929 2c20 3029 0d0a 2020 2020 2020 2020  )), 0)..        
-00007d70: 7365 6c65 6374 5f65 6467 6573 5f64 6972  select_edges_dir
-00007d80: 203d 2073 656c 6563 745f 6564 6765 732e   = select_edges.
-00007d90: 7265 7368 6170 6528 2833 2c20 2d31 2929  reshape((3, -1))
-00007da0: 0d0a 0d0a 2020 2020 2020 2020 7365 6c65  ....        sele
-00007db0: 6374 5f76 6f78 656c 7320 3d20 542e 7a65  ct_voxels = T.ze
-00007dc0: 726f 735f 6c69 6b65 2875 765f 3364 290d  ros_like(uv_3d).
-00007dd0: 0a20 2020 2020 2020 2073 656c 6563 745f  .        select_
-00007de0: 766f 7865 6c73 203d 2054 2e69 6e63 5f73  voxels = T.inc_s
-00007df0: 7562 7465 6e73 6f72 2873 656c 6563 745f  ubtensor(select_
-00007e00: 766f 7865 6c73 5b31 3a2c 203a 2c20 3a5d  voxels[1:, :, :]
-00007e10: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00007830: 315d 2929 2c0d 0a20 2020 2020 2020 2020  1])),..         
+00007840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007850: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007860: 2020 206e 6469 6d3d 3329 290d 0a0d 0a20     ndim=3)).... 
+00007870: 2020 2020 2020 2075 765f 6c72 203d 2054         uv_lr = T
+00007880: 2e76 6572 7469 6361 6c5f 7374 6163 6b28  .vertical_stack(
+00007890: 7576 5f6c 2e72 6573 6861 7065 2828 312c  uv_l.reshape((1,
+000078a0: 202d 3129 292c 2075 765f 722e 7265 7368   -1)), uv_r.resh
+000078b0: 6170 6528 2831 2c20 2d31 2929 290d 0a20  ape((1, -1))).. 
+000078c0: 2020 2020 2020 2075 765f 6c72 5f62 6f75         uv_lr_bou
+000078d0: 6e64 6172 6965 7320 3d20 7576 5f6c 725b  ndaries = uv_lr[
+000078e0: 0d0a 2020 2020 2020 2020 2020 2020 542e  ..            T.
+000078f0: 7469 6c65 2873 656c 6563 745f 6564 6765  tile(select_edge
+00007900: 732e 7265 7368 6170 6528 2831 2c20 2d31  s.reshape((1, -1
+00007910: 2929 2c20 2832 2c20 3129 295d 2e72 6573  )), (2, 1))].res
+00007920: 6861 7065 2828 322c 202d 3129 292e 540d  hape((2, -1)).T.
+00007930: 0a0d 0a20 2020 2020 2020 2023 2061 203d  ...        # a =
+00007940: 2054 2e62 696e 636f 756e 7428 7576 5f6c   T.bincount(uv_l
+00007950: 725f 626f 756e 6461 7269 6573 290d 0a20  r_boundaries).. 
+00007960: 2020 2020 2020 2065 6467 6573 5f69 642c         edges_id,
+00007970: 2063 6f75 6e74 5f65 6467 6573 203d 2054   count_edges = T
+00007980: 2e65 7874 7261 5f6f 7073 2e55 6e69 7175  .extra_ops.Uniqu
+00007990: 6528 7265 7475 726e 5f63 6f75 6e74 733d  e(return_counts=
+000079a0: 5472 7565 2c20 6178 6973 3d30 2928 0d0a  True, axis=0)(..
+000079b0: 2020 2020 2020 2020 2020 2020 7576 5f6c              uv_l
+000079c0: 725f 626f 756e 6461 7269 6573 290d 0a20  r_boundaries).. 
+000079d0: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
+000079e0: 6c65 6374 5f76 6f78 656c 732c 2065 6467  lect_voxels, edg
+000079f0: 6573 5f69 642c 2063 6f75 6e74 5f65 6467  es_id, count_edg
+00007a00: 6573 0d0a 0d0a 2020 2020 6465 6620 6765  es....    def ge
+00007a10: 745f 626f 756e 6461 7279 5f76 6f78 656c  t_boundary_voxel
+00007a20: 7328 7365 6c66 2c20 756e 6971 7565 5f76  s(self, unique_v
+00007a30: 616c 293a 0d0a 2020 2020 2020 2020 7576  al):..        uv
+00007a40: 5f33 6420 3d20 542e 6361 7374 2854 2e72  _3d = T.cast(T.r
+00007a50: 6f75 6e64 2875 6e69 7175 655f 7661 6c5b  ound(unique_val[
+00007a60: 302c 203a 542e 7072 6f64 2873 656c 662e  0, :T.prod(self.
+00007a70: 7265 6775 6c61 725f 6772 6964 5f72 6573  regular_grid_res
+00007a80: 295d 2e72 6573 6861 7065 280d 0a20 2020  )].reshape(..   
+00007a90: 2020 2020 2020 2020 2073 656c 662e 7265           self.re
+00007aa0: 6775 6c61 725f 6772 6964 5f72 6573 2c20  gular_grid_res, 
+00007ab0: 6e64 696d 3d33 2929 2c0d 0a20 2020 2020  ndim=3)),..     
+00007ac0: 2020 2020 2020 2027 696e 7433 3227 290d         'int32').
+00007ad0: 0a0d 0a20 2020 2020 2020 2075 765f 6c20  ...        uv_l 
+00007ae0: 3d20 542e 686f 7269 7a6f 6e74 616c 5f73  = T.horizontal_s
+00007af0: 7461 636b 2875 765f 3364 5b31 3a2c 203a  tack(uv_3d[1:, :
+00007b00: 2c20 3a5d 2e72 6573 6861 7065 2828 312c  , :].reshape((1,
+00007b10: 202d 3129 292c 0d0a 2020 2020 2020 2020   -1)),..        
+00007b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007b30: 2020 2020 2020 2020 2020 7576 5f33 645b            uv_3d[
+00007b40: 3a2c 2031 3a2c 203a 5d2e 7265 7368 6170  :, 1:, :].reshap
+00007b50: 6528 2831 2c20 2d31 2929 2c0d 0a20 2020  e((1, -1)),..   
+00007b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007b70: 2020 2020 2020 2020 2020 2020 2020 2075                 u
+00007b80: 765f 3364 5b3a 2c20 3a2c 2031 3a5d 2e72  v_3d[:, :, 1:].r
+00007b90: 6573 6861 7065 2828 312c 202d 3129 2929  eshape((1, -1)))
+00007ba0: 0d0a 0d0a 2020 2020 2020 2020 7576 5f72  ....        uv_r
+00007bb0: 203d 2054 2e68 6f72 697a 6f6e 7461 6c5f   = T.horizontal_
+00007bc0: 7374 6163 6b28 7576 5f33 645b 3a2d 312c  stack(uv_3d[:-1,
+00007bd0: 203a 2c20 3a5d 2e72 6573 6861 7065 2828   :, :].reshape((
+00007be0: 312c 202d 3129 292c 0d0a 2020 2020 2020  1, -1)),..      
+00007bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007c00: 2020 2020 2020 2020 2020 2020 7576 5f33              uv_3
+00007c10: 645b 3a2c 203a 2d31 2c20 3a5d 2e72 6573  d[:, :-1, :].res
+00007c20: 6861 7065 2828 312c 202d 3129 292c 0d0a  hape((1, -1)),..
+00007c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007c50: 2020 7576 5f33 645b 3a2c 203a 2c20 3a2d    uv_3d[:, :, :-
+00007c60: 315d 2e72 6573 6861 7065 2828 312c 202d  1].reshape((1, -
+00007c70: 3129 2929 0d0a 0d0a 2020 2020 2020 2020  1)))....        
+00007c80: 7368 6966 7420 3d20 7576 5f6c 202d 2075  shift = uv_l - u
+00007c90: 765f 720d 0a20 2020 2020 2020 2073 656c  v_r..        sel
+00007ca0: 6563 745f 6564 6765 7320 3d20 542e 6e65  ect_edges = T.ne
+00007cb0: 7128 7368 6966 742e 7265 7368 6170 6528  q(shift.reshape(
+00007cc0: 2831 2c20 2d31 2929 2c20 3029 0d0a 2020  (1, -1)), 0)..  
+00007cd0: 2020 2020 2020 7365 6c65 6374 5f65 6467        select_edg
+00007ce0: 6573 5f64 6972 203d 2073 656c 6563 745f  es_dir = select_
+00007cf0: 6564 6765 732e 7265 7368 6170 6528 2833  edges.reshape((3
+00007d00: 2c20 2d31 2929 0d0a 0d0a 2020 2020 2020  , -1))....      
+00007d10: 2020 7365 6c65 6374 5f76 6f78 656c 7320    select_voxels 
+00007d20: 3d20 542e 7a65 726f 735f 6c69 6b65 2875  = T.zeros_like(u
+00007d30: 765f 3364 290d 0a20 2020 2020 2020 2073  v_3d)..        s
+00007d40: 656c 6563 745f 766f 7865 6c73 203d 2054  elect_voxels = T
+00007d50: 2e69 6e63 5f73 7562 7465 6e73 6f72 2873  .inc_subtensor(s
+00007d60: 656c 6563 745f 766f 7865 6c73 5b31 3a2c  elect_voxels[1:,
+00007d70: 203a 2c20 3a5d 2c0d 0a20 2020 2020 2020   :, :],..       
+00007d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007da0: 2073 656c 6563 745f 6564 6765 735f 6469   select_edges_di
+00007db0: 725b 305d 2e72 6573 6861 7065 2828 0d0a  r[0].reshape((..
+00007dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007df0: 7365 6c66 2e72 6567 756c 6172 5f67 7269  self.regular_gri
+00007e00: 645f 7265 7320 2d20 6e70 2e61 7272 6179  d_res - np.array
+00007e10: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
 00007e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007e30: 2020 2020 2020 2020 2020 2073 656c 6563             selec
-00007e40: 745f 6564 6765 735f 6469 725b 305d 2e72  t_edges_dir[0].r
-00007e50: 6573 6861 7065 2828 0d0a 2020 2020 2020  eshape((..      
+00007e30: 2020 2020 2020 2020 2020 2020 2020 205b                 [
+00007e40: 312c 2030 2c0d 0a20 2020 2020 2020 2020  1, 0,..         
+00007e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00007e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007e80: 2020 2020 2020 2020 2020 7365 6c66 2e72            self.r
-00007e90: 6567 756c 6172 5f67 7269 645f 7265 7320  egular_grid_res 
-00007ea0: 2d20 6e70 2e61 7272 6179 280d 0a20 2020  - np.array(..   
-00007eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007ed0: 2020 2020 2020 2020 205b 312c 2030 2c0d           [1, 0,.
-00007ee0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007f00: 2020 2020 2020 2020 2020 2020 2020 305d                0]
-00007f10: 2929 2c0d 0a20 2020 2020 2020 2020 2020  )),..           
-00007f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007f40: 206e 6469 6d3d 3329 290d 0a20 2020 2020   ndim=3))..     
-00007f50: 2020 2073 656c 6563 745f 766f 7865 6c73     select_voxels
-00007f60: 203d 2054 2e69 6e63 5f73 7562 7465 6e73   = T.inc_subtens
-00007f70: 6f72 2873 656c 6563 745f 766f 7865 6c73  or(select_voxels
-00007f80: 5b3a 2d31 2c20 3a2c 203a 5d2c 0d0a 2020  [:-1, :, :],..  
+00007e70: 2020 2020 305d 2929 2c0d 0a20 2020 2020      0])),..     
+00007e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007ea0: 2020 2020 2020 206e 6469 6d3d 3329 290d         ndim=3)).
+00007eb0: 0a20 2020 2020 2020 2073 656c 6563 745f  .        select_
+00007ec0: 766f 7865 6c73 203d 2054 2e69 6e63 5f73  voxels = T.inc_s
+00007ed0: 7562 7465 6e73 6f72 2873 656c 6563 745f  ubtensor(select_
+00007ee0: 766f 7865 6c73 5b3a 2d31 2c20 3a2c 203a  voxels[:-1, :, :
+00007ef0: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+00007f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007f10: 2020 2020 2020 2020 2020 2020 7365 6c65              sele
+00007f20: 6374 5f65 6467 6573 5f64 6972 5b30 5d2e  ct_edges_dir[0].
+00007f30: 7265 7368 6170 6528 280d 0a20 2020 2020  reshape((..     
+00007f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007f60: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00007f70: 7265 6775 6c61 725f 6772 6964 5f72 6573  regular_grid_res
+00007f80: 202d 206e 702e 6172 7261 7928 0d0a 2020   - np.array(..  
 00007f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00007fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007fb0: 2020 2020 2020 7365 6c65 6374 5f65 6467        select_edg
-00007fc0: 6573 5f64 6972 5b30 5d2e 7265 7368 6170  es_dir[0].reshap
-00007fd0: 6528 280d 0a20 2020 2020 2020 2020 2020  e((..           
-00007fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008000: 2020 2020 2073 656c 662e 7265 6775 6c61       self.regula
-00008010: 725f 6772 6964 5f72 6573 202d 206e 702e  r_grid_res - np.
-00008020: 6172 7261 7928 0d0a 2020 2020 2020 2020  array(..        
-00008030: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008040: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008050: 2020 2020 5b31 2c20 302c 0d0a 2020 2020      [1, 0,..    
-00008060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007fb0: 2020 2020 2020 2020 2020 5b31 2c20 302c            [1, 0,
+00007fc0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00007fd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007fe0: 2020 2020 2020 2020 2020 2020 2020 2030                 0
+00007ff0: 5d29 292c 0d0a 2020 2020 2020 2020 2020  ])),..          
+00008000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008020: 2020 6e64 696d 3d33 2929 0d0a 0d0a 2020    ndim=3))....  
+00008030: 2020 2020 2020 7365 6c65 6374 5f76 6f78        select_vox
+00008040: 656c 7320 3d20 542e 696e 635f 7375 6274  els = T.inc_subt
+00008050: 656e 736f 7228 7365 6c65 6374 5f76 6f78  ensor(select_vox
+00008060: 656c 735b 3a2c 2031 3a2c 203a 5d2c 0d0a  els[:, 1:, :],..
 00008070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008080: 2020 2020 2020 2020 2030 5d29 292c 0d0a           0])),..
-00008090: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000080a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000080b0: 2020 2020 2020 2020 2020 2020 6e64 696d              ndim
-000080c0: 3d33 2929 0d0a 0d0a 2020 2020 2020 2020  =3))....        
-000080d0: 7365 6c65 6374 5f76 6f78 656c 7320 3d20  select_voxels = 
-000080e0: 542e 696e 635f 7375 6274 656e 736f 7228  T.inc_subtensor(
-000080f0: 7365 6c65 6374 5f76 6f78 656c 735b 3a2c  select_voxels[:,
-00008100: 2031 3a2c 203a 5d2c 0d0a 2020 2020 2020   1:, :],..      
+00008080: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008090: 2020 2020 2020 2020 7365 6c65 6374 5f65          select_e
+000080a0: 6467 6573 5f64 6972 5b31 5d2e 7265 7368  dges_dir[1].resh
+000080b0: 6170 6528 280d 0a20 2020 2020 2020 2020  ape((..         
+000080c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000080d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000080e0: 2020 2020 2020 2073 656c 662e 7265 6775         self.regu
+000080f0: 6c61 725f 6772 6964 5f72 6573 202d 206e  lar_grid_res - n
+00008100: 702e 6172 7261 7928 0d0a 2020 2020 2020  p.array(..      
 00008110: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00008120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008130: 2020 7365 6c65 6374 5f65 6467 6573 5f64    select_edges_d
-00008140: 6972 5b31 5d2e 7265 7368 6170 6528 280d  ir[1].reshape((.
-00008150: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00008160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008180: 2073 656c 662e 7265 6775 6c61 725f 6772   self.regular_gr
-00008190: 6964 5f72 6573 202d 206e 702e 6172 7261  id_res - np.arra
-000081a0: 7928 0d0a 2020 2020 2020 2020 2020 2020  y(..            
-000081b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000081c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000081d0: 5b30 2c20 312c 0d0a 2020 2020 2020 2020  [0, 1,..        
-000081e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008130: 2020 2020 2020 5b30 2c20 312c 0d0a 2020        [0, 1,..  
+00008140: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008160: 2020 2020 2020 2020 2020 2030 5d29 292c             0])),
+00008170: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00008180: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008190: 2020 2020 2020 2020 2020 2020 2020 6e64                nd
+000081a0: 696d 3d33 2929 0d0a 2020 2020 2020 2020  im=3))..        
+000081b0: 7365 6c65 6374 5f76 6f78 656c 7320 3d20  select_voxels = 
+000081c0: 542e 696e 635f 7375 6274 656e 736f 7228  T.inc_subtensor(
+000081d0: 7365 6c65 6374 5f76 6f78 656c 735b 3a2c  select_voxels[:,
+000081e0: 203a 2d31 2c20 3a5d 2c0d 0a20 2020 2020   :-1, :],..     
 000081f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008200: 2020 2020 2030 5d29 292c 0d0a 2020 2020       0])),..    
-00008210: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008220: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008230: 2020 2020 2020 2020 6e64 696d 3d33 2929          ndim=3))
-00008240: 0d0a 2020 2020 2020 2020 7365 6c65 6374  ..        select
-00008250: 5f76 6f78 656c 7320 3d20 542e 696e 635f  _voxels = T.inc_
-00008260: 7375 6274 656e 736f 7228 7365 6c65 6374  subtensor(select
-00008270: 5f76 6f78 656c 735b 3a2c 203a 2d31 2c20  _voxels[:, :-1, 
-00008280: 3a5d 2c0d 0a20 2020 2020 2020 2020 2020  :],..           
+00008200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008210: 2020 2073 656c 6563 745f 6564 6765 735f     select_edges_
+00008220: 6469 725b 315d 2e72 6573 6861 7065 2828  dir[1].reshape((
+00008230: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00008240: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008260: 2020 7365 6c66 2e72 6567 756c 6172 5f67    self.regular_g
+00008270: 7269 645f 7265 7320 2d20 6e70 2e61 7272  rid_res - np.arr
+00008280: 6179 280d 0a20 2020 2020 2020 2020 2020  ay(..           
 00008290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000082a0: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-000082b0: 6563 745f 6564 6765 735f 6469 725b 315d  ect_edges_dir[1]
-000082c0: 2e72 6573 6861 7065 2828 0d0a 2020 2020  .reshape((..    
+000082a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000082b0: 205b 302c 2031 2c0d 0a20 2020 2020 2020   [0, 1,..       
+000082c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000082d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000082e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000082f0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00008300: 2e72 6567 756c 6172 5f67 7269 645f 7265  .regular_grid_re
-00008310: 7320 2d20 6e70 2e61 7272 6179 280d 0a20  s - np.array(.. 
-00008320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008340: 2020 2020 2020 2020 2020 205b 302c 2031             [0, 1
-00008350: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00008360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000082e0: 2020 2020 2020 305d 2929 2c0d 0a20 2020        0])),..   
+000082f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008310: 2020 2020 2020 2020 206e 6469 6d3d 3329           ndim=3)
+00008320: 290d 0a0d 0a20 2020 2020 2020 2073 656c  )....        sel
+00008330: 6563 745f 766f 7865 6c73 203d 2054 2e69  ect_voxels = T.i
+00008340: 6e63 5f73 7562 7465 6e73 6f72 2873 656c  nc_subtensor(sel
+00008350: 6563 745f 766f 7865 6c73 5b3a 2c20 3a2c  ect_voxels[:, :,
+00008360: 2031 3a5d 2c0d 0a20 2020 2020 2020 2020   1:],..         
 00008370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008380: 305d 2929 2c0d 0a20 2020 2020 2020 2020  0])),..         
-00008390: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000083a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000083b0: 2020 206e 6469 6d3d 3329 290d 0a0d 0a20     ndim=3)).... 
-000083c0: 2020 2020 2020 2073 656c 6563 745f 766f         select_vo
-000083d0: 7865 6c73 203d 2054 2e69 6e63 5f73 7562  xels = T.inc_sub
-000083e0: 7465 6e73 6f72 2873 656c 6563 745f 766f  tensor(select_vo
-000083f0: 7865 6c73 5b3a 2c20 3a2c 2031 3a5d 2c0d  xels[:, :, 1:],.
+00008380: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00008390: 656c 6563 745f 6564 6765 735f 6469 725b  elect_edges_dir[
+000083a0: 325d 2e72 6573 6861 7065 2828 0d0a 2020  2].reshape((..  
+000083b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000083c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000083d0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+000083e0: 6c66 2e72 6567 756c 6172 5f67 7269 645f  lf.regular_grid_
+000083f0: 7265 7320 2d20 6e70 2e61 7272 6179 280d  res - np.array(.
 00008400: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
 00008410: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008420: 2020 2020 2020 2020 2073 656c 6563 745f           select_
-00008430: 6564 6765 735f 6469 725b 325d 2e72 6573  edges_dir[2].res
-00008440: 6861 7065 2828 0d0a 2020 2020 2020 2020  hape((..        
+00008420: 2020 2020 2020 2020 2020 2020 205b 302c               [0,
+00008430: 2030 2c0d 0a20 2020 2020 2020 2020 2020   0,..           
+00008440: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00008450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008470: 2020 2020 2020 2020 7365 6c66 2e72 6567          self.reg
-00008480: 756c 6172 5f67 7269 645f 7265 7320 2d20  ular_grid_res - 
-00008490: 6e70 2e61 7272 6179 280d 0a20 2020 2020  np.array(..     
-000084a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000084b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000084c0: 2020 2020 2020 205b 302c 2030 2c0d 0a20         [0, 0,.. 
-000084d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000084e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000084f0: 2020 2020 2020 2020 2020 2020 315d 2929              1]))
-00008500: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00008510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008520: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-00008530: 6469 6d3d 3329 290d 0a20 2020 2020 2020  dim=3))..       
-00008540: 2073 656c 6563 745f 766f 7865 6c73 203d   select_voxels =
-00008550: 2054 2e69 6e63 5f73 7562 7465 6e73 6f72   T.inc_subtensor
-00008560: 2873 656c 6563 745f 766f 7865 6c73 5b3a  (select_voxels[:
-00008570: 2c20 3a2c 203a 2d31 5d2c 0d0a 2020 2020  , :, :-1],..    
+00008460: 2020 315d 2929 2c0d 0a20 2020 2020 2020    1])),..       
+00008470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008480: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008490: 2020 2020 206e 6469 6d3d 3329 290d 0a20       ndim=3)).. 
+000084a0: 2020 2020 2020 2073 656c 6563 745f 766f         select_vo
+000084b0: 7865 6c73 203d 2054 2e69 6e63 5f73 7562  xels = T.inc_sub
+000084c0: 7465 6e73 6f72 2873 656c 6563 745f 766f  tensor(select_vo
+000084d0: 7865 6c73 5b3a 2c20 3a2c 203a 2d31 5d2c  xels[:, :, :-1],
+000084e0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000084f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008500: 2020 2020 2020 2020 2020 7365 6c65 6374            select
+00008510: 5f65 6467 6573 5f64 6972 5b32 5d2e 7265  _edges_dir[2].re
+00008520: 7368 6170 6528 280d 0a20 2020 2020 2020  shape((..       
+00008530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008550: 2020 2020 2020 2020 2073 656c 662e 7265           self.re
+00008560: 6775 6c61 725f 6772 6964 5f72 6573 202d  gular_grid_res -
+00008570: 206e 702e 6172 7261 7928 0d0a 2020 2020   np.array(..    
 00008580: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00008590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000085a0: 2020 2020 7365 6c65 6374 5f65 6467 6573      select_edges
-000085b0: 5f64 6972 5b32 5d2e 7265 7368 6170 6528  _dir[2].reshape(
-000085c0: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-000085d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000085e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000085f0: 2020 2073 656c 662e 7265 6775 6c61 725f     self.regular_
-00008600: 6772 6964 5f72 6573 202d 206e 702e 6172  grid_res - np.ar
-00008610: 7261 7928 0d0a 2020 2020 2020 2020 2020  ray(..          
-00008620: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008630: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008640: 2020 5b30 2c20 302c 0d0a 2020 2020 2020    [0, 0,..      
-00008650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008670: 2020 2020 2020 2031 5d29 292c 0d0a 2020         1])),..  
-00008680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000086a0: 2020 2020 2020 2020 2020 6e64 696d 3d33            ndim=3
-000086b0: 2929 0d0a 0d0a 2020 2020 2020 2020 7265  ))....        re
-000086c0: 7475 726e 2073 656c 6563 745f 766f 7865  turn select_voxe
-000086d0: 6c73 0d0a 0d0a 2020 2020 2320 7265 6769  ls....    # regi
-000086e0: 6f6e 2047 656f 6d65 7472 790d 0a20 2020  on Geometry..   
-000086f0: 2064 6566 2072 6570 6561 745f 6c69 7374   def repeat_list
-00008700: 2873 656c 662c 2076 616c 2c20 725f 302c  (self, val, r_0,
-00008710: 2072 5f31 2c20 7265 7065 6174 6564 5f61   r_1, repeated_a
-00008720: 7272 6179 2c20 6e5f 636f 6c29 3a0d 0a20  rray, n_col):.. 
-00008730: 2020 2020 2020 2022 2222 0d0a 2020 2020         """..    
-00008740: 2020 2020 5265 7065 6174 2061 6e20 6172      Repeat an ar
-00008750: 7261 790d 0a0d 0a20 2020 2020 2020 2041  ray....        A
-00008760: 7267 733a 0d0a 2020 2020 2020 2020 2020  rgs:..          
-00008770: 2020 7661 6c3a 2065 6c65 6d65 6e74 206f    val: element o
-00008780: 7220 6c69 7374 2074 6861 7420 796f 7520  r list that you 
-00008790: 7761 6e74 2074 6f20 7265 7065 6174 0d0a  want to repeat..
-000087a0: 2020 2020 2020 2020 2020 2020 725f 303a              r_0:
-000087b0: 2069 6e69 7469 616c 2073 6c69 6369 6e67   initial slicing
-000087c0: 2070 6f73 6974 696f 6e20 6f6e 2074 6865   position on the
-000087d0: 2066 696e 616c 2061 7272 6179 0d0a 2020   final array..  
-000087e0: 2020 2020 2020 2020 2020 725f 313a 2066            r_1: f
-000087f0: 696e 616c 2073 6c69 6369 6e67 2070 6f73  inal slicing pos
-00008800: 6974 696f 6e20 6f6e 2074 6865 2066 696e  ition on the fin
-00008810: 616c 2061 7272 6179 0d0a 2020 2020 2020  al array..      
-00008820: 2020 2020 2020 7265 7065 6174 6564 5f61        repeated_a
-00008830: 7272 6179 3a20 6669 6e61 6c20 6172 7261  rray: final arra
-00008840: 790d 0a0d 0a20 2020 2020 2020 2052 6574  y....        Ret
-00008850: 7572 6e73 3a0d 0a20 2020 2020 2020 2020  urns:..         
-00008860: 2020 2066 696e 616c 2061 7272 6179 0d0a     final array..
-00008870: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-00008880: 2020 2020 2072 6570 6561 7465 645f 6172       repeated_ar
-00008890: 7261 7920 3d20 542e 7365 745f 7375 6274  ray = T.set_subt
-000088a0: 656e 736f 7228 7265 7065 6174 6564 5f61  ensor(repeated_a
-000088b0: 7272 6179 5b72 5f30 3a20 725f 315d 2c0d  rray[r_0: r_1],.
-000088c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000088d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000088e0: 2020 2020 2020 2020 2020 542e 616c 6c6f            T.allo
-000088f0: 6328 7661 6c2c 2072 5f31 202d 2072 5f30  c(val, r_1 - r_0
-00008900: 2c20 6e5f 636f 6c29 290d 0a20 2020 2020  , n_col))..     
-00008910: 2020 2072 6574 7572 6e20 7265 7065 6174     return repeat
-00008920: 6564 5f61 7272 6179 0d0a 0d0a 2020 2020  ed_array....    
-00008930: 6465 6620 7365 745f 7265 7374 5f72 6566  def set_rest_ref
-00008940: 5f6d 6174 7269 7828 7365 6c66 2c20 6e75  _matrix(self, nu
-00008950: 6d62 6572 5f6f 665f 706f 696e 7473 5f70  mber_of_points_p
-00008960: 6572 5f73 7572 6661 6365 293a 0d0a 2020  er_surface):..  
-00008970: 2020 2020 2020 7265 665f 706f 7369 7469        ref_positi
-00008980: 6f6e 7320 3d20 542e 6375 6d73 756d 280d  ons = T.cumsum(.
-00008990: 0a20 2020 2020 2020 2020 2020 2054 2e63  .            T.c
-000089a0: 6f6e 6361 7465 6e61 7465 2828 542e 7374  oncatenate((T.st
-000089b0: 6163 6b28 5b30 5d29 2c20 6e75 6d62 6572  ack([0]), number
-000089c0: 5f6f 665f 706f 696e 7473 5f70 6572 5f73  _of_points_per_s
-000089d0: 7572 6661 6365 5b3a 2d31 5d20 2b20 3129  urface[:-1] + 1)
-000089e0: 2929 0d0a 2020 2020 2020 2020 6375 6d5f  ))..        cum_
-000089f0: 7265 7020 3d20 542e 6375 6d73 756d 280d  rep = T.cumsum(.
-00008a00: 0a20 2020 2020 2020 2020 2020 2054 2e63  .            T.c
-00008a10: 6f6e 6361 7465 6e61 7465 2828 542e 7374  oncatenate((T.st
-00008a20: 6163 6b28 5b30 5d29 2c20 6e75 6d62 6572  ack([0]), number
-00008a30: 5f6f 665f 706f 696e 7473 5f70 6572 5f73  _of_points_per_s
-00008a40: 7572 6661 6365 2929 290d 0a0d 0a20 2020  urface)))....   
-00008a50: 2020 2020 2072 6566 5f70 6f69 6e74 735f       ref_points_
-00008a60: 696e 6974 203d 2054 2e7a 6572 6f73 2828  init = T.zeros((
-00008a70: 6375 6d5f 7265 705b 2d31 5d2c 2033 2929  cum_rep[-1], 3))
-00008a80: 0d0a 2020 2020 2020 2020 7265 665f 706f  ..        ref_po
-00008a90: 696e 7473 5f6c 6f6f 702c 2075 7064 6174  ints_loop, updat
-00008aa0: 655f 203d 2074 6865 616e 6f2e 7363 616e  e_ = theano.scan
-00008ab0: 2873 656c 662e 7265 7065 6174 5f6c 6973  (self.repeat_lis
-00008ac0: 742c 0d0a 2020 2020 2020 2020 2020 2020  t,..            
+000085a0: 2020 2020 2020 2020 5b30 2c20 302c 0d0a          [0, 0,..
+000085b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000085c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000085d0: 2020 2020 2020 2020 2020 2020 2031 5d29               1])
+000085e0: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
+000085f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008610: 6e64 696d 3d33 2929 0d0a 0d0a 2020 2020  ndim=3))....    
+00008620: 2020 2020 7265 7475 726e 2073 656c 6563      return selec
+00008630: 745f 766f 7865 6c73 0d0a 0d0a 2020 2020  t_voxels....    
+00008640: 2320 7265 6769 6f6e 2047 656f 6d65 7472  # region Geometr
+00008650: 790d 0a20 2020 2064 6566 2072 6570 6561  y..    def repea
+00008660: 745f 6c69 7374 2873 656c 662c 2076 616c  t_list(self, val
+00008670: 2c20 725f 302c 2072 5f31 2c20 7265 7065  , r_0, r_1, repe
+00008680: 6174 6564 5f61 7272 6179 2c20 6e5f 636f  ated_array, n_co
+00008690: 6c29 3a0d 0a20 2020 2020 2020 2022 2222  l):..        """
+000086a0: 0d0a 2020 2020 2020 2020 5265 7065 6174  ..        Repeat
+000086b0: 2061 6e20 6172 7261 790d 0a0d 0a20 2020   an array....   
+000086c0: 2020 2020 2041 7267 733a 0d0a 2020 2020       Args:..    
+000086d0: 2020 2020 2020 2020 7661 6c3a 2065 6c65          val: ele
+000086e0: 6d65 6e74 206f 7220 6c69 7374 2074 6861  ment or list tha
+000086f0: 7420 796f 7520 7761 6e74 2074 6f20 7265  t you want to re
+00008700: 7065 6174 0d0a 2020 2020 2020 2020 2020  peat..          
+00008710: 2020 725f 303a 2069 6e69 7469 616c 2073    r_0: initial s
+00008720: 6c69 6369 6e67 2070 6f73 6974 696f 6e20  licing position 
+00008730: 6f6e 2074 6865 2066 696e 616c 2061 7272  on the final arr
+00008740: 6179 0d0a 2020 2020 2020 2020 2020 2020  ay..            
+00008750: 725f 313a 2066 696e 616c 2073 6c69 6369  r_1: final slici
+00008760: 6e67 2070 6f73 6974 696f 6e20 6f6e 2074  ng position on t
+00008770: 6865 2066 696e 616c 2061 7272 6179 0d0a  he final array..
+00008780: 2020 2020 2020 2020 2020 2020 7265 7065              repe
+00008790: 6174 6564 5f61 7272 6179 3a20 6669 6e61  ated_array: fina
+000087a0: 6c20 6172 7261 790d 0a0d 0a20 2020 2020  l array....     
+000087b0: 2020 2052 6574 7572 6e73 3a0d 0a20 2020     Returns:..   
+000087c0: 2020 2020 2020 2020 2066 696e 616c 2061           final a
+000087d0: 7272 6179 0d0a 2020 2020 2020 2020 2222  rray..        ""
+000087e0: 220d 0a20 2020 2020 2020 2072 6570 6561  "..        repea
+000087f0: 7465 645f 6172 7261 7920 3d20 542e 7365  ted_array = T.se
+00008800: 745f 7375 6274 656e 736f 7228 7265 7065  t_subtensor(repe
+00008810: 6174 6564 5f61 7272 6179 5b72 5f30 3a20  ated_array[r_0: 
+00008820: 725f 315d 2c0d 0a20 2020 2020 2020 2020  r_1],..         
+00008830: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008850: 542e 616c 6c6f 6328 7661 6c2c 2072 5f31  T.alloc(val, r_1
+00008860: 202d 2072 5f30 2c20 6e5f 636f 6c29 290d   - r_0, n_col)).
+00008870: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00008880: 7265 7065 6174 6564 5f61 7272 6179 0d0a  repeated_array..
+00008890: 0d0a 2020 2020 6465 6620 7365 745f 7265  ..    def set_re
+000088a0: 7374 5f72 6566 5f6d 6174 7269 7828 7365  st_ref_matrix(se
+000088b0: 6c66 2c20 6e75 6d62 6572 5f6f 665f 706f  lf, number_of_po
+000088c0: 696e 7473 5f70 6572 5f73 7572 6661 6365  ints_per_surface
+000088d0: 293a 0d0a 2020 2020 2020 2020 7265 665f  ):..        ref_
+000088e0: 706f 7369 7469 6f6e 7320 3d20 542e 6375  positions = T.cu
+000088f0: 6d73 756d 280d 0a20 2020 2020 2020 2020  msum(..         
+00008900: 2020 2054 2e63 6f6e 6361 7465 6e61 7465     T.concatenate
+00008910: 2828 542e 7374 6163 6b28 5b30 5d29 2c20  ((T.stack([0]), 
+00008920: 6e75 6d62 6572 5f6f 665f 706f 696e 7473  number_of_points
+00008930: 5f70 6572 5f73 7572 6661 6365 5b3a 2d31  _per_surface[:-1
+00008940: 5d20 2b20 3129 2929 0d0a 2020 2020 2020  ] + 1)))..      
+00008950: 2020 6375 6d5f 7265 7020 3d20 542e 6375    cum_rep = T.cu
+00008960: 6d73 756d 280d 0a20 2020 2020 2020 2020  msum(..         
+00008970: 2020 2054 2e63 6f6e 6361 7465 6e61 7465     T.concatenate
+00008980: 2828 542e 7374 6163 6b28 5b30 5d29 2c20  ((T.stack([0]), 
+00008990: 6e75 6d62 6572 5f6f 665f 706f 696e 7473  number_of_points
+000089a0: 5f70 6572 5f73 7572 6661 6365 2929 290d  _per_surface))).
+000089b0: 0a0d 0a20 2020 2020 2020 2072 6566 5f70  ...        ref_p
+000089c0: 6f69 6e74 735f 696e 6974 203d 2054 2e7a  oints_init = T.z
+000089d0: 6572 6f73 2828 6375 6d5f 7265 705b 2d31  eros((cum_rep[-1
+000089e0: 5d2c 2033 2929 0d0a 2020 2020 2020 2020  ], 3))..        
+000089f0: 7265 665f 706f 696e 7473 5f6c 6f6f 702c  ref_points_loop,
+00008a00: 2075 7064 6174 655f 203d 2061 6573 6172   update_ = aesar
+00008a10: 612e 7363 616e 2873 656c 662e 7265 7065  a.scan(self.repe
+00008a20: 6174 5f6c 6973 742c 0d0a 2020 2020 2020  at_list,..      
+00008a30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008a50: 2020 2020 2020 2020 206f 7574 7075 7473           outputs
+00008a60: 5f69 6e66 6f3d 5b72 6566 5f70 6f69 6e74  _info=[ref_point
+00008a70: 735f 696e 6974 5d2c 0d0a 2020 2020 2020  s_init],..      
+00008a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008aa0: 2020 2020 2020 2020 2073 6571 7565 6e63           sequenc
+00008ab0: 6573 3d5b 7365 6c66 2e73 7572 6661 6365  es=[self.surface
+00008ac0: 5f70 6f69 6e74 735f 616c 6c5b 0d0a 2020  _points_all[..  
 00008ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00008ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008af0: 2020 206f 7574 7075 7473 5f69 6e66 6f3d     outputs_info=
-00008b00: 5b72 6566 5f70 6f69 6e74 735f 696e 6974  [ref_points_init
-00008b10: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+00008af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008b00: 2020 2020 2020 2020 2020 2020 7265 665f              ref_
+00008b10: 706f 7369 7469 6f6e 735d 2c0d 0a20 2020  positions],..   
 00008b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00008b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008b40: 2020 2073 6571 7565 6e63 6573 3d5b 7365     sequences=[se
-00008b50: 6c66 2e73 7572 6661 6365 5f70 6f69 6e74  lf.surface_point
-00008b60: 735f 616c 6c5b 0d0a 2020 2020 2020 2020  s_all[..        
+00008b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008b50: 2020 2020 2020 2064 6963 7428 696e 7075         dict(inpu
+00008b60: 743d 6375 6d5f 7265 702c 0d0a 2020 2020  t=cum_rep,..    
 00008b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00008b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00008b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008ba0: 2020 2020 2020 7265 665f 706f 7369 7469        ref_positi
-00008bb0: 6f6e 735d 2c0d 0a20 2020 2020 2020 2020  ons],..         
+00008ba0: 2020 2020 2020 2020 2020 2074 6170 733d             taps=
+00008bb0: 5b30 2c20 315d 295d 2c0d 0a20 2020 2020  [0, 1])],..     
 00008bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00008bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008bf0: 2064 6963 7428 696e 7075 743d 6375 6d5f   dict(input=cum_
-00008c00: 7265 702c 0d0a 2020 2020 2020 2020 2020  rep,..          
+00008be0: 2020 2020 2020 2020 2020 6e6f 6e5f 7365            non_se
+00008bf0: 7175 656e 6365 733d 5b54 2e61 735f 7465  quences=[T.as_te
+00008c00: 6e73 6f72 2833 295d 2c0d 0a0d 0a20 2020  nsor(3)],....   
 00008c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00008c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008c40: 2020 2020 2074 6170 733d 5b30 2c20 315d       taps=[0, 1]
-00008c50: 295d 2c0d 0a20 2020 2020 2020 2020 2020  )],..           
-00008c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008c80: 2020 2020 6e6f 6e5f 7365 7175 656e 6365      non_sequence
-00008c90: 733d 5b54 2e61 735f 7465 6e73 6f72 2833  s=[T.as_tensor(3
-00008ca0: 295d 2c0d 0a0d 0a20 2020 2020 2020 2020  )],....         
-00008cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008cd0: 2020 2020 2020 7265 7475 726e 5f6c 6973        return_lis
-00008ce0: 743d 4661 6c73 6529 0d0a 0d0a 2020 2020  t=False)....    
-00008cf0: 2020 2020 2320 2020 7265 665f 706f 696e      #   ref_poin
-00008d00: 7473 5f6c 6f6f 7020 3d20 7468 6561 6e6f  ts_loop = theano
-00008d10: 2e70 7269 6e74 696e 672e 5072 696e 7428  .printing.Print(
-00008d20: 276c 6f6f 7027 2928 7265 665f 706f 696e  'loop')(ref_poin
-00008d30: 7473 5f6c 6f6f 7029 0d0a 2020 2020 2020  ts_loop)..      
-00008d40: 2020 7265 665f 706f 696e 7473 203d 2072    ref_points = r
-00008d50: 6566 5f70 6f69 6e74 735f 6c6f 6f70 5b2d  ef_points_loop[-
-00008d60: 315d 0d0a 2020 2020 2020 2020 2320 2072  1]..        #  r
-00008d70: 6566 5f70 6f69 6e74 7320 3d20 542e 7265  ef_points = T.re
-00008d80: 7065 6174 2873 656c 662e 7375 7266 6163  peat(self.surfac
-00008d90: 655f 706f 696e 7473 5f61 6c6c 5b72 6566  e_points_all[ref
-00008da0: 5f70 6f73 6974 696f 6e73 5d2c 206e 756d  _positions], num
-00008db0: 6265 725f 6f66 5f70 6f69 6e74 735f 7065  ber_of_points_pe
-00008dc0: 725f 7375 7266 6163 652c 2061 7869 733d  r_surface, axis=
-00008dd0: 3029 0d0a 0d0a 2020 2020 2020 2020 7265  0)....        re
-00008de0: 7374 5f6d 6173 6b20 3d20 542e 6f6e 6573  st_mask = T.ones
-00008df0: 2854 2e73 7461 636b 285b 7365 6c66 2e73  (T.stack([self.s
-00008e00: 7572 6661 6365 5f70 6f69 6e74 735f 616c  urface_points_al
-00008e10: 6c2e 7368 6170 655b 305d 5d29 2c0d 0a20  l.shape[0]]),.. 
-00008e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008e30: 2020 2020 2020 2020 2020 6474 7970 653d            dtype=
-00008e40: 2769 6e74 3136 2729 0d0a 2020 2020 2020  'int16')..      
-00008e50: 2020 7265 7374 5f6d 6173 6b20 3d20 542e    rest_mask = T.
-00008e60: 7365 745f 7375 6274 656e 736f 7228 7265  set_subtensor(re
-00008e70: 7374 5f6d 6173 6b5b 7265 665f 706f 7369  st_mask[ref_posi
-00008e80: 7469 6f6e 735d 2c20 3029 0d0a 2020 2020  tions], 0)..    
-00008e90: 2020 2020 7265 7374 5f6d 6173 6b20 3d20      rest_mask = 
-00008ea0: 542e 6e6f 6e7a 6572 6f28 7265 7374 5f6d  T.nonzero(rest_m
-00008eb0: 6173 6b29 5b30 5d0d 0a20 2020 2020 2020  ask)[0]..       
-00008ec0: 2072 6573 745f 706f 696e 7473 203d 2073   rest_points = s
-00008ed0: 656c 662e 7375 7266 6163 655f 706f 696e  elf.surface_poin
-00008ee0: 7473 5f61 6c6c 5b72 6573 745f 6d61 736b  ts_all[rest_mask
-00008ef0: 5d0d 0a20 2020 2020 2020 2072 6574 7572  ]..        retur
-00008f00: 6e20 5b72 6566 5f70 6f69 6e74 732c 2072  n [ref_points, r
-00008f10: 6573 745f 706f 696e 7473 2c20 7265 665f  est_points, ref_
-00008f20: 706f 7369 7469 6f6e 732c 2072 6573 745f  positions, rest_
-00008f30: 6d61 736b 5d0d 0a0d 0a20 2020 2064 6566  mask]....    def
-00008f40: 2073 6574 5f6e 7567 6765 745f 7375 7266   set_nugget_surf
-00008f50: 6163 655f 706f 696e 7473 2873 656c 662c  ace_points(self,
-00008f60: 2072 6566 5f70 6f73 6974 696f 6e73 2c20   ref_positions, 
-00008f70: 7265 7374 5f6d 6173 6b2c 0d0a 2020 2020  rest_mask,..    
-00008f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008f90: 2020 2020 2020 2020 2020 2020 2020 6e75                nu
-00008fa0: 6d62 6572 5f6f 665f 706f 696e 7473 5f70  mber_of_points_p
-00008fb0: 6572 5f73 7572 6661 6365 293a 0d0a 2020  er_surface):..  
-00008fc0: 2020 2020 2020 2320 7265 665f 6e75 6767        # ref_nugg
-00008fd0: 6574 203d 2054 2e72 6570 6561 7428 7365  et = T.repeat(se
-00008fe0: 6c66 2e6e 7567 6765 745f 6566 6665 6374  lf.nugget_effect
-00008ff0: 5f73 6361 6c61 725f 545b 7265 665f 706f  _scalar_T[ref_po
-00009000: 7369 7469 6f6e 735d 2c20 6e75 6d62 6572  sitions], number
-00009010: 5f6f 665f 706f 696e 7473 5f70 6572 5f73  _of_points_per_s
-00009020: 7572 6661 6365 290d 0a20 2020 2020 2020  urface)..       
-00009030: 2063 756d 5f72 6570 203d 2054 2e63 756d   cum_rep = T.cum
-00009040: 7375 6d28 0d0a 2020 2020 2020 2020 2020  sum(..          
-00009050: 2020 542e 636f 6e63 6174 656e 6174 6528    T.concatenate(
-00009060: 2854 2e73 7461 636b 285b 305d 292c 206e  (T.stack([0]), n
-00009070: 756d 6265 725f 6f66 5f70 6f69 6e74 735f  umber_of_points_
-00009080: 7065 725f 7375 7266 6163 6529 2929 0d0a  per_surface)))..
-00009090: 2020 2020 2020 2020 7265 665f 6e75 6767          ref_nugg
-000090a0: 6574 5f69 6e69 7420 3d20 542e 7a65 726f  et_init = T.zero
-000090b0: 7328 2863 756d 5f72 6570 5b2d 315d 2c20  s((cum_rep[-1], 
-000090c0: 3129 290d 0a20 2020 2020 2020 2072 6566  1))..        ref
-000090d0: 5f6e 7567 6765 745f 6c6f 6f70 2c20 7570  _nugget_loop, up
-000090e0: 6461 7465 5f20 3d20 7468 6561 6e6f 2e73  date_ = theano.s
-000090f0: 6361 6e28 7365 6c66 2e72 6570 6561 745f  can(self.repeat_
-00009100: 6c69 7374 2c0d 0a20 2020 2020 2020 2020  list,..         
+00008c30: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00008c40: 726e 5f6c 6973 743d 4661 6c73 6529 0d0a  rn_list=False)..
+00008c50: 0d0a 2020 2020 2020 2020 2320 2020 7265  ..        #   re
+00008c60: 665f 706f 696e 7473 5f6c 6f6f 7020 3d20  f_points_loop = 
+00008c70: 6165 7361 7261 2e70 7269 6e74 696e 672e  aesara.printing.
+00008c80: 5072 696e 7428 276c 6f6f 7027 2928 7265  Print('loop')(re
+00008c90: 665f 706f 696e 7473 5f6c 6f6f 7029 0d0a  f_points_loop)..
+00008ca0: 2020 2020 2020 2020 7265 665f 706f 696e          ref_poin
+00008cb0: 7473 203d 2072 6566 5f70 6f69 6e74 735f  ts = ref_points_
+00008cc0: 6c6f 6f70 5b2d 315d 0d0a 2020 2020 2020  loop[-1]..      
+00008cd0: 2020 2320 2072 6566 5f70 6f69 6e74 7320    #  ref_points 
+00008ce0: 3d20 542e 7265 7065 6174 2873 656c 662e  = T.repeat(self.
+00008cf0: 7375 7266 6163 655f 706f 696e 7473 5f61  surface_points_a
+00008d00: 6c6c 5b72 6566 5f70 6f73 6974 696f 6e73  ll[ref_positions
+00008d10: 5d2c 206e 756d 6265 725f 6f66 5f70 6f69  ], number_of_poi
+00008d20: 6e74 735f 7065 725f 7375 7266 6163 652c  nts_per_surface,
+00008d30: 2061 7869 733d 3029 0d0a 0d0a 2020 2020   axis=0)....    
+00008d40: 2020 2020 7265 7374 5f6d 6173 6b20 3d20      rest_mask = 
+00008d50: 542e 6f6e 6573 2854 2e73 7461 636b 285b  T.ones(T.stack([
+00008d60: 7365 6c66 2e73 7572 6661 6365 5f70 6f69  self.surface_poi
+00008d70: 6e74 735f 616c 6c2e 7368 6170 655b 305d  nts_all.shape[0]
+00008d80: 5d29 2c0d 0a20 2020 2020 2020 2020 2020  ]),..           
+00008d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008da0: 6474 7970 653d 2769 6e74 3136 2729 0d0a  dtype='int16')..
+00008db0: 2020 2020 2020 2020 7265 7374 5f6d 6173          rest_mas
+00008dc0: 6b20 3d20 542e 7365 745f 7375 6274 656e  k = T.set_subten
+00008dd0: 736f 7228 7265 7374 5f6d 6173 6b5b 7265  sor(rest_mask[re
+00008de0: 665f 706f 7369 7469 6f6e 735d 2c20 3029  f_positions], 0)
+00008df0: 0d0a 2020 2020 2020 2020 7265 7374 5f6d  ..        rest_m
+00008e00: 6173 6b20 3d20 542e 6e6f 6e7a 6572 6f28  ask = T.nonzero(
+00008e10: 7265 7374 5f6d 6173 6b29 5b30 5d0d 0a20  rest_mask)[0].. 
+00008e20: 2020 2020 2020 2072 6573 745f 706f 696e         rest_poin
+00008e30: 7473 203d 2073 656c 662e 7375 7266 6163  ts = self.surfac
+00008e40: 655f 706f 696e 7473 5f61 6c6c 5b72 6573  e_points_all[res
+00008e50: 745f 6d61 736b 5d0d 0a20 2020 2020 2020  t_mask]..       
+00008e60: 2072 6574 7572 6e20 5b72 6566 5f70 6f69   return [ref_poi
+00008e70: 6e74 732c 2072 6573 745f 706f 696e 7473  nts, rest_points
+00008e80: 2c20 7265 665f 706f 7369 7469 6f6e 732c  , ref_positions,
+00008e90: 2072 6573 745f 6d61 736b 5d0d 0a0d 0a20   rest_mask].... 
+00008ea0: 2020 2064 6566 2073 6574 5f6e 7567 6765     def set_nugge
+00008eb0: 745f 7375 7266 6163 655f 706f 696e 7473  t_surface_points
+00008ec0: 2873 656c 662c 2072 6566 5f70 6f73 6974  (self, ref_posit
+00008ed0: 696f 6e73 2c20 7265 7374 5f6d 6173 6b2c  ions, rest_mask,
+00008ee0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00008ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008f00: 2020 2020 6e75 6d62 6572 5f6f 665f 706f      number_of_po
+00008f10: 696e 7473 5f70 6572 5f73 7572 6661 6365  ints_per_surface
+00008f20: 293a 0d0a 2020 2020 2020 2020 2320 7265  ):..        # re
+00008f30: 665f 6e75 6767 6574 203d 2054 2e72 6570  f_nugget = T.rep
+00008f40: 6561 7428 7365 6c66 2e6e 7567 6765 745f  eat(self.nugget_
+00008f50: 6566 6665 6374 5f73 6361 6c61 725f 545b  effect_scalar_T[
+00008f60: 7265 665f 706f 7369 7469 6f6e 735d 2c20  ref_positions], 
+00008f70: 6e75 6d62 6572 5f6f 665f 706f 696e 7473  number_of_points
+00008f80: 5f70 6572 5f73 7572 6661 6365 290d 0a20  _per_surface).. 
+00008f90: 2020 2020 2020 2063 756d 5f72 6570 203d         cum_rep =
+00008fa0: 2054 2e63 756d 7375 6d28 0d0a 2020 2020   T.cumsum(..    
+00008fb0: 2020 2020 2020 2020 542e 636f 6e63 6174          T.concat
+00008fc0: 656e 6174 6528 2854 2e73 7461 636b 285b  enate((T.stack([
+00008fd0: 305d 292c 206e 756d 6265 725f 6f66 5f70  0]), number_of_p
+00008fe0: 6f69 6e74 735f 7065 725f 7375 7266 6163  oints_per_surfac
+00008ff0: 6529 2929 0d0a 2020 2020 2020 2020 7265  e)))..        re
+00009000: 665f 6e75 6767 6574 5f69 6e69 7420 3d20  f_nugget_init = 
+00009010: 542e 7a65 726f 7328 2863 756d 5f72 6570  T.zeros((cum_rep
+00009020: 5b2d 315d 2c20 3129 290d 0a20 2020 2020  [-1], 1))..     
+00009030: 2020 2072 6566 5f6e 7567 6765 745f 6c6f     ref_nugget_lo
+00009040: 6f70 2c20 7570 6461 7465 5f20 3d20 6165  op, update_ = ae
+00009050: 7361 7261 2e73 6361 6e28 7365 6c66 2e72  sara.scan(self.r
+00009060: 6570 6561 745f 6c69 7374 2c0d 0a20 2020  epeat_list,..   
+00009070: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009080: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009090: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
+000090a0: 7574 735f 696e 666f 3d5b 7265 665f 6e75  uts_info=[ref_nu
+000090b0: 6767 6574 5f69 6e69 745d 2c0d 0a20 2020  gget_init],..   
+000090c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000090d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000090e0: 2020 2020 2020 2020 2020 2020 7365 7175              sequ
+000090f0: 656e 6365 733d 5b0d 0a20 2020 2020 2020  ences=[..       
+00009100: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00009110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009130: 2020 2020 2020 6f75 7470 7574 735f 696e        outputs_in
-00009140: 666f 3d5b 7265 665f 6e75 6767 6574 5f69  fo=[ref_nugget_i
-00009150: 6e69 745d 2c0d 0a20 2020 2020 2020 2020  nit],..         
+00009120: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00009130: 2e6e 7567 6765 745f 6566 6665 6374 5f73  .nugget_effect_s
+00009140: 6361 6c61 725f 545b 0d0a 2020 2020 2020  calar_T[..      
+00009150: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00009160: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00009170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009180: 2020 2020 2020 7365 7175 656e 6365 733d        sequences=
-00009190: 5b0d 0a20 2020 2020 2020 2020 2020 2020  [..             
+00009180: 2072 6566 5f70 6f73 6974 696f 6e73 5d2c   ref_positions],
+00009190: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
 000091a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000091b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000091c0: 2020 2020 2020 7365 6c66 2e6e 7567 6765        self.nugge
-000091d0: 745f 6566 6665 6374 5f73 6361 6c61 725f  t_effect_scalar_
-000091e0: 545b 0d0a 2020 2020 2020 2020 2020 2020  T[..            
+000091c0: 2020 2020 2064 6963 7428 696e 7075 743d       dict(input=
+000091d0: 6375 6d5f 7265 702c 2074 6170 733d 5b30  cum_rep, taps=[0
+000091e0: 2c20 315d 295d 2c0d 0a20 2020 2020 2020  , 1])],..       
 000091f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00009200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009210: 2020 2020 2020 2020 2020 2072 6566 5f70             ref_p
-00009220: 6f73 6974 696f 6e73 5d2c 0d0a 2020 2020  ositions],..    
-00009230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009210: 2020 2020 2020 2020 6e6f 6e5f 7365 7175          non_sequ
+00009220: 656e 6365 733d 5b54 2e61 735f 7465 6e73  ences=[T.as_tens
+00009230: 6f72 2831 295d 2c0d 0a20 2020 2020 2020  or(1)],..       
 00009240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009250: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-00009260: 6963 7428 696e 7075 743d 6375 6d5f 7265  ict(input=cum_re
-00009270: 702c 2074 6170 733d 5b30 2c20 315d 295d  p, taps=[0, 1])]
-00009280: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00009290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000092a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000092b0: 2020 6e6f 6e5f 7365 7175 656e 6365 733d    non_sequences=
-000092c0: 5b54 2e61 735f 7465 6e73 6f72 2831 295d  [T.as_tensor(1)]
-000092d0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-000092e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000092f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009300: 2020 7265 7475 726e 5f6c 6973 743d 4661    return_list=Fa
-00009310: 6c73 6529 0d0a 0d0a 2020 2020 2020 2020  lse)....        
-00009320: 2320 7265 665f 6e75 6767 6574 5f6c 6f6f  # ref_nugget_loo
-00009330: 7020 3d20 7468 6561 6e6f 2e70 7269 6e74  p = theano.print
-00009340: 696e 672e 5072 696e 7428 276c 6f6f 7027  ing.Print('loop'
-00009350: 2928 7265 665f 6e75 6767 6574 5f6c 6f6f  )(ref_nugget_loo
-00009360: 7029 0d0a 2020 2020 2020 2020 7265 665f  p)..        ref_
-00009370: 6e75 6767 6574 203d 2072 6566 5f6e 7567  nugget = ref_nug
-00009380: 6765 745f 6c6f 6f70 5b2d 315d 0d0a 0d0a  get_loop[-1]....
-00009390: 2020 2020 2020 2020 7265 7374 5f6e 7567          rest_nug
-000093a0: 6765 7420 3d20 7365 6c66 2e6e 7567 6765  get = self.nugge
-000093b0: 745f 6566 6665 6374 5f73 6361 6c61 725f  t_effect_scalar_
-000093c0: 545b 7265 7374 5f6d 6173 6b5d 0d0a 2020  T[rest_mask]..  
-000093d0: 2020 2020 2020 6e75 6767 6574 5f72 6573        nugget_res
-000093e0: 745f 7265 6620 3d20 7265 665f 6e75 6767  t_ref = ref_nugg
-000093f0: 6574 2e72 6573 6861 7065 2828 312c 202d  et.reshape((1, -
-00009400: 3129 295b 305d 202b 2072 6573 745f 6e75  1))[0] + rest_nu
-00009410: 6767 6574 0d0a 2020 2020 2020 2020 7265  gget..        re
-00009420: 7475 726e 206e 7567 6765 745f 7265 7374  turn nugget_rest
-00009430: 5f72 6566 0d0a 0d0a 2020 2020 4073 7461  _ref....    @sta
-00009440: 7469 636d 6574 686f 640d 0a20 2020 2064  ticmethod..    d
-00009450: 6566 2073 7175 6172 6564 5f65 7563 6c69  ef squared_eucli
-00009460: 6465 616e 5f64 6973 7461 6e63 6573 2878  dean_distances(x
-00009470: 5f31 2c20 785f 3229 3a0d 0a20 2020 2020  _1, x_2):..     
-00009480: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-00009490: 436f 6d70 7574 6520 7468 6520 6575 636c  Compute the eucl
-000094a0: 6964 6961 6e20 6469 7374 616e 6365 7320  idian distances 
-000094b0: 696e 2033 4420 6265 7477 6565 6e20 616c  in 3D between al
-000094c0: 6c20 7468 6520 706f 696e 7473 2069 6e20  l the points in 
-000094d0: 785f 3120 616e 6420 785f 320d 0a0d 0a20  x_1 and x_2.... 
-000094e0: 2020 2020 2020 2041 7267 733a 0d0a 2020         Args:..  
-000094f0: 2020 2020 2020 2020 2020 785f 3120 2874            x_1 (t
-00009500: 6865 616e 6f2e 7465 6e73 6f72 2e6d 6174  heano.tensor.mat
-00009510: 7269 7829 3a20 7368 6170 6520 6e5f 706f  rix): shape n_po
-00009520: 696e 7473 2078 206e 756d 6265 7220 6469  ints x number di
-00009530: 6d65 6e73 696f 6e0d 0a20 2020 2020 2020  mension..       
-00009540: 2020 2020 2078 5f32 2028 7468 6561 6e6f       x_2 (theano
-00009550: 2e74 656e 736f 722e 6d61 7472 6978 293a  .tensor.matrix):
-00009560: 2073 6861 7065 206e 5f70 6f69 6e74 7320   shape n_points 
-00009570: 7820 6e75 6d62 6572 2064 696d 656e 7369  x number dimensi
-00009580: 6f6e 0d0a 0d0a 2020 2020 2020 2020 5265  on....        Re
-00009590: 7475 726e 733a 0d0a 2020 2020 2020 2020  turns:..        
-000095a0: 2020 2020 7468 6561 6e6f 2e74 656e 736f      theano.tenso
-000095b0: 722e 6d61 7472 6978 3a20 4469 7374 616e  r.matrix: Distan
-000095c0: 6373 6520 6d61 7472 6978 2e20 7368 6170  cse matrix. shap
-000095d0: 6520 6e5f 706f 696e 7473 2078 206e 5f70  e n_points x n_p
-000095e0: 6f69 6e74 730d 0a20 2020 2020 2020 2022  oints..        "
-000095f0: 2222 0d0a 0d0a 2020 2020 2020 2020 2320  ""....        # 
-00009600: 542e 6d61 7869 6d75 6d20 6176 6f69 6420  T.maximum avoid 
-00009610: 6e65 6761 7469 7665 206e 756d 6265 7273  negative numbers
-00009620: 2069 6e63 7265 6173 696e 6720 7374 6162   increasing stab
-00009630: 696c 6974 790d 0a20 2020 2020 2020 2073  ility..        s
-00009640: 7164 203d 2054 2e73 7172 7428 542e 6d61  qd = T.sqrt(T.ma
-00009650: 7869 6d75 6d28 0d0a 2020 2020 2020 2020  ximum(..        
-00009660: 2020 2020 2878 5f31 202a 2a20 3229 2e73      (x_1 ** 2).s
-00009670: 756d 2831 292e 7265 7368 6170 6528 2878  um(1).reshape((x
-00009680: 5f31 2e73 6861 7065 5b30 5d2c 2031 2929  _1.shape[0], 1))
-00009690: 202b 0d0a 2020 2020 2020 2020 2020 2020   +..            
-000096a0: 2878 5f32 202a 2a20 3229 2e73 756d 2831  (x_2 ** 2).sum(1
-000096b0: 292e 7265 7368 6170 6528 2831 2c20 785f  ).reshape((1, x_
-000096c0: 322e 7368 6170 655b 305d 2929 202d 0d0a  2.shape[0])) -..
-000096d0: 2020 2020 2020 2020 2020 2020 3220 2a20              2 * 
-000096e0: 785f 312e 646f 7428 785f 322e 5429 2c20  x_1.dot(x_2.T), 
-000096f0: 3165 2d31 320d 0a20 2020 2020 2020 2029  1e-12..        )
-00009700: 290d 0a20 2020 2020 2020 2072 6574 7572  )..        retur
-00009710: 6e20 7371 640d 0a0d 0a20 2020 2064 6566  n sqd....    def
-00009720: 206d 6174 7269 6365 735f 7368 6170 6573   matrices_shapes
-00009730: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
-00009740: 2022 2222 0d0a 2020 2020 2020 2020 4765   """..        Ge
-00009750: 7420 616c 6c20 7468 6520 6c65 6e67 7468  t all the length
-00009760: 7320 6f66 2074 6865 206d 6174 7269 6365  s of the matrice
-00009770: 7320 7468 6174 2066 6f72 6d20 7468 6520  s that form the 
-00009780: 636f 7661 7269 616e 6365 206d 6174 7269  covariance matri
-00009790: 780d 0a0d 0a20 2020 2020 2020 2052 6574  x....        Ret
-000097a0: 7572 6e73 3a0d 0a20 2020 2020 2020 2020  urns:..         
-000097b0: 2020 2020 6c65 6e67 7468 5f6f 665f 4347      length_of_CG
-000097c0: 2c20 6c65 6e67 7468 5f6f 665f 4347 492c  , length_of_CGI,
-000097d0: 206c 656e 6774 685f 6f66 5f55 5f49 2c20   length_of_U_I, 
-000097e0: 6c65 6e67 7468 5f6f 665f 6661 756c 7473  length_of_faults
-000097f0: 2c20 6c65 6e67 7468 5f6f 665f 430d 0a20  , length_of_C.. 
-00009800: 2020 2020 2020 2022 2222 0d0a 0d0a 2020         """....  
-00009810: 2020 2020 2020 2320 4361 6c63 756c 6174        # Calculat
-00009820: 696e 6720 7468 6520 6469 6d65 6e73 696f  ing the dimensio
-00009830: 6e73 206f 6620 7468 650d 0a20 2020 2020  ns of the..     
-00009840: 2020 206c 656e 6774 685f 6f66 5f43 4720     length_of_CG 
-00009850: 3d20 7365 6c66 2e64 6970 735f 706f 7369  = self.dips_posi
-00009860: 7469 6f6e 5f74 696c 6564 2e73 6861 7065  tion_tiled.shape
-00009870: 5b30 5d0d 0a20 2020 2020 2020 206c 656e  [0]..        len
-00009880: 6774 685f 6f66 5f43 4749 203d 2073 656c  gth_of_CGI = sel
-00009890: 662e 7265 7374 5f6c 6179 6572 5f70 6f69  f.rest_layer_poi
-000098a0: 6e74 732e 7368 6170 655b 305d 0d0a 2020  nts.shape[0]..  
-000098b0: 2020 2020 2020 6c65 6e67 7468 5f6f 665f        length_of_
-000098c0: 555f 4920 3d20 7365 6c66 2e6e 5f75 6e69  U_I = self.n_uni
-000098d0: 7665 7273 616c 5f65 715f 545f 6f70 0d0a  versal_eq_T_op..
-000098e0: 0d0a 2020 2020 2020 2020 2320 5365 6c66  ..        # Self
-000098f0: 2066 6175 6c74 206d 6174 7269 7820 636f   fault matrix co
-00009900: 6e74 6169 6e73 2074 6865 2062 6c6f 636b  ntains the block
-00009910: 2061 6e64 2074 6865 2070 6f74 656e 7469   and the potenti
-00009920: 616c 2066 6965 6c64 2028 4920 616d 206e  al field (I am n
-00009930: 6f74 2061 626c 6520 746f 2073 706c 6974  ot able to split
-00009940: 2074 6865 6d29 2e20 5468 6572 6566 6f72   them). Therefor
-00009950: 6520 7765 206e 6565 640d 0a20 2020 2020  e we need..     
-00009960: 2020 2023 2074 6f20 6469 7669 6465 2069     # to divide i
-00009970: 7420 6279 2032 0d0a 2020 2020 2020 2020  t by 2..        
-00009980: 6c65 6e67 7468 5f6f 665f 6661 756c 7473  length_of_faults
-00009990: 203d 2073 656c 662e 6c65 6e67 6874 5f6f   = self.lenght_o
-000099a0: 665f 6661 756c 7473 2020 2320 542e 6361  f_faults  # T.ca
-000099b0: 7374 2873 656c 662e 6661 756c 745f 6d61  st(self.fault_ma
-000099c0: 7472 6978 2e73 6861 7065 5b30 5d2c 2027  trix.shape[0], '
-000099d0: 696e 7433 3227 290d 0a20 2020 2020 2020  int32')..       
-000099e0: 206c 656e 6774 685f 6f66 5f43 203d 206c   length_of_C = l
-000099f0: 656e 6774 685f 6f66 5f43 4720 2b20 6c65  ength_of_CG + le
-00009a00: 6e67 7468 5f6f 665f 4347 4920 2b20 6c65  ngth_of_CGI + le
-00009a10: 6e67 7468 5f6f 665f 555f 4920 2b20 6c65  ngth_of_U_I + le
-00009a20: 6e67 7468 5f6f 665f 6661 756c 7473 0d0a  ngth_of_faults..
-00009a30: 0d0a 2020 2020 2020 2020 6966 2027 6d61  ..        if 'ma
-00009a40: 7472 6963 6573 5f73 6861 7065 7327 2069  trices_shapes' i
-00009a50: 6e20 7365 6c66 2e76 6572 626f 7365 3a0d  n self.verbose:.
-00009a60: 0a20 2020 2020 2020 2020 2020 206c 656e  .            len
-00009a70: 6774 685f 6f66 5f43 4720 3d20 7468 6561  gth_of_CG = thea
-00009a80: 6e6f 2e70 7269 6e74 696e 672e 5072 696e  no.printing.Prin
-00009a90: 7428 226c 656e 6774 685f 6f66 5f43 4722  t("length_of_CG"
-00009aa0: 2928 6c65 6e67 7468 5f6f 665f 4347 290d  )(length_of_CG).
-00009ab0: 0a20 2020 2020 2020 2020 2020 206c 656e  .            len
-00009ac0: 6774 685f 6f66 5f43 4749 203d 2074 6865  gth_of_CGI = the
-00009ad0: 616e 6f2e 7072 696e 7469 6e67 2e50 7269  ano.printing.Pri
-00009ae0: 6e74 2822 6c65 6e67 7468 5f6f 665f 4347  nt("length_of_CG
-00009af0: 4922 2928 6c65 6e67 7468 5f6f 665f 4347  I")(length_of_CG
-00009b00: 4929 0d0a 2020 2020 2020 2020 2020 2020  I)..            
-00009b10: 6c65 6e67 7468 5f6f 665f 555f 4920 3d20  length_of_U_I = 
-00009b20: 7468 6561 6e6f 2e70 7269 6e74 696e 672e  theano.printing.
-00009b30: 5072 696e 7428 226c 656e 6774 685f 6f66  Print("length_of
-00009b40: 5f55 5f49 2229 286c 656e 6774 685f 6f66  _U_I")(length_of
-00009b50: 5f55 5f49 290d 0a20 2020 2020 2020 2020  _U_I)..         
-00009b60: 2020 206c 656e 6774 685f 6f66 5f66 6175     length_of_fau
-00009b70: 6c74 7320 3d20 7468 6561 6e6f 2e70 7269  lts = theano.pri
-00009b80: 6e74 696e 672e 5072 696e 7428 226c 656e  nting.Print("len
-00009b90: 6774 685f 6f66 5f66 6175 6c74 7322 2928  gth_of_faults")(
-00009ba0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00009bb0: 2020 6c65 6e67 7468 5f6f 665f 6661 756c    length_of_faul
-00009bc0: 7473 290d 0a20 2020 2020 2020 2020 2020  ts)..           
-00009bd0: 206c 656e 6774 685f 6f66 5f43 203d 2074   length_of_C = t
-00009be0: 6865 616e 6f2e 7072 696e 7469 6e67 2e50  heano.printing.P
-00009bf0: 7269 6e74 2822 6c65 6e67 7468 5f6f 665f  rint("length_of_
-00009c00: 4322 2928 6c65 6e67 7468 5f6f 665f 4329  C")(length_of_C)
-00009c10: 0d0a 0d0a 2020 2020 2020 2020 7265 7475  ....        retu
-00009c20: 726e 206c 656e 6774 685f 6f66 5f43 472c  rn length_of_CG,
-00009c30: 206c 656e 6774 685f 6f66 5f43 4749 2c20   length_of_CGI, 
-00009c40: 6c65 6e67 7468 5f6f 665f 555f 492c 206c  length_of_U_I, l
-00009c50: 656e 6774 685f 6f66 5f66 6175 6c74 732c  ength_of_faults,
-00009c60: 206c 656e 6774 685f 6f66 5f43 0d0a 0d0a   length_of_C....
-00009c70: 2020 2020 2320 656e 6472 6567 696f 6e0d      # endregion.
-00009c80: 0a0d 0a20 2020 2023 2072 6567 696f 6e20  ...    # region 
-00009c90: 4b72 6967 696e 670d 0a20 2020 2064 6566  Kriging..    def
-00009ca0: 2063 6f76 5f73 7572 6661 6365 5f70 6f69   cov_surface_poi
-00009cb0: 6e74 7328 7365 6c66 293a 0d0a 2020 2020  nts(self):..    
-00009cc0: 2020 2020 2222 220d 0a20 2020 2020 2020      """..       
-00009cd0: 2043 7265 6174 6520 636f 7661 7269 616e   Create covarian
-00009ce0: 6365 2066 756e 6374 696f 6e20 666f 7220  ce function for 
-00009cf0: 7468 6520 7375 7266 6163 655f 706f 696e  the surface_poin
-00009d00: 7473 0d0a 0d0a 2020 2020 2020 2020 5265  ts....        Re
-00009d10: 7475 726e 733a 0d0a 2020 2020 2020 2020  turns:..        
-00009d20: 2020 2020 7468 6561 6e6f 2e74 656e 736f      theano.tenso
-00009d30: 722e 6d61 7472 6978 3a20 636f 7661 7269  r.matrix: covari
-00009d40: 616e 6365 206f 6620 7468 6520 7375 7266  ance of the surf
-00009d50: 6163 655f 706f 696e 7473 2e20 5368 6170  ace_points. Shap
-00009d60: 6520 6e75 6d62 6572 206f 6620 706f 696e  e number of poin
-00009d70: 7473 2069 6e20 7265 7374 2078 206e 756d  ts in rest x num
-00009d80: 6265 7220 6f66 0d0a 2020 2020 2020 2020  ber of..        
-00009d90: 2020 2020 706f 696e 7473 2069 6e20 7265      points in re
-00009da0: 7374 0d0a 0d0a 2020 2020 2020 2020 2222  st....        ""
-00009db0: 220d 0a0d 0a20 2020 2020 2020 2023 2043  "....        # C
-00009dc0: 6f6d 7075 7465 2065 7563 6c69 6469 616e  ompute euclidian
-00009dd0: 2064 6973 7461 6e63 6573 0d0a 2020 2020   distances..    
-00009de0: 2020 2020 7365 645f 7265 7374 5f72 6573      sed_rest_res
-00009df0: 7420 3d20 7365 6c66 2e73 7175 6172 6564  t = self.squared
-00009e00: 5f65 7563 6c69 6465 616e 5f64 6973 7461  _euclidean_dista
-00009e10: 6e63 6573 2873 656c 662e 7265 7374 5f6c  nces(self.rest_l
-00009e20: 6179 6572 5f70 6f69 6e74 732c 0d0a 2020  ayer_points,..  
-00009e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009260: 2020 2020 2020 2020 7265 7475 726e 5f6c          return_l
+00009270: 6973 743d 4661 6c73 6529 0d0a 0d0a 2020  ist=False)....  
+00009280: 2020 2020 2020 2320 7265 665f 6e75 6767        # ref_nugg
+00009290: 6574 5f6c 6f6f 7020 3d20 6165 7361 7261  et_loop = aesara
+000092a0: 2e70 7269 6e74 696e 672e 5072 696e 7428  .printing.Print(
+000092b0: 276c 6f6f 7027 2928 7265 665f 6e75 6767  'loop')(ref_nugg
+000092c0: 6574 5f6c 6f6f 7029 0d0a 2020 2020 2020  et_loop)..      
+000092d0: 2020 7265 665f 6e75 6767 6574 203d 2072    ref_nugget = r
+000092e0: 6566 5f6e 7567 6765 745f 6c6f 6f70 5b2d  ef_nugget_loop[-
+000092f0: 315d 0d0a 0d0a 2020 2020 2020 2020 7265  1]....        re
+00009300: 7374 5f6e 7567 6765 7420 3d20 7365 6c66  st_nugget = self
+00009310: 2e6e 7567 6765 745f 6566 6665 6374 5f73  .nugget_effect_s
+00009320: 6361 6c61 725f 545b 7265 7374 5f6d 6173  calar_T[rest_mas
+00009330: 6b5d 0d0a 2020 2020 2020 2020 6e75 6767  k]..        nugg
+00009340: 6574 5f72 6573 745f 7265 6620 3d20 7265  et_rest_ref = re
+00009350: 665f 6e75 6767 6574 2e72 6573 6861 7065  f_nugget.reshape
+00009360: 2828 312c 202d 3129 295b 305d 202b 2072  ((1, -1))[0] + r
+00009370: 6573 745f 6e75 6767 6574 0d0a 2020 2020  est_nugget..    
+00009380: 2020 2020 7265 7475 726e 206e 7567 6765      return nugge
+00009390: 745f 7265 7374 5f72 6566 0d0a 0d0a 2020  t_rest_ref....  
+000093a0: 2020 4073 7461 7469 636d 6574 686f 640d    @staticmethod.
+000093b0: 0a20 2020 2064 6566 2073 7175 6172 6564  .    def squared
+000093c0: 5f65 7563 6c69 6465 616e 5f64 6973 7461  _euclidean_dista
+000093d0: 6e63 6573 2878 5f31 2c20 785f 3229 3a0d  nces(x_1, x_2):.
+000093e0: 0a20 2020 2020 2020 2022 2222 0d0a 2020  .        """..  
+000093f0: 2020 2020 2020 436f 6d70 7574 6520 7468        Compute th
+00009400: 6520 6575 636c 6964 6961 6e20 6469 7374  e euclidian dist
+00009410: 616e 6365 7320 696e 2033 4420 6265 7477  ances in 3D betw
+00009420: 6565 6e20 616c 6c20 7468 6520 706f 696e  een all the poin
+00009430: 7473 2069 6e20 785f 3120 616e 6420 785f  ts in x_1 and x_
+00009440: 320d 0a0d 0a20 2020 2020 2020 2041 7267  2....        Arg
+00009450: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
+00009460: 785f 3120 2861 6573 6172 612e 7465 6e73  x_1 (aesara.tens
+00009470: 6f72 2e6d 6174 7269 7829 3a20 7368 6170  or.matrix): shap
+00009480: 6520 6e5f 706f 696e 7473 2078 206e 756d  e n_points x num
+00009490: 6265 7220 6469 6d65 6e73 696f 6e0d 0a20  ber dimension.. 
+000094a0: 2020 2020 2020 2020 2020 2078 5f32 2028             x_2 (
+000094b0: 6165 7361 7261 2e74 656e 736f 722e 6d61  aesara.tensor.ma
+000094c0: 7472 6978 293a 2073 6861 7065 206e 5f70  trix): shape n_p
+000094d0: 6f69 6e74 7320 7820 6e75 6d62 6572 2064  oints x number d
+000094e0: 696d 656e 7369 6f6e 0d0a 0d0a 2020 2020  imension....    
+000094f0: 2020 2020 5265 7475 726e 733a 0d0a 2020      Returns:..  
+00009500: 2020 2020 2020 2020 2020 6165 7361 7261            aesara
+00009510: 2e74 656e 736f 722e 6d61 7472 6978 3a20  .tensor.matrix: 
+00009520: 4469 7374 616e 6373 6520 6d61 7472 6978  Distancse matrix
+00009530: 2e20 7368 6170 6520 6e5f 706f 696e 7473  . shape n_points
+00009540: 2078 206e 5f70 6f69 6e74 730d 0a20 2020   x n_points..   
+00009550: 2020 2020 2022 2222 0d0a 0d0a 2020 2020       """....    
+00009560: 2020 2020 2320 542e 6d61 7869 6d75 6d20      # T.maximum 
+00009570: 6176 6f69 6420 6e65 6761 7469 7665 206e  avoid negative n
+00009580: 756d 6265 7273 2069 6e63 7265 6173 696e  umbers increasin
+00009590: 6720 7374 6162 696c 6974 790d 0a20 2020  g stability..   
+000095a0: 2020 2020 2073 7164 203d 2054 2e73 7172       sqd = T.sqr
+000095b0: 7428 542e 6d61 7869 6d75 6d28 0d0a 2020  t(T.maximum(..  
+000095c0: 2020 2020 2020 2020 2020 2878 5f31 202a            (x_1 *
+000095d0: 2a20 3229 2e73 756d 2831 292e 7265 7368  * 2).sum(1).resh
+000095e0: 6170 6528 2878 5f31 2e73 6861 7065 5b30  ape((x_1.shape[0
+000095f0: 5d2c 2031 2929 202b 0d0a 2020 2020 2020  ], 1)) +..      
+00009600: 2020 2020 2020 2878 5f32 202a 2a20 3229        (x_2 ** 2)
+00009610: 2e73 756d 2831 292e 7265 7368 6170 6528  .sum(1).reshape(
+00009620: 2831 2c20 785f 322e 7368 6170 655b 305d  (1, x_2.shape[0]
+00009630: 2929 202d 0d0a 2020 2020 2020 2020 2020  )) -..          
+00009640: 2020 3220 2a20 785f 312e 646f 7428 785f    2 * x_1.dot(x_
+00009650: 322e 5429 2c20 3165 2d31 320d 0a20 2020  2.T), 1e-12..   
+00009660: 2020 2020 2029 290d 0a20 2020 2020 2020       ))..       
+00009670: 2072 6574 7572 6e20 7371 640d 0a0d 0a20   return sqd.... 
+00009680: 2020 2064 6566 206d 6174 7269 6365 735f     def matrices_
+00009690: 7368 6170 6573 2873 656c 6629 3a0d 0a20  shapes(self):.. 
+000096a0: 2020 2020 2020 2022 2222 0d0a 2020 2020         """..    
+000096b0: 2020 2020 4765 7420 616c 6c20 7468 6520      Get all the 
+000096c0: 6c65 6e67 7468 7320 6f66 2074 6865 206d  lengths of the m
+000096d0: 6174 7269 6365 7320 7468 6174 2066 6f72  atrices that for
+000096e0: 6d20 7468 6520 636f 7661 7269 616e 6365  m the covariance
+000096f0: 206d 6174 7269 780d 0a0d 0a20 2020 2020   matrix....     
+00009700: 2020 2052 6574 7572 6e73 3a0d 0a20 2020     Returns:..   
+00009710: 2020 2020 2020 2020 2020 6c65 6e67 7468            length
+00009720: 5f6f 665f 4347 2c20 6c65 6e67 7468 5f6f  _of_CG, length_o
+00009730: 665f 4347 492c 206c 656e 6774 685f 6f66  f_CGI, length_of
+00009740: 5f55 5f49 2c20 6c65 6e67 7468 5f6f 665f  _U_I, length_of_
+00009750: 6661 756c 7473 2c20 6c65 6e67 7468 5f6f  faults, length_o
+00009760: 665f 430d 0a20 2020 2020 2020 2022 2222  f_C..        """
+00009770: 0d0a 0d0a 2020 2020 2020 2020 2320 4361  ....        # Ca
+00009780: 6c63 756c 6174 696e 6720 7468 6520 6469  lculating the di
+00009790: 6d65 6e73 696f 6e73 206f 6620 7468 650d  mensions of the.
+000097a0: 0a20 2020 2020 2020 206c 656e 6774 685f  .        length_
+000097b0: 6f66 5f43 4720 3d20 7365 6c66 2e64 6970  of_CG = self.dip
+000097c0: 735f 706f 7369 7469 6f6e 5f74 696c 6564  s_position_tiled
+000097d0: 2e73 6861 7065 5b30 5d0d 0a20 2020 2020  .shape[0]..     
+000097e0: 2020 206c 656e 6774 685f 6f66 5f43 4749     length_of_CGI
+000097f0: 203d 2073 656c 662e 7265 7374 5f6c 6179   = self.rest_lay
+00009800: 6572 5f70 6f69 6e74 732e 7368 6170 655b  er_points.shape[
+00009810: 305d 0d0a 2020 2020 2020 2020 6c65 6e67  0]..        leng
+00009820: 7468 5f6f 665f 555f 4920 3d20 7365 6c66  th_of_U_I = self
+00009830: 2e6e 5f75 6e69 7665 7273 616c 5f65 715f  .n_universal_eq_
+00009840: 545f 6f70 0d0a 0d0a 2020 2020 2020 2020  T_op....        
+00009850: 2320 5365 6c66 2066 6175 6c74 206d 6174  # Self fault mat
+00009860: 7269 7820 636f 6e74 6169 6e73 2074 6865  rix contains the
+00009870: 2062 6c6f 636b 2061 6e64 2074 6865 2070   block and the p
+00009880: 6f74 656e 7469 616c 2066 6965 6c64 2028  otential field (
+00009890: 4920 616d 206e 6f74 2061 626c 6520 746f  I am not able to
+000098a0: 2073 706c 6974 2074 6865 6d29 2e20 5468   split them). Th
+000098b0: 6572 6566 6f72 6520 7765 206e 6565 640d  erefore we need.
+000098c0: 0a20 2020 2020 2020 2023 2074 6f20 6469  .        # to di
+000098d0: 7669 6465 2069 7420 6279 2032 0d0a 2020  vide it by 2..  
+000098e0: 2020 2020 2020 6c65 6e67 7468 5f6f 665f        length_of_
+000098f0: 6661 756c 7473 203d 2073 656c 662e 6c65  faults = self.le
+00009900: 6e67 6874 5f6f 665f 6661 756c 7473 2020  nght_of_faults  
+00009910: 2320 542e 6361 7374 2873 656c 662e 6661  # T.cast(self.fa
+00009920: 756c 745f 6d61 7472 6978 2e73 6861 7065  ult_matrix.shape
+00009930: 5b30 5d2c 2027 696e 7433 3227 290d 0a20  [0], 'int32').. 
+00009940: 2020 2020 2020 206c 656e 6774 685f 6f66         length_of
+00009950: 5f43 203d 206c 656e 6774 685f 6f66 5f43  _C = length_of_C
+00009960: 4720 2b20 6c65 6e67 7468 5f6f 665f 4347  G + length_of_CG
+00009970: 4920 2b20 6c65 6e67 7468 5f6f 665f 555f  I + length_of_U_
+00009980: 4920 2b20 6c65 6e67 7468 5f6f 665f 6661  I + length_of_fa
+00009990: 756c 7473 0d0a 0d0a 2020 2020 2020 2020  ults....        
+000099a0: 6966 2027 6d61 7472 6963 6573 5f73 6861  if 'matrices_sha
+000099b0: 7065 7327 2069 6e20 7365 6c66 2e76 6572  pes' in self.ver
+000099c0: 626f 7365 3a0d 0a20 2020 2020 2020 2020  bose:..         
+000099d0: 2020 206c 656e 6774 685f 6f66 5f43 4720     length_of_CG 
+000099e0: 3d20 6165 7361 7261 2e70 7269 6e74 696e  = aesara.printin
+000099f0: 672e 5072 696e 7428 226c 656e 6774 685f  g.Print("length_
+00009a00: 6f66 5f43 4722 2928 6c65 6e67 7468 5f6f  of_CG")(length_o
+00009a10: 665f 4347 290d 0a20 2020 2020 2020 2020  f_CG)..         
+00009a20: 2020 206c 656e 6774 685f 6f66 5f43 4749     length_of_CGI
+00009a30: 203d 2061 6573 6172 612e 7072 696e 7469   = aesara.printi
+00009a40: 6e67 2e50 7269 6e74 2822 6c65 6e67 7468  ng.Print("length
+00009a50: 5f6f 665f 4347 4922 2928 6c65 6e67 7468  _of_CGI")(length
+00009a60: 5f6f 665f 4347 4929 0d0a 2020 2020 2020  _of_CGI)..      
+00009a70: 2020 2020 2020 6c65 6e67 7468 5f6f 665f        length_of_
+00009a80: 555f 4920 3d20 6165 7361 7261 2e70 7269  U_I = aesara.pri
+00009a90: 6e74 696e 672e 5072 696e 7428 226c 656e  nting.Print("len
+00009aa0: 6774 685f 6f66 5f55 5f49 2229 286c 656e  gth_of_U_I")(len
+00009ab0: 6774 685f 6f66 5f55 5f49 290d 0a20 2020  gth_of_U_I)..   
+00009ac0: 2020 2020 2020 2020 206c 656e 6774 685f           length_
+00009ad0: 6f66 5f66 6175 6c74 7320 3d20 6165 7361  of_faults = aesa
+00009ae0: 7261 2e70 7269 6e74 696e 672e 5072 696e  ra.printing.Prin
+00009af0: 7428 226c 656e 6774 685f 6f66 5f66 6175  t("length_of_fau
+00009b00: 6c74 7322 2928 0d0a 2020 2020 2020 2020  lts")(..        
+00009b10: 2020 2020 2020 2020 6c65 6e67 7468 5f6f          length_o
+00009b20: 665f 6661 756c 7473 290d 0a20 2020 2020  f_faults)..     
+00009b30: 2020 2020 2020 206c 656e 6774 685f 6f66         length_of
+00009b40: 5f43 203d 2061 6573 6172 612e 7072 696e  _C = aesara.prin
+00009b50: 7469 6e67 2e50 7269 6e74 2822 6c65 6e67  ting.Print("leng
+00009b60: 7468 5f6f 665f 4322 2928 6c65 6e67 7468  th_of_C")(length
+00009b70: 5f6f 665f 4329 0d0a 0d0a 2020 2020 2020  _of_C)....      
+00009b80: 2020 7265 7475 726e 206c 656e 6774 685f    return length_
+00009b90: 6f66 5f43 472c 206c 656e 6774 685f 6f66  of_CG, length_of
+00009ba0: 5f43 4749 2c20 6c65 6e67 7468 5f6f 665f  _CGI, length_of_
+00009bb0: 555f 492c 206c 656e 6774 685f 6f66 5f66  U_I, length_of_f
+00009bc0: 6175 6c74 732c 206c 656e 6774 685f 6f66  aults, length_of
+00009bd0: 5f43 0d0a 0d0a 2020 2020 2320 656e 6472  _C....    # endr
+00009be0: 6567 696f 6e0d 0a0d 0a20 2020 2023 2072  egion....    # r
+00009bf0: 6567 696f 6e20 4b72 6967 696e 670d 0a20  egion Kriging.. 
+00009c00: 2020 2064 6566 2063 6f76 5f73 7572 6661     def cov_surfa
+00009c10: 6365 5f70 6f69 6e74 7328 7365 6c66 293a  ce_points(self):
+00009c20: 0d0a 2020 2020 2020 2020 2222 220d 0a20  ..        """.. 
+00009c30: 2020 2020 2020 2043 7265 6174 6520 636f         Create co
+00009c40: 7661 7269 616e 6365 2066 756e 6374 696f  variance functio
+00009c50: 6e20 666f 7220 7468 6520 7375 7266 6163  n for the surfac
+00009c60: 655f 706f 696e 7473 0d0a 0d0a 2020 2020  e_points....    
+00009c70: 2020 2020 5265 7475 726e 733a 0d0a 2020      Returns:..  
+00009c80: 2020 2020 2020 2020 2020 6165 7361 7261            aesara
+00009c90: 2e74 656e 736f 722e 6d61 7472 6978 3a20  .tensor.matrix: 
+00009ca0: 636f 7661 7269 616e 6365 206f 6620 7468  covariance of th
+00009cb0: 6520 7375 7266 6163 655f 706f 696e 7473  e surface_points
+00009cc0: 2e20 5368 6170 6520 6e75 6d62 6572 206f  . Shape number o
+00009cd0: 6620 706f 696e 7473 2069 6e20 7265 7374  f points in rest
+00009ce0: 2078 206e 756d 6265 7220 6f66 0d0a 2020   x number of..  
+00009cf0: 2020 2020 2020 2020 2020 706f 696e 7473            points
+00009d00: 2069 6e20 7265 7374 0d0a 0d0a 2020 2020   in rest....    
+00009d10: 2020 2020 2222 220d 0a0d 0a20 2020 2020      """....     
+00009d20: 2020 2023 2043 6f6d 7075 7465 2065 7563     # Compute euc
+00009d30: 6c69 6469 616e 2064 6973 7461 6e63 6573  lidian distances
+00009d40: 0d0a 2020 2020 2020 2020 7365 645f 7265  ..        sed_re
+00009d50: 7374 5f72 6573 7420 3d20 7365 6c66 2e73  st_rest = self.s
+00009d60: 7175 6172 6564 5f65 7563 6c69 6465 616e  quared_euclidean
+00009d70: 5f64 6973 7461 6e63 6573 2873 656c 662e  _distances(self.
+00009d80: 7265 7374 5f6c 6179 6572 5f70 6f69 6e74  rest_layer_point
+00009d90: 732c 0d0a 2020 2020 2020 2020 2020 2020  s,..            
+00009da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009db0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009dc0: 2020 2020 2020 2020 2020 2020 2073 656c               sel
+00009dd0: 662e 7265 7374 5f6c 6179 6572 5f70 6f69  f.rest_layer_poi
+00009de0: 6e74 7329 0d0a 2020 2020 2020 2020 7365  nts)..        se
+00009df0: 645f 7265 665f 7265 7374 203d 2073 656c  d_ref_rest = sel
+00009e00: 662e 7371 7561 7265 645f 6575 636c 6964  f.squared_euclid
+00009e10: 6561 6e5f 6469 7374 616e 6365 7328 7365  ean_distances(se
+00009e20: 6c66 2e72 6566 5f6c 6179 6572 5f70 6f69  lf.ref_layer_poi
+00009e30: 6e74 732c 0d0a 2020 2020 2020 2020 2020  nts,..          
 00009e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00009e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009e60: 2020 2020 2020 2073 656c 662e 7265 7374         self.rest
-00009e70: 5f6c 6179 6572 5f70 6f69 6e74 7329 0d0a  _layer_points)..
-00009e80: 2020 2020 2020 2020 7365 645f 7265 665f          sed_ref_
-00009e90: 7265 7374 203d 2073 656c 662e 7371 7561  rest = self.squa
-00009ea0: 7265 645f 6575 636c 6964 6561 6e5f 6469  red_euclidean_di
-00009eb0: 7374 616e 6365 7328 7365 6c66 2e72 6566  stances(self.ref
-00009ec0: 5f6c 6179 6572 5f70 6f69 6e74 732c 0d0a  _layer_points,..
-00009ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009e60: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00009e70: 6c66 2e72 6573 745f 6c61 7965 725f 706f  lf.rest_layer_po
+00009e80: 696e 7473 290d 0a20 2020 2020 2020 2073  ints)..        s
+00009e90: 6564 5f72 6573 745f 7265 6620 3d20 7365  ed_rest_ref = se
+00009ea0: 6c66 2e73 7175 6172 6564 5f65 7563 6c69  lf.squared_eucli
+00009eb0: 6465 616e 5f64 6973 7461 6e63 6573 2873  dean_distances(s
+00009ec0: 656c 662e 7265 7374 5f6c 6179 6572 5f70  elf.rest_layer_p
+00009ed0: 6f69 6e74 732c 0d0a 2020 2020 2020 2020  oints,..        
 00009ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00009ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009f00: 2020 2020 2020 2020 7365 6c66 2e72 6573          self.res
-00009f10: 745f 6c61 7965 725f 706f 696e 7473 290d  t_layer_points).
-00009f20: 0a20 2020 2020 2020 2073 6564 5f72 6573  .        sed_res
-00009f30: 745f 7265 6620 3d20 7365 6c66 2e73 7175  t_ref = self.squ
-00009f40: 6172 6564 5f65 7563 6c69 6465 616e 5f64  ared_euclidean_d
-00009f50: 6973 7461 6e63 6573 2873 656c 662e 7265  istances(self.re
-00009f60: 7374 5f6c 6179 6572 5f70 6f69 6e74 732c  st_layer_points,
-00009f70: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00009f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009f10: 7365 6c66 2e72 6566 5f6c 6179 6572 5f70  self.ref_layer_p
+00009f20: 6f69 6e74 7329 0d0a 2020 2020 2020 2020  oints)..        
+00009f30: 7365 645f 7265 665f 7265 6620 3d20 7365  sed_ref_ref = se
+00009f40: 6c66 2e73 7175 6172 6564 5f65 7563 6c69  lf.squared_eucli
+00009f50: 6465 616e 5f64 6973 7461 6e63 6573 2873  dean_distances(s
+00009f60: 656c 662e 7265 665f 6c61 7965 725f 706f  elf.ref_layer_po
+00009f70: 696e 7473 2c0d 0a20 2020 2020 2020 2020  ints,..         
 00009f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00009f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009fa0: 2020 2020 2020 2020 2020 7365 6c66 2e72            self.r
-00009fb0: 6566 5f6c 6179 6572 5f70 6f69 6e74 7329  ef_layer_points)
-00009fc0: 0d0a 2020 2020 2020 2020 7365 645f 7265  ..        sed_re
-00009fd0: 665f 7265 6620 3d20 7365 6c66 2e73 7175  f_ref = self.squ
-00009fe0: 6172 6564 5f65 7563 6c69 6465 616e 5f64  ared_euclidean_d
-00009ff0: 6973 7461 6e63 6573 2873 656c 662e 7265  istances(self.re
-0000a000: 665f 6c61 7965 725f 706f 696e 7473 2c0d  f_layer_points,.
-0000a010: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000a020: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009fa0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00009fb0: 6c66 2e72 6566 5f6c 6179 6572 5f70 6f69  lf.ref_layer_poi
+00009fc0: 6e74 7329 0d0a 0d0a 2020 2020 2020 2020  nts)....        
+00009fd0: 2320 436f 7661 7269 616e 6365 206d 6174  # Covariance mat
+00009fe0: 7269 7820 666f 7220 7375 7266 6163 655f  rix for surface_
+00009ff0: 706f 696e 7473 0d0a 2020 2020 2020 2020  points..        
+0000a000: 435f 4920 3d20 2873 656c 662e 635f 6f5f  C_I = (self.c_o_
+0000a010: 545f 7363 616c 6172 202a 2073 656c 662e  T_scalar * self.
+0000a020: 695f 7265 6573 6361 6c65 202a 2028 0d0a  i_reescale * (..
 0000a030: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a040: 2020 2020 2020 2020 7365 6c66 2e72 6566          self.ref
-0000a050: 5f6c 6179 6572 5f70 6f69 6e74 7329 0d0a  _layer_points)..
-0000a060: 0d0a 2020 2020 2020 2020 2320 436f 7661  ..        # Cova
-0000a070: 7269 616e 6365 206d 6174 7269 7820 666f  riance matrix fo
-0000a080: 7220 7375 7266 6163 655f 706f 696e 7473  r surface_points
-0000a090: 0d0a 2020 2020 2020 2020 435f 4920 3d20  ..        C_I = 
-0000a0a0: 2873 656c 662e 635f 6f5f 545f 7363 616c  (self.c_o_T_scal
-0000a0b0: 6172 202a 2073 656c 662e 695f 7265 6573  ar * self.i_rees
-0000a0c0: 6361 6c65 202a 2028 0d0a 2020 2020 2020  cale * (..      
-0000a0d0: 2020 2020 2020 2020 2020 2873 6564 5f72            (sed_r
-0000a0e0: 6573 745f 7265 7374 203c 2073 656c 662e  est_rest < self.
-0000a0f0: 615f 545f 7363 616c 6172 2920 2a20 2023  a_T_scalar) *  #
-0000a100: 2052 6573 7420 2d20 5265 7374 2043 6f76   Rest - Rest Cov
-0000a110: 6172 6961 6e63 6573 204d 6174 7269 780d  ariances Matrix.
-0000a120: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000a130: 2028 3120 2d20 3720 2a20 2873 6564 5f72   (1 - 7 * (sed_r
-0000a140: 6573 745f 7265 7374 202f 2073 656c 662e  est_rest / self.
-0000a150: 615f 545f 7363 616c 6172 2920 2a2a 2032  a_T_scalar) ** 2
-0000a160: 202b 0d0a 2020 2020 2020 2020 2020 2020   +..            
-0000a170: 2020 2020 2033 3520 2f20 3420 2a20 2873       35 / 4 * (s
-0000a180: 6564 5f72 6573 745f 7265 7374 202f 2073  ed_rest_rest / s
-0000a190: 656c 662e 615f 545f 7363 616c 6172 2920  elf.a_T_scalar) 
-0000a1a0: 2a2a 2033 202d 0d0a 2020 2020 2020 2020  ** 3 -..        
-0000a1b0: 2020 2020 2020 2020 2037 202f 2032 202a           7 / 2 *
-0000a1c0: 2028 7365 645f 7265 7374 5f72 6573 7420   (sed_rest_rest 
-0000a1d0: 2f20 7365 6c66 2e61 5f54 5f73 6361 6c61  / self.a_T_scala
-0000a1e0: 7229 202a 2a20 3520 2b0d 0a20 2020 2020  r) ** 5 +..     
-0000a1f0: 2020 2020 2020 2020 2020 2020 3320 2f20              3 / 
-0000a200: 3420 2a20 2873 6564 5f72 6573 745f 7265  4 * (sed_rest_re
-0000a210: 7374 202f 2073 656c 662e 615f 545f 7363  st / self.a_T_sc
-0000a220: 616c 6172 2920 2a2a 2037 2920 2d0d 0a20  alar) ** 7) -.. 
-0000a230: 2020 2020 2020 2020 2020 2020 2020 2028                 (
-0000a240: 2873 6564 5f72 6566 5f72 6573 7420 3c20  (sed_ref_rest < 
-0000a250: 7365 6c66 2e61 5f54 5f73 6361 6c61 7229  self.a_T_scalar)
-0000a260: 202a 2020 2320 5265 6665 7265 6e63 6520   *  # Reference 
-0000a270: 2d20 5265 7374 0d0a 2020 2020 2020 2020  - Rest..        
-0000a280: 2020 2020 2020 2020 2028 3120 2d20 3720           (1 - 7 
-0000a290: 2a20 2873 6564 5f72 6566 5f72 6573 7420  * (sed_ref_rest 
-0000a2a0: 2f20 7365 6c66 2e61 5f54 5f73 6361 6c61  / self.a_T_scala
-0000a2b0: 7229 202a 2a20 3220 2b0d 0a20 2020 2020  r) ** 2 +..     
-0000a2c0: 2020 2020 2020 2020 2020 2020 2033 3520               35 
-0000a2d0: 2f20 3420 2a20 2873 6564 5f72 6566 5f72  / 4 * (sed_ref_r
-0000a2e0: 6573 7420 2f20 7365 6c66 2e61 5f54 5f73  est / self.a_T_s
-0000a2f0: 6361 6c61 7229 202a 2a20 3320 2d0d 0a20  calar) ** 3 -.. 
-0000a300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a310: 2037 202f 2032 202a 2028 7365 645f 7265   7 / 2 * (sed_re
-0000a320: 665f 7265 7374 202f 2073 656c 662e 615f  f_rest / self.a_
-0000a330: 545f 7363 616c 6172 2920 2a2a 2035 202b  T_scalar) ** 5 +
-0000a340: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000a350: 2020 2020 3320 2f20 3420 2a20 2873 6564      3 / 4 * (sed
-0000a360: 5f72 6566 5f72 6573 7420 2f20 7365 6c66  _ref_rest / self
-0000a370: 2e61 5f54 5f73 6361 6c61 7229 202a 2a20  .a_T_scalar) ** 
-0000a380: 3729 2920 2d0d 0a20 2020 2020 2020 2020  7)) -..         
-0000a390: 2020 2020 2020 2028 2873 6564 5f72 6573         ((sed_res
-0000a3a0: 745f 7265 6620 3c20 7365 6c66 2e61 5f54  t_ref < self.a_T
-0000a3b0: 5f73 6361 6c61 7229 202a 2020 2320 5265  _scalar) *  # Re
-0000a3c0: 7374 202d 2052 6566 6572 656e 6365 0d0a  st - Reference..
-0000a3d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a3e0: 2028 3120 2d20 3720 2a20 2873 6564 5f72   (1 - 7 * (sed_r
-0000a3f0: 6573 745f 7265 6620 2f20 7365 6c66 2e61  est_ref / self.a
-0000a400: 5f54 5f73 6361 6c61 7229 202a 2a20 3220  _T_scalar) ** 2 
-0000a410: 2b0d 0a20 2020 2020 2020 2020 2020 2020  +..             
-0000a420: 2020 2020 2033 3520 2f20 3420 2a20 2873       35 / 4 * (s
-0000a430: 6564 5f72 6573 745f 7265 6620 2f20 7365  ed_rest_ref / se
-0000a440: 6c66 2e61 5f54 5f73 6361 6c61 7229 202a  lf.a_T_scalar) *
-0000a450: 2a20 3320 2d0d 0a20 2020 2020 2020 2020  * 3 -..         
-0000a460: 2020 2020 2020 2020 2037 202f 2032 202a           7 / 2 *
-0000a470: 2028 7365 645f 7265 7374 5f72 6566 202f   (sed_rest_ref /
-0000a480: 2073 656c 662e 615f 545f 7363 616c 6172   self.a_T_scalar
-0000a490: 2920 2a2a 2035 202b 0d0a 2020 2020 2020  ) ** 5 +..      
-0000a4a0: 2020 2020 2020 2020 2020 2020 3320 2f20              3 / 
-0000a4b0: 3420 2a20 2873 6564 5f72 6573 745f 7265  4 * (sed_rest_re
-0000a4c0: 6620 2f20 7365 6c66 2e61 5f54 5f73 6361  f / self.a_T_sca
-0000a4d0: 6c61 7229 202a 2a20 3729 2920 2b0d 0a20  lar) ** 7)) +.. 
-0000a4e0: 2020 2020 2020 2020 2020 2020 2020 2028                 (
-0000a4f0: 2873 6564 5f72 6566 5f72 6566 203c 2073  (sed_ref_ref < s
+0000a040: 2873 6564 5f72 6573 745f 7265 7374 203c  (sed_rest_rest <
+0000a050: 2073 656c 662e 615f 545f 7363 616c 6172   self.a_T_scalar
+0000a060: 2920 2a20 2023 2052 6573 7420 2d20 5265  ) *  # Rest - Re
+0000a070: 7374 2043 6f76 6172 6961 6e63 6573 204d  st Covariances M
+0000a080: 6174 7269 780d 0a20 2020 2020 2020 2020  atrix..         
+0000a090: 2020 2020 2020 2028 3120 2d20 3720 2a20         (1 - 7 * 
+0000a0a0: 2873 6564 5f72 6573 745f 7265 7374 202f  (sed_rest_rest /
+0000a0b0: 2073 656c 662e 615f 545f 7363 616c 6172   self.a_T_scalar
+0000a0c0: 2920 2a2a 2032 202b 0d0a 2020 2020 2020  ) ** 2 +..      
+0000a0d0: 2020 2020 2020 2020 2020 2033 3520 2f20             35 / 
+0000a0e0: 3420 2a20 2873 6564 5f72 6573 745f 7265  4 * (sed_rest_re
+0000a0f0: 7374 202f 2073 656c 662e 615f 545f 7363  st / self.a_T_sc
+0000a100: 616c 6172 2920 2a2a 2033 202d 0d0a 2020  alar) ** 3 -..  
+0000a110: 2020 2020 2020 2020 2020 2020 2020 2037                 7
+0000a120: 202f 2032 202a 2028 7365 645f 7265 7374   / 2 * (sed_rest
+0000a130: 5f72 6573 7420 2f20 7365 6c66 2e61 5f54  _rest / self.a_T
+0000a140: 5f73 6361 6c61 7229 202a 2a20 3520 2b0d  _scalar) ** 5 +.
+0000a150: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a160: 2020 3320 2f20 3420 2a20 2873 6564 5f72    3 / 4 * (sed_r
+0000a170: 6573 745f 7265 7374 202f 2073 656c 662e  est_rest / self.
+0000a180: 615f 545f 7363 616c 6172 2920 2a2a 2037  a_T_scalar) ** 7
+0000a190: 2920 2d0d 0a20 2020 2020 2020 2020 2020  ) -..           
+0000a1a0: 2020 2020 2028 2873 6564 5f72 6566 5f72       ((sed_ref_r
+0000a1b0: 6573 7420 3c20 7365 6c66 2e61 5f54 5f73  est < self.a_T_s
+0000a1c0: 6361 6c61 7229 202a 2020 2320 5265 6665  calar) *  # Refe
+0000a1d0: 7265 6e63 6520 2d20 5265 7374 0d0a 2020  rence - Rest..  
+0000a1e0: 2020 2020 2020 2020 2020 2020 2020 2028                 (
+0000a1f0: 3120 2d20 3720 2a20 2873 6564 5f72 6566  1 - 7 * (sed_ref
+0000a200: 5f72 6573 7420 2f20 7365 6c66 2e61 5f54  _rest / self.a_T
+0000a210: 5f73 6361 6c61 7229 202a 2a20 3220 2b0d  _scalar) ** 2 +.
+0000a220: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a230: 2020 2033 3520 2f20 3420 2a20 2873 6564     35 / 4 * (sed
+0000a240: 5f72 6566 5f72 6573 7420 2f20 7365 6c66  _ref_rest / self
+0000a250: 2e61 5f54 5f73 6361 6c61 7229 202a 2a20  .a_T_scalar) ** 
+0000a260: 3320 2d0d 0a20 2020 2020 2020 2020 2020  3 -..           
+0000a270: 2020 2020 2020 2037 202f 2032 202a 2028         7 / 2 * (
+0000a280: 7365 645f 7265 665f 7265 7374 202f 2073  sed_ref_rest / s
+0000a290: 656c 662e 615f 545f 7363 616c 6172 2920  elf.a_T_scalar) 
+0000a2a0: 2a2a 2035 202b 0d0a 2020 2020 2020 2020  ** 5 +..        
+0000a2b0: 2020 2020 2020 2020 2020 3320 2f20 3420            3 / 4 
+0000a2c0: 2a20 2873 6564 5f72 6566 5f72 6573 7420  * (sed_ref_rest 
+0000a2d0: 2f20 7365 6c66 2e61 5f54 5f73 6361 6c61  / self.a_T_scala
+0000a2e0: 7229 202a 2a20 3729 2920 2d0d 0a20 2020  r) ** 7)) -..   
+0000a2f0: 2020 2020 2020 2020 2020 2020 2028 2873               ((s
+0000a300: 6564 5f72 6573 745f 7265 6620 3c20 7365  ed_rest_ref < se
+0000a310: 6c66 2e61 5f54 5f73 6361 6c61 7229 202a  lf.a_T_scalar) *
+0000a320: 2020 2320 5265 7374 202d 2052 6566 6572    # Rest - Refer
+0000a330: 656e 6365 0d0a 2020 2020 2020 2020 2020  ence..          
+0000a340: 2020 2020 2020 2028 3120 2d20 3720 2a20         (1 - 7 * 
+0000a350: 2873 6564 5f72 6573 745f 7265 6620 2f20  (sed_rest_ref / 
+0000a360: 7365 6c66 2e61 5f54 5f73 6361 6c61 7229  self.a_T_scalar)
+0000a370: 202a 2a20 3220 2b0d 0a20 2020 2020 2020   ** 2 +..       
+0000a380: 2020 2020 2020 2020 2020 2033 3520 2f20             35 / 
+0000a390: 3420 2a20 2873 6564 5f72 6573 745f 7265  4 * (sed_rest_re
+0000a3a0: 6620 2f20 7365 6c66 2e61 5f54 5f73 6361  f / self.a_T_sca
+0000a3b0: 6c61 7229 202a 2a20 3320 2d0d 0a20 2020  lar) ** 3 -..   
+0000a3c0: 2020 2020 2020 2020 2020 2020 2020 2037                 7
+0000a3d0: 202f 2032 202a 2028 7365 645f 7265 7374   / 2 * (sed_rest
+0000a3e0: 5f72 6566 202f 2073 656c 662e 615f 545f  _ref / self.a_T_
+0000a3f0: 7363 616c 6172 2920 2a2a 2035 202b 0d0a  scalar) ** 5 +..
+0000a400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a410: 2020 3320 2f20 3420 2a20 2873 6564 5f72    3 / 4 * (sed_r
+0000a420: 6573 745f 7265 6620 2f20 7365 6c66 2e61  est_ref / self.a
+0000a430: 5f54 5f73 6361 6c61 7229 202a 2a20 3729  _T_scalar) ** 7)
+0000a440: 2920 2b0d 0a20 2020 2020 2020 2020 2020  ) +..           
+0000a450: 2020 2020 2028 2873 6564 5f72 6566 5f72       ((sed_ref_r
+0000a460: 6566 203c 2073 656c 662e 615f 545f 7363  ef < self.a_T_sc
+0000a470: 616c 6172 2920 2a20 2023 2052 6566 6572  alar) *  # Refer
+0000a480: 656e 6365 202d 2052 6566 6572 656e 6365  ence - Reference
+0000a490: 730d 0a20 2020 2020 2020 2020 2020 2020  s..             
+0000a4a0: 2020 2020 2831 202d 2037 202a 2028 7365      (1 - 7 * (se
+0000a4b0: 645f 7265 665f 7265 6620 2f20 7365 6c66  d_ref_ref / self
+0000a4c0: 2e61 5f54 5f73 6361 6c61 7229 202a 2a20  .a_T_scalar) ** 
+0000a4d0: 3220 2b0d 0a20 2020 2020 2020 2020 2020  2 +..           
+0000a4e0: 2020 2020 2020 2033 3520 2f20 3420 2a20         35 / 4 * 
+0000a4f0: 2873 6564 5f72 6566 5f72 6566 202f 2073  (sed_ref_ref / s
 0000a500: 656c 662e 615f 545f 7363 616c 6172 2920  elf.a_T_scalar) 
-0000a510: 2a20 2023 2052 6566 6572 656e 6365 202d  *  # Reference -
-0000a520: 2052 6566 6572 656e 6365 730d 0a20 2020   References..   
-0000a530: 2020 2020 2020 2020 2020 2020 2020 2831                (1
-0000a540: 202d 2037 202a 2028 7365 645f 7265 665f   - 7 * (sed_ref_
-0000a550: 7265 6620 2f20 7365 6c66 2e61 5f54 5f73  ref / self.a_T_s
-0000a560: 6361 6c61 7229 202a 2a20 3220 2b0d 0a20  calar) ** 2 +.. 
-0000a570: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a580: 2033 3520 2f20 3420 2a20 2873 6564 5f72   35 / 4 * (sed_r
-0000a590: 6566 5f72 6566 202f 2073 656c 662e 615f  ef_ref / self.a_
-0000a5a0: 545f 7363 616c 6172 2920 2a2a 2033 202d  T_scalar) ** 3 -
-0000a5b0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000a5c0: 2020 2020 3720 2f20 3220 2a20 2873 6564      7 / 2 * (sed
-0000a5d0: 5f72 6566 5f72 6566 202f 2073 656c 662e  _ref_ref / self.
-0000a5e0: 615f 545f 7363 616c 6172 2920 2a2a 2035  a_T_scalar) ** 5
-0000a5f0: 202b 0d0a 2020 2020 2020 2020 2020 2020   +..            
-0000a600: 2020 2020 2020 3320 2f20 3420 2a20 2873        3 / 4 * (s
-0000a610: 6564 5f72 6566 5f72 6566 202f 2073 656c  ed_ref_ref / sel
-0000a620: 662e 615f 545f 7363 616c 6172 2920 2a2a  f.a_T_scalar) **
-0000a630: 2037 2929 2929 0d0a 0d0a 2020 2020 2020   7))))....      
-0000a640: 2020 2320 7365 6c66 2e6e 7567 6765 745f    # self.nugget_
-0000a650: 6566 6665 6374 5f73 6361 6c61 725f 545f  effect_scalar_T_
-0000a660: 6f70 203d 2074 6865 616e 6f2e 7072 696e  op = theano.prin
-0000a670: 7469 6e67 2e50 7269 6e74 2827 6e75 6720  ting.Print('nug 
-0000a680: 7363 616c 6172 2729 2873 656c 662e 6e75  scalar')(self.nu
-0000a690: 6767 6574 5f65 6666 6563 745f 7363 616c  gget_effect_scal
-0000a6a0: 6172 5f54 5f6f 7029 0d0a 0d0a 2020 2020  ar_T_op)....    
-0000a6b0: 2020 2020 435f 4920 2b3d 2054 2e65 7965      C_I += T.eye
-0000a6c0: 2843 5f49 2e73 6861 7065 5b30 5d29 202a  (C_I.shape[0]) *
-0000a6d0: 2073 656c 662e 6e75 6767 6574 5f65 6666   self.nugget_eff
-0000a6e0: 6563 745f 7363 616c 6172 5f54 5f6f 700d  ect_scalar_T_op.
-0000a6f0: 0a20 2020 2020 2020 2023 2041 6464 206e  .        # Add n
-0000a700: 616d 6520 746f 2074 6865 2074 6865 616e  ame to the thean
-0000a710: 6f20 6e6f 6465 0d0a 2020 2020 2020 2020  o node..        
-0000a720: 435f 492e 6e61 6d65 203d 2027 436f 7661  C_I.name = 'Cova
-0000a730: 7269 616e 6365 2053 7572 6661 6365 506f  riance SurfacePo
-0000a740: 696e 7473 270d 0a0d 0a20 2020 2020 2020  ints'....       
-0000a750: 2069 6620 7374 7228 7379 732e 5f67 6574   if str(sys._get
-0000a760: 6672 616d 6528 292e 665f 636f 6465 2e63  frame().f_code.c
-0000a770: 6f5f 6e61 6d65 2920 696e 2073 656c 662e  o_name) in self.
-0000a780: 7665 7262 6f73 653a 0d0a 2020 2020 2020  verbose:..      
-0000a790: 2020 2020 2020 435f 4920 3d20 7468 6561        C_I = thea
-0000a7a0: 6e6f 2e70 7269 6e74 696e 672e 5072 696e  no.printing.Prin
-0000a7b0: 7428 2743 6f76 2073 7572 6661 6365 5f70  t('Cov surface_p
-0000a7c0: 6f69 6e74 7327 2928 435f 4929 0d0a 0d0a  oints')(C_I)....
-0000a7d0: 2020 2020 2020 2020 7265 7475 726e 2043          return C
-0000a7e0: 5f49 0d0a 0d0a 2020 2020 6465 6620 636f  _I....    def co
-0000a7f0: 765f 6772 6164 6965 6e74 7328 7365 6c66  v_gradients(self
-0000a800: 2c20 7665 7262 6f73 653d 3029 3a0d 0a20  , verbose=0):.. 
-0000a810: 2020 2020 2020 2022 2222 0d0a 2020 2020         """..    
-0000a820: 2020 2020 2043 7265 6174 6520 636f 7661       Create cova
-0000a830: 7269 616e 6365 2066 756e 6374 696f 6e20  riance function 
-0000a840: 666f 7220 7468 6520 6772 6164 6965 6e74  for the gradient
-0000a850: 730d 0a0d 0a20 2020 2020 2020 2020 5265  s....         Re
-0000a860: 7475 726e 733a 0d0a 2020 2020 2020 2020  turns:..        
-0000a870: 2020 2020 2074 6865 616e 6f2e 7465 6e73       theano.tens
-0000a880: 6f72 2e6d 6174 7269 783a 2063 6f76 6172  or.matrix: covar
-0000a890: 6961 6e63 6520 6f66 2074 6865 2067 7261  iance of the gra
-0000a8a0: 6469 656e 7473 2e20 5368 6170 6520 6e75  dients. Shape nu
-0000a8b0: 6d62 6572 206f 6620 706f 696e 7473 2069  mber of points i
-0000a8c0: 6e20 6469 705f 706f 7320 7820 6e75 6d62  n dip_pos x numb
-0000a8d0: 6572 206f 660d 0a20 2020 2020 2020 2020  er of..         
-0000a8e0: 2020 2020 706f 696e 7473 2069 6e20 6469      points in di
-0000a8f0: 705f 706f 730d 0a0d 0a20 2020 2020 2020  p_pos....       
-0000a900: 2020 2222 220d 0a0d 0a20 2020 2020 2020    """....       
-0000a910: 2023 2045 7563 6c69 6465 616e 2064 6973   # Euclidean dis
-0000a920: 7461 6e63 6573 0d0a 2020 2020 2020 2020  tances..        
-0000a930: 7365 645f 6469 7073 5f64 6970 7320 3d20  sed_dips_dips = 
-0000a940: 7365 6c66 2e73 7175 6172 6564 5f65 7563  self.squared_euc
-0000a950: 6c69 6465 616e 5f64 6973 7461 6e63 6573  lidean_distances
-0000a960: 2873 656c 662e 6469 7073 5f70 6f73 6974  (self.dips_posit
-0000a970: 696f 6e5f 7469 6c65 642c 0d0a 2020 2020  ion_tiled,..    
-0000a980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a990: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a9a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a9b0: 2020 2020 2073 656c 662e 6469 7073 5f70       self.dips_p
-0000a9c0: 6f73 6974 696f 6e5f 7469 6c65 6429 0d0a  osition_tiled)..
-0000a9d0: 0d0a 2020 2020 2020 2020 6966 2027 7365  ..        if 'se
-0000a9e0: 645f 6469 7073 5f64 6970 7327 2069 6e20  d_dips_dips' in 
-0000a9f0: 7365 6c66 2e76 6572 626f 7365 3a0d 0a20  self.verbose:.. 
-0000aa00: 2020 2020 2020 2020 2020 2073 6564 5f64             sed_d
-0000aa10: 6970 735f 6469 7073 203d 2074 6865 616e  ips_dips = thean
-0000aa20: 6f2e 7072 696e 7469 6e67 2e50 7269 6e74  o.printing.Print
-0000aa30: 2827 7365 645f 6469 7073 5f64 6970 7327  ('sed_dips_dips'
-0000aa40: 2928 7365 645f 6469 7073 5f64 6970 7329  )(sed_dips_dips)
-0000aa50: 0d0a 0d0a 2020 2020 2020 2020 2320 4361  ....        # Ca
-0000aa60: 7274 6573 6961 6e20 6469 7374 616e 6365  rtesian distance
-0000aa70: 7320 6265 7477 6565 6e20 6469 7073 2070  s between dips p
-0000aa80: 6f73 6974 696f 6e73 0d0a 2020 2020 2020  ositions..      
-0000aa90: 2020 685f 7520 3d20 542e 7665 7274 6963    h_u = T.vertic
-0000aaa0: 616c 5f73 7461 636b 280d 0a20 2020 2020  al_stack(..     
-0000aab0: 2020 2020 2020 2054 2e74 696c 6528 7365         T.tile(se
-0000aac0: 6c66 2e64 6970 735f 706f 7369 7469 6f6e  lf.dips_position
-0000aad0: 5b3a 2c20 305d 202d 2073 656c 662e 6469  [:, 0] - self.di
-0000aae0: 7073 5f70 6f73 6974 696f 6e5b 3a2c 2030  ps_position[:, 0
-0000aaf0: 5d2e 7265 7368 6170 6528 0d0a 2020 2020  ].reshape(..    
-0000ab00: 2020 2020 2020 2020 2020 2020 2873 656c              (sel
-0000ab10: 662e 6469 7073 5f70 6f73 6974 696f 6e5b  f.dips_position[
-0000ab20: 3a2c 2030 5d2e 7368 6170 655b 305d 2c20  :, 0].shape[0], 
-0000ab30: 3129 292c 0d0a 2020 2020 2020 2020 2020  1)),..          
-0000ab40: 2020 2020 2020 2020 2073 656c 662e 6e5f           self.n_
-0000ab50: 6469 6d65 6e73 696f 6e73 292c 0d0a 2020  dimensions),..  
-0000ab60: 2020 2020 2020 2020 2020 542e 7469 6c65            T.tile
-0000ab70: 2873 656c 662e 6469 7073 5f70 6f73 6974  (self.dips_posit
-0000ab80: 696f 6e5b 3a2c 2031 5d20 2d20 7365 6c66  ion[:, 1] - self
-0000ab90: 2e64 6970 735f 706f 7369 7469 6f6e 5b3a  .dips_position[:
-0000aba0: 2c20 315d 2e72 6573 6861 7065 280d 0a20  , 1].reshape(.. 
-0000abb0: 2020 2020 2020 2020 2020 2020 2020 2028                 (
-0000abc0: 7365 6c66 2e64 6970 735f 706f 7369 7469  self.dips_positi
-0000abd0: 6f6e 5b3a 2c20 315d 2e73 6861 7065 5b30  on[:, 1].shape[0
-0000abe0: 5d2c 2031 2929 2c0d 0a20 2020 2020 2020  ], 1)),..       
-0000abf0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-0000ac00: 2e6e 5f64 696d 656e 7369 6f6e 7329 2c0d  .n_dimensions),.
-0000ac10: 0a20 2020 2020 2020 2020 2020 2054 2e74  .            T.t
-0000ac20: 696c 6528 7365 6c66 2e64 6970 735f 706f  ile(self.dips_po
-0000ac30: 7369 7469 6f6e 5b3a 2c20 325d 202d 2073  sition[:, 2] - s
-0000ac40: 656c 662e 6469 7073 5f70 6f73 6974 696f  elf.dips_positio
-0000ac50: 6e5b 3a2c 2032 5d2e 7265 7368 6170 6528  n[:, 2].reshape(
-0000ac60: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000ac70: 2020 2873 656c 662e 6469 7073 5f70 6f73    (self.dips_pos
-0000ac80: 6974 696f 6e5b 3a2c 2032 5d2e 7368 6170  ition[:, 2].shap
-0000ac90: 655b 305d 2c20 3129 292c 0d0a 2020 2020  e[0], 1)),..    
-0000aca0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-0000acb0: 656c 662e 6e5f 6469 6d65 6e73 696f 6e73  elf.n_dimensions
-0000acc0: 2929 0d0a 0d0a 2020 2020 2020 2020 2320  ))....        # 
-0000acd0: 5472 616e 7370 6f73 650d 0a20 2020 2020  Transpose..     
-0000ace0: 2020 2068 5f76 203d 2068 5f75 2e54 0d0a     h_v = h_u.T..
-0000acf0: 0d0a 2020 2020 2020 2020 2320 5065 7270  ..        # Perp
-0000ad00: 656e 6469 6375 6c61 7269 7479 206d 6174  endicularity mat
-0000ad10: 7269 782e 2042 6f6f 6c65 616e 206d 6174  rix. Boolean mat
-0000ad20: 7269 7820 746f 2073 6570 6172 6174 6520  rix to separate 
-0000ad30: 6372 6f73 732d 636f 7661 7269 616e 6365  cross-covariance
-0000ad40: 2061 6e64 0d0a 2020 2020 2020 2020 2320   and..        # 
-0000ad50: 6576 6572 7920 6772 6164 6965 6e74 2064  every gradient d
-0000ad60: 6972 6563 7469 6f6e 2063 6f76 6172 6961  irection covaria
-0000ad70: 6e63 6520 2862 6c6f 636b 2064 6961 676f  nce (block diago
-0000ad80: 6e61 6c29 0d0a 2020 2020 2020 2020 7065  nal)..        pe
-0000ad90: 7270 656e 6469 6375 6c61 7269 7479 5f6d  rpendicularity_m
-0000ada0: 6174 7269 7820 3d20 542e 7a65 726f 735f  atrix = T.zeros_
-0000adb0: 6c69 6b65 2873 6564 5f64 6970 735f 6469  like(sed_dips_di
-0000adc0: 7073 290d 0a0d 0a20 2020 2020 2020 2023  ps)....        #
-0000add0: 2043 726f 7373 2d63 6f76 6172 6961 6e63   Cross-covarianc
-0000ade0: 6573 206f 6620 780d 0a20 2020 2020 2020  es of x..       
-0000adf0: 2070 6572 7065 6e64 6963 756c 6172 6974   perpendicularit
-0000ae00: 795f 6d61 7472 6978 203d 2054 2e73 6574  y_matrix = T.set
-0000ae10: 5f73 7562 7465 6e73 6f72 280d 0a20 2020  _subtensor(..   
-0000ae20: 2020 2020 2020 2020 2070 6572 7065 6e64           perpend
-0000ae30: 6963 756c 6172 6974 795f 6d61 7472 6978  icularity_matrix
-0000ae40: 5b30 3a73 656c 662e 6469 7073 5f70 6f73  [0:self.dips_pos
-0000ae50: 6974 696f 6e2e 7368 6170 655b 305d 2c0d  ition.shape[0],.
-0000ae60: 0a20 2020 2020 2020 2020 2020 2030 3a73  .            0:s
-0000ae70: 656c 662e 6469 7073 5f70 6f73 6974 696f  elf.dips_positio
-0000ae80: 6e2e 7368 6170 655b 305d 5d2c 2031 290d  n.shape[0]], 1).
-0000ae90: 0a0d 0a20 2020 2020 2020 2023 2043 726f  ...        # Cro
-0000aea0: 7373 2d63 6f76 6172 6961 6e63 6573 206f  ss-covariances o
-0000aeb0: 6620 790d 0a20 2020 2020 2020 2070 6572  f y..        per
-0000aec0: 7065 6e64 6963 756c 6172 6974 795f 6d61  pendicularity_ma
-0000aed0: 7472 6978 203d 2054 2e73 6574 5f73 7562  trix = T.set_sub
-0000aee0: 7465 6e73 6f72 280d 0a20 2020 2020 2020  tensor(..       
-0000aef0: 2020 2020 2070 6572 7065 6e64 6963 756c       perpendicul
-0000af00: 6172 6974 795f 6d61 7472 6978 5b0d 0a20  arity_matrix[.. 
-0000af10: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-0000af20: 6469 7073 5f70 6f73 6974 696f 6e2e 7368  dips_position.sh
-0000af30: 6170 655b 305d 3a73 656c 662e 6469 7073  ape[0]:self.dips
-0000af40: 5f70 6f73 6974 696f 6e2e 7368 6170 655b  _position.shape[
-0000af50: 305d 202a 2032 2c0d 0a20 2020 2020 2020  0] * 2,..       
-0000af60: 2020 2020 2073 656c 662e 6469 7073 5f70       self.dips_p
-0000af70: 6f73 6974 696f 6e2e 7368 6170 655b 305d  osition.shape[0]
-0000af80: 3a73 656c 662e 6469 7073 5f70 6f73 6974  :self.dips_posit
-0000af90: 696f 6e2e 7368 6170 655b 305d 202a 2032  ion.shape[0] * 2
-0000afa0: 5d2c 2031 290d 0a0d 0a20 2020 2020 2020  ], 1)....       
-0000afb0: 2023 2043 726f 7373 2d63 6f76 6172 6961   # Cross-covaria
-0000afc0: 6e63 6573 206f 6620 7a0d 0a20 2020 2020  nces of z..     
-0000afd0: 2020 2070 6572 7065 6e64 6963 756c 6172     perpendicular
-0000afe0: 6974 795f 6d61 7472 6978 203d 2054 2e73  ity_matrix = T.s
-0000aff0: 6574 5f73 7562 7465 6e73 6f72 280d 0a20  et_subtensor(.. 
-0000b000: 2020 2020 2020 2020 2020 2070 6572 7065             perpe
-0000b010: 6e64 6963 756c 6172 6974 795f 6d61 7472  ndicularity_matr
-0000b020: 6978 5b0d 0a20 2020 2020 2020 2020 2020  ix[..           
-0000b030: 2073 656c 662e 6469 7073 5f70 6f73 6974   self.dips_posit
-0000b040: 696f 6e2e 7368 6170 655b 305d 202a 2032  ion.shape[0] * 2
-0000b050: 3a73 656c 662e 6469 7073 5f70 6f73 6974  :self.dips_posit
-0000b060: 696f 6e2e 7368 6170 655b 305d 202a 2033  ion.shape[0] * 3
-0000b070: 2c0d 0a20 2020 2020 2020 2020 2020 2073  ,..            s
-0000b080: 656c 662e 6469 7073 5f70 6f73 6974 696f  elf.dips_positio
-0000b090: 6e2e 7368 6170 655b 305d 202a 2032 3a73  n.shape[0] * 2:s
-0000b0a0: 656c 662e 6469 7073 5f70 6f73 6974 696f  elf.dips_positio
-0000b0b0: 6e2e 7368 6170 655b 305d 202a 2033 5d2c  n.shape[0] * 3],
-0000b0c0: 2031 290d 0a0d 0a20 2020 2020 2020 2023   1)....        #
-0000b0d0: 2043 6f76 6172 6961 6e63 6520 6d61 7472   Covariance matr
-0000b0e0: 6978 2066 6f72 2067 7261 6469 656e 7473  ix for gradients
-0000b0f0: 2061 7420 6576 6572 7920 7879 7a20 6469   at every xyz di
-0000b100: 7265 6374 696f 6e20 616e 6420 7468 6569  rection and thei
-0000b110: 7220 6372 6f73 732d 636f 7661 7269 616e  r cross-covarian
-0000b120: 6365 730d 0a20 2020 2020 2020 2043 5f47  ces..        C_G
-0000b130: 203d 2054 2e73 7769 7463 6828 0d0a 2020   = T.switch(..  
-0000b140: 2020 2020 2020 2020 2020 542e 6571 2873            T.eq(s
-0000b150: 6564 5f64 6970 735f 6469 7073 2c20 3029  ed_dips_dips, 0)
-0000b160: 2c20 2023 2054 6869 7320 6973 2074 6865  ,  # This is the
-0000b170: 2063 6f6e 6469 7469 6f6e 0d0a 2020 2020   condition..    
-0000b180: 2020 2020 2020 2020 302c 2020 2320 4966          0,  # If
-0000b190: 2074 7275 6520 6974 2069 7320 6571 7561   true it is equa
-0000b1a0: 6c20 746f 2030 2e20 5468 6973 2069 7320  l to 0. This is 
-0000b1b0: 686f 7720 6120 6469 7265 6374 696f 6e20  how a direction 
-0000b1c0: 6166 6665 6374 2061 6e6f 7468 6572 0d0a  affect another..
-0000b1d0: 2020 2020 2020 2020 2020 2020 2820 2023              (  #
-0000b1e0: 2065 6c73 652c 2066 6f6c 6c6f 7769 6e67   else, following
-0000b1f0: 2043 6869 6c65 7320 626f 6f6b 0d0a 2020   Chiles book..  
-0000b200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b210: 2020 2868 5f75 202a 2068 5f76 202f 2073    (h_u * h_v / s
-0000b220: 6564 5f64 6970 735f 6469 7073 202a 2a20  ed_dips_dips ** 
-0000b230: 3229 202a 0d0a 2020 2020 2020 2020 2020  2) *..          
-0000b240: 2020 2020 2020 2020 2020 2828 0d0a 2020            ((..  
+0000a510: 2a2a 2033 202d 0d0a 2020 2020 2020 2020  ** 3 -..        
+0000a520: 2020 2020 2020 2020 2020 3720 2f20 3220            7 / 2 
+0000a530: 2a20 2873 6564 5f72 6566 5f72 6566 202f  * (sed_ref_ref /
+0000a540: 2073 656c 662e 615f 545f 7363 616c 6172   self.a_T_scalar
+0000a550: 2920 2a2a 2035 202b 0d0a 2020 2020 2020  ) ** 5 +..      
+0000a560: 2020 2020 2020 2020 2020 2020 3320 2f20              3 / 
+0000a570: 3420 2a20 2873 6564 5f72 6566 5f72 6566  4 * (sed_ref_ref
+0000a580: 202f 2073 656c 662e 615f 545f 7363 616c   / self.a_T_scal
+0000a590: 6172 2920 2a2a 2037 2929 2929 0d0a 0d0a  ar) ** 7))))....
+0000a5a0: 2020 2020 2020 2020 2320 7365 6c66 2e6e          # self.n
+0000a5b0: 7567 6765 745f 6566 6665 6374 5f73 6361  ugget_effect_sca
+0000a5c0: 6c61 725f 545f 6f70 203d 2061 6573 6172  lar_T_op = aesar
+0000a5d0: 612e 7072 696e 7469 6e67 2e50 7269 6e74  a.printing.Print
+0000a5e0: 2827 6e75 6720 7363 616c 6172 2729 2873  ('nug scalar')(s
+0000a5f0: 656c 662e 6e75 6767 6574 5f65 6666 6563  elf.nugget_effec
+0000a600: 745f 7363 616c 6172 5f54 5f6f 7029 0d0a  t_scalar_T_op)..
+0000a610: 0d0a 2020 2020 2020 2020 435f 4920 2b3d  ..        C_I +=
+0000a620: 2054 2e65 7965 2843 5f49 2e73 6861 7065   T.eye(C_I.shape
+0000a630: 5b30 5d29 202a 2073 656c 662e 6e75 6767  [0]) * self.nugg
+0000a640: 6574 5f65 6666 6563 745f 7363 616c 6172  et_effect_scalar
+0000a650: 5f54 5f6f 700d 0a20 2020 2020 2020 2023  _T_op..        #
+0000a660: 2041 6464 206e 616d 6520 746f 2074 6865   Add name to the
+0000a670: 2061 6573 6172 6120 6e6f 6465 0d0a 2020   aesara node..  
+0000a680: 2020 2020 2020 435f 492e 6e61 6d65 203d        C_I.name =
+0000a690: 2027 436f 7661 7269 616e 6365 2053 7572   'Covariance Sur
+0000a6a0: 6661 6365 506f 696e 7473 270d 0a0d 0a20  facePoints'.... 
+0000a6b0: 2020 2020 2020 2069 6620 7374 7228 7379         if str(sy
+0000a6c0: 732e 5f67 6574 6672 616d 6528 292e 665f  s._getframe().f_
+0000a6d0: 636f 6465 2e63 6f5f 6e61 6d65 2920 696e  code.co_name) in
+0000a6e0: 2073 656c 662e 7665 7262 6f73 653a 0d0a   self.verbose:..
+0000a6f0: 2020 2020 2020 2020 2020 2020 435f 4920              C_I 
+0000a700: 3d20 6165 7361 7261 2e70 7269 6e74 696e  = aesara.printin
+0000a710: 672e 5072 696e 7428 2743 6f76 2073 7572  g.Print('Cov sur
+0000a720: 6661 6365 5f70 6f69 6e74 7327 2928 435f  face_points')(C_
+0000a730: 4929 0d0a 0d0a 2020 2020 2020 2020 7265  I)....        re
+0000a740: 7475 726e 2043 5f49 0d0a 0d0a 2020 2020  turn C_I....    
+0000a750: 6465 6620 636f 765f 6772 6164 6965 6e74  def cov_gradient
+0000a760: 7328 7365 6c66 2c20 7665 7262 6f73 653d  s(self, verbose=
+0000a770: 3029 3a0d 0a20 2020 2020 2020 2022 2222  0):..        """
+0000a780: 0d0a 2020 2020 2020 2020 2043 7265 6174  ..         Creat
+0000a790: 6520 636f 7661 7269 616e 6365 2066 756e  e covariance fun
+0000a7a0: 6374 696f 6e20 666f 7220 7468 6520 6772  ction for the gr
+0000a7b0: 6164 6965 6e74 730d 0a0d 0a20 2020 2020  adients....     
+0000a7c0: 2020 2020 5265 7475 726e 733a 0d0a 2020      Returns:..  
+0000a7d0: 2020 2020 2020 2020 2020 2061 6573 6172             aesar
+0000a7e0: 612e 7465 6e73 6f72 2e6d 6174 7269 783a  a.tensor.matrix:
+0000a7f0: 2063 6f76 6172 6961 6e63 6520 6f66 2074   covariance of t
+0000a800: 6865 2067 7261 6469 656e 7473 2e20 5368  he gradients. Sh
+0000a810: 6170 6520 6e75 6d62 6572 206f 6620 706f  ape number of po
+0000a820: 696e 7473 2069 6e20 6469 705f 706f 7320  ints in dip_pos 
+0000a830: 7820 6e75 6d62 6572 206f 660d 0a20 2020  x number of..   
+0000a840: 2020 2020 2020 2020 2020 706f 696e 7473            points
+0000a850: 2069 6e20 6469 705f 706f 730d 0a0d 0a20   in dip_pos.... 
+0000a860: 2020 2020 2020 2020 2222 220d 0a0d 0a20          """.... 
+0000a870: 2020 2020 2020 2023 2045 7563 6c69 6465         # Euclide
+0000a880: 616e 2064 6973 7461 6e63 6573 0d0a 2020  an distances..  
+0000a890: 2020 2020 2020 7365 645f 6469 7073 5f64        sed_dips_d
+0000a8a0: 6970 7320 3d20 7365 6c66 2e73 7175 6172  ips = self.squar
+0000a8b0: 6564 5f65 7563 6c69 6465 616e 5f64 6973  ed_euclidean_dis
+0000a8c0: 7461 6e63 6573 2873 656c 662e 6469 7073  tances(self.dips
+0000a8d0: 5f70 6f73 6974 696f 6e5f 7469 6c65 642c  _position_tiled,
+0000a8e0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000a8f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a900: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a910: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+0000a920: 6469 7073 5f70 6f73 6974 696f 6e5f 7469  dips_position_ti
+0000a930: 6c65 6429 0d0a 0d0a 2020 2020 2020 2020  led)....        
+0000a940: 6966 2027 7365 645f 6469 7073 5f64 6970  if 'sed_dips_dip
+0000a950: 7327 2069 6e20 7365 6c66 2e76 6572 626f  s' in self.verbo
+0000a960: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
+0000a970: 2073 6564 5f64 6970 735f 6469 7073 203d   sed_dips_dips =
+0000a980: 2061 6573 6172 612e 7072 696e 7469 6e67   aesara.printing
+0000a990: 2e50 7269 6e74 2827 7365 645f 6469 7073  .Print('sed_dips
+0000a9a0: 5f64 6970 7327 2928 7365 645f 6469 7073  _dips')(sed_dips
+0000a9b0: 5f64 6970 7329 0d0a 0d0a 2020 2020 2020  _dips)....      
+0000a9c0: 2020 2320 4361 7274 6573 6961 6e20 6469    # Cartesian di
+0000a9d0: 7374 616e 6365 7320 6265 7477 6565 6e20  stances between 
+0000a9e0: 6469 7073 2070 6f73 6974 696f 6e73 0d0a  dips positions..
+0000a9f0: 2020 2020 2020 2020 685f 7520 3d20 542e          h_u = T.
+0000aa00: 7665 7274 6963 616c 5f73 7461 636b 280d  vertical_stack(.
+0000aa10: 0a20 2020 2020 2020 2020 2020 2054 2e74  .            T.t
+0000aa20: 696c 6528 7365 6c66 2e64 6970 735f 706f  ile(self.dips_po
+0000aa30: 7369 7469 6f6e 5b3a 2c20 305d 202d 2073  sition[:, 0] - s
+0000aa40: 656c 662e 6469 7073 5f70 6f73 6974 696f  elf.dips_positio
+0000aa50: 6e5b 3a2c 2030 5d2e 7265 7368 6170 6528  n[:, 0].reshape(
+0000aa60: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000aa70: 2020 2873 656c 662e 6469 7073 5f70 6f73    (self.dips_pos
+0000aa80: 6974 696f 6e5b 3a2c 2030 5d2e 7368 6170  ition[:, 0].shap
+0000aa90: 655b 305d 2c20 3129 292c 0d0a 2020 2020  e[0], 1)),..    
+0000aaa0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+0000aab0: 656c 662e 6e5f 6469 6d65 6e73 696f 6e73  elf.n_dimensions
+0000aac0: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
+0000aad0: 542e 7469 6c65 2873 656c 662e 6469 7073  T.tile(self.dips
+0000aae0: 5f70 6f73 6974 696f 6e5b 3a2c 2031 5d20  _position[:, 1] 
+0000aaf0: 2d20 7365 6c66 2e64 6970 735f 706f 7369  - self.dips_posi
+0000ab00: 7469 6f6e 5b3a 2c20 315d 2e72 6573 6861  tion[:, 1].resha
+0000ab10: 7065 280d 0a20 2020 2020 2020 2020 2020  pe(..           
+0000ab20: 2020 2020 2028 7365 6c66 2e64 6970 735f       (self.dips_
+0000ab30: 706f 7369 7469 6f6e 5b3a 2c20 315d 2e73  position[:, 1].s
+0000ab40: 6861 7065 5b30 5d2c 2031 2929 2c0d 0a20  hape[0], 1)),.. 
+0000ab50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ab60: 2020 7365 6c66 2e6e 5f64 696d 656e 7369    self.n_dimensi
+0000ab70: 6f6e 7329 2c0d 0a20 2020 2020 2020 2020  ons),..         
+0000ab80: 2020 2054 2e74 696c 6528 7365 6c66 2e64     T.tile(self.d
+0000ab90: 6970 735f 706f 7369 7469 6f6e 5b3a 2c20  ips_position[:, 
+0000aba0: 325d 202d 2073 656c 662e 6469 7073 5f70  2] - self.dips_p
+0000abb0: 6f73 6974 696f 6e5b 3a2c 2032 5d2e 7265  osition[:, 2].re
+0000abc0: 7368 6170 6528 0d0a 2020 2020 2020 2020  shape(..        
+0000abd0: 2020 2020 2020 2020 2873 656c 662e 6469          (self.di
+0000abe0: 7073 5f70 6f73 6974 696f 6e5b 3a2c 2032  ps_position[:, 2
+0000abf0: 5d2e 7368 6170 655b 305d 2c20 3129 292c  ].shape[0], 1)),
+0000ac00: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000ac10: 2020 2020 2073 656c 662e 6e5f 6469 6d65       self.n_dime
+0000ac20: 6e73 696f 6e73 2929 0d0a 0d0a 2020 2020  nsions))....    
+0000ac30: 2020 2020 2320 5472 616e 7370 6f73 650d      # Transpose.
+0000ac40: 0a20 2020 2020 2020 2068 5f76 203d 2068  .        h_v = h
+0000ac50: 5f75 2e54 0d0a 0d0a 2020 2020 2020 2020  _u.T....        
+0000ac60: 2320 5065 7270 656e 6469 6375 6c61 7269  # Perpendiculari
+0000ac70: 7479 206d 6174 7269 782e 2042 6f6f 6c65  ty matrix. Boole
+0000ac80: 616e 206d 6174 7269 7820 746f 2073 6570  an matrix to sep
+0000ac90: 6172 6174 6520 6372 6f73 732d 636f 7661  arate cross-cova
+0000aca0: 7269 616e 6365 2061 6e64 0d0a 2020 2020  riance and..    
+0000acb0: 2020 2020 2320 6576 6572 7920 6772 6164      # every grad
+0000acc0: 6965 6e74 2064 6972 6563 7469 6f6e 2063  ient direction c
+0000acd0: 6f76 6172 6961 6e63 6520 2862 6c6f 636b  ovariance (block
+0000ace0: 2064 6961 676f 6e61 6c29 0d0a 2020 2020   diagonal)..    
+0000acf0: 2020 2020 7065 7270 656e 6469 6375 6c61      perpendicula
+0000ad00: 7269 7479 5f6d 6174 7269 7820 3d20 542e  rity_matrix = T.
+0000ad10: 7a65 726f 735f 6c69 6b65 2873 6564 5f64  zeros_like(sed_d
+0000ad20: 6970 735f 6469 7073 290d 0a0d 0a20 2020  ips_dips)....   
+0000ad30: 2020 2020 2023 2043 726f 7373 2d63 6f76       # Cross-cov
+0000ad40: 6172 6961 6e63 6573 206f 6620 780d 0a20  ariances of x.. 
+0000ad50: 2020 2020 2020 2070 6572 7065 6e64 6963         perpendic
+0000ad60: 756c 6172 6974 795f 6d61 7472 6978 203d  ularity_matrix =
+0000ad70: 2054 2e73 6574 5f73 7562 7465 6e73 6f72   T.set_subtensor
+0000ad80: 280d 0a20 2020 2020 2020 2020 2020 2070  (..            p
+0000ad90: 6572 7065 6e64 6963 756c 6172 6974 795f  erpendicularity_
+0000ada0: 6d61 7472 6978 5b30 3a73 656c 662e 6469  matrix[0:self.di
+0000adb0: 7073 5f70 6f73 6974 696f 6e2e 7368 6170  ps_position.shap
+0000adc0: 655b 305d 2c0d 0a20 2020 2020 2020 2020  e[0],..         
+0000add0: 2020 2030 3a73 656c 662e 6469 7073 5f70     0:self.dips_p
+0000ade0: 6f73 6974 696f 6e2e 7368 6170 655b 305d  osition.shape[0]
+0000adf0: 5d2c 2031 290d 0a0d 0a20 2020 2020 2020  ], 1)....       
+0000ae00: 2023 2043 726f 7373 2d63 6f76 6172 6961   # Cross-covaria
+0000ae10: 6e63 6573 206f 6620 790d 0a20 2020 2020  nces of y..     
+0000ae20: 2020 2070 6572 7065 6e64 6963 756c 6172     perpendicular
+0000ae30: 6974 795f 6d61 7472 6978 203d 2054 2e73  ity_matrix = T.s
+0000ae40: 6574 5f73 7562 7465 6e73 6f72 280d 0a20  et_subtensor(.. 
+0000ae50: 2020 2020 2020 2020 2020 2070 6572 7065             perpe
+0000ae60: 6e64 6963 756c 6172 6974 795f 6d61 7472  ndicularity_matr
+0000ae70: 6978 5b0d 0a20 2020 2020 2020 2020 2020  ix[..           
+0000ae80: 2073 656c 662e 6469 7073 5f70 6f73 6974   self.dips_posit
+0000ae90: 696f 6e2e 7368 6170 655b 305d 3a73 656c  ion.shape[0]:sel
+0000aea0: 662e 6469 7073 5f70 6f73 6974 696f 6e2e  f.dips_position.
+0000aeb0: 7368 6170 655b 305d 202a 2032 2c0d 0a20  shape[0] * 2,.. 
+0000aec0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+0000aed0: 6469 7073 5f70 6f73 6974 696f 6e2e 7368  dips_position.sh
+0000aee0: 6170 655b 305d 3a73 656c 662e 6469 7073  ape[0]:self.dips
+0000aef0: 5f70 6f73 6974 696f 6e2e 7368 6170 655b  _position.shape[
+0000af00: 305d 202a 2032 5d2c 2031 290d 0a0d 0a20  0] * 2], 1).... 
+0000af10: 2020 2020 2020 2023 2043 726f 7373 2d63         # Cross-c
+0000af20: 6f76 6172 6961 6e63 6573 206f 6620 7a0d  ovariances of z.
+0000af30: 0a20 2020 2020 2020 2070 6572 7065 6e64  .        perpend
+0000af40: 6963 756c 6172 6974 795f 6d61 7472 6978  icularity_matrix
+0000af50: 203d 2054 2e73 6574 5f73 7562 7465 6e73   = T.set_subtens
+0000af60: 6f72 280d 0a20 2020 2020 2020 2020 2020  or(..           
+0000af70: 2070 6572 7065 6e64 6963 756c 6172 6974   perpendicularit
+0000af80: 795f 6d61 7472 6978 5b0d 0a20 2020 2020  y_matrix[..     
+0000af90: 2020 2020 2020 2073 656c 662e 6469 7073         self.dips
+0000afa0: 5f70 6f73 6974 696f 6e2e 7368 6170 655b  _position.shape[
+0000afb0: 305d 202a 2032 3a73 656c 662e 6469 7073  0] * 2:self.dips
+0000afc0: 5f70 6f73 6974 696f 6e2e 7368 6170 655b  _position.shape[
+0000afd0: 305d 202a 2033 2c0d 0a20 2020 2020 2020  0] * 3,..       
+0000afe0: 2020 2020 2073 656c 662e 6469 7073 5f70       self.dips_p
+0000aff0: 6f73 6974 696f 6e2e 7368 6170 655b 305d  osition.shape[0]
+0000b000: 202a 2032 3a73 656c 662e 6469 7073 5f70   * 2:self.dips_p
+0000b010: 6f73 6974 696f 6e2e 7368 6170 655b 305d  osition.shape[0]
+0000b020: 202a 2033 5d2c 2031 290d 0a0d 0a20 2020   * 3], 1)....   
+0000b030: 2020 2020 2023 2043 6f76 6172 6961 6e63       # Covarianc
+0000b040: 6520 6d61 7472 6978 2066 6f72 2067 7261  e matrix for gra
+0000b050: 6469 656e 7473 2061 7420 6576 6572 7920  dients at every 
+0000b060: 7879 7a20 6469 7265 6374 696f 6e20 616e  xyz direction an
+0000b070: 6420 7468 6569 7220 6372 6f73 732d 636f  d their cross-co
+0000b080: 7661 7269 616e 6365 730d 0a20 2020 2020  variances..     
+0000b090: 2020 2043 5f47 203d 2054 2e73 7769 7463     C_G = T.switc
+0000b0a0: 6828 0d0a 2020 2020 2020 2020 2020 2020  h(..            
+0000b0b0: 542e 6571 2873 6564 5f64 6970 735f 6469  T.eq(sed_dips_di
+0000b0c0: 7073 2c20 3029 2c20 2023 2054 6869 7320  ps, 0),  # This 
+0000b0d0: 6973 2074 6865 2063 6f6e 6469 7469 6f6e  is the condition
+0000b0e0: 0d0a 2020 2020 2020 2020 2020 2020 302c  ..            0,
+0000b0f0: 2020 2320 4966 2074 7275 6520 6974 2069    # If true it i
+0000b100: 7320 6571 7561 6c20 746f 2030 2e20 5468  s equal to 0. Th
+0000b110: 6973 2069 7320 686f 7720 6120 6469 7265  is is how a dire
+0000b120: 6374 696f 6e20 6166 6665 6374 2061 6e6f  ction affect ano
+0000b130: 7468 6572 0d0a 2020 2020 2020 2020 2020  ther..          
+0000b140: 2020 2820 2023 2065 6c73 652c 2066 6f6c    (  # else, fol
+0000b150: 6c6f 7769 6e67 2043 6869 6c65 7320 626f  lowing Chiles bo
+0000b160: 6f6b 0d0a 2020 2020 2020 2020 2020 2020  ok..            
+0000b170: 2020 2020 2020 2020 2868 5f75 202a 2068          (h_u * h
+0000b180: 5f76 202f 2073 6564 5f64 6970 735f 6469  _v / sed_dips_di
+0000b190: 7073 202a 2a20 3229 202a 0d0a 2020 2020  ps ** 2) *..    
+0000b1a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b1b0: 2828 0d0a 2020 2020 2020 2020 2020 2020  ((..            
+0000b1c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b1d0: 2028 7365 645f 6469 7073 5f64 6970 7320   (sed_dips_dips 
+0000b1e0: 3c20 7365 6c66 2e61 5f54 5f73 6361 6c61  < self.a_T_scala
+0000b1f0: 7229 202a 2020 2320 6669 7273 7420 6465  r) *  # first de
+0000b200: 7269 7661 7469 7665 0d0a 2020 2020 2020  rivative..      
+0000b210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b220: 2020 2020 2020 2028 2d73 656c 662e 635f         (-self.c_
+0000b230: 6f5f 545f 7363 616c 6172 202a 2028 280d  o_T_scalar * ((.
+0000b240: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
 0000b250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b260: 2020 2020 2020 2020 2020 2028 7365 645f             (sed_
-0000b270: 6469 7073 5f64 6970 7320 3c20 7365 6c66  dips_dips < self
-0000b280: 2e61 5f54 5f73 6361 6c61 7229 202a 2020  .a_T_scalar) *  
-0000b290: 2320 6669 7273 7420 6465 7269 7661 7469  # first derivati
-0000b2a0: 7665 0d0a 2020 2020 2020 2020 2020 2020  ve..            
-0000b2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b2c0: 2028 2d73 656c 662e 635f 6f5f 545f 7363   (-self.c_o_T_sc
-0000b2d0: 616c 6172 202a 2028 280d 0a20 2020 2020  alar * ((..     
+0000b260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b270: 2020 2020 2020 2020 2020 2020 202d 3134               -14
+0000b280: 202f 2073 656c 662e 615f 545f 7363 616c   / self.a_T_scal
+0000b290: 6172 202a 2a20 3229 202b 2031 3035 202f  ar ** 2) + 105 /
+0000b2a0: 2034 202a 2073 6564 5f64 6970 735f 6469   4 * sed_dips_di
+0000b2b0: 7073 202f 2073 656c 662e 615f 545f 7363  ps / self.a_T_sc
+0000b2c0: 616c 6172 202a 2a20 3320 2d0d 0a20 2020  alar ** 3 -..   
+0000b2d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 0000b2e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 0000b2f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b310: 2020 2020 2020 202d 3134 202f 2073 656c         -14 / sel
-0000b320: 662e 615f 545f 7363 616c 6172 202a 2a20  f.a_T_scalar ** 
-0000b330: 3229 202b 2031 3035 202f 2034 202a 2073  2) + 105 / 4 * s
-0000b340: 6564 5f64 6970 735f 6469 7073 202f 2073  ed_dips_dips / s
-0000b350: 656c 662e 615f 545f 7363 616c 6172 202a  elf.a_T_scalar *
-0000b360: 2a20 3320 2d0d 0a20 2020 2020 2020 2020  * 3 -..         
-0000b370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b380: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b390: 2020 2020 2020 2020 2020 2033 3520 2f20             35 / 
-0000b3a0: 3220 2a20 7365 645f 6469 7073 5f64 6970  2 * sed_dips_dip
-0000b3b0: 7320 2a2a 2033 202f 2073 656c 662e 615f  s ** 3 / self.a_
-0000b3c0: 545f 7363 616c 6172 202a 2a20 3520 2b0d  T_scalar ** 5 +.
-0000b3d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000b3e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b3f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b400: 2020 2020 2032 3120 2f20 3420 2a20 7365       21 / 4 * se
-0000b410: 645f 6469 7073 5f64 6970 7320 2a2a 2035  d_dips_dips ** 5
-0000b420: 202f 2073 656c 662e 615f 545f 7363 616c   / self.a_T_scal
-0000b430: 6172 202a 2a20 3729 2929 202b 0d0a 2020  ar ** 7))) +..  
-0000b440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b450: 2020 2028 7365 645f 6469 7073 5f64 6970     (sed_dips_dip
-0000b460: 7320 3c20 7365 6c66 2e61 5f54 5f73 6361  s < self.a_T_sca
-0000b470: 6c61 7229 202a 2020 2320 5365 636f 6e64  lar) *  # Second
-0000b480: 2064 6572 6976 6174 6976 650d 0a20 2020   derivative..   
+0000b300: 2033 3520 2f20 3220 2a20 7365 645f 6469   35 / 2 * sed_di
+0000b310: 7073 5f64 6970 7320 2a2a 2033 202f 2073  ps_dips ** 3 / s
+0000b320: 656c 662e 615f 545f 7363 616c 6172 202a  elf.a_T_scalar *
+0000b330: 2a20 3520 2b0d 0a20 2020 2020 2020 2020  * 5 +..         
+0000b340: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b350: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b360: 2020 2020 2020 2020 2020 2032 3120 2f20             21 / 
+0000b370: 3420 2a20 7365 645f 6469 7073 5f64 6970  4 * sed_dips_dip
+0000b380: 7320 2a2a 2035 202f 2073 656c 662e 615f  s ** 5 / self.a_
+0000b390: 545f 7363 616c 6172 202a 2a20 3729 2929  T_scalar ** 7)))
+0000b3a0: 202b 0d0a 2020 2020 2020 2020 2020 2020   +..            
+0000b3b0: 2020 2020 2020 2020 2028 7365 645f 6469           (sed_di
+0000b3c0: 7073 5f64 6970 7320 3c20 7365 6c66 2e61  ps_dips < self.a
+0000b3d0: 5f54 5f73 6361 6c61 7229 202a 2020 2320  _T_scalar) *  # 
+0000b3e0: 5365 636f 6e64 2064 6572 6976 6174 6976  Second derivativ
+0000b3f0: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
+0000b400: 2020 2020 2020 2020 7365 6c66 2e63 5f6f          self.c_o
+0000b410: 5f54 5f73 6361 6c61 7220 2a20 3720 2a20  _T_scalar * 7 * 
+0000b420: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+0000b430: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b440: 3920 2a20 7365 645f 6469 7073 5f64 6970  9 * sed_dips_dip
+0000b450: 7320 2a2a 2035 202d 2032 3020 2a20 7365  s ** 5 - 20 * se
+0000b460: 6c66 2e61 5f54 5f73 6361 6c61 7220 2a2a  lf.a_T_scalar **
+0000b470: 2032 202a 2073 6564 5f64 6970 735f 6469   2 * sed_dips_di
+0000b480: 7073 202a 2a20 3320 2b0d 0a20 2020 2020  ps ** 3 +..     
 0000b490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b4a0: 2020 7365 6c66 2e63 5f6f 5f54 5f73 6361    self.c_o_T_sca
-0000b4b0: 6c61 7220 2a20 3720 2a20 280d 0a20 2020  lar * 7 * (..   
-0000b4c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b4d0: 2020 2020 2020 2020 2020 3920 2a20 7365            9 * se
-0000b4e0: 645f 6469 7073 5f64 6970 7320 2a2a 2035  d_dips_dips ** 5
-0000b4f0: 202d 2032 3020 2a20 7365 6c66 2e61 5f54   - 20 * self.a_T
-0000b500: 5f73 6361 6c61 7220 2a2a 2032 202a 2073  _scalar ** 2 * s
-0000b510: 6564 5f64 6970 735f 6469 7073 202a 2a20  ed_dips_dips ** 
-0000b520: 3320 2b0d 0a20 2020 2020 2020 2020 2020  3 +..           
+0000b4a0: 2020 2020 2020 2020 3135 202a 2073 656c          15 * sel
+0000b4b0: 662e 615f 545f 7363 616c 6172 202a 2a20  f.a_T_scalar ** 
+0000b4c0: 3420 2a20 7365 645f 6469 7073 5f64 6970  4 * sed_dips_dip
+0000b4d0: 7320 2d20 3420 2a20 7365 6c66 2e61 5f54  s - 4 * self.a_T
+0000b4e0: 5f73 6361 6c61 7220 2a2a 2035 2920 2f20  _scalar ** 5) / 
+0000b4f0: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+0000b500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b510: 3220 2a20 7365 6c66 2e61 5f54 5f73 6361  2 * self.a_T_sca
+0000b520: 6c61 7220 2a2a 2037 2929 202d 0d0a 2020  lar ** 7)) -..  
 0000b530: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b540: 2020 3135 202a 2073 656c 662e 615f 545f    15 * self.a_T_
-0000b550: 7363 616c 6172 202a 2a20 3420 2a20 7365  scalar ** 4 * se
-0000b560: 645f 6469 7073 5f64 6970 7320 2d20 3420  d_dips_dips - 4 
-0000b570: 2a20 7365 6c66 2e61 5f54 5f73 6361 6c61  * self.a_T_scala
-0000b580: 7220 2a2a 2035 2920 2f20 280d 0a20 2020  r ** 5) / (..   
-0000b590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b5a0: 2020 2020 2020 2020 2020 3220 2a20 7365            2 * se
-0000b5b0: 6c66 2e61 5f54 5f73 6361 6c61 7220 2a2a  lf.a_T_scalar **
-0000b5c0: 2037 2929 202d 0d0a 2020 2020 2020 2020   7)) -..        
-0000b5d0: 2020 2020 2020 2020 2020 2020 2870 6572              (per
-0000b5e0: 7065 6e64 6963 756c 6172 6974 795f 6d61  pendicularity_ma
-0000b5f0: 7472 6978 202a 0d0a 2020 2020 2020 2020  trix *..        
-0000b600: 2020 2020 2020 2020 2020 2020 2028 7365               (se
-0000b610: 645f 6469 7073 5f64 6970 7320 3c20 7365  d_dips_dips < se
-0000b620: 6c66 2e61 5f54 5f73 6361 6c61 7229 202a  lf.a_T_scalar) *
-0000b630: 2020 2320 6669 7273 7420 6465 7269 7661    # first deriva
-0000b640: 7469 7665 0d0a 2020 2020 2020 2020 2020  tive..          
-0000b650: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-0000b660: 635f 6f5f 545f 7363 616c 6172 202a 2028  c_o_T_scalar * (
-0000b670: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-0000b680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b6a0: 2020 2020 202d 3134 202f 2073 656c 662e       -14 / self.
-0000b6b0: 615f 545f 7363 616c 6172 202a 2a20 3229  a_T_scalar ** 2)
-0000b6c0: 202b 2031 3035 202f 2034 202a 2073 6564   + 105 / 4 * sed
-0000b6d0: 5f64 6970 735f 6469 7073 202f 2073 656c  _dips_dips / sel
-0000b6e0: 662e 615f 545f 7363 616c 6172 202a 2a20  f.a_T_scalar ** 
-0000b6f0: 3320 2d0d 0a20 2020 2020 2020 2020 2020  3 -..           
-0000b700: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b710: 2020 2020 2020 2020 2020 2020 2020 2033                 3
-0000b720: 3520 2f20 3220 2a20 7365 645f 6469 7073  5 / 2 * sed_dips
-0000b730: 5f64 6970 7320 2a2a 2033 202f 2073 656c  _dips ** 3 / sel
-0000b740: 662e 615f 545f 7363 616c 6172 202a 2a20  f.a_T_scalar ** 
-0000b750: 3520 2b0d 0a20 2020 2020 2020 2020 2020  5 +..           
-0000b760: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b770: 2020 2020 2020 2020 2020 2020 2020 2032                 2
-0000b780: 3120 2f20 3420 2a20 7365 645f 6469 7073  1 / 4 * sed_dips
-0000b790: 5f64 6970 7320 2a2a 2035 202f 2073 656c  _dips ** 5 / sel
-0000b7a0: 662e 615f 545f 7363 616c 6172 202a 2a20  f.a_T_scalar ** 
-0000b7b0: 3729 2929 0d0a 2020 2020 2020 2020 290d  7)))..        ).
-0000b7c0: 0a0d 0a20 2020 2020 2020 2023 2053 6574  ...        # Set
-0000b7d0: 7469 6e67 206e 7567 6765 7420 6566 6665  ting nugget effe
-0000b7e0: 6374 206f 6620 7468 6520 6772 6164 6965  ct of the gradie
-0000b7f0: 6e74 730d 0a20 2020 2020 2020 2023 2054  nts..        # T
-0000b800: 4f44 4f3a 2054 6869 7320 6675 6e63 7469  ODO: This functi
-0000b810: 6f6e 2063 616e 2062 6520 7375 6273 7469  on can be substi
-0000b820: 7475 6564 2062 7920 7369 6d70 6c79 2061  tued by simply a
-0000b830: 6464 696e 6720 7468 6520 6e75 6767 6574  dding the nugget
-0000b840: 2065 6666 6563 7420 746f 2074 6865 2064   effect to the d
-0000b850: 6961 6720 6966 2049 2072 656d 6f76 6520  iag if I remove 
-0000b860: 7468 6520 636f 6e64 6974 696f 6e0d 0a20  the condition.. 
-0000b870: 2020 2020 2020 2043 5f47 202b 3d20 542e         C_G += T.
-0000b880: 6579 6528 435f 472e 7368 6170 655b 305d  eye(C_G.shape[0]
-0000b890: 2920 2a20 7365 6c66 2e6e 7567 6765 745f  ) * self.nugget_
-0000b8a0: 6566 6665 6374 5f67 7261 645f 545f 6f70  effect_grad_T_op
-0000b8b0: 0d0a 0d0a 2020 2020 2020 2020 2320 4164  ....        # Ad
-0000b8c0: 6420 6e61 6d65 2074 6f20 7468 6520 7468  d name to the th
-0000b8d0: 6561 6e6f 206e 6f64 650d 0a20 2020 2020  eano node..     
-0000b8e0: 2020 2043 5f47 2e6e 616d 6520 3d20 2743     C_G.name = 'C
-0000b8f0: 6f76 6172 6961 6e63 6520 4772 6164 6965  ovariance Gradie
-0000b900: 6e74 270d 0a0d 0a20 2020 2020 2020 2069  nt'....        i
-0000b910: 6620 7665 7262 6f73 6520 3e20 313a 0d0a  f verbose > 1:..
-0000b920: 2020 2020 2020 2020 2020 2020 7468 6561              thea
-0000b930: 6e6f 2e70 7269 6e74 696e 672e 7079 646f  no.printing.pydo
-0000b940: 7470 7269 6e74 2843 5f47 2c0d 0a20 2020  tprint(C_G,..   
-0000b950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b960: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b970: 2020 2020 6f75 7466 696c 653d 2267 7261      outfile="gra
-0000b980: 7068 732f 2220 2b20 7379 732e 5f67 6574  phs/" + sys._get
-0000b990: 6672 616d 6528 292e 665f 636f 6465 2e63  frame().f_code.c
-0000b9a0: 6f5f 6e61 6d65 202b 2022 2e70 6e67 222c  o_name + ".png",
-0000b9b0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000b9c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b9d0: 2020 2020 2020 2020 2076 6172 5f77 6974           var_wit
-0000b9e0: 685f 6e61 6d65 5f73 696d 706c 653d 5472  h_name_simple=Tr
-0000b9f0: 7565 290d 0a0d 0a20 2020 2020 2020 2069  ue)....        i
-0000ba00: 6620 7374 7228 7379 732e 5f67 6574 6672  f str(sys._getfr
-0000ba10: 616d 6528 292e 665f 636f 6465 2e63 6f5f  ame().f_code.co_
-0000ba20: 6e61 6d65 2920 696e 2073 656c 662e 7665  name) in self.ve
-0000ba30: 7262 6f73 653a 0d0a 2020 2020 2020 2020  rbose:..        
-0000ba40: 2020 2020 435f 4720 3d20 7468 6561 6e6f      C_G = theano
-0000ba50: 2e70 7269 6e74 696e 672e 5072 696e 7428  .printing.Print(
-0000ba60: 2743 6f76 2047 7261 6469 656e 7473 2729  'Cov Gradients')
-0000ba70: 2843 5f47 290d 0a0d 0a20 2020 2020 2020  (C_G)....       
-0000ba80: 2072 6574 7572 6e20 435f 470d 0a0d 0a20   return C_G.... 
-0000ba90: 2020 2064 6566 2063 6f76 5f69 6e74 6572     def cov_inter
-0000baa0: 6661 6365 5f67 7261 6469 656e 7473 2873  face_gradients(s
-0000bab0: 656c 6629 3a0d 0a20 2020 2020 2020 2022  elf):..        "
-0000bac0: 2222 0d0a 2020 2020 2020 2020 4372 6561  ""..        Crea
-0000bad0: 7465 2063 6f76 6172 6961 6e63 6520 6675  te covariance fu
-0000bae0: 6e63 7469 6f6e 2066 6f72 2074 6865 2067  nction for the g
-0000baf0: 7261 6469 656e 730d 0a20 2020 2020 2020  radiens..       
-0000bb00: 2052 6574 7572 6e73 3a0d 0a20 2020 2020   Returns:..     
-0000bb10: 2020 2020 2020 2074 6865 616e 6f2e 7465         theano.te
-0000bb20: 6e73 6f72 2e6d 6174 7269 783a 2063 6f76  nsor.matrix: cov
-0000bb30: 6172 6961 6e63 6520 6f66 2074 6865 2067  ariance of the g
-0000bb40: 7261 6469 656e 7473 2e20 5368 6170 6520  radients. Shape 
-0000bb50: 6e75 6d62 6572 206f 6620 706f 696e 7473  number of points
-0000bb60: 2069 6e20 7265 7374 2078 206e 756d 6265   in rest x numbe
-0000bb70: 7220 6f66 0d0a 2020 2020 2020 2020 2020  r of..          
-0000bb80: 2020 2020 706f 696e 7473 2069 6e20 6469      points in di
-0000bb90: 705f 706f 730d 0a20 2020 2020 2020 2022  p_pos..        "
-0000bba0: 2222 0d0a 0d0a 2020 2020 2020 2020 2320  ""....        # 
-0000bbb0: 4575 636c 6964 6961 6e20 6469 7374 616e  Euclidian distan
-0000bbc0: 6365 730d 0a20 2020 2020 2020 2073 6564  ces..        sed
-0000bbd0: 5f64 6970 735f 7265 7374 203d 2073 656c  _dips_rest = sel
-0000bbe0: 662e 7371 7561 7265 645f 6575 636c 6964  f.squared_euclid
-0000bbf0: 6561 6e5f 6469 7374 616e 6365 7328 7365  ean_distances(se
-0000bc00: 6c66 2e64 6970 735f 706f 7369 7469 6f6e  lf.dips_position
-0000bc10: 5f74 696c 6564 2c0d 0a20 2020 2020 2020  _tiled,..       
-0000bc20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b540: 2020 2870 6572 7065 6e64 6963 756c 6172    (perpendicular
+0000b550: 6974 795f 6d61 7472 6978 202a 0d0a 2020  ity_matrix *..  
+0000b560: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b570: 2020 2028 7365 645f 6469 7073 5f64 6970     (sed_dips_dip
+0000b580: 7320 3c20 7365 6c66 2e61 5f54 5f73 6361  s < self.a_T_sca
+0000b590: 6c61 7229 202a 2020 2320 6669 7273 7420  lar) *  # first 
+0000b5a0: 6465 7269 7661 7469 7665 0d0a 2020 2020  derivative..    
+0000b5b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b5c0: 2073 656c 662e 635f 6f5f 545f 7363 616c   self.c_o_T_scal
+0000b5d0: 6172 202a 2028 280d 0a20 2020 2020 2020  ar * ((..       
+0000b5e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b5f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b600: 2020 2020 2020 2020 2020 202d 3134 202f             -14 /
+0000b610: 2073 656c 662e 615f 545f 7363 616c 6172   self.a_T_scalar
+0000b620: 202a 2a20 3229 202b 2031 3035 202f 2034   ** 2) + 105 / 4
+0000b630: 202a 2073 6564 5f64 6970 735f 6469 7073   * sed_dips_dips
+0000b640: 202f 2073 656c 662e 615f 545f 7363 616c   / self.a_T_scal
+0000b650: 6172 202a 2a20 3320 2d0d 0a20 2020 2020  ar ** 3 -..     
+0000b660: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b670: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b680: 2020 2020 2033 3520 2f20 3220 2a20 7365       35 / 2 * se
+0000b690: 645f 6469 7073 5f64 6970 7320 2a2a 2033  d_dips_dips ** 3
+0000b6a0: 202f 2073 656c 662e 615f 545f 7363 616c   / self.a_T_scal
+0000b6b0: 6172 202a 2a20 3520 2b0d 0a20 2020 2020  ar ** 5 +..     
+0000b6c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b6d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b6e0: 2020 2020 2032 3120 2f20 3420 2a20 7365       21 / 4 * se
+0000b6f0: 645f 6469 7073 5f64 6970 7320 2a2a 2035  d_dips_dips ** 5
+0000b700: 202f 2073 656c 662e 615f 545f 7363 616c   / self.a_T_scal
+0000b710: 6172 202a 2a20 3729 2929 0d0a 2020 2020  ar ** 7)))..    
+0000b720: 2020 2020 290d 0a0d 0a20 2020 2020 2020      )....       
+0000b730: 2023 2053 6574 7469 6e67 206e 7567 6765   # Setting nugge
+0000b740: 7420 6566 6665 6374 206f 6620 7468 6520  t effect of the 
+0000b750: 6772 6164 6965 6e74 730d 0a20 2020 2020  gradients..     
+0000b760: 2020 2023 2054 4f44 4f3a 2054 6869 7320     # TODO: This 
+0000b770: 6675 6e63 7469 6f6e 2063 616e 2062 6520  function can be 
+0000b780: 7375 6273 7469 7475 6564 2062 7920 7369  substitued by si
+0000b790: 6d70 6c79 2061 6464 696e 6720 7468 6520  mply adding the 
+0000b7a0: 6e75 6767 6574 2065 6666 6563 7420 746f  nugget effect to
+0000b7b0: 2074 6865 2064 6961 6720 6966 2049 2072   the diag if I r
+0000b7c0: 656d 6f76 6520 7468 6520 636f 6e64 6974  emove the condit
+0000b7d0: 696f 6e0d 0a20 2020 2020 2020 2043 5f47  ion..        C_G
+0000b7e0: 202b 3d20 542e 6579 6528 435f 472e 7368   += T.eye(C_G.sh
+0000b7f0: 6170 655b 305d 2920 2a20 7365 6c66 2e6e  ape[0]) * self.n
+0000b800: 7567 6765 745f 6566 6665 6374 5f67 7261  ugget_effect_gra
+0000b810: 645f 545f 6f70 0d0a 0d0a 2020 2020 2020  d_T_op....      
+0000b820: 2020 2320 4164 6420 6e61 6d65 2074 6f20    # Add name to 
+0000b830: 7468 6520 6165 7361 7261 206e 6f64 650d  the aesara node.
+0000b840: 0a20 2020 2020 2020 2043 5f47 2e6e 616d  .        C_G.nam
+0000b850: 6520 3d20 2743 6f76 6172 6961 6e63 6520  e = 'Covariance 
+0000b860: 4772 6164 6965 6e74 270d 0a0d 0a20 2020  Gradient'....   
+0000b870: 2020 2020 2069 6620 7665 7262 6f73 6520       if verbose 
+0000b880: 3e20 313a 0d0a 2020 2020 2020 2020 2020  > 1:..          
+0000b890: 2020 6165 7361 7261 2e70 7269 6e74 696e    aesara.printin
+0000b8a0: 672e 7079 646f 7470 7269 6e74 2843 5f47  g.pydotprint(C_G
+0000b8b0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+0000b8c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b8d0: 2020 2020 2020 2020 2020 6f75 7466 696c            outfil
+0000b8e0: 653d 2267 7261 7068 732f 2220 2b20 7379  e="graphs/" + sy
+0000b8f0: 732e 5f67 6574 6672 616d 6528 292e 665f  s._getframe().f_
+0000b900: 636f 6465 2e63 6f5f 6e61 6d65 202b 2022  code.co_name + "
+0000b910: 2e70 6e67 222c 0d0a 2020 2020 2020 2020  .png",..        
+0000b920: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b930: 2020 2020 2020 2020 2020 2020 2020 2076                 v
+0000b940: 6172 5f77 6974 685f 6e61 6d65 5f73 696d  ar_with_name_sim
+0000b950: 706c 653d 5472 7565 290d 0a0d 0a20 2020  ple=True)....   
+0000b960: 2020 2020 2069 6620 7374 7228 7379 732e       if str(sys.
+0000b970: 5f67 6574 6672 616d 6528 292e 665f 636f  _getframe().f_co
+0000b980: 6465 2e63 6f5f 6e61 6d65 2920 696e 2073  de.co_name) in s
+0000b990: 656c 662e 7665 7262 6f73 653a 0d0a 2020  elf.verbose:..  
+0000b9a0: 2020 2020 2020 2020 2020 435f 4720 3d20            C_G = 
+0000b9b0: 6165 7361 7261 2e70 7269 6e74 696e 672e  aesara.printing.
+0000b9c0: 5072 696e 7428 2743 6f76 2047 7261 6469  Print('Cov Gradi
+0000b9d0: 656e 7473 2729 2843 5f47 290d 0a0d 0a20  ents')(C_G).... 
+0000b9e0: 2020 2020 2020 2072 6574 7572 6e20 435f         return C_
+0000b9f0: 470d 0a0d 0a20 2020 2064 6566 2063 6f76  G....    def cov
+0000ba00: 5f69 6e74 6572 6661 6365 5f67 7261 6469  _interface_gradi
+0000ba10: 656e 7473 2873 656c 6629 3a0d 0a20 2020  ents(self):..   
+0000ba20: 2020 2020 2022 2222 0d0a 2020 2020 2020       """..      
+0000ba30: 2020 4372 6561 7465 2063 6f76 6172 6961    Create covaria
+0000ba40: 6e63 6520 6675 6e63 7469 6f6e 2066 6f72  nce function for
+0000ba50: 2074 6865 2067 7261 6469 656e 730d 0a20   the gradiens.. 
+0000ba60: 2020 2020 2020 2052 6574 7572 6e73 3a0d         Returns:.
+0000ba70: 0a20 2020 2020 2020 2020 2020 2061 6573  .            aes
+0000ba80: 6172 612e 7465 6e73 6f72 2e6d 6174 7269  ara.tensor.matri
+0000ba90: 783a 2063 6f76 6172 6961 6e63 6520 6f66  x: covariance of
+0000baa0: 2074 6865 2067 7261 6469 656e 7473 2e20   the gradients. 
+0000bab0: 5368 6170 6520 6e75 6d62 6572 206f 6620  Shape number of 
+0000bac0: 706f 696e 7473 2069 6e20 7265 7374 2078  points in rest x
+0000bad0: 206e 756d 6265 7220 6f66 0d0a 2020 2020   number of..    
+0000bae0: 2020 2020 2020 2020 2020 706f 696e 7473            points
+0000baf0: 2069 6e20 6469 705f 706f 730d 0a20 2020   in dip_pos..   
+0000bb00: 2020 2020 2022 2222 0d0a 0d0a 2020 2020       """....    
+0000bb10: 2020 2020 2320 4575 636c 6964 6961 6e20      # Euclidian 
+0000bb20: 6469 7374 616e 6365 730d 0a20 2020 2020  distances..     
+0000bb30: 2020 2073 6564 5f64 6970 735f 7265 7374     sed_dips_rest
+0000bb40: 203d 2073 656c 662e 7371 7561 7265 645f   = self.squared_
+0000bb50: 6575 636c 6964 6561 6e5f 6469 7374 616e  euclidean_distan
+0000bb60: 6365 7328 7365 6c66 2e64 6970 735f 706f  ces(self.dips_po
+0000bb70: 7369 7469 6f6e 5f74 696c 6564 2c0d 0a20  sition_tiled,.. 
+0000bb80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bb90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bbb0: 2020 2020 2020 2020 7365 6c66 2e72 6573          self.res
+0000bbc0: 745f 6c61 7965 725f 706f 696e 7473 290d  t_layer_points).
+0000bbd0: 0a20 2020 2020 2020 2073 6564 5f64 6970  .        sed_dip
+0000bbe0: 735f 7265 6620 3d20 7365 6c66 2e73 7175  s_ref = self.squ
+0000bbf0: 6172 6564 5f65 7563 6c69 6465 616e 5f64  ared_euclidean_d
+0000bc00: 6973 7461 6e63 6573 2873 656c 662e 6469  istances(self.di
+0000bc10: 7073 5f70 6f73 6974 696f 6e5f 7469 6c65  ps_position_tile
+0000bc20: 642c 0d0a 2020 2020 2020 2020 2020 2020  d,..            
 0000bc30: 2020 2020 2020 2020 2020 2020 2020 2020                  
 0000bc40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bc50: 2020 7365 6c66 2e72 6573 745f 6c61 7965    self.rest_laye
-0000bc60: 725f 706f 696e 7473 290d 0a20 2020 2020  r_points)..     
-0000bc70: 2020 2073 6564 5f64 6970 735f 7265 6620     sed_dips_ref 
-0000bc80: 3d20 7365 6c66 2e73 7175 6172 6564 5f65  = self.squared_e
-0000bc90: 7563 6c69 6465 616e 5f64 6973 7461 6e63  uclidean_distanc
-0000bca0: 6573 2873 656c 662e 6469 7073 5f70 6f73  es(self.dips_pos
-0000bcb0: 6974 696f 6e5f 7469 6c65 642c 0d0a 2020  ition_tiled,..  
-0000bcc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bcd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bcf0: 2020 2020 2020 7365 6c66 2e72 6566 5f6c        self.ref_l
-0000bd00: 6179 6572 5f70 6f69 6e74 7329 0d0a 0d0a  ayer_points)....
-0000bd10: 2020 2020 2020 2020 2320 4361 7274 6573          # Cartes
-0000bd20: 6961 6e20 6469 7374 616e 6365 7320 6265  ian distances be
-0000bd30: 7477 6565 6e20 6469 7073 2061 6e64 2069  tween dips and i
-0000bd40: 6e74 6572 6661 6365 2070 6f69 6e74 730d  nterface points.
-0000bd50: 0a20 2020 2020 2020 2023 2052 6573 740d  .        # Rest.
-0000bd60: 0a20 2020 2020 2020 2068 755f 7265 7374  .        hu_rest
-0000bd70: 203d 2054 2e76 6572 7469 6361 6c5f 7374   = T.vertical_st
-0000bd80: 6163 6b28 0d0a 2020 2020 2020 2020 2020  ack(..          
-0000bd90: 2020 2873 656c 662e 6469 7073 5f70 6f73    (self.dips_pos
-0000bda0: 6974 696f 6e5b 3a2c 2030 5d20 2d20 7365  ition[:, 0] - se
-0000bdb0: 6c66 2e72 6573 745f 6c61 7965 725f 706f  lf.rest_layer_po
-0000bdc0: 696e 7473 5b3a 2c20 305d 2e72 6573 6861  ints[:, 0].resha
-0000bdd0: 7065 280d 0a20 2020 2020 2020 2020 2020  pe(..           
-0000bde0: 2020 2020 2028 7365 6c66 2e72 6573 745f       (self.rest_
-0000bdf0: 6c61 7965 725f 706f 696e 7473 5b3a 2c20  layer_points[:, 
-0000be00: 305d 2e73 6861 7065 5b30 5d2c 2031 2929  0].shape[0], 1))
-0000be10: 292e 542c 0d0a 2020 2020 2020 2020 2020  ).T,..          
-0000be20: 2020 2873 656c 662e 6469 7073 5f70 6f73    (self.dips_pos
-0000be30: 6974 696f 6e5b 3a2c 2031 5d20 2d20 7365  ition[:, 1] - se
-0000be40: 6c66 2e72 6573 745f 6c61 7965 725f 706f  lf.rest_layer_po
-0000be50: 696e 7473 5b3a 2c20 315d 2e72 6573 6861  ints[:, 1].resha
-0000be60: 7065 280d 0a20 2020 2020 2020 2020 2020  pe(..           
-0000be70: 2020 2020 2028 7365 6c66 2e72 6573 745f       (self.rest_
-0000be80: 6c61 7965 725f 706f 696e 7473 5b3a 2c20  layer_points[:, 
-0000be90: 315d 2e73 6861 7065 5b30 5d2c 2031 2929  1].shape[0], 1))
-0000bea0: 292e 542c 0d0a 2020 2020 2020 2020 2020  ).T,..          
-0000beb0: 2020 2873 656c 662e 6469 7073 5f70 6f73    (self.dips_pos
-0000bec0: 6974 696f 6e5b 3a2c 2032 5d20 2d20 7365  ition[:, 2] - se
-0000bed0: 6c66 2e72 6573 745f 6c61 7965 725f 706f  lf.rest_layer_po
-0000bee0: 696e 7473 5b3a 2c20 325d 2e72 6573 6861  ints[:, 2].resha
-0000bef0: 7065 280d 0a20 2020 2020 2020 2020 2020  pe(..           
-0000bf00: 2020 2020 2028 7365 6c66 2e72 6573 745f       (self.rest_
-0000bf10: 6c61 7965 725f 706f 696e 7473 5b3a 2c20  layer_points[:, 
-0000bf20: 325d 2e73 6861 7065 5b30 5d2c 2031 2929  2].shape[0], 1))
-0000bf30: 292e 540d 0a20 2020 2020 2020 2029 0d0a  ).T..        )..
-0000bf40: 0d0a 2020 2020 2020 2020 2320 5265 6665  ..        # Refe
-0000bf50: 7265 6e63 6520 706f 696e 740d 0a20 2020  rence point..   
-0000bf60: 2020 2020 2068 755f 7265 6620 3d20 542e       hu_ref = T.
-0000bf70: 7665 7274 6963 616c 5f73 7461 636b 280d  vertical_stack(.
-0000bf80: 0a20 2020 2020 2020 2020 2020 2028 7365  .            (se
-0000bf90: 6c66 2e64 6970 735f 706f 7369 7469 6f6e  lf.dips_position
-0000bfa0: 5b3a 2c20 305d 202d 2073 656c 662e 7265  [:, 0] - self.re
-0000bfb0: 665f 6c61 7965 725f 706f 696e 7473 5b3a  f_layer_points[:
-0000bfc0: 2c20 305d 2e72 6573 6861 7065 280d 0a20  , 0].reshape(.. 
-0000bfd0: 2020 2020 2020 2020 2020 2020 2020 2028                 (
-0000bfe0: 7365 6c66 2e72 6566 5f6c 6179 6572 5f70  self.ref_layer_p
-0000bff0: 6f69 6e74 735b 3a2c 2030 5d2e 7368 6170  oints[:, 0].shap
-0000c000: 655b 305d 2c20 3129 2929 2e54 2c0d 0a20  e[0], 1))).T,.. 
-0000c010: 2020 2020 2020 2020 2020 2028 7365 6c66             (self
-0000c020: 2e64 6970 735f 706f 7369 7469 6f6e 5b3a  .dips_position[:
-0000c030: 2c20 315d 202d 2073 656c 662e 7265 665f  , 1] - self.ref_
-0000c040: 6c61 7965 725f 706f 696e 7473 5b3a 2c20  layer_points[:, 
-0000c050: 315d 2e72 6573 6861 7065 280d 0a20 2020  1].reshape(..   
-0000c060: 2020 2020 2020 2020 2020 2020 2028 7365               (se
-0000c070: 6c66 2e72 6566 5f6c 6179 6572 5f70 6f69  lf.ref_layer_poi
-0000c080: 6e74 735b 3a2c 2031 5d2e 7368 6170 655b  nts[:, 1].shape[
-0000c090: 305d 2c20 3129 2929 2e54 2c0d 0a20 2020  0], 1))).T,..   
-0000c0a0: 2020 2020 2020 2020 2028 7365 6c66 2e64           (self.d
-0000c0b0: 6970 735f 706f 7369 7469 6f6e 5b3a 2c20  ips_position[:, 
-0000c0c0: 325d 202d 2073 656c 662e 7265 665f 6c61  2] - self.ref_la
-0000c0d0: 7965 725f 706f 696e 7473 5b3a 2c20 325d  yer_points[:, 2]
-0000c0e0: 2e72 6573 6861 7065 280d 0a20 2020 2020  .reshape(..     
-0000c0f0: 2020 2020 2020 2020 2020 2028 7365 6c66             (self
-0000c100: 2e72 6566 5f6c 6179 6572 5f70 6f69 6e74  .ref_layer_point
-0000c110: 735b 3a2c 2032 5d2e 7368 6170 655b 305d  s[:, 2].shape[0]
-0000c120: 2c20 3129 2929 2e54 0d0a 2020 2020 2020  , 1))).T..      
-0000c130: 2020 290d 0a0d 0a20 2020 2020 2020 2023    )....        #
-0000c140: 2043 726f 7373 2d43 6f76 6172 6961 6e63   Cross-Covarianc
-0000c150: 6520 6772 6164 6965 6e74 732d 7375 7266  e gradients-surf
-0000c160: 6163 655f 706f 696e 7473 0d0a 2020 2020  ace_points..    
-0000c170: 2020 2020 435f 4749 203d 2073 656c 662e      C_GI = self.
-0000c180: 6769 5f72 6565 7363 616c 6520 2a20 280d  gi_reescale * (.
-0000c190: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000c1a0: 2028 6875 5f72 6573 7420 2a0d 0a20 2020   (hu_rest *..   
-0000c1b0: 2020 2020 2020 2020 2020 2020 2020 2873                (s
-0000c1c0: 6564 5f64 6970 735f 7265 7374 203c 2073  ed_dips_rest < s
-0000c1d0: 656c 662e 615f 545f 7363 616c 6172 2920  elf.a_T_scalar) 
-0000c1e0: 2a20 2023 2066 6972 7374 2064 6572 6976  *  # first deriv
-0000c1f0: 6174 6976 650d 0a20 2020 2020 2020 2020  ative..         
-0000c200: 2020 2020 2020 2020 282d 2073 656c 662e          (- self.
-0000c210: 635f 6f5f 545f 7363 616c 6172 202a 2028  c_o_T_scalar * (
-0000c220: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-0000c230: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c250: 2020 2020 2d31 3420 2f20 7365 6c66 2e61      -14 / self.a
-0000c260: 5f54 5f73 6361 6c61 7220 2a2a 2032 2920  _T_scalar ** 2) 
-0000c270: 2b20 3130 3520 2f20 3420 2a20 7365 645f  + 105 / 4 * sed_
-0000c280: 6469 7073 5f72 6573 7420 2f20 7365 6c66  dips_rest / self
-0000c290: 2e61 5f54 5f73 6361 6c61 7220 2a2a 2033  .a_T_scalar ** 3
-0000c2a0: 202d 0d0a 2020 2020 2020 2020 2020 2020   -..            
-0000c2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c2c0: 2020 2020 2020 2020 2020 2020 2033 3520               35 
-0000c2d0: 2f20 3220 2a20 7365 645f 6469 7073 5f72  / 2 * sed_dips_r
-0000c2e0: 6573 7420 2a2a 2033 202f 2073 656c 662e  est ** 3 / self.
-0000c2f0: 615f 545f 7363 616c 6172 202a 2a20 3520  a_T_scalar ** 5 
-0000c300: 2b0d 0a20 2020 2020 2020 2020 2020 2020  +..             
-0000c310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c320: 2020 2020 2020 2020 2020 2020 3231 202f              21 /
-0000c330: 2034 202a 2073 6564 5f64 6970 735f 7265   4 * sed_dips_re
-0000c340: 7374 202a 2a20 3520 2f20 7365 6c66 2e61  st ** 5 / self.a
-0000c350: 5f54 5f73 6361 6c61 7220 2a2a 2037 2929  _T_scalar ** 7))
-0000c360: 2920 2d0d 0a20 2020 2020 2020 2020 2020  ) -..           
-0000c370: 2020 2020 2028 6875 5f72 6566 202a 0d0a       (hu_ref *..
-0000c380: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c390: 2028 7365 645f 6469 7073 5f72 6566 203c   (sed_dips_ref <
-0000c3a0: 2073 656c 662e 615f 545f 7363 616c 6172   self.a_T_scalar
-0000c3b0: 2920 2a20 2023 2066 6972 7374 2064 6572  ) *  # first der
-0000c3c0: 6976 6174 6976 650d 0a20 2020 2020 2020  ivative..       
-0000c3d0: 2020 2020 2020 2020 2020 282d 2073 656c            (- sel
-0000c3e0: 662e 635f 6f5f 545f 7363 616c 6172 202a  f.c_o_T_scalar *
-0000c3f0: 2028 280d 0a20 2020 2020 2020 2020 2020   ((..           
-0000c400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c410: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c420: 2020 2020 2020 2d31 3420 2f20 7365 6c66        -14 / self
-0000c430: 2e61 5f54 5f73 6361 6c61 7220 2a2a 2032  .a_T_scalar ** 2
-0000c440: 2920 2b20 3130 3520 2f20 3420 2a20 7365  ) + 105 / 4 * se
-0000c450: 645f 6469 7073 5f72 6566 202f 2073 656c  d_dips_ref / sel
-0000c460: 662e 615f 545f 7363 616c 6172 202a 2a20  f.a_T_scalar ** 
-0000c470: 3320 2d0d 0a20 2020 2020 2020 2020 2020  3 -..           
-0000c480: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c490: 2020 2020 2020 2020 2020 2020 2020 3335                35
-0000c4a0: 202f 2032 202a 2073 6564 5f64 6970 735f   / 2 * sed_dips_
-0000c4b0: 7265 6620 2a2a 2033 202f 2073 656c 662e  ref ** 3 / self.
-0000c4c0: 615f 545f 7363 616c 6172 202a 2a20 3520  a_T_scalar ** 5 
-0000c4d0: 2b0d 0a20 2020 2020 2020 2020 2020 2020  +..             
-0000c4e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c4f0: 2020 2020 2020 2020 2020 2020 3231 202f              21 /
-0000c500: 2034 202a 2073 6564 5f64 6970 735f 7265   4 * sed_dips_re
-0000c510: 6620 2a2a 2035 202f 2073 656c 662e 615f  f ** 5 / self.a_
-0000c520: 545f 7363 616c 6172 202a 2a20 3729 2929  T_scalar ** 7)))
-0000c530: 0d0a 2020 2020 2020 2020 292e 540d 0a0d  ..        ).T...
-0000c540: 0a20 2020 2020 2020 2023 2041 6464 206e  .        # Add n
-0000c550: 616d 6520 746f 2074 6865 2074 6865 616e  ame to the thean
-0000c560: 6f20 6e6f 6465 0d0a 2020 2020 2020 2020  o node..        
-0000c570: 435f 4749 2e6e 616d 6520 3d20 2743 6f76  C_GI.name = 'Cov
-0000c580: 6172 6961 6e63 6520 6772 6164 6965 6e74  ariance gradient
-0000c590: 2069 6e74 6572 6661 6365 270d 0a20 2020   interface'..   
-0000c5a0: 2020 2020 2069 6620 7374 7228 7379 732e       if str(sys.
-0000c5b0: 5f67 6574 6672 616d 6528 292e 665f 636f  _getframe().f_co
-0000c5c0: 6465 2e63 6f5f 6e61 6d65 2920 696e 2073  de.co_name) in s
-0000c5d0: 656c 662e 7665 7262 6f73 653a 0d0a 2020  elf.verbose:..  
-0000c5e0: 2020 2020 2020 2020 2020 435f 4749 203d            C_GI =
-0000c5f0: 2074 6865 616e 6f2e 7072 696e 7469 6e67   theano.printing
-0000c600: 2e50 7269 6e74 2827 436f 7620 4772 6164  .Print('Cov Grad
-0000c610: 6965 6e74 7320 2d20 496e 7465 7266 6163  ients - Interfac
-0000c620: 6527 2928 435f 4749 290d 0a0d 0a20 2020  e')(C_GI)....   
-0000c630: 2020 2020 2069 6620 7374 7228 7379 732e       if str(sys.
-0000c640: 5f67 6574 6672 616d 6528 292e 665f 636f  _getframe().f_co
-0000c650: 6465 2e63 6f5f 6e61 6d65 2920 2b20 275f  de.co_name) + '_
-0000c660: 6727 2069 6e20 7365 6c66 2e76 6572 626f  g' in self.verbo
-0000c670: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
-0000c680: 2074 6865 616e 6f2e 7072 696e 7469 6e67   theano.printing
-0000c690: 2e70 7964 6f74 7072 696e 7428 435f 4749  .pydotprint(C_GI
-0000c6a0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-0000c6b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c6c0: 2020 2020 2020 2020 2020 6f75 7466 696c            outfil
-0000c6d0: 653d 2267 7261 7068 732f 2220 2b20 7379  e="graphs/" + sy
-0000c6e0: 732e 5f67 6574 6672 616d 6528 292e 665f  s._getframe().f_
-0000c6f0: 636f 6465 2e63 6f5f 6e61 6d65 202b 2022  code.co_name + "
-0000c700: 2e70 6e67 222c 0d0a 2020 2020 2020 2020  .png",..        
-0000c710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c720: 2020 2020 2020 2020 2020 2020 2020 2076                 v
-0000c730: 6172 5f77 6974 685f 6e61 6d65 5f73 696d  ar_with_name_sim
-0000c740: 706c 653d 5472 7565 290d 0a20 2020 2020  ple=True)..     
-0000c750: 2020 2072 6574 7572 6e20 435f 4749 0d0a     return C_GI..
-0000c760: 0d0a 2020 2020 6465 6620 756e 6976 6572  ..    def univer
-0000c770: 7361 6c5f 6d61 7472 6978 2873 656c 6629  sal_matrix(self)
-0000c780: 3a0d 0a20 2020 2020 2020 2022 2222 0d0a  :..        """..
-0000c790: 2020 2020 2020 2020 4372 6561 7465 2074          Create t
-0000c7a0: 6865 2064 7269 6674 206d 6174 7269 6365  he drift matrice
-0000c7b0: 7320 666f 7220 7468 6520 706f 7465 6e74  s for the potent
-0000c7c0: 6961 6c20 6669 656c 6420 616e 6420 6974  ial field and it
-0000c7d0: 7320 6772 6164 6965 6e74 0d0a 0d0a 2020  s gradient....  
-0000c7e0: 2020 2020 2020 5265 7475 726e 733a 0d0a        Returns:..
-0000c7f0: 2020 2020 2020 2020 2020 2020 7468 6561              thea
-0000c800: 6e6f 2e74 656e 736f 722e 6d61 7472 6978  no.tensor.matrix
-0000c810: 3a20 4472 6966 7420 6d61 7472 6978 2066  : Drift matrix f
-0000c820: 6f72 2074 6865 2073 7572 6661 6365 5f70  or the surface_p
-0000c830: 6f69 6e74 732e 2053 6861 7065 206e 756d  oints. Shape num
-0000c840: 6265 7220 6f66 2070 6f69 6e74 7320 696e  ber of points in
-0000c850: 2072 6573 7420 7820 332a 2a64 6567 7265   rest x 3**degre
-0000c860: 6520 6472 6966 740d 0a20 2020 2020 2020  e drift..       
-0000c870: 2020 2020 2028 6578 6365 7074 2064 6567       (except deg
-0000c880: 7265 6520 3020 7468 6174 2069 7320 3029  ree 0 that is 0)
-0000c890: 0d0a 0d0a 2020 2020 2020 2020 2020 2020  ....            
-0000c8a0: 7468 6561 6e6f 2e74 656e 736f 722e 6d61  theano.tensor.ma
-0000c8b0: 7472 6978 3a20 4472 6966 7420 6d61 7472  trix: Drift matr
-0000c8c0: 6978 2066 6f72 2074 6865 2067 7261 6469  ix for the gradi
-0000c8d0: 656e 7473 2e20 5368 6170 6520 6e75 6d62  ents. Shape numb
-0000c8e0: 6572 206f 6620 706f 696e 7473 2069 6e20  er of points in 
-0000c8f0: 6469 7073 2078 2033 2a2a 6465 6772 6565  dips x 3**degree
-0000c900: 2064 7269 6674 0d0a 2020 2020 2020 2020   drift..        
-0000c910: 2020 2020 2865 7863 6570 7420 6465 6772      (except degr
-0000c920: 6565 2030 2074 6861 7420 6973 2030 290d  ee 0 that is 0).
-0000c930: 0a20 2020 2020 2020 2022 2222 0d0a 0d0a  .        """....
-0000c940: 2020 2020 2020 2020 2320 436f 6e64 6974          # Condit
-0000c950: 696f 6e20 6f66 2075 6e69 7665 7273 616c  ion of universal
-0000c960: 6974 7920 3220 6465 6772 6565 0d0a 2020  ity 2 degree..  
-0000c970: 2020 2020 2020 2320 4772 6164 6965 6e74        # Gradient
-0000c980: 730d 0a0d 0a20 2020 2020 2020 206e 203d  s....        n =
-0000c990: 2073 656c 662e 6469 7073 5f70 6f73 6974   self.dips_posit
-0000c9a0: 696f 6e2e 7368 6170 655b 305d 0d0a 2020  ion.shape[0]..  
-0000c9b0: 2020 2020 2020 555f 4720 3d20 542e 7a65        U_G = T.ze
-0000c9c0: 726f 7328 286e 202a 2073 656c 662e 6e5f  ros((n * self.n_
-0000c9d0: 6469 6d65 6e73 696f 6e73 2c20 3320 2a20  dimensions, 3 * 
-0000c9e0: 7365 6c66 2e6e 5f64 696d 656e 7369 6f6e  self.n_dimension
-0000c9f0: 7329 290d 0a20 2020 2020 2020 2023 2078  s))..        # x
-0000ca00: 0d0a 2020 2020 2020 2020 555f 4720 3d20  ..        U_G = 
-0000ca10: 542e 7365 745f 7375 6274 656e 736f 7228  T.set_subtensor(
-0000ca20: 555f 475b 3a6e 2c20 305d 2c20 3129 0d0a  U_G[:n, 0], 1)..
-0000ca30: 2020 2020 2020 2020 2320 790d 0a20 2020          # y..   
-0000ca40: 2020 2020 2055 5f47 203d 2054 2e73 6574       U_G = T.set
-0000ca50: 5f73 7562 7465 6e73 6f72 2855 5f47 5b6e  _subtensor(U_G[n
-0000ca60: 202a 2031 3a6e 202a 2032 2c20 315d 2c20   * 1:n * 2, 1], 
-0000ca70: 3129 0d0a 2020 2020 2020 2020 2320 7a0d  1)..        # z.
-0000ca80: 0a20 2020 2020 2020 2055 5f47 203d 2054  .        U_G = T
-0000ca90: 2e73 6574 5f73 7562 7465 6e73 6f72 2855  .set_subtensor(U
-0000caa0: 5f47 5b6e 202a 2032 3a20 6e20 2a20 332c  _G[n * 2: n * 3,
-0000cab0: 2032 5d2c 2031 290d 0a20 2020 2020 2020   2], 1)..       
-0000cac0: 2023 2078 2a2a 320d 0a20 2020 2020 2020   # x**2..       
-0000cad0: 2055 5f47 203d 2054 2e73 6574 5f73 7562   U_G = T.set_sub
-0000cae0: 7465 6e73 6f72 2855 5f47 5b3a 6e2c 2033  tensor(U_G[:n, 3
-0000caf0: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
-0000cb00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cb10: 2020 3220 2a20 7365 6c66 2e67 695f 7265    2 * self.gi_re
-0000cb20: 6573 6361 6c65 202a 2073 656c 662e 6469  escale * self.di
-0000cb30: 7073 5f70 6f73 6974 696f 6e5b 3a2c 2030  ps_position[:, 0
-0000cb40: 5d29 0d0a 2020 2020 2020 2020 2320 792a  ])..        # y*
-0000cb50: 2a32 0d0a 2020 2020 2020 2020 555f 4720  *2..        U_G 
-0000cb60: 3d20 542e 7365 745f 7375 6274 656e 736f  = T.set_subtenso
-0000cb70: 7228 555f 475b 6e20 2a20 313a 6e20 2a20  r(U_G[n * 1:n * 
-0000cb80: 322c 2034 5d2c 0d0a 2020 2020 2020 2020  2, 4],..        
+0000bc50: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0000bc60: 2e72 6566 5f6c 6179 6572 5f70 6f69 6e74  .ref_layer_point
+0000bc70: 7329 0d0a 0d0a 2020 2020 2020 2020 2320  s)....        # 
+0000bc80: 4361 7274 6573 6961 6e20 6469 7374 616e  Cartesian distan
+0000bc90: 6365 7320 6265 7477 6565 6e20 6469 7073  ces between dips
+0000bca0: 2061 6e64 2069 6e74 6572 6661 6365 2070   and interface p
+0000bcb0: 6f69 6e74 730d 0a20 2020 2020 2020 2023  oints..        #
+0000bcc0: 2052 6573 740d 0a20 2020 2020 2020 2068   Rest..        h
+0000bcd0: 755f 7265 7374 203d 2054 2e76 6572 7469  u_rest = T.verti
+0000bce0: 6361 6c5f 7374 6163 6b28 0d0a 2020 2020  cal_stack(..    
+0000bcf0: 2020 2020 2020 2020 2873 656c 662e 6469          (self.di
+0000bd00: 7073 5f70 6f73 6974 696f 6e5b 3a2c 2030  ps_position[:, 0
+0000bd10: 5d20 2d20 7365 6c66 2e72 6573 745f 6c61  ] - self.rest_la
+0000bd20: 7965 725f 706f 696e 7473 5b3a 2c20 305d  yer_points[:, 0]
+0000bd30: 2e72 6573 6861 7065 280d 0a20 2020 2020  .reshape(..     
+0000bd40: 2020 2020 2020 2020 2020 2028 7365 6c66             (self
+0000bd50: 2e72 6573 745f 6c61 7965 725f 706f 696e  .rest_layer_poin
+0000bd60: 7473 5b3a 2c20 305d 2e73 6861 7065 5b30  ts[:, 0].shape[0
+0000bd70: 5d2c 2031 2929 292e 542c 0d0a 2020 2020  ], 1))).T,..    
+0000bd80: 2020 2020 2020 2020 2873 656c 662e 6469          (self.di
+0000bd90: 7073 5f70 6f73 6974 696f 6e5b 3a2c 2031  ps_position[:, 1
+0000bda0: 5d20 2d20 7365 6c66 2e72 6573 745f 6c61  ] - self.rest_la
+0000bdb0: 7965 725f 706f 696e 7473 5b3a 2c20 315d  yer_points[:, 1]
+0000bdc0: 2e72 6573 6861 7065 280d 0a20 2020 2020  .reshape(..     
+0000bdd0: 2020 2020 2020 2020 2020 2028 7365 6c66             (self
+0000bde0: 2e72 6573 745f 6c61 7965 725f 706f 696e  .rest_layer_poin
+0000bdf0: 7473 5b3a 2c20 315d 2e73 6861 7065 5b30  ts[:, 1].shape[0
+0000be00: 5d2c 2031 2929 292e 542c 0d0a 2020 2020  ], 1))).T,..    
+0000be10: 2020 2020 2020 2020 2873 656c 662e 6469          (self.di
+0000be20: 7073 5f70 6f73 6974 696f 6e5b 3a2c 2032  ps_position[:, 2
+0000be30: 5d20 2d20 7365 6c66 2e72 6573 745f 6c61  ] - self.rest_la
+0000be40: 7965 725f 706f 696e 7473 5b3a 2c20 325d  yer_points[:, 2]
+0000be50: 2e72 6573 6861 7065 280d 0a20 2020 2020  .reshape(..     
+0000be60: 2020 2020 2020 2020 2020 2028 7365 6c66             (self
+0000be70: 2e72 6573 745f 6c61 7965 725f 706f 696e  .rest_layer_poin
+0000be80: 7473 5b3a 2c20 325d 2e73 6861 7065 5b30  ts[:, 2].shape[0
+0000be90: 5d2c 2031 2929 292e 540d 0a20 2020 2020  ], 1))).T..     
+0000bea0: 2020 2029 0d0a 0d0a 2020 2020 2020 2020     )....        
+0000beb0: 2320 5265 6665 7265 6e63 6520 706f 696e  # Reference poin
+0000bec0: 740d 0a20 2020 2020 2020 2068 755f 7265  t..        hu_re
+0000bed0: 6620 3d20 542e 7665 7274 6963 616c 5f73  f = T.vertical_s
+0000bee0: 7461 636b 280d 0a20 2020 2020 2020 2020  tack(..         
+0000bef0: 2020 2028 7365 6c66 2e64 6970 735f 706f     (self.dips_po
+0000bf00: 7369 7469 6f6e 5b3a 2c20 305d 202d 2073  sition[:, 0] - s
+0000bf10: 656c 662e 7265 665f 6c61 7965 725f 706f  elf.ref_layer_po
+0000bf20: 696e 7473 5b3a 2c20 305d 2e72 6573 6861  ints[:, 0].resha
+0000bf30: 7065 280d 0a20 2020 2020 2020 2020 2020  pe(..           
+0000bf40: 2020 2020 2028 7365 6c66 2e72 6566 5f6c       (self.ref_l
+0000bf50: 6179 6572 5f70 6f69 6e74 735b 3a2c 2030  ayer_points[:, 0
+0000bf60: 5d2e 7368 6170 655b 305d 2c20 3129 2929  ].shape[0], 1)))
+0000bf70: 2e54 2c0d 0a20 2020 2020 2020 2020 2020  .T,..           
+0000bf80: 2028 7365 6c66 2e64 6970 735f 706f 7369   (self.dips_posi
+0000bf90: 7469 6f6e 5b3a 2c20 315d 202d 2073 656c  tion[:, 1] - sel
+0000bfa0: 662e 7265 665f 6c61 7965 725f 706f 696e  f.ref_layer_poin
+0000bfb0: 7473 5b3a 2c20 315d 2e72 6573 6861 7065  ts[:, 1].reshape
+0000bfc0: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+0000bfd0: 2020 2028 7365 6c66 2e72 6566 5f6c 6179     (self.ref_lay
+0000bfe0: 6572 5f70 6f69 6e74 735b 3a2c 2031 5d2e  er_points[:, 1].
+0000bff0: 7368 6170 655b 305d 2c20 3129 2929 2e54  shape[0], 1))).T
+0000c000: 2c0d 0a20 2020 2020 2020 2020 2020 2028  ,..            (
+0000c010: 7365 6c66 2e64 6970 735f 706f 7369 7469  self.dips_positi
+0000c020: 6f6e 5b3a 2c20 325d 202d 2073 656c 662e  on[:, 2] - self.
+0000c030: 7265 665f 6c61 7965 725f 706f 696e 7473  ref_layer_points
+0000c040: 5b3a 2c20 325d 2e72 6573 6861 7065 280d  [:, 2].reshape(.
+0000c050: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000c060: 2028 7365 6c66 2e72 6566 5f6c 6179 6572   (self.ref_layer
+0000c070: 5f70 6f69 6e74 735b 3a2c 2032 5d2e 7368  _points[:, 2].sh
+0000c080: 6170 655b 305d 2c20 3129 2929 2e54 0d0a  ape[0], 1))).T..
+0000c090: 2020 2020 2020 2020 290d 0a0d 0a20 2020          )....   
+0000c0a0: 2020 2020 2023 2043 726f 7373 2d43 6f76       # Cross-Cov
+0000c0b0: 6172 6961 6e63 6520 6772 6164 6965 6e74  ariance gradient
+0000c0c0: 732d 7375 7266 6163 655f 706f 696e 7473  s-surface_points
+0000c0d0: 0d0a 2020 2020 2020 2020 435f 4749 203d  ..        C_GI =
+0000c0e0: 2073 656c 662e 6769 5f72 6565 7363 616c   self.gi_reescal
+0000c0f0: 6520 2a20 280d 0a20 2020 2020 2020 2020  e * (..         
+0000c100: 2020 2020 2020 2028 6875 5f72 6573 7420         (hu_rest 
+0000c110: 2a0d 0a20 2020 2020 2020 2020 2020 2020  *..             
+0000c120: 2020 2020 2873 6564 5f64 6970 735f 7265      (sed_dips_re
+0000c130: 7374 203c 2073 656c 662e 615f 545f 7363  st < self.a_T_sc
+0000c140: 616c 6172 2920 2a20 2023 2066 6972 7374  alar) *  # first
+0000c150: 2064 6572 6976 6174 6976 650d 0a20 2020   derivative..   
+0000c160: 2020 2020 2020 2020 2020 2020 2020 282d                (-
+0000c170: 2073 656c 662e 635f 6f5f 545f 7363 616c   self.c_o_T_scal
+0000c180: 6172 202a 2028 280d 0a20 2020 2020 2020  ar * ((..       
+0000c190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c1a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c1b0: 2020 2020 2020 2020 2020 2d31 3420 2f20            -14 / 
+0000c1c0: 7365 6c66 2e61 5f54 5f73 6361 6c61 7220  self.a_T_scalar 
+0000c1d0: 2a2a 2032 2920 2b20 3130 3520 2f20 3420  ** 2) + 105 / 4 
+0000c1e0: 2a20 7365 645f 6469 7073 5f72 6573 7420  * sed_dips_rest 
+0000c1f0: 2f20 7365 6c66 2e61 5f54 5f73 6361 6c61  / self.a_T_scala
+0000c200: 7220 2a2a 2033 202d 0d0a 2020 2020 2020  r ** 3 -..      
+0000c210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c230: 2020 2033 3520 2f20 3220 2a20 7365 645f     35 / 2 * sed_
+0000c240: 6469 7073 5f72 6573 7420 2a2a 2033 202f  dips_rest ** 3 /
+0000c250: 2073 656c 662e 615f 545f 7363 616c 6172   self.a_T_scalar
+0000c260: 202a 2a20 3520 2b0d 0a20 2020 2020 2020   ** 5 +..       
+0000c270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c290: 2020 3231 202f 2034 202a 2073 6564 5f64    21 / 4 * sed_d
+0000c2a0: 6970 735f 7265 7374 202a 2a20 3520 2f20  ips_rest ** 5 / 
+0000c2b0: 7365 6c66 2e61 5f54 5f73 6361 6c61 7220  self.a_T_scalar 
+0000c2c0: 2a2a 2037 2929 2920 2d0d 0a20 2020 2020  ** 7))) -..     
+0000c2d0: 2020 2020 2020 2020 2020 2028 6875 5f72             (hu_r
+0000c2e0: 6566 202a 0d0a 2020 2020 2020 2020 2020  ef *..          
+0000c2f0: 2020 2020 2020 2028 7365 645f 6469 7073         (sed_dips
+0000c300: 5f72 6566 203c 2073 656c 662e 615f 545f  _ref < self.a_T_
+0000c310: 7363 616c 6172 2920 2a20 2023 2066 6972  scalar) *  # fir
+0000c320: 7374 2064 6572 6976 6174 6976 650d 0a20  st derivative.. 
+0000c330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c340: 282d 2073 656c 662e 635f 6f5f 545f 7363  (- self.c_o_T_sc
+0000c350: 616c 6172 202a 2028 280d 0a20 2020 2020  alar * ((..     
+0000c360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c380: 2020 2020 2020 2020 2020 2020 2d31 3420              -14 
+0000c390: 2f20 7365 6c66 2e61 5f54 5f73 6361 6c61  / self.a_T_scala
+0000c3a0: 7220 2a2a 2032 2920 2b20 3130 3520 2f20  r ** 2) + 105 / 
+0000c3b0: 3420 2a20 7365 645f 6469 7073 5f72 6566  4 * sed_dips_ref
+0000c3c0: 202f 2073 656c 662e 615f 545f 7363 616c   / self.a_T_scal
+0000c3d0: 6172 202a 2a20 3320 2d0d 0a20 2020 2020  ar ** 3 -..     
+0000c3e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c3f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c400: 2020 2020 3335 202f 2032 202a 2073 6564      35 / 2 * sed
+0000c410: 5f64 6970 735f 7265 6620 2a2a 2033 202f  _dips_ref ** 3 /
+0000c420: 2073 656c 662e 615f 545f 7363 616c 6172   self.a_T_scalar
+0000c430: 202a 2a20 3520 2b0d 0a20 2020 2020 2020   ** 5 +..       
+0000c440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c460: 2020 3231 202f 2034 202a 2073 6564 5f64    21 / 4 * sed_d
+0000c470: 6970 735f 7265 6620 2a2a 2035 202f 2073  ips_ref ** 5 / s
+0000c480: 656c 662e 615f 545f 7363 616c 6172 202a  elf.a_T_scalar *
+0000c490: 2a20 3729 2929 0d0a 2020 2020 2020 2020  * 7)))..        
+0000c4a0: 292e 540d 0a0d 0a20 2020 2020 2020 2023  ).T....        #
+0000c4b0: 2041 6464 206e 616d 6520 746f 2074 6865   Add name to the
+0000c4c0: 2061 6573 6172 6120 6e6f 6465 0d0a 2020   aesara node..  
+0000c4d0: 2020 2020 2020 435f 4749 2e6e 616d 6520        C_GI.name 
+0000c4e0: 3d20 2743 6f76 6172 6961 6e63 6520 6772  = 'Covariance gr
+0000c4f0: 6164 6965 6e74 2069 6e74 6572 6661 6365  adient interface
+0000c500: 270d 0a20 2020 2020 2020 2069 6620 7374  '..        if st
+0000c510: 7228 7379 732e 5f67 6574 6672 616d 6528  r(sys._getframe(
+0000c520: 292e 665f 636f 6465 2e63 6f5f 6e61 6d65  ).f_code.co_name
+0000c530: 2920 696e 2073 656c 662e 7665 7262 6f73  ) in self.verbos
+0000c540: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+0000c550: 435f 4749 203d 2061 6573 6172 612e 7072  C_GI = aesara.pr
+0000c560: 696e 7469 6e67 2e50 7269 6e74 2827 436f  inting.Print('Co
+0000c570: 7620 4772 6164 6965 6e74 7320 2d20 496e  v Gradients - In
+0000c580: 7465 7266 6163 6527 2928 435f 4749 290d  terface')(C_GI).
+0000c590: 0a0d 0a20 2020 2020 2020 2069 6620 7374  ...        if st
+0000c5a0: 7228 7379 732e 5f67 6574 6672 616d 6528  r(sys._getframe(
+0000c5b0: 292e 665f 636f 6465 2e63 6f5f 6e61 6d65  ).f_code.co_name
+0000c5c0: 2920 2b20 275f 6727 2069 6e20 7365 6c66  ) + '_g' in self
+0000c5d0: 2e76 6572 626f 7365 3a0d 0a20 2020 2020  .verbose:..     
+0000c5e0: 2020 2020 2020 2061 6573 6172 612e 7072         aesara.pr
+0000c5f0: 696e 7469 6e67 2e70 7964 6f74 7072 696e  inting.pydotprin
+0000c600: 7428 435f 4749 2c0d 0a20 2020 2020 2020  t(C_GI,..       
+0000c610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c630: 6f75 7466 696c 653d 2267 7261 7068 732f  outfile="graphs/
+0000c640: 2220 2b20 7379 732e 5f67 6574 6672 616d  " + sys._getfram
+0000c650: 6528 292e 665f 636f 6465 2e63 6f5f 6e61  e().f_code.co_na
+0000c660: 6d65 202b 2022 2e70 6e67 222c 0d0a 2020  me + ".png",..  
+0000c670: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c680: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c690: 2020 2020 2076 6172 5f77 6974 685f 6e61       var_with_na
+0000c6a0: 6d65 5f73 696d 706c 653d 5472 7565 290d  me_simple=True).
+0000c6b0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0000c6c0: 435f 4749 0d0a 0d0a 2020 2020 6465 6620  C_GI....    def 
+0000c6d0: 756e 6976 6572 7361 6c5f 6d61 7472 6978  universal_matrix
+0000c6e0: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
+0000c6f0: 2022 2222 0d0a 2020 2020 2020 2020 4372   """..        Cr
+0000c700: 6561 7465 2074 6865 2064 7269 6674 206d  eate the drift m
+0000c710: 6174 7269 6365 7320 666f 7220 7468 6520  atrices for the 
+0000c720: 706f 7465 6e74 6961 6c20 6669 656c 6420  potential field 
+0000c730: 616e 6420 6974 7320 6772 6164 6965 6e74  and its gradient
+0000c740: 0d0a 0d0a 2020 2020 2020 2020 5265 7475  ....        Retu
+0000c750: 726e 733a 0d0a 2020 2020 2020 2020 2020  rns:..          
+0000c760: 2020 6165 7361 7261 2e74 656e 736f 722e    aesara.tensor.
+0000c770: 6d61 7472 6978 3a20 4472 6966 7420 6d61  matrix: Drift ma
+0000c780: 7472 6978 2066 6f72 2074 6865 2073 7572  trix for the sur
+0000c790: 6661 6365 5f70 6f69 6e74 732e 2053 6861  face_points. Sha
+0000c7a0: 7065 206e 756d 6265 7220 6f66 2070 6f69  pe number of poi
+0000c7b0: 6e74 7320 696e 2072 6573 7420 7820 332a  nts in rest x 3*
+0000c7c0: 2a64 6567 7265 6520 6472 6966 740d 0a20  *degree drift.. 
+0000c7d0: 2020 2020 2020 2020 2020 2028 6578 6365             (exce
+0000c7e0: 7074 2064 6567 7265 6520 3020 7468 6174  pt degree 0 that
+0000c7f0: 2069 7320 3029 0d0a 0d0a 2020 2020 2020   is 0)....      
+0000c800: 2020 2020 2020 6165 7361 7261 2e74 656e        aesara.ten
+0000c810: 736f 722e 6d61 7472 6978 3a20 4472 6966  sor.matrix: Drif
+0000c820: 7420 6d61 7472 6978 2066 6f72 2074 6865  t matrix for the
+0000c830: 2067 7261 6469 656e 7473 2e20 5368 6170   gradients. Shap
+0000c840: 6520 6e75 6d62 6572 206f 6620 706f 696e  e number of poin
+0000c850: 7473 2069 6e20 6469 7073 2078 2033 2a2a  ts in dips x 3**
+0000c860: 6465 6772 6565 2064 7269 6674 0d0a 2020  degree drift..  
+0000c870: 2020 2020 2020 2020 2020 2865 7863 6570            (excep
+0000c880: 7420 6465 6772 6565 2030 2074 6861 7420  t degree 0 that 
+0000c890: 6973 2030 290d 0a20 2020 2020 2020 2022  is 0)..        "
+0000c8a0: 2222 0d0a 0d0a 2020 2020 2020 2020 2320  ""....        # 
+0000c8b0: 436f 6e64 6974 696f 6e20 6f66 2075 6e69  Condition of uni
+0000c8c0: 7665 7273 616c 6974 7920 3220 6465 6772  versality 2 degr
+0000c8d0: 6565 0d0a 2020 2020 2020 2020 2320 4772  ee..        # Gr
+0000c8e0: 6164 6965 6e74 730d 0a0d 0a20 2020 2020  adients....     
+0000c8f0: 2020 206e 203d 2073 656c 662e 6469 7073     n = self.dips
+0000c900: 5f70 6f73 6974 696f 6e2e 7368 6170 655b  _position.shape[
+0000c910: 305d 0d0a 2020 2020 2020 2020 555f 4720  0]..        U_G 
+0000c920: 3d20 542e 7a65 726f 7328 286e 202a 2073  = T.zeros((n * s
+0000c930: 656c 662e 6e5f 6469 6d65 6e73 696f 6e73  elf.n_dimensions
+0000c940: 2c20 3320 2a20 7365 6c66 2e6e 5f64 696d  , 3 * self.n_dim
+0000c950: 656e 7369 6f6e 7329 290d 0a20 2020 2020  ensions))..     
+0000c960: 2020 2023 2078 0d0a 2020 2020 2020 2020     # x..        
+0000c970: 555f 4720 3d20 542e 7365 745f 7375 6274  U_G = T.set_subt
+0000c980: 656e 736f 7228 555f 475b 3a6e 2c20 305d  ensor(U_G[:n, 0]
+0000c990: 2c20 3129 0d0a 2020 2020 2020 2020 2320  , 1)..        # 
+0000c9a0: 790d 0a20 2020 2020 2020 2055 5f47 203d  y..        U_G =
+0000c9b0: 2054 2e73 6574 5f73 7562 7465 6e73 6f72   T.set_subtensor
+0000c9c0: 2855 5f47 5b6e 202a 2031 3a6e 202a 2032  (U_G[n * 1:n * 2
+0000c9d0: 2c20 315d 2c20 3129 0d0a 2020 2020 2020  , 1], 1)..      
+0000c9e0: 2020 2320 7a0d 0a20 2020 2020 2020 2055    # z..        U
+0000c9f0: 5f47 203d 2054 2e73 6574 5f73 7562 7465  _G = T.set_subte
+0000ca00: 6e73 6f72 2855 5f47 5b6e 202a 2032 3a20  nsor(U_G[n * 2: 
+0000ca10: 6e20 2a20 332c 2032 5d2c 2031 290d 0a20  n * 3, 2], 1).. 
+0000ca20: 2020 2020 2020 2023 2078 2a2a 320d 0a20         # x**2.. 
+0000ca30: 2020 2020 2020 2055 5f47 203d 2054 2e73         U_G = T.s
+0000ca40: 6574 5f73 7562 7465 6e73 6f72 2855 5f47  et_subtensor(U_G
+0000ca50: 5b3a 6e2c 2033 5d2c 0d0a 2020 2020 2020  [:n, 3],..      
+0000ca60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ca70: 2020 2020 2020 2020 3220 2a20 7365 6c66          2 * self
+0000ca80: 2e67 695f 7265 6573 6361 6c65 202a 2073  .gi_reescale * s
+0000ca90: 656c 662e 6469 7073 5f70 6f73 6974 696f  elf.dips_positio
+0000caa0: 6e5b 3a2c 2030 5d29 0d0a 2020 2020 2020  n[:, 0])..      
+0000cab0: 2020 2320 792a 2a32 0d0a 2020 2020 2020    # y**2..      
+0000cac0: 2020 555f 4720 3d20 542e 7365 745f 7375    U_G = T.set_su
+0000cad0: 6274 656e 736f 7228 555f 475b 6e20 2a20  btensor(U_G[n * 
+0000cae0: 313a 6e20 2a20 322c 2034 5d2c 0d0a 2020  1:n * 2, 4],..  
+0000caf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cb00: 2020 2020 2020 2020 2020 2020 3220 2a20              2 * 
+0000cb10: 7365 6c66 2e67 695f 7265 6573 6361 6c65  self.gi_reescale
+0000cb20: 202a 2073 656c 662e 6469 7073 5f70 6f73   * self.dips_pos
+0000cb30: 6974 696f 6e5b 3a2c 2031 5d29 0d0a 2020  ition[:, 1])..  
+0000cb40: 2020 2020 2020 2320 7a2a 2a32 0d0a 2020        # z**2..  
+0000cb50: 2020 2020 2020 555f 4720 3d20 542e 7365        U_G = T.se
+0000cb60: 745f 7375 6274 656e 736f 7228 555f 475b  t_subtensor(U_G[
+0000cb70: 6e20 2a20 323a 206e 202a 2033 2c20 355d  n * 2: n * 3, 5]
+0000cb80: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
 0000cb90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cba0: 2020 2020 2020 3220 2a20 7365 6c66 2e67        2 * self.g
-0000cbb0: 695f 7265 6573 6361 6c65 202a 2073 656c  i_reescale * sel
-0000cbc0: 662e 6469 7073 5f70 6f73 6974 696f 6e5b  f.dips_position[
-0000cbd0: 3a2c 2031 5d29 0d0a 2020 2020 2020 2020  :, 1])..        
-0000cbe0: 2320 7a2a 2a32 0d0a 2020 2020 2020 2020  # z**2..        
-0000cbf0: 555f 4720 3d20 542e 7365 745f 7375 6274  U_G = T.set_subt
-0000cc00: 656e 736f 7228 555f 475b 6e20 2a20 323a  ensor(U_G[n * 2:
-0000cc10: 206e 202a 2033 2c20 355d 2c0d 0a20 2020   n * 3, 5],..   
-0000cc20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cc30: 2020 2020 2020 2020 2020 2032 202a 2073             2 * s
-0000cc40: 656c 662e 6769 5f72 6565 7363 616c 6520  elf.gi_reescale 
-0000cc50: 2a20 7365 6c66 2e64 6970 735f 706f 7369  * self.dips_posi
-0000cc60: 7469 6f6e 5b3a 2c20 325d 290d 0a20 2020  tion[:, 2])..   
-0000cc70: 2020 2020 2023 2078 790d 0a20 2020 2020       # xy..     
-0000cc80: 2020 2055 5f47 203d 2054 2e73 6574 5f73     U_G = T.set_s
-0000cc90: 7562 7465 6e73 6f72 2855 5f47 5b3a 6e2c  ubtensor(U_G[:n,
-0000cca0: 2036 5d2c 2073 656c 662e 6769 5f72 6565   6], self.gi_ree
-0000ccb0: 7363 616c 6520 2a20 7365 6c66 2e64 6970  scale * self.dip
-0000ccc0: 735f 706f 7369 7469 6f6e 5b3a 2c0d 0a20  s_position[:,.. 
-0000ccd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ccf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cd00: 2020 2020 2020 2020 2020 2020 315d 2920              1]) 
-0000cd10: 2023 2054 6869 7320 6973 2079 0d0a 2020   # This is y..  
-0000cd20: 2020 2020 2020 555f 4720 3d20 542e 7365        U_G = T.se
-0000cd30: 745f 7375 6274 656e 736f 7228 555f 475b  t_subtensor(U_G[
-0000cd40: 6e20 2a20 313a 6e20 2a20 322c 2036 5d2c  n * 1:n * 2, 6],
-0000cd50: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000cd60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cd70: 7365 6c66 2e67 695f 7265 6573 6361 6c65  self.gi_reescale
-0000cd80: 202a 2073 656c 662e 6469 7073 5f70 6f73   * self.dips_pos
-0000cd90: 6974 696f 6e5b 3a2c 0d0a 2020 2020 2020  ition[:,..      
-0000cda0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cba0: 2032 202a 2073 656c 662e 6769 5f72 6565   2 * self.gi_ree
+0000cbb0: 7363 616c 6520 2a20 7365 6c66 2e64 6970  scale * self.dip
+0000cbc0: 735f 706f 7369 7469 6f6e 5b3a 2c20 325d  s_position[:, 2]
+0000cbd0: 290d 0a20 2020 2020 2020 2023 2078 790d  )..        # xy.
+0000cbe0: 0a20 2020 2020 2020 2055 5f47 203d 2054  .        U_G = T
+0000cbf0: 2e73 6574 5f73 7562 7465 6e73 6f72 2855  .set_subtensor(U
+0000cc00: 5f47 5b3a 6e2c 2036 5d2c 2073 656c 662e  _G[:n, 6], self.
+0000cc10: 6769 5f72 6565 7363 616c 6520 2a20 7365  gi_reescale * se
+0000cc20: 6c66 2e64 6970 735f 706f 7369 7469 6f6e  lf.dips_position
+0000cc30: 5b3a 2c0d 0a20 2020 2020 2020 2020 2020  [:,..           
+0000cc40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cc50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cc60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cc70: 2020 315d 2920 2023 2054 6869 7320 6973    1])  # This is
+0000cc80: 2079 0d0a 2020 2020 2020 2020 555f 4720   y..        U_G 
+0000cc90: 3d20 542e 7365 745f 7375 6274 656e 736f  = T.set_subtenso
+0000cca0: 7228 555f 475b 6e20 2a20 313a 6e20 2a20  r(U_G[n * 1:n * 
+0000ccb0: 322c 2036 5d2c 0d0a 2020 2020 2020 2020  2, 6],..        
+0000ccc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ccd0: 2020 2020 2020 7365 6c66 2e67 695f 7265        self.gi_re
+0000cce0: 6573 6361 6c65 202a 2073 656c 662e 6469  escale * self.di
+0000ccf0: 7073 5f70 6f73 6974 696f 6e5b 3a2c 0d0a  ps_position[:,..
+0000cd00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cd10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cd20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cd30: 2030 5d29 2020 2320 5468 6973 2069 7320   0])  # This is 
+0000cd40: 780d 0a20 2020 2020 2020 2023 2078 7a0d  x..        # xz.
+0000cd50: 0a20 2020 2020 2020 2055 5f47 203d 2054  .        U_G = T
+0000cd60: 2e73 6574 5f73 7562 7465 6e73 6f72 2855  .set_subtensor(U
+0000cd70: 5f47 5b3a 6e2c 2037 5d2c 2073 656c 662e  _G[:n, 7], self.
+0000cd80: 6769 5f72 6565 7363 616c 6520 2a20 7365  gi_reescale * se
+0000cd90: 6c66 2e64 6970 735f 706f 7369 7469 6f6e  lf.dips_position
+0000cda0: 5b3a 2c0d 0a20 2020 2020 2020 2020 2020  [:,..           
 0000cdb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cdc0: 2020 2020 2020 2020 2020 2030 5d29 2020             0])  
-0000cdd0: 2320 5468 6973 2069 7320 780d 0a20 2020  # This is x..   
-0000cde0: 2020 2020 2023 2078 7a0d 0a20 2020 2020       # xz..     
-0000cdf0: 2020 2055 5f47 203d 2054 2e73 6574 5f73     U_G = T.set_s
-0000ce00: 7562 7465 6e73 6f72 2855 5f47 5b3a 6e2c  ubtensor(U_G[:n,
-0000ce10: 2037 5d2c 2073 656c 662e 6769 5f72 6565   7], self.gi_ree
-0000ce20: 7363 616c 6520 2a20 7365 6c66 2e64 6970  scale * self.dip
-0000ce30: 735f 706f 7369 7469 6f6e 5b3a 2c0d 0a20  s_position[:,.. 
-0000ce40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ce50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ce60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ce70: 2020 2020 2020 2020 2020 2020 325d 2920              2]) 
-0000ce80: 2023 2054 6869 7320 6973 207a 0d0a 2020   # This is z..  
-0000ce90: 2020 2020 2020 555f 4720 3d20 542e 7365        U_G = T.se
-0000cea0: 745f 7375 6274 656e 736f 7228 555f 475b  t_subtensor(U_G[
-0000ceb0: 6e20 2a20 323a 206e 202a 2033 2c20 375d  n * 2: n * 3, 7]
-0000cec0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-0000ced0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cee0: 2073 656c 662e 6769 5f72 6565 7363 616c   self.gi_reescal
-0000cef0: 6520 2a20 7365 6c66 2e64 6970 735f 706f  e * self.dips_po
-0000cf00: 7369 7469 6f6e 5b3a 2c0d 0a20 2020 2020  sition[:,..     
-0000cf10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cf20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cf30: 2020 2020 2020 2020 2020 2020 305d 2920              0]) 
-0000cf40: 2023 2054 6869 7320 6973 2078 0d0a 2020   # This is x..  
-0000cf50: 2020 2020 2020 2320 797a 0d0a 2020 2020        # yz..    
-0000cf60: 2020 2020 555f 4720 3d20 542e 7365 745f      U_G = T.set_
-0000cf70: 7375 6274 656e 736f 7228 555f 475b 6e20  subtensor(U_G[n 
-0000cf80: 2a20 313a 6e20 2a20 322c 2038 5d2c 0d0a  * 1:n * 2, 8],..
-0000cf90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cfa0: 2020 2020 2020 2020 2020 2020 2020 7365                se
-0000cfb0: 6c66 2e67 695f 7265 6573 6361 6c65 202a  lf.gi_reescale *
-0000cfc0: 2073 656c 662e 6469 7073 5f70 6f73 6974   self.dips_posit
-0000cfd0: 696f 6e5b 3a2c 0d0a 2020 2020 2020 2020  ion[:,..        
-0000cfe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d000: 2020 2020 2020 2020 2032 5d29 2020 2320           2])  # 
-0000d010: 5468 6973 2069 7320 7a0d 0a20 2020 2020  This is z..     
-0000d020: 2020 2055 5f47 203d 2054 2e73 6574 5f73     U_G = T.set_s
-0000d030: 7562 7465 6e73 6f72 2855 5f47 5b6e 202a  ubtensor(U_G[n *
-0000d040: 2032 3a6e 202a 2033 2c20 385d 2c0d 0a20   2:n * 3, 8],.. 
-0000d050: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d060: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-0000d070: 662e 6769 5f72 6565 7363 616c 6520 2a20  f.gi_reescale * 
-0000d080: 7365 6c66 2e64 6970 735f 706f 7369 7469  self.dips_positi
-0000d090: 6f6e 5b3a 2c0d 0a20 2020 2020 2020 2020  on[:,..         
-0000d0a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d0b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d0c0: 2020 2020 2020 2020 315d 2920 2023 2054          1])  # T
-0000d0d0: 6869 7320 6973 2079 0d0a 0d0a 2020 2020  his is y....    
-0000d0e0: 2020 2020 2320 496e 7465 7266 6163 650d      # Interface.
-0000d0f0: 0a20 2020 2020 2020 2055 5f49 203d 202d  .        U_I = -
-0000d100: 2054 2e73 7461 636b 280d 0a20 2020 2020   T.stack(..     
-0000d110: 2020 2020 2020 2028 7365 6c66 2e67 695f         (self.gi_
-0000d120: 7265 6573 6361 6c65 202a 2028 0d0a 2020  reescale * (..  
-0000d130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d140: 2020 7365 6c66 2e72 6573 745f 6c61 7965    self.rest_laye
-0000d150: 725f 706f 696e 7473 5b3a 2c20 305d 202d  r_points[:, 0] -
-0000d160: 2073 656c 662e 7265 665f 6c61 7965 725f   self.ref_layer_
-0000d170: 706f 696e 7473 5b3a 2c20 305d 292c 0d0a  points[:, 0]),..
-0000d180: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-0000d190: 662e 6769 5f72 6565 7363 616c 6520 2a20  f.gi_reescale * 
-0000d1a0: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-0000d1b0: 2020 2020 2020 2020 7365 6c66 2e72 6573          self.res
-0000d1c0: 745f 6c61 7965 725f 706f 696e 7473 5b3a  t_layer_points[:
-0000d1d0: 2c20 315d 202d 2073 656c 662e 7265 665f  , 1] - self.ref_
-0000d1e0: 6c61 7965 725f 706f 696e 7473 5b3a 2c20  layer_points[:, 
-0000d1f0: 315d 292c 0d0a 2020 2020 2020 2020 2020  1]),..          
-0000d200: 2020 2073 656c 662e 6769 5f72 6565 7363     self.gi_reesc
-0000d210: 616c 6520 2a20 280d 0a20 2020 2020 2020  ale * (..       
-0000d220: 2020 2020 2020 2020 2020 2020 2020 7365                se
-0000d230: 6c66 2e72 6573 745f 6c61 7965 725f 706f  lf.rest_layer_po
-0000d240: 696e 7473 5b3a 2c20 325d 202d 2073 656c  ints[:, 2] - sel
-0000d250: 662e 7265 665f 6c61 7965 725f 706f 696e  f.ref_layer_poin
-0000d260: 7473 5b3a 2c20 325d 292c 0d0a 2020 2020  ts[:, 2]),..    
-0000d270: 2020 2020 2020 2020 2073 656c 662e 6769           self.gi
-0000d280: 5f72 6565 7363 616c 6520 2a2a 2032 202a  _reescale ** 2 *
-0000d290: 2028 0d0a 2020 2020 2020 2020 2020 2020   (..            
-0000d2a0: 2020 2020 2020 2020 2073 656c 662e 7265           self.re
-0000d2b0: 7374 5f6c 6179 6572 5f70 6f69 6e74 735b  st_layer_points[
-0000d2c0: 3a2c 2030 5d20 2a2a 2032 202d 2073 656c  :, 0] ** 2 - sel
-0000d2d0: 662e 7265 665f 6c61 7965 725f 706f 696e  f.ref_layer_poin
-0000d2e0: 7473 5b3a 2c0d 0a20 2020 2020 2020 2020  ts[:,..         
-0000d2f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cdc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cdd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cde0: 2020 325d 2920 2023 2054 6869 7320 6973    2])  # This is
+0000cdf0: 207a 0d0a 2020 2020 2020 2020 555f 4720   z..        U_G 
+0000ce00: 3d20 542e 7365 745f 7375 6274 656e 736f  = T.set_subtenso
+0000ce10: 7228 555f 475b 6e20 2a20 323a 206e 202a  r(U_G[n * 2: n *
+0000ce20: 2033 2c20 375d 2c0d 0a20 2020 2020 2020   3, 7],..       
+0000ce30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ce40: 2020 2020 2020 2073 656c 662e 6769 5f72         self.gi_r
+0000ce50: 6565 7363 616c 6520 2a20 7365 6c66 2e64  eescale * self.d
+0000ce60: 6970 735f 706f 7369 7469 6f6e 5b3a 2c0d  ips_position[:,.
+0000ce70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000ce80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ce90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cea0: 2020 305d 2920 2023 2054 6869 7320 6973    0])  # This is
+0000ceb0: 2078 0d0a 2020 2020 2020 2020 2320 797a   x..        # yz
+0000cec0: 0d0a 2020 2020 2020 2020 555f 4720 3d20  ..        U_G = 
+0000ced0: 542e 7365 745f 7375 6274 656e 736f 7228  T.set_subtensor(
+0000cee0: 555f 475b 6e20 2a20 313a 6e20 2a20 322c  U_G[n * 1:n * 2,
+0000cef0: 2038 5d2c 0d0a 2020 2020 2020 2020 2020   8],..          
+0000cf00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cf10: 2020 2020 7365 6c66 2e67 695f 7265 6573      self.gi_rees
+0000cf20: 6361 6c65 202a 2073 656c 662e 6469 7073  cale * self.dips
+0000cf30: 5f70 6f73 6974 696f 6e5b 3a2c 0d0a 2020  _position[:,..  
+0000cf40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cf50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cf60: 2020 2020 2020 2020 2020 2020 2020 2032                 2
+0000cf70: 5d29 2020 2320 5468 6973 2069 7320 7a0d  ])  # This is z.
+0000cf80: 0a20 2020 2020 2020 2055 5f47 203d 2054  .        U_G = T
+0000cf90: 2e73 6574 5f73 7562 7465 6e73 6f72 2855  .set_subtensor(U
+0000cfa0: 5f47 5b6e 202a 2032 3a6e 202a 2033 2c20  _G[n * 2:n * 3, 
+0000cfb0: 385d 2c0d 0a20 2020 2020 2020 2020 2020  8],..           
+0000cfc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cfd0: 2020 2073 656c 662e 6769 5f72 6565 7363     self.gi_reesc
+0000cfe0: 616c 6520 2a20 7365 6c66 2e64 6970 735f  ale * self.dips_
+0000cff0: 706f 7369 7469 6f6e 5b3a 2c0d 0a20 2020  position[:,..   
+0000d000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d020: 2020 2020 2020 2020 2020 2020 2020 315d                1]
+0000d030: 2920 2023 2054 6869 7320 6973 2079 0d0a  )  # This is y..
+0000d040: 0d0a 2020 2020 2020 2020 2320 496e 7465  ..        # Inte
+0000d050: 7266 6163 650d 0a20 2020 2020 2020 2055  rface..        U
+0000d060: 5f49 203d 202d 2054 2e73 7461 636b 280d  _I = - T.stack(.
+0000d070: 0a20 2020 2020 2020 2020 2020 2028 7365  .            (se
+0000d080: 6c66 2e67 695f 7265 6573 6361 6c65 202a  lf.gi_reescale *
+0000d090: 2028 0d0a 2020 2020 2020 2020 2020 2020   (..            
+0000d0a0: 2020 2020 2020 2020 7365 6c66 2e72 6573          self.res
+0000d0b0: 745f 6c61 7965 725f 706f 696e 7473 5b3a  t_layer_points[:
+0000d0c0: 2c20 305d 202d 2073 656c 662e 7265 665f  , 0] - self.ref_
+0000d0d0: 6c61 7965 725f 706f 696e 7473 5b3a 2c20  layer_points[:, 
+0000d0e0: 305d 292c 0d0a 2020 2020 2020 2020 2020  0]),..          
+0000d0f0: 2020 2073 656c 662e 6769 5f72 6565 7363     self.gi_reesc
+0000d100: 616c 6520 2a20 280d 0a20 2020 2020 2020  ale * (..       
+0000d110: 2020 2020 2020 2020 2020 2020 2020 7365                se
+0000d120: 6c66 2e72 6573 745f 6c61 7965 725f 706f  lf.rest_layer_po
+0000d130: 696e 7473 5b3a 2c20 315d 202d 2073 656c  ints[:, 1] - sel
+0000d140: 662e 7265 665f 6c61 7965 725f 706f 696e  f.ref_layer_poin
+0000d150: 7473 5b3a 2c20 315d 292c 0d0a 2020 2020  ts[:, 1]),..    
+0000d160: 2020 2020 2020 2020 2073 656c 662e 6769           self.gi
+0000d170: 5f72 6565 7363 616c 6520 2a20 280d 0a20  _reescale * (.. 
+0000d180: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d190: 2020 2020 7365 6c66 2e72 6573 745f 6c61      self.rest_la
+0000d1a0: 7965 725f 706f 696e 7473 5b3a 2c20 325d  yer_points[:, 2]
+0000d1b0: 202d 2073 656c 662e 7265 665f 6c61 7965   - self.ref_laye
+0000d1c0: 725f 706f 696e 7473 5b3a 2c20 325d 292c  r_points[:, 2]),
+0000d1d0: 0d0a 2020 2020 2020 2020 2020 2020 2073  ..             s
+0000d1e0: 656c 662e 6769 5f72 6565 7363 616c 6520  elf.gi_reescale 
+0000d1f0: 2a2a 2032 202a 2028 0d0a 2020 2020 2020  ** 2 * (..      
+0000d200: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+0000d210: 656c 662e 7265 7374 5f6c 6179 6572 5f70  elf.rest_layer_p
+0000d220: 6f69 6e74 735b 3a2c 2030 5d20 2a2a 2032  oints[:, 0] ** 2
+0000d230: 202d 2073 656c 662e 7265 665f 6c61 7965   - self.ref_laye
+0000d240: 725f 706f 696e 7473 5b3a 2c0d 0a20 2020  r_points[:,..   
+0000d250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d280: 2020 2020 2020 305d 202a 2a20 3229 2c0d        0] ** 2),.
+0000d290: 0a20 2020 2020 2020 2020 2020 2020 7365  .             se
+0000d2a0: 6c66 2e67 695f 7265 6573 6361 6c65 202a  lf.gi_reescale *
+0000d2b0: 2a20 3220 2a20 280d 0a20 2020 2020 2020  * 2 * (..       
+0000d2c0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+0000d2d0: 6c66 2e72 6573 745f 6c61 7965 725f 706f  lf.rest_layer_po
+0000d2e0: 696e 7473 5b3a 2c20 315d 202a 2a20 3220  ints[:, 1] ** 2 
+0000d2f0: 2d20 7365 6c66 2e72 6566 5f6c 6179 6572  - self.ref_layer
+0000d300: 5f70 6f69 6e74 735b 3a2c 0d0a 2020 2020  _points[:,..    
 0000d310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d320: 305d 202a 2a20 3229 2c0d 0a20 2020 2020  0] ** 2),..     
-0000d330: 2020 2020 2020 2020 7365 6c66 2e67 695f          self.gi_
-0000d340: 7265 6573 6361 6c65 202a 2a20 3220 2a20  reescale ** 2 * 
-0000d350: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-0000d360: 2020 2020 2020 2020 7365 6c66 2e72 6573          self.res
-0000d370: 745f 6c61 7965 725f 706f 696e 7473 5b3a  t_layer_points[:
-0000d380: 2c20 315d 202a 2a20 3220 2d20 7365 6c66  , 1] ** 2 - self
-0000d390: 2e72 6566 5f6c 6179 6572 5f70 6f69 6e74  .ref_layer_point
-0000d3a0: 735b 3a2c 0d0a 2020 2020 2020 2020 2020  s[:,..          
-0000d3b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d3c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d3d0: 2020 2020 2020 2020 2020 2020 2020 2031                 1
-0000d3e0: 5d20 2a2a 2032 292c 0d0a 2020 2020 2020  ] ** 2),..      
-0000d3f0: 2020 2020 2020 2073 656c 662e 6769 5f72         self.gi_r
-0000d400: 6565 7363 616c 6520 2a2a 2032 202a 2028  eescale ** 2 * (
-0000d410: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000d420: 2020 2020 2020 2073 656c 662e 7265 7374         self.rest
-0000d430: 5f6c 6179 6572 5f70 6f69 6e74 735b 3a2c  _layer_points[:,
-0000d440: 2032 5d20 2a2a 2032 202d 2073 656c 662e   2] ** 2 - self.
-0000d450: 7265 665f 6c61 7965 725f 706f 696e 7473  ref_layer_points
-0000d460: 5b3a 2c0d 0a20 2020 2020 2020 2020 2020  [:,..           
-0000d470: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d480: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d490: 2020 2020 2020 2020 2020 2020 2020 325d                2]
-0000d4a0: 202a 2a20 3229 2c0d 0a20 2020 2020 2020   ** 2),..       
-0000d4b0: 2020 2020 2020 7365 6c66 2e67 695f 7265        self.gi_re
-0000d4c0: 6573 6361 6c65 202a 2a20 3220 2a20 280d  escale ** 2 * (.
-0000d4d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000d4e0: 2020 2020 2020 7365 6c66 2e72 6573 745f        self.rest_
-0000d4f0: 6c61 7965 725f 706f 696e 7473 5b3a 2c20  layer_points[:, 
-0000d500: 305d 202a 2073 656c 662e 7265 7374 5f6c  0] * self.rest_l
-0000d510: 6179 6572 5f70 6f69 6e74 735b 3a2c 2031  ayer_points[:, 1
-0000d520: 5d20 2d20 7365 6c66 2e72 6566 5f6c 6179  ] - self.ref_lay
-0000d530: 6572 5f70 6f69 6e74 735b 3a2c 2030 5d20  er_points[:, 0] 
-0000d540: 2a20 7365 6c66 2e72 6566 5f6c 6179 6572  * self.ref_layer
-0000d550: 5f70 6f69 6e74 735b 3a2c 2031 5d29 2c0d  _points[:, 1]),.
-0000d560: 0a20 2020 2020 2020 2020 2020 2020 7365  .             se
-0000d570: 6c66 2e67 695f 7265 6573 6361 6c65 202a  lf.gi_reescale *
-0000d580: 2a20 3220 2a20 280d 0a20 2020 2020 2020  * 2 * (..       
-0000d590: 2020 2020 2020 2020 2020 2020 2020 7365                se
-0000d5a0: 6c66 2e72 6573 745f 6c61 7965 725f 706f  lf.rest_layer_po
-0000d5b0: 696e 7473 5b3a 2c20 305d 202a 2073 656c  ints[:, 0] * sel
-0000d5c0: 662e 7265 7374 5f6c 6179 6572 5f70 6f69  f.rest_layer_poi
-0000d5d0: 6e74 735b 3a2c 2032 5d20 2d20 7365 6c66  nts[:, 2] - self
-0000d5e0: 2e72 6566 5f6c 6179 6572 5f70 6f69 6e74  .ref_layer_point
-0000d5f0: 735b 3a2c 2030 5d20 2a20 7365 6c66 2e72  s[:, 0] * self.r
+0000d320: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d340: 2020 2020 2031 5d20 2a2a 2032 292c 0d0a       1] ** 2),..
+0000d350: 2020 2020 2020 2020 2020 2020 2073 656c               sel
+0000d360: 662e 6769 5f72 6565 7363 616c 6520 2a2a  f.gi_reescale **
+0000d370: 2032 202a 2028 0d0a 2020 2020 2020 2020   2 * (..        
+0000d380: 2020 2020 2020 2020 2020 2020 2073 656c               sel
+0000d390: 662e 7265 7374 5f6c 6179 6572 5f70 6f69  f.rest_layer_poi
+0000d3a0: 6e74 735b 3a2c 2032 5d20 2a2a 2032 202d  nts[:, 2] ** 2 -
+0000d3b0: 2073 656c 662e 7265 665f 6c61 7965 725f   self.ref_layer_
+0000d3c0: 706f 696e 7473 5b3a 2c0d 0a20 2020 2020  points[:,..     
+0000d3d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d3e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d3f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d400: 2020 2020 325d 202a 2a20 3229 2c0d 0a20      2] ** 2),.. 
+0000d410: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0000d420: 2e67 695f 7265 6573 6361 6c65 202a 2a20  .gi_reescale ** 
+0000d430: 3220 2a20 280d 0a20 2020 2020 2020 2020  2 * (..         
+0000d440: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0000d450: 2e72 6573 745f 6c61 7965 725f 706f 696e  .rest_layer_poin
+0000d460: 7473 5b3a 2c20 305d 202a 2073 656c 662e  ts[:, 0] * self.
+0000d470: 7265 7374 5f6c 6179 6572 5f70 6f69 6e74  rest_layer_point
+0000d480: 735b 3a2c 2031 5d20 2d20 7365 6c66 2e72  s[:, 1] - self.r
+0000d490: 6566 5f6c 6179 6572 5f70 6f69 6e74 735b  ef_layer_points[
+0000d4a0: 3a2c 2030 5d20 2a20 7365 6c66 2e72 6566  :, 0] * self.ref
+0000d4b0: 5f6c 6179 6572 5f70 6f69 6e74 735b 3a2c  _layer_points[:,
+0000d4c0: 2031 5d29 2c0d 0a20 2020 2020 2020 2020   1]),..         
+0000d4d0: 2020 2020 7365 6c66 2e67 695f 7265 6573      self.gi_rees
+0000d4e0: 6361 6c65 202a 2a20 3220 2a20 280d 0a20  cale ** 2 * (.. 
+0000d4f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d500: 2020 2020 7365 6c66 2e72 6573 745f 6c61      self.rest_la
+0000d510: 7965 725f 706f 696e 7473 5b3a 2c20 305d  yer_points[:, 0]
+0000d520: 202a 2073 656c 662e 7265 7374 5f6c 6179   * self.rest_lay
+0000d530: 6572 5f70 6f69 6e74 735b 3a2c 2032 5d20  er_points[:, 2] 
+0000d540: 2d20 7365 6c66 2e72 6566 5f6c 6179 6572  - self.ref_layer
+0000d550: 5f70 6f69 6e74 735b 3a2c 2030 5d20 2a20  _points[:, 0] * 
+0000d560: 7365 6c66 2e72 6566 5f6c 6179 6572 5f70  self.ref_layer_p
+0000d570: 6f69 6e74 735b 3a2c 2032 5d29 2c0d 0a20  oints[:, 2]),.. 
+0000d580: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0000d590: 2e67 695f 7265 6573 6361 6c65 202a 2a20  .gi_reescale ** 
+0000d5a0: 3220 2a20 280d 0a20 2020 2020 2020 2020  2 * (..         
+0000d5b0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0000d5c0: 2e72 6573 745f 6c61 7965 725f 706f 696e  .rest_layer_poin
+0000d5d0: 7473 5b3a 2c20 315d 202a 2073 656c 662e  ts[:, 1] * self.
+0000d5e0: 7265 7374 5f6c 6179 6572 5f70 6f69 6e74  rest_layer_point
+0000d5f0: 735b 3a2c 2032 5d20 2d20 7365 6c66 2e72  s[:, 2] - self.r
 0000d600: 6566 5f6c 6179 6572 5f70 6f69 6e74 735b  ef_layer_points[
-0000d610: 3a2c 2032 5d29 2c0d 0a20 2020 2020 2020  :, 2]),..       
-0000d620: 2020 2020 2020 7365 6c66 2e67 695f 7265        self.gi_re
-0000d630: 6573 6361 6c65 202a 2a20 3220 2a20 280d  escale ** 2 * (.
-0000d640: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000d650: 2020 2020 2020 7365 6c66 2e72 6573 745f        self.rest_
-0000d660: 6c61 7965 725f 706f 696e 7473 5b3a 2c20  layer_points[:, 
-0000d670: 315d 202a 2073 656c 662e 7265 7374 5f6c  1] * self.rest_l
-0000d680: 6179 6572 5f70 6f69 6e74 735b 3a2c 2032  ayer_points[:, 2
-0000d690: 5d20 2d20 7365 6c66 2e72 6566 5f6c 6179  ] - self.ref_lay
-0000d6a0: 6572 5f70 6f69 6e74 735b 3a2c 2031 5d20  er_points[:, 1] 
-0000d6b0: 2a20 7365 6c66 2e72 6566 5f6c 6179 6572  * self.ref_layer
-0000d6c0: 5f70 6f69 6e74 735b 3a2c 2032 5d29 2c0d  _points[:, 2]),.
-0000d6d0: 0a20 2020 2020 2020 2020 2020 2020 2929  .             ))
-0000d6e0: 2e54 0d0a 0d0a 2020 2020 2020 2020 6966  .T....        if
-0000d6f0: 2027 555f 4927 2069 6e20 7365 6c66 2e76   'U_I' in self.v
-0000d700: 6572 626f 7365 3a0d 0a20 2020 2020 2020  erbose:..       
-0000d710: 2020 2020 2055 5f49 203d 2074 6865 616e       U_I = thean
-0000d720: 6f2e 7072 696e 7469 6e67 2e50 7269 6e74  o.printing.Print
-0000d730: 2827 555f 4927 2928 555f 4929 0d0a 0d0a  ('U_I')(U_I)....
-0000d740: 2020 2020 2020 2020 6966 2027 555f 4727          if 'U_G'
-0000d750: 2069 6e20 7365 6c66 2e76 6572 626f 7365   in self.verbose
-0000d760: 3a0d 0a20 2020 2020 2020 2020 2020 2055  :..            U
-0000d770: 5f47 203d 2074 6865 616e 6f2e 7072 696e  _G = theano.prin
-0000d780: 7469 6e67 2e50 7269 6e74 2827 555f 4727  ting.Print('U_G'
-0000d790: 2928 555f 4729 0d0a 0d0a 2020 2020 2020  )(U_G)....      
-0000d7a0: 2020 6966 2073 7472 2873 7973 2e5f 6765    if str(sys._ge
-0000d7b0: 7466 7261 6d65 2829 2e66 5f63 6f64 652e  tframe().f_code.
-0000d7c0: 636f 5f6e 616d 6529 202b 2027 5f67 2720  co_name) + '_g' 
-0000d7d0: 696e 2073 656c 662e 7665 7262 6f73 653a  in self.verbose:
-0000d7e0: 0d0a 2020 2020 2020 2020 2020 2020 7468  ..            th
-0000d7f0: 6561 6e6f 2e70 7269 6e74 696e 672e 7079  eano.printing.py
-0000d800: 646f 7470 7269 6e74 2855 5f49 2c0d 0a20  dotprint(U_I,.. 
-0000d810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d830: 2020 2020 2020 6f75 7466 696c 653d 2267        outfile="g
-0000d840: 7261 7068 732f 2220 2b20 7379 732e 5f67  raphs/" + sys._g
-0000d850: 6574 6672 616d 6528 292e 665f 636f 6465  etframe().f_code
-0000d860: 2e63 6f5f 6e61 6d65 202b 2022 5f69 2e70  .co_name + "_i.p
-0000d870: 6e67 222c 0d0a 2020 2020 2020 2020 2020  ng",..          
-0000d880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d890: 2020 2020 2020 2020 2020 2020 2076 6172               var
-0000d8a0: 5f77 6974 685f 6e61 6d65 5f73 696d 706c  _with_name_simpl
-0000d8b0: 653d 5472 7565 290d 0a0d 0a20 2020 2020  e=True)....     
-0000d8c0: 2020 2020 2020 2074 6865 616e 6f2e 7072         theano.pr
-0000d8d0: 696e 7469 6e67 2e70 7964 6f74 7072 696e  inting.pydotprin
-0000d8e0: 7428 555f 472c 0d0a 2020 2020 2020 2020  t(U_G,..        
-0000d8f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d900: 2020 2020 2020 2020 2020 2020 2020 206f                 o
-0000d910: 7574 6669 6c65 3d22 6772 6170 6873 2f22  utfile="graphs/"
-0000d920: 202b 2073 7973 2e5f 6765 7466 7261 6d65   + sys._getframe
-0000d930: 2829 2e66 5f63 6f64 652e 636f 5f6e 616d  ().f_code.co_nam
-0000d940: 6520 2b20 225f 672e 706e 6722 2c0d 0a20  e + "_g.png",.. 
-0000d950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d960: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d970: 2020 2020 2020 7661 725f 7769 7468 5f6e        var_with_n
-0000d980: 616d 655f 7369 6d70 6c65 3d54 7275 6529  ame_simple=True)
-0000d990: 0d0a 0d0a 2020 2020 2020 2020 2320 4164  ....        # Ad
-0000d9a0: 6420 6e61 6d65 2074 6f20 7468 6520 7468  d name to the th
-0000d9b0: 6561 6e6f 206e 6f64 650d 0a20 2020 2020  eano node..     
-0000d9c0: 2020 2069 6620 555f 493a 0d0a 2020 2020     if U_I:..    
-0000d9d0: 2020 2020 2020 2020 555f 492e 6e61 6d65          U_I.name
-0000d9e0: 203d 2027 4472 6966 7420 7375 7266 6163   = 'Drift surfac
-0000d9f0: 655f 706f 696e 7473 270d 0a20 2020 2020  e_points'..     
-0000da00: 2020 2020 2020 2055 5f47 2e6e 616d 6520         U_G.name 
-0000da10: 3d20 2744 7269 6674 2066 6f6c 6961 7469  = 'Drift foliati
-0000da20: 6f6e 7327 0d0a 0d0a 2020 2020 2020 2020  ons'....        
-0000da30: 7265 7475 726e 2055 5f49 5b3a 2c20 3a73  return U_I[:, :s
-0000da40: 656c 662e 6e5f 756e 6976 6572 7361 6c5f  elf.n_universal_
-0000da50: 6571 5f54 5f6f 705d 2c20 555f 475b 3a2c  eq_T_op], U_G[:,
-0000da60: 203a 7365 6c66 2e6e 5f75 6e69 7665 7273   :self.n_univers
-0000da70: 616c 5f65 715f 545f 6f70 5d0d 0a0d 0a20  al_eq_T_op].... 
-0000da80: 2020 2064 6566 2066 6175 6c74 735f 6d61     def faults_ma
-0000da90: 7472 6978 2873 656c 662c 2066 5f72 6566  trix(self, f_ref
-0000daa0: 3d4e 6f6e 652c 2066 5f72 6573 3d4e 6f6e  =None, f_res=Non
-0000dab0: 6529 3a0d 0a20 2020 2020 2020 2022 2222  e):..        """
-0000dac0: 0d0a 2020 2020 2020 2020 5468 6973 2066  ..        This f
-0000dad0: 756e 6374 696f 6e20 6372 6561 7465 7320  unction creates 
-0000dae0: 7468 6520 7061 7274 206f 6620 7468 6520  the part of the 
-0000daf0: 6772 6170 6820 7468 6174 2067 656e 6572  graph that gener
-0000db00: 6174 6573 2074 6865 2064 6620 6675 6e63  ates the df func
-0000db10: 7469 6f6e 2063 7265 6174 696e 6720 6120  tion creating a 
-0000db20: 2262 6c6f 636b 206d 6f64 656c 2220 6174  "block model" at
-0000db30: 2074 6865 0d0a 2020 2020 2020 2020 7265   the..        re
-0000db40: 6665 7265 6e63 6573 2061 6e64 2074 6865  ferences and the
-0000db50: 2072 6573 7420 6f66 2074 6865 2070 6f69   rest of the poi
-0000db60: 6e74 732e 2054 6865 6e20 7468 6973 2076  nts. Then this v
-0000db70: 6563 746f 7220 6861 7320 746f 2062 6520  ector has to be 
-0000db80: 6170 7065 6e64 6564 2074 6f20 7468 6520  appended to the 
-0000db90: 636f 7661 7269 616e 6365 2066 756e 6374  covariance funct
-0000dba0: 696f 6e0d 0a0d 0a20 2020 2020 2020 2052  ion....        R
-0000dbb0: 6574 7572 6e73 3a0d 0a0d 0a20 2020 2020  eturns:....     
-0000dbc0: 2020 2020 2020 206c 6973 743a 0d0a 0d0a         list:....
-0000dbd0: 2020 2020 2020 2020 2020 2020 2d20 7468              - th
-0000dbe0: 6561 6e6f 2e74 656e 736f 722e 6d61 7472  eano.tensor.matr
-0000dbf0: 6978 3a20 4472 6966 7420 6d61 7472 6978  ix: Drift matrix
-0000dc00: 2066 6f72 2074 6865 2073 7572 6661 6365   for the surface
-0000dc10: 5f70 6f69 6e74 732e 2053 6861 7065 206e  _points. Shape n
-0000dc20: 756d 6265 7220 6f66 2070 6f69 6e74 7320  umber of points 
-0000dc30: 696e 2072 6573 7420 7820 6e20 6466 2e20  in rest x n df. 
-0000dc40: 5468 6973 2064 7269 660d 0a20 2020 2020  This drif..     
-0000dc50: 2020 2020 2020 2020 2069 7320 6120 7369           is a si
-0000dc60: 6d70 6c65 2061 6464 6974 696f 6e20 6f66  mple addition of
-0000dc70: 2061 6e20 6172 6269 7472 6172 7920 6e75   an arbitrary nu
-0000dc80: 6d62 6572 0d0a 0d0a 2020 2020 2020 2020  mber....        
-0000dc90: 2020 2020 2d20 7468 6561 6e6f 2e74 656e      - theano.ten
-0000dca0: 736f 722e 6d61 7472 6978 3a20 4472 6966  sor.matrix: Drif
-0000dcb0: 7420 6d61 7472 6978 2066 6f72 2074 6865  t matrix for the
-0000dcc0: 2067 7261 6469 656e 7473 2e20 5368 6170   gradients. Shap
-0000dcd0: 6520 6e75 6d62 6572 206f 6620 706f 696e  e number of poin
-0000dce0: 7473 2069 6e20 6469 7073 2078 206e 2064  ts in dips x n d
-0000dcf0: 662e 2046 6f72 0d0a 2020 2020 2020 2020  f. For..        
-0000dd00: 2020 2020 2020 6469 7363 7265 7465 2076        discrete v
-0000dd10: 616c 7565 7320 7468 6973 206d 6174 7269  alues this matri
-0000dd20: 7820 7769 6c6c 2062 6520 6e75 6c6c 2073  x will be null s
-0000dd30: 696e 6365 2074 6865 2064 6572 6976 6174  ince the derivat
-0000dd40: 6976 6520 6f66 2061 2063 6f6e 7374 616e  ive of a constan
-0000dd50: 7420 6973 2030 0d0a 2020 2020 2020 2020  t is 0..        
-0000dd60: 2222 220d 0a0d 0a20 2020 2020 2020 206c  """....        l
-0000dd70: 656e 6774 685f 6f66 5f43 472c 206c 656e  ength_of_CG, len
-0000dd80: 6774 685f 6f66 5f43 4749 2c20 6c65 6e67  gth_of_CGI, leng
-0000dd90: 7468 5f6f 665f 555f 492c 206c 656e 6774  th_of_U_I, lengt
-0000dda0: 685f 6f66 5f66 6175 6c74 7320 3d20 7365  h_of_faults = se
-0000ddb0: 6c66 2e6d 6174 7269 6365 735f 7368 6170  lf.matrices_shap
-0000ddc0: 6573 2829 5b0d 0a20 2020 2020 2020 2020  es()[..         
-0000ddd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dde0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ddf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000de00: 2020 2020 2020 2020 2020 2020 2020 3a34                :4
-0000de10: 5d0d 0a0d 0a20 2020 2020 2020 2023 2073  ]....        # s
-0000de20: 656c 662e 6661 756c 745f 6472 6966 7420  elf.fault_drift 
-0000de30: 636f 6e74 6169 6e73 2074 6865 2064 6620  contains the df 
-0000de40: 766f 6c75 6d65 206f 6620 7468 6520 6772  volume of the gr
-0000de50: 6964 2061 6e64 2074 6865 2072 6573 7420  id and the rest 
-0000de60: 616e 6420 7265 6620 706f 696e 7473 2e20  and ref points. 
-0000de70: 466f 7220 7468 6520 6472 6966 7420 7765  For the drift we
-0000de80: 206e 6565 640d 0a20 2020 2020 2020 2023   need..        #
-0000de90: 2074 6f20 6d61 6b65 2069 7420 7265 6c61   to make it rela
-0000dea0: 7469 7665 2074 6f20 7468 6520 7265 6665  tive to the refe
-0000deb0: 7265 6e63 6520 706f 696e 740d 0a20 2020  rence point..   
-0000dec0: 2020 2020 2069 6620 2766 6175 6c74 206d       if 'fault m
-0000ded0: 6174 7269 7827 2069 6e20 7365 6c66 2e76  atrix' in self.v
-0000dee0: 6572 626f 7365 3a0d 0a20 2020 2020 2020  erbose:..       
-0000def0: 2020 2020 2073 656c 662e 6661 756c 745f       self.fault_
-0000df00: 6d61 7472 6978 203d 2074 6865 616e 6f2e  matrix = theano.
-0000df10: 7072 696e 7469 6e67 2e50 7269 6e74 2827  printing.Print('
-0000df20: 7365 6c66 2e66 6175 6c74 5f64 7269 6674  self.fault_drift
-0000df30: 2729 280d 0a20 2020 2020 2020 2020 2020  ')(..           
-0000df40: 2020 2020 2073 656c 662e 6661 756c 745f       self.fault_
-0000df50: 6d61 7472 6978 290d 0a20 2020 2020 2020  matrix)..       
-0000df60: 2023 2069 6e74 6572 6661 6365 5f6c 6f63   # interface_loc
-0000df70: 203d 2073 656c 662e 6661 756c 745f 6472   = self.fault_dr
-0000df80: 6966 742e 7368 6170 655b 315d 202d 2032  ift.shape[1] - 2
-0000df90: 202a 2073 656c 662e 6c65 6e5f 706f 696e   * self.len_poin
-0000dfa0: 7473 0d0a 2020 2020 2020 2020 230d 0a20  ts..        #.. 
-0000dfb0: 2020 2020 2020 2023 2066 6175 6c74 5f64         # fault_d
-0000dfc0: 7269 6674 5f61 745f 7375 7266 6163 655f  rift_at_surface_
-0000dfd0: 706f 696e 7473 5f72 6573 7420 3d20 7365  points_rest = se
-0000dfe0: 6c66 2e66 6175 6c74 5f64 7269 6674 0d0a  lf.fault_drift..
-0000dff0: 2020 2020 2020 2020 2320 6661 756c 745f          # fault_
-0000e000: 6472 6966 745f 6174 5f73 7572 6661 6365  drift_at_surface
-0000e010: 5f70 6f69 6e74 735f 7265 6620 3d20 7365  _points_ref = se
-0000e020: 6c66 2e66 6175 6c74 5f64 7269 6674 0d0a  lf.fault_drift..
-0000e030: 0d0a 2020 2020 2020 2020 465f 4920 3d20  ..        F_I = 
-0000e040: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-0000e050: 2020 2020 2020 2020 2073 656c 662e 6661           self.fa
-0000e060: 756c 745f 6472 6966 745f 6174 5f73 7572  ult_drift_at_sur
-0000e070: 6661 6365 5f70 6f69 6e74 735f 7265 6620  face_points_ref 
-0000e080: 2d20 7365 6c66 2e66 6175 6c74 5f64 7269  - self.fault_dri
-0000e090: 6674 5f61 745f 7375 7266 6163 655f 706f  ft_at_surface_po
-0000e0a0: 696e 7473 5f72 6573 7429 202b 2030 2e30  ints_rest) + 0.0
-0000e0b0: 3030 310d 0a0d 0a20 2020 2020 2020 2023  001....        #
-0000e0c0: 2041 7320 6c6f 6e67 2061 7320 7468 6520   As long as the 
-0000e0d0: 6472 6966 7420 6973 2061 2063 6f6e 7374  drift is a const
-0000e0e0: 616e 7420 465f 4720 6973 206e 756c 6c0d  ant F_G is null.
-0000e0f0: 0a20 2020 2020 2020 2046 5f47 203d 2054  .        F_G = T
-0000e100: 2e7a 6572 6f73 2828 6c65 6e67 7468 5f6f  .zeros((length_o
-0000e110: 665f 6661 756c 7473 2c20 6c65 6e67 7468  f_faults, length
-0000e120: 5f6f 665f 4347 2929 202b 2030 2e30 3030  _of_CG)) + 0.000
-0000e130: 310d 0a0d 0a20 2020 2020 2020 2069 6620  1....        if 
-0000e140: 7374 7228 7379 732e 5f67 6574 6672 616d  str(sys._getfram
-0000e150: 6528 292e 665f 636f 6465 2e63 6f5f 6e61  e().f_code.co_na
-0000e160: 6d65 2920 696e 2073 656c 662e 7665 7262  me) in self.verb
-0000e170: 6f73 653a 0d0a 2020 2020 2020 2020 2020  ose:..          
-0000e180: 2020 465f 4920 3d20 7468 6561 6e6f 2e70    F_I = theano.p
-0000e190: 7269 6e74 696e 672e 5072 696e 7428 2746  rinting.Print('F
-0000e1a0: 6175 6c74 7320 7375 7266 6163 655f 706f  aults surface_po
-0000e1b0: 696e 7473 206d 6174 7269 7827 2928 465f  ints matrix')(F_
-0000e1c0: 4929 0d0a 2020 2020 2020 2020 2020 2020  I)..            
-0000e1d0: 465f 4720 3d20 7468 6561 6e6f 2e70 7269  F_G = theano.pri
-0000e1e0: 6e74 696e 672e 5072 696e 7428 2746 6175  nting.Print('Fau
-0000e1f0: 6c74 7320 6772 6164 6965 6e74 7320 6d61  lts gradients ma
-0000e200: 7472 6978 2729 2846 5f47 290d 0a0d 0a20  trix')(F_G).... 
-0000e210: 2020 2020 2020 2072 6574 7572 6e20 465f         return F_
-0000e220: 492c 2046 5f47 0d0a 0d0a 2020 2020 6465  I, F_G....    de
-0000e230: 6620 636f 7661 7269 616e 6365 5f6d 6174  f covariance_mat
-0000e240: 7269 7828 7365 6c66 293a 0d0a 2020 2020  rix(self):..    
-0000e250: 2020 2020 2222 220d 0a20 2020 2020 2020      """..       
-0000e260: 2053 6574 2061 6c6c 2074 6865 2070 7265   Set all the pre
-0000e270: 7669 6f75 7320 636f 7661 7269 616e 6365  vious covariance
-0000e280: 7320 746f 6765 7468 6572 2069 6e20 7468  s together in th
-0000e290: 6520 756e 6976 6572 7361 6c20 636f 6b72  e universal cokr
-0000e2a0: 6967 696e 6720 6d61 7472 6978 0d0a 0d0a  iging matrix....
-0000e2b0: 2020 2020 2020 2020 5265 7475 726e 733a          Returns:
-0000e2c0: 0d0a 2020 2020 2020 2020 2020 2020 7468  ..            th
-0000e2d0: 6561 6e6f 2e74 656e 736f 722e 6d61 7472  eano.tensor.matr
-0000e2e0: 6978 3a20 4d75 6c74 6976 6172 6961 7465  ix: Multivariate
-0000e2f0: 2063 6f76 6172 6961 6e63 650d 0a20 2020   covariance..   
-0000e300: 2020 2020 2022 2222 0d0a 0d0a 2020 2020       """....    
-0000e310: 2020 2020 2320 4c65 6e67 7468 730d 0a20      # Lengths.. 
-0000e320: 2020 2020 2020 206c 656e 6774 685f 6f66         length_of
-0000e330: 5f43 472c 206c 656e 6774 685f 6f66 5f43  _CG, length_of_C
-0000e340: 4749 2c20 6c65 6e67 7468 5f6f 665f 555f  GI, length_of_U_
-0000e350: 492c 206c 656e 6774 685f 6f66 5f66 6175  I, length_of_fau
-0000e360: 6c74 732c 206c 656e 6774 685f 6f66 5f43  lts, length_of_C
-0000e370: 203d 2073 656c 662e 6d61 7472 6963 6573   = self.matrices
-0000e380: 5f73 6861 7065 7328 290d 0a0d 0a20 2020  _shapes()....   
-0000e390: 2020 2020 2023 2049 6e64 6976 6964 7561       # Individua
-0000e3a0: 6c20 6d61 7472 6963 6573 0d0a 2020 2020  l matrices..    
-0000e3b0: 2020 2020 435f 4720 3d20 7365 6c66 2e63      C_G = self.c
-0000e3c0: 6f76 5f67 7261 6469 656e 7473 2829 0d0a  ov_gradients()..
-0000e3d0: 2020 2020 2020 2020 435f 4920 3d20 7365          C_I = se
-0000e3e0: 6c66 2e63 6f76 5f73 7572 6661 6365 5f70  lf.cov_surface_p
-0000e3f0: 6f69 6e74 7328 290d 0a20 2020 2020 2020  oints()..       
-0000e400: 2043 5f47 4920 3d20 7365 6c66 2e63 6f76   C_GI = self.cov
-0000e410: 5f69 6e74 6572 6661 6365 5f67 7261 6469  _interface_gradi
-0000e420: 656e 7473 2829 0d0a 2020 2020 2020 2020  ents()..        
-0000e430: 555f 492c 2055 5f47 203d 2073 656c 662e  U_I, U_G = self.
-0000e440: 756e 6976 6572 7361 6c5f 6d61 7472 6978  universal_matrix
-0000e450: 2829 0d0a 2020 2020 2020 2020 465f 492c  ()..        F_I,
-0000e460: 2046 5f47 203d 2073 656c 662e 6661 756c   F_G = self.faul
-0000e470: 7473 5f6d 6174 7269 7828 290d 0a0d 0a20  ts_matrix().... 
-0000e480: 2020 2020 2020 2023 203d 3d3d 3d3d 3d3d         # =======
-0000e490: 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d  ================
-0000e4a0: 3d3d 3d3d 3d3d 3d3d 3d3d 0d0a 2020 2020  ==========..    
-0000e4b0: 2020 2020 2320 4372 6561 7469 6f6e 206f      # Creation o
-0000e4c0: 6620 7468 6520 436f 7661 7269 616e 6365  f the Covariance
-0000e4d0: 204d 6174 7269 780d 0a20 2020 2020 2020   Matrix..       
-0000e4e0: 2023 203d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d   # =============
-0000e4f0: 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d  ================
-0000e500: 3d3d 3d3d 0d0a 2020 2020 2020 2020 435f  ====..        C_
-0000e510: 6d61 7472 6978 203d 2054 2e7a 6572 6f73  matrix = T.zeros
-0000e520: 2828 6c65 6e67 7468 5f6f 665f 432c 206c  ((length_of_C, l
-0000e530: 656e 6774 685f 6f66 5f43 2929 0d0a 0d0a  ength_of_C))....
-0000e540: 2020 2020 2020 2020 2320 4669 7273 7420          # First 
-0000e550: 726f 7720 6f66 206d 6174 7269 6365 730d  row of matrices.
-0000e560: 0a20 2020 2020 2020 2023 2053 6574 2043  .        # Set C
-0000e570: 5f47 0d0a 2020 2020 2020 2020 435f 6d61  _G..        C_ma
-0000e580: 7472 6978 203d 2054 2e73 6574 5f73 7562  trix = T.set_sub
-0000e590: 7465 6e73 6f72 2843 5f6d 6174 7269 785b  tensor(C_matrix[
-0000e5a0: 303a 6c65 6e67 7468 5f6f 665f 4347 2c20  0:length_of_CG, 
-0000e5b0: 303a 6c65 6e67 7468 5f6f 665f 4347 5d2c  0:length_of_CG],
-0000e5c0: 2043 5f47 290d 0a20 2020 2020 2020 2023   C_G)..        #
-0000e5d0: 2053 6574 2043 4749 0d0a 2020 2020 2020   Set CGI..      
-0000e5e0: 2020 435f 6d61 7472 6978 203d 2054 2e73    C_matrix = T.s
-0000e5f0: 6574 5f73 7562 7465 6e73 6f72 280d 0a20  et_subtensor(.. 
-0000e600: 2020 2020 2020 2020 2020 2043 5f6d 6174             C_mat
-0000e610: 7269 785b 303a 6c65 6e67 7468 5f6f 665f  rix[0:length_of_
-0000e620: 4347 2c20 6c65 6e67 7468 5f6f 665f 4347  CG, length_of_CG
-0000e630: 3a6c 656e 6774 685f 6f66 5f43 4720 2b20  :length_of_CG + 
-0000e640: 6c65 6e67 7468 5f6f 665f 4347 495d 2c0d  length_of_CGI],.
-0000e650: 0a20 2020 2020 2020 2020 2020 2043 5f47  .            C_G
-0000e660: 492e 5429 0d0a 2020 2020 2020 2020 2320  I.T)..        # 
-0000e670: 5365 7420 5547 0d0a 2020 2020 2020 2020  Set UG..        
-0000e680: 435f 6d61 7472 6978 203d 2054 2e73 6574  C_matrix = T.set
-0000e690: 5f73 7562 7465 6e73 6f72 2843 5f6d 6174  _subtensor(C_mat
-0000e6a0: 7269 785b 303a 6c65 6e67 7468 5f6f 665f  rix[0:length_of_
-0000e6b0: 4347 2c0d 0a20 2020 2020 2020 2020 2020  CG,..           
-0000e6c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e6d0: 2020 2020 2020 2020 6c65 6e67 7468 5f6f          length_o
-0000e6e0: 665f 4347 202b 206c 656e 6774 685f 6f66  f_CG + length_of
-0000e6f0: 5f43 4749 3a6c 656e 6774 685f 6f66 5f43  _CGI:length_of_C
-0000e700: 4720 2b20 6c65 6e67 7468 5f6f 665f 4347  G + length_of_CG
-0000e710: 4920 2b20 6c65 6e67 7468 5f6f 665f 555f  I + length_of_U_
-0000e720: 495d 2c0d 0a20 2020 2020 2020 2020 2020  I],..           
-0000e730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e740: 2020 2020 2020 2020 555f 4729 0d0a 2020          U_G)..  
-0000e750: 2020 2020 2020 2320 5365 7420 4647 2e20        # Set FG. 
-0000e760: 4920 6361 6e6e 6f74 2075 7365 202d 696e  I cannot use -in
-0000e770: 6465 7820 6265 6361 7573 6520 7768 656e  dex because when
-0000e780: 2069 7320 2d30 2069 7320 6571 7569 7661   is -0 is equiva
-0000e790: 6c65 6e74 2074 6f20 300d 0a20 2020 2020  lent to 0..     
-0000e7a0: 2020 2043 5f6d 6174 7269 7820 3d20 542e     C_matrix = T.
-0000e7b0: 7365 745f 7375 6274 656e 736f 7228 0d0a  set_subtensor(..
-0000e7c0: 2020 2020 2020 2020 2020 2020 435f 6d61              C_ma
-0000e7d0: 7472 6978 5b30 3a6c 656e 6774 685f 6f66  trix[0:length_of
-0000e7e0: 5f43 472c 206c 656e 6774 685f 6f66 5f43  _CG, length_of_C
-0000e7f0: 4720 2b20 6c65 6e67 7468 5f6f 665f 4347  G + length_of_CG
-0000e800: 4920 2b20 6c65 6e67 7468 5f6f 665f 555f  I + length_of_U_
-0000e810: 493a 5d2c 0d0a 2020 2020 2020 2020 2020  I:],..          
-0000e820: 2020 465f 472e 5429 0d0a 2020 2020 2020    F_G.T)..      
-0000e830: 2020 2320 5365 636f 6e64 2072 6f77 206f    # Second row o
-0000e840: 6620 6d61 7472 6963 6573 0d0a 2020 2020  f matrices..    
-0000e850: 2020 2020 2320 5365 7420 435f 4947 0d0a      # Set C_IG..
-0000e860: 2020 2020 2020 2020 435f 6d61 7472 6978          C_matrix
-0000e870: 203d 2054 2e73 6574 5f73 7562 7465 6e73   = T.set_subtens
-0000e880: 6f72 280d 0a20 2020 2020 2020 2020 2020  or(..           
-0000e890: 2043 5f6d 6174 7269 785b 6c65 6e67 7468   C_matrix[length
-0000e8a0: 5f6f 665f 4347 3a6c 656e 6774 685f 6f66  _of_CG:length_of
-0000e8b0: 5f43 4720 2b20 6c65 6e67 7468 5f6f 665f  _CG + length_of_
-0000e8c0: 4347 492c 2030 3a6c 656e 6774 685f 6f66  CGI, 0:length_of
-0000e8d0: 5f43 475d 2c0d 0a20 2020 2020 2020 2020  _CG],..         
-0000e8e0: 2020 2043 5f47 4929 0d0a 2020 2020 2020     C_GI)..      
-0000e8f0: 2020 2320 5365 7420 435f 490d 0a20 2020    # Set C_I..   
-0000e900: 2020 2020 2043 5f6d 6174 7269 7820 3d20       C_matrix = 
-0000e910: 542e 7365 745f 7375 6274 656e 736f 7228  T.set_subtensor(
-0000e920: 0d0a 2020 2020 2020 2020 2020 2020 435f  ..            C_
-0000e930: 6d61 7472 6978 5b6c 656e 6774 685f 6f66  matrix[length_of
-0000e940: 5f43 473a 6c65 6e67 7468 5f6f 665f 4347  _CG:length_of_CG
-0000e950: 202b 206c 656e 6774 685f 6f66 5f43 4749   + length_of_CGI
-0000e960: 2c0d 0a20 2020 2020 2020 2020 2020 206c  ,..            l
-0000e970: 656e 6774 685f 6f66 5f43 473a 6c65 6e67  ength_of_CG:leng
-0000e980: 7468 5f6f 665f 4347 202b 206c 656e 6774  th_of_CG + lengt
-0000e990: 685f 6f66 5f43 4749 5d2c 2043 5f49 290d  h_of_CGI], C_I).
-0000e9a0: 0a20 2020 2020 2020 2023 2053 6574 2055  .        # Set U
-0000e9b0: 5f49 0d0a 2020 2020 2020 2020 2320 6966  _I..        # if
-0000e9c0: 206e 6f74 2073 656c 662e 755f 6772 6164   not self.u_grad
-0000e9d0: 655f 542e 6765 745f 7661 6c75 6528 2920  e_T.get_value() 
-0000e9e0: 3d3d 2030 3a0d 0a20 2020 2020 2020 2043  == 0:..        C
-0000e9f0: 5f6d 6174 7269 7820 3d20 542e 7365 745f  _matrix = T.set_
-0000ea00: 7375 6274 656e 736f 7228 0d0a 2020 2020  subtensor(..    
-0000ea10: 2020 2020 2020 2020 435f 6d61 7472 6978          C_matrix
-0000ea20: 5b6c 656e 6774 685f 6f66 5f43 473a 6c65  [length_of_CG:le
-0000ea30: 6e67 7468 5f6f 665f 4347 202b 206c 656e  ngth_of_CG + len
-0000ea40: 6774 685f 6f66 5f43 4749 2c0d 0a20 2020  gth_of_CGI,..   
-0000ea50: 2020 2020 2020 2020 206c 656e 6774 685f           length_
-0000ea60: 6f66 5f43 4720 2b20 6c65 6e67 7468 5f6f  of_CG + length_o
-0000ea70: 665f 4347 493a 6c65 6e67 7468 5f6f 665f  f_CGI:length_of_
-0000ea80: 4347 202b 206c 656e 6774 685f 6f66 5f43  CG + length_of_C
-0000ea90: 4749 202b 206c 656e 6774 685f 6f66 5f55  GI + length_of_U
-0000eaa0: 5f49 5d2c 0d0a 2020 2020 2020 2020 2020  _I],..          
-0000eab0: 2020 555f 4929 0d0a 2020 2020 2020 2020    U_I)..        
-0000eac0: 2320 5365 7420 465f 490d 0a20 2020 2020  # Set F_I..     
-0000ead0: 2020 2043 5f6d 6174 7269 7820 3d20 542e     C_matrix = T.
-0000eae0: 7365 745f 7375 6274 656e 736f 7228 0d0a  set_subtensor(..
-0000eaf0: 2020 2020 2020 2020 2020 2020 435f 6d61              C_ma
-0000eb00: 7472 6978 5b6c 656e 6774 685f 6f66 5f43  trix[length_of_C
-0000eb10: 473a 6c65 6e67 7468 5f6f 665f 4347 202b  G:length_of_CG +
-0000eb20: 206c 656e 6774 685f 6f66 5f43 4749 2c0d   length_of_CGI,.
-0000eb30: 0a20 2020 2020 2020 2020 2020 206c 656e  .            len
-0000eb40: 6774 685f 6f66 5f43 4720 2b20 6c65 6e67  gth_of_CG + leng
-0000eb50: 7468 5f6f 665f 4347 4920 2b20 6c65 6e67  th_of_CGI + leng
-0000eb60: 7468 5f6f 665f 555f 493a 5d2c 2046 5f49  th_of_U_I:], F_I
-0000eb70: 2e54 290d 0a20 2020 2020 2020 2023 2054  .T)..        # T
-0000eb80: 6869 7264 2072 6f77 206f 6620 6d61 7472  hird row of matr
-0000eb90: 6963 6573 0d0a 2020 2020 2020 2020 2320  ices..        # 
-0000eba0: 5365 7420 555f 470d 0a20 2020 2020 2020  Set U_G..       
-0000ebb0: 2043 5f6d 6174 7269 7820 3d20 542e 7365   C_matrix = T.se
-0000ebc0: 745f 7375 6274 656e 736f 7228 0d0a 2020  t_subtensor(..  
-0000ebd0: 2020 2020 2020 2020 2020 435f 6d61 7472            C_matr
-0000ebe0: 6978 5b0d 0a20 2020 2020 2020 2020 2020  ix[..           
-0000ebf0: 206c 656e 6774 685f 6f66 5f43 4720 2b20   length_of_CG + 
-0000ec00: 6c65 6e67 7468 5f6f 665f 4347 493a 6c65  length_of_CGI:le
-0000ec10: 6e67 7468 5f6f 665f 4347 202b 206c 656e  ngth_of_CG + len
-0000ec20: 6774 685f 6f66 5f43 4749 202b 206c 656e  gth_of_CGI + len
-0000ec30: 6774 685f 6f66 5f55 5f49 2c0d 0a20 2020  gth_of_U_I,..   
-0000ec40: 2020 2020 2020 2020 2030 3a6c 656e 6774           0:lengt
-0000ec50: 685f 6f66 5f43 475d 2c20 555f 472e 5429  h_of_CG], U_G.T)
-0000ec60: 0d0a 2020 2020 2020 2020 2320 5365 7420  ..        # Set 
-0000ec70: 555f 490d 0a20 2020 2020 2020 2043 5f6d  U_I..        C_m
-0000ec80: 6174 7269 7820 3d20 542e 7365 745f 7375  atrix = T.set_su
-0000ec90: 6274 656e 736f 7228 435f 6d61 7472 6978  btensor(C_matrix
-0000eca0: 5b0d 0a20 2020 2020 2020 2020 2020 2020  [..             
-0000ecb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ecc0: 2020 2020 2020 6c65 6e67 7468 5f6f 665f        length_of_
-0000ecd0: 4347 202b 206c 656e 6774 685f 6f66 5f43  CG + length_of_C
-0000ece0: 4749 3a6c 656e 6774 685f 6f66 5f43 4720  GI:length_of_CG 
-0000ecf0: 2b20 6c65 6e67 7468 5f6f 665f 4347 4920  + length_of_CGI 
-0000ed00: 2b20 6c65 6e67 7468 5f6f 665f 555f 492c  + length_of_U_I,
-0000ed10: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000ed20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ed30: 2020 2020 206c 656e 6774 685f 6f66 5f43       length_of_C
-0000ed40: 473a 6c65 6e67 7468 5f6f 665f 4347 202b  G:length_of_CG +
-0000ed50: 206c 656e 6774 685f 6f66 5f43 4749 5d2c   length_of_CGI],
-0000ed60: 2055 5f49 2e54 290d 0a20 2020 2020 2020   U_I.T)..       
-0000ed70: 2023 2046 6f75 7274 6820 726f 7720 6f66   # Fourth row of
-0000ed80: 206d 6174 7269 6365 730d 0a20 2020 2020   matrices..     
-0000ed90: 2020 2023 2053 6574 2046 5f47 0d0a 2020     # Set F_G..  
-0000eda0: 2020 2020 2020 435f 6d61 7472 6978 203d        C_matrix =
-0000edb0: 2054 2e73 6574 5f73 7562 7465 6e73 6f72   T.set_subtensor
-0000edc0: 280d 0a20 2020 2020 2020 2020 2020 2043  (..            C
-0000edd0: 5f6d 6174 7269 785b 6c65 6e67 7468 5f6f  _matrix[length_o
-0000ede0: 665f 4347 202b 206c 656e 6774 685f 6f66  f_CG + length_of
-0000edf0: 5f43 4749 202b 206c 656e 6774 685f 6f66  _CGI + length_of
-0000ee00: 5f55 5f49 3a2c 2030 3a6c 656e 6774 685f  _U_I:, 0:length_
-0000ee10: 6f66 5f43 475d 2c0d 0a20 2020 2020 2020  of_CG],..       
-0000ee20: 2020 2020 2046 5f47 290d 0a20 2020 2020       F_G)..     
-0000ee30: 2020 2023 2053 6574 2046 5f49 0d0a 2020     # Set F_I..  
-0000ee40: 2020 2020 2020 435f 6d61 7472 6978 203d        C_matrix =
-0000ee50: 2054 2e73 6574 5f73 7562 7465 6e73 6f72   T.set_subtensor
-0000ee60: 280d 0a20 2020 2020 2020 2020 2020 2043  (..            C
-0000ee70: 5f6d 6174 7269 785b 6c65 6e67 7468 5f6f  _matrix[length_o
-0000ee80: 665f 4347 202b 206c 656e 6774 685f 6f66  f_CG + length_of
-0000ee90: 5f43 4749 202b 206c 656e 6774 685f 6f66  _CGI + length_of
-0000eea0: 5f55 5f49 3a2c 0d0a 2020 2020 2020 2020  _U_I:,..        
-0000eeb0: 2020 2020 6c65 6e67 7468 5f6f 665f 4347      length_of_CG
-0000eec0: 3a6c 656e 6774 685f 6f66 5f43 4720 2b20  :length_of_CG + 
-0000eed0: 6c65 6e67 7468 5f6f 665f 4347 495d 2c20  length_of_CGI], 
-0000eee0: 465f 4929 0d0a 2020 2020 2020 2020 2320  F_I)..        # 
-0000eef0: 4164 6420 6e61 6d65 2074 6f20 7468 6520  Add name to the 
-0000ef00: 7468 6561 6e6f 206e 6f64 650d 0a20 2020  theano node..   
-0000ef10: 2020 2020 2043 5f6d 6174 7269 782e 6e61       C_matrix.na
-0000ef20: 6d65 203d 2027 426c 6f63 6b20 436f 7661  me = 'Block Cova
-0000ef30: 7269 616e 6365 204d 6174 7269 7827 0d0a  riance Matrix'..
-0000ef40: 2020 2020 2020 2020 6966 2073 7472 2873          if str(s
-0000ef50: 7973 2e5f 6765 7466 7261 6d65 2829 2e66  ys._getframe().f
-0000ef60: 5f63 6f64 652e 636f 5f6e 616d 6529 2069  _code.co_name) i
-0000ef70: 6e20 7365 6c66 2e76 6572 626f 7365 3a0d  n self.verbose:.
-0000ef80: 0a20 2020 2020 2020 2020 2020 2043 5f6d  .            C_m
-0000ef90: 6174 7269 7820 3d20 7468 6561 6e6f 2e70  atrix = theano.p
-0000efa0: 7269 6e74 696e 672e 5072 696e 7428 2763  rinting.Print('c
-0000efb0: 6f76 5f66 756e 6374 696f 6e27 2928 435f  ov_function')(C_
-0000efc0: 6d61 7472 6978 290d 0a0d 0a20 2020 2020  matrix)....     
-0000efd0: 2020 2072 6574 7572 6e20 435f 6d61 7472     return C_matr
-0000efe0: 6978 0d0a 0d0a 2020 2020 6465 6620 625f  ix....    def b_
-0000eff0: 7665 6374 6f72 2873 656c 662c 2064 6970  vector(self, dip
-0000f000: 5f61 6e67 6c65 733d 4e6f 6e65 2c20 617a  _angles=None, az
-0000f010: 696d 7574 683d 4e6f 6e65 2c20 706f 6c61  imuth=None, pola
-0000f020: 7269 7479 3d4e 6f6e 6529 3a0d 0a20 2020  rity=None):..   
-0000f030: 2020 2020 2022 2222 0d0a 2020 2020 2020       """..      
-0000f040: 2020 4372 6561 7469 6f6e 206f 6620 7468    Creation of th
-0000f050: 6520 696e 6465 7065 6e64 656e 7420 7665  e independent ve
-0000f060: 6374 6f72 2062 2074 6f20 736f 6c76 6520  ctor b to solve 
-0000f070: 7468 6520 6b72 6967 696e 6720 7379 7374  the kriging syst
-0000f080: 656d 0d0a 0d0a 2020 2020 2020 2020 4172  em....        Ar
-0000f090: 6773 3a0d 0a20 2020 2020 2020 2020 2020  gs:..           
-0000f0a0: 2076 6572 626f 7365 3a20 2d64 6570 7265   verbose: -depre
-0000f0b0: 6361 7465 642d 0d0a 0d0a 2020 2020 2020  cated-....      
-0000f0c0: 2020 5265 7475 726e 733a 0d0a 2020 2020    Returns:..    
-0000f0d0: 2020 2020 2020 2020 7468 6561 6e6f 2e74          theano.t
-0000f0e0: 656e 736f 722e 7665 6374 6f72 3a20 696e  ensor.vector: in
-0000f0f0: 6465 7065 6e64 656e 7420 7665 6374 6f72  dependent vector
-0000f100: 0d0a 2020 2020 2020 2020 2222 220d 0a0d  ..        """...
-0000f110: 0a20 2020 2020 2020 206c 656e 6774 685f  .        length_
-0000f120: 6f66 5f43 203d 2073 656c 662e 6d61 7472  of_C = self.matr
-0000f130: 6963 6573 5f73 6861 7065 7328 295b 2d31  ices_shapes()[-1
-0000f140: 5d0d 0a20 2020 2020 2020 2069 6620 6469  ]..        if di
-0000f150: 705f 616e 676c 6573 2069 7320 4e6f 6e65  p_angles is None
-0000f160: 3a0d 0a20 2020 2020 2020 2020 2020 2064  :..            d
-0000f170: 6970 5f61 6e67 6c65 7320 3d20 7365 6c66  ip_angles = self
-0000f180: 2e64 6970 5f61 6e67 6c65 730d 0a20 2020  .dip_angles..   
-0000f190: 2020 2020 2069 6620 617a 696d 7574 6820       if azimuth 
-0000f1a0: 6973 204e 6f6e 653a 0d0a 2020 2020 2020  is None:..      
-0000f1b0: 2020 2020 2020 617a 696d 7574 6820 3d20        azimuth = 
-0000f1c0: 7365 6c66 2e61 7a69 6d75 7468 0d0a 2020  self.azimuth..  
-0000f1d0: 2020 2020 2020 6966 2070 6f6c 6172 6974        if polarit
-0000f1e0: 7920 6973 204e 6f6e 653a 0d0a 2020 2020  y is None:..    
-0000f1f0: 2020 2020 2020 2020 706f 6c61 7269 7479          polarity
-0000f200: 203d 2073 656c 662e 706f 6c61 7269 7479   = self.polarity
-0000f210: 0d0a 0d0a 2020 2020 2020 2020 2320 3d3d  ....        # ==
-0000f220: 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d  ================
-0000f230: 3d3d 3d0d 0a20 2020 2020 2020 2023 2043  ===..        # C
-0000f240: 7265 6174 696f 6e20 6f66 2074 6865 2067  reation of the g
-0000f250: 7261 6469 656e 7473 2047 2076 6563 746f  radients G vecto
-0000f260: 720d 0a20 2020 2020 2020 2023 2043 616c  r..        # Cal
-0000f270: 6375 6c61 7469 6f6e 206f 6620 7468 6520  culation of the 
-0000f280: 6361 7274 6573 6961 6e20 636f 6d70 6f6e  cartesian compon
-0000f290: 656e 7473 206f 6620 7468 6520 6469 7073  ents of the dips
-0000f2a0: 2061 7373 756d 696e 6720 7468 6520 756e   assuming the un
-0000f2b0: 6974 206d 6f64 756c 650d 0a20 2020 2020  it module..     
-0000f2c0: 2020 2047 5f78 203d 2054 2e73 696e 2854     G_x = T.sin(T
-0000f2d0: 2e64 6567 3272 6164 2864 6970 5f61 6e67  .deg2rad(dip_ang
-0000f2e0: 6c65 7329 2920 2a20 542e 7369 6e28 542e  les)) * T.sin(T.
-0000f2f0: 6465 6732 7261 6428 617a 696d 7574 6829  deg2rad(azimuth)
-0000f300: 2920 2a20 706f 6c61 7269 7479 0d0a 2020  ) * polarity..  
-0000f310: 2020 2020 2020 475f 7920 3d20 542e 7369        G_y = T.si
-0000f320: 6e28 542e 6465 6732 7261 6428 6469 705f  n(T.deg2rad(dip_
-0000f330: 616e 676c 6573 2929 202a 2054 2e63 6f73  angles)) * T.cos
-0000f340: 2854 2e64 6567 3272 6164 2861 7a69 6d75  (T.deg2rad(azimu
-0000f350: 7468 2929 202a 2070 6f6c 6172 6974 790d  th)) * polarity.
-0000f360: 0a20 2020 2020 2020 2047 5f7a 203d 2054  .        G_z = T
-0000f370: 2e63 6f73 2854 2e64 6567 3272 6164 2864  .cos(T.deg2rad(d
-0000f380: 6970 5f61 6e67 6c65 7329 2920 2a20 706f  ip_angles)) * po
-0000f390: 6c61 7269 7479 0d0a 0d0a 2020 2020 2020  larity....      
-0000f3a0: 2020 4720 3d20 542e 636f 6e63 6174 656e    G = T.concaten
-0000f3b0: 6174 6528 2847 5f78 2c20 475f 792c 2047  ate((G_x, G_y, G
-0000f3c0: 5f7a 2929 0d0a 0d0a 2020 2020 2020 2020  _z))....        
-0000f3d0: 2320 4372 6561 7469 6f6e 206f 6620 7468  # Creation of th
-0000f3e0: 6520 4475 616c 204b 7269 6769 6e67 2076  e Dual Kriging v
-0000f3f0: 6563 746f 720d 0a20 2020 2020 2020 2062  ector..        b
-0000f400: 203d 2054 2e7a 6572 6f73 2828 6c65 6e67   = T.zeros((leng
-0000f410: 7468 5f6f 665f 432c 2929 0d0a 2020 2020  th_of_C,))..    
-0000f420: 2020 2020 6220 3d20 542e 7365 745f 7375      b = T.set_su
-0000f430: 6274 656e 736f 7228 625b 303a 472e 7368  btensor(b[0:G.sh
-0000f440: 6170 655b 305d 5d2c 2047 290d 0a0d 0a20  ape[0]], G).... 
-0000f450: 2020 2020 2020 2069 6620 7374 7228 7379         if str(sy
-0000f460: 732e 5f67 6574 6672 616d 6528 292e 665f  s._getframe().f_
-0000f470: 636f 6465 2e63 6f5f 6e61 6d65 2920 696e  code.co_name) in
-0000f480: 2073 656c 662e 7665 7262 6f73 653a 0d0a   self.verbose:..
-0000f490: 2020 2020 2020 2020 2020 2020 6220 3d20              b = 
-0000f4a0: 7468 6561 6e6f 2e70 7269 6e74 696e 672e  theano.printing.
-0000f4b0: 5072 696e 7428 2762 2076 6563 746f 7227  Print('b vector'
-0000f4c0: 2928 6229 0d0a 0d0a 2020 2020 2020 2020  )(b)....        
-0000f4d0: 2320 4164 6420 6e61 6d65 2074 6f20 7468  # Add name to th
-0000f4e0: 6520 7468 6561 6e6f 206e 6f64 650d 0a20  e theano node.. 
-0000f4f0: 2020 2020 2020 2062 2e6e 616d 6520 3d20         b.name = 
-0000f500: 2762 2076 6563 746f 7227 0d0a 2020 2020  'b vector'..    
-0000f510: 2020 2020 7265 7475 726e 2062 0d0a 0d0a      return b....
-0000f520: 2020 2020 6465 6620 736f 6c76 655f 6b72      def solve_kr
-0000f530: 6967 696e 6728 7365 6c66 2c20 623d 4e6f  iging(self, b=No
-0000f540: 6e65 293a 0d0a 2020 2020 2020 2020 2222  ne):..        ""
-0000f550: 220d 0a20 2020 2020 2020 2053 6f6c 7665  "..        Solve
-0000f560: 2074 6865 206b 7269 6769 6e67 2073 7973   the kriging sys
-0000f570: 7465 6d2e 2054 6869 7320 6861 7320 746f  tem. This has to
-0000f580: 2067 6574 2073 7562 7374 6974 7574 6564   get substituted
-0000f590: 2062 7920 6120 6d6f 7265 2065 6666 6963   by a more effic
-0000f5a0: 6965 6e74 2061 6e64 2073 7461 626c 6520  ient and stable 
-0000f5b0: 6d65 7468 6f64 2051 520d 0a20 2020 2020  method QR..     
-0000f5c0: 2020 2064 6563 6f6d 706f 7369 7469 6f6e     decomposition
-0000f5d0: 2069 6e20 616c 6c20 6c69 6b65 6c69 686f   in all likeliho
-0000f5e0: 6f64 0d0a 0d0a 2020 2020 2020 2020 5265  od....        Re
-0000f5f0: 7475 726e 733a 0d0a 2020 2020 2020 2020  turns:..        
-0000f600: 2020 2020 7468 6561 6e6f 2e74 656e 736f      theano.tenso
-0000f610: 722e 7665 6374 6f72 3a20 4475 616c 206b  r.vector: Dual k
-0000f620: 7269 6769 6e67 2070 6172 616d 6574 6572  riging parameter
-0000f630: 730d 0a0d 0a20 2020 2020 2020 2022 2222  s....        """
-0000f640: 0d0a 2020 2020 2020 2020 435f 6d61 7472  ..        C_matr
-0000f650: 6978 203d 2073 656c 662e 636f 7661 7269  ix = self.covari
-0000f660: 616e 6365 5f6d 6174 7269 7828 290d 0a20  ance_matrix().. 
-0000f670: 2020 2020 2020 2069 6620 6220 6973 204e         if b is N
-0000f680: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
-0000f690: 2020 6220 3d20 7365 6c66 2e62 5f76 6563    b = self.b_vec
-0000f6a0: 746f 7228 290d 0a20 2020 2020 2020 2020  tor()..         
-0000f6b0: 2020 2023 2062 203d 2074 6865 616e 6f2e     # b = theano.
-0000f6c0: 7072 696e 7469 6e67 2e50 7269 6e74 2827  printing.Print('
-0000f6d0: 6227 2928 6229 0d0a 2020 2020 2020 2020  b')(b)..        
-0000f6e0: 6966 2073 656c 662e 7370 6172 7365 5f76  if self.sparse_v
-0000f6f0: 6572 7369 6f6e 2069 7320 5472 7565 3a0d  ersion is True:.
-0000f700: 0a20 2020 2020 2020 2020 2020 2062 3220  .            b2 
-0000f710: 3d20 542e 7469 6c65 2862 2c20 2831 2c20  = T.tile(b, (1, 
-0000f720: 3129 292e 540d 0a0d 0a20 2020 2020 2020  1)).T....       
-0000f730: 2020 2020 2043 5f73 7061 7273 6520 3d20       C_sparse = 
-0000f740: 7370 6172 7365 2e63 7372 5f66 726f 6d5f  sparse.csr_from_
-0000f750: 6465 6e73 6528 435f 6d61 7472 6978 290d  dense(C_matrix).
-0000f760: 0a20 2020 2020 2020 2020 2020 2062 5f73  .            b_s
-0000f770: 7061 7273 6520 3d20 7370 6172 7365 2e63  parse = sparse.c
-0000f780: 7372 5f66 726f 6d5f 6465 6e73 6528 6232  sr_from_dense(b2
-0000f790: 290d 0a20 2020 2020 2020 2020 2020 2044  )..            D
-0000f7a0: 4b20 3d20 736f 6c76 2843 5f73 7061 7273  K = solv(C_spars
-0000f7b0: 652c 2062 5f73 7061 7273 6529 0d0a 2020  e, b_sparse)..  
-0000f7c0: 2020 2020 2020 2020 2020 7265 7475 726e            return
-0000f7d0: 2044 4b0d 0a0d 0a20 2020 2020 2020 2023   DK....        #
-0000f7e0: 2053 6f6c 7669 6e67 2074 6865 206b 7269   Solving the kri
-0000f7f0: 6769 6e67 2073 7973 7465 6d0d 0a20 2020  ging system..   
-0000f800: 2020 2020 2065 6c69 6620 7365 6c66 2e64       elif self.d
-0000f810: 6576 6963 6520 3d3d 2027 6375 6461 2720  evice == 'cuda' 
-0000f820: 616e 6420 534b 4355 4441 5f49 4d50 4f52  and SKCUDA_IMPOR
-0000f830: 5420 6973 2054 7275 653a 0d0a 2020 2020  T is True:..    
-0000f840: 2020 2020 2020 2020 696d 706f 7274 2074          import t
-0000f850: 6865 616e 6f2e 6770 7561 7272 6179 2e6c  heano.gpuarray.l
-0000f860: 696e 616c 670d 0a20 2020 2020 2020 2020  inalg..         
-0000f870: 2020 2062 3220 3d20 542e 7469 6c65 2862     b2 = T.tile(b
-0000f880: 2c20 2831 2c20 3129 292e 540d 0a20 2020  , (1, 1)).T..   
-0000f890: 2020 2020 2020 2020 2044 4b5f 7061 7261           DK_para
-0000f8a0: 6d65 7465 7273 203d 2074 6865 616e 6f2e  meters = theano.
-0000f8b0: 6770 7561 7272 6179 2e6c 696e 616c 672e  gpuarray.linalg.
-0000f8c0: 6770 755f 736f 6c76 6528 435f 6d61 7472  gpu_solve(C_matr
-0000f8d0: 6978 2c20 6232 290d 0a0d 0a20 2020 2020  ix, b2)....     
-0000f8e0: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
-0000f8f0: 2020 2020 2020 696d 706f 7274 2074 6865        import the
-0000f900: 616e 6f2e 7465 6e73 6f72 2e73 6c69 6e61  ano.tensor.slina
-0000f910: 6c67 0d0a 0d0a 2020 2020 2020 2020 2020  lg....          
-0000f920: 2020 444b 5f70 6172 616d 6574 6572 7320    DK_parameters 
-0000f930: 3d20 7468 6561 6e6f 2e74 656e 736f 722e  = theano.tensor.
-0000f940: 736c 696e 616c 672e 736f 6c76 6528 435f  slinalg.solve(C_
-0000f950: 6d61 7472 6978 2c20 6229 0d0a 0d0a 2020  matrix, b)....  
-0000f960: 2020 2020 2020 444b 5f70 6172 616d 6574        DK_paramet
-0000f970: 6572 7320 3d20 444b 5f70 6172 616d 6574  ers = DK_paramet
-0000f980: 6572 732e 7265 7368 6170 6528 2844 4b5f  ers.reshape((DK_
-0000f990: 7061 7261 6d65 7465 7273 2e73 6861 7065  parameters.shape
-0000f9a0: 5b30 5d2c 2929 0d0a 0d0a 2020 2020 2020  [0],))....      
-0000f9b0: 2020 2320 4164 6420 6e61 6d65 2074 6f20    # Add name to 
-0000f9c0: 7468 6520 7468 6561 6e6f 206e 6f64 650d  the theano node.
-0000f9d0: 0a20 2020 2020 2020 2044 4b5f 7061 7261  .        DK_para
-0000f9e0: 6d65 7465 7273 2e6e 616d 6520 3d20 2744  meters.name = 'D
-0000f9f0: 7561 6c20 4b72 6967 696e 6720 7061 7261  ual Kriging para
-0000fa00: 6d65 7465 7273 270d 0a0d 0a20 2020 2020  meters'....     
-0000fa10: 2020 2069 6620 7374 7228 7379 732e 5f67     if str(sys._g
-0000fa20: 6574 6672 616d 6528 292e 665f 636f 6465  etframe().f_code
-0000fa30: 2e63 6f5f 6e61 6d65 2920 696e 2073 656c  .co_name) in sel
-0000fa40: 662e 7665 7262 6f73 653a 0d0a 2020 2020  f.verbose:..    
-0000fa50: 2020 2020 2020 2020 444b 5f70 6172 616d          DK_param
-0000fa60: 6574 6572 7320 3d20 7468 6561 6e6f 2e70  eters = theano.p
-0000fa70: 7269 6e74 696e 672e 5072 696e 7428 444b  rinting.Print(DK
-0000fa80: 5f70 6172 616d 6574 6572 732e 6e61 6d65  _parameters.name
-0000fa90: 2928 444b 5f70 6172 616d 6574 6572 7329  )(DK_parameters)
-0000faa0: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-0000fab0: 2044 4b5f 7061 7261 6d65 7465 7273 0d0a   DK_parameters..
-0000fac0: 0d0a 2020 2020 2320 656e 6472 6567 696f  ..    # endregio
-0000fad0: 6e0d 0a0d 0a20 2020 2023 2072 6567 696f  n....    # regio
-0000fae0: 6e20 4576 616c 7561 7465 0d0a 2020 2020  n Evaluate..    
-0000faf0: 6465 6620 785f 746f 5f69 6e74 6572 706f  def x_to_interpo
-0000fb00: 6c61 7465 2873 656c 662c 2067 7269 642c  late(self, grid,
-0000fb10: 2076 6572 626f 7365 3d30 293a 0d0a 2020   verbose=0):..  
-0000fb20: 2020 2020 2020 2222 220d 0a20 2020 2020        """..     
-0000fb30: 2020 2068 6572 6520 4920 6164 6420 746f     here I add to
-0000fb40: 2074 6865 2067 7269 6420 706f 696e 7473   the grid points
-0000fb50: 2061 6c73 6f20 7468 6520 7265 6665 7265   also the refere
-0000fb60: 6e63 6573 2070 6f69 6e74 7328 746f 2063  nces points(to c
-0000fb70: 6865 636b 2074 6865 2076 616c 7565 206f  heck the value o
-0000fb80: 6620 7468 6520 706f 7465 6e74 6961 6c20  f the potential 
-0000fb90: 6669 656c 6420 6174 2074 6865 0d0a 2020  field at the..  
-0000fba0: 2020 2020 2020 7375 7266 6163 655f 706f        surface_po
-0000fbb0: 696e 7473 292e 2041 6c73 6f20 6865 7265  ints). Also here
-0000fbc0: 2049 2077 696c 6c20 6368 6563 6b20 7768   I will check wh
-0000fbd0: 6174 2070 6172 7473 206f 6620 7468 6520  at parts of the 
-0000fbe0: 6772 6964 2068 6176 6520 6265 656e 2061  grid have been a
-0000fbf0: 6c72 6561 6479 2063 6f6d 7075 7465 6420  lready computed 
-0000fc00: 696e 2061 2070 7265 7669 6f75 7320 7365  in a previous se
-0000fc10: 7269 6573 0d0a 2020 2020 2020 2020 746f  ries..        to
-0000fc20: 2061 766f 6964 2074 6f20 7265 636f 6d70   avoid to recomp
-0000fc30: 7574 652e 0d0a 0d0a 2020 2020 2020 2020  ute.....        
-0000fc40: 5265 7475 726e 733a 0d0a 2020 2020 2020  Returns:..      
-0000fc50: 2020 2020 2020 7468 6561 6e6f 2e74 656e        theano.ten
-0000fc60: 736f 722e 6d61 7472 6978 3a20 5468 6520  sor.matrix: The 
-0000fc70: 3344 2070 6f69 6e74 7320 6f66 2074 6865  3D points of the
-0000fc80: 2067 6976 656e 2067 7269 6420 706c 7573   given grid plus
-0000fc90: 2074 6865 2072 6566 6572 656e 6365 2061   the reference a
-0000fca0: 6e64 2072 6573 7420 706f 696e 7473 0d0a  nd rest points..
-0000fcb0: 2020 2020 2020 2020 2222 220d 0a0d 0a20          """.... 
-0000fcc0: 2020 2020 2020 2067 7269 645f 7661 6c20         grid_val 
-0000fcd0: 3d20 542e 636f 6e63 6174 656e 6174 6528  = T.concatenate(
-0000fce0: 5b67 7269 642c 2073 656c 662e 7265 7374  [grid, self.rest
-0000fcf0: 5f6c 6179 6572 5f70 6f69 6e74 735f 616c  _layer_points_al
-0000fd00: 6c2c 0d0a 2020 2020 2020 2020 2020 2020  l,..            
-0000fd10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fd20: 2020 2020 2020 7365 6c66 2e72 6566 5f6c        self.ref_l
-0000fd30: 6179 6572 5f70 6f69 6e74 735f 616c 6c5d  ayer_points_all]
-0000fd40: 290d 0a0d 0a20 2020 2020 2020 2069 6620  )....        if 
-0000fd50: 7665 7262 6f73 6520 3e20 313a 0d0a 2020  verbose > 1:..  
-0000fd60: 2020 2020 2020 2020 2020 7468 6561 6e6f            theano
-0000fd70: 2e70 7269 6e74 696e 672e 7079 646f 7470  .printing.pydotp
-0000fd80: 7269 6e74 2867 7269 645f 7661 6c2c 0d0a  rint(grid_val,..
-0000fd90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fda0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fdb0: 2020 2020 2020 206f 7574 6669 6c65 3d22         outfile="
-0000fdc0: 6772 6170 6873 2f22 202b 2073 7973 2e5f  graphs/" + sys._
-0000fdd0: 6765 7466 7261 6d65 2829 2e66 5f63 6f64  getframe().f_cod
-0000fde0: 652e 636f 5f6e 616d 6520 2b20 222e 706e  e.co_name + ".pn
-0000fdf0: 6722 2c0d 0a20 2020 2020 2020 2020 2020  g",..           
-0000fe00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fe10: 2020 2020 2020 2020 2020 2020 7661 725f              var_
-0000fe20: 7769 7468 5f6e 616d 655f 7369 6d70 6c65  with_name_simple
-0000fe30: 3d54 7275 6529 0d0a 0d0a 2020 2020 2020  =True)....      
-0000fe40: 2020 6966 2027 6772 6964 5f76 616c 2720    if 'grid_val' 
-0000fe50: 696e 2073 656c 662e 7665 7262 6f73 653a  in self.verbose:
-0000fe60: 0d0a 2020 2020 2020 2020 2020 2020 6772  ..            gr
-0000fe70: 6964 5f76 616c 203d 2074 6865 616e 6f2e  id_val = theano.
-0000fe80: 7072 696e 7469 6e67 2e50 7269 6e74 2827  printing.Print('
-0000fe90: 506f 696e 7473 2074 6f20 696e 7465 7270  Points to interp
-0000fea0: 6f6c 6174 6527 2928 6772 6964 5f76 616c  olate')(grid_val
-0000feb0: 290d 0a0d 0a20 2020 2020 2020 2072 6574  )....        ret
-0000fec0: 7572 6e20 6772 6964 5f76 616c 0d0a 0d0a  urn grid_val....
-0000fed0: 2020 2020 6465 6620 6578 7465 6e64 5f64      def extend_d
-0000fee0: 7561 6c5f 6b72 6967 696e 6728 7365 6c66  ual_kriging(self
-0000fef0: 2c20 7765 6967 6874 732c 2067 7269 645f  , weights, grid_
-0000ff00: 7368 6170 6529 3a0d 0a20 2020 2020 2020  shape):..       
-0000ff10: 2023 2054 4f44 4f20 5468 696e 6b20 7768   # TODO Think wh
-0000ff20: 6174 206f 626a 6563 7420 6973 2077 6f72  at object is wor
-0000ff30: 7468 2074 6f20 7361 7665 2074 6f20 7370  th to save to sp
-0000ff40: 6565 6420 7570 2063 6f6d 7075 7461 7469  eed up computati
-0000ff50: 6f6e 0d0a 2020 2020 2020 2020 2222 220d  on..        """.
-0000ff60: 0a20 2020 2020 2020 2054 696c 6520 7468  .        Tile th
-0000ff70: 6520 6475 616c 206b 7269 6769 6e67 2076  e dual kriging v
-0000ff80: 6563 746f 7220 746f 2063 6f76 6572 2061  ector to cover a
-0000ff90: 6c6c 2074 6865 2070 6f69 6e74 7320 746f  ll the points to
-0000ffa0: 2069 6e74 6572 706f 6c61 7465 2e53 6f20   interpolate.So 
-0000ffb0: 6661 7220 4920 6a75 7374 206d 616b 6520  far I just make 
-0000ffc0: 6120 6d61 7472 6978 2077 6974 6820 7468  a matrix with th
-0000ffd0: 650d 0a20 2020 2020 2020 2064 696d 656e  e..        dimen
-0000ffe0: 7369 6f6e 7320 6c65 6e28 444b 2978 2867  sions len(DK)x(g
-0000fff0: 7269 6429 2062 7574 2069 6e20 7468 6520  rid) but in the 
-00010000: 6675 7475 7265 206d 6179 6265 2049 2068  future maybe I h
-00010010: 6176 6520 746f 2074 7279 2074 6f20 6c6f  ave to try to lo
-00010020: 6f70 2061 6c6c 2074 6869 7320 7061 7274  op all this part
-00010030: 2073 6f20 636f 6e73 756d 6520 6c65 7373   so consume less
-00010040: 206d 656d 6f72 790d 0a0d 0a20 2020 2020   memory....     
-00010050: 2020 2052 6574 7572 6e73 3a0d 0a20 2020     Returns:..   
-00010060: 2020 2020 2020 2020 2074 6865 616e 6f2e           theano.
-00010070: 7465 6e73 6f72 2e6d 6174 7269 783a 204d  tensor.matrix: M
-00010080: 6174 7269 7820 7769 7468 2074 6865 2044  atrix with the D
-00010090: 6b20 7061 7261 6d65 7465 7273 2072 6570  k parameters rep
-000100a0: 6561 7465 6420 666f 7220 616c 6c20 7468  eated for all th
-000100b0: 6520 706f 696e 7473 2074 6f20 696e 7465  e points to inte
-000100c0: 7270 6f6c 6174 650d 0a20 2020 2020 2020  rpolate..       
-000100d0: 2022 2222 0d0a 2020 2020 2020 2020 444b   """..        DK
-000100e0: 5f70 6172 616d 6574 6572 7320 3d20 7765  _parameters = we
-000100f0: 6967 6874 730d 0a20 2020 2020 2020 2023  ights..        #
-00010100: 2043 7265 6174 696f 6e20 6f66 2061 206d   Creation of a m
-00010110: 6174 7269 7820 6f66 2064 696d 656e 7369  atrix of dimensi
-00010120: 6f6e 7320 6571 7561 6c20 746f 2074 6865  ons equal to the
-00010130: 2067 7269 6420 7769 7468 2074 6865 2077   grid with the w
-00010140: 6569 6768 7473 2066 6f72 2065 7665 7279  eights for every
-00010150: 2070 6f69 6e74 2028 6269 6720 3444 206d   point (big 4D m
-00010160: 6174 7269 7820 696e 0d0a 2020 2020 2020  atrix in..      
-00010170: 2020 2320 7261 7665 6c20 666f 726d 290d    # ravel form).
-00010180: 0a20 2020 2020 2020 2023 2054 4f44 4f20  .        # TODO 
-00010190: 494d 503a 2043 6861 6e67 6520 7468 6520  IMP: Change the 
-000101a0: 7469 6c65 2062 7920 6120 7369 6d70 6c65  tile by a simple
-000101b0: 2064 6f74 206f 7020 2d3e 2054 6865 2044   dot op -> The D
-000101c0: 4f54 2076 6572 7369 6f6e 2069 6e20 6770  OT version in gp
-000101d0: 7520 6973 2073 6c6f 7765 720d 0a20 2020  u is slower..   
-000101e0: 2020 2020 2044 4b5f 7765 6967 6874 7320       DK_weights 
-000101f0: 3d20 542e 7469 6c65 2844 4b5f 7061 7261  = T.tile(DK_para
-00010200: 6d65 7465 7273 2c20 2867 7269 645f 7368  meters, (grid_sh
-00010210: 6170 652c 2031 2929 2e54 0d0a 0d0a 2020  ape, 1)).T....  
-00010220: 2020 2020 2020 7265 7475 726e 2044 4b5f        return DK_
-00010230: 7765 6967 6874 730d 0a0d 0a20 2020 2023  weights....    #
-00010240: 2065 6e64 7265 6769 6f6e 0d0a 0d0a 2020   endregion....  
-00010250: 2020 2320 7265 6769 6f6e 2045 7661 6c75    # region Evalu
-00010260: 6174 6520 4765 6f6c 6f67 790d 0a20 2020  ate Geology..   
-00010270: 2064 6566 2063 6f6e 7472 6962 7574 696f   def contributio
-00010280: 6e5f 6772 6164 6965 6e74 5f69 6e74 6572  n_gradient_inter
-00010290: 6661 6365 2873 656c 662c 2067 7269 645f  face(self, grid_
-000102a0: 7661 6c3d 4e6f 6e65 2c20 7765 6967 6874  val=None, weight
-000102b0: 733d 4e6f 6e65 293a 0d0a 2020 2020 2020  s=None):..      
-000102c0: 2020 2222 220d 0a20 2020 2020 2020 2043    """..        C
-000102d0: 6f6d 7075 7461 7469 6f6e 206f 6620 7468  omputation of th
-000102e0: 6520 636f 6e74 7269 6275 7469 6f6e 206f  e contribution o
-000102f0: 6620 7468 6520 666f 6c69 6174 696f 6e73  f the foliations
-00010300: 2061 7420 6576 6572 7920 706f 696e 7420   at every point 
-00010310: 746f 2069 6e74 6572 706f 6c61 7465 0d0a  to interpolate..
-00010320: 0d0a 2020 2020 2020 2020 5265 7475 726e  ..        Return
-00010330: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
-00010340: 7468 6561 6e6f 2e74 656e 736f 722e 7665  theano.tensor.ve
-00010350: 6374 6f72 3a20 436f 6e74 7269 6275 7469  ctor: Contributi
-00010360: 6f6e 206f 6620 616c 6c20 666f 6c69 6174  on of all foliat
-00010370: 696f 6e73 2028 696e 7075 7429 2061 7420  ions (input) at 
-00010380: 6576 6572 7920 706f 696e 7420 746f 2069  every point to i
-00010390: 6e74 6572 706f 6c61 7465 0d0a 2020 2020  nterpolate..    
-000103a0: 2020 2020 2222 220d 0a20 2020 2020 2020      """..       
-000103b0: 2069 6620 7765 6967 6874 7320 6973 204e   if weights is N
-000103c0: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
-000103d0: 2020 7765 6967 6874 7320 3d20 7365 6c66    weights = self
-000103e0: 2e65 7874 656e 645f 6475 616c 5f6b 7269  .extend_dual_kri
-000103f0: 6769 6e67 2829 0d0a 2020 2020 2020 2020  ging()..        
-00010400: 6966 2067 7269 645f 7661 6c20 6973 204e  if grid_val is N
-00010410: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
-00010420: 2020 6772 6964 5f76 616c 203d 2073 656c    grid_val = sel
-00010430: 662e 785f 746f 5f69 6e74 6572 706f 6c61  f.x_to_interpola
-00010440: 7465 2829 0d0a 0d0a 2020 2020 2020 2020  te()....        
-00010450: 6c65 6e67 7468 5f6f 665f 4347 203d 2073  length_of_CG = s
-00010460: 656c 662e 6d61 7472 6963 6573 5f73 6861  elf.matrices_sha
-00010470: 7065 7328 295b 305d 0d0a 0d0a 2020 2020  pes()[0]....    
-00010480: 2020 2020 2320 4361 7274 6573 6961 6e20      # Cartesian 
-00010490: 6469 7374 616e 6365 7320 6265 7477 6565  distances betwee
-000104a0: 6e20 7468 6520 706f 696e 7420 746f 2073  n the point to s
-000104b0: 696d 756c 6174 6520 616e 6420 7468 6520  imulate and the 
-000104c0: 6469 7073 0d0a 2020 2020 2020 2020 6875  dips..        hu
-000104d0: 5f53 696d 506f 696e 7420 3d20 542e 7665  _SimPoint = T.ve
-000104e0: 7274 6963 616c 5f73 7461 636b 280d 0a20  rtical_stack(.. 
-000104f0: 2020 2020 2020 2020 2020 2028 7365 6c66             (self
-00010500: 2e64 6970 735f 706f 7369 7469 6f6e 5b3a  .dips_position[:
-00010510: 2c20 305d 202d 2067 7269 645f 7661 6c5b  , 0] - grid_val[
-00010520: 3a2c 2030 5d2e 7265 7368 6170 6528 0d0a  :, 0].reshape(..
-00010530: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010540: 2867 7269 645f 7661 6c5b 3a2c 2030 5d2e  (grid_val[:, 0].
-00010550: 7368 6170 655b 305d 2c20 3129 2929 2e54  shape[0], 1))).T
-00010560: 2c0d 0a20 2020 2020 2020 2020 2020 2028  ,..            (
-00010570: 7365 6c66 2e64 6970 735f 706f 7369 7469  self.dips_positi
-00010580: 6f6e 5b3a 2c20 315d 202d 2067 7269 645f  on[:, 1] - grid_
-00010590: 7661 6c5b 3a2c 2031 5d2e 7265 7368 6170  val[:, 1].reshap
-000105a0: 6528 0d0a 2020 2020 2020 2020 2020 2020  e(..            
-000105b0: 2020 2020 2867 7269 645f 7661 6c5b 3a2c      (grid_val[:,
-000105c0: 2031 5d2e 7368 6170 655b 305d 2c20 3129   1].shape[0], 1)
-000105d0: 2929 2e54 2c0d 0a20 2020 2020 2020 2020  )).T,..         
-000105e0: 2020 2028 7365 6c66 2e64 6970 735f 706f     (self.dips_po
-000105f0: 7369 7469 6f6e 5b3a 2c20 325d 202d 2067  sition[:, 2] - g
-00010600: 7269 645f 7661 6c5b 3a2c 2032 5d2e 7265  rid_val[:, 2].re
-00010610: 7368 6170 6528 0d0a 2020 2020 2020 2020  shape(..        
-00010620: 2020 2020 2020 2020 2867 7269 645f 7661          (grid_va
-00010630: 6c5b 3a2c 2032 5d2e 7368 6170 655b 305d  l[:, 2].shape[0]
-00010640: 2c20 3129 2929 2e54 0d0a 2020 2020 2020  , 1))).T..      
-00010650: 2020 290d 0a0d 0a20 2020 2020 2020 2023    )....        #
-00010660: 2045 7563 6c69 6469 616e 2064 6973 7461   Euclidian dista
-00010670: 6e63 6573 0d0a 2020 2020 2020 2020 7365  nces..        se
-00010680: 645f 6469 7073 5f53 696d 506f 696e 7420  d_dips_SimPoint 
-00010690: 3d20 7365 6c66 2e73 7175 6172 6564 5f65  = self.squared_e
-000106a0: 7563 6c69 6465 616e 5f64 6973 7461 6e63  uclidean_distanc
-000106b0: 6573 280d 0a20 2020 2020 2020 2020 2020  es(..           
-000106c0: 2073 656c 662e 6469 7073 5f70 6f73 6974   self.dips_posit
-000106d0: 696f 6e5f 7469 6c65 642c 2067 7269 645f  ion_tiled, grid_
-000106e0: 7661 6c29 0d0a 0d0a 2020 2020 2020 2020  val)....        
-000106f0: 6966 2073 656c 662e 7370 6172 7365 5f76  if self.sparse_v
-00010700: 6572 7369 6f6e 2069 7320 5472 7565 3a0d  ersion is True:.
-00010710: 0a20 2020 2020 2020 2020 2020 2063 6f76  .            cov
-00010720: 5f61 7578 203d 2073 7061 7273 652e 6373  _aux = sparse.cs
-00010730: 725f 6672 6f6d 5f64 656e 7365 280d 0a20  r_from_dense(.. 
-00010740: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00010750: 656c 662e 6769 5f72 6565 7363 616c 6520  elf.gi_reescale 
-00010760: 2a0d 0a20 2020 2020 2020 2020 2020 2020  *..             
-00010770: 2020 2028 2d68 755f 5369 6d50 6f69 6e74     (-hu_SimPoint
-00010780: 202a 0d0a 2020 2020 2020 2020 2020 2020   *..            
-00010790: 2020 2020 2028 7365 645f 6469 7073 5f53       (sed_dips_S
-000107a0: 696d 506f 696e 7420 3c20 7365 6c66 2e61  imPoint < self.a
-000107b0: 5f54 5f73 6361 6c61 7229 202a 2020 2320  _T_scalar) *  # 
-000107c0: 6669 7273 7420 6465 7269 7661 7469 7665  first derivative
-000107d0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-000107e0: 2020 2028 2d20 7365 6c66 2e63 5f6f 5f54     (- self.c_o_T
-000107f0: 5f73 6361 6c61 7220 2a20 2828 0d0a 2020  _scalar * ((..  
+0000d610: 3a2c 2031 5d20 2a20 7365 6c66 2e72 6566  :, 1] * self.ref
+0000d620: 5f6c 6179 6572 5f70 6f69 6e74 735b 3a2c  _layer_points[:,
+0000d630: 2032 5d29 2c0d 0a20 2020 2020 2020 2020   2]),..         
+0000d640: 2020 2020 2929 2e54 0d0a 0d0a 2020 2020      )).T....    
+0000d650: 2020 2020 6966 2027 555f 4927 2069 6e20      if 'U_I' in 
+0000d660: 7365 6c66 2e76 6572 626f 7365 3a0d 0a20  self.verbose:.. 
+0000d670: 2020 2020 2020 2020 2020 2055 5f49 203d             U_I =
+0000d680: 2061 6573 6172 612e 7072 696e 7469 6e67   aesara.printing
+0000d690: 2e50 7269 6e74 2827 555f 4927 2928 555f  .Print('U_I')(U_
+0000d6a0: 4929 0d0a 0d0a 2020 2020 2020 2020 6966  I)....        if
+0000d6b0: 2027 555f 4727 2069 6e20 7365 6c66 2e76   'U_G' in self.v
+0000d6c0: 6572 626f 7365 3a0d 0a20 2020 2020 2020  erbose:..       
+0000d6d0: 2020 2020 2055 5f47 203d 2061 6573 6172       U_G = aesar
+0000d6e0: 612e 7072 696e 7469 6e67 2e50 7269 6e74  a.printing.Print
+0000d6f0: 2827 555f 4727 2928 555f 4729 0d0a 0d0a  ('U_G')(U_G)....
+0000d700: 2020 2020 2020 2020 6966 2073 7472 2873          if str(s
+0000d710: 7973 2e5f 6765 7466 7261 6d65 2829 2e66  ys._getframe().f
+0000d720: 5f63 6f64 652e 636f 5f6e 616d 6529 202b  _code.co_name) +
+0000d730: 2027 5f67 2720 696e 2073 656c 662e 7665   '_g' in self.ve
+0000d740: 7262 6f73 653a 0d0a 2020 2020 2020 2020  rbose:..        
+0000d750: 2020 2020 6165 7361 7261 2e70 7269 6e74      aesara.print
+0000d760: 696e 672e 7079 646f 7470 7269 6e74 2855  ing.pydotprint(U
+0000d770: 5f49 2c0d 0a20 2020 2020 2020 2020 2020  _I,..           
+0000d780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d790: 2020 2020 2020 2020 2020 2020 6f75 7466              outf
+0000d7a0: 696c 653d 2267 7261 7068 732f 2220 2b20  ile="graphs/" + 
+0000d7b0: 7379 732e 5f67 6574 6672 616d 6528 292e  sys._getframe().
+0000d7c0: 665f 636f 6465 2e63 6f5f 6e61 6d65 202b  f_code.co_name +
+0000d7d0: 2022 5f69 2e70 6e67 222c 0d0a 2020 2020   "_i.png",..    
+0000d7e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d7f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d800: 2020 2076 6172 5f77 6974 685f 6e61 6d65     var_with_name
+0000d810: 5f73 696d 706c 653d 5472 7565 290d 0a0d  _simple=True)...
+0000d820: 0a20 2020 2020 2020 2020 2020 2061 6573  .            aes
+0000d830: 6172 612e 7072 696e 7469 6e67 2e70 7964  ara.printing.pyd
+0000d840: 6f74 7072 696e 7428 555f 472c 0d0a 2020  otprint(U_G,..  
+0000d850: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d870: 2020 2020 206f 7574 6669 6c65 3d22 6772       outfile="gr
+0000d880: 6170 6873 2f22 202b 2073 7973 2e5f 6765  aphs/" + sys._ge
+0000d890: 7466 7261 6d65 2829 2e66 5f63 6f64 652e  tframe().f_code.
+0000d8a0: 636f 5f6e 616d 6520 2b20 225f 672e 706e  co_name + "_g.pn
+0000d8b0: 6722 2c0d 0a20 2020 2020 2020 2020 2020  g",..           
+0000d8c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d8d0: 2020 2020 2020 2020 2020 2020 7661 725f              var_
+0000d8e0: 7769 7468 5f6e 616d 655f 7369 6d70 6c65  with_name_simple
+0000d8f0: 3d54 7275 6529 0d0a 0d0a 2020 2020 2020  =True)....      
+0000d900: 2020 2320 4164 6420 6e61 6d65 2074 6f20    # Add name to 
+0000d910: 7468 6520 6165 7361 7261 206e 6f64 650d  the aesara node.
+0000d920: 0a20 2020 2020 2020 2069 6620 555f 493a  .        if U_I:
+0000d930: 0d0a 2020 2020 2020 2020 2020 2020 555f  ..            U_
+0000d940: 492e 6e61 6d65 203d 2027 4472 6966 7420  I.name = 'Drift 
+0000d950: 7375 7266 6163 655f 706f 696e 7473 270d  surface_points'.
+0000d960: 0a20 2020 2020 2020 2020 2020 2055 5f47  .            U_G
+0000d970: 2e6e 616d 6520 3d20 2744 7269 6674 2066  .name = 'Drift f
+0000d980: 6f6c 6961 7469 6f6e 7327 0d0a 0d0a 2020  oliations'....  
+0000d990: 2020 2020 2020 7265 7475 726e 2055 5f49        return U_I
+0000d9a0: 5b3a 2c20 3a73 656c 662e 6e5f 756e 6976  [:, :self.n_univ
+0000d9b0: 6572 7361 6c5f 6571 5f54 5f6f 705d 2c20  ersal_eq_T_op], 
+0000d9c0: 555f 475b 3a2c 203a 7365 6c66 2e6e 5f75  U_G[:, :self.n_u
+0000d9d0: 6e69 7665 7273 616c 5f65 715f 545f 6f70  niversal_eq_T_op
+0000d9e0: 5d0d 0a0d 0a20 2020 2064 6566 2066 6175  ]....    def fau
+0000d9f0: 6c74 735f 6d61 7472 6978 2873 656c 662c  lts_matrix(self,
+0000da00: 2066 5f72 6566 3d4e 6f6e 652c 2066 5f72   f_ref=None, f_r
+0000da10: 6573 3d4e 6f6e 6529 3a0d 0a20 2020 2020  es=None):..     
+0000da20: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
+0000da30: 5468 6973 2066 756e 6374 696f 6e20 6372  This function cr
+0000da40: 6561 7465 7320 7468 6520 7061 7274 206f  eates the part o
+0000da50: 6620 7468 6520 6772 6170 6820 7468 6174  f the graph that
+0000da60: 2067 656e 6572 6174 6573 2074 6865 2064   generates the d
+0000da70: 6620 6675 6e63 7469 6f6e 2063 7265 6174  f function creat
+0000da80: 696e 6720 6120 2262 6c6f 636b 206d 6f64  ing a "block mod
+0000da90: 656c 2220 6174 2074 6865 0d0a 2020 2020  el" at the..    
+0000daa0: 2020 2020 7265 6665 7265 6e63 6573 2061      references a
+0000dab0: 6e64 2074 6865 2072 6573 7420 6f66 2074  nd the rest of t
+0000dac0: 6865 2070 6f69 6e74 732e 2054 6865 6e20  he points. Then 
+0000dad0: 7468 6973 2076 6563 746f 7220 6861 7320  this vector has 
+0000dae0: 746f 2062 6520 6170 7065 6e64 6564 2074  to be appended t
+0000daf0: 6f20 7468 6520 636f 7661 7269 616e 6365  o the covariance
+0000db00: 2066 756e 6374 696f 6e0d 0a0d 0a20 2020   function....   
+0000db10: 2020 2020 2052 6574 7572 6e73 3a0d 0a0d       Returns:...
+0000db20: 0a20 2020 2020 2020 2020 2020 206c 6973  .            lis
+0000db30: 743a 0d0a 0d0a 2020 2020 2020 2020 2020  t:....          
+0000db40: 2020 2d20 6165 7361 7261 2e74 656e 736f    - aesara.tenso
+0000db50: 722e 6d61 7472 6978 3a20 4472 6966 7420  r.matrix: Drift 
+0000db60: 6d61 7472 6978 2066 6f72 2074 6865 2073  matrix for the s
+0000db70: 7572 6661 6365 5f70 6f69 6e74 732e 2053  urface_points. S
+0000db80: 6861 7065 206e 756d 6265 7220 6f66 2070  hape number of p
+0000db90: 6f69 6e74 7320 696e 2072 6573 7420 7820  oints in rest x 
+0000dba0: 6e20 6466 2e20 5468 6973 2064 7269 660d  n df. This drif.
+0000dbb0: 0a20 2020 2020 2020 2020 2020 2020 2069  .              i
+0000dbc0: 7320 6120 7369 6d70 6c65 2061 6464 6974  s a simple addit
+0000dbd0: 696f 6e20 6f66 2061 6e20 6172 6269 7472  ion of an arbitr
+0000dbe0: 6172 7920 6e75 6d62 6572 0d0a 0d0a 2020  ary number....  
+0000dbf0: 2020 2020 2020 2020 2020 2d20 6165 7361            - aesa
+0000dc00: 7261 2e74 656e 736f 722e 6d61 7472 6978  ra.tensor.matrix
+0000dc10: 3a20 4472 6966 7420 6d61 7472 6978 2066  : Drift matrix f
+0000dc20: 6f72 2074 6865 2067 7261 6469 656e 7473  or the gradients
+0000dc30: 2e20 5368 6170 6520 6e75 6d62 6572 206f  . Shape number o
+0000dc40: 6620 706f 696e 7473 2069 6e20 6469 7073  f points in dips
+0000dc50: 2078 206e 2064 662e 2046 6f72 0d0a 2020   x n df. For..  
+0000dc60: 2020 2020 2020 2020 2020 2020 6469 7363              disc
+0000dc70: 7265 7465 2076 616c 7565 7320 7468 6973  rete values this
+0000dc80: 206d 6174 7269 7820 7769 6c6c 2062 6520   matrix will be 
+0000dc90: 6e75 6c6c 2073 696e 6365 2074 6865 2064  null since the d
+0000dca0: 6572 6976 6174 6976 6520 6f66 2061 2063  erivative of a c
+0000dcb0: 6f6e 7374 616e 7420 6973 2030 0d0a 2020  onstant is 0..  
+0000dcc0: 2020 2020 2020 2222 220d 0a0d 0a20 2020        """....   
+0000dcd0: 2020 2020 206c 656e 6774 685f 6f66 5f43       length_of_C
+0000dce0: 472c 206c 656e 6774 685f 6f66 5f43 4749  G, length_of_CGI
+0000dcf0: 2c20 6c65 6e67 7468 5f6f 665f 555f 492c  , length_of_U_I,
+0000dd00: 206c 656e 6774 685f 6f66 5f66 6175 6c74   length_of_fault
+0000dd10: 7320 3d20 7365 6c66 2e6d 6174 7269 6365  s = self.matrice
+0000dd20: 735f 7368 6170 6573 2829 5b0d 0a20 2020  s_shapes()[..   
+0000dd30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dd40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dd50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dd60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dd70: 2020 2020 3a34 5d0d 0a0d 0a20 2020 2020      :4]....     
+0000dd80: 2020 2023 2073 656c 662e 6661 756c 745f     # self.fault_
+0000dd90: 6472 6966 7420 636f 6e74 6169 6e73 2074  drift contains t
+0000dda0: 6865 2064 6620 766f 6c75 6d65 206f 6620  he df volume of 
+0000ddb0: 7468 6520 6772 6964 2061 6e64 2074 6865  the grid and the
+0000ddc0: 2072 6573 7420 616e 6420 7265 6620 706f   rest and ref po
+0000ddd0: 696e 7473 2e20 466f 7220 7468 6520 6472  ints. For the dr
+0000dde0: 6966 7420 7765 206e 6565 640d 0a20 2020  ift we need..   
+0000ddf0: 2020 2020 2023 2074 6f20 6d61 6b65 2069       # to make i
+0000de00: 7420 7265 6c61 7469 7665 2074 6f20 7468  t relative to th
+0000de10: 6520 7265 6665 7265 6e63 6520 706f 696e  e reference poin
+0000de20: 740d 0a20 2020 2020 2020 2069 6620 2766  t..        if 'f
+0000de30: 6175 6c74 206d 6174 7269 7827 2069 6e20  ault matrix' in 
+0000de40: 7365 6c66 2e76 6572 626f 7365 3a0d 0a20  self.verbose:.. 
+0000de50: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+0000de60: 6661 756c 745f 6d61 7472 6978 203d 2061  fault_matrix = a
+0000de70: 6573 6172 612e 7072 696e 7469 6e67 2e50  esara.printing.P
+0000de80: 7269 6e74 2827 7365 6c66 2e66 6175 6c74  rint('self.fault
+0000de90: 5f64 7269 6674 2729 280d 0a20 2020 2020  _drift')(..     
+0000dea0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+0000deb0: 6661 756c 745f 6d61 7472 6978 290d 0a20  fault_matrix).. 
+0000dec0: 2020 2020 2020 2023 2069 6e74 6572 6661         # interfa
+0000ded0: 6365 5f6c 6f63 203d 2073 656c 662e 6661  ce_loc = self.fa
+0000dee0: 756c 745f 6472 6966 742e 7368 6170 655b  ult_drift.shape[
+0000def0: 315d 202d 2032 202a 2073 656c 662e 6c65  1] - 2 * self.le
+0000df00: 6e5f 706f 696e 7473 0d0a 2020 2020 2020  n_points..      
+0000df10: 2020 230d 0a20 2020 2020 2020 2023 2066    #..        # f
+0000df20: 6175 6c74 5f64 7269 6674 5f61 745f 7375  ault_drift_at_su
+0000df30: 7266 6163 655f 706f 696e 7473 5f72 6573  rface_points_res
+0000df40: 7420 3d20 7365 6c66 2e66 6175 6c74 5f64  t = self.fault_d
+0000df50: 7269 6674 0d0a 2020 2020 2020 2020 2320  rift..        # 
+0000df60: 6661 756c 745f 6472 6966 745f 6174 5f73  fault_drift_at_s
+0000df70: 7572 6661 6365 5f70 6f69 6e74 735f 7265  urface_points_re
+0000df80: 6620 3d20 7365 6c66 2e66 6175 6c74 5f64  f = self.fault_d
+0000df90: 7269 6674 0d0a 0d0a 2020 2020 2020 2020  rift....        
+0000dfa0: 465f 4920 3d20 280d 0a20 2020 2020 2020  F_I = (..       
+0000dfb0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+0000dfc0: 656c 662e 6661 756c 745f 6472 6966 745f  elf.fault_drift_
+0000dfd0: 6174 5f73 7572 6661 6365 5f70 6f69 6e74  at_surface_point
+0000dfe0: 735f 7265 6620 2d20 7365 6c66 2e66 6175  s_ref - self.fau
+0000dff0: 6c74 5f64 7269 6674 5f61 745f 7375 7266  lt_drift_at_surf
+0000e000: 6163 655f 706f 696e 7473 5f72 6573 7429  ace_points_rest)
+0000e010: 202b 2030 2e30 3030 310d 0a0d 0a20 2020   + 0.0001....   
+0000e020: 2020 2020 2023 2041 7320 6c6f 6e67 2061       # As long a
+0000e030: 7320 7468 6520 6472 6966 7420 6973 2061  s the drift is a
+0000e040: 2063 6f6e 7374 616e 7420 465f 4720 6973   constant F_G is
+0000e050: 206e 756c 6c0d 0a20 2020 2020 2020 2046   null..        F
+0000e060: 5f47 203d 2054 2e7a 6572 6f73 2828 6c65  _G = T.zeros((le
+0000e070: 6e67 7468 5f6f 665f 6661 756c 7473 2c20  ngth_of_faults, 
+0000e080: 6c65 6e67 7468 5f6f 665f 4347 2929 202b  length_of_CG)) +
+0000e090: 2030 2e30 3030 310d 0a0d 0a20 2020 2020   0.0001....     
+0000e0a0: 2020 2069 6620 7374 7228 7379 732e 5f67     if str(sys._g
+0000e0b0: 6574 6672 616d 6528 292e 665f 636f 6465  etframe().f_code
+0000e0c0: 2e63 6f5f 6e61 6d65 2920 696e 2073 656c  .co_name) in sel
+0000e0d0: 662e 7665 7262 6f73 653a 0d0a 2020 2020  f.verbose:..    
+0000e0e0: 2020 2020 2020 2020 465f 4920 3d20 6165          F_I = ae
+0000e0f0: 7361 7261 2e70 7269 6e74 696e 672e 5072  sara.printing.Pr
+0000e100: 696e 7428 2746 6175 6c74 7320 7375 7266  int('Faults surf
+0000e110: 6163 655f 706f 696e 7473 206d 6174 7269  ace_points matri
+0000e120: 7827 2928 465f 4929 0d0a 2020 2020 2020  x')(F_I)..      
+0000e130: 2020 2020 2020 465f 4720 3d20 6165 7361        F_G = aesa
+0000e140: 7261 2e70 7269 6e74 696e 672e 5072 696e  ra.printing.Prin
+0000e150: 7428 2746 6175 6c74 7320 6772 6164 6965  t('Faults gradie
+0000e160: 6e74 7320 6d61 7472 6978 2729 2846 5f47  nts matrix')(F_G
+0000e170: 290d 0a0d 0a20 2020 2020 2020 2072 6574  )....        ret
+0000e180: 7572 6e20 465f 492c 2046 5f47 0d0a 0d0a  urn F_I, F_G....
+0000e190: 2020 2020 6465 6620 636f 7661 7269 616e      def covarian
+0000e1a0: 6365 5f6d 6174 7269 7828 7365 6c66 293a  ce_matrix(self):
+0000e1b0: 0d0a 2020 2020 2020 2020 2222 220d 0a20  ..        """.. 
+0000e1c0: 2020 2020 2020 2053 6574 2061 6c6c 2074         Set all t
+0000e1d0: 6865 2070 7265 7669 6f75 7320 636f 7661  he previous cova
+0000e1e0: 7269 616e 6365 7320 746f 6765 7468 6572  riances together
+0000e1f0: 2069 6e20 7468 6520 756e 6976 6572 7361   in the universa
+0000e200: 6c20 636f 6b72 6967 696e 6720 6d61 7472  l cokriging matr
+0000e210: 6978 0d0a 0d0a 2020 2020 2020 2020 5265  ix....        Re
+0000e220: 7475 726e 733a 0d0a 2020 2020 2020 2020  turns:..        
+0000e230: 2020 2020 6165 7361 7261 2e74 656e 736f      aesara.tenso
+0000e240: 722e 6d61 7472 6978 3a20 4d75 6c74 6976  r.matrix: Multiv
+0000e250: 6172 6961 7465 2063 6f76 6172 6961 6e63  ariate covarianc
+0000e260: 650d 0a20 2020 2020 2020 2022 2222 0d0a  e..        """..
+0000e270: 0d0a 2020 2020 2020 2020 2320 4c65 6e67  ..        # Leng
+0000e280: 7468 730d 0a20 2020 2020 2020 206c 656e  ths..        len
+0000e290: 6774 685f 6f66 5f43 472c 206c 656e 6774  gth_of_CG, lengt
+0000e2a0: 685f 6f66 5f43 4749 2c20 6c65 6e67 7468  h_of_CGI, length
+0000e2b0: 5f6f 665f 555f 492c 206c 656e 6774 685f  _of_U_I, length_
+0000e2c0: 6f66 5f66 6175 6c74 732c 206c 656e 6774  of_faults, lengt
+0000e2d0: 685f 6f66 5f43 203d 2073 656c 662e 6d61  h_of_C = self.ma
+0000e2e0: 7472 6963 6573 5f73 6861 7065 7328 290d  trices_shapes().
+0000e2f0: 0a0d 0a20 2020 2020 2020 2023 2049 6e64  ...        # Ind
+0000e300: 6976 6964 7561 6c20 6d61 7472 6963 6573  ividual matrices
+0000e310: 0d0a 2020 2020 2020 2020 435f 4720 3d20  ..        C_G = 
+0000e320: 7365 6c66 2e63 6f76 5f67 7261 6469 656e  self.cov_gradien
+0000e330: 7473 2829 0d0a 2020 2020 2020 2020 435f  ts()..        C_
+0000e340: 4920 3d20 7365 6c66 2e63 6f76 5f73 7572  I = self.cov_sur
+0000e350: 6661 6365 5f70 6f69 6e74 7328 290d 0a20  face_points().. 
+0000e360: 2020 2020 2020 2043 5f47 4920 3d20 7365         C_GI = se
+0000e370: 6c66 2e63 6f76 5f69 6e74 6572 6661 6365  lf.cov_interface
+0000e380: 5f67 7261 6469 656e 7473 2829 0d0a 2020  _gradients()..  
+0000e390: 2020 2020 2020 555f 492c 2055 5f47 203d        U_I, U_G =
+0000e3a0: 2073 656c 662e 756e 6976 6572 7361 6c5f   self.universal_
+0000e3b0: 6d61 7472 6978 2829 0d0a 2020 2020 2020  matrix()..      
+0000e3c0: 2020 465f 492c 2046 5f47 203d 2073 656c    F_I, F_G = sel
+0000e3d0: 662e 6661 756c 7473 5f6d 6174 7269 7828  f.faults_matrix(
+0000e3e0: 290d 0a0d 0a20 2020 2020 2020 2023 203d  )....        # =
+0000e3f0: 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d  ================
+0000e400: 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d  ================
+0000e410: 0d0a 2020 2020 2020 2020 2320 4372 6561  ..        # Crea
+0000e420: 7469 6f6e 206f 6620 7468 6520 436f 7661  tion of the Cova
+0000e430: 7269 616e 6365 204d 6174 7269 780d 0a20  riance Matrix.. 
+0000e440: 2020 2020 2020 2023 203d 3d3d 3d3d 3d3d         # =======
+0000e450: 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d  ================
+0000e460: 3d3d 3d3d 3d3d 3d3d 3d3d 0d0a 2020 2020  ==========..    
+0000e470: 2020 2020 435f 6d61 7472 6978 203d 2054      C_matrix = T
+0000e480: 2e7a 6572 6f73 2828 6c65 6e67 7468 5f6f  .zeros((length_o
+0000e490: 665f 432c 206c 656e 6774 685f 6f66 5f43  f_C, length_of_C
+0000e4a0: 2929 0d0a 0d0a 2020 2020 2020 2020 2320  ))....        # 
+0000e4b0: 4669 7273 7420 726f 7720 6f66 206d 6174  First row of mat
+0000e4c0: 7269 6365 730d 0a20 2020 2020 2020 2023  rices..        #
+0000e4d0: 2053 6574 2043 5f47 0d0a 2020 2020 2020   Set C_G..      
+0000e4e0: 2020 435f 6d61 7472 6978 203d 2054 2e73    C_matrix = T.s
+0000e4f0: 6574 5f73 7562 7465 6e73 6f72 2843 5f6d  et_subtensor(C_m
+0000e500: 6174 7269 785b 303a 6c65 6e67 7468 5f6f  atrix[0:length_o
+0000e510: 665f 4347 2c20 303a 6c65 6e67 7468 5f6f  f_CG, 0:length_o
+0000e520: 665f 4347 5d2c 2043 5f47 290d 0a20 2020  f_CG], C_G)..   
+0000e530: 2020 2020 2023 2053 6574 2043 4749 0d0a       # Set CGI..
+0000e540: 2020 2020 2020 2020 435f 6d61 7472 6978          C_matrix
+0000e550: 203d 2054 2e73 6574 5f73 7562 7465 6e73   = T.set_subtens
+0000e560: 6f72 280d 0a20 2020 2020 2020 2020 2020  or(..           
+0000e570: 2043 5f6d 6174 7269 785b 303a 6c65 6e67   C_matrix[0:leng
+0000e580: 7468 5f6f 665f 4347 2c20 6c65 6e67 7468  th_of_CG, length
+0000e590: 5f6f 665f 4347 3a6c 656e 6774 685f 6f66  _of_CG:length_of
+0000e5a0: 5f43 4720 2b20 6c65 6e67 7468 5f6f 665f  _CG + length_of_
+0000e5b0: 4347 495d 2c0d 0a20 2020 2020 2020 2020  CGI],..         
+0000e5c0: 2020 2043 5f47 492e 5429 0d0a 2020 2020     C_GI.T)..    
+0000e5d0: 2020 2020 2320 5365 7420 5547 0d0a 2020      # Set UG..  
+0000e5e0: 2020 2020 2020 435f 6d61 7472 6978 203d        C_matrix =
+0000e5f0: 2054 2e73 6574 5f73 7562 7465 6e73 6f72   T.set_subtensor
+0000e600: 2843 5f6d 6174 7269 785b 303a 6c65 6e67  (C_matrix[0:leng
+0000e610: 7468 5f6f 665f 4347 2c0d 0a20 2020 2020  th_of_CG,..     
+0000e620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e630: 2020 2020 2020 2020 2020 2020 2020 6c65                le
+0000e640: 6e67 7468 5f6f 665f 4347 202b 206c 656e  ngth_of_CG + len
+0000e650: 6774 685f 6f66 5f43 4749 3a6c 656e 6774  gth_of_CGI:lengt
+0000e660: 685f 6f66 5f43 4720 2b20 6c65 6e67 7468  h_of_CG + length
+0000e670: 5f6f 665f 4347 4920 2b20 6c65 6e67 7468  _of_CGI + length
+0000e680: 5f6f 665f 555f 495d 2c0d 0a20 2020 2020  _of_U_I],..     
+0000e690: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e6a0: 2020 2020 2020 2020 2020 2020 2020 555f                U_
+0000e6b0: 4729 0d0a 2020 2020 2020 2020 2320 5365  G)..        # Se
+0000e6c0: 7420 4647 2e20 4920 6361 6e6e 6f74 2075  t FG. I cannot u
+0000e6d0: 7365 202d 696e 6465 7820 6265 6361 7573  se -index becaus
+0000e6e0: 6520 7768 656e 2069 7320 2d30 2069 7320  e when is -0 is 
+0000e6f0: 6571 7569 7661 6c65 6e74 2074 6f20 300d  equivalent to 0.
+0000e700: 0a20 2020 2020 2020 2043 5f6d 6174 7269  .        C_matri
+0000e710: 7820 3d20 542e 7365 745f 7375 6274 656e  x = T.set_subten
+0000e720: 736f 7228 0d0a 2020 2020 2020 2020 2020  sor(..          
+0000e730: 2020 435f 6d61 7472 6978 5b30 3a6c 656e    C_matrix[0:len
+0000e740: 6774 685f 6f66 5f43 472c 206c 656e 6774  gth_of_CG, lengt
+0000e750: 685f 6f66 5f43 4720 2b20 6c65 6e67 7468  h_of_CG + length
+0000e760: 5f6f 665f 4347 4920 2b20 6c65 6e67 7468  _of_CGI + length
+0000e770: 5f6f 665f 555f 493a 5d2c 0d0a 2020 2020  _of_U_I:],..    
+0000e780: 2020 2020 2020 2020 465f 472e 5429 0d0a          F_G.T)..
+0000e790: 2020 2020 2020 2020 2320 5365 636f 6e64          # Second
+0000e7a0: 2072 6f77 206f 6620 6d61 7472 6963 6573   row of matrices
+0000e7b0: 0d0a 2020 2020 2020 2020 2320 5365 7420  ..        # Set 
+0000e7c0: 435f 4947 0d0a 2020 2020 2020 2020 435f  C_IG..        C_
+0000e7d0: 6d61 7472 6978 203d 2054 2e73 6574 5f73  matrix = T.set_s
+0000e7e0: 7562 7465 6e73 6f72 280d 0a20 2020 2020  ubtensor(..     
+0000e7f0: 2020 2020 2020 2043 5f6d 6174 7269 785b         C_matrix[
+0000e800: 6c65 6e67 7468 5f6f 665f 4347 3a6c 656e  length_of_CG:len
+0000e810: 6774 685f 6f66 5f43 4720 2b20 6c65 6e67  gth_of_CG + leng
+0000e820: 7468 5f6f 665f 4347 492c 2030 3a6c 656e  th_of_CGI, 0:len
+0000e830: 6774 685f 6f66 5f43 475d 2c0d 0a20 2020  gth_of_CG],..   
+0000e840: 2020 2020 2020 2020 2043 5f47 4929 0d0a           C_GI)..
+0000e850: 2020 2020 2020 2020 2320 5365 7420 435f          # Set C_
+0000e860: 490d 0a20 2020 2020 2020 2043 5f6d 6174  I..        C_mat
+0000e870: 7269 7820 3d20 542e 7365 745f 7375 6274  rix = T.set_subt
+0000e880: 656e 736f 7228 0d0a 2020 2020 2020 2020  ensor(..        
+0000e890: 2020 2020 435f 6d61 7472 6978 5b6c 656e      C_matrix[len
+0000e8a0: 6774 685f 6f66 5f43 473a 6c65 6e67 7468  gth_of_CG:length
+0000e8b0: 5f6f 665f 4347 202b 206c 656e 6774 685f  _of_CG + length_
+0000e8c0: 6f66 5f43 4749 2c0d 0a20 2020 2020 2020  of_CGI,..       
+0000e8d0: 2020 2020 206c 656e 6774 685f 6f66 5f43       length_of_C
+0000e8e0: 473a 6c65 6e67 7468 5f6f 665f 4347 202b  G:length_of_CG +
+0000e8f0: 206c 656e 6774 685f 6f66 5f43 4749 5d2c   length_of_CGI],
+0000e900: 2043 5f49 290d 0a20 2020 2020 2020 2023   C_I)..        #
+0000e910: 2053 6574 2055 5f49 0d0a 2020 2020 2020   Set U_I..      
+0000e920: 2020 2320 6966 206e 6f74 2073 656c 662e    # if not self.
+0000e930: 755f 6772 6164 655f 542e 6765 745f 7661  u_grade_T.get_va
+0000e940: 6c75 6528 2920 3d3d 2030 3a0d 0a20 2020  lue() == 0:..   
+0000e950: 2020 2020 2043 5f6d 6174 7269 7820 3d20       C_matrix = 
+0000e960: 542e 7365 745f 7375 6274 656e 736f 7228  T.set_subtensor(
+0000e970: 0d0a 2020 2020 2020 2020 2020 2020 435f  ..            C_
+0000e980: 6d61 7472 6978 5b6c 656e 6774 685f 6f66  matrix[length_of
+0000e990: 5f43 473a 6c65 6e67 7468 5f6f 665f 4347  _CG:length_of_CG
+0000e9a0: 202b 206c 656e 6774 685f 6f66 5f43 4749   + length_of_CGI
+0000e9b0: 2c0d 0a20 2020 2020 2020 2020 2020 206c  ,..            l
+0000e9c0: 656e 6774 685f 6f66 5f43 4720 2b20 6c65  ength_of_CG + le
+0000e9d0: 6e67 7468 5f6f 665f 4347 493a 6c65 6e67  ngth_of_CGI:leng
+0000e9e0: 7468 5f6f 665f 4347 202b 206c 656e 6774  th_of_CG + lengt
+0000e9f0: 685f 6f66 5f43 4749 202b 206c 656e 6774  h_of_CGI + lengt
+0000ea00: 685f 6f66 5f55 5f49 5d2c 0d0a 2020 2020  h_of_U_I],..    
+0000ea10: 2020 2020 2020 2020 555f 4929 0d0a 2020          U_I)..  
+0000ea20: 2020 2020 2020 2320 5365 7420 465f 490d        # Set F_I.
+0000ea30: 0a20 2020 2020 2020 2043 5f6d 6174 7269  .        C_matri
+0000ea40: 7820 3d20 542e 7365 745f 7375 6274 656e  x = T.set_subten
+0000ea50: 736f 7228 0d0a 2020 2020 2020 2020 2020  sor(..          
+0000ea60: 2020 435f 6d61 7472 6978 5b6c 656e 6774    C_matrix[lengt
+0000ea70: 685f 6f66 5f43 473a 6c65 6e67 7468 5f6f  h_of_CG:length_o
+0000ea80: 665f 4347 202b 206c 656e 6774 685f 6f66  f_CG + length_of
+0000ea90: 5f43 4749 2c0d 0a20 2020 2020 2020 2020  _CGI,..         
+0000eaa0: 2020 206c 656e 6774 685f 6f66 5f43 4720     length_of_CG 
+0000eab0: 2b20 6c65 6e67 7468 5f6f 665f 4347 4920  + length_of_CGI 
+0000eac0: 2b20 6c65 6e67 7468 5f6f 665f 555f 493a  + length_of_U_I:
+0000ead0: 5d2c 2046 5f49 2e54 290d 0a20 2020 2020  ], F_I.T)..     
+0000eae0: 2020 2023 2054 6869 7264 2072 6f77 206f     # Third row o
+0000eaf0: 6620 6d61 7472 6963 6573 0d0a 2020 2020  f matrices..    
+0000eb00: 2020 2020 2320 5365 7420 555f 470d 0a20      # Set U_G.. 
+0000eb10: 2020 2020 2020 2043 5f6d 6174 7269 7820         C_matrix 
+0000eb20: 3d20 542e 7365 745f 7375 6274 656e 736f  = T.set_subtenso
+0000eb30: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
+0000eb40: 435f 6d61 7472 6978 5b0d 0a20 2020 2020  C_matrix[..     
+0000eb50: 2020 2020 2020 206c 656e 6774 685f 6f66         length_of
+0000eb60: 5f43 4720 2b20 6c65 6e67 7468 5f6f 665f  _CG + length_of_
+0000eb70: 4347 493a 6c65 6e67 7468 5f6f 665f 4347  CGI:length_of_CG
+0000eb80: 202b 206c 656e 6774 685f 6f66 5f43 4749   + length_of_CGI
+0000eb90: 202b 206c 656e 6774 685f 6f66 5f55 5f49   + length_of_U_I
+0000eba0: 2c0d 0a20 2020 2020 2020 2020 2020 2030  ,..            0
+0000ebb0: 3a6c 656e 6774 685f 6f66 5f43 475d 2c20  :length_of_CG], 
+0000ebc0: 555f 472e 5429 0d0a 2020 2020 2020 2020  U_G.T)..        
+0000ebd0: 2320 5365 7420 555f 490d 0a20 2020 2020  # Set U_I..     
+0000ebe0: 2020 2043 5f6d 6174 7269 7820 3d20 542e     C_matrix = T.
+0000ebf0: 7365 745f 7375 6274 656e 736f 7228 435f  set_subtensor(C_
+0000ec00: 6d61 7472 6978 5b0d 0a20 2020 2020 2020  matrix[..       
+0000ec10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ec20: 2020 2020 2020 2020 2020 2020 6c65 6e67              leng
+0000ec30: 7468 5f6f 665f 4347 202b 206c 656e 6774  th_of_CG + lengt
+0000ec40: 685f 6f66 5f43 4749 3a6c 656e 6774 685f  h_of_CGI:length_
+0000ec50: 6f66 5f43 4720 2b20 6c65 6e67 7468 5f6f  of_CG + length_o
+0000ec60: 665f 4347 4920 2b20 6c65 6e67 7468 5f6f  f_CGI + length_o
+0000ec70: 665f 555f 492c 0d0a 2020 2020 2020 2020  f_U_I,..        
+0000ec80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ec90: 2020 2020 2020 2020 2020 206c 656e 6774             lengt
+0000eca0: 685f 6f66 5f43 473a 6c65 6e67 7468 5f6f  h_of_CG:length_o
+0000ecb0: 665f 4347 202b 206c 656e 6774 685f 6f66  f_CG + length_of
+0000ecc0: 5f43 4749 5d2c 2055 5f49 2e54 290d 0a20  _CGI], U_I.T).. 
+0000ecd0: 2020 2020 2020 2023 2046 6f75 7274 6820         # Fourth 
+0000ece0: 726f 7720 6f66 206d 6174 7269 6365 730d  row of matrices.
+0000ecf0: 0a20 2020 2020 2020 2023 2053 6574 2046  .        # Set F
+0000ed00: 5f47 0d0a 2020 2020 2020 2020 435f 6d61  _G..        C_ma
+0000ed10: 7472 6978 203d 2054 2e73 6574 5f73 7562  trix = T.set_sub
+0000ed20: 7465 6e73 6f72 280d 0a20 2020 2020 2020  tensor(..       
+0000ed30: 2020 2020 2043 5f6d 6174 7269 785b 6c65       C_matrix[le
+0000ed40: 6e67 7468 5f6f 665f 4347 202b 206c 656e  ngth_of_CG + len
+0000ed50: 6774 685f 6f66 5f43 4749 202b 206c 656e  gth_of_CGI + len
+0000ed60: 6774 685f 6f66 5f55 5f49 3a2c 2030 3a6c  gth_of_U_I:, 0:l
+0000ed70: 656e 6774 685f 6f66 5f43 475d 2c0d 0a20  ength_of_CG],.. 
+0000ed80: 2020 2020 2020 2020 2020 2046 5f47 290d             F_G).
+0000ed90: 0a20 2020 2020 2020 2023 2053 6574 2046  .        # Set F
+0000eda0: 5f49 0d0a 2020 2020 2020 2020 435f 6d61  _I..        C_ma
+0000edb0: 7472 6978 203d 2054 2e73 6574 5f73 7562  trix = T.set_sub
+0000edc0: 7465 6e73 6f72 280d 0a20 2020 2020 2020  tensor(..       
+0000edd0: 2020 2020 2043 5f6d 6174 7269 785b 6c65       C_matrix[le
+0000ede0: 6e67 7468 5f6f 665f 4347 202b 206c 656e  ngth_of_CG + len
+0000edf0: 6774 685f 6f66 5f43 4749 202b 206c 656e  gth_of_CGI + len
+0000ee00: 6774 685f 6f66 5f55 5f49 3a2c 0d0a 2020  gth_of_U_I:,..  
+0000ee10: 2020 2020 2020 2020 2020 6c65 6e67 7468            length
+0000ee20: 5f6f 665f 4347 3a6c 656e 6774 685f 6f66  _of_CG:length_of
+0000ee30: 5f43 4720 2b20 6c65 6e67 7468 5f6f 665f  _CG + length_of_
+0000ee40: 4347 495d 2c20 465f 4929 0d0a 2020 2020  CGI], F_I)..    
+0000ee50: 2020 2020 2320 4164 6420 6e61 6d65 2074      # Add name t
+0000ee60: 6f20 7468 6520 6165 7361 7261 206e 6f64  o the aesara nod
+0000ee70: 650d 0a20 2020 2020 2020 2043 5f6d 6174  e..        C_mat
+0000ee80: 7269 782e 6e61 6d65 203d 2027 426c 6f63  rix.name = 'Bloc
+0000ee90: 6b20 436f 7661 7269 616e 6365 204d 6174  k Covariance Mat
+0000eea0: 7269 7827 0d0a 2020 2020 2020 2020 6966  rix'..        if
+0000eeb0: 2073 7472 2873 7973 2e5f 6765 7466 7261   str(sys._getfra
+0000eec0: 6d65 2829 2e66 5f63 6f64 652e 636f 5f6e  me().f_code.co_n
+0000eed0: 616d 6529 2069 6e20 7365 6c66 2e76 6572  ame) in self.ver
+0000eee0: 626f 7365 3a0d 0a20 2020 2020 2020 2020  bose:..         
+0000eef0: 2020 2043 5f6d 6174 7269 7820 3d20 6165     C_matrix = ae
+0000ef00: 7361 7261 2e70 7269 6e74 696e 672e 5072  sara.printing.Pr
+0000ef10: 696e 7428 2763 6f76 5f66 756e 6374 696f  int('cov_functio
+0000ef20: 6e27 2928 435f 6d61 7472 6978 290d 0a0d  n')(C_matrix)...
+0000ef30: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0000ef40: 435f 6d61 7472 6978 0d0a 0d0a 2020 2020  C_matrix....    
+0000ef50: 6465 6620 625f 7665 6374 6f72 2873 656c  def b_vector(sel
+0000ef60: 662c 2064 6970 5f61 6e67 6c65 733d 4e6f  f, dip_angles=No
+0000ef70: 6e65 2c20 617a 696d 7574 683d 4e6f 6e65  ne, azimuth=None
+0000ef80: 2c20 706f 6c61 7269 7479 3d4e 6f6e 6529  , polarity=None)
+0000ef90: 3a0d 0a20 2020 2020 2020 2022 2222 0d0a  :..        """..
+0000efa0: 2020 2020 2020 2020 4372 6561 7469 6f6e          Creation
+0000efb0: 206f 6620 7468 6520 696e 6465 7065 6e64   of the independ
+0000efc0: 656e 7420 7665 6374 6f72 2062 2074 6f20  ent vector b to 
+0000efd0: 736f 6c76 6520 7468 6520 6b72 6967 696e  solve the krigin
+0000efe0: 6720 7379 7374 656d 0d0a 0d0a 2020 2020  g system....    
+0000eff0: 2020 2020 4172 6773 3a0d 0a20 2020 2020      Args:..     
+0000f000: 2020 2020 2020 2076 6572 626f 7365 3a20         verbose: 
+0000f010: 2d64 6570 7265 6361 7465 642d 0d0a 0d0a  -deprecated-....
+0000f020: 2020 2020 2020 2020 5265 7475 726e 733a          Returns:
+0000f030: 0d0a 2020 2020 2020 2020 2020 2020 6165  ..            ae
+0000f040: 7361 7261 2e74 656e 736f 722e 7665 6374  sara.tensor.vect
+0000f050: 6f72 3a20 696e 6465 7065 6e64 656e 7420  or: independent 
+0000f060: 7665 6374 6f72 0d0a 2020 2020 2020 2020  vector..        
+0000f070: 2222 220d 0a0d 0a20 2020 2020 2020 206c  """....        l
+0000f080: 656e 6774 685f 6f66 5f43 203d 2073 656c  ength_of_C = sel
+0000f090: 662e 6d61 7472 6963 6573 5f73 6861 7065  f.matrices_shape
+0000f0a0: 7328 295b 2d31 5d0d 0a20 2020 2020 2020  s()[-1]..       
+0000f0b0: 2069 6620 6469 705f 616e 676c 6573 2069   if dip_angles i
+0000f0c0: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
+0000f0d0: 2020 2020 2064 6970 5f61 6e67 6c65 7320       dip_angles 
+0000f0e0: 3d20 7365 6c66 2e64 6970 5f61 6e67 6c65  = self.dip_angle
+0000f0f0: 730d 0a20 2020 2020 2020 2069 6620 617a  s..        if az
+0000f100: 696d 7574 6820 6973 204e 6f6e 653a 0d0a  imuth is None:..
+0000f110: 2020 2020 2020 2020 2020 2020 617a 696d              azim
+0000f120: 7574 6820 3d20 7365 6c66 2e61 7a69 6d75  uth = self.azimu
+0000f130: 7468 0d0a 2020 2020 2020 2020 6966 2070  th..        if p
+0000f140: 6f6c 6172 6974 7920 6973 204e 6f6e 653a  olarity is None:
+0000f150: 0d0a 2020 2020 2020 2020 2020 2020 706f  ..            po
+0000f160: 6c61 7269 7479 203d 2073 656c 662e 706f  larity = self.po
+0000f170: 6c61 7269 7479 0d0a 0d0a 2020 2020 2020  larity....      
+0000f180: 2020 2320 3d3d 3d3d 3d3d 3d3d 3d3d 3d3d    # ============
+0000f190: 3d3d 3d3d 3d3d 3d3d 3d0d 0a20 2020 2020  =========..     
+0000f1a0: 2020 2023 2043 7265 6174 696f 6e20 6f66     # Creation of
+0000f1b0: 2074 6865 2067 7261 6469 656e 7473 2047   the gradients G
+0000f1c0: 2076 6563 746f 720d 0a20 2020 2020 2020   vector..       
+0000f1d0: 2023 2043 616c 6375 6c61 7469 6f6e 206f   # Calculation o
+0000f1e0: 6620 7468 6520 6361 7274 6573 6961 6e20  f the cartesian 
+0000f1f0: 636f 6d70 6f6e 656e 7473 206f 6620 7468  components of th
+0000f200: 6520 6469 7073 2061 7373 756d 696e 6720  e dips assuming 
+0000f210: 7468 6520 756e 6974 206d 6f64 756c 650d  the unit module.
+0000f220: 0a20 2020 2020 2020 2047 5f78 203d 2054  .        G_x = T
+0000f230: 2e73 696e 2854 2e64 6567 3272 6164 2864  .sin(T.deg2rad(d
+0000f240: 6970 5f61 6e67 6c65 7329 2920 2a20 542e  ip_angles)) * T.
+0000f250: 7369 6e28 542e 6465 6732 7261 6428 617a  sin(T.deg2rad(az
+0000f260: 696d 7574 6829 2920 2a20 706f 6c61 7269  imuth)) * polari
+0000f270: 7479 0d0a 2020 2020 2020 2020 475f 7920  ty..        G_y 
+0000f280: 3d20 542e 7369 6e28 542e 6465 6732 7261  = T.sin(T.deg2ra
+0000f290: 6428 6469 705f 616e 676c 6573 2929 202a  d(dip_angles)) *
+0000f2a0: 2054 2e63 6f73 2854 2e64 6567 3272 6164   T.cos(T.deg2rad
+0000f2b0: 2861 7a69 6d75 7468 2929 202a 2070 6f6c  (azimuth)) * pol
+0000f2c0: 6172 6974 790d 0a20 2020 2020 2020 2047  arity..        G
+0000f2d0: 5f7a 203d 2054 2e63 6f73 2854 2e64 6567  _z = T.cos(T.deg
+0000f2e0: 3272 6164 2864 6970 5f61 6e67 6c65 7329  2rad(dip_angles)
+0000f2f0: 2920 2a20 706f 6c61 7269 7479 0d0a 0d0a  ) * polarity....
+0000f300: 2020 2020 2020 2020 4720 3d20 542e 636f          G = T.co
+0000f310: 6e63 6174 656e 6174 6528 2847 5f78 2c20  ncatenate((G_x, 
+0000f320: 475f 792c 2047 5f7a 2929 0d0a 0d0a 2020  G_y, G_z))....  
+0000f330: 2020 2020 2020 2320 4372 6561 7469 6f6e        # Creation
+0000f340: 206f 6620 7468 6520 4475 616c 204b 7269   of the Dual Kri
+0000f350: 6769 6e67 2076 6563 746f 720d 0a20 2020  ging vector..   
+0000f360: 2020 2020 2062 203d 2054 2e7a 6572 6f73       b = T.zeros
+0000f370: 2828 6c65 6e67 7468 5f6f 665f 432c 2929  ((length_of_C,))
+0000f380: 0d0a 2020 2020 2020 2020 6220 3d20 542e  ..        b = T.
+0000f390: 7365 745f 7375 6274 656e 736f 7228 625b  set_subtensor(b[
+0000f3a0: 303a 472e 7368 6170 655b 305d 5d2c 2047  0:G.shape[0]], G
+0000f3b0: 290d 0a0d 0a20 2020 2020 2020 2069 6620  )....        if 
+0000f3c0: 7374 7228 7379 732e 5f67 6574 6672 616d  str(sys._getfram
+0000f3d0: 6528 292e 665f 636f 6465 2e63 6f5f 6e61  e().f_code.co_na
+0000f3e0: 6d65 2920 696e 2073 656c 662e 7665 7262  me) in self.verb
+0000f3f0: 6f73 653a 0d0a 2020 2020 2020 2020 2020  ose:..          
+0000f400: 2020 6220 3d20 6165 7361 7261 2e70 7269    b = aesara.pri
+0000f410: 6e74 696e 672e 5072 696e 7428 2762 2076  nting.Print('b v
+0000f420: 6563 746f 7227 2928 6229 0d0a 0d0a 2020  ector')(b)....  
+0000f430: 2020 2020 2020 2320 4164 6420 6e61 6d65        # Add name
+0000f440: 2074 6f20 7468 6520 6165 7361 7261 206e   to the aesara n
+0000f450: 6f64 650d 0a20 2020 2020 2020 2062 2e6e  ode..        b.n
+0000f460: 616d 6520 3d20 2762 2076 6563 746f 7227  ame = 'b vector'
+0000f470: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+0000f480: 2062 0d0a 0d0a 2020 2020 6465 6620 736f   b....    def so
+0000f490: 6c76 655f 6b72 6967 696e 6728 7365 6c66  lve_kriging(self
+0000f4a0: 2c20 623d 4e6f 6e65 293a 0d0a 2020 2020  , b=None):..    
+0000f4b0: 2020 2020 2222 220d 0a20 2020 2020 2020      """..       
+0000f4c0: 2053 6f6c 7665 2074 6865 206b 7269 6769   Solve the krigi
+0000f4d0: 6e67 2073 7973 7465 6d2e 2054 6869 7320  ng system. This 
+0000f4e0: 6861 7320 746f 2067 6574 2073 7562 7374  has to get subst
+0000f4f0: 6974 7574 6564 2062 7920 6120 6d6f 7265  ituted by a more
+0000f500: 2065 6666 6963 6965 6e74 2061 6e64 2073   efficient and s
+0000f510: 7461 626c 6520 6d65 7468 6f64 2051 520d  table method QR.
+0000f520: 0a20 2020 2020 2020 2064 6563 6f6d 706f  .        decompo
+0000f530: 7369 7469 6f6e 2069 6e20 616c 6c20 6c69  sition in all li
+0000f540: 6b65 6c69 686f 6f64 0d0a 0d0a 2020 2020  kelihood....    
+0000f550: 2020 2020 5265 7475 726e 733a 0d0a 2020      Returns:..  
+0000f560: 2020 2020 2020 2020 2020 6165 7361 7261            aesara
+0000f570: 2e74 656e 736f 722e 7665 6374 6f72 3a20  .tensor.vector: 
+0000f580: 4475 616c 206b 7269 6769 6e67 2070 6172  Dual kriging par
+0000f590: 616d 6574 6572 730d 0a0d 0a20 2020 2020  ameters....     
+0000f5a0: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
+0000f5b0: 435f 6d61 7472 6978 203d 2073 656c 662e  C_matrix = self.
+0000f5c0: 636f 7661 7269 616e 6365 5f6d 6174 7269  covariance_matri
+0000f5d0: 7828 290d 0a20 2020 2020 2020 2069 6620  x()..        if 
+0000f5e0: 6220 6973 204e 6f6e 653a 0d0a 2020 2020  b is None:..    
+0000f5f0: 2020 2020 2020 2020 6220 3d20 7365 6c66          b = self
+0000f600: 2e62 5f76 6563 746f 7228 290d 0a20 2020  .b_vector()..   
+0000f610: 2020 2020 2020 2020 2023 2062 203d 2061           # b = a
+0000f620: 6573 6172 612e 7072 696e 7469 6e67 2e50  esara.printing.P
+0000f630: 7269 6e74 2827 6227 2928 6229 0d0a 2020  rint('b')(b)..  
+0000f640: 2020 2020 2020 6966 2073 656c 662e 7370        if self.sp
+0000f650: 6172 7365 5f76 6572 7369 6f6e 2069 7320  arse_version is 
+0000f660: 5472 7565 3a0d 0a20 2020 2020 2020 2020  True:..         
+0000f670: 2020 2062 3220 3d20 542e 7469 6c65 2862     b2 = T.tile(b
+0000f680: 2c20 2831 2c20 3129 292e 540d 0a0d 0a20  , (1, 1)).T.... 
+0000f690: 2020 2020 2020 2020 2020 2043 5f73 7061             C_spa
+0000f6a0: 7273 6520 3d20 7370 6172 7365 2e63 7372  rse = sparse.csr
+0000f6b0: 5f66 726f 6d5f 6465 6e73 6528 435f 6d61  _from_dense(C_ma
+0000f6c0: 7472 6978 290d 0a20 2020 2020 2020 2020  trix)..         
+0000f6d0: 2020 2062 5f73 7061 7273 6520 3d20 7370     b_sparse = sp
+0000f6e0: 6172 7365 2e63 7372 5f66 726f 6d5f 6465  arse.csr_from_de
+0000f6f0: 6e73 6528 6232 290d 0a20 2020 2020 2020  nse(b2)..       
+0000f700: 2020 2020 2044 4b20 3d20 736f 6c76 2843       DK = solv(C
+0000f710: 5f73 7061 7273 652c 2062 5f73 7061 7273  _sparse, b_spars
+0000f720: 6529 0d0a 2020 2020 2020 2020 2020 2020  e)..            
+0000f730: 7265 7475 726e 2044 4b0d 0a0d 0a20 2020  return DK....   
+0000f740: 2020 2020 2023 2053 6f6c 7669 6e67 2074       # Solving t
+0000f750: 6865 206b 7269 6769 6e67 2073 7973 7465  he kriging syste
+0000f760: 6d0d 0a20 2020 2020 2020 2065 6c69 6620  m..        elif 
+0000f770: 7365 6c66 2e64 6576 6963 6520 3d3d 2027  self.device == '
+0000f780: 6375 6461 2720 616e 6420 534b 4355 4441  cuda' and SKCUDA
+0000f790: 5f49 4d50 4f52 5420 6973 2054 7275 653a  _IMPORT is True:
+0000f7a0: 0d0a 2020 2020 2020 2020 2020 2020 696d  ..            im
+0000f7b0: 706f 7274 2061 6573 6172 612e 6770 7561  port aesara.gpua
+0000f7c0: 7272 6179 2e6c 696e 616c 670d 0a20 2020  rray.linalg..   
+0000f7d0: 2020 2020 2020 2020 2062 3220 3d20 542e           b2 = T.
+0000f7e0: 7469 6c65 2862 2c20 2831 2c20 3129 292e  tile(b, (1, 1)).
+0000f7f0: 540d 0a20 2020 2020 2020 2020 2020 2044  T..            D
+0000f800: 4b5f 7061 7261 6d65 7465 7273 203d 2061  K_parameters = a
+0000f810: 6573 6172 612e 6770 7561 7272 6179 2e6c  esara.gpuarray.l
+0000f820: 696e 616c 672e 6770 755f 736f 6c76 6528  inalg.gpu_solve(
+0000f830: 435f 6d61 7472 6978 2c20 6232 290d 0a0d  C_matrix, b2)...
+0000f840: 0a20 2020 2020 2020 2065 6c73 653a 0d0a  .        else:..
+0000f850: 2020 2020 2020 2020 2020 2020 696d 706f              impo
+0000f860: 7274 2061 6573 6172 612e 7465 6e73 6f72  rt aesara.tensor
+0000f870: 2e73 6c69 6e61 6c67 0d0a 0d0a 2020 2020  .slinalg....    
+0000f880: 2020 2020 2020 2020 444b 5f70 6172 616d          DK_param
+0000f890: 6574 6572 7320 3d20 6165 7361 7261 2e74  eters = aesara.t
+0000f8a0: 656e 736f 722e 736c 696e 616c 672e 736f  ensor.slinalg.so
+0000f8b0: 6c76 6528 435f 6d61 7472 6978 2c20 6229  lve(C_matrix, b)
+0000f8c0: 0d0a 0d0a 2020 2020 2020 2020 444b 5f70  ....        DK_p
+0000f8d0: 6172 616d 6574 6572 7320 3d20 444b 5f70  arameters = DK_p
+0000f8e0: 6172 616d 6574 6572 732e 7265 7368 6170  arameters.reshap
+0000f8f0: 6528 2844 4b5f 7061 7261 6d65 7465 7273  e((DK_parameters
+0000f900: 2e73 6861 7065 5b30 5d2c 2929 0d0a 0d0a  .shape[0],))....
+0000f910: 2020 2020 2020 2020 2320 4164 6420 6e61          # Add na
+0000f920: 6d65 2074 6f20 7468 6520 6165 7361 7261  me to the aesara
+0000f930: 206e 6f64 650d 0a20 2020 2020 2020 2044   node..        D
+0000f940: 4b5f 7061 7261 6d65 7465 7273 2e6e 616d  K_parameters.nam
+0000f950: 6520 3d20 2744 7561 6c20 4b72 6967 696e  e = 'Dual Krigin
+0000f960: 6720 7061 7261 6d65 7465 7273 270d 0a0d  g parameters'...
+0000f970: 0a20 2020 2020 2020 2069 6620 7374 7228  .        if str(
+0000f980: 7379 732e 5f67 6574 6672 616d 6528 292e  sys._getframe().
+0000f990: 665f 636f 6465 2e63 6f5f 6e61 6d65 2920  f_code.co_name) 
+0000f9a0: 696e 2073 656c 662e 7665 7262 6f73 653a  in self.verbose:
+0000f9b0: 0d0a 2020 2020 2020 2020 2020 2020 444b  ..            DK
+0000f9c0: 5f70 6172 616d 6574 6572 7320 3d20 6165  _parameters = ae
+0000f9d0: 7361 7261 2e70 7269 6e74 696e 672e 5072  sara.printing.Pr
+0000f9e0: 696e 7428 444b 5f70 6172 616d 6574 6572  int(DK_parameter
+0000f9f0: 732e 6e61 6d65 2928 444b 5f70 6172 616d  s.name)(DK_param
+0000fa00: 6574 6572 7329 0d0a 2020 2020 2020 2020  eters)..        
+0000fa10: 7265 7475 726e 2044 4b5f 7061 7261 6d65  return DK_parame
+0000fa20: 7465 7273 0d0a 0d0a 2020 2020 2320 656e  ters....    # en
+0000fa30: 6472 6567 696f 6e0d 0a0d 0a20 2020 2023  dregion....    #
+0000fa40: 2072 6567 696f 6e20 4576 616c 7561 7465   region Evaluate
+0000fa50: 0d0a 2020 2020 6465 6620 785f 746f 5f69  ..    def x_to_i
+0000fa60: 6e74 6572 706f 6c61 7465 2873 656c 662c  nterpolate(self,
+0000fa70: 2067 7269 642c 2076 6572 626f 7365 3d30   grid, verbose=0
+0000fa80: 293a 0d0a 2020 2020 2020 2020 2222 220d  ):..        """.
+0000fa90: 0a20 2020 2020 2020 2068 6572 6520 4920  .        here I 
+0000faa0: 6164 6420 746f 2074 6865 2067 7269 6420  add to the grid 
+0000fab0: 706f 696e 7473 2061 6c73 6f20 7468 6520  points also the 
+0000fac0: 7265 6665 7265 6e63 6573 2070 6f69 6e74  references point
+0000fad0: 7328 746f 2063 6865 636b 2074 6865 2076  s(to check the v
+0000fae0: 616c 7565 206f 6620 7468 6520 706f 7465  alue of the pote
+0000faf0: 6e74 6961 6c20 6669 656c 6420 6174 2074  ntial field at t
+0000fb00: 6865 0d0a 2020 2020 2020 2020 7375 7266  he..        surf
+0000fb10: 6163 655f 706f 696e 7473 292e 2041 6c73  ace_points). Als
+0000fb20: 6f20 6865 7265 2049 2077 696c 6c20 6368  o here I will ch
+0000fb30: 6563 6b20 7768 6174 2070 6172 7473 206f  eck what parts o
+0000fb40: 6620 7468 6520 6772 6964 2068 6176 6520  f the grid have 
+0000fb50: 6265 656e 2061 6c72 6561 6479 2063 6f6d  been already com
+0000fb60: 7075 7465 6420 696e 2061 2070 7265 7669  puted in a previ
+0000fb70: 6f75 7320 7365 7269 6573 0d0a 2020 2020  ous series..    
+0000fb80: 2020 2020 746f 2061 766f 6964 2074 6f20      to avoid to 
+0000fb90: 7265 636f 6d70 7574 652e 0d0a 0d0a 2020  recompute.....  
+0000fba0: 2020 2020 2020 5265 7475 726e 733a 0d0a        Returns:..
+0000fbb0: 2020 2020 2020 2020 2020 2020 6165 7361              aesa
+0000fbc0: 7261 2e74 656e 736f 722e 6d61 7472 6978  ra.tensor.matrix
+0000fbd0: 3a20 5468 6520 3344 2070 6f69 6e74 7320  : The 3D points 
+0000fbe0: 6f66 2074 6865 2067 6976 656e 2067 7269  of the given gri
+0000fbf0: 6420 706c 7573 2074 6865 2072 6566 6572  d plus the refer
+0000fc00: 656e 6365 2061 6e64 2072 6573 7420 706f  ence and rest po
+0000fc10: 696e 7473 0d0a 2020 2020 2020 2020 2222  ints..        ""
+0000fc20: 220d 0a0d 0a20 2020 2020 2020 2067 7269  "....        gri
+0000fc30: 645f 7661 6c20 3d20 542e 636f 6e63 6174  d_val = T.concat
+0000fc40: 656e 6174 6528 5b67 7269 642c 2073 656c  enate([grid, sel
+0000fc50: 662e 7265 7374 5f6c 6179 6572 5f70 6f69  f.rest_layer_poi
+0000fc60: 6e74 735f 616c 6c2c 0d0a 2020 2020 2020  nts_all,..      
+0000fc70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fc80: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0000fc90: 2e72 6566 5f6c 6179 6572 5f70 6f69 6e74  .ref_layer_point
+0000fca0: 735f 616c 6c5d 290d 0a0d 0a20 2020 2020  s_all])....     
+0000fcb0: 2020 2069 6620 7665 7262 6f73 6520 3e20     if verbose > 
+0000fcc0: 313a 0d0a 2020 2020 2020 2020 2020 2020  1:..            
+0000fcd0: 6165 7361 7261 2e70 7269 6e74 696e 672e  aesara.printing.
+0000fce0: 7079 646f 7470 7269 6e74 2867 7269 645f  pydotprint(grid_
+0000fcf0: 7661 6c2c 0d0a 2020 2020 2020 2020 2020  val,..          
+0000fd00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fd10: 2020 2020 2020 2020 2020 2020 206f 7574               out
+0000fd20: 6669 6c65 3d22 6772 6170 6873 2f22 202b  file="graphs/" +
+0000fd30: 2073 7973 2e5f 6765 7466 7261 6d65 2829   sys._getframe()
+0000fd40: 2e66 5f63 6f64 652e 636f 5f6e 616d 6520  .f_code.co_name 
+0000fd50: 2b20 222e 706e 6722 2c0d 0a20 2020 2020  + ".png",..     
+0000fd60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fd70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fd80: 2020 7661 725f 7769 7468 5f6e 616d 655f    var_with_name_
+0000fd90: 7369 6d70 6c65 3d54 7275 6529 0d0a 0d0a  simple=True)....
+0000fda0: 2020 2020 2020 2020 6966 2027 6772 6964          if 'grid
+0000fdb0: 5f76 616c 2720 696e 2073 656c 662e 7665  _val' in self.ve
+0000fdc0: 7262 6f73 653a 0d0a 2020 2020 2020 2020  rbose:..        
+0000fdd0: 2020 2020 6772 6964 5f76 616c 203d 2061      grid_val = a
+0000fde0: 6573 6172 612e 7072 696e 7469 6e67 2e50  esara.printing.P
+0000fdf0: 7269 6e74 2827 506f 696e 7473 2074 6f20  rint('Points to 
+0000fe00: 696e 7465 7270 6f6c 6174 6527 2928 6772  interpolate')(gr
+0000fe10: 6964 5f76 616c 290d 0a0d 0a20 2020 2020  id_val)....     
+0000fe20: 2020 2072 6574 7572 6e20 6772 6964 5f76     return grid_v
+0000fe30: 616c 0d0a 0d0a 2020 2020 6465 6620 6578  al....    def ex
+0000fe40: 7465 6e64 5f64 7561 6c5f 6b72 6967 696e  tend_dual_krigin
+0000fe50: 6728 7365 6c66 2c20 7765 6967 6874 732c  g(self, weights,
+0000fe60: 2067 7269 645f 7368 6170 6529 3a0d 0a20   grid_shape):.. 
+0000fe70: 2020 2020 2020 2023 2054 4f44 4f20 5468         # TODO Th
+0000fe80: 696e 6b20 7768 6174 206f 626a 6563 7420  ink what object 
+0000fe90: 6973 2077 6f72 7468 2074 6f20 7361 7665  is worth to save
+0000fea0: 2074 6f20 7370 6565 6420 7570 2063 6f6d   to speed up com
+0000feb0: 7075 7461 7469 6f6e 0d0a 2020 2020 2020  putation..      
+0000fec0: 2020 2222 220d 0a20 2020 2020 2020 2054    """..        T
+0000fed0: 696c 6520 7468 6520 6475 616c 206b 7269  ile the dual kri
+0000fee0: 6769 6e67 2076 6563 746f 7220 746f 2063  ging vector to c
+0000fef0: 6f76 6572 2061 6c6c 2074 6865 2070 6f69  over all the poi
+0000ff00: 6e74 7320 746f 2069 6e74 6572 706f 6c61  nts to interpola
+0000ff10: 7465 2e53 6f20 6661 7220 4920 6a75 7374  te.So far I just
+0000ff20: 206d 616b 6520 6120 6d61 7472 6978 2077   make a matrix w
+0000ff30: 6974 6820 7468 650d 0a20 2020 2020 2020  ith the..       
+0000ff40: 2064 696d 656e 7369 6f6e 7320 6c65 6e28   dimensions len(
+0000ff50: 444b 2978 2867 7269 6429 2062 7574 2069  DK)x(grid) but i
+0000ff60: 6e20 7468 6520 6675 7475 7265 206d 6179  n the future may
+0000ff70: 6265 2049 2068 6176 6520 746f 2074 7279  be I have to try
+0000ff80: 2074 6f20 6c6f 6f70 2061 6c6c 2074 6869   to loop all thi
+0000ff90: 7320 7061 7274 2073 6f20 636f 6e73 756d  s part so consum
+0000ffa0: 6520 6c65 7373 206d 656d 6f72 790d 0a0d  e less memory...
+0000ffb0: 0a20 2020 2020 2020 2052 6574 7572 6e73  .        Returns
+0000ffc0: 3a0d 0a20 2020 2020 2020 2020 2020 2061  :..            a
+0000ffd0: 6573 6172 612e 7465 6e73 6f72 2e6d 6174  esara.tensor.mat
+0000ffe0: 7269 783a 204d 6174 7269 7820 7769 7468  rix: Matrix with
+0000fff0: 2074 6865 2044 6b20 7061 7261 6d65 7465   the Dk paramete
+00010000: 7273 2072 6570 6561 7465 6420 666f 7220  rs repeated for 
+00010010: 616c 6c20 7468 6520 706f 696e 7473 2074  all the points t
+00010020: 6f20 696e 7465 7270 6f6c 6174 650d 0a20  o interpolate.. 
+00010030: 2020 2020 2020 2022 2222 0d0a 2020 2020         """..    
+00010040: 2020 2020 444b 5f70 6172 616d 6574 6572      DK_parameter
+00010050: 7320 3d20 7765 6967 6874 730d 0a20 2020  s = weights..   
+00010060: 2020 2020 2023 2043 7265 6174 696f 6e20       # Creation 
+00010070: 6f66 2061 206d 6174 7269 7820 6f66 2064  of a matrix of d
+00010080: 696d 656e 7369 6f6e 7320 6571 7561 6c20  imensions equal 
+00010090: 746f 2074 6865 2067 7269 6420 7769 7468  to the grid with
+000100a0: 2074 6865 2077 6569 6768 7473 2066 6f72   the weights for
+000100b0: 2065 7665 7279 2070 6f69 6e74 2028 6269   every point (bi
+000100c0: 6720 3444 206d 6174 7269 7820 696e 0d0a  g 4D matrix in..
+000100d0: 2020 2020 2020 2020 2320 7261 7665 6c20          # ravel 
+000100e0: 666f 726d 290d 0a20 2020 2020 2020 2023  form)..        #
+000100f0: 2054 4f44 4f20 494d 503a 2043 6861 6e67   TODO IMP: Chang
+00010100: 6520 7468 6520 7469 6c65 2062 7920 6120  e the tile by a 
+00010110: 7369 6d70 6c65 2064 6f74 206f 7020 2d3e  simple dot op ->
+00010120: 2054 6865 2044 4f54 2076 6572 7369 6f6e   The DOT version
+00010130: 2069 6e20 6770 7520 6973 2073 6c6f 7765   in gpu is slowe
+00010140: 720d 0a20 2020 2020 2020 2044 4b5f 7765  r..        DK_we
+00010150: 6967 6874 7320 3d20 542e 7469 6c65 2844  ights = T.tile(D
+00010160: 4b5f 7061 7261 6d65 7465 7273 2c20 2867  K_parameters, (g
+00010170: 7269 645f 7368 6170 652c 2031 2929 2e54  rid_shape, 1)).T
+00010180: 0d0a 0d0a 2020 2020 2020 2020 7265 7475  ....        retu
+00010190: 726e 2044 4b5f 7765 6967 6874 730d 0a0d  rn DK_weights...
+000101a0: 0a20 2020 2023 2065 6e64 7265 6769 6f6e  .    # endregion
+000101b0: 0d0a 0d0a 2020 2020 2320 7265 6769 6f6e  ....    # region
+000101c0: 2045 7661 6c75 6174 6520 4765 6f6c 6f67   Evaluate Geolog
+000101d0: 790d 0a20 2020 2064 6566 2063 6f6e 7472  y..    def contr
+000101e0: 6962 7574 696f 6e5f 6772 6164 6965 6e74  ibution_gradient
+000101f0: 5f69 6e74 6572 6661 6365 2873 656c 662c  _interface(self,
+00010200: 2067 7269 645f 7661 6c3d 4e6f 6e65 2c20   grid_val=None, 
+00010210: 7765 6967 6874 733d 4e6f 6e65 293a 0d0a  weights=None):..
+00010220: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
+00010230: 2020 2020 2043 6f6d 7075 7461 7469 6f6e       Computation
+00010240: 206f 6620 7468 6520 636f 6e74 7269 6275   of the contribu
+00010250: 7469 6f6e 206f 6620 7468 6520 666f 6c69  tion of the foli
+00010260: 6174 696f 6e73 2061 7420 6576 6572 7920  ations at every 
+00010270: 706f 696e 7420 746f 2069 6e74 6572 706f  point to interpo
+00010280: 6c61 7465 0d0a 0d0a 2020 2020 2020 2020  late....        
+00010290: 5265 7475 726e 733a 0d0a 2020 2020 2020  Returns:..      
+000102a0: 2020 2020 2020 6165 7361 7261 2e74 656e        aesara.ten
+000102b0: 736f 722e 7665 6374 6f72 3a20 436f 6e74  sor.vector: Cont
+000102c0: 7269 6275 7469 6f6e 206f 6620 616c 6c20  ribution of all 
+000102d0: 666f 6c69 6174 696f 6e73 2028 696e 7075  foliations (inpu
+000102e0: 7429 2061 7420 6576 6572 7920 706f 696e  t) at every poin
+000102f0: 7420 746f 2069 6e74 6572 706f 6c61 7465  t to interpolate
+00010300: 0d0a 2020 2020 2020 2020 2222 220d 0a20  ..        """.. 
+00010310: 2020 2020 2020 2069 6620 7765 6967 6874         if weight
+00010320: 7320 6973 204e 6f6e 653a 0d0a 2020 2020  s is None:..    
+00010330: 2020 2020 2020 2020 7765 6967 6874 7320          weights 
+00010340: 3d20 7365 6c66 2e65 7874 656e 645f 6475  = self.extend_du
+00010350: 616c 5f6b 7269 6769 6e67 2829 0d0a 2020  al_kriging()..  
+00010360: 2020 2020 2020 6966 2067 7269 645f 7661        if grid_va
+00010370: 6c20 6973 204e 6f6e 653a 0d0a 2020 2020  l is None:..    
+00010380: 2020 2020 2020 2020 6772 6964 5f76 616c          grid_val
+00010390: 203d 2073 656c 662e 785f 746f 5f69 6e74   = self.x_to_int
+000103a0: 6572 706f 6c61 7465 2829 0d0a 0d0a 2020  erpolate()....  
+000103b0: 2020 2020 2020 6c65 6e67 7468 5f6f 665f        length_of_
+000103c0: 4347 203d 2073 656c 662e 6d61 7472 6963  CG = self.matric
+000103d0: 6573 5f73 6861 7065 7328 295b 305d 0d0a  es_shapes()[0]..
+000103e0: 0d0a 2020 2020 2020 2020 2320 4361 7274  ..        # Cart
+000103f0: 6573 6961 6e20 6469 7374 616e 6365 7320  esian distances 
+00010400: 6265 7477 6565 6e20 7468 6520 706f 696e  between the poin
+00010410: 7420 746f 2073 696d 756c 6174 6520 616e  t to simulate an
+00010420: 6420 7468 6520 6469 7073 0d0a 2020 2020  d the dips..    
+00010430: 2020 2020 6875 5f53 696d 506f 696e 7420      hu_SimPoint 
+00010440: 3d20 542e 7665 7274 6963 616c 5f73 7461  = T.vertical_sta
+00010450: 636b 280d 0a20 2020 2020 2020 2020 2020  ck(..           
+00010460: 2028 7365 6c66 2e64 6970 735f 706f 7369   (self.dips_posi
+00010470: 7469 6f6e 5b3a 2c20 305d 202d 2067 7269  tion[:, 0] - gri
+00010480: 645f 7661 6c5b 3a2c 2030 5d2e 7265 7368  d_val[:, 0].resh
+00010490: 6170 6528 0d0a 2020 2020 2020 2020 2020  ape(..          
+000104a0: 2020 2020 2020 2867 7269 645f 7661 6c5b        (grid_val[
+000104b0: 3a2c 2030 5d2e 7368 6170 655b 305d 2c20  :, 0].shape[0], 
+000104c0: 3129 2929 2e54 2c0d 0a20 2020 2020 2020  1))).T,..       
+000104d0: 2020 2020 2028 7365 6c66 2e64 6970 735f       (self.dips_
+000104e0: 706f 7369 7469 6f6e 5b3a 2c20 315d 202d  position[:, 1] -
+000104f0: 2067 7269 645f 7661 6c5b 3a2c 2031 5d2e   grid_val[:, 1].
+00010500: 7265 7368 6170 6528 0d0a 2020 2020 2020  reshape(..      
+00010510: 2020 2020 2020 2020 2020 2867 7269 645f            (grid_
+00010520: 7661 6c5b 3a2c 2031 5d2e 7368 6170 655b  val[:, 1].shape[
+00010530: 305d 2c20 3129 2929 2e54 2c0d 0a20 2020  0], 1))).T,..   
+00010540: 2020 2020 2020 2020 2028 7365 6c66 2e64           (self.d
+00010550: 6970 735f 706f 7369 7469 6f6e 5b3a 2c20  ips_position[:, 
+00010560: 325d 202d 2067 7269 645f 7661 6c5b 3a2c  2] - grid_val[:,
+00010570: 2032 5d2e 7265 7368 6170 6528 0d0a 2020   2].reshape(..  
+00010580: 2020 2020 2020 2020 2020 2020 2020 2867                (g
+00010590: 7269 645f 7661 6c5b 3a2c 2032 5d2e 7368  rid_val[:, 2].sh
+000105a0: 6170 655b 305d 2c20 3129 2929 2e54 0d0a  ape[0], 1))).T..
+000105b0: 2020 2020 2020 2020 290d 0a0d 0a20 2020          )....   
+000105c0: 2020 2020 2023 2045 7563 6c69 6469 616e       # Euclidian
+000105d0: 2064 6973 7461 6e63 6573 0d0a 2020 2020   distances..    
+000105e0: 2020 2020 7365 645f 6469 7073 5f53 696d      sed_dips_Sim
+000105f0: 506f 696e 7420 3d20 7365 6c66 2e73 7175  Point = self.squ
+00010600: 6172 6564 5f65 7563 6c69 6465 616e 5f64  ared_euclidean_d
+00010610: 6973 7461 6e63 6573 280d 0a20 2020 2020  istances(..     
+00010620: 2020 2020 2020 2073 656c 662e 6469 7073         self.dips
+00010630: 5f70 6f73 6974 696f 6e5f 7469 6c65 642c  _position_tiled,
+00010640: 2067 7269 645f 7661 6c29 0d0a 0d0a 2020   grid_val)....  
+00010650: 2020 2020 2020 6966 2073 656c 662e 7370        if self.sp
+00010660: 6172 7365 5f76 6572 7369 6f6e 2069 7320  arse_version is 
+00010670: 5472 7565 3a0d 0a20 2020 2020 2020 2020  True:..         
+00010680: 2020 2063 6f76 5f61 7578 203d 2073 7061     cov_aux = spa
+00010690: 7273 652e 6373 725f 6672 6f6d 5f64 656e  rse.csr_from_den
+000106a0: 7365 280d 0a20 2020 2020 2020 2020 2020  se(..           
+000106b0: 2020 2020 2073 656c 662e 6769 5f72 6565       self.gi_ree
+000106c0: 7363 616c 6520 2a0d 0a20 2020 2020 2020  scale *..       
+000106d0: 2020 2020 2020 2020 2028 2d68 755f 5369           (-hu_Si
+000106e0: 6d50 6f69 6e74 202a 0d0a 2020 2020 2020  mPoint *..      
+000106f0: 2020 2020 2020 2020 2020 2028 7365 645f             (sed_
+00010700: 6469 7073 5f53 696d 506f 696e 7420 3c20  dips_SimPoint < 
+00010710: 7365 6c66 2e61 5f54 5f73 6361 6c61 7229  self.a_T_scalar)
+00010720: 202a 2020 2320 6669 7273 7420 6465 7269   *  # first deri
+00010730: 7661 7469 7665 0d0a 2020 2020 2020 2020  vative..        
+00010740: 2020 2020 2020 2020 2028 2d20 7365 6c66           (- self
+00010750: 2e63 5f6f 5f54 5f73 6361 6c61 7220 2a20  .c_o_T_scalar * 
+00010760: 2828 0d0a 2020 2020 2020 2020 2020 2020  ((..            
+00010770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010790: 2020 2020 202d 3134 202f 2073 656c 662e       -14 / self.
+000107a0: 615f 545f 7363 616c 6172 202a 2a20 3229  a_T_scalar ** 2)
+000107b0: 202b 2031 3035 202f 2034 202a 2073 6564   + 105 / 4 * sed
+000107c0: 5f64 6970 735f 5369 6d50 6f69 6e74 202f  _dips_SimPoint /
+000107d0: 2073 656c 662e 615f 545f 7363 616c 6172   self.a_T_scalar
+000107e0: 202a 2a20 3320 2d0d 0a20 2020 2020 2020   ** 3 -..       
+000107f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00010800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010820: 2020 2020 2020 2020 2020 2020 2020 202d                 -
-00010830: 3134 202f 2073 656c 662e 615f 545f 7363  14 / self.a_T_sc
-00010840: 616c 6172 202a 2a20 3229 202b 2031 3035  alar ** 2) + 105
-00010850: 202f 2034 202a 2073 6564 5f64 6970 735f   / 4 * sed_dips_
-00010860: 5369 6d50 6f69 6e74 202f 2073 656c 662e  SimPoint / self.
-00010870: 615f 545f 7363 616c 6172 202a 2a20 3320  a_T_scalar ** 3 
-00010880: 2d0d 0a20 2020 2020 2020 2020 2020 2020  -..             
-00010890: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000108a0: 2020 2020 2020 2020 2020 2020 3335 202f              35 /
-000108b0: 2032 202a 2073 6564 5f64 6970 735f 5369   2 * sed_dips_Si
-000108c0: 6d50 6f69 6e74 202a 2a20 3320 2f20 7365  mPoint ** 3 / se
-000108d0: 6c66 2e61 5f54 5f73 6361 6c61 7220 2a2a  lf.a_T_scalar **
-000108e0: 2035 202b 0d0a 2020 2020 2020 2020 2020   5 +..          
-000108f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010900: 2020 2020 2020 2020 2020 2020 2020 2032                 2
-00010910: 3120 2f20 3420 2a20 7365 645f 6469 7073  1 / 4 * sed_dips
-00010920: 5f53 696d 506f 696e 7420 2a2a 2035 202f  _SimPoint ** 5 /
-00010930: 2073 656c 662e 615f 545f 7363 616c 6172   self.a_T_scalar
-00010940: 202a 2a20 3729 2929 290d 0a0d 0a20 2020   ** 7))))....   
-00010950: 2020 2020 2020 2020 2073 6c69 6365 645f           sliced_
-00010960: 7765 6967 6874 7320 3d20 7765 6967 6874  weights = weight
-00010970: 735b 0d0a 2020 2020 2020 2020 2020 2020  s[..            
-00010980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010990: 2030 3a6c 656e 6774 685f 6f66 5f43 475d   0:length_of_CG]
-000109a0: 2020 2320 542e 7374 6163 6b28 5b77 6569    # T.stack([wei
-000109b0: 6768 7473 5b30 2c20 303a 6c65 6e67 7468  ghts[0, 0:length
-000109c0: 5f6f 665f 4347 5d5d 2923 7765 6967 6874  _of_CG]])#weight
-000109d0: 735b 303a 6c65 6e67 7468 5f6f 665f 4347  s[0:length_of_CG
-000109e0: 5d0d 0a20 2020 2020 2020 2020 2020 2073  ]..            s
-000109f0: 6967 6d61 5f30 5f67 7261 6420 3d20 7370  igma_0_grad = sp
-00010a00: 6172 7365 2e64 6f74 2873 6c69 6365 645f  arse.dot(sliced_
-00010a10: 7765 6967 6874 732c 2063 6f76 5f61 7578  weights, cov_aux
-00010a20: 290d 0a0d 0a20 2020 2020 2020 2065 6c73  )....        els
-00010a30: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00010a40: 2320 4772 6164 6965 6e74 2063 6f6e 7472  # Gradient contr
-00010a50: 6962 7574 696f 6e0d 0a20 2020 2020 2020  ibution..       
-00010a60: 2020 2020 2073 6967 6d61 5f30 5f67 7261       sigma_0_gra
-00010a70: 6420 3d20 542e 7375 6d28 0d0a 2020 2020  d = T.sum(..    
-00010a80: 2020 2020 2020 2020 2020 2020 2877 6569              (wei
-00010a90: 6768 7473 5b3a 6c65 6e67 7468 5f6f 665f  ghts[:length_of_
-00010aa0: 4347 5d20 2a0d 0a20 2020 2020 2020 2020  CG] *..         
-00010ab0: 2020 2020 2020 2020 7365 6c66 2e67 695f          self.gi_
-00010ac0: 7265 6573 6361 6c65 202a 0d0a 2020 2020  reescale *..    
-00010ad0: 2020 2020 2020 2020 2020 2020 2028 2d68               (-h
-00010ae0: 755f 5369 6d50 6f69 6e74 202a 0d0a 2020  u_SimPoint *..  
+00010810: 2020 3335 202f 2032 202a 2073 6564 5f64    35 / 2 * sed_d
+00010820: 6970 735f 5369 6d50 6f69 6e74 202a 2a20  ips_SimPoint ** 
+00010830: 3320 2f20 7365 6c66 2e61 5f54 5f73 6361  3 / self.a_T_sca
+00010840: 6c61 7220 2a2a 2035 202b 0d0a 2020 2020  lar ** 5 +..    
+00010850: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010870: 2020 2020 2032 3120 2f20 3420 2a20 7365       21 / 4 * se
+00010880: 645f 6469 7073 5f53 696d 506f 696e 7420  d_dips_SimPoint 
+00010890: 2a2a 2035 202f 2073 656c 662e 615f 545f  ** 5 / self.a_T_
+000108a0: 7363 616c 6172 202a 2a20 3729 2929 290d  scalar ** 7)))).
+000108b0: 0a0d 0a20 2020 2020 2020 2020 2020 2073  ...            s
+000108c0: 6c69 6365 645f 7765 6967 6874 7320 3d20  liced_weights = 
+000108d0: 7765 6967 6874 735b 0d0a 2020 2020 2020  weights[..      
+000108e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000108f0: 2020 2020 2020 2030 3a6c 656e 6774 685f         0:length_
+00010900: 6f66 5f43 475d 2020 2320 542e 7374 6163  of_CG]  # T.stac
+00010910: 6b28 5b77 6569 6768 7473 5b30 2c20 303a  k([weights[0, 0:
+00010920: 6c65 6e67 7468 5f6f 665f 4347 5d5d 2923  length_of_CG]])#
+00010930: 7765 6967 6874 735b 303a 6c65 6e67 7468  weights[0:length
+00010940: 5f6f 665f 4347 5d0d 0a20 2020 2020 2020  _of_CG]..       
+00010950: 2020 2020 2073 6967 6d61 5f30 5f67 7261       sigma_0_gra
+00010960: 6420 3d20 7370 6172 7365 2e64 6f74 2873  d = sparse.dot(s
+00010970: 6c69 6365 645f 7765 6967 6874 732c 2063  liced_weights, c
+00010980: 6f76 5f61 7578 290d 0a0d 0a20 2020 2020  ov_aux)....     
+00010990: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
+000109a0: 2020 2020 2020 2320 4772 6164 6965 6e74        # Gradient
+000109b0: 2063 6f6e 7472 6962 7574 696f 6e0d 0a20   contribution.. 
+000109c0: 2020 2020 2020 2020 2020 2073 6967 6d61             sigma
+000109d0: 5f30 5f67 7261 6420 3d20 542e 7375 6d28  _0_grad = T.sum(
+000109e0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000109f0: 2020 2877 6569 6768 7473 5b3a 6c65 6e67    (weights[:leng
+00010a00: 7468 5f6f 665f 4347 5d20 2a0d 0a20 2020  th_of_CG] *..   
+00010a10: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00010a20: 6c66 2e67 695f 7265 6573 6361 6c65 202a  lf.gi_reescale *
+00010a30: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00010a40: 2020 2028 2d68 755f 5369 6d50 6f69 6e74     (-hu_SimPoint
+00010a50: 202a 0d0a 2020 2020 2020 2020 2020 2020   *..            
+00010a60: 2020 2020 2020 2873 6564 5f64 6970 735f        (sed_dips_
+00010a70: 5369 6d50 6f69 6e74 203c 2073 656c 662e  SimPoint < self.
+00010a80: 615f 545f 7363 616c 6172 2920 2a20 2023  a_T_scalar) *  #
+00010a90: 2066 6972 7374 2064 6572 6976 6174 6976   first derivativ
+00010aa0: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
+00010ab0: 2020 2020 2028 2d20 7365 6c66 2e63 5f6f       (- self.c_o
+00010ac0: 5f54 5f73 6361 6c61 7220 2a20 2828 0d0a  _T_scalar * ((..
+00010ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00010af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010b00: 2873 6564 5f64 6970 735f 5369 6d50 6f69  (sed_dips_SimPoi
-00010b10: 6e74 203c 2073 656c 662e 615f 545f 7363  nt < self.a_T_sc
-00010b20: 616c 6172 2920 2a20 2023 2066 6972 7374  alar) *  # first
-00010b30: 2064 6572 6976 6174 6976 650d 0a20 2020   derivative..   
-00010b40: 2020 2020 2020 2020 2020 2020 2020 2028                 (
-00010b50: 2d20 7365 6c66 2e63 5f6f 5f54 5f73 6361  - self.c_o_T_sca
-00010b60: 6c61 7220 2a20 2828 0d0a 2020 2020 2020  lar * ((..      
+00010b00: 2020 2d31 3420 2f20 7365 6c66 2e61 5f54    -14 / self.a_T
+00010b10: 5f73 6361 6c61 7220 2a2a 2032 2920 2b20  _scalar ** 2) + 
+00010b20: 3130 3520 2f20 3420 2a20 7365 645f 6469  105 / 4 * sed_di
+00010b30: 7073 5f53 696d 506f 696e 7420 2f20 7365  ps_SimPoint / se
+00010b40: 6c66 2e61 5f54 5f73 6361 6c61 7220 2a2a  lf.a_T_scalar **
+00010b50: 2033 202d 0d0a 2020 2020 2020 2020 2020   3 -..          
+00010b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00010b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010b90: 2020 2020 2020 2020 2020 2020 2d31 3420              -14 
+00010b80: 3335 202f 2032 202a 2073 6564 5f64 6970  35 / 2 * sed_dip
+00010b90: 735f 5369 6d50 6f69 6e74 202a 2a20 3320  s_SimPoint ** 3 
 00010ba0: 2f20 7365 6c66 2e61 5f54 5f73 6361 6c61  / self.a_T_scala
-00010bb0: 7220 2a2a 2032 2920 2b20 3130 3520 2f20  r ** 2) + 105 / 
-00010bc0: 3420 2a20 7365 645f 6469 7073 5f53 696d  4 * sed_dips_Sim
-00010bd0: 506f 696e 7420 2f20 7365 6c66 2e61 5f54  Point / self.a_T
-00010be0: 5f73 6361 6c61 7220 2a2a 2033 202d 0d0a  _scalar ** 3 -..
-00010bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010c10: 2020 2020 2020 2020 2020 3335 202f 2032            35 / 2
-00010c20: 202a 2073 6564 5f64 6970 735f 5369 6d50   * sed_dips_SimP
-00010c30: 6f69 6e74 202a 2a20 3320 2f20 7365 6c66  oint ** 3 / self
-00010c40: 2e61 5f54 5f73 6361 6c61 7220 2a2a 2035  .a_T_scalar ** 5
-00010c50: 202b 0d0a 2020 2020 2020 2020 2020 2020   +..            
-00010c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010c70: 2020 2020 2020 2020 2020 2020 2020 3231                21
-00010c80: 202f 2034 202a 2073 6564 5f64 6970 735f   / 4 * sed_dips_
-00010c90: 5369 6d50 6f69 6e74 202a 2a20 3520 2f20  SimPoint ** 5 / 
-00010ca0: 7365 6c66 2e61 5f54 5f73 6361 6c61 7220  self.a_T_scalar 
-00010cb0: 2a2a 2037 2929 2929 2c0d 0a20 2020 2020  ** 7)))),..     
-00010cc0: 2020 2020 2020 2020 2020 2061 7869 733d             axis=
-00010cd0: 3029 0d0a 0d0a 2020 2020 2020 2020 2320  0)....        # 
-00010ce0: 4164 6420 6e61 6d65 2074 6f20 7468 6520  Add name to the 
-00010cf0: 7468 6561 6e6f 206e 6f64 650d 0a20 2020  theano node..   
-00010d00: 2020 2020 2073 6967 6d61 5f30 5f67 7261       sigma_0_gra
-00010d10: 642e 6e61 6d65 203d 2027 436f 6e74 7269  d.name = 'Contri
-00010d20: 6275 7469 6f6e 206f 6620 7468 6520 666f  bution of the fo
-00010d30: 6c69 6174 696f 6e73 2074 6f20 7468 6520  liations to the 
-00010d40: 706f 7465 6e74 6961 6c20 6669 656c 6420  potential field 
-00010d50: 6174 2065 7665 7279 2070 6f69 6e74 206f  at every point o
-00010d60: 6620 7468 6520 6772 6964 270d 0a0d 0a20  f the grid'.... 
-00010d70: 2020 2020 2020 2069 6620 7374 7228 7379         if str(sy
-00010d80: 732e 5f67 6574 6672 616d 6528 292e 665f  s._getframe().f_
-00010d90: 636f 6465 2e63 6f5f 6e61 6d65 2920 696e  code.co_name) in
-00010da0: 2073 656c 662e 7665 7262 6f73 653a 0d0a   self.verbose:..
-00010db0: 2020 2020 2020 2020 2020 2020 7369 676d              sigm
-00010dc0: 615f 305f 6772 6164 203d 2074 6865 616e  a_0_grad = thean
-00010dd0: 6f2e 7072 696e 7469 6e67 2e50 7269 6e74  o.printing.Print
-00010de0: 2827 696e 7465 7266 6163 655f 6772 6164  ('interface_grad
-00010df0: 6965 6e74 5f63 6f6e 7472 6962 7574 696f  ient_contributio
-00010e00: 6e27 2928 0d0a 2020 2020 2020 2020 2020  n')(..          
-00010e10: 2020 2020 2020 7369 676d 615f 305f 6772        sigma_0_gr
-00010e20: 6164 290d 0a0d 0a20 2020 2020 2020 2072  ad)....        r
-00010e30: 6574 7572 6e20 7369 676d 615f 305f 6772  eturn sigma_0_gr
-00010e40: 6164 0d0a 0d0a 2020 2020 6465 6620 636f  ad....    def co
-00010e50: 6e74 7269 6275 7469 6f6e 5f69 6e74 6572  ntribution_inter
-00010e60: 6661 6365 2873 656c 662c 2067 7269 645f  face(self, grid_
-00010e70: 7661 6c2c 2077 6569 6768 7473 3d4e 6f6e  val, weights=Non
-00010e80: 6529 3a0d 0a20 2020 2020 2020 2022 2222  e):..        """
-00010e90: 0d0a 2020 2020 2020 2020 2020 436f 6d70  ..          Comp
-00010ea0: 7574 6174 696f 6e20 6f66 2074 6865 2063  utation of the c
-00010eb0: 6f6e 7472 6962 7574 696f 6e20 6f66 2074  ontribution of t
-00010ec0: 6865 2073 7572 6661 6365 5f70 6f69 6e74  he surface_point
-00010ed0: 7320 6174 2065 7665 7279 2070 6f69 6e74  s at every point
-00010ee0: 2074 6f20 696e 7465 7270 6f6c 6174 650d   to interpolate.
-00010ef0: 0a0d 0a20 2020 2020 2020 2020 2052 6574  ...          Ret
-00010f00: 7572 6e73 3a0d 0a20 2020 2020 2020 2020  urns:..         
-00010f10: 2020 2020 2074 6865 616e 6f2e 7465 6e73       theano.tens
-00010f20: 6f72 2e76 6563 746f 723a 2043 6f6e 7472  or.vector: Contr
-00010f30: 6962 7574 696f 6e20 6f66 2061 6c6c 2073  ibution of all s
-00010f40: 7572 6661 6365 5f70 6f69 6e74 7320 2869  urface_points (i
-00010f50: 6e70 7574 2920 6174 2065 7665 7279 2070  nput) at every p
-00010f60: 6f69 6e74 2074 6f20 696e 7465 7270 6f6c  oint to interpol
-00010f70: 6174 650d 0a20 2020 2020 2020 2020 2022  ate..          "
-00010f80: 2222 0d0a 0d0a 2020 2020 2020 2020 6966  ""....        if
-00010f90: 2077 6569 6768 7473 2069 7320 4e6f 6e65   weights is None
-00010fa0: 3a0d 0a20 2020 2020 2020 2020 2020 2077  :..            w
-00010fb0: 6569 6768 7473 203d 2073 656c 662e 636f  eights = self.co
-00010fc0: 6d70 7574 655f 7765 6967 6874 7328 290d  mpute_weights().
-00010fd0: 0a0d 0a20 2020 2020 2020 206c 656e 6774  ...        lengt
-00010fe0: 685f 6f66 5f43 472c 206c 656e 6774 685f  h_of_CG, length_
-00010ff0: 6f66 5f43 4749 203d 2073 656c 662e 6d61  of_CGI = self.ma
-00011000: 7472 6963 6573 5f73 6861 7065 7328 295b  trices_shapes()[
-00011010: 3a32 5d0d 0a0d 0a20 2020 2020 2020 2023  :2]....        #
-00011020: 2045 7563 6c69 6469 616e 2064 6973 7461   Euclidian dista
-00011030: 6e63 6573 0d0a 2020 2020 2020 2020 7365  nces..        se
-00011040: 645f 7265 7374 5f53 696d 506f 696e 7420  d_rest_SimPoint 
-00011050: 3d20 7365 6c66 2e73 7175 6172 6564 5f65  = self.squared_e
-00011060: 7563 6c69 6465 616e 5f64 6973 7461 6e63  uclidean_distanc
-00011070: 6573 2873 656c 662e 7265 7374 5f6c 6179  es(self.rest_lay
-00011080: 6572 5f70 6f69 6e74 732c 0d0a 2020 2020  er_points,..    
+00010bb0: 7220 2a2a 2035 202b 0d0a 2020 2020 2020  r ** 5 +..      
+00010bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010be0: 2020 2020 3231 202f 2034 202a 2073 6564      21 / 4 * sed
+00010bf0: 5f64 6970 735f 5369 6d50 6f69 6e74 202a  _dips_SimPoint *
+00010c00: 2a20 3520 2f20 7365 6c66 2e61 5f54 5f73  * 5 / self.a_T_s
+00010c10: 6361 6c61 7220 2a2a 2037 2929 2929 2c0d  calar ** 7)))),.
+00010c20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00010c30: 2061 7869 733d 3029 0d0a 0d0a 2020 2020   axis=0)....    
+00010c40: 2020 2020 2320 4164 6420 6e61 6d65 2074      # Add name t
+00010c50: 6f20 7468 6520 6165 7361 7261 206e 6f64  o the aesara nod
+00010c60: 650d 0a20 2020 2020 2020 2073 6967 6d61  e..        sigma
+00010c70: 5f30 5f67 7261 642e 6e61 6d65 203d 2027  _0_grad.name = '
+00010c80: 436f 6e74 7269 6275 7469 6f6e 206f 6620  Contribution of 
+00010c90: 7468 6520 666f 6c69 6174 696f 6e73 2074  the foliations t
+00010ca0: 6f20 7468 6520 706f 7465 6e74 6961 6c20  o the potential 
+00010cb0: 6669 656c 6420 6174 2065 7665 7279 2070  field at every p
+00010cc0: 6f69 6e74 206f 6620 7468 6520 6772 6964  oint of the grid
+00010cd0: 270d 0a0d 0a20 2020 2020 2020 2069 6620  '....        if 
+00010ce0: 7374 7228 7379 732e 5f67 6574 6672 616d  str(sys._getfram
+00010cf0: 6528 292e 665f 636f 6465 2e63 6f5f 6e61  e().f_code.co_na
+00010d00: 6d65 2920 696e 2073 656c 662e 7665 7262  me) in self.verb
+00010d10: 6f73 653a 0d0a 2020 2020 2020 2020 2020  ose:..          
+00010d20: 2020 7369 676d 615f 305f 6772 6164 203d    sigma_0_grad =
+00010d30: 2061 6573 6172 612e 7072 696e 7469 6e67   aesara.printing
+00010d40: 2e50 7269 6e74 2827 696e 7465 7266 6163  .Print('interfac
+00010d50: 655f 6772 6164 6965 6e74 5f63 6f6e 7472  e_gradient_contr
+00010d60: 6962 7574 696f 6e27 2928 0d0a 2020 2020  ibution')(..    
+00010d70: 2020 2020 2020 2020 2020 2020 7369 676d              sigm
+00010d80: 615f 305f 6772 6164 290d 0a0d 0a20 2020  a_0_grad)....   
+00010d90: 2020 2020 2072 6574 7572 6e20 7369 676d       return sigm
+00010da0: 615f 305f 6772 6164 0d0a 0d0a 2020 2020  a_0_grad....    
+00010db0: 6465 6620 636f 6e74 7269 6275 7469 6f6e  def contribution
+00010dc0: 5f69 6e74 6572 6661 6365 2873 656c 662c  _interface(self,
+00010dd0: 2067 7269 645f 7661 6c2c 2077 6569 6768   grid_val, weigh
+00010de0: 7473 3d4e 6f6e 6529 3a0d 0a20 2020 2020  ts=None):..     
+00010df0: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
+00010e00: 2020 436f 6d70 7574 6174 696f 6e20 6f66    Computation of
+00010e10: 2074 6865 2063 6f6e 7472 6962 7574 696f   the contributio
+00010e20: 6e20 6f66 2074 6865 2073 7572 6661 6365  n of the surface
+00010e30: 5f70 6f69 6e74 7320 6174 2065 7665 7279  _points at every
+00010e40: 2070 6f69 6e74 2074 6f20 696e 7465 7270   point to interp
+00010e50: 6f6c 6174 650d 0a0d 0a20 2020 2020 2020  olate....       
+00010e60: 2020 2052 6574 7572 6e73 3a0d 0a20 2020     Returns:..   
+00010e70: 2020 2020 2020 2020 2020 2061 6573 6172             aesar
+00010e80: 612e 7465 6e73 6f72 2e76 6563 746f 723a  a.tensor.vector:
+00010e90: 2043 6f6e 7472 6962 7574 696f 6e20 6f66   Contribution of
+00010ea0: 2061 6c6c 2073 7572 6661 6365 5f70 6f69   all surface_poi
+00010eb0: 6e74 7320 2869 6e70 7574 2920 6174 2065  nts (input) at e
+00010ec0: 7665 7279 2070 6f69 6e74 2074 6f20 696e  very point to in
+00010ed0: 7465 7270 6f6c 6174 650d 0a20 2020 2020  terpolate..     
+00010ee0: 2020 2020 2022 2222 0d0a 0d0a 2020 2020       """....    
+00010ef0: 2020 2020 6966 2077 6569 6768 7473 2069      if weights i
+00010f00: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
+00010f10: 2020 2020 2077 6569 6768 7473 203d 2073       weights = s
+00010f20: 656c 662e 636f 6d70 7574 655f 7765 6967  elf.compute_weig
+00010f30: 6874 7328 290d 0a0d 0a20 2020 2020 2020  hts()....       
+00010f40: 206c 656e 6774 685f 6f66 5f43 472c 206c   length_of_CG, l
+00010f50: 656e 6774 685f 6f66 5f43 4749 203d 2073  ength_of_CGI = s
+00010f60: 656c 662e 6d61 7472 6963 6573 5f73 6861  elf.matrices_sha
+00010f70: 7065 7328 295b 3a32 5d0d 0a0d 0a20 2020  pes()[:2]....   
+00010f80: 2020 2020 2023 2045 7563 6c69 6469 616e       # Euclidian
+00010f90: 2064 6973 7461 6e63 6573 0d0a 2020 2020   distances..    
+00010fa0: 2020 2020 7365 645f 7265 7374 5f53 696d      sed_rest_Sim
+00010fb0: 506f 696e 7420 3d20 7365 6c66 2e73 7175  Point = self.squ
+00010fc0: 6172 6564 5f65 7563 6c69 6465 616e 5f64  ared_euclidean_d
+00010fd0: 6973 7461 6e63 6573 2873 656c 662e 7265  istances(self.re
+00010fe0: 7374 5f6c 6179 6572 5f70 6f69 6e74 732c  st_layer_points,
+00010ff0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00011000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011020: 2020 2020 2020 2020 2020 2020 2020 2067                 g
+00011030: 7269 645f 7661 6c29 0d0a 2020 2020 2020  rid_val)..      
+00011040: 2020 7365 645f 7265 665f 5369 6d50 6f69    sed_ref_SimPoi
+00011050: 6e74 203d 2073 656c 662e 7371 7561 7265  nt = self.square
+00011060: 645f 6575 636c 6964 6561 6e5f 6469 7374  d_euclidean_dist
+00011070: 616e 6365 7328 7365 6c66 2e72 6566 5f6c  ances(self.ref_l
+00011080: 6179 6572 5f70 6f69 6e74 732c 0d0a 2020  ayer_points,..  
 00011090: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000110a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000110b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000110c0: 2020 2020 2020 2020 2067 7269 645f 7661           grid_va
-000110d0: 6c29 0d0a 2020 2020 2020 2020 7365 645f  l)..        sed_
-000110e0: 7265 665f 5369 6d50 6f69 6e74 203d 2073  ref_SimPoint = s
-000110f0: 656c 662e 7371 7561 7265 645f 6575 636c  elf.squared_eucl
-00011100: 6964 6561 6e5f 6469 7374 616e 6365 7328  idean_distances(
-00011110: 7365 6c66 2e72 6566 5f6c 6179 6572 5f70  self.ref_layer_p
-00011120: 6f69 6e74 732c 0d0a 2020 2020 2020 2020  oints,..        
-00011130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011140: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011160: 2020 2020 6772 6964 5f76 616c 290d 0a0d      grid_val)...
-00011170: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
-00011180: 2e73 7061 7273 655f 7665 7273 696f 6e20  .sparse_version 
-00011190: 6973 2054 7275 653a 0d0a 2020 2020 2020  is True:..      
-000111a0: 2020 2020 2020 636f 765f 6175 7820 3d20        cov_aux = 
-000111b0: 7370 6172 7365 2e63 7372 5f66 726f 6d5f  sparse.csr_from_
-000111c0: 6465 6e73 6528 7365 6c66 2e63 5f6f 5f54  dense(self.c_o_T
-000111d0: 5f73 6361 6c61 7220 2a20 7365 6c66 2e69  _scalar * self.i
-000111e0: 5f72 6565 7363 616c 6520 2a20 280d 0a20  _reescale * (.. 
-000111f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011200: 2020 2028 0d0a 2020 2020 2020 2020 2020     (..          
-00011210: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011220: 2020 7365 645f 7265 7374 5f53 696d 506f    sed_rest_SimPo
-00011230: 696e 7420 3c20 7365 6c66 2e61 5f54 5f73  int < self.a_T_s
-00011240: 6361 6c61 7229 202a 2020 2320 5369 6d50  calar) *  # SimP
-00011250: 6f69 6e74 202d 2052 6573 7420 436f 7661  oint - Rest Cova
-00011260: 7269 616e 6365 7320 4d61 7472 6978 0d0a  riances Matrix..
+000110c0: 2020 2020 2020 2020 2020 6772 6964 5f76            grid_v
+000110d0: 616c 290d 0a0d 0a20 2020 2020 2020 2069  al)....        i
+000110e0: 6620 7365 6c66 2e73 7061 7273 655f 7665  f self.sparse_ve
+000110f0: 7273 696f 6e20 6973 2054 7275 653a 0d0a  rsion is True:..
+00011100: 2020 2020 2020 2020 2020 2020 636f 765f              cov_
+00011110: 6175 7820 3d20 7370 6172 7365 2e63 7372  aux = sparse.csr
+00011120: 5f66 726f 6d5f 6465 6e73 6528 7365 6c66  _from_dense(self
+00011130: 2e63 5f6f 5f54 5f73 6361 6c61 7220 2a20  .c_o_T_scalar * 
+00011140: 7365 6c66 2e69 5f72 6565 7363 616c 6520  self.i_reescale 
+00011150: 2a20 280d 0a20 2020 2020 2020 2020 2020  * (..           
+00011160: 2020 2020 2020 2020 2028 0d0a 2020 2020           (..    
+00011170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011180: 2020 2020 2020 2020 7365 645f 7265 7374          sed_rest
+00011190: 5f53 696d 506f 696e 7420 3c20 7365 6c66  _SimPoint < self
+000111a0: 2e61 5f54 5f73 6361 6c61 7229 202a 2020  .a_T_scalar) *  
+000111b0: 2320 5369 6d50 6f69 6e74 202d 2052 6573  # SimPoint - Res
+000111c0: 7420 436f 7661 7269 616e 6365 7320 4d61  t Covariances Ma
+000111d0: 7472 6978 0d0a 2020 2020 2020 2020 2020  trix..          
+000111e0: 2020 2020 2020 2020 2020 2831 202d 2037            (1 - 7
+000111f0: 202a 2028 7365 645f 7265 7374 5f53 696d   * (sed_rest_Sim
+00011200: 506f 696e 7420 2f20 7365 6c66 2e61 5f54  Point / self.a_T
+00011210: 5f73 6361 6c61 7229 202a 2a20 3220 2b0d  _scalar) ** 2 +.
+00011220: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011230: 2020 2020 2020 3335 202f 2034 202a 2028        35 / 4 * (
+00011240: 7365 645f 7265 7374 5f53 696d 506f 696e  sed_rest_SimPoin
+00011250: 7420 2f20 7365 6c66 2e61 5f54 5f73 6361  t / self.a_T_sca
+00011260: 6c61 7229 202a 2a20 3320 2d0d 0a20 2020  lar) ** 3 -..   
 00011270: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011280: 2020 2020 2831 202d 2037 202a 2028 7365      (1 - 7 * (se
-00011290: 645f 7265 7374 5f53 696d 506f 696e 7420  d_rest_SimPoint 
-000112a0: 2f20 7365 6c66 2e61 5f54 5f73 6361 6c61  / self.a_T_scala
-000112b0: 7229 202a 2a20 3220 2b0d 0a20 2020 2020  r) ** 2 +..     
-000112c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000112d0: 3335 202f 2034 202a 2028 7365 645f 7265  35 / 4 * (sed_re
-000112e0: 7374 5f53 696d 506f 696e 7420 2f20 7365  st_SimPoint / se
-000112f0: 6c66 2e61 5f54 5f73 6361 6c61 7229 202a  lf.a_T_scalar) *
-00011300: 2a20 3320 2d0d 0a20 2020 2020 2020 2020  * 3 -..         
-00011310: 2020 2020 2020 2020 2020 2020 3720 2f20              7 / 
-00011320: 3220 2a20 2873 6564 5f72 6573 745f 5369  2 * (sed_rest_Si
-00011330: 6d50 6f69 6e74 202f 2073 656c 662e 615f  mPoint / self.a_
-00011340: 545f 7363 616c 6172 2920 2a2a 2035 202b  T_scalar) ** 5 +
+00011280: 2020 3720 2f20 3220 2a20 2873 6564 5f72    7 / 2 * (sed_r
+00011290: 6573 745f 5369 6d50 6f69 6e74 202f 2073  est_SimPoint / s
+000112a0: 656c 662e 615f 545f 7363 616c 6172 2920  elf.a_T_scalar) 
+000112b0: 2a2a 2035 202b 0d0a 2020 2020 2020 2020  ** 5 +..        
+000112c0: 2020 2020 2020 2020 2020 2020 2033 202f               3 /
+000112d0: 2034 202a 2028 7365 645f 7265 7374 5f53   4 * (sed_rest_S
+000112e0: 696d 506f 696e 7420 2f20 7365 6c66 2e61  imPoint / self.a
+000112f0: 5f54 5f73 6361 6c61 7229 202a 2a20 3729  _T_scalar) ** 7)
+00011300: 202d 0d0a 2020 2020 2020 2020 2020 2020   -..            
+00011310: 2020 2020 2020 2020 2828 7365 645f 7265          ((sed_re
+00011320: 665f 5369 6d50 6f69 6e74 203c 2073 656c  f_SimPoint < sel
+00011330: 662e 615f 545f 7363 616c 6172 2920 2a20  f.a_T_scalar) * 
+00011340: 2023 2053 696d 506f 696e 742d 2052 6566   # SimPoint- Ref
 00011350: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00011360: 2020 2020 2020 2033 202f 2034 202a 2028         3 / 4 * (
-00011370: 7365 645f 7265 7374 5f53 696d 506f 696e  sed_rest_SimPoin
+00011360: 2020 2020 2020 2028 3120 2d20 3720 2a20         (1 - 7 * 
+00011370: 2873 6564 5f72 6566 5f53 696d 506f 696e  (sed_ref_SimPoin
 00011380: 7420 2f20 7365 6c66 2e61 5f54 5f73 6361  t / self.a_T_sca
-00011390: 6c61 7229 202a 2a20 3729 202d 0d0a 2020  lar) ** 7) -..  
+00011390: 6c61 7229 202a 2a20 3220 2b0d 0a20 2020  lar) ** 2 +..   
 000113a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000113b0: 2020 2828 7365 645f 7265 665f 5369 6d50    ((sed_ref_SimP
-000113c0: 6f69 6e74 203c 2073 656c 662e 615f 545f  oint < self.a_T_
-000113d0: 7363 616c 6172 2920 2a20 2023 2053 696d  scalar) *  # Sim
-000113e0: 506f 696e 742d 2052 6566 0d0a 2020 2020  Point- Ref..    
-000113f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011400: 2028 3120 2d20 3720 2a20 2873 6564 5f72   (1 - 7 * (sed_r
-00011410: 6566 5f53 696d 506f 696e 7420 2f20 7365  ef_SimPoint / se
-00011420: 6c66 2e61 5f54 5f73 6361 6c61 7229 202a  lf.a_T_scalar) *
-00011430: 2a20 3220 2b0d 0a20 2020 2020 2020 2020  * 2 +..         
-00011440: 2020 2020 2020 2020 2020 2020 2033 3520               35 
-00011450: 2f20 3420 2a20 2873 6564 5f72 6566 5f53  / 4 * (sed_ref_S
-00011460: 696d 506f 696e 7420 2f20 7365 6c66 2e61  imPoint / self.a
-00011470: 5f54 5f73 6361 6c61 7229 202a 2a20 3320  _T_scalar) ** 3 
-00011480: 2d0d 0a20 2020 2020 2020 2020 2020 2020  -..             
-00011490: 2020 2020 2020 2020 2037 202f 2032 202a           7 / 2 *
-000114a0: 2028 7365 645f 7265 665f 5369 6d50 6f69   (sed_ref_SimPoi
-000114b0: 6e74 202f 2073 656c 662e 615f 545f 7363  nt / self.a_T_sc
-000114c0: 616c 6172 2920 2a2a 2035 202b 0d0a 2020  alar) ** 5 +..  
-000114d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000114e0: 2020 2020 3320 2f20 3420 2a20 2873 6564      3 / 4 * (sed
-000114f0: 5f72 6566 5f53 696d 506f 696e 7420 2f20  _ref_SimPoint / 
-00011500: 7365 6c66 2e61 5f54 5f73 6361 6c61 7229  self.a_T_scalar)
-00011510: 202a 2a20 3729 2929 290d 0a0d 0a20 2020   ** 7))))....   
-00011520: 2020 2020 2020 2020 2077 6569 6768 7473           weights
-00011530: 5f73 6c69 6365 6420 3d20 2d77 6569 6768  _sliced = -weigh
-00011540: 7473 5b6c 656e 6774 685f 6f66 5f43 473a  ts[length_of_CG:
-00011550: 6c65 6e67 7468 5f6f 665f 4347 202b 206c  length_of_CG + l
-00011560: 656e 6774 685f 6f66 5f43 4749 5d0d 0a0d  ength_of_CGI]...
-00011570: 0a20 2020 2020 2020 2020 2020 2073 6967  .            sig
-00011580: 6d61 5f30 5f69 6e74 6572 6620 3d20 7370  ma_0_interf = sp
-00011590: 6172 7365 2e64 6f74 2877 6569 6768 7473  arse.dot(weights
-000115a0: 5f73 6c69 6365 642c 2063 6f76 5f61 7578  _sliced, cov_aux
-000115b0: 290d 0a0d 0a20 2020 2020 2020 2065 6c73  )....        els
-000115c0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-000115d0: 2320 496e 7465 7266 6163 6520 636f 6e74  # Interface cont
-000115e0: 7269 6275 7469 6f6e 0d0a 2020 2020 2020  ribution..      
-000115f0: 2020 2020 2020 7369 676d 615f 305f 696e        sigma_0_in
-00011600: 7465 7266 203d 2028 542e 7375 6d28 0d0a  terf = (T.sum(..
-00011610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011620: 2d77 6569 6768 7473 5b6c 656e 6774 685f  -weights[length_
-00011630: 6f66 5f43 473a 6c65 6e67 7468 5f6f 665f  of_CG:length_of_
-00011640: 4347 202b 206c 656e 6774 685f 6f66 5f43  CG + length_of_C
-00011650: 4749 2c20 3a5d 202a 0d0a 2020 2020 2020  GI, :] *..      
-00011660: 2020 2020 2020 2020 2020 2873 656c 662e            (self.
-00011670: 635f 6f5f 545f 7363 616c 6172 202a 2073  c_o_T_scalar * s
-00011680: 656c 662e 695f 7265 6573 6361 6c65 202a  elf.i_reescale *
-00011690: 2028 0d0a 2020 2020 2020 2020 2020 2020   (..            
-000116a0: 2020 2020 2020 2020 2020 2020 280d 0a20              (.. 
-000116b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000116c0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-000116d0: 6564 5f72 6573 745f 5369 6d50 6f69 6e74  ed_rest_SimPoint
-000116e0: 203c 2073 656c 662e 615f 545f 7363 616c   < self.a_T_scal
-000116f0: 6172 2920 2a20 2023 2053 696d 506f 696e  ar) *  # SimPoin
-00011700: 7420 2d20 5265 7374 2043 6f76 6172 6961  t - Rest Covaria
-00011710: 6e63 6573 204d 6174 7269 780d 0a20 2020  nces Matrix..   
-00011720: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011730: 2020 2020 2028 3120 2d20 3720 2a20 2873       (1 - 7 * (s
-00011740: 6564 5f72 6573 745f 5369 6d50 6f69 6e74  ed_rest_SimPoint
-00011750: 202f 2073 656c 662e 615f 545f 7363 616c   / self.a_T_scal
-00011760: 6172 2920 2a2a 2032 202b 0d0a 2020 2020  ar) ** 2 +..    
-00011770: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011780: 2020 2020 2033 3520 2f20 3420 2a20 2873       35 / 4 * (s
-00011790: 6564 5f72 6573 745f 5369 6d50 6f69 6e74  ed_rest_SimPoint
-000117a0: 202f 2073 656c 662e 615f 545f 7363 616c   / self.a_T_scal
-000117b0: 6172 2920 2a2a 2033 202d 0d0a 2020 2020  ar) ** 3 -..    
-000117c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000117d0: 2020 2020 2037 202f 2032 202a 2028 7365       7 / 2 * (se
-000117e0: 645f 7265 7374 5f53 696d 506f 696e 7420  d_rest_SimPoint 
-000117f0: 2f20 7365 6c66 2e61 5f54 5f73 6361 6c61  / self.a_T_scala
-00011800: 7229 202a 2a20 3520 2b0d 0a20 2020 2020  r) ** 5 +..     
-00011810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011820: 2020 2020 3320 2f20 3420 2a20 2873 6564      3 / 4 * (sed
-00011830: 5f72 6573 745f 5369 6d50 6f69 6e74 202f  _rest_SimPoint /
-00011840: 2073 656c 662e 615f 545f 7363 616c 6172   self.a_T_scalar
-00011850: 2920 2a2a 2037 2920 2d0d 0a20 2020 2020  ) ** 7) -..     
-00011860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011870: 2020 2028 2873 6564 5f72 6566 5f53 696d     ((sed_ref_Sim
-00011880: 506f 696e 7420 3c20 7365 6c66 2e61 5f54  Point < self.a_T
-00011890: 5f73 6361 6c61 7229 202a 2020 2320 5369  _scalar) *  # Si
-000118a0: 6d50 6f69 6e74 2d20 5265 660d 0a20 2020  mPoint- Ref..   
-000118b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000118c0: 2020 2020 2020 2831 202d 2037 202a 2028        (1 - 7 * (
-000118d0: 7365 645f 7265 665f 5369 6d50 6f69 6e74  sed_ref_SimPoint
-000118e0: 202f 2073 656c 662e 615f 545f 7363 616c   / self.a_T_scal
-000118f0: 6172 2920 2a2a 2032 202b 0d0a 2020 2020  ar) ** 2 +..    
-00011900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011910: 2020 2020 2020 3335 202f 2034 202a 2028        35 / 4 * (
-00011920: 7365 645f 7265 665f 5369 6d50 6f69 6e74  sed_ref_SimPoint
-00011930: 202f 2073 656c 662e 615f 545f 7363 616c   / self.a_T_scal
-00011940: 6172 2920 2a2a 2033 202d 0d0a 2020 2020  ar) ** 3 -..    
-00011950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011960: 2020 2020 2020 3720 2f20 3220 2a20 2873        7 / 2 * (s
-00011970: 6564 5f72 6566 5f53 696d 506f 696e 7420  ed_ref_SimPoint 
-00011980: 2f20 7365 6c66 2e61 5f54 5f73 6361 6c61  / self.a_T_scala
-00011990: 7229 202a 2a20 3520 2b0d 0a20 2020 2020  r) ** 5 +..     
-000119a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000119b0: 2020 2020 2033 202f 2034 202a 2028 7365       3 / 4 * (se
-000119c0: 645f 7265 665f 5369 6d50 6f69 6e74 202f  d_ref_SimPoint /
-000119d0: 2073 656c 662e 615f 545f 7363 616c 6172   self.a_T_scalar
-000119e0: 2920 2a2a 2037 2929 2929 2c0d 0a20 2020  ) ** 7)))),..   
-000119f0: 2020 2020 2020 2020 2020 2020 2061 7869               axi
-00011a00: 733d 3029 290d 0a20 2020 2020 2020 2023  s=0))..        #
-00011a10: 2041 6464 206e 616d 6520 746f 2074 6865   Add name to the
-00011a20: 2074 6865 616e 6f20 6e6f 6465 0d0a 2020   theano node..  
-00011a30: 2020 2020 2020 7369 676d 615f 305f 696e        sigma_0_in
-00011a40: 7465 7266 2e6e 616d 6520 3d20 2743 6f6e  terf.name = 'Con
-00011a50: 7472 6962 7574 696f 6e20 6f66 2074 6865  tribution of the
-00011a60: 2073 7572 6661 6365 5f70 6f69 6e74 7320   surface_points 
-00011a70: 746f 2074 6865 2070 6f74 656e 7469 616c  to the potential
-00011a80: 2066 6965 6c64 2061 7420 6576 6572 7920   field at every 
-00011a90: 706f 696e 7420 6f66 2074 6865 2067 7269  point of the gri
-00011aa0: 6427 0d0a 0d0a 2020 2020 2020 2020 6966  d'....        if
-00011ab0: 2073 7472 2873 7973 2e5f 6765 7466 7261   str(sys._getfra
-00011ac0: 6d65 2829 2e66 5f63 6f64 652e 636f 5f6e  me().f_code.co_n
-00011ad0: 616d 6529 2069 6e20 7365 6c66 2e76 6572  ame) in self.ver
-00011ae0: 626f 7365 3a0d 0a20 2020 2020 2020 2020  bose:..         
-00011af0: 2020 2073 6967 6d61 5f30 5f69 6e74 6572     sigma_0_inter
-00011b00: 6620 3d20 7468 6561 6e6f 2e70 7269 6e74  f = theano.print
-00011b10: 696e 672e 5072 696e 7428 2769 6e74 6572  ing.Print('inter
-00011b20: 6661 6365 5f63 6f6e 7472 6962 7574 696f  face_contributio
-00011b30: 6e27 2928 0d0a 2020 2020 2020 2020 2020  n')(..          
-00011b40: 2020 2020 2020 7369 676d 615f 305f 696e        sigma_0_in
-00011b50: 7465 7266 290d 0a0d 0a20 2020 2020 2020  terf)....       
-00011b60: 2072 6574 7572 6e20 7369 676d 615f 305f   return sigma_0_
-00011b70: 696e 7465 7266 0d0a 0d0a 2020 2020 6465  interf....    de
-00011b80: 6620 636f 6e74 7269 6275 7469 6f6e 5f75  f contribution_u
-00011b90: 6e69 7665 7273 616c 5f64 7269 6674 2873  niversal_drift(s
-00011ba0: 656c 662c 2067 7269 645f 7661 6c2c 2077  elf, grid_val, w
-00011bb0: 6569 6768 7473 3d4e 6f6e 6529 3a0d 0a20  eights=None):.. 
-00011bc0: 2020 2020 2020 2022 2222 0d0a 2020 2020         """..    
-00011bd0: 2020 2020 436f 6d70 7574 6174 696f 6e20      Computation 
-00011be0: 6f66 2074 6865 2063 6f6e 7472 6962 7574  of the contribut
-00011bf0: 696f 6e20 6f66 2074 6865 2075 6e69 7665  ion of the unive
-00011c00: 7273 616c 2064 7269 6674 2061 7420 6576  rsal drift at ev
-00011c10: 6572 7920 706f 696e 7420 746f 2069 6e74  ery point to int
-00011c20: 6572 706f 6c61 7465 0d0a 0d0a 2020 2020  erpolate....    
-00011c30: 2020 2020 5265 7475 726e 733a 0d0a 2020      Returns:..  
-00011c40: 2020 2020 2020 2020 2020 7468 6561 6e6f            theano
-00011c50: 2e74 656e 736f 722e 7665 6374 6f72 3a20  .tensor.vector: 
-00011c60: 436f 6e74 7269 6275 7469 6f6e 206f 6620  Contribution of 
-00011c70: 7468 6520 756e 6976 6572 7361 6c20 6472  the universal dr
-00011c80: 6966 7420 2869 6e70 7574 2920 6174 2065  ift (input) at e
-00011c90: 7665 7279 2070 6f69 6e74 2074 6f20 696e  very point to in
-00011ca0: 7465 7270 6f6c 6174 650d 0a20 2020 2020  terpolate..     
-00011cb0: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-00011cc0: 6966 2077 6569 6768 7473 2069 7320 4e6f  if weights is No
-00011cd0: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
-00011ce0: 2077 6569 6768 7473 203d 2073 656c 662e   weights = self.
-00011cf0: 636f 6d70 7574 655f 7765 6967 6874 7328  compute_weights(
-00011d00: 290d 0a0d 0a20 2020 2020 2020 206c 656e  )....        len
-00011d10: 6774 685f 6f66 5f43 472c 206c 656e 6774  gth_of_CG, lengt
-00011d20: 685f 6f66 5f43 4749 2c20 6c65 6e67 7468  h_of_CGI, length
-00011d30: 5f6f 665f 555f 492c 206c 656e 6774 685f  _of_U_I, length_
-00011d40: 6f66 5f66 6175 6c74 732c 206c 656e 6774  of_faults, lengt
-00011d50: 685f 6f66 5f43 203d 2073 656c 662e 6d61  h_of_C = self.ma
-00011d60: 7472 6963 6573 5f73 6861 7065 7328 290d  trices_shapes().
-00011d70: 0a0d 0a20 2020 2020 2020 2075 6e69 7665  ...        unive
-00011d80: 7273 616c 5f67 7269 645f 7375 7266 6163  rsal_grid_surfac
-00011d90: 655f 706f 696e 7473 5f6d 6174 7269 7820  e_points_matrix 
-00011da0: 3d20 542e 686f 7269 7a6f 6e74 616c 5f73  = T.horizontal_s
-00011db0: 7461 636b 280d 0a20 2020 2020 2020 2020  tack(..         
-00011dc0: 2020 2067 7269 645f 7661 6c2c 0d0a 2020     grid_val,..  
-00011dd0: 2020 2020 2020 2020 2020 2867 7269 645f            (grid_
-00011de0: 7661 6c20 2a2a 2032 292c 0d0a 2020 2020  val ** 2),..    
-00011df0: 2020 2020 2020 2020 542e 7374 6163 6b28          T.stack(
-00011e00: 2867 7269 645f 7661 6c5b 3a2c 2030 5d20  (grid_val[:, 0] 
-00011e10: 2a20 6772 6964 5f76 616c 5b3a 2c20 315d  * grid_val[:, 1]
-00011e20: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00011e30: 2020 2020 2020 2020 6772 6964 5f76 616c          grid_val
-00011e40: 5b3a 2c20 305d 202a 2067 7269 645f 7661  [:, 0] * grid_va
-00011e50: 6c5b 3a2c 2032 5d2c 0d0a 2020 2020 2020  l[:, 2],..      
-00011e60: 2020 2020 2020 2020 2020 2020 2020 2067                 g
-00011e70: 7269 645f 7661 6c5b 3a2c 2031 5d20 2a20  rid_val[:, 1] * 
-00011e80: 6772 6964 5f76 616c 5b3a 2c20 325d 292c  grid_val[:, 2]),
-00011e90: 2061 7869 733d 3129 292e 540d 0a0d 0a20   axis=1)).T.... 
-00011ea0: 2020 2020 2020 2069 5f72 6573 6361 6c65         i_rescale
-00011eb0: 5f61 7578 203d 2054 2e74 696c 6528 7365  _aux = T.tile(se
-00011ec0: 6c66 2e67 695f 7265 6573 6361 6c65 2c20  lf.gi_reescale, 
-00011ed0: 3929 0d0a 2020 2020 2020 2020 695f 7265  9)..        i_re
-00011ee0: 7363 616c 655f 6175 7820 3d20 542e 7365  scale_aux = T.se
-00011ef0: 745f 7375 6274 656e 736f 7228 695f 7265  t_subtensor(i_re
-00011f00: 7363 616c 655f 6175 785b 3a33 5d2c 2031  scale_aux[:3], 1
-00011f10: 290d 0a20 2020 2020 2020 205f 6175 785f  )..        _aux_
-00011f20: 6d61 6769 635f 7465 726d 203d 2054 2e74  magic_term = T.t
-00011f30: 696c 6528 695f 7265 7363 616c 655f 6175  ile(i_rescale_au
-00011f40: 785b 3a73 656c 662e 6e5f 756e 6976 6572  x[:self.n_univer
-00011f50: 7361 6c5f 6571 5f54 5f6f 705d 2c0d 0a20  sal_eq_T_op],.. 
-00011f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011f80: 2867 7269 645f 7661 6c2e 7368 6170 655b  (grid_val.shape[
-00011f90: 305d 2c20 3129 292e 540d 0a0d 0a20 2020  0], 1)).T....   
-00011fa0: 2020 2020 2069 6620 7365 6c66 2e73 7061       if self.spa
-00011fb0: 7273 655f 7665 7273 696f 6e20 6973 2054  rse_version is T
-00011fc0: 7275 653a 2020 2320 7365 6c66 2e64 6f74  rue:  # self.dot
-00011fd0: 5f76 6572 7369 6f6e 3a0d 0a20 2020 2020  _version:..     
-00011fe0: 2020 2020 2020 2066 5f30 203d 2054 2e64         f_0 = T.d
-00011ff0: 6f74 280d 0a20 2020 2020 2020 2020 2020  ot(..           
-00012000: 2020 2020 2077 6569 6768 7473 5b0d 0a20       weights[.. 
-00012010: 2020 2020 2020 2020 2020 2020 2020 206c                 l
-00012020: 656e 6774 685f 6f66 5f43 4720 2b20 6c65  ength_of_CG + le
-00012030: 6e67 7468 5f6f 665f 4347 493a 6c65 6e67  ngth_of_CGI:leng
-00012040: 7468 5f6f 665f 4347 202b 206c 656e 6774  th_of_CG + lengt
-00012050: 685f 6f66 5f43 4749 202b 206c 656e 6774  h_of_CGI + lengt
-00012060: 685f 6f66 5f55 5f49 5d2c 0d0a 2020 2020  h_of_U_I],..    
-00012070: 2020 2020 2020 2020 2020 2020 2873 656c              (sel
-00012080: 662e 6769 5f72 6565 7363 616c 6520 2a20  f.gi_reescale * 
-00012090: 5f61 7578 5f6d 6167 6963 5f74 6572 6d20  _aux_magic_term 
-000120a0: 2a0d 0a20 2020 2020 2020 2020 2020 2020  *..             
-000120b0: 2020 2020 756e 6976 6572 7361 6c5f 6772      universal_gr
-000120c0: 6964 5f73 7572 6661 6365 5f70 6f69 6e74  id_surface_point
-000120d0: 735f 6d61 7472 6978 5b3a 7365 6c66 2e6e  s_matrix[:self.n
-000120e0: 5f75 6e69 7665 7273 616c 5f65 715f 545f  _universal_eq_T_
-000120f0: 6f70 5d29 290d 0a20 2020 2020 2020 2065  op]))..        e
-00012100: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
-00012110: 2020 756e 6976 6572 7361 6c5f 6b65 726e    universal_kern
-00012120: 656c 203d 2073 656c 662e 6769 5f72 6565  el = self.gi_ree
-00012130: 7363 616c 6520 2a20 5f61 7578 5f6d 6167  scale * _aux_mag
-00012140: 6963 5f74 6572 6d20 2a20 5c0d 0a20 2020  ic_term * \..   
-00012150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012160: 2020 2020 2020 2020 2020 2020 756e 6976              univ
-00012170: 6572 7361 6c5f 6772 6964 5f73 7572 6661  ersal_grid_surfa
-00012180: 6365 5f70 6f69 6e74 735f 6d61 7472 6978  ce_points_matrix
-00012190: 5b3a 7365 6c66 2e6e 5f75 6e69 7665 7273  [:self.n_univers
-000121a0: 616c 5f65 715f 545f 6f70 5d0d 0a0d 0a0d  al_eq_T_op].....
-000121b0: 0a20 2020 2020 2020 2020 2020 2023 2044  .            # D
-000121c0: 7269 6674 2063 6f6e 7472 6962 7574 696f  rift contributio
-000121d0: 6e0d 0a20 2020 2020 2020 2020 2020 2066  n..            f
-000121e0: 5f30 203d 2028 542e 7375 6d28 0d0a 2020  _0 = (T.sum(..  
-000121f0: 2020 2020 2020 2020 2020 2020 2020 7765                we
-00012200: 6967 6874 735b 6c65 6e67 7468 5f6f 665f  ights[length_of_
-00012210: 4347 202b 206c 656e 6774 685f 6f66 5f43  CG + length_of_C
-00012220: 4749 3a6c 656e 6774 685f 6f66 5f43 4720  GI:length_of_CG 
-00012230: 2b20 6c65 6e67 7468 5f6f 665f 4347 4920  + length_of_CGI 
-00012240: 2b20 6c65 6e67 7468 5f6f 665f 555f 495d  + length_of_U_I]
-00012250: 202a 0d0a 2020 2020 2020 2020 2020 2020   *..            
-00012260: 2020 2020 756e 6976 6572 7361 6c5f 6b65      universal_ke
-00012270: 726e 656c 0d0a 2020 2020 2020 2020 2020  rnel..          
-00012280: 2020 2020 2020 2c20 6178 6973 3d30 2929        , axis=0))
-00012290: 0d0a 0d0a 2020 2020 2020 2020 6966 206e  ....        if n
-000122a0: 6f74 2074 7970 6528 665f 3029 203d 3d20  ot type(f_0) == 
-000122b0: 696e 743a 0d0a 2020 2020 2020 2020 2020  int:..          
-000122c0: 2020 665f 302e 6e61 6d65 203d 2027 436f    f_0.name = 'Co
-000122d0: 6e74 7269 6275 7469 6f6e 206f 6620 7468  ntribution of th
-000122e0: 6520 756e 6976 6572 7361 6c20 6472 6966  e universal drif
-000122f0: 7420 746f 2074 6865 2070 6f74 656e 7469  t to the potenti
-00012300: 616c 2066 6965 6c64 2061 7420 6576 6572  al field at ever
-00012310: 7920 706f 696e 7420 6f66 2074 6865 2067  y point of the g
-00012320: 7269 6427 0d0a 0d0a 2020 2020 2020 2020  rid'....        
-00012330: 6966 2073 7472 2873 7973 2e5f 6765 7466  if str(sys._getf
-00012340: 7261 6d65 2829 2e66 5f63 6f64 652e 636f  rame().f_code.co
-00012350: 5f6e 616d 6529 2069 6e20 7365 6c66 2e76  _name) in self.v
-00012360: 6572 626f 7365 3a0d 0a20 2020 2020 2020  erbose:..       
-00012370: 2020 2020 2066 5f30 203d 2074 6865 616e       f_0 = thean
-00012380: 6f2e 7072 696e 7469 6e67 2e50 7269 6e74  o.printing.Print
-00012390: 2827 556e 6976 6572 7361 6c20 7465 726d  ('Universal term
-000123a0: 7320 636f 6e74 7269 6275 7469 6f6e 2729  s contribution')
-000123b0: 2866 5f30 290d 0a0d 0a20 2020 2020 2020  (f_0)....       
-000123c0: 2072 6574 7572 6e20 665f 300d 0a0d 0a20   return f_0.... 
-000123d0: 2020 2064 6566 2063 6f6e 7472 6962 7574     def contribut
-000123e0: 696f 6e5f 6661 756c 7473 2873 656c 662c  ion_faults(self,
-000123f0: 2077 6569 6768 7473 3d4e 6f6e 652c 2061   weights=None, a
-00012400: 3d30 2c20 623d 3130 3030 3030 3030 302c  =0, b=100000000,
-00012410: 2066 5f6d 3d4e 6f6e 6529 3a0d 0a20 2020   f_m=None):..   
-00012420: 2020 2020 2022 2222 0d0a 2020 2020 2020       """..      
-00012430: 2020 436f 6d70 7574 6174 696f 6e20 6f66    Computation of
-00012440: 2074 6865 2063 6f6e 7472 6962 7574 696f   the contributio
-00012450: 6e20 6f66 2074 6865 2064 6620 6472 6966  n of the df drif
-00012460: 7420 6174 2065 7665 7279 2070 6f69 6e74  t at every point
-00012470: 2074 6f20 696e 7465 7270 6f6c 6174 652e   to interpolate.
-00012480: 2054 6f20 6765 7420 7468 6573 6520 7765   To get these we
-00012490: 206e 6565 6420 746f 0d0a 2020 2020 2020   need to..      
-000124a0: 2020 636f 6d70 7574 6520 6120 7768 6f6c    compute a whol
-000124b0: 6520 626c 6f63 6b20 6d6f 6465 6c20 7769  e block model wi
-000124c0: 7468 2074 6865 2064 6620 6461 7461 0d0a  th the df data..
-000124d0: 0d0a 2020 2020 2020 2020 5265 7475 726e  ..        Return
-000124e0: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
-000124f0: 7468 6561 6e6f 2e74 656e 736f 722e 7665  theano.tensor.ve
-00012500: 6374 6f72 3a20 436f 6e74 7269 6275 7469  ctor: Contributi
-00012510: 6f6e 206f 6620 7468 6520 6466 2064 7269  on of the df dri
-00012520: 6674 2028 696e 7075 7429 2061 7420 6576  ft (input) at ev
-00012530: 6572 7920 706f 696e 7420 746f 2069 6e74  ery point to int
-00012540: 6572 706f 6c61 7465 0d0a 2020 2020 2020  erpolate..      
-00012550: 2020 2222 220d 0a20 2020 2020 2020 2069    """..        i
-00012560: 6620 7765 6967 6874 7320 6973 204e 6f6e  f weights is Non
-00012570: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00012580: 7765 6967 6874 7320 3d20 7365 6c66 2e63  weights = self.c
-00012590: 6f6d 7075 7465 5f77 6569 6768 7473 2829  ompute_weights()
-000125a0: 0d0a 2020 2020 2020 2020 6c65 6e67 7468  ..        length
-000125b0: 5f6f 665f 4347 2c20 6c65 6e67 7468 5f6f  _of_CG, length_o
-000125c0: 665f 4347 492c 206c 656e 6774 685f 6f66  f_CGI, length_of
-000125d0: 5f55 5f49 2c20 6c65 6e67 7468 5f6f 665f  _U_I, length_of_
-000125e0: 6661 756c 7473 2c20 6c65 6e67 7468 5f6f  faults, length_o
-000125f0: 665f 4320 3d20 7365 6c66 2e6d 6174 7269  f_C = self.matri
-00012600: 6365 735f 7368 6170 6573 2829 0d0a 0d0a  ces_shapes()....
-00012610: 2020 2020 2020 2020 6661 756c 745f 6d61          fault_ma
-00012620: 7472 6978 5f73 656c 6563 7469 6f6e 5f6e  trix_selection_n
-00012630: 6f6e 5f7a 6572 6f20 3d20 665f 6d5b 3a2c  on_zero = f_m[:,
-00012640: 2061 3a62 5d0d 0a0d 0a20 2020 2020 2020   a:b]....       
-00012650: 2069 6620 7365 6c66 2e73 7061 7273 655f   if self.sparse_
-00012660: 7665 7273 696f 6e20 6973 2054 7275 653a  version is True:
-00012670: 2020 2320 7365 6c66 2e64 6f74 5f76 6572    # self.dot_ver
-00012680: 7369 6f6e 3a0d 0a20 2020 2020 2020 2020  sion:..         
-00012690: 2020 2066 5f31 203d 2054 2e64 6f74 280d     f_1 = T.dot(.
-000126a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000126b0: 2077 6569 6768 7473 5b6c 656e 6774 685f   weights[length_
-000126c0: 6f66 5f43 4720 2b20 6c65 6e67 7468 5f6f  of_CG + length_o
-000126d0: 665f 4347 4920 2b20 6c65 6e67 7468 5f6f  f_CGI + length_o
-000126e0: 665f 555f 493a 5d2c 2028 0d0a 2020 2020  f_U_I:], (..    
-000126f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012700: 6661 756c 745f 6d61 7472 6978 5f73 656c  fault_matrix_sel
-00012710: 6563 7469 6f6e 5f6e 6f6e 5f7a 6572 6f29  ection_non_zero)
-00012720: 290d 0a20 2020 2020 2020 2065 6c73 653a  )..        else:
-00012730: 0d0a 2020 2020 2020 2020 2020 2020 665f  ..            f_
-00012740: 3120 3d20 542e 7375 6d28 0d0a 2020 2020  1 = T.sum(..    
-00012750: 2020 2020 2020 2020 2020 2020 7765 6967              weig
-00012760: 6874 735b 6c65 6e67 7468 5f6f 665f 4347  hts[length_of_CG
-00012770: 202b 206c 656e 6774 685f 6f66 5f43 4749   + length_of_CGI
-00012780: 202b 206c 656e 6774 685f 6f66 5f55 5f49   + length_of_U_I
-00012790: 3a2c 0d0a 2020 2020 2020 2020 2020 2020  :,..            
-000127a0: 2020 2020 3a5d 202a 2066 6175 6c74 5f6d      :] * fault_m
-000127b0: 6174 7269 785f 7365 6c65 6374 696f 6e5f  atrix_selection_
-000127c0: 6e6f 6e5f 7a65 726f 2c20 6178 6973 3d30  non_zero, axis=0
-000127d0: 290d 0a0d 0a20 2020 2020 2020 2023 2041  )....        # A
-000127e0: 6464 206e 616d 6520 746f 2074 6865 2074  dd name to the t
-000127f0: 6865 616e 6f20 6e6f 6465 0d0a 2020 2020  heano node..    
-00012800: 2020 2020 665f 312e 6e61 6d65 203d 2027      f_1.name = '
-00012810: 4661 756c 7473 2063 6f6e 7472 6962 7574  Faults contribut
-00012820: 696f 6e27 0d0a 0d0a 2020 2020 2020 2020  ion'....        
-00012830: 6966 2073 7472 2873 7973 2e5f 6765 7466  if str(sys._getf
-00012840: 7261 6d65 2829 2e66 5f63 6f64 652e 636f  rame().f_code.co
-00012850: 5f6e 616d 6529 2069 6e20 7365 6c66 2e76  _name) in self.v
-00012860: 6572 626f 7365 3a0d 0a20 2020 2020 2020  erbose:..       
-00012870: 2020 2020 2066 5f31 203d 2074 6865 616e       f_1 = thean
-00012880: 6f2e 7072 696e 7469 6e67 2e50 7269 6e74  o.printing.Print
-00012890: 2827 4661 756c 7473 2063 6f6e 7472 6962  ('Faults contrib
-000128a0: 7574 696f 6e27 2928 665f 3129 0d0a 0d0a  ution')(f_1)....
-000128b0: 2020 2020 2020 2020 7265 7475 726e 2066          return f
-000128c0: 5f31 0d0a 0d0a 2020 2020 6465 6620 7363  _1....    def sc
-000128d0: 616c 6172 5f66 6965 6c64 5f6c 6f6f 7028  alar_field_loop(
-000128e0: 7365 6c66 2c20 612c 2062 2c20 5a5f 782c  self, a, b, Z_x,
-000128f0: 2067 7269 645f 7661 6c2c 2077 6569 6768   grid_val, weigh
-00012900: 7473 2c20 6661 756c 745f 6d61 7472 6978  ts, fault_matrix
-00012910: 293a 0d0a 0d0a 2020 2020 2020 2020 6966  ):....        if
-00012920: 2073 656c 662e 7370 6172 7365 5f76 6572   self.sparse_ver
-00012930: 7369 6f6e 2069 7320 5472 7565 3a0d 0a20  sion is True:.. 
-00012940: 2020 2020 2020 2020 2020 2072 616e 6720             rang 
-00012950: 3d20 350d 0a20 2020 2020 2020 2020 2020  = 5..           
-00012960: 2074 696c 6564 5f77 6569 6768 7473 203d   tiled_weights =
-00012970: 2073 656c 662e 6578 7465 6e64 5f64 7561   self.extend_dua
-00012980: 6c5f 6b72 6967 696e 6728 7765 6967 6874  l_kriging(weight
-00012990: 732c 2072 616e 6729 0d0a 2020 2020 2020  s, rang)..      
-000129a0: 2020 2020 2020 7369 676d 615f 305f 6772        sigma_0_gr
-000129b0: 6164 203d 2073 656c 662e 636f 6e74 7269  ad = self.contri
-000129c0: 6275 7469 6f6e 5f67 7261 6469 656e 745f  bution_gradient_
-000129d0: 696e 7465 7266 6163 6528 6772 6964 5f76  interface(grid_v
-000129e0: 616c 5b61 3a62 5d2c 0d0a 2020 2020 2020  al[a:b],..      
+000113b0: 2020 2033 3520 2f20 3420 2a20 2873 6564     35 / 4 * (sed
+000113c0: 5f72 6566 5f53 696d 506f 696e 7420 2f20  _ref_SimPoint / 
+000113d0: 7365 6c66 2e61 5f54 5f73 6361 6c61 7229  self.a_T_scalar)
+000113e0: 202a 2a20 3320 2d0d 0a20 2020 2020 2020   ** 3 -..       
+000113f0: 2020 2020 2020 2020 2020 2020 2020 2037                 7
+00011400: 202f 2032 202a 2028 7365 645f 7265 665f   / 2 * (sed_ref_
+00011410: 5369 6d50 6f69 6e74 202f 2073 656c 662e  SimPoint / self.
+00011420: 615f 545f 7363 616c 6172 2920 2a2a 2035  a_T_scalar) ** 5
+00011430: 202b 0d0a 2020 2020 2020 2020 2020 2020   +..            
+00011440: 2020 2020 2020 2020 2020 3320 2f20 3420            3 / 4 
+00011450: 2a20 2873 6564 5f72 6566 5f53 696d 506f  * (sed_ref_SimPo
+00011460: 696e 7420 2f20 7365 6c66 2e61 5f54 5f73  int / self.a_T_s
+00011470: 6361 6c61 7229 202a 2a20 3729 2929 290d  calar) ** 7)))).
+00011480: 0a0d 0a20 2020 2020 2020 2020 2020 2077  ...            w
+00011490: 6569 6768 7473 5f73 6c69 6365 6420 3d20  eights_sliced = 
+000114a0: 2d77 6569 6768 7473 5b6c 656e 6774 685f  -weights[length_
+000114b0: 6f66 5f43 473a 6c65 6e67 7468 5f6f 665f  of_CG:length_of_
+000114c0: 4347 202b 206c 656e 6774 685f 6f66 5f43  CG + length_of_C
+000114d0: 4749 5d0d 0a0d 0a20 2020 2020 2020 2020  GI]....         
+000114e0: 2020 2073 6967 6d61 5f30 5f69 6e74 6572     sigma_0_inter
+000114f0: 6620 3d20 7370 6172 7365 2e64 6f74 2877  f = sparse.dot(w
+00011500: 6569 6768 7473 5f73 6c69 6365 642c 2063  eights_sliced, c
+00011510: 6f76 5f61 7578 290d 0a0d 0a20 2020 2020  ov_aux)....     
+00011520: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
+00011530: 2020 2020 2020 2320 496e 7465 7266 6163        # Interfac
+00011540: 6520 636f 6e74 7269 6275 7469 6f6e 0d0a  e contribution..
+00011550: 2020 2020 2020 2020 2020 2020 7369 676d              sigm
+00011560: 615f 305f 696e 7465 7266 203d 2028 542e  a_0_interf = (T.
+00011570: 7375 6d28 0d0a 2020 2020 2020 2020 2020  sum(..          
+00011580: 2020 2020 2020 2d77 6569 6768 7473 5b6c        -weights[l
+00011590: 656e 6774 685f 6f66 5f43 473a 6c65 6e67  ength_of_CG:leng
+000115a0: 7468 5f6f 665f 4347 202b 206c 656e 6774  th_of_CG + lengt
+000115b0: 685f 6f66 5f43 4749 2c20 3a5d 202a 0d0a  h_of_CGI, :] *..
+000115c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000115d0: 2873 656c 662e 635f 6f5f 545f 7363 616c  (self.c_o_T_scal
+000115e0: 6172 202a 2073 656c 662e 695f 7265 6573  ar * self.i_rees
+000115f0: 6361 6c65 202a 2028 0d0a 2020 2020 2020  cale * (..      
+00011600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011610: 2020 280d 0a20 2020 2020 2020 2020 2020    (..           
+00011620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011630: 2020 2020 2073 6564 5f72 6573 745f 5369       sed_rest_Si
+00011640: 6d50 6f69 6e74 203c 2073 656c 662e 615f  mPoint < self.a_
+00011650: 545f 7363 616c 6172 2920 2a20 2023 2053  T_scalar) *  # S
+00011660: 696d 506f 696e 7420 2d20 5265 7374 2043  imPoint - Rest C
+00011670: 6f76 6172 6961 6e63 6573 204d 6174 7269  ovariances Matri
+00011680: 780d 0a20 2020 2020 2020 2020 2020 2020  x..             
+00011690: 2020 2020 2020 2020 2020 2028 3120 2d20             (1 - 
+000116a0: 3720 2a20 2873 6564 5f72 6573 745f 5369  7 * (sed_rest_Si
+000116b0: 6d50 6f69 6e74 202f 2073 656c 662e 615f  mPoint / self.a_
+000116c0: 545f 7363 616c 6172 2920 2a2a 2032 202b  T_scalar) ** 2 +
+000116d0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000116e0: 2020 2020 2020 2020 2020 2033 3520 2f20             35 / 
+000116f0: 3420 2a20 2873 6564 5f72 6573 745f 5369  4 * (sed_rest_Si
+00011700: 6d50 6f69 6e74 202f 2073 656c 662e 615f  mPoint / self.a_
+00011710: 545f 7363 616c 6172 2920 2a2a 2033 202d  T_scalar) ** 3 -
+00011720: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00011730: 2020 2020 2020 2020 2020 2037 202f 2032             7 / 2
+00011740: 202a 2028 7365 645f 7265 7374 5f53 696d   * (sed_rest_Sim
+00011750: 506f 696e 7420 2f20 7365 6c66 2e61 5f54  Point / self.a_T
+00011760: 5f73 6361 6c61 7229 202a 2a20 3520 2b0d  _scalar) ** 5 +.
+00011770: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011780: 2020 2020 2020 2020 2020 3320 2f20 3420            3 / 4 
+00011790: 2a20 2873 6564 5f72 6573 745f 5369 6d50  * (sed_rest_SimP
+000117a0: 6f69 6e74 202f 2073 656c 662e 615f 545f  oint / self.a_T_
+000117b0: 7363 616c 6172 2920 2a2a 2037 2920 2d0d  scalar) ** 7) -.
+000117c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000117d0: 2020 2020 2020 2020 2028 2873 6564 5f72           ((sed_r
+000117e0: 6566 5f53 696d 506f 696e 7420 3c20 7365  ef_SimPoint < se
+000117f0: 6c66 2e61 5f54 5f73 6361 6c61 7229 202a  lf.a_T_scalar) *
+00011800: 2020 2320 5369 6d50 6f69 6e74 2d20 5265    # SimPoint- Re
+00011810: 660d 0a20 2020 2020 2020 2020 2020 2020  f..             
+00011820: 2020 2020 2020 2020 2020 2020 2831 202d              (1 -
+00011830: 2037 202a 2028 7365 645f 7265 665f 5369   7 * (sed_ref_Si
+00011840: 6d50 6f69 6e74 202f 2073 656c 662e 615f  mPoint / self.a_
+00011850: 545f 7363 616c 6172 2920 2a2a 2032 202b  T_scalar) ** 2 +
+00011860: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00011870: 2020 2020 2020 2020 2020 2020 3335 202f              35 /
+00011880: 2034 202a 2028 7365 645f 7265 665f 5369   4 * (sed_ref_Si
+00011890: 6d50 6f69 6e74 202f 2073 656c 662e 615f  mPoint / self.a_
+000118a0: 545f 7363 616c 6172 2920 2a2a 2033 202d  T_scalar) ** 3 -
+000118b0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000118c0: 2020 2020 2020 2020 2020 2020 3720 2f20              7 / 
+000118d0: 3220 2a20 2873 6564 5f72 6566 5f53 696d  2 * (sed_ref_Sim
+000118e0: 506f 696e 7420 2f20 7365 6c66 2e61 5f54  Point / self.a_T
+000118f0: 5f73 6361 6c61 7229 202a 2a20 3520 2b0d  _scalar) ** 5 +.
+00011900: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011910: 2020 2020 2020 2020 2020 2033 202f 2034             3 / 4
+00011920: 202a 2028 7365 645f 7265 665f 5369 6d50   * (sed_ref_SimP
+00011930: 6f69 6e74 202f 2073 656c 662e 615f 545f  oint / self.a_T_
+00011940: 7363 616c 6172 2920 2a2a 2037 2929 2929  scalar) ** 7))))
+00011950: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00011960: 2020 2061 7869 733d 3029 290d 0a20 2020     axis=0))..   
+00011970: 2020 2020 2023 2041 6464 206e 616d 6520       # Add name 
+00011980: 746f 2074 6865 2061 6573 6172 6120 6e6f  to the aesara no
+00011990: 6465 0d0a 2020 2020 2020 2020 7369 676d  de..        sigm
+000119a0: 615f 305f 696e 7465 7266 2e6e 616d 6520  a_0_interf.name 
+000119b0: 3d20 2743 6f6e 7472 6962 7574 696f 6e20  = 'Contribution 
+000119c0: 6f66 2074 6865 2073 7572 6661 6365 5f70  of the surface_p
+000119d0: 6f69 6e74 7320 746f 2074 6865 2070 6f74  oints to the pot
+000119e0: 656e 7469 616c 2066 6965 6c64 2061 7420  ential field at 
+000119f0: 6576 6572 7920 706f 696e 7420 6f66 2074  every point of t
+00011a00: 6865 2067 7269 6427 0d0a 0d0a 2020 2020  he grid'....    
+00011a10: 2020 2020 6966 2073 7472 2873 7973 2e5f      if str(sys._
+00011a20: 6765 7466 7261 6d65 2829 2e66 5f63 6f64  getframe().f_cod
+00011a30: 652e 636f 5f6e 616d 6529 2069 6e20 7365  e.co_name) in se
+00011a40: 6c66 2e76 6572 626f 7365 3a0d 0a20 2020  lf.verbose:..   
+00011a50: 2020 2020 2020 2020 2073 6967 6d61 5f30           sigma_0
+00011a60: 5f69 6e74 6572 6620 3d20 6165 7361 7261  _interf = aesara
+00011a70: 2e70 7269 6e74 696e 672e 5072 696e 7428  .printing.Print(
+00011a80: 2769 6e74 6572 6661 6365 5f63 6f6e 7472  'interface_contr
+00011a90: 6962 7574 696f 6e27 2928 0d0a 2020 2020  ibution')(..    
+00011aa0: 2020 2020 2020 2020 2020 2020 7369 676d              sigm
+00011ab0: 615f 305f 696e 7465 7266 290d 0a0d 0a20  a_0_interf).... 
+00011ac0: 2020 2020 2020 2072 6574 7572 6e20 7369         return si
+00011ad0: 676d 615f 305f 696e 7465 7266 0d0a 0d0a  gma_0_interf....
+00011ae0: 2020 2020 6465 6620 636f 6e74 7269 6275      def contribu
+00011af0: 7469 6f6e 5f75 6e69 7665 7273 616c 5f64  tion_universal_d
+00011b00: 7269 6674 2873 656c 662c 2067 7269 645f  rift(self, grid_
+00011b10: 7661 6c2c 2077 6569 6768 7473 3d4e 6f6e  val, weights=Non
+00011b20: 6529 3a0d 0a20 2020 2020 2020 2022 2222  e):..        """
+00011b30: 0d0a 2020 2020 2020 2020 436f 6d70 7574  ..        Comput
+00011b40: 6174 696f 6e20 6f66 2074 6865 2063 6f6e  ation of the con
+00011b50: 7472 6962 7574 696f 6e20 6f66 2074 6865  tribution of the
+00011b60: 2075 6e69 7665 7273 616c 2064 7269 6674   universal drift
+00011b70: 2061 7420 6576 6572 7920 706f 696e 7420   at every point 
+00011b80: 746f 2069 6e74 6572 706f 6c61 7465 0d0a  to interpolate..
+00011b90: 0d0a 2020 2020 2020 2020 5265 7475 726e  ..        Return
+00011ba0: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
+00011bb0: 6165 7361 7261 2e74 656e 736f 722e 7665  aesara.tensor.ve
+00011bc0: 6374 6f72 3a20 436f 6e74 7269 6275 7469  ctor: Contributi
+00011bd0: 6f6e 206f 6620 7468 6520 756e 6976 6572  on of the univer
+00011be0: 7361 6c20 6472 6966 7420 2869 6e70 7574  sal drift (input
+00011bf0: 2920 6174 2065 7665 7279 2070 6f69 6e74  ) at every point
+00011c00: 2074 6f20 696e 7465 7270 6f6c 6174 650d   to interpolate.
+00011c10: 0a20 2020 2020 2020 2022 2222 0d0a 2020  .        """..  
+00011c20: 2020 2020 2020 6966 2077 6569 6768 7473        if weights
+00011c30: 2069 7320 4e6f 6e65 3a0d 0a20 2020 2020   is None:..     
+00011c40: 2020 2020 2020 2077 6569 6768 7473 203d         weights =
+00011c50: 2073 656c 662e 636f 6d70 7574 655f 7765   self.compute_we
+00011c60: 6967 6874 7328 290d 0a0d 0a20 2020 2020  ights()....     
+00011c70: 2020 206c 656e 6774 685f 6f66 5f43 472c     length_of_CG,
+00011c80: 206c 656e 6774 685f 6f66 5f43 4749 2c20   length_of_CGI, 
+00011c90: 6c65 6e67 7468 5f6f 665f 555f 492c 206c  length_of_U_I, l
+00011ca0: 656e 6774 685f 6f66 5f66 6175 6c74 732c  ength_of_faults,
+00011cb0: 206c 656e 6774 685f 6f66 5f43 203d 2073   length_of_C = s
+00011cc0: 656c 662e 6d61 7472 6963 6573 5f73 6861  elf.matrices_sha
+00011cd0: 7065 7328 290d 0a0d 0a20 2020 2020 2020  pes()....       
+00011ce0: 2075 6e69 7665 7273 616c 5f67 7269 645f   universal_grid_
+00011cf0: 7375 7266 6163 655f 706f 696e 7473 5f6d  surface_points_m
+00011d00: 6174 7269 7820 3d20 542e 686f 7269 7a6f  atrix = T.horizo
+00011d10: 6e74 616c 5f73 7461 636b 280d 0a20 2020  ntal_stack(..   
+00011d20: 2020 2020 2020 2020 2067 7269 645f 7661           grid_va
+00011d30: 6c2c 0d0a 2020 2020 2020 2020 2020 2020  l,..            
+00011d40: 2867 7269 645f 7661 6c20 2a2a 2032 292c  (grid_val ** 2),
+00011d50: 0d0a 2020 2020 2020 2020 2020 2020 542e  ..            T.
+00011d60: 7374 6163 6b28 2867 7269 645f 7661 6c5b  stack((grid_val[
+00011d70: 3a2c 2030 5d20 2a20 6772 6964 5f76 616c  :, 0] * grid_val
+00011d80: 5b3a 2c20 315d 2c0d 0a20 2020 2020 2020  [:, 1],..       
+00011d90: 2020 2020 2020 2020 2020 2020 2020 6772                gr
+00011da0: 6964 5f76 616c 5b3a 2c20 305d 202a 2067  id_val[:, 0] * g
+00011db0: 7269 645f 7661 6c5b 3a2c 2032 5d2c 0d0a  rid_val[:, 2],..
+00011dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011dd0: 2020 2020 2067 7269 645f 7661 6c5b 3a2c       grid_val[:,
+00011de0: 2031 5d20 2a20 6772 6964 5f76 616c 5b3a   1] * grid_val[:
+00011df0: 2c20 325d 292c 2061 7869 733d 3129 292e  , 2]), axis=1)).
+00011e00: 540d 0a0d 0a20 2020 2020 2020 2069 5f72  T....        i_r
+00011e10: 6573 6361 6c65 5f61 7578 203d 2054 2e74  escale_aux = T.t
+00011e20: 696c 6528 7365 6c66 2e67 695f 7265 6573  ile(self.gi_rees
+00011e30: 6361 6c65 2c20 3929 0d0a 2020 2020 2020  cale, 9)..      
+00011e40: 2020 695f 7265 7363 616c 655f 6175 7820    i_rescale_aux 
+00011e50: 3d20 542e 7365 745f 7375 6274 656e 736f  = T.set_subtenso
+00011e60: 7228 695f 7265 7363 616c 655f 6175 785b  r(i_rescale_aux[
+00011e70: 3a33 5d2c 2031 290d 0a20 2020 2020 2020  :3], 1)..       
+00011e80: 205f 6175 785f 6d61 6769 635f 7465 726d   _aux_magic_term
+00011e90: 203d 2054 2e74 696c 6528 695f 7265 7363   = T.tile(i_resc
+00011ea0: 616c 655f 6175 785b 3a73 656c 662e 6e5f  ale_aux[:self.n_
+00011eb0: 756e 6976 6572 7361 6c5f 6571 5f54 5f6f  universal_eq_T_o
+00011ec0: 705d 2c0d 0a20 2020 2020 2020 2020 2020  p],..           
+00011ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011ee0: 2020 2020 2020 2867 7269 645f 7661 6c2e        (grid_val.
+00011ef0: 7368 6170 655b 305d 2c20 3129 292e 540d  shape[0], 1)).T.
+00011f00: 0a0d 0a20 2020 2020 2020 2069 6620 7365  ...        if se
+00011f10: 6c66 2e73 7061 7273 655f 7665 7273 696f  lf.sparse_versio
+00011f20: 6e20 6973 2054 7275 653a 2020 2320 7365  n is True:  # se
+00011f30: 6c66 2e64 6f74 5f76 6572 7369 6f6e 3a0d  lf.dot_version:.
+00011f40: 0a20 2020 2020 2020 2020 2020 2066 5f30  .            f_0
+00011f50: 203d 2054 2e64 6f74 280d 0a20 2020 2020   = T.dot(..     
+00011f60: 2020 2020 2020 2020 2020 2077 6569 6768             weigh
+00011f70: 7473 5b0d 0a20 2020 2020 2020 2020 2020  ts[..           
+00011f80: 2020 2020 206c 656e 6774 685f 6f66 5f43       length_of_C
+00011f90: 4720 2b20 6c65 6e67 7468 5f6f 665f 4347  G + length_of_CG
+00011fa0: 493a 6c65 6e67 7468 5f6f 665f 4347 202b  I:length_of_CG +
+00011fb0: 206c 656e 6774 685f 6f66 5f43 4749 202b   length_of_CGI +
+00011fc0: 206c 656e 6774 685f 6f66 5f55 5f49 5d2c   length_of_U_I],
+00011fd0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00011fe0: 2020 2873 656c 662e 6769 5f72 6565 7363    (self.gi_reesc
+00011ff0: 616c 6520 2a20 5f61 7578 5f6d 6167 6963  ale * _aux_magic
+00012000: 5f74 6572 6d20 2a0d 0a20 2020 2020 2020  _term *..       
+00012010: 2020 2020 2020 2020 2020 756e 6976 6572            univer
+00012020: 7361 6c5f 6772 6964 5f73 7572 6661 6365  sal_grid_surface
+00012030: 5f70 6f69 6e74 735f 6d61 7472 6978 5b3a  _points_matrix[:
+00012040: 7365 6c66 2e6e 5f75 6e69 7665 7273 616c  self.n_universal
+00012050: 5f65 715f 545f 6f70 5d29 290d 0a20 2020  _eq_T_op]))..   
+00012060: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
+00012070: 2020 2020 2020 2020 756e 6976 6572 7361          universa
+00012080: 6c5f 6b65 726e 656c 203d 2073 656c 662e  l_kernel = self.
+00012090: 6769 5f72 6565 7363 616c 6520 2a20 5f61  gi_reescale * _a
+000120a0: 7578 5f6d 6167 6963 5f74 6572 6d20 2a20  ux_magic_term * 
+000120b0: 5c0d 0a20 2020 2020 2020 2020 2020 2020  \..             
+000120c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000120d0: 2020 756e 6976 6572 7361 6c5f 6772 6964    universal_grid
+000120e0: 5f73 7572 6661 6365 5f70 6f69 6e74 735f  _surface_points_
+000120f0: 6d61 7472 6978 5b3a 7365 6c66 2e6e 5f75  matrix[:self.n_u
+00012100: 6e69 7665 7273 616c 5f65 715f 545f 6f70  niversal_eq_T_op
+00012110: 5d0d 0a0d 0a20 2020 2020 2020 2020 2020  ]....           
+00012120: 2023 2044 7269 6674 2063 6f6e 7472 6962   # Drift contrib
+00012130: 7574 696f 6e0d 0a20 2020 2020 2020 2020  ution..         
+00012140: 2020 2066 5f30 203d 2028 542e 7375 6d28     f_0 = (T.sum(
+00012150: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00012160: 2020 7765 6967 6874 735b 6c65 6e67 7468    weights[length
+00012170: 5f6f 665f 4347 202b 206c 656e 6774 685f  _of_CG + length_
+00012180: 6f66 5f43 4749 3a6c 656e 6774 685f 6f66  of_CGI:length_of
+00012190: 5f43 4720 2b20 6c65 6e67 7468 5f6f 665f  _CG + length_of_
+000121a0: 4347 4920 2b20 6c65 6e67 7468 5f6f 665f  CGI + length_of_
+000121b0: 555f 495d 202a 0d0a 2020 2020 2020 2020  U_I] *..        
+000121c0: 2020 2020 2020 2020 756e 6976 6572 7361          universa
+000121d0: 6c5f 6b65 726e 656c 0d0a 2020 2020 2020  l_kernel..      
+000121e0: 2020 2020 2020 2020 2020 2c20 6178 6973            , axis
+000121f0: 3d30 2929 0d0a 0d0a 2020 2020 2020 2020  =0))....        
+00012200: 6966 206e 6f74 2074 7970 6528 665f 3029  if not type(f_0)
+00012210: 203d 3d20 696e 743a 0d0a 2020 2020 2020   == int:..      
+00012220: 2020 2020 2020 665f 302e 6e61 6d65 203d        f_0.name =
+00012230: 2027 436f 6e74 7269 6275 7469 6f6e 206f   'Contribution o
+00012240: 6620 7468 6520 756e 6976 6572 7361 6c20  f the universal 
+00012250: 6472 6966 7420 746f 2074 6865 2070 6f74  drift to the pot
+00012260: 656e 7469 616c 2066 6965 6c64 2061 7420  ential field at 
+00012270: 6576 6572 7920 706f 696e 7420 6f66 2074  every point of t
+00012280: 6865 2067 7269 6427 0d0a 0d0a 2020 2020  he grid'....    
+00012290: 2020 2020 6966 2073 7472 2873 7973 2e5f      if str(sys._
+000122a0: 6765 7466 7261 6d65 2829 2e66 5f63 6f64  getframe().f_cod
+000122b0: 652e 636f 5f6e 616d 6529 2069 6e20 7365  e.co_name) in se
+000122c0: 6c66 2e76 6572 626f 7365 3a0d 0a20 2020  lf.verbose:..   
+000122d0: 2020 2020 2020 2020 2066 5f30 203d 2061           f_0 = a
+000122e0: 6573 6172 612e 7072 696e 7469 6e67 2e50  esara.printing.P
+000122f0: 7269 6e74 2827 556e 6976 6572 7361 6c20  rint('Universal 
+00012300: 7465 726d 7320 636f 6e74 7269 6275 7469  terms contributi
+00012310: 6f6e 2729 2866 5f30 290d 0a0d 0a20 2020  on')(f_0)....   
+00012320: 2020 2020 2072 6574 7572 6e20 665f 300d       return f_0.
+00012330: 0a0d 0a20 2020 2064 6566 2063 6f6e 7472  ...    def contr
+00012340: 6962 7574 696f 6e5f 6661 756c 7473 2873  ibution_faults(s
+00012350: 656c 662c 2077 6569 6768 7473 3d4e 6f6e  elf, weights=Non
+00012360: 652c 2061 3d30 2c20 623d 3130 3030 3030  e, a=0, b=100000
+00012370: 3030 302c 2066 5f6d 3d4e 6f6e 6529 3a0d  000, f_m=None):.
+00012380: 0a20 2020 2020 2020 2022 2222 0d0a 2020  .        """..  
+00012390: 2020 2020 2020 436f 6d70 7574 6174 696f        Computatio
+000123a0: 6e20 6f66 2074 6865 2063 6f6e 7472 6962  n of the contrib
+000123b0: 7574 696f 6e20 6f66 2074 6865 2064 6620  ution of the df 
+000123c0: 6472 6966 7420 6174 2065 7665 7279 2070  drift at every p
+000123d0: 6f69 6e74 2074 6f20 696e 7465 7270 6f6c  oint to interpol
+000123e0: 6174 652e 2054 6f20 6765 7420 7468 6573  ate. To get thes
+000123f0: 6520 7765 206e 6565 6420 746f 0d0a 2020  e we need to..  
+00012400: 2020 2020 2020 636f 6d70 7574 6520 6120        compute a 
+00012410: 7768 6f6c 6520 626c 6f63 6b20 6d6f 6465  whole block mode
+00012420: 6c20 7769 7468 2074 6865 2064 6620 6461  l with the df da
+00012430: 7461 0d0a 0d0a 2020 2020 2020 2020 5265  ta....        Re
+00012440: 7475 726e 733a 0d0a 2020 2020 2020 2020  turns:..        
+00012450: 2020 2020 6165 7361 7261 2e74 656e 736f      aesara.tenso
+00012460: 722e 7665 6374 6f72 3a20 436f 6e74 7269  r.vector: Contri
+00012470: 6275 7469 6f6e 206f 6620 7468 6520 6466  bution of the df
+00012480: 2064 7269 6674 2028 696e 7075 7429 2061   drift (input) a
+00012490: 7420 6576 6572 7920 706f 696e 7420 746f  t every point to
+000124a0: 2069 6e74 6572 706f 6c61 7465 0d0a 2020   interpolate..  
+000124b0: 2020 2020 2020 2222 220d 0a20 2020 2020        """..     
+000124c0: 2020 2069 6620 7765 6967 6874 7320 6973     if weights is
+000124d0: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
+000124e0: 2020 2020 7765 6967 6874 7320 3d20 7365      weights = se
+000124f0: 6c66 2e63 6f6d 7075 7465 5f77 6569 6768  lf.compute_weigh
+00012500: 7473 2829 0d0a 2020 2020 2020 2020 6c65  ts()..        le
+00012510: 6e67 7468 5f6f 665f 4347 2c20 6c65 6e67  ngth_of_CG, leng
+00012520: 7468 5f6f 665f 4347 492c 206c 656e 6774  th_of_CGI, lengt
+00012530: 685f 6f66 5f55 5f49 2c20 6c65 6e67 7468  h_of_U_I, length
+00012540: 5f6f 665f 6661 756c 7473 2c20 6c65 6e67  _of_faults, leng
+00012550: 7468 5f6f 665f 4320 3d20 7365 6c66 2e6d  th_of_C = self.m
+00012560: 6174 7269 6365 735f 7368 6170 6573 2829  atrices_shapes()
+00012570: 0d0a 0d0a 2020 2020 2020 2020 6661 756c  ....        faul
+00012580: 745f 6d61 7472 6978 5f73 656c 6563 7469  t_matrix_selecti
+00012590: 6f6e 5f6e 6f6e 5f7a 6572 6f20 3d20 665f  on_non_zero = f_
+000125a0: 6d5b 3a2c 2061 3a62 5d0d 0a0d 0a20 2020  m[:, a:b]....   
+000125b0: 2020 2020 2069 6620 7365 6c66 2e73 7061       if self.spa
+000125c0: 7273 655f 7665 7273 696f 6e20 6973 2054  rse_version is T
+000125d0: 7275 653a 2020 2320 7365 6c66 2e64 6f74  rue:  # self.dot
+000125e0: 5f76 6572 7369 6f6e 3a0d 0a20 2020 2020  _version:..     
+000125f0: 2020 2020 2020 2066 5f31 203d 2054 2e64         f_1 = T.d
+00012600: 6f74 280d 0a20 2020 2020 2020 2020 2020  ot(..           
+00012610: 2020 2020 2077 6569 6768 7473 5b6c 656e       weights[len
+00012620: 6774 685f 6f66 5f43 4720 2b20 6c65 6e67  gth_of_CG + leng
+00012630: 7468 5f6f 665f 4347 4920 2b20 6c65 6e67  th_of_CGI + leng
+00012640: 7468 5f6f 665f 555f 493a 5d2c 2028 0d0a  th_of_U_I:], (..
+00012650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012660: 2020 2020 6661 756c 745f 6d61 7472 6978      fault_matrix
+00012670: 5f73 656c 6563 7469 6f6e 5f6e 6f6e 5f7a  _selection_non_z
+00012680: 6572 6f29 290d 0a20 2020 2020 2020 2065  ero))..        e
+00012690: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
+000126a0: 2020 665f 3120 3d20 542e 7375 6d28 0d0a    f_1 = T.sum(..
+000126b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000126c0: 7765 6967 6874 735b 6c65 6e67 7468 5f6f  weights[length_o
+000126d0: 665f 4347 202b 206c 656e 6774 685f 6f66  f_CG + length_of
+000126e0: 5f43 4749 202b 206c 656e 6774 685f 6f66  _CGI + length_of
+000126f0: 5f55 5f49 3a2c 0d0a 2020 2020 2020 2020  _U_I:,..        
+00012700: 2020 2020 2020 2020 3a5d 202a 2066 6175          :] * fau
+00012710: 6c74 5f6d 6174 7269 785f 7365 6c65 6374  lt_matrix_select
+00012720: 696f 6e5f 6e6f 6e5f 7a65 726f 2c20 6178  ion_non_zero, ax
+00012730: 6973 3d30 290d 0a0d 0a20 2020 2020 2020  is=0)....       
+00012740: 2023 2041 6464 206e 616d 6520 746f 2074   # Add name to t
+00012750: 6865 2061 6573 6172 6120 6e6f 6465 0d0a  he aesara node..
+00012760: 2020 2020 2020 2020 665f 312e 6e61 6d65          f_1.name
+00012770: 203d 2027 4661 756c 7473 2063 6f6e 7472   = 'Faults contr
+00012780: 6962 7574 696f 6e27 0d0a 0d0a 2020 2020  ibution'....    
+00012790: 2020 2020 6966 2073 7472 2873 7973 2e5f      if str(sys._
+000127a0: 6765 7466 7261 6d65 2829 2e66 5f63 6f64  getframe().f_cod
+000127b0: 652e 636f 5f6e 616d 6529 2069 6e20 7365  e.co_name) in se
+000127c0: 6c66 2e76 6572 626f 7365 3a0d 0a20 2020  lf.verbose:..   
+000127d0: 2020 2020 2020 2020 2066 5f31 203d 2061           f_1 = a
+000127e0: 6573 6172 612e 7072 696e 7469 6e67 2e50  esara.printing.P
+000127f0: 7269 6e74 2827 4661 756c 7473 2063 6f6e  rint('Faults con
+00012800: 7472 6962 7574 696f 6e27 2928 665f 3129  tribution')(f_1)
+00012810: 0d0a 0d0a 2020 2020 2020 2020 7265 7475  ....        retu
+00012820: 726e 2066 5f31 0d0a 0d0a 2020 2020 6465  rn f_1....    de
+00012830: 6620 7363 616c 6172 5f66 6965 6c64 5f6c  f scalar_field_l
+00012840: 6f6f 7028 7365 6c66 2c20 612c 2062 2c20  oop(self, a, b, 
+00012850: 5a5f 782c 2067 7269 645f 7661 6c2c 2077  Z_x, grid_val, w
+00012860: 6569 6768 7473 2c20 6661 756c 745f 6d61  eights, fault_ma
+00012870: 7472 6978 293a 0d0a 0d0a 2020 2020 2020  trix):....      
+00012880: 2020 6966 2073 656c 662e 7370 6172 7365    if self.sparse
+00012890: 5f76 6572 7369 6f6e 2069 7320 5472 7565  _version is True
+000128a0: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
+000128b0: 616e 6720 3d20 350d 0a20 2020 2020 2020  ang = 5..       
+000128c0: 2020 2020 2074 696c 6564 5f77 6569 6768       tiled_weigh
+000128d0: 7473 203d 2073 656c 662e 6578 7465 6e64  ts = self.extend
+000128e0: 5f64 7561 6c5f 6b72 6967 696e 6728 7765  _dual_kriging(we
+000128f0: 6967 6874 732c 2072 616e 6729 0d0a 2020  ights, rang)..  
+00012900: 2020 2020 2020 2020 2020 7369 676d 615f            sigma_
+00012910: 305f 6772 6164 203d 2073 656c 662e 636f  0_grad = self.co
+00012920: 6e74 7269 6275 7469 6f6e 5f67 7261 6469  ntribution_gradi
+00012930: 656e 745f 696e 7465 7266 6163 6528 6772  ent_interface(gr
+00012940: 6964 5f76 616c 5b61 3a62 5d2c 0d0a 2020  id_val[a:b],..  
+00012950: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012970: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012980: 2020 2020 2020 2020 2020 2020 2020 7469                ti
+00012990: 6c65 645f 7765 6967 6874 7329 0d0a 2020  led_weights)..  
+000129a0: 2020 2020 2020 2020 2020 7369 676d 615f            sigma_
+000129b0: 305f 696e 7465 7266 203d 2073 656c 662e  0_interf = self.
+000129c0: 636f 6e74 7269 6275 7469 6f6e 5f69 6e74  contribution_int
+000129d0: 6572 6661 6365 2867 7269 645f 7661 6c5b  erface(grid_val[
+000129e0: 613a 625d 2c0d 0a20 2020 2020 2020 2020  a:b],..         
 000129f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00012a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00012a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012a20: 2020 2020 2020 2020 2020 7469 6c65 645f            tiled_
-00012a30: 7765 6967 6874 7329 0d0a 2020 2020 2020  weights)..      
-00012a40: 2020 2020 2020 7369 676d 615f 305f 696e        sigma_0_in
-00012a50: 7465 7266 203d 2073 656c 662e 636f 6e74  terf = self.cont
-00012a60: 7269 6275 7469 6f6e 5f69 6e74 6572 6661  ribution_interfa
-00012a70: 6365 2867 7269 645f 7661 6c5b 613a 625d  ce(grid_val[a:b]
-00012a80: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00012a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012ab0: 2020 2020 2020 2020 2020 2020 7469 6c65              tile
-00012ac0: 645f 7765 6967 6874 7329 0d0a 2020 2020  d_weights)..    
-00012ad0: 2020 2020 2020 2020 665f 3020 3d20 7365          f_0 = se
-00012ae0: 6c66 2e63 6f6e 7472 6962 7574 696f 6e5f  lf.contribution_
-00012af0: 756e 6976 6572 7361 6c5f 6472 6966 7428  universal_drift(
-00012b00: 6772 6964 5f76 616c 5b61 3a62 5d2c 2074  grid_val[a:b], t
-00012b10: 696c 6564 5f77 6569 6768 7473 290d 0a20  iled_weights).. 
-00012b20: 2020 2020 2020 2020 2020 2066 5f31 203d             f_1 =
-00012b30: 2073 656c 662e 636f 6e74 7269 6275 7469   self.contributi
-00012b40: 6f6e 5f66 6175 6c74 7328 7469 6c65 645f  on_faults(tiled_
-00012b50: 7765 6967 6874 732c 2061 2c20 6229 0d0a  weights, a, b)..
-00012b60: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
-00012b70: 4164 6420 616e 2061 7262 6974 7261 7279  Add an arbitrary
-00012b80: 206e 756d 6265 7220 6174 2074 6865 2070   number at the p
-00012b90: 6f74 656e 7469 616c 2066 6965 6c64 2074  otential field t
-00012ba0: 6f20 6765 7420 756e 6971 7565 2076 616c  o get unique val
-00012bb0: 7565 7320 666f 7220 6561 6368 206f 6620  ues for each of 
-00012bc0: 7468 656d 0d0a 2020 2020 2020 2020 2020  them..          
-00012bd0: 2020 7061 7274 6961 6c5f 5a5f 7820 3d20    partial_Z_x = 
-00012be0: 2873 6967 6d61 5f30 5f67 7261 6420 2b20  (sigma_0_grad + 
-00012bf0: 7369 676d 615f 305f 696e 7465 7266 202b  sigma_0_interf +
-00012c00: 2066 5f30 202b 2066 5f31 295b 305d 0d0a   f_0 + f_1)[0]..
-00012c10: 0d0a 2020 2020 2020 2020 656c 7365 3a0d  ..        else:.
-00012c20: 0a20 2020 2020 2020 2020 2020 2072 616e  .            ran
-00012c30: 6720 3d20 6220 2d20 610d 0a20 2020 2020  g = b - a..     
-00012c40: 2020 2020 2020 2074 696c 6564 5f77 6569         tiled_wei
-00012c50: 6768 7473 203d 2073 656c 662e 6578 7465  ghts = self.exte
-00012c60: 6e64 5f64 7561 6c5f 6b72 6967 696e 6728  nd_dual_kriging(
-00012c70: 7765 6967 6874 732c 2072 616e 6729 0d0a  weights, rang)..
-00012c80: 2020 2020 2020 2020 2020 2020 7369 676d              sigm
-00012c90: 615f 305f 6772 6164 203d 2073 656c 662e  a_0_grad = self.
-00012ca0: 636f 6e74 7269 6275 7469 6f6e 5f67 7261  contribution_gra
-00012cb0: 6469 656e 745f 696e 7465 7266 6163 6528  dient_interface(
-00012cc0: 6772 6964 5f76 616c 5b61 3a62 5d2c 0d0a  grid_val[a:b],..
-00012cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012a20: 7469 6c65 645f 7765 6967 6874 7329 0d0a  tiled_weights)..
+00012a30: 2020 2020 2020 2020 2020 2020 665f 3020              f_0 
+00012a40: 3d20 7365 6c66 2e63 6f6e 7472 6962 7574  = self.contribut
+00012a50: 696f 6e5f 756e 6976 6572 7361 6c5f 6472  ion_universal_dr
+00012a60: 6966 7428 6772 6964 5f76 616c 5b61 3a62  ift(grid_val[a:b
+00012a70: 5d2c 2074 696c 6564 5f77 6569 6768 7473  ], tiled_weights
+00012a80: 290d 0a20 2020 2020 2020 2020 2020 2066  )..            f
+00012a90: 5f31 203d 2073 656c 662e 636f 6e74 7269  _1 = self.contri
+00012aa0: 6275 7469 6f6e 5f66 6175 6c74 7328 7469  bution_faults(ti
+00012ab0: 6c65 645f 7765 6967 6874 732c 2061 2c20  led_weights, a, 
+00012ac0: 6229 0d0a 0d0a 2020 2020 2020 2020 2020  b)....          
+00012ad0: 2020 2320 4164 6420 616e 2061 7262 6974    # Add an arbit
+00012ae0: 7261 7279 206e 756d 6265 7220 6174 2074  rary number at t
+00012af0: 6865 2070 6f74 656e 7469 616c 2066 6965  he potential fie
+00012b00: 6c64 2074 6f20 6765 7420 756e 6971 7565  ld to get unique
+00012b10: 2076 616c 7565 7320 666f 7220 6561 6368   values for each
+00012b20: 206f 6620 7468 656d 0d0a 2020 2020 2020   of them..      
+00012b30: 2020 2020 2020 7061 7274 6961 6c5f 5a5f        partial_Z_
+00012b40: 7820 3d20 2873 6967 6d61 5f30 5f67 7261  x = (sigma_0_gra
+00012b50: 6420 2b20 7369 676d 615f 305f 696e 7465  d + sigma_0_inte
+00012b60: 7266 202b 2066 5f30 202b 2066 5f31 295b  rf + f_0 + f_1)[
+00012b70: 305d 0d0a 0d0a 2020 2020 2020 2020 656c  0]....        el
+00012b80: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
+00012b90: 2072 616e 6720 3d20 6220 2d20 610d 0a20   rang = b - a.. 
+00012ba0: 2020 2020 2020 2020 2020 2074 696c 6564             tiled
+00012bb0: 5f77 6569 6768 7473 203d 2073 656c 662e  _weights = self.
+00012bc0: 6578 7465 6e64 5f64 7561 6c5f 6b72 6967  extend_dual_krig
+00012bd0: 696e 6728 7765 6967 6874 732c 2072 616e  ing(weights, ran
+00012be0: 6729 0d0a 2020 2020 2020 2020 2020 2020  g)..            
+00012bf0: 7369 676d 615f 305f 6772 6164 203d 2073  sigma_0_grad = s
+00012c00: 656c 662e 636f 6e74 7269 6275 7469 6f6e  elf.contribution
+00012c10: 5f67 7261 6469 656e 745f 696e 7465 7266  _gradient_interf
+00012c20: 6163 6528 6772 6964 5f76 616c 5b61 3a62  ace(grid_val[a:b
+00012c30: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+00012c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012c70: 2020 2020 7469 6c65 645f 7765 6967 6874      tiled_weight
+00012c80: 735b 3a2c 203a 5d29 0d0a 2020 2020 2020  s[:, :])..      
+00012c90: 2020 2020 2020 7369 676d 615f 305f 696e        sigma_0_in
+00012ca0: 7465 7266 203d 2073 656c 662e 636f 6e74  terf = self.cont
+00012cb0: 7269 6275 7469 6f6e 5f69 6e74 6572 6661  ribution_interfa
+00012cc0: 6365 2867 7269 645f 7661 6c5b 613a 625d  ce(grid_val[a:b]
+00012cd0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
 00012ce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00012cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012d10: 7469 6c65 645f 7765 6967 6874 735b 3a2c  tiled_weights[:,
-00012d20: 203a 5d29 0d0a 2020 2020 2020 2020 2020   :])..          
-00012d30: 2020 7369 676d 615f 305f 696e 7465 7266    sigma_0_interf
-00012d40: 203d 2073 656c 662e 636f 6e74 7269 6275   = self.contribu
-00012d50: 7469 6f6e 5f69 6e74 6572 6661 6365 2867  tion_interface(g
-00012d60: 7269 645f 7661 6c5b 613a 625d 2c0d 0a20  rid_val[a:b],.. 
+00012d00: 2020 2020 2020 2020 2020 2020 7469 6c65              tile
+00012d10: 645f 7765 6967 6874 735b 3a2c 203a 5d29  d_weights[:, :])
+00012d20: 0d0a 2020 2020 2020 2020 2020 2020 665f  ..            f_
+00012d30: 3020 3d20 7365 6c66 2e63 6f6e 7472 6962  0 = self.contrib
+00012d40: 7574 696f 6e5f 756e 6976 6572 7361 6c5f  ution_universal_
+00012d50: 6472 6966 7428 6772 6964 5f76 616c 5b61  drift(grid_val[a
+00012d60: 3a62 5d2c 0d0a 2020 2020 2020 2020 2020  :b],..          
 00012d70: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00012d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012da0: 2020 2020 2020 2020 7469 6c65 645f 7765          tiled_we
-00012db0: 6967 6874 735b 3a2c 203a 5d29 0d0a 2020  ights[:, :])..  
-00012dc0: 2020 2020 2020 2020 2020 665f 3020 3d20            f_0 = 
-00012dd0: 7365 6c66 2e63 6f6e 7472 6962 7574 696f  self.contributio
-00012de0: 6e5f 756e 6976 6572 7361 6c5f 6472 6966  n_universal_drif
-00012df0: 7428 6772 6964 5f76 616c 5b61 3a62 5d2c  t(grid_val[a:b],
-00012e00: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00012e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012e30: 2020 2020 2020 7469 6c65 645f 7765 6967        tiled_weig
-00012e40: 6874 735b 3a2c 203a 5d29 0d0a 2020 2020  hts[:, :])..    
-00012e50: 2020 2020 2020 2020 665f 3120 3d20 7365          f_1 = se
-00012e60: 6c66 2e63 6f6e 7472 6962 7574 696f 6e5f  lf.contribution_
-00012e70: 6661 756c 7473 2874 696c 6564 5f77 6569  faults(tiled_wei
-00012e80: 6768 7473 5b3a 2c20 3a5d 2c20 612c 2062  ghts[:, :], a, b
-00012e90: 2c20 6661 756c 745f 6d61 7472 6978 290d  , fault_matrix).
-00012ea0: 0a0d 0a20 2020 2020 2020 2020 2020 2023  ...            #
-00012eb0: 2041 6464 2061 6e20 6172 6269 7472 6172   Add an arbitrar
-00012ec0: 7920 6e75 6d62 6572 2061 7420 7468 6520  y number at the 
-00012ed0: 706f 7465 6e74 6961 6c20 6669 656c 6420  potential field 
-00012ee0: 746f 2067 6574 2075 6e69 7175 6520 7661  to get unique va
-00012ef0: 6c75 6573 2066 6f72 2065 6163 6820 6f66  lues for each of
-00012f00: 2074 6865 6d0d 0a20 2020 2020 2020 2020   them..         
-00012f10: 2020 2070 6172 7469 616c 5f5a 5f78 203d     partial_Z_x =
-00012f20: 2028 7369 676d 615f 305f 6772 6164 202b   (sigma_0_grad +
-00012f30: 2073 6967 6d61 5f30 5f69 6e74 6572 6620   sigma_0_interf 
-00012f40: 2b20 665f 3020 2b20 665f 3129 0d0a 0d0a  + f_0 + f_1)....
-00012f50: 2020 2020 2020 2020 5a5f 7820 3d20 542e          Z_x = T.
-00012f60: 7365 745f 7375 6274 656e 736f 7228 5a5f  set_subtensor(Z_
-00012f70: 785b 613a 625d 2c20 7061 7274 6961 6c5f  x[a:b], partial_
-00012f80: 5a5f 7829 0d0a 0d0a 2020 2020 2020 2020  Z_x)....        
-00012f90: 7265 7475 726e 205a 5f78 0d0a 0d0a 2020  return Z_x....  
-00012fa0: 2020 6465 6620 7363 616c 6172 5f66 6965    def scalar_fie
-00012fb0: 6c64 5f61 745f 616c 6c28 7365 6c66 2c20  ld_at_all(self, 
-00012fc0: 7765 6967 6874 732c 2067 7269 645f 7661  weights, grid_va
-00012fd0: 6c2c 2066 6175 6c74 5f6d 6174 7269 7829  l, fault_matrix)
-00012fe0: 3a0d 0a20 2020 2020 2020 2022 2222 0d0a  :..        """..
-00012ff0: 2020 2020 2020 2020 436f 6d70 7574 6520          Compute 
-00013000: 7468 6520 706f 7465 6e74 6961 6c20 6669  the potential fi
-00013010: 656c 6420 6174 2061 6c6c 2074 6865 2069  eld at all the i
-00013020: 6e74 6572 706f 6c61 7469 6f6e 2070 6f69  nterpolation poi
-00013030: 6e74 732c 2069 2e65 2e20 6772 6964 2070  nts, i.e. grid p
-00013040: 6c75 7320 7265 7374 2070 6c75 7320 7265  lus rest plus re
-00013050: 660d 0a20 2020 2020 2020 2052 6574 7572  f..        Retur
-00013060: 6e73 3a0d 0a20 2020 2020 2020 2020 2020  ns:..           
-00013070: 2074 6865 616e 6f2e 7465 6e73 6f72 2e76   theano.tensor.v
-00013080: 6563 746f 723a 2050 6f74 656e 7469 616c  ector: Potential
-00013090: 2066 6965 6c64 7320 6174 2061 6c6c 2070   fields at all p
-000130a0: 6f69 6e74 730d 0a0d 0a20 2020 2020 2020  oints....       
-000130b0: 2022 2222 0d0a 2020 2020 2020 2020 230d   """..        #.
-000130c0: 0a0d 0a20 2020 2020 2020 2067 7269 645f  ...        grid_
-000130d0: 7368 6170 6520 3d20 542e 7374 6163 6b28  shape = T.stack(
-000130e0: 5b67 7269 645f 7661 6c2e 7368 6170 655b  [grid_val.shape[
-000130f0: 305d 5d2c 2061 7869 733d 3029 0d0a 2020  0]], axis=0)..  
-00013100: 2020 2020 2020 5a5f 785f 696e 6974 203d        Z_x_init =
-00013110: 2054 2e7a 6572 6f73 2867 7269 645f 7368   T.zeros(grid_sh
-00013120: 6170 6529 0d0a 2020 2020 2020 2020 6966  ape)..        if
-00013130: 2027 6772 6964 5f73 6861 7065 2720 696e   'grid_shape' in
-00013140: 2073 656c 662e 7665 7262 6f73 653a 0d0a   self.verbose:..
-00013150: 2020 2020 2020 2020 2020 2020 6772 6964              grid
-00013160: 5f73 6861 7065 203d 2074 6865 616e 6f2e  _shape = theano.
-00013170: 7072 696e 7469 6e67 2e50 7269 6e74 2827  printing.Print('
-00013180: 6772 6964 5f73 6861 7065 2729 2867 7269  grid_shape')(gri
-00013190: 645f 7368 6170 6529 0d0a 0d0a 2020 2020  d_shape)....    
-000131a0: 2020 2020 2320 4966 206d 656d 6f72 7920      # If memory 
-000131b0: 6572 726f 7273 2072 6564 7563 6520 7468  errors reduce th
-000131c0: 6973 2074 6f20 3131 0d0a 2020 2020 2020  is to 11..      
-000131d0: 2020 7374 6570 7320 3d20 3565 3620 2f20    steps = 5e6 / 
-000131e0: 7365 6c66 2e6d 6174 7269 6365 735f 7368  self.matrices_sh
-000131f0: 6170 6573 2829 5b2d 315d 2020 2320 2f20  apes()[-1]  # / 
-00013200: 6772 6964 5f73 6861 7065 0d0a 2020 2020  grid_shape..    
-00013210: 2020 2020 6966 2027 7374 6570 7327 2069      if 'steps' i
-00013220: 6e20 7365 6c66 2e76 6572 626f 7365 3a0d  n self.verbose:.
-00013230: 0a20 2020 2020 2020 2020 2020 2073 7465  .            ste
-00013240: 7073 203d 2074 6865 616e 6f2e 7072 696e  ps = theano.prin
-00013250: 7469 6e67 2e50 7269 6e74 2827 7374 6570  ting.Print('step
-00013260: 7327 2928 7374 6570 7329 0d0a 0d0a 2020  s')(steps)....  
-00013270: 2020 2020 2020 736c 6963 6573 203d 2054        slices = T
-00013280: 2e63 6f6e 6361 7465 6e61 7465 280d 0a20  .concatenate(.. 
-00013290: 2020 2020 2020 2020 2020 2028 542e 6172             (T.ar
-000132a0: 616e 6765 2830 2c20 6772 6964 5f73 6861  ange(0, grid_sha
-000132b0: 7065 5b30 5d2c 2073 7465 7073 2c20 6474  pe[0], steps, dt
-000132c0: 7970 653d 2769 6e74 3634 2729 2c20 6772  ype='int64'), gr
-000132d0: 6964 5f73 6861 7065 2929 0d0a 0d0a 2020  id_shape))....  
-000132e0: 2020 2020 2020 6966 2027 736c 6963 6573        if 'slices
-000132f0: 2720 696e 2073 656c 662e 7665 7262 6f73  ' in self.verbos
-00013300: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00013310: 736c 6963 6573 203d 2074 6865 616e 6f2e  slices = theano.
-00013320: 7072 696e 7469 6e67 2e50 7269 6e74 2827  printing.Print('
-00013330: 736c 6963 6573 2729 2873 6c69 6365 7329  slices')(slices)
-00013340: 0d0a 0d0a 2020 2020 2020 2020 2320 4368  ....        # Ch
-00013350: 6563 6b20 6966 2077 6520 6c6f 6f70 2074  eck if we loop t
-00013360: 6865 2067 7269 6420 6f72 206e 6f74 0d0a  he grid or not..
-00013370: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00013380: 7370 6172 7365 5f76 6572 7369 6f6e 2069  sparse_version i
-00013390: 7320 5472 7565 3a0d 0a20 2020 2020 2020  s True:..       
-000133a0: 2020 2020 2073 656c 662e 646f 745f 7665       self.dot_ve
-000133b0: 7273 696f 6e20 3d20 5472 7565 0d0a 2020  rsion = True..  
-000133c0: 2020 2020 2020 2020 2020 5a5f 7820 3d20            Z_x = 
-000133d0: 7365 6c66 2e73 6361 6c61 725f 6669 656c  self.scalar_fiel
-000133e0: 645f 6c6f 6f70 2830 2c20 3130 3030 3030  d_loop(0, 100000
-000133f0: 3030 302c 205a 5f78 5f69 6e69 742c 2067  000, Z_x_init, g
-00013400: 7269 645f 7661 6c2c 2077 6569 6768 7473  rid_val, weights
-00013410: 290d 0a0d 0a20 2020 2020 2020 2065 6c69  )....        eli
-00013420: 6620 7365 6c66 2e6d 6178 5f73 7065 6564  f self.max_speed
-00013430: 203c 2032 3a0d 0a20 2020 2020 2020 2020   < 2:..         
-00013440: 2020 2023 2074 696c 6564 5f77 6569 6768     # tiled_weigh
-00013450: 7473 203d 2073 656c 662e 6578 7465 6e64  ts = self.extend
-00013460: 5f64 7561 6c5f 6b72 6967 696e 6728 7765  _dual_kriging(we
-00013470: 6967 6874 732c 2067 7269 645f 7661 6c2e  ights, grid_val.
-00013480: 7368 6170 655b 305d 290d 0a20 2020 2020  shape[0])..     
-00013490: 2020 2020 2020 205a 5f78 5f6c 6f6f 702c         Z_x_loop,
-000134a0: 2075 7064 6174 6573 3320 3d20 7468 6561   updates3 = thea
-000134b0: 6e6f 2e73 6361 6e28 0d0a 2020 2020 2020  no.scan(..      
-000134c0: 2020 2020 2020 2020 2020 666e 3d73 656c            fn=sel
-000134d0: 662e 7363 616c 6172 5f66 6965 6c64 5f6c  f.scalar_field_l
-000134e0: 6f6f 702c 0d0a 2020 2020 2020 2020 2020  oop,..          
-000134f0: 2020 2020 2020 6f75 7470 7574 735f 696e        outputs_in
-00013500: 666f 3d5b 5a5f 785f 696e 6974 5d2c 0d0a  fo=[Z_x_init],..
-00013510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013520: 7365 7175 656e 6365 733d 5b64 6963 7428  sequences=[dict(
-00013530: 696e 7075 743d 736c 6963 6573 2c20 7461  input=slices, ta
-00013540: 7073 3d5b 302c 2031 5d29 5d2c 0d0a 2020  ps=[0, 1])],..  
-00013550: 2020 2020 2020 2020 2020 2020 2020 6e6f                no
-00013560: 6e5f 7365 7175 656e 6365 733d 5b67 7269  n_sequences=[gri
-00013570: 645f 7661 6c2c 2077 6569 6768 7473 2c20  d_val, weights, 
-00013580: 6661 756c 745f 6d61 7472 6978 5d2c 0d0a  fault_matrix],..
-00013590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000135a0: 7072 6f66 696c 653d 4661 6c73 652c 0d0a  profile=False,..
-000135b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000135c0: 6e61 6d65 3d27 4c6f 6f70 696e 6720 6772  name='Looping gr
-000135d0: 6964 272c 0d0a 2020 2020 2020 2020 2020  id',..          
-000135e0: 2020 2020 2020 7265 7475 726e 5f6c 6973        return_lis
-000135f0: 743d 5472 7565 290d 0a0d 0a20 2020 2020  t=True)....     
-00013600: 2020 2020 2020 205a 5f78 203d 205a 5f78         Z_x = Z_x
-00013610: 5f6c 6f6f 705b 2d31 5d5b 2d31 5d0d 0a20  _loop[-1][-1].. 
-00013620: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-00013630: 2020 2020 2020 2020 2020 7469 6c65 645f            tiled_
-00013640: 7765 6967 6874 7320 3d20 7365 6c66 2e65  weights = self.e
-00013650: 7874 656e 645f 6475 616c 5f6b 7269 6769  xtend_dual_krigi
-00013660: 6e67 2877 6569 6768 7473 2c20 6772 6964  ng(weights, grid
-00013670: 5f76 616c 2e73 6861 7065 5b30 5d29 0d0a  _val.shape[0])..
-00013680: 2020 2020 2020 2020 2020 2020 5a5f 7820              Z_x 
-00013690: 3d20 7365 6c66 2e73 6361 6c61 725f 6669  = self.scalar_fi
-000136a0: 656c 645f 6c6f 6f70 2830 2c20 3130 3030  eld_loop(0, 1000
-000136b0: 3030 3030 302c 205a 5f78 5f69 6e69 742c  00000, Z_x_init,
-000136c0: 2067 7269 645f 7661 6c2c 0d0a 2020 2020   grid_val,..    
-000136d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000136e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000136f0: 2020 2020 2074 696c 6564 5f77 6569 6768       tiled_weigh
-00013700: 7473 290d 0a0d 0a20 2020 2020 2020 205a  ts)....        Z
-00013710: 5f78 2e6e 616d 6520 3d20 2756 616c 7565  _x.name = 'Value
-00013720: 206f 6620 7468 6520 706f 7465 6e74 6961   of the potentia
-00013730: 6c20 6669 656c 6420 6174 2065 7665 7279  l field at every
-00013740: 2070 6f69 6e74 270d 0a0d 0a20 2020 2020   point'....     
-00013750: 2020 2069 6620 7374 7228 7379 732e 5f67     if str(sys._g
-00013760: 6574 6672 616d 6528 292e 665f 636f 6465  etframe().f_code
-00013770: 2e63 6f5f 6e61 6d65 2920 696e 2073 656c  .co_name) in sel
-00013780: 662e 7665 7262 6f73 653a 0d0a 2020 2020  f.verbose:..    
-00013790: 2020 2020 2020 2020 5a5f 7820 3d20 7468          Z_x = th
-000137a0: 6561 6e6f 2e70 7269 6e74 696e 672e 5072  eano.printing.Pr
-000137b0: 696e 7428 2750 6f74 656e 7469 616c 2066  int('Potential f
-000137c0: 6965 6c64 2061 7420 616c 6c20 706f 696e  ield at all poin
-000137d0: 7473 2729 285a 5f78 290d 0a0d 0a20 2020  ts')(Z_x)....   
-000137e0: 2020 2020 2072 6574 7572 6e20 5a5f 780d       return Z_x.
-000137f0: 0a0d 0a20 2020 2064 6566 2067 6574 5f73  ...    def get_s
-00013800: 6361 6c61 725f 6669 656c 645f 6174 5f73  calar_field_at_s
-00013810: 7572 6661 6365 5f70 6f69 6e74 7328 7365  urface_points(se
-00013820: 6c66 2c20 5a5f 782c 206e 7066 5f6f 703d  lf, Z_x, npf_op=
-00013830: 4e6f 6e65 293a 0d0a 2020 2020 2020 2020  None):..        
-00013840: 6966 206e 7066 5f6f 7020 6973 204e 6f6e  if npf_op is Non
-00013850: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00013860: 6e70 665f 6f70 203d 2073 656c 662e 6e70  npf_op = self.np
-00013870: 665f 6f70 0d0a 0d0a 2020 2020 2020 2020  f_op....        
-00013880: 6966 2027 6c65 6e5f 7069 6e74 7327 2069  if 'len_pints' i
-00013890: 6e20 7365 6c66 2e76 6572 626f 7365 3a0d  n self.verbose:.
-000138a0: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-000138b0: 662e 6c65 6e5f 706f 696e 7473 203d 2074  f.len_points = t
-000138c0: 6865 616e 6f2e 7072 696e 7469 6e67 2e50  heano.printing.P
-000138d0: 7269 6e74 2827 6c65 6e5f 706f 696e 7473  rint('len_points
-000138e0: 2729 2873 656c 662e 6c65 6e5f 706f 696e  ')(self.len_poin
-000138f0: 7473 290d 0a20 2020 2020 2020 2069 6620  ts)..        if 
-00013900: 276e 7066 5f6f 7027 2069 6e20 7365 6c66  'npf_op' in self
-00013910: 2e76 6572 626f 7365 3a0d 0a20 2020 2020  .verbose:..     
-00013920: 2020 2020 2020 206e 7066 5f6f 7020 3d20         npf_op = 
-00013930: 7468 6561 6e6f 2e70 7269 6e74 696e 672e  theano.printing.
-00013940: 5072 696e 7428 276e 7066 5f6f 7027 2928  Print('npf_op')(
-00013950: 6e70 665f 6f70 290d 0a20 2020 2020 2020  npf_op)..       
+00012d90: 2020 2020 2020 2020 2020 7469 6c65 645f            tiled_
+00012da0: 7765 6967 6874 735b 3a2c 203a 5d29 0d0a  weights[:, :])..
+00012db0: 2020 2020 2020 2020 2020 2020 665f 3120              f_1 
+00012dc0: 3d20 7365 6c66 2e63 6f6e 7472 6962 7574  = self.contribut
+00012dd0: 696f 6e5f 6661 756c 7473 2874 696c 6564  ion_faults(tiled
+00012de0: 5f77 6569 6768 7473 5b3a 2c20 3a5d 2c20  _weights[:, :], 
+00012df0: 612c 2062 2c20 6661 756c 745f 6d61 7472  a, b, fault_matr
+00012e00: 6978 290d 0a0d 0a20 2020 2020 2020 2020  ix)....         
+00012e10: 2020 2023 2041 6464 2061 6e20 6172 6269     # Add an arbi
+00012e20: 7472 6172 7920 6e75 6d62 6572 2061 7420  trary number at 
+00012e30: 7468 6520 706f 7465 6e74 6961 6c20 6669  the potential fi
+00012e40: 656c 6420 746f 2067 6574 2075 6e69 7175  eld to get uniqu
+00012e50: 6520 7661 6c75 6573 2066 6f72 2065 6163  e values for eac
+00012e60: 6820 6f66 2074 6865 6d0d 0a20 2020 2020  h of them..     
+00012e70: 2020 2020 2020 2070 6172 7469 616c 5f5a         partial_Z
+00012e80: 5f78 203d 2028 7369 676d 615f 305f 6772  _x = (sigma_0_gr
+00012e90: 6164 202b 2073 6967 6d61 5f30 5f69 6e74  ad + sigma_0_int
+00012ea0: 6572 6620 2b20 665f 3020 2b20 665f 3129  erf + f_0 + f_1)
+00012eb0: 0d0a 0d0a 2020 2020 2020 2020 5a5f 7820  ....        Z_x 
+00012ec0: 3d20 542e 7365 745f 7375 6274 656e 736f  = T.set_subtenso
+00012ed0: 7228 5a5f 785b 613a 625d 2c20 7061 7274  r(Z_x[a:b], part
+00012ee0: 6961 6c5f 5a5f 7829 0d0a 0d0a 2020 2020  ial_Z_x)....    
+00012ef0: 2020 2020 7265 7475 726e 205a 5f78 0d0a      return Z_x..
+00012f00: 0d0a 2020 2020 6465 6620 7363 616c 6172  ..    def scalar
+00012f10: 5f66 6965 6c64 5f61 745f 616c 6c28 7365  _field_at_all(se
+00012f20: 6c66 2c20 7765 6967 6874 732c 2067 7269  lf, weights, gri
+00012f30: 645f 7661 6c2c 2066 6175 6c74 5f6d 6174  d_val, fault_mat
+00012f40: 7269 7829 3a0d 0a20 2020 2020 2020 2022  rix):..        "
+00012f50: 2222 0d0a 2020 2020 2020 2020 436f 6d70  ""..        Comp
+00012f60: 7574 6520 7468 6520 706f 7465 6e74 6961  ute the potentia
+00012f70: 6c20 6669 656c 6420 6174 2061 6c6c 2074  l field at all t
+00012f80: 6865 2069 6e74 6572 706f 6c61 7469 6f6e  he interpolation
+00012f90: 2070 6f69 6e74 732c 2069 2e65 2e20 6772   points, i.e. gr
+00012fa0: 6964 2070 6c75 7320 7265 7374 2070 6c75  id plus rest plu
+00012fb0: 7320 7265 660d 0a20 2020 2020 2020 2052  s ref..        R
+00012fc0: 6574 7572 6e73 3a0d 0a20 2020 2020 2020  eturns:..       
+00012fd0: 2020 2020 2061 6573 6172 612e 7465 6e73       aesara.tens
+00012fe0: 6f72 2e76 6563 746f 723a 2050 6f74 656e  or.vector: Poten
+00012ff0: 7469 616c 2066 6965 6c64 7320 6174 2061  tial fields at a
+00013000: 6c6c 2070 6f69 6e74 730d 0a0d 0a20 2020  ll points....   
+00013010: 2020 2020 2022 2222 0d0a 2020 2020 2020       """..      
+00013020: 2020 230d 0a0d 0a20 2020 2020 2020 2067    #....        g
+00013030: 7269 645f 7368 6170 6520 3d20 542e 7374  rid_shape = T.st
+00013040: 6163 6b28 5b67 7269 645f 7661 6c2e 7368  ack([grid_val.sh
+00013050: 6170 655b 305d 5d2c 2061 7869 733d 3029  ape[0]], axis=0)
+00013060: 0d0a 2020 2020 2020 2020 5a5f 785f 696e  ..        Z_x_in
+00013070: 6974 203d 2054 2e7a 6572 6f73 2867 7269  it = T.zeros(gri
+00013080: 645f 7368 6170 6529 0d0a 2020 2020 2020  d_shape)..      
+00013090: 2020 6966 2027 6772 6964 5f73 6861 7065    if 'grid_shape
+000130a0: 2720 696e 2073 656c 662e 7665 7262 6f73  ' in self.verbos
+000130b0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+000130c0: 6772 6964 5f73 6861 7065 203d 2061 6573  grid_shape = aes
+000130d0: 6172 612e 7072 696e 7469 6e67 2e50 7269  ara.printing.Pri
+000130e0: 6e74 2827 6772 6964 5f73 6861 7065 2729  nt('grid_shape')
+000130f0: 2867 7269 645f 7368 6170 6529 0d0a 0d0a  (grid_shape)....
+00013100: 2020 2020 2020 2020 2320 4966 206d 656d          # If mem
+00013110: 6f72 7920 6572 726f 7273 2072 6564 7563  ory errors reduc
+00013120: 6520 7468 6973 2074 6f20 3131 0d0a 2020  e this to 11..  
+00013130: 2020 2020 2020 7374 6570 7320 3d20 3565        steps = 5e
+00013140: 3620 2f20 7365 6c66 2e6d 6174 7269 6365  6 / self.matrice
+00013150: 735f 7368 6170 6573 2829 5b2d 315d 2020  s_shapes()[-1]  
+00013160: 2320 2f20 6772 6964 5f73 6861 7065 0d0a  # / grid_shape..
+00013170: 2020 2020 2020 2020 6966 2027 7374 6570          if 'step
+00013180: 7327 2069 6e20 7365 6c66 2e76 6572 626f  s' in self.verbo
+00013190: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
+000131a0: 2073 7465 7073 203d 2061 6573 6172 612e   steps = aesara.
+000131b0: 7072 696e 7469 6e67 2e50 7269 6e74 2827  printing.Print('
+000131c0: 7374 6570 7327 2928 7374 6570 7329 0d0a  steps')(steps)..
+000131d0: 0d0a 2020 2020 2020 2020 736c 6963 6573  ..        slices
+000131e0: 203d 2054 2e63 6f6e 6361 7465 6e61 7465   = T.concatenate
+000131f0: 280d 0a20 2020 2020 2020 2020 2020 2028  (..            (
+00013200: 542e 6172 616e 6765 2830 2c20 6772 6964  T.arange(0, grid
+00013210: 5f73 6861 7065 5b30 5d2c 2073 7465 7073  _shape[0], steps
+00013220: 2c20 6474 7970 653d 2769 6e74 3634 2729  , dtype='int64')
+00013230: 2c20 6772 6964 5f73 6861 7065 2929 0d0a  , grid_shape))..
+00013240: 0d0a 2020 2020 2020 2020 6966 2027 736c  ..        if 'sl
+00013250: 6963 6573 2720 696e 2073 656c 662e 7665  ices' in self.ve
+00013260: 7262 6f73 653a 0d0a 2020 2020 2020 2020  rbose:..        
+00013270: 2020 2020 736c 6963 6573 203d 2061 6573      slices = aes
+00013280: 6172 612e 7072 696e 7469 6e67 2e50 7269  ara.printing.Pri
+00013290: 6e74 2827 736c 6963 6573 2729 2873 6c69  nt('slices')(sli
+000132a0: 6365 7329 0d0a 0d0a 2020 2020 2020 2020  ces)....        
+000132b0: 2320 4368 6563 6b20 6966 2077 6520 6c6f  # Check if we lo
+000132c0: 6f70 2074 6865 2067 7269 6420 6f72 206e  op the grid or n
+000132d0: 6f74 0d0a 2020 2020 2020 2020 6966 2073  ot..        if s
+000132e0: 656c 662e 7370 6172 7365 5f76 6572 7369  elf.sparse_versi
+000132f0: 6f6e 2069 7320 5472 7565 3a0d 0a20 2020  on is True:..   
+00013300: 2020 2020 2020 2020 2073 656c 662e 646f           self.do
+00013310: 745f 7665 7273 696f 6e20 3d20 5472 7565  t_version = True
+00013320: 0d0a 2020 2020 2020 2020 2020 2020 5a5f  ..            Z_
+00013330: 7820 3d20 7365 6c66 2e73 6361 6c61 725f  x = self.scalar_
+00013340: 6669 656c 645f 6c6f 6f70 2830 2c20 3130  field_loop(0, 10
+00013350: 3030 3030 3030 302c 205a 5f78 5f69 6e69  0000000, Z_x_ini
+00013360: 742c 2067 7269 645f 7661 6c2c 2077 6569  t, grid_val, wei
+00013370: 6768 7473 290d 0a0d 0a20 2020 2020 2020  ghts)....       
+00013380: 2065 6c69 6620 7365 6c66 2e6d 6178 5f73   elif self.max_s
+00013390: 7065 6564 203c 2032 3a0d 0a20 2020 2020  peed < 2:..     
+000133a0: 2020 2020 2020 2023 2074 696c 6564 5f77         # tiled_w
+000133b0: 6569 6768 7473 203d 2073 656c 662e 6578  eights = self.ex
+000133c0: 7465 6e64 5f64 7561 6c5f 6b72 6967 696e  tend_dual_krigin
+000133d0: 6728 7765 6967 6874 732c 2067 7269 645f  g(weights, grid_
+000133e0: 7661 6c2e 7368 6170 655b 305d 290d 0a20  val.shape[0]).. 
+000133f0: 2020 2020 2020 2020 2020 205a 5f78 5f6c             Z_x_l
+00013400: 6f6f 702c 2075 7064 6174 6573 3320 3d20  oop, updates3 = 
+00013410: 6165 7361 7261 2e73 6361 6e28 0d0a 2020  aesara.scan(..  
+00013420: 2020 2020 2020 2020 2020 2020 2020 666e                fn
+00013430: 3d73 656c 662e 7363 616c 6172 5f66 6965  =self.scalar_fie
+00013440: 6c64 5f6c 6f6f 702c 0d0a 2020 2020 2020  ld_loop,..      
+00013450: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+00013460: 735f 696e 666f 3d5b 5a5f 785f 696e 6974  s_info=[Z_x_init
+00013470: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+00013480: 2020 2020 7365 7175 656e 6365 733d 5b64      sequences=[d
+00013490: 6963 7428 696e 7075 743d 736c 6963 6573  ict(input=slices
+000134a0: 2c20 7461 7073 3d5b 302c 2031 5d29 5d2c  , taps=[0, 1])],
+000134b0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000134c0: 2020 6e6f 6e5f 7365 7175 656e 6365 733d    non_sequences=
+000134d0: 5b67 7269 645f 7661 6c2c 2077 6569 6768  [grid_val, weigh
+000134e0: 7473 2c20 6661 756c 745f 6d61 7472 6978  ts, fault_matrix
+000134f0: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+00013500: 2020 2020 7072 6f66 696c 653d 4661 6c73      profile=Fals
+00013510: 652c 0d0a 2020 2020 2020 2020 2020 2020  e,..            
+00013520: 2020 2020 6e61 6d65 3d27 4c6f 6f70 696e      name='Loopin
+00013530: 6720 6772 6964 272c 0d0a 2020 2020 2020  g grid',..      
+00013540: 2020 2020 2020 2020 2020 7265 7475 726e            return
+00013550: 5f6c 6973 743d 5472 7565 290d 0a0d 0a20  _list=True).... 
+00013560: 2020 2020 2020 2020 2020 205a 5f78 203d             Z_x =
+00013570: 205a 5f78 5f6c 6f6f 705b 2d31 5d5b 2d31   Z_x_loop[-1][-1
+00013580: 5d0d 0a20 2020 2020 2020 2065 6c73 653a  ]..        else:
+00013590: 0d0a 2020 2020 2020 2020 2020 2020 7469  ..            ti
+000135a0: 6c65 645f 7765 6967 6874 7320 3d20 7365  led_weights = se
+000135b0: 6c66 2e65 7874 656e 645f 6475 616c 5f6b  lf.extend_dual_k
+000135c0: 7269 6769 6e67 2877 6569 6768 7473 2c20  riging(weights, 
+000135d0: 6772 6964 5f76 616c 2e73 6861 7065 5b30  grid_val.shape[0
+000135e0: 5d29 0d0a 2020 2020 2020 2020 2020 2020  ])..            
+000135f0: 5a5f 7820 3d20 7365 6c66 2e73 6361 6c61  Z_x = self.scala
+00013600: 725f 6669 656c 645f 6c6f 6f70 2830 2c20  r_field_loop(0, 
+00013610: 3130 3030 3030 3030 302c 205a 5f78 5f69  100000000, Z_x_i
+00013620: 6e69 742c 2067 7269 645f 7661 6c2c 0d0a  nit, grid_val,..
+00013630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013640: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013650: 2020 2020 2020 2020 2074 696c 6564 5f77           tiled_w
+00013660: 6569 6768 7473 290d 0a0d 0a20 2020 2020  eights)....     
+00013670: 2020 205a 5f78 2e6e 616d 6520 3d20 2756     Z_x.name = 'V
+00013680: 616c 7565 206f 6620 7468 6520 706f 7465  alue of the pote
+00013690: 6e74 6961 6c20 6669 656c 6420 6174 2065  ntial field at e
+000136a0: 7665 7279 2070 6f69 6e74 270d 0a0d 0a20  very point'.... 
+000136b0: 2020 2020 2020 2069 6620 7374 7228 7379         if str(sy
+000136c0: 732e 5f67 6574 6672 616d 6528 292e 665f  s._getframe().f_
+000136d0: 636f 6465 2e63 6f5f 6e61 6d65 2920 696e  code.co_name) in
+000136e0: 2073 656c 662e 7665 7262 6f73 653a 0d0a   self.verbose:..
+000136f0: 2020 2020 2020 2020 2020 2020 5a5f 7820              Z_x 
+00013700: 3d20 6165 7361 7261 2e70 7269 6e74 696e  = aesara.printin
+00013710: 672e 5072 696e 7428 2750 6f74 656e 7469  g.Print('Potenti
+00013720: 616c 2066 6965 6c64 2061 7420 616c 6c20  al field at all 
+00013730: 706f 696e 7473 2729 285a 5f78 290d 0a0d  points')(Z_x)...
+00013740: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00013750: 5a5f 780d 0a0d 0a20 2020 2064 6566 2067  Z_x....    def g
+00013760: 6574 5f73 6361 6c61 725f 6669 656c 645f  et_scalar_field_
+00013770: 6174 5f73 7572 6661 6365 5f70 6f69 6e74  at_surface_point
+00013780: 7328 7365 6c66 2c20 5a5f 782c 206e 7066  s(self, Z_x, npf
+00013790: 5f6f 703d 4e6f 6e65 293a 0d0a 2020 2020  _op=None):..    
+000137a0: 2020 2020 6966 206e 7066 5f6f 7020 6973      if npf_op is
+000137b0: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
+000137c0: 2020 2020 6e70 665f 6f70 203d 2073 656c      npf_op = sel
+000137d0: 662e 6e70 665f 6f70 0d0a 0d0a 2020 2020  f.npf_op....    
+000137e0: 2020 2020 6966 2027 6c65 6e5f 7069 6e74      if 'len_pint
+000137f0: 7327 2069 6e20 7365 6c66 2e76 6572 626f  s' in self.verbo
+00013800: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
+00013810: 2073 656c 662e 6c65 6e5f 706f 696e 7473   self.len_points
+00013820: 203d 2061 6573 6172 612e 7072 696e 7469   = aesara.printi
+00013830: 6e67 2e50 7269 6e74 2827 6c65 6e5f 706f  ng.Print('len_po
+00013840: 696e 7473 2729 2873 656c 662e 6c65 6e5f  ints')(self.len_
+00013850: 706f 696e 7473 290d 0a20 2020 2020 2020  points)..       
+00013860: 2069 6620 276e 7066 5f6f 7027 2069 6e20   if 'npf_op' in 
+00013870: 7365 6c66 2e76 6572 626f 7365 3a0d 0a20  self.verbose:.. 
+00013880: 2020 2020 2020 2020 2020 206e 7066 5f6f             npf_o
+00013890: 7020 3d20 6165 7361 7261 2e70 7269 6e74  p = aesara.print
+000138a0: 696e 672e 5072 696e 7428 276e 7066 5f6f  ing.Print('npf_o
+000138b0: 7027 2928 6e70 665f 6f70 290d 0a20 2020  p')(npf_op)..   
+000138c0: 2020 2020 2073 6361 6c61 725f 6669 656c       scalar_fiel
+000138d0: 645f 6174 5f73 7572 6661 6365 5f70 6f69  d_at_surface_poi
+000138e0: 6e74 735f 7661 6c75 6573 203d 205c 0d0a  nts_values = \..
+000138f0: 2020 2020 2020 2020 2020 2020 5a5f 785b              Z_x[
+00013900: 2d32 202a 2073 656c 662e 6c65 6e5f 706f  -2 * self.len_po
+00013910: 696e 7473 3a20 2d73 656c 662e 6c65 6e5f  ints: -self.len_
+00013920: 706f 696e 7473 5d5b 6e70 665f 6f70 5d0d  points][npf_op].
+00013930: 0a20 2020 2020 2020 2069 6620 2773 6661  .        if 'sfa
+00013940: 6927 2069 6e20 7365 6c66 2e76 6572 626f  i' in self.verbo
+00013950: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
 00013960: 2073 6361 6c61 725f 6669 656c 645f 6174   scalar_field_at
 00013970: 5f73 7572 6661 6365 5f70 6f69 6e74 735f  _surface_points_
-00013980: 7661 6c75 6573 203d 205c 0d0a 2020 2020  values = \..    
-00013990: 2020 2020 2020 2020 5a5f 785b 2d32 202a          Z_x[-2 *
-000139a0: 2073 656c 662e 6c65 6e5f 706f 696e 7473   self.len_points
-000139b0: 3a20 2d73 656c 662e 6c65 6e5f 706f 696e  : -self.len_poin
-000139c0: 7473 5d5b 6e70 665f 6f70 5d0d 0a20 2020  ts][npf_op]..   
-000139d0: 2020 2020 2069 6620 2773 6661 6927 2069       if 'sfai' i
-000139e0: 6e20 7365 6c66 2e76 6572 626f 7365 3a0d  n self.verbose:.
-000139f0: 0a20 2020 2020 2020 2020 2020 2073 6361  .            sca
-00013a00: 6c61 725f 6669 656c 645f 6174 5f73 7572  lar_field_at_sur
-00013a10: 6661 6365 5f70 6f69 6e74 735f 7661 6c75  face_points_valu
-00013a20: 6573 203d 2074 6865 616e 6f2e 7072 696e  es = theano.prin
-00013a30: 7469 6e67 2e50 7269 6e74 2827 7366 6169  ting.Print('sfai
-00013a40: 2729 280d 0a20 2020 2020 2020 2020 2020  ')(..           
-00013a50: 2020 2020 2073 6361 6c61 725f 6669 656c       scalar_fiel
-00013a60: 645f 6174 5f73 7572 6661 6365 5f70 6f69  d_at_surface_poi
-00013a70: 6e74 735f 7661 6c75 6573 290d 0a0d 0a20  nts_values).... 
-00013a80: 2020 2020 2020 2072 6574 7572 6e20 7363         return sc
-00013a90: 616c 6172 5f66 6965 6c64 5f61 745f 7375  alar_field_at_su
-00013aa0: 7266 6163 655f 706f 696e 7473 5f76 616c  rface_points_val
-00013ab0: 7565 730d 0a0d 0a20 2020 2023 2065 6e64  ues....    # end
-00013ac0: 7265 6769 6f6e 0d0a 0d0a 2020 2020 2320  region....    # 
-00013ad0: 7265 6769 6f6e 2042 6c6f 636b 2065 7870  region Block exp
-00013ae0: 6f72 740d 0a20 2020 2064 6566 2073 656c  ort..    def sel
-00013af0: 6563 745f 6669 6e69 7465 5f66 6175 6c74  ect_finite_fault
-00013b00: 7328 7365 6c66 2c20 6772 6964 293a 0d0a  s(self, grid):..
-00013b10: 2020 2020 2020 2020 6661 756c 745f 706f          fault_po
-00013b20: 696e 7473 203d 2054 2e76 6572 7469 6361  ints = T.vertica
-00013b30: 6c5f 7374 6163 6b28 542e 7374 6163 6b28  l_stack(T.stack(
-00013b40: 5b73 656c 662e 7265 665f 6c61 7965 725f  [self.ref_layer_
-00013b50: 706f 696e 7473 5b30 5d5d 2c20 6178 6973  points[0]], axis
-00013b60: 3d30 292c 0d0a 2020 2020 2020 2020 2020  =0),..          
-00013b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013b80: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00013b90: 6c66 2e72 6573 745f 6c61 7965 725f 706f  lf.rest_layer_po
-00013ba0: 696e 7473 292e 540d 0a20 2020 2020 2020  ints).T..       
-00013bb0: 2063 7472 203d 2054 2e6d 6561 6e28 6661   ctr = T.mean(fa
-00013bc0: 756c 745f 706f 696e 7473 2c20 6178 6973  ult_points, axis
-00013bd0: 3d31 290d 0a20 2020 2020 2020 2078 203d  =1)..        x =
-00013be0: 2066 6175 6c74 5f70 6f69 6e74 7320 2d20   fault_points - 
-00013bf0: 6374 722e 7265 7368 6170 6528 282d 312c  ctr.reshape((-1,
-00013c00: 2031 2929 0d0a 2020 2020 2020 2020 4d20   1))..        M 
-00013c10: 3d20 542e 646f 7428 782c 2078 2e54 290d  = T.dot(x, x.T).
-00013c20: 0a20 2020 2020 2020 2055 2c20 442c 2056  .        U, D, V
-00013c30: 203d 2054 2e6e 6c69 6e61 6c67 2e73 7664   = T.nlinalg.svd
-00013c40: 284d 290d 0a20 2020 2020 2020 2072 6f74  (M)..        rot
-00013c50: 6174 6564 5f78 203d 2054 2e64 6f74 2854  ated_x = T.dot(T
-00013c60: 2e64 6f74 2867 7269 642c 2055 292c 2056  .dot(grid, U), V
-00013c70: 290d 0a20 2020 2020 2020 2072 6f74 6174  )..        rotat
-00013c80: 6564 5f66 6175 6c74 5f70 6f69 6e74 7320  ed_fault_points 
-00013c90: 3d20 542e 646f 7428 542e 646f 7428 6661  = T.dot(T.dot(fa
-00013ca0: 756c 745f 706f 696e 7473 2e54 2c20 5529  ult_points.T, U)
-00013cb0: 2c20 5629 0d0a 2020 2020 2020 2020 726f  , V)..        ro
-00013cc0: 7461 7465 645f 6374 7220 3d20 542e 6d65  tated_ctr = T.me
-00013cd0: 616e 2872 6f74 6174 6564 5f66 6175 6c74  an(rotated_fault
-00013ce0: 5f70 6f69 6e74 732c 2061 7869 733d 3029  _points, axis=0)
-00013cf0: 0d0a 2020 2020 2020 2020 615f 7261 6469  ..        a_radi
-00013d00: 7573 203d 2028 726f 7461 7465 645f 6661  us = (rotated_fa
-00013d10: 756c 745f 706f 696e 7473 5b3a 2c20 305d  ult_points[:, 0]
-00013d20: 2e6d 6178 2829 202d 2072 6f74 6174 6564  .max() - rotated
-00013d30: 5f66 6175 6c74 5f70 6f69 6e74 735b 3a2c  _fault_points[:,
-00013d40: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00013980: 7661 6c75 6573 203d 2061 6573 6172 612e  values = aesara.
+00013990: 7072 696e 7469 6e67 2e50 7269 6e74 2827  printing.Print('
+000139a0: 7366 6169 2729 280d 0a20 2020 2020 2020  sfai')(..       
+000139b0: 2020 2020 2020 2020 2073 6361 6c61 725f           scalar_
+000139c0: 6669 656c 645f 6174 5f73 7572 6661 6365  field_at_surface
+000139d0: 5f70 6f69 6e74 735f 7661 6c75 6573 290d  _points_values).
+000139e0: 0a0d 0a20 2020 2020 2020 2072 6574 7572  ...        retur
+000139f0: 6e20 7363 616c 6172 5f66 6965 6c64 5f61  n scalar_field_a
+00013a00: 745f 7375 7266 6163 655f 706f 696e 7473  t_surface_points
+00013a10: 5f76 616c 7565 730d 0a0d 0a20 2020 2023  _values....    #
+00013a20: 2065 6e64 7265 6769 6f6e 0d0a 0d0a 2020   endregion....  
+00013a30: 2020 2320 7265 6769 6f6e 2042 6c6f 636b    # region Block
+00013a40: 2065 7870 6f72 740d 0a20 2020 2064 6566   export..    def
+00013a50: 2073 656c 6563 745f 6669 6e69 7465 5f66   select_finite_f
+00013a60: 6175 6c74 7328 7365 6c66 2c20 6772 6964  aults(self, grid
+00013a70: 293a 0d0a 2020 2020 2020 2020 6661 756c  ):..        faul
+00013a80: 745f 706f 696e 7473 203d 2054 2e76 6572  t_points = T.ver
+00013a90: 7469 6361 6c5f 7374 6163 6b28 542e 7374  tical_stack(T.st
+00013aa0: 6163 6b28 5b73 656c 662e 7265 665f 6c61  ack([self.ref_la
+00013ab0: 7965 725f 706f 696e 7473 5b30 5d5d 2c20  yer_points[0]], 
+00013ac0: 6178 6973 3d30 292c 0d0a 2020 2020 2020  axis=0),..      
+00013ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013af0: 2020 7365 6c66 2e72 6573 745f 6c61 7965    self.rest_laye
+00013b00: 725f 706f 696e 7473 292e 540d 0a20 2020  r_points).T..   
+00013b10: 2020 2020 2063 7472 203d 2054 2e6d 6561       ctr = T.mea
+00013b20: 6e28 6661 756c 745f 706f 696e 7473 2c20  n(fault_points, 
+00013b30: 6178 6973 3d31 290d 0a20 2020 2020 2020  axis=1)..       
+00013b40: 2078 203d 2066 6175 6c74 5f70 6f69 6e74   x = fault_point
+00013b50: 7320 2d20 6374 722e 7265 7368 6170 6528  s - ctr.reshape(
+00013b60: 282d 312c 2031 2929 0d0a 2020 2020 2020  (-1, 1))..      
+00013b70: 2020 4d20 3d20 542e 646f 7428 782c 2078    M = T.dot(x, x
+00013b80: 2e54 290d 0a20 2020 2020 2020 2055 2c20  .T)..        U, 
+00013b90: 442c 2056 203d 2054 2e6e 6c69 6e61 6c67  D, V = T.nlinalg
+00013ba0: 2e73 7664 284d 290d 0a20 2020 2020 2020  .svd(M)..       
+00013bb0: 2072 6f74 6174 6564 5f78 203d 2054 2e64   rotated_x = T.d
+00013bc0: 6f74 2854 2e64 6f74 2867 7269 642c 2055  ot(T.dot(grid, U
+00013bd0: 292c 2056 290d 0a20 2020 2020 2020 2072  ), V)..        r
+00013be0: 6f74 6174 6564 5f66 6175 6c74 5f70 6f69  otated_fault_poi
+00013bf0: 6e74 7320 3d20 542e 646f 7428 542e 646f  nts = T.dot(T.do
+00013c00: 7428 6661 756c 745f 706f 696e 7473 2e54  t(fault_points.T
+00013c10: 2c20 5529 2c20 5629 0d0a 2020 2020 2020  , U), V)..      
+00013c20: 2020 726f 7461 7465 645f 6374 7220 3d20    rotated_ctr = 
+00013c30: 542e 6d65 616e 2872 6f74 6174 6564 5f66  T.mean(rotated_f
+00013c40: 6175 6c74 5f70 6f69 6e74 732c 2061 7869  ault_points, axi
+00013c50: 733d 3029 0d0a 2020 2020 2020 2020 615f  s=0)..        a_
+00013c60: 7261 6469 7573 203d 2028 726f 7461 7465  radius = (rotate
+00013c70: 645f 6661 756c 745f 706f 696e 7473 5b3a  d_fault_points[:
+00013c80: 2c20 305d 2e6d 6178 2829 202d 2072 6f74  , 0].max() - rot
+00013c90: 6174 6564 5f66 6175 6c74 5f70 6f69 6e74  ated_fault_point
+00013ca0: 735b 3a2c 0d0a 2020 2020 2020 2020 2020  s[:,..          
+00013cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013cd0: 2020 2020 2020 2020 2020 2020 2030 5d2e               0].
+00013ce0: 6d69 6e28 2929 202f 2032 0d0a 2020 2020  min()) / 2..    
+00013cf0: 2020 2020 625f 7261 6469 7573 203d 2028      b_radius = (
+00013d00: 726f 7461 7465 645f 6661 756c 745f 706f  rotated_fault_po
+00013d10: 696e 7473 5b3a 2c20 315d 2e6d 6178 2829  ints[:, 1].max()
+00013d20: 202d 2072 6f74 6174 6564 5f66 6175 6c74   - rotated_fault
+00013d30: 5f70 6f69 6e74 735b 3a2c 0d0a 2020 2020  _points[:,..    
+00013d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00013d50: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00013d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013d70: 2020 2020 2020 2020 2030 5d2e 6d69 6e28           0].min(
-00013d80: 2929 202f 2032 0d0a 2020 2020 2020 2020  )) / 2..        
-00013d90: 625f 7261 6469 7573 203d 2028 726f 7461  b_radius = (rota
-00013da0: 7465 645f 6661 756c 745f 706f 696e 7473  ted_fault_points
-00013db0: 5b3a 2c20 315d 2e6d 6178 2829 202d 2072  [:, 1].max() - r
-00013dc0: 6f74 6174 6564 5f66 6175 6c74 5f70 6f69  otated_fault_poi
-00013dd0: 6e74 735b 3a2c 0d0a 2020 2020 2020 2020  nts[:,..        
+00013d70: 2020 2031 5d2e 6d69 6e28 2929 202f 2032     1].min()) / 2
+00013d80: 0d0a 0d0a 2020 2020 2020 2020 656c 6c69  ....        elli
+00013d90: 7073 655f 6661 6374 6f72 203d 2028 726f  pse_factor = (ro
+00013da0: 7461 7465 645f 785b 3a2c 2030 5d20 2d20  tated_x[:, 0] - 
+00013db0: 726f 7461 7465 645f 6374 725b 305d 2920  rotated_ctr[0]) 
+00013dc0: 2a2a 2032 202f 2061 5f72 6164 6975 7320  ** 2 / a_radius 
+00013dd0: 2a2a 2032 202b 205c 0d0a 2020 2020 2020  ** 2 + \..      
 00013de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013df0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013e00: 2020 2020 2020 2020 2020 2020 2020 2031                 1
-00013e10: 5d2e 6d69 6e28 2929 202f 2032 0d0a 0d0a  ].min()) / 2....
-00013e20: 2020 2020 2020 2020 656c 6c69 7073 655f          ellipse_
-00013e30: 6661 6374 6f72 203d 2028 726f 7461 7465  factor = (rotate
-00013e40: 645f 785b 3a2c 2030 5d20 2d20 726f 7461  d_x[:, 0] - rota
-00013e50: 7465 645f 6374 725b 305d 2920 2a2a 2032  ted_ctr[0]) ** 2
-00013e60: 202f 2061 5f72 6164 6975 7320 2a2a 2032   / a_radius ** 2
-00013e70: 202b 205c 0d0a 2020 2020 2020 2020 2020   + \..          
-00013e80: 2020 2020 2020 2020 2020 2020 2020 2028                 (
-00013e90: 726f 7461 7465 645f 785b 3a2c 2031 5d20  rotated_x[:, 1] 
-00013ea0: 2d20 726f 7461 7465 645f 6374 725b 315d  - rotated_ctr[1]
-00013eb0: 2920 2a2a 2032 202f 2062 5f72 6164 6975  ) ** 2 / b_radiu
-00013ec0: 7320 2a2a 2032 0d0a 0d0a 2020 2020 2020  s ** 2....      
-00013ed0: 2020 6966 2022 7365 6c65 6374 5f66 696e    if "select_fin
-00013ee0: 6974 655f 6661 756c 7473 2220 696e 2073  ite_faults" in s
-00013ef0: 656c 662e 7665 7262 6f73 653a 0d0a 2020  elf.verbose:..  
-00013f00: 2020 2020 2020 2020 2020 656c 6c69 7073            ellips
-00013f10: 655f 6661 6374 6f72 203d 2074 6865 616e  e_factor = thean
-00013f20: 6f2e 7072 696e 7469 6e67 2e50 7269 6e74  o.printing.Print
-00013f30: 2822 6822 2928 656c 6c69 7073 655f 6661  ("h")(ellipse_fa
-00013f40: 6374 6f72 290d 0a0d 0a20 2020 2020 2020  ctor)....       
-00013f50: 2072 6574 7572 6e20 656c 6c69 7073 655f   return ellipse_
-00013f60: 6661 6374 6f72 0d0a 0d0a 2020 2020 6465  factor....    de
-00013f70: 6620 636f 6d70 6172 6528 7365 6c66 2c20  f compare(self, 
-00013f80: 612c 2062 2c20 736c 6963 655f 696e 6974  a, b, slice_init
-00013f90: 2c20 5a5f 782c 206c 2c20 6e5f 7375 7266  , Z_x, l, n_surf
-00013fa0: 6163 652c 2064 7269 6674 293a 0d0a 2020  ace, drift):..  
-00013fb0: 2020 2020 2020 2222 220d 0a20 2020 2020        """..     
-00013fc0: 2020 2054 7265 7368 6f6c 6420 6f66 2074     Treshold of t
-00013fd0: 6865 2070 6f69 6e74 7320 746f 2069 6e74  he points to int
-00013fe0: 6572 706f 6c61 7465 2067 6976 656e 2032  erpolate given 2
-00013ff0: 2070 6f74 656e 7469 616c 2066 6965 6c64   potential field
-00014000: 2076 616c 7565 732e 2054 4f44 4f3a 2054   values. TODO: T
-00014010: 6869 7320 6675 6e63 7469 6f6e 2069 7320  his function is 
-00014020: 7468 6520 6f6e 6520 7765 0d0a 2020 2020  the one we..    
-00014030: 2020 2020 6e65 6564 2074 6f20 6368 616e      need to chan
-00014040: 6765 2066 6f72 2061 2073 6967 6d6f 6964  ge for a sigmoid
-00014050: 2066 756e 6374 696f 6e0d 0a0d 0a20 2020   function....   
-00014060: 2020 2020 2041 7267 733a 0d0a 2020 2020       Args:..    
-00014070: 2020 2020 2020 2020 6120 2873 6361 6c61          a (scala
-00014080: 7229 3a20 5570 7065 7220 6c69 6d69 7420  r): Upper limit 
-00014090: 6f66 2074 6865 2070 6f74 656e 7469 616c  of the potential
-000140a0: 2066 6965 6c64 0d0a 2020 2020 2020 2020   field..        
-000140b0: 2020 2020 6220 2873 6361 6c61 7229 3a20      b (scalar): 
-000140c0: 4c6f 7765 7220 6c69 6d69 7420 6f66 2074  Lower limit of t
-000140d0: 6865 2070 6f74 656e 7469 616c 2066 6965  he potential fie
-000140e0: 6c64 0d0a 2020 2020 2020 2020 2020 2020  ld..            
-000140f0: 6e5f 7375 7266 6163 6520 2873 6361 6c61  n_surface (scala
-00014100: 7229 3a20 5661 6c75 6520 6769 7665 6e20  r): Value given 
-00014110: 746f 2074 6865 2073 6567 6d65 6e74 6174  to the segmentat
-00014120: 696f 6e2c 2069 2e65 2e20 6c69 7468 6f6c  ion, i.e. lithol
-00014130: 6f67 7920 6e75 6d62 6572 0d0a 2020 2020  ogy number..    
-00014140: 2020 2020 2020 2020 5a78 2028 7665 6374          Zx (vect
-00014150: 6f72 293a 2050 6f74 656e 7469 616c 2066  or): Potential f
-00014160: 6965 6c64 2076 616c 7565 7320 6174 2061  ield values at a
-00014170: 6c6c 2074 6865 2069 6e74 6572 706f 6c61  ll the interpola
-00014180: 7465 6420 706f 696e 7473 0d0a 0d0a 2020  ted points....  
-00014190: 2020 2020 2020 5265 7475 726e 733a 0d0a        Returns:..
-000141a0: 2020 2020 2020 2020 2020 2020 7468 6561              thea
-000141b0: 6e6f 2e74 656e 736f 722e 7665 6374 6f72  no.tensor.vector
-000141c0: 3a20 7365 676d 656e 7465 6420 7661 6c75  : segmented valu
-000141d0: 6573 0d0a 2020 2020 2020 2020 2222 220d  es..        """.
-000141e0: 0a0d 0a20 2020 2020 2020 2073 6c69 6365  ...        slice
-000141f0: 5f69 6e69 7420 3d20 736c 6963 655f 696e  _init = slice_in
-00014200: 6974 0d0a 2020 2020 2020 2020 6e5f 7375  it..        n_su
-00014210: 7266 6163 655f 3020 3d20 6e5f 7375 7266  rface_0 = n_surf
-00014220: 6163 655b 3a2c 2073 6c69 6365 5f69 6e69  ace[:, slice_ini
-00014230: 743a 736c 6963 655f 696e 6974 202b 2031  t:slice_init + 1
-00014240: 5d0d 0a20 2020 2020 2020 206e 5f73 7572  ]..        n_sur
-00014250: 6661 6365 5f31 203d 206e 5f73 7572 6661  face_1 = n_surfa
-00014260: 6365 5b3a 2c20 736c 6963 655f 696e 6974  ce[:, slice_init
-00014270: 202b 2031 3a73 6c69 6365 5f69 6e69 7420   + 1:slice_init 
-00014280: 2b20 325d 0d0a 2020 2020 2020 2020 6472  + 2]..        dr
-00014290: 6966 7420 3d20 6472 6966 745b 3a2c 2073  ift = drift[:, s
-000142a0: 6c69 6365 5f69 6e69 743a 736c 6963 655f  lice_init:slice_
-000142b0: 696e 6974 202b 2031 5d0d 0a0d 0a20 2020  init + 1]....   
-000142c0: 2020 2020 2069 6620 2763 6f6d 7061 7265       if 'compare
-000142d0: 2720 696e 2073 656c 662e 7665 7262 6f73  ' in self.verbos
-000142e0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-000142f0: 6120 3d20 7468 6561 6e6f 2e70 7269 6e74  a = theano.print
-00014300: 696e 672e 5072 696e 7428 2261 2229 2861  ing.Print("a")(a
-00014310: 290d 0a20 2020 2020 2020 2020 2020 2062  )..            b
-00014320: 203d 2074 6865 616e 6f2e 7072 696e 7469   = theano.printi
-00014330: 6e67 2e50 7269 6e74 2822 6222 2928 6229  ng.Print("b")(b)
-00014340: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
-00014350: 6c20 3d20 3230 302f 2028 6120 2d20 6229  l = 200/ (a - b)
-00014360: 0d0a 2020 2020 2020 2020 2020 2020 736c  ..            sl
-00014370: 6963 655f 696e 6974 203d 2074 6865 616e  ice_init = thean
-00014380: 6f2e 7072 696e 7469 6e67 2e50 7269 6e74  o.printing.Print
-00014390: 2822 736c 6963 655f 696e 6974 2229 2873  ("slice_init")(s
-000143a0: 6c69 6365 5f69 6e69 7429 0d0a 2020 2020  lice_init)..    
-000143b0: 2020 2020 2020 2020 6e5f 7375 7266 6163          n_surfac
-000143c0: 655f 3020 3d20 7468 6561 6e6f 2e70 7269  e_0 = theano.pri
-000143d0: 6e74 696e 672e 5072 696e 7428 226e 5f73  nting.Print("n_s
-000143e0: 7572 6661 6365 5f30 2229 286e 5f73 7572  urface_0")(n_sur
-000143f0: 6661 6365 5f30 290d 0a20 2020 2020 2020  face_0)..       
-00014400: 2020 2020 206e 5f73 7572 6661 6365 5f31       n_surface_1
-00014410: 203d 2074 6865 616e 6f2e 7072 696e 7469   = theano.printi
-00014420: 6e67 2e50 7269 6e74 2822 6e5f 7375 7266  ng.Print("n_surf
-00014430: 6163 655f 3122 2928 6e5f 7375 7266 6163  ace_1")(n_surfac
-00014440: 655f 3129 0d0a 2020 2020 2020 2020 2020  e_1)..          
-00014450: 2020 6472 6966 7420 3d20 7468 6561 6e6f    drift = theano
-00014460: 2e70 7269 6e74 696e 672e 5072 696e 7428  .printing.Print(
-00014470: 2264 7269 6674 5b73 6c69 6365 5f69 6e69  "drift[slice_ini
-00014480: 743a 736c 6963 655f 696e 6974 2b31 5d5b  t:slice_init+1][
-00014490: 305d 2229 2864 7269 6674 290d 0a0d 0a20  0]")(drift).... 
-000144a0: 2020 2020 2020 2023 2054 6865 2035 2072         # The 5 r
-000144b0: 756c 6573 2074 6865 2073 6c6f 7065 206f  ules the slope o
-000144c0: 6620 7468 6520 6675 6e63 7469 6f6e 0d0a  f the function..
-000144d0: 2020 2020 2020 2020 7369 676d 203d 2028          sigm = (
-000144e0: 2d6e 5f73 7572 6661 6365 5f30 2e72 6573  -n_surface_0.res
-000144f0: 6861 7065 2828 2d31 2c20 3129 2920 2f20  hape((-1, 1)) / 
-00014500: 2831 202b 2054 2e65 7870 282d 6c20 2a20  (1 + T.exp(-l * 
-00014510: 285a 5f78 202d 2061 2929 2929 205c 0d0a  (Z_x - a)))) \..
-00014520: 2020 2020 2020 2020 2020 2020 2020 202d                 -
-00014530: 2028 6e5f 7375 7266 6163 655f 312e 7265   (n_surface_1.re
-00014540: 7368 6170 6528 282d 312c 2031 2929 202f  shape((-1, 1)) /
-00014550: 2028 3120 2b20 542e 6578 7028 6c20 2a20   (1 + T.exp(l * 
-00014560: 285a 5f78 202d 2062 2929 2929 202b 2064  (Z_x - b)))) + d
-00014570: 7269 6674 2e72 6573 6861 7065 2828 2d31  rift.reshape((-1
-00014580: 2c20 3129 290d 0a20 2020 2020 2020 2069  , 1))..        i
-00014590: 6620 2773 6967 6d61 2720 696e 2073 656c  f 'sigma' in sel
-000145a0: 662e 7665 7262 6f73 653a 0d0a 2020 2020  f.verbose:..    
-000145b0: 2020 2020 2020 2020 7369 676d 203d 2074          sigm = t
-000145c0: 6865 616e 6f2e 7072 696e 7469 6e67 2e50  heano.printing.P
-000145d0: 7269 6e74 2822 6d69 6464 6c65 2070 6f69  rint("middle poi
-000145e0: 6e74 2229 2873 6967 6d29 0d0a 2020 2020  nt")(sigm)..    
-000145f0: 2020 2020 7265 7475 726e 2073 6967 6d0d      return sigm.
-00014600: 0a0d 0a20 2020 2064 6566 2065 7870 6f72  ...    def expor
-00014610: 745f 6661 756c 745f 626c 6f63 6b28 7365  t_fault_block(se
-00014620: 6c66 2c20 5a5f 782c 2073 6361 6c61 725f  lf, Z_x, scalar_
-00014630: 6669 656c 645f 6174 5f73 7572 6661 6365  field_at_surface
-00014640: 5f70 6f69 6e74 732c 0d0a 2020 2020 2020  _points,..      
-00014650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014660: 2020 2020 2076 616c 7565 735f 7072 6f70       values_prop
-00014670: 6572 7469 6573 5f6f 702c 2066 696e 6974  erties_op, finit
-00014680: 655f 6661 756c 7473 5f73 656c 2c0d 0a20  e_faults_sel,.. 
-00014690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000146a0: 2020 2020 2020 2020 2020 736c 6f70 653d            slope=
-000146b0: 3530 2c20 6f66 6673 6574 5f73 6c6f 7065  50, offset_slope
-000146c0: 3d39 3530 293a 0d0a 2020 2020 2020 2020  =950):..        
-000146d0: 2222 220d 0a20 2020 2020 2020 2043 6f6d  """..        Com
-000146e0: 7075 7465 2074 6865 2070 6172 7420 6f66  pute the part of
-000146f0: 2074 6865 2062 6c6f 636b 206d 6f64 656c   the block model
-00014700: 206f 6620 6120 6769 7665 6e20 7365 7269   of a given seri
-00014710: 6573 2028 6469 6374 6174 6564 2062 7920  es (dictated by 
-00014720: 7468 6520 626f 6f6c 2061 7272 6179 2079  the bool array y
-00014730: 6574 2074 6f20 6265 2063 6f6d 7075 7465  et to be compute
-00014740: 6429 0d0a 0d0a 2020 2020 2020 2020 5265  d)....        Re
-00014750: 7475 726e 733a 0d0a 2020 2020 2020 2020  turns:..        
-00014760: 2020 2020 7468 6561 6e6f 2e74 656e 736f      theano.tenso
-00014770: 722e 7665 6374 6f72 3a20 5661 6c75 6520  r.vector: Value 
-00014780: 6f66 206c 6974 686f 6c6f 6779 2061 7420  of lithology at 
-00014790: 6576 6572 7920 696e 7465 7270 6f6c 6174  every interpolat
-000147a0: 6564 2070 6f69 6e74 0d0a 2020 2020 2020  ed point..      
-000147b0: 2020 2222 220d 0a0d 0a20 2020 2020 2020    """....       
-000147c0: 2023 2069 6620 5a5f 7820 6973 204e 6f6e   # if Z_x is Non
-000147d0: 653a 0d0a 2020 2020 2020 2020 2320 2020  e:..        #   
-000147e0: 2020 5a5f 7820 3d20 7365 6c66 2e5a 5f78    Z_x = self.Z_x
-000147f0: 0d0a 0d0a 2020 2020 2020 2020 2320 4d61  ....        # Ma
-00014800: 7820 616e 6420 6d69 6e20 7661 6c75 6573  x and min values
-00014810: 206f 6620 7468 6520 706f 7465 6e74 6961   of the potentia
-00014820: 6c20 6669 656c 642e 0d0a 2020 2020 2020  l field...      
-00014830: 2020 2320 6d61 785f 706f 7420 3d20 542e    # max_pot = T.
-00014840: 6d61 7828 5a5f 7829 202b 2031 0d0a 2020  max(Z_x) + 1..  
-00014850: 2020 2020 2020 2320 6d69 6e5f 706f 7420        # min_pot 
-00014860: 3d20 542e 6d69 6e28 5a5f 7829 202d 2031  = T.min(Z_x) - 1
-00014870: 0d0a 2020 2020 2020 2020 2320 6d61 785f  ..        # max_
-00014880: 706f 7420 2b3d 206d 6178 5f70 6f74 202a  pot += max_pot *
-00014890: 2030 2e31 0d0a 2020 2020 2020 2020 2320   0.1..        # 
-000148a0: 6d69 6e5f 706f 7420 2d3d 206d 696e 5f70  min_pot -= min_p
-000148b0: 6f74 202a 2030 2e31 0d0a 0d0a 2020 2020  ot * 0.1....    
-000148c0: 2020 2020 2320 5661 6c75 6520 6f66 2074      # Value of t
-000148d0: 6865 2070 6f74 656e 7469 616c 2066 6965  he potential fie
-000148e0: 6c64 2061 7420 7468 6520 7375 7266 6163  ld at the surfac
-000148f0: 655f 706f 696e 7473 206f 6620 7468 6520  e_points of the 
-00014900: 636f 6d70 7574 6564 2073 6572 6965 730d  computed series.
-00014910: 0a20 2020 2020 2020 2023 2054 4f44 4f20  .        # TODO 
-00014920: 7469 6d65 6974 2e20 4920 7468 696e 6b20  timeit. I think 
-00014930: 7468 650d 0a20 2020 2020 2020 206d 6178  the..        max
-00014940: 5f70 6f74 203d 2054 2e6d 6178 285a 5f78  _pot = T.max(Z_x
-00014950: 290d 0a20 2020 2020 2020 2023 206d 6178  )..        # max
-00014960: 5f70 6f74 203d 2074 6865 616e 6f2e 7072  _pot = theano.pr
-00014970: 696e 7469 6e67 2e50 7269 6e74 2822 6d61  inting.Print("ma
-00014980: 785f 706f 7422 2928 6d61 785f 706f 7429  x_pot")(max_pot)
-00014990: 0d0a 0d0a 2020 2020 2020 2020 6d69 6e5f  ....        min_
-000149a0: 706f 7420 3d20 542e 6d69 6e28 5a5f 7829  pot = T.min(Z_x)
-000149b0: 0d0a 2020 2020 2020 2020 2320 2020 2020  ..        #     
-000149c0: 6d69 6e5f 706f 7420 3d20 7468 6561 6e6f  min_pot = theano
-000149d0: 2e70 7269 6e74 696e 672e 5072 696e 7428  .printing.Print(
-000149e0: 226d 696e 5f70 6f74 2229 286d 696e 5f70  "min_pot")(min_p
-000149f0: 6f74 290d 0a0d 0a20 2020 2020 2020 2023  ot)....        #
-00014a00: 206d 6178 5f70 6f74 5f73 6967 6d20 3d20   max_pot_sigm = 
-00014a10: 3220 2a20 6d61 785f 706f 7420 2d20 7365  2 * max_pot - se
-00014a20: 6c66 2e73 6361 6c61 725f 6669 656c 645f  lf.scalar_field_
-00014a30: 6174 5f73 7572 6661 6365 5f70 6f69 6e74  at_surface_point
-00014a40: 735f 7661 6c75 6573 5b30 5d0d 0a20 2020  s_values[0]..   
-00014a50: 2020 2020 2023 206d 696e 5f70 6f74 5f73       # min_pot_s
-00014a60: 6967 6d20 3d20 3220 2a20 6d69 6e5f 706f  igm = 2 * min_po
-00014a70: 7420 2d20 7365 6c66 2e73 6361 6c61 725f  t - self.scalar_
-00014a80: 6669 656c 645f 6174 5f73 7572 6661 6365  field_at_surface
-00014a90: 5f70 6f69 6e74 735f 7661 6c75 6573 5b2d  _points_values[-
-00014aa0: 315d 0d0a 0d0a 2020 2020 2020 2020 626f  1]....        bo
-00014ab0: 756e 6461 7279 5f70 6164 203d 2028 6d61  undary_pad = (ma
-00014ac0: 785f 706f 7420 2d20 6d69 6e5f 706f 7429  x_pot - min_pot)
-00014ad0: 202a 2030 2e30 310d 0a20 2020 2020 2020   * 0.01..       
-00014ae0: 2023 206c 203d 2073 6c6f 7065 202f 2028   # l = slope / (
-00014af0: 6d61 785f 706f 7420 2d20 6d69 6e5f 706f  max_pot - min_po
-00014b00: 7429 2020 2320 286d 6178 5f70 6f74 202d  t)  # (max_pot -
-00014b10: 206d 696e 5f70 6f74 290d 0a0d 0a20 2020   min_pot)....   
-00014b20: 2020 2020 2023 2054 6869 7320 6973 2074       # This is t
-00014b30: 6865 2064 6966 6665 7265 6e74 206c 696e  he different lin
-00014b40: 6520 7769 7468 2072 6573 7065 6374 206c  e with respect l
-00014b50: 6179 6572 730d 0a20 2020 2020 2020 2023  ayers..        #
-00014b60: 206c 203d 2054 2e73 7769 7463 6828 6669   l = T.switch(fi
-00014b70: 6e69 7465 5f66 6175 6c74 735f 7365 6c2c  nite_faults_sel,
-00014b80: 206f 6666 7365 745f 736c 6f70 6520 2f20   offset_slope / 
-00014b90: 286d 6178 5f70 6f74 202d 206d 696e 5f70  (max_pot - min_p
-00014ba0: 6f74 292c 2073 6c6f 7065 202f 2028 6d61  ot), slope / (ma
-00014bb0: 785f 706f 7420 2d20 6d69 6e5f 706f 7429  x_pot - min_pot)
-00014bc0: 290d 0a20 2020 2020 2020 2023 2020 6c20  )..        #  l 
-00014bd0: 3d20 7468 6561 6e6f 2e70 7269 6e74 696e  = theano.printin
-00014be0: 672e 5072 696e 7428 226c 2229 286c 290d  g.Print("l")(l).
-00014bf0: 0a0d 0a20 2020 2020 2020 2023 202d 2d2d  ...        # ---
-00014c00: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00014c10: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 0d0a 2020  ------------..  
-00014c20: 2020 2020 2020 2320 416c 6578 2053 6368        # Alex Sch
-00014c30: 6161 6620 636f 6e74 7269 6275 7469 6f6e  aaf contribution
-00014c40: 3a0d 0a20 2020 2020 2020 2023 2065 6c6c  :..        # ell
-00014c50: 6970 7365 5f66 6163 746f 7220 3d20 7365  ipse_factor = se
-00014c60: 6c66 2e73 656c 6563 745f 6669 6e69 7465  lf.select_finite
-00014c70: 5f66 6175 6c74 7328 290d 0a20 2020 2020  _faults()..     
-00014c80: 2020 2065 6c6c 6970 7365 5f66 6163 746f     ellipse_facto
-00014c90: 725f 7265 6374 6966 6965 6420 3d20 542e  r_rectified = T.
-00014ca0: 7377 6974 6368 2866 696e 6974 655f 6661  switch(finite_fa
-00014cb0: 756c 7473 5f73 656c 203c 2031 2e2c 0d0a  ults_sel < 1.,..
-00014cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014ce0: 2020 2020 2020 2020 2020 2020 6669 6e69              fini
-00014cf0: 7465 5f66 6175 6c74 735f 7365 6c2c 2031  te_faults_sel, 1
-00014d00: 2e29 0d0a 0d0a 2020 2020 2020 2020 6966  .)....        if
-00014d10: 2022 7365 6c65 6374 5f66 696e 6974 655f   "select_finite_
-00014d20: 6661 756c 7473 2220 696e 2073 656c 662e  faults" in self.
-00014d30: 7665 7262 6f73 653a 0d0a 2020 2020 2020  verbose:..      
-00014d40: 2020 2020 2020 656c 6c69 7073 655f 6661        ellipse_fa
-00014d50: 6374 6f72 5f72 6563 7469 6669 6564 203d  ctor_rectified =
-00014d60: 2074 6865 616e 6f2e 7072 696e 7469 6e67   theano.printing
-00014d70: 2e50 7269 6e74 2822 685f 6661 6374 6f72  .Print("h_factor
-00014d80: 5f72 6563 7469 6669 6564 2229 280d 0a20  _rectified")(.. 
-00014d90: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-00014da0: 6c6c 6970 7365 5f66 6163 746f 725f 7265  llipse_factor_re
-00014db0: 6374 6966 6965 6429 0d0a 0d0a 2020 2020  ctified)....    
-00014dc0: 2020 2020 6966 2022 7365 6c65 6374 5f66      if "select_f
-00014dd0: 696e 6974 655f 6661 756c 7473 2220 696e  inite_faults" in
-00014de0: 2073 656c 662e 7665 7262 6f73 653a 0d0a   self.verbose:..
-00014df0: 2020 2020 2020 2020 2020 2020 6d69 6e5f              min_
-00014e00: 706f 7420 3d20 7468 6561 6e6f 2e70 7269  pot = theano.pri
-00014e10: 6e74 696e 672e 5072 696e 7428 226d 696e  nting.Print("min
-00014e20: 5f70 6f74 2229 286d 696e 5f70 6f74 290d  _pot")(min_pot).
-00014e30: 0a20 2020 2020 2020 2020 2020 206d 6178  .            max
-00014e40: 5f70 6f74 203d 2074 6865 616e 6f2e 7072  _pot = theano.pr
-00014e50: 696e 7469 6e67 2e50 7269 6e74 2822 6d61  inting.Print("ma
-00014e60: 785f 706f 7422 2928 6d61 785f 706f 7429  x_pot")(max_pot)
-00014e70: 0d0a 0d0a 2020 2020 2020 2020 2320 7369  ....        # si
-00014e80: 676d 6f69 645f 736c 6f70 6520 3d20 2873  gmoid_slope = (s
-00014e90: 656c 662e 6e6f 745f 6c20 2a20 2831 202f  elf.not_l * (1 /
-00014ea0: 2065 6c6c 6970 7365 5f66 6163 746f 725f   ellipse_factor_
-00014eb0: 7265 6374 6966 6965 6429 2a2a 3329 202f  rectified)**3) /
-00014ec0: 2028 6d61 785f 706f 7420 2d20 6d69 6e5f   (max_pot - min_
-00014ed0: 706f 7429 0d0a 2020 2020 2020 2020 7369  pot)..        si
-00014ee0: 676d 6f69 645f 736c 6f70 6520 3d20 6f66  gmoid_slope = of
-00014ef0: 6673 6574 5f73 6c6f 7065 202d 206f 6666  fset_slope - off
-00014f00: 7365 745f 736c 6f70 6520 2a20 656c 6c69  set_slope * elli
-00014f10: 7073 655f 6661 6374 6f72 5f72 6563 7469  pse_factor_recti
-00014f20: 6669 6564 202a 2a20 7365 6c66 2e65 6c6c  fied ** self.ell
-00014f30: 6970 7365 5f66 6163 746f 725f 6578 706f  ipse_factor_expo
-00014f40: 6e65 6e74 202b 2073 656c 662e 6e6f 745f  nent + self.not_
-00014f50: 6c0d 0a20 2020 2020 2020 2023 206c 203d  l..        # l =
-00014f60: 2054 2e73 7769 7463 6828 7365 6c66 2e73   T.switch(self.s
-00014f70: 656c 6563 745f 6669 6e69 7465 5f66 6175  elect_finite_fau
-00014f80: 6c74 7328 292c 2035 3030 3020 2f20 286d  lts(), 5000 / (m
-00014f90: 6178 5f70 6f74 202d 206d 696e 5f70 6f74  ax_pot - min_pot
-00014fa0: 292c 2035 3020 2f20 286d 6178 5f70 6f74  ), 50 / (max_pot
-00014fb0: 202d 206d 696e 5f70 6f74 2929 0d0a 0d0a   - min_pot))....
-00014fc0: 2020 2020 2020 2020 6966 2022 7365 6c65          if "sele
-00014fd0: 6374 5f66 696e 6974 655f 6661 756c 7473  ct_finite_faults
-00014fe0: 2220 696e 2073 656c 662e 7665 7262 6f73  " in self.verbos
-00014ff0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00015000: 7369 676d 6f69 645f 736c 6f70 6520 3d20  sigmoid_slope = 
-00015010: 7468 6561 6e6f 2e70 7269 6e74 696e 672e  theano.printing.
-00015020: 5072 696e 7428 226c 2229 2873 6967 6d6f  Print("l")(sigmo
-00015030: 6964 5f73 6c6f 7065 290d 0a20 2020 2020  id_slope)..     
-00015040: 2020 2023 202d 2d2d 2d2d 2d2d 2d2d 2d2d     # -----------
-00015050: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00015060: 2d2d 2d2d 2d0d 0a20 2020 2020 2020 2023  -----..        #
-00015070: 2041 2074 656e 736f 7220 7769 7468 2074   A tensor with t
-00015080: 6865 2076 616c 7565 7320 746f 2073 6567  he values to seg
-00015090: 6d65 6e74 0d0a 2020 2020 2020 2020 7363  ment..        sc
-000150a0: 616c 6172 5f66 6965 6c64 5f69 7465 7220  alar_field_iter 
-000150b0: 3d20 542e 636f 6e63 6174 656e 6174 6528  = T.concatenate(
-000150c0: 280d 0a20 2020 2020 2020 2020 2020 2054  (..            T
-000150d0: 2e73 7461 636b 285b 6d61 785f 706f 7420  .stack([max_pot 
-000150e0: 2b20 626f 756e 6461 7279 5f70 6164 5d2c  + boundary_pad],
-000150f0: 2061 7869 733d 3029 2c0d 0a20 2020 2020   axis=0),..     
-00015100: 2020 2020 2020 2073 6361 6c61 725f 6669         scalar_fi
-00015110: 656c 645f 6174 5f73 7572 6661 6365 5f70  eld_at_surface_p
-00015120: 6f69 6e74 732c 0d0a 2020 2020 2020 2020  oints,..        
-00015130: 2020 2020 542e 7374 6163 6b28 5b6d 696e      T.stack([min
-00015140: 5f70 6f74 202d 2062 6f75 6e64 6172 795f  _pot - boundary_
-00015150: 7061 645d 2c20 6178 6973 3d30 290d 0a20  pad], axis=0).. 
-00015160: 2020 2020 2020 2029 290d 0a0d 0a20 2020         ))....   
-00015170: 2020 2020 2069 6620 2273 6361 6c61 725f       if "scalar_
-00015180: 6669 656c 645f 6974 6572 2220 696e 2073  field_iter" in s
-00015190: 656c 662e 7665 7262 6f73 653a 0d0a 2020  elf.verbose:..  
-000151a0: 2020 2020 2020 2020 2020 7363 616c 6172            scalar
-000151b0: 5f66 6965 6c64 5f69 7465 7220 3d20 7468  _field_iter = th
-000151c0: 6561 6e6f 2e70 7269 6e74 696e 672e 5072  eano.printing.Pr
-000151d0: 696e 7428 2273 6361 6c61 725f 6669 656c  int("scalar_fiel
-000151e0: 645f 6974 6572 2229 280d 0a20 2020 2020  d_iter")(..     
-000151f0: 2020 2020 2020 2020 2020 2073 6361 6c61             scala
-00015200: 725f 6669 656c 645f 6974 6572 290d 0a0d  r_field_iter)...
-00015210: 0a20 2020 2020 2020 2023 2048 6572 6520  .        # Here 
-00015220: 7765 206a 7573 7420 7461 6b65 2074 6865  we just take the
-00015230: 2066 6972 7374 2065 6c65 6d65 6e74 206f   first element o
-00015240: 6620 7661 6c75 6573 2070 726f 7065 7274  f values propert
-00015250: 6965 7320 6265 6361 7573 6520 6174 206c  ies because at l
-00015260: 6561 7374 2073 6f20 6661 7220 7765 2064  east so far we d
-00015270: 6f20 6e6f 7420 6669 6e64 2061 2072 6561  o not find a rea
-00015280: 736f 6e0d 0a20 2020 2020 2020 2023 2074  son..        # t
-00015290: 6f20 706f 7075 6c61 7465 2066 6175 6c74  o populate fault
-000152a0: 2062 6c6f 636b 7320 7769 7468 2061 6e79   blocks with any
-000152b0: 7468 696e 6720 656c 7365 0d0a 0d0a 2020  thing else....  
-000152c0: 2020 2020 2020 6e5f 7375 7266 6163 655f        n_surface_
-000152d0: 6f70 5f66 6c6f 6174 5f73 6967 6d6f 6964  op_float_sigmoid
-000152e0: 203d 2054 2e72 6570 6561 7428 7661 6c75   = T.repeat(valu
-000152f0: 6573 5f70 726f 7065 7274 6965 735f 6f70  es_properties_op
-00015300: 5b5b 305d 2c20 3a5d 2c20 322c 0d0a 2020  [[0], :], 2,..  
-00015310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015330: 2020 2020 2020 2020 2020 2020 6178 6973              axis
-00015340: 3d31 290d 0a0d 0a20 2020 2020 2020 2023  =1)....        #
-00015350: 2054 4f44 4f3a 2069 6e73 7465 6164 202d   TODO: instead -
-00015360: 3120 6174 2074 6865 2062 6f72 6465 7220  1 at the border 
-00015370: 6c6f 6f6b 2066 6f72 2074 6865 2061 7665  look for the ave
-00015380: 7261 6765 2064 6973 7461 6e63 6520 6f66  rage distance of
-00015390: 2074 6865 2069 6e70 7574 210d 0a20 2020   the input!..   
-000153a0: 2020 2020 2023 2054 4f44 4f20 4920 7468       # TODO I th
-000153b0: 696e 6b20 7368 6f75 6c64 2062 6520 2d3e  ink should be ->
-000153c0: 206e 5f73 7572 6661 6365 5f6f 705f 666c   n_surface_op_fl
-000153d0: 6f61 745f 7369 676d 6f69 645b 3a2c 2032  oat_sigmoid[:, 2
-000153e0: 5d20 2d20 6e5f 7375 7266 6163 655f 6f70  ] - n_surface_op
-000153f0: 5f66 6c6f 6174 5f73 6967 6d6f 6964 5b3a  _float_sigmoid[:
-00015400: 2c20 315d 0d0a 2020 2020 2020 2020 6e5f  , 1]..        n_
-00015410: 7375 7266 6163 655f 6f70 5f66 6c6f 6174  surface_op_float
-00015420: 5f73 6967 6d6f 6964 203d 2054 2e73 6574  _sigmoid = T.set
-00015430: 5f73 7562 7465 6e73 6f72 280d 0a20 2020  _subtensor(..   
-00015440: 2020 2020 2020 2020 206e 5f73 7572 6661           n_surfa
-00015450: 6365 5f6f 705f 666c 6f61 745f 7369 676d  ce_op_float_sigm
-00015460: 6f69 645b 3a2c 2031 5d2c 202d 3129 0d0a  oid[:, 1], -1)..
-00015470: 2020 2020 2020 2020 2320 2d20 542e 7371          # - T.sq
-00015480: 7274 2854 2e73 7175 6172 6528 6e5f 7375  rt(T.square(n_su
-00015490: 7266 6163 655f 6f70 5f66 6c6f 6174 5f73  rface_op_float_s
-000154a0: 6967 6d6f 6964 5b30 5d20 2d20 6e5f 7375  igmoid[0] - n_su
-000154b0: 7266 6163 655f 6f70 5f66 6c6f 6174 5f73  rface_op_float_s
-000154c0: 6967 6d6f 6964 5b32 5d29 2929 0d0a 0d0a  igmoid[2])))....
-000154d0: 2020 2020 2020 2020 6e5f 7375 7266 6163          n_surfac
-000154e0: 655f 6f70 5f66 6c6f 6174 5f73 6967 6d6f  e_op_float_sigmo
-000154f0: 6964 203d 2054 2e73 6574 5f73 7562 7465  id = T.set_subte
-00015500: 6e73 6f72 280d 0a20 2020 2020 2020 2020  nsor(..         
-00015510: 2020 206e 5f73 7572 6661 6365 5f6f 705f     n_surface_op_
-00015520: 666c 6f61 745f 7369 676d 6f69 645b 3a2c  float_sigmoid[:,
-00015530: 202d 315d 2c20 2d31 290d 0a20 2020 2020   -1], -1)..     
-00015540: 2020 2023 202d 2054 2e73 7172 7428 542e     # - T.sqrt(T.
-00015550: 7371 7561 7265 286e 5f73 7572 6661 6365  square(n_surface
-00015560: 5f6f 705f 666c 6f61 745f 7369 676d 6f69  _op_float_sigmoi
-00015570: 645b 335d 202d 206e 5f73 7572 6661 6365  d[3] - n_surface
-00015580: 5f6f 705f 666c 6f61 745f 7369 676d 6f69  _op_float_sigmoi
-00015590: 645b 2d31 5d29 2929 0d0a 0d0a 2020 2020  d[-1])))....    
-000155a0: 2020 2020 6472 6966 7420 3d20 542e 7365      drift = T.se
-000155b0: 745f 7375 6274 656e 736f 7228 6e5f 7375  t_subtensor(n_su
-000155c0: 7266 6163 655f 6f70 5f66 6c6f 6174 5f73  rface_op_float_s
-000155d0: 6967 6d6f 6964 5b3a 2c20 305d 2c0d 0a20  igmoid[:, 0],.. 
-000155e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000155f0: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-00015600: 5f73 7572 6661 6365 5f6f 705f 666c 6f61  _surface_op_floa
-00015610: 745f 7369 676d 6f69 645b 3a2c 2031 5d29  t_sigmoid[:, 1])
-00015620: 0d0a 0d0a 2020 2020 2020 2020 6966 2027  ....        if '
-00015630: 6e5f 7375 7266 6163 655f 6f70 5f66 6c6f  n_surface_op_flo
-00015640: 6174 5f73 6967 6d6f 6964 2720 696e 2073  at_sigmoid' in s
-00015650: 656c 662e 7665 7262 6f73 653a 0d0a 2020  elf.verbose:..  
-00015660: 2020 2020 2020 2020 2020 6e5f 7375 7266            n_surf
-00015670: 6163 655f 6f70 5f66 6c6f 6174 5f73 6967  ace_op_float_sig
-00015680: 6d6f 6964 203d 2074 6865 616e 6f2e 7072  moid = theano.pr
-00015690: 696e 7469 6e67 2e50 7269 6e74 280d 0a20  inting.Print(.. 
-000156a0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-000156b0: 6e5f 7375 7266 6163 655f 6f70 5f66 6c6f  n_surface_op_flo
-000156c0: 6174 5f73 6967 6d6f 6964 2229 205c 0d0a  at_sigmoid") \..
-000156d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000156e0: 286e 5f73 7572 6661 6365 5f6f 705f 666c  (n_surface_op_fl
-000156f0: 6f61 745f 7369 676d 6f69 6429 0d0a 0d0a  oat_sigmoid)....
-00015700: 2020 2020 2020 2020 6661 756c 745f 626c          fault_bl
-00015710: 6f63 6b2c 2075 7064 6174 6573 3220 3d20  ock, updates2 = 
-00015720: 7468 6561 6e6f 2e73 6361 6e28 0d0a 2020  theano.scan(..  
-00015730: 2020 2020 2020 2020 2020 666e 3d73 656c            fn=sel
-00015740: 662e 636f 6d70 6172 652c 0d0a 2020 2020  f.compare,..    
-00015750: 2020 2020 2020 2020 6f75 7470 7574 735f          outputs_
-00015760: 696e 666f 3d4e 6f6e 652c 0d0a 2020 2020  info=None,..    
-00015770: 2020 2020 2020 2020 7365 7175 656e 6365          sequence
-00015780: 733d 5b64 6963 7428 696e 7075 743d 7363  s=[dict(input=sc
-00015790: 616c 6172 5f66 6965 6c64 5f69 7465 722c  alar_field_iter,
-000157a0: 2074 6170 733d 5b30 2c20 315d 292c 0d0a   taps=[0, 1]),..
-000157b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000157c0: 2020 2020 2020 2054 2e61 7261 6e67 6528         T.arange(
-000157d0: 302c 206e 5f73 7572 6661 6365 5f6f 705f  0, n_surface_op_
-000157e0: 666c 6f61 745f 7369 676d 6f69 642e 7368  float_sigmoid.sh
-000157f0: 6170 655b 315d 2c20 322c 0d0a 2020 2020  ape[1], 2,..    
-00015800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015810: 2020 2020 2020 2020 2020 2020 6474 7970              dtyp
-00015820: 653d 2769 6e74 3634 2729 5d2c 0d0a 2020  e='int64')],..  
-00015830: 2020 2020 2020 2020 2020 6e6f 6e5f 7365            non_se
-00015840: 7175 656e 6365 733d 5b5a 5f78 2c20 7369  quences=[Z_x, si
-00015850: 676d 6f69 645f 736c 6f70 652c 206e 5f73  gmoid_slope, n_s
-00015860: 7572 6661 6365 5f6f 705f 666c 6f61 745f  urface_op_float_
-00015870: 7369 676d 6f69 642c 2064 7269 6674 5d2c  sigmoid, drift],
-00015880: 0d0a 2020 2020 2020 2020 2020 2020 6e61  ..            na
-00015890: 6d65 3d27 4c6f 6f70 696e 6720 636f 6d70  me='Looping comp
-000158a0: 6172 6527 2c0d 0a20 2020 2020 2020 2020  are',..         
-000158b0: 2020 2070 726f 6669 6c65 3d46 616c 7365     profile=False
-000158c0: 2c0d 0a20 2020 2020 2020 2020 2020 2072  ,..            r
-000158d0: 6574 7572 6e5f 6c69 7374 3d46 616c 7365  eturn_list=False
-000158e0: 290d 0a0d 0a20 2020 2020 2020 2023 2046  )....        # F
-000158f0: 6f72 2065 7665 7279 2073 7572 6661 6365  or every surface
-00015900: 2077 6520 6765 7420 6120 7665 6374 6f72   we get a vector
-00015910: 2073 6f20 7765 206e 6565 6420 746f 2073   so we need to s
-00015920: 756d 2063 6f6d 7072 6573 7320 7468 656d  um compress them
-00015930: 2074 6f20 6f6e 6520 6469 6d65 6e73 696f   to one dimensio
-00015940: 6e0d 0a20 2020 2020 2020 2066 6175 6c74  n..        fault
-00015950: 5f62 6c6f 636b 203d 2066 6175 6c74 5f62  _block = fault_b
-00015960: 6c6f 636b 2e73 756d 2861 7869 733d 3029  lock.sum(axis=0)
-00015970: 0d0a 0d0a 2020 2020 2020 2020 2320 4164  ....        # Ad
-00015980: 6420 6e61 6d65 2074 6f20 7468 6520 7468  d name to the th
-00015990: 6561 6e6f 206e 6f64 650d 0a20 2020 2020  eano node..     
-000159a0: 2020 2066 6175 6c74 5f62 6c6f 636b 2e6e     fault_block.n
-000159b0: 616d 6520 3d20 2754 6865 2063 6875 6e6b  ame = 'The chunk
-000159c0: 206f 6620 626c 6f63 6b20 6d6f 6465 6c20   of block model 
-000159d0: 6f66 2061 2073 7065 6369 6669 6320 7365  of a specific se
-000159e0: 7269 6573 270d 0a20 2020 2020 2020 2069  ries'..        i
-000159f0: 6620 7374 7228 7379 732e 5f67 6574 6672  f str(sys._getfr
-00015a00: 616d 6528 292e 665f 636f 6465 2e63 6f5f  ame().f_code.co_
-00015a10: 6e61 6d65 2920 696e 2073 656c 662e 7665  name) in self.ve
-00015a20: 7262 6f73 653a 0d0a 2020 2020 2020 2020  rbose:..        
-00015a30: 2020 2020 6661 756c 745f 626c 6f63 6b20      fault_block 
-00015a40: 3d20 7468 6561 6e6f 2e70 7269 6e74 696e  = theano.printin
-00015a50: 672e 5072 696e 7428 6661 756c 745f 626c  g.Print(fault_bl
-00015a60: 6f63 6b2e 6e61 6d65 2928 6661 756c 745f  ock.name)(fault_
-00015a70: 626c 6f63 6b29 0d0a 0d0a 2020 2020 2020  block)....      
-00015a80: 2020 7265 7475 726e 2066 6175 6c74 5f62    return fault_b
-00015a90: 6c6f 636b 0d0a 0d0a 2020 2020 6465 6620  lock....    def 
-00015aa0: 6578 706f 7274 5f66 6f72 6d61 7469 6f6e  export_formation
-00015ab0: 5f62 6c6f 636b 2873 656c 662c 205a 5f78  _block(self, Z_x
-00015ac0: 2c20 7363 616c 6172 5f66 6965 6c64 5f61  , scalar_field_a
-00015ad0: 745f 7375 7266 6163 655f 706f 696e 7473  t_surface_points
-00015ae0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00015af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015b00: 2020 7661 6c75 6573 5f70 726f 7065 7274    values_propert
-00015b10: 6965 735f 6f70 293a 0d0a 2020 2020 2020  ies_op):..      
-00015b20: 2020 2222 220d 0a20 2020 2020 2020 2043    """..        C
-00015b30: 6f6d 7075 7465 2074 6865 2070 6172 7420  ompute the part 
-00015b40: 6f66 2074 6865 2062 6c6f 636b 206d 6f64  of the block mod
-00015b50: 656c 206f 6620 6120 6769 7665 6e20 7365  el of a given se
-00015b60: 7269 6573 2028 6469 6374 6174 6564 2062  ries (dictated b
-00015b70: 7920 7468 6520 626f 6f6c 2061 7272 6179  y the bool array
-00015b80: 2079 6574 2074 6f20 6265 2063 6f6d 7075   yet to be compu
-00015b90: 7465 6429 0d0a 0d0a 2020 2020 2020 2020  ted)....        
-00015ba0: 5265 7475 726e 733a 0d0a 2020 2020 2020  Returns:..      
-00015bb0: 2020 2020 2020 7468 6561 6e6f 2e74 656e        theano.ten
-00015bc0: 736f 722e 7665 6374 6f72 3a20 5661 6c75  sor.vector: Valu
-00015bd0: 6520 6f66 206c 6974 686f 6c6f 6779 2061  e of lithology a
-00015be0: 7420 6576 6572 7920 696e 7465 7270 6f6c  t every interpol
-00015bf0: 6174 6564 2070 6f69 6e74 0d0a 2020 2020  ated point..    
-00015c00: 2020 2020 2222 220d 0a20 2020 2020 2020      """..       
-00015c10: 2023 2054 4f44 4f3a 2049 4d50 2073 6574   # TODO: IMP set
-00015c20: 2073 6f66 7420 6d61 7820 696e 2074 6865   soft max in the
-00015c30: 2062 6f72 6465 7273 3a20 5465 7374 0d0a   borders: Test..
-00015c40: 2020 2020 2020 2020 2320 544f 444f 3a20          # TODO: 
-00015c50: 696e 7374 6561 6420 2d31 2061 7420 7468  instead -1 at th
-00015c60: 6520 626f 7264 6572 206c 6f6f 6b20 666f  e border look fo
-00015c70: 7220 7468 6520 6176 6572 6167 6520 6469  r the average di
-00015c80: 7374 616e 6365 206f 6620 7468 6520 696e  stance of the in
-00015c90: 7075 7421 3a20 5465 7374 0d0a 0d0a 2020  put!: Test....  
-00015ca0: 2020 2020 2020 736c 6f70 6520 3d20 7365        slope = se
-00015cb0: 6c66 2e73 6967 5f73 6c6f 7065 0d0a 2020  lf.sig_slope..  
-00015cc0: 2020 2020 2020 6966 2073 656c 662e 6d61        if self.ma
-00015cd0: 785f 7370 6565 6420 3c20 313a 0d0a 2020  x_speed < 1:..  
-00015ce0: 2020 2020 2020 2020 2020 2320 6d61 785f            # max_
-00015cf0: 706f 7420 3d20 542e 6d61 7828 7363 616c  pot = T.max(scal
-00015d00: 6172 5f66 6965 6c64 5f61 745f 7375 7266  ar_field_at_surf
-00015d10: 6163 655f 706f 696e 7473 290d 0a20 2020  ace_points)..   
-00015d20: 2020 2020 2020 2020 2023 206d 696e 5f70           # min_p
-00015d30: 6f74 203d 2054 2e6d 696e 2873 6361 6c61  ot = T.min(scala
-00015d40: 725f 6669 656c 645f 6174 5f73 7572 6661  r_field_at_surfa
-00015d50: 6365 5f70 6f69 6e74 7329 0d0a 0d0a 2020  ce_points)....  
-00015d60: 2020 2020 2020 2020 2020 6d61 785f 706f            max_po
-00015d70: 7420 3d20 542e 6d61 7828 5a5f 7829 0d0a  t = T.max(Z_x)..
-00015d80: 2020 2020 2020 2020 2020 2020 2320 6d61              # ma
-00015d90: 785f 706f 7420 3d20 7468 6561 6e6f 2e70  x_pot = theano.p
-00015da0: 7269 6e74 696e 672e 5072 696e 7428 226d  rinting.Print("m
-00015db0: 6178 5f70 6f74 2229 286d 6178 5f70 6f74  ax_pot")(max_pot
-00015dc0: 290d 0a20 2020 2020 2020 2020 2020 206d  )..            m
-00015dd0: 696e 5f70 6f74 203d 2054 2e6d 696e 285a  in_pot = T.min(Z
-00015de0: 5f78 290d 0a20 2020 2020 2020 2020 2020  _x)..           
-00015df0: 2023 206d 696e 5f70 6f74 203d 2074 6865   # min_pot = the
-00015e00: 616e 6f2e 7072 696e 7469 6e67 2e50 7269  ano.printing.Pri
-00015e10: 6e74 2822 6d69 6e5f 706f 7422 2928 6d69  nt("min_pot")(mi
-00015e20: 6e5f 706f 7429 0d0a 0d0a 2020 2020 2020  n_pot)....      
-00015e30: 2020 2020 2020 2320 6d61 785f 706f 745f        # max_pot_
-00015e40: 7369 676d 203d 2032 202a 206d 6178 5f70  sigm = 2 * max_p
-00015e50: 6f74 202d 2073 656c 662e 7363 616c 6172  ot - self.scalar
-00015e60: 5f66 6965 6c64 5f61 745f 7375 7266 6163  _field_at_surfac
-00015e70: 655f 706f 696e 7473 5f76 616c 7565 735b  e_points_values[
-00015e80: 305d 0d0a 2020 2020 2020 2020 2020 2020  0]..            
-00015e90: 2320 6d69 6e5f 706f 745f 7369 676d 203d  # min_pot_sigm =
-00015ea0: 2032 202a 206d 696e 5f70 6f74 202d 2073   2 * min_pot - s
-00015eb0: 656c 662e 7363 616c 6172 5f66 6965 6c64  elf.scalar_field
-00015ec0: 5f61 745f 7375 7266 6163 655f 706f 696e  _at_surface_poin
-00015ed0: 7473 5f76 616c 7565 735b 2d31 5d0d 0a0d  ts_values[-1]...
-00015ee0: 0a20 2020 2020 2020 2020 2020 2023 2062  .            # b
-00015ef0: 6f75 6e64 6172 795f 7061 6420 3d20 286d  oundary_pad = (m
-00015f00: 6178 5f70 6f74 202d 206d 696e 5f70 6f74  ax_pot - min_pot
-00015f10: 2920 2a20 302e 3031 0d0a 2020 2020 2020  ) * 0.01..      
-00015f20: 2020 2020 2020 6c20 3d20 736c 6f70 6520        l = slope 
-00015f30: 2f20 286d 6178 5f70 6f74 202d 206d 696e  / (max_pot - min
-00015f40: 5f70 6f74 290d 0a20 2020 2020 2020 2065  _pot)..        e
-00015f50: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
-00015f60: 2020 6c20 3d20 736c 6f70 650d 0a0d 0a20    l = slope.... 
-00015f70: 2020 2020 2020 2023 2041 2074 656e 736f         # A tenso
-00015f80: 7220 7769 7468 2074 6865 2076 616c 7565  r with the value
-00015f90: 7320 746f 2073 6567 6d65 6e74 0d0a 2020  s to segment..  
-00015fa0: 2020 2020 2020 7363 616c 6172 5f66 6965        scalar_fie
-00015fb0: 6c64 5f69 7465 7220 3d20 542e 636f 6e63  ld_iter = T.conc
-00015fc0: 6174 656e 6174 6528 280d 0a20 2020 2020  atenate((..     
-00015fd0: 2020 2020 2020 2023 2020 542e 7374 6163         #  T.stac
-00015fe0: 6b28 5b54 2e6d 6178 285a 5f78 295d 2c20  k([T.max(Z_x)], 
-00015ff0: 6178 6973 3d30 292c 0d0a 2020 2020 2020  axis=0),..      
-00016000: 2020 2020 2020 542e 7374 6163 6b28 5b30        T.stack([0
-00016010: 5d2c 2061 7869 733d 3029 2c20 2023 2073  ], axis=0),  # s
-00016020: 6f6d 6568 6f77 2074 6869 7320 616c 736f  omehow this also
-00016030: 2077 6f72 6b73 2e20 4920 646f 206e 6f74   works. I do not
-00016040: 2072 656d 656d 6265 7220 7768 790d 0a20   remember why.. 
-00016050: 2020 2020 2020 2020 2020 2073 6361 6c61             scala
-00016060: 725f 6669 656c 645f 6174 5f73 7572 6661  r_field_at_surfa
-00016070: 6365 5f70 6f69 6e74 732c 0d0a 2020 2020  ce_points,..    
-00016080: 2020 2020 2020 2020 542e 7374 6163 6b28          T.stack(
-00016090: 5b30 5d2c 2061 7869 733d 3029 0d0a 2020  [0], axis=0)..  
-000160a0: 2020 2020 2020 2020 2020 2320 2020 542e            #   T.
-000160b0: 7374 6163 6b28 5b54 2e6d 696e 285a 5f78  stack([T.min(Z_x
-000160c0: 295d 2c20 6178 6973 3d30 290d 0a20 2020  )], axis=0)..   
-000160d0: 2020 2020 2029 290d 0a0d 0a20 2020 2020       ))....     
-000160e0: 2020 2069 6620 2273 6361 6c61 725f 6669     if "scalar_fi
-000160f0: 656c 645f 6974 6572 2220 696e 2073 656c  eld_iter" in sel
-00016100: 662e 7665 7262 6f73 653a 0d0a 2020 2020  f.verbose:..    
-00016110: 2020 2020 2020 2020 7363 616c 6172 5f66          scalar_f
-00016120: 6965 6c64 5f69 7465 7220 3d20 7468 6561  ield_iter = thea
-00016130: 6e6f 2e70 7269 6e74 696e 672e 5072 696e  no.printing.Prin
-00016140: 7428 2273 6361 6c61 725f 6669 656c 645f  t("scalar_field_
-00016150: 6974 6572 2229 280d 0a20 2020 2020 2020  iter")(..       
-00016160: 2020 2020 2020 2020 2073 6361 6c61 725f           scalar_
-00016170: 6669 656c 645f 6974 6572 290d 0a0d 0a20  field_iter).... 
-00016180: 2020 2020 2020 2023 204c 6f6f 7020 746f         # Loop to
-00016190: 2073 6567 6d65 6e74 2074 6865 2064 6973   segment the dis
-000161a0: 7469 6e63 7420 6c69 7468 6f6c 6f67 6965  tinct lithologie
-000161b0: 730d 0a0d 0a20 2020 2020 2020 206e 5f73  s....        n_s
-000161c0: 7572 6661 6365 5f6f 705f 666c 6f61 745f  urface_op_float_
-000161d0: 7369 676d 6f69 6420 3d20 542e 7265 7065  sigmoid = T.repe
-000161e0: 6174 2876 616c 7565 735f 7072 6f70 6572  at(values_proper
-000161f0: 7469 6573 5f6f 702c 2032 2c20 6178 6973  ties_op, 2, axis
-00016200: 3d31 290d 0a20 2020 2020 2020 206e 5f73  =1)..        n_s
-00016210: 7572 6661 6365 5f6f 705f 666c 6f61 745f  urface_op_float_
-00016220: 7369 676d 6f69 6420 3d20 542e 7365 745f  sigmoid = T.set_
-00016230: 7375 6274 656e 736f 7228 0d0a 2020 2020  subtensor(..    
-00016240: 2020 2020 2020 2020 6e5f 7375 7266 6163          n_surfac
-00016250: 655f 6f70 5f66 6c6f 6174 5f73 6967 6d6f  e_op_float_sigmo
-00016260: 6964 5b3a 2c20 305d 2c20 3029 0d0a 2020  id[:, 0], 0)..  
-00016270: 2020 2020 2020 6e5f 7375 7266 6163 655f        n_surface_
-00016280: 6f70 5f66 6c6f 6174 5f73 6967 6d6f 6964  op_float_sigmoid
-00016290: 203d 2054 2e73 6574 5f73 7562 7465 6e73   = T.set_subtens
-000162a0: 6f72 280d 0a20 2020 2020 2020 2020 2020  or(..           
-000162b0: 206e 5f73 7572 6661 6365 5f6f 705f 666c   n_surface_op_fl
-000162c0: 6f61 745f 7369 676d 6f69 645b 3a2c 202d  oat_sigmoid[:, -
-000162d0: 315d 2c20 3029 0d0a 2020 2020 2020 2020  1], 0)..        
-000162e0: 6472 6966 7420 3d20 542e 7365 745f 7375  drift = T.set_su
-000162f0: 6274 656e 736f 7228 6e5f 7375 7266 6163  btensor(n_surfac
-00016300: 655f 6f70 5f66 6c6f 6174 5f73 6967 6d6f  e_op_float_sigmo
-00016310: 6964 5b3a 2c20 305d 2c0d 0a20 2020 2020  id[:, 0],..     
-00016320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016330: 2020 2020 2020 2020 2020 206e 5f73 7572             n_sur
-00016340: 6661 6365 5f6f 705f 666c 6f61 745f 7369  face_op_float_si
-00016350: 676d 6f69 645b 3a2c 2031 5d29 0d0a 0d0a  gmoid[:, 1])....
-00016360: 2020 2020 2020 2020 6966 2027 6e5f 7375          if 'n_su
-00016370: 7266 6163 655f 6f70 5f66 6c6f 6174 5f73  rface_op_float_s
-00016380: 6967 6d6f 6964 2720 696e 2073 656c 662e  igmoid' in self.
-00016390: 7665 7262 6f73 653a 0d0a 2020 2020 2020  verbose:..      
-000163a0: 2020 2020 2020 6e5f 7375 7266 6163 655f        n_surface_
-000163b0: 6f70 5f66 6c6f 6174 5f73 6967 6d6f 6964  op_float_sigmoid
-000163c0: 203d 2074 6865 616e 6f2e 7072 696e 7469   = theano.printi
-000163d0: 6e67 2e50 7269 6e74 280d 0a20 2020 2020  ng.Print(..     
-000163e0: 2020 2020 2020 2020 2020 2022 6e5f 7375             "n_su
-000163f0: 7266 6163 655f 6f70 5f66 6c6f 6174 5f73  rface_op_float_s
-00016400: 6967 6d6f 6964 2229 205c 0d0a 2020 2020  igmoid") \..    
-00016410: 2020 2020 2020 2020 2020 2020 286e 5f73              (n_s
-00016420: 7572 6661 6365 5f6f 705f 666c 6f61 745f  urface_op_float_
-00016430: 7369 676d 6f69 6429 0d0a 0d0a 2020 2020  sigmoid)....    
-00016440: 2020 2020 666f 726d 6174 696f 6e73 5f62      formations_b
-00016450: 6c6f 636b 2c20 7570 6461 7465 7332 203d  lock, updates2 =
-00016460: 2074 6865 616e 6f2e 7363 616e 280d 0a20   theano.scan(.. 
-00016470: 2020 2020 2020 2020 2020 2066 6e3d 7365             fn=se
-00016480: 6c66 2e63 6f6d 7061 7265 2c0d 0a20 2020  lf.compare,..   
-00016490: 2020 2020 2020 2020 206f 7574 7075 7473           outputs
-000164a0: 5f69 6e66 6f3d 4e6f 6e65 2c0d 0a20 2020  _info=None,..   
-000164b0: 2020 2020 2020 2020 2073 6571 7565 6e63           sequenc
-000164c0: 6573 3d5b 6469 6374 2869 6e70 7574 3d73  es=[dict(input=s
-000164d0: 6361 6c61 725f 6669 656c 645f 6974 6572  calar_field_iter
-000164e0: 2c20 7461 7073 3d5b 302c 2031 5d29 2c0d  , taps=[0, 1]),.
-000164f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00016500: 2020 2020 2020 2020 542e 6172 616e 6765          T.arange
-00016510: 2830 2c20 6e5f 7375 7266 6163 655f 6f70  (0, n_surface_op
-00016520: 5f66 6c6f 6174 5f73 6967 6d6f 6964 2e73  _float_sigmoid.s
-00016530: 6861 7065 5b31 5d2c 2032 2c0d 0a20 2020  hape[1], 2,..   
-00016540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016550: 2020 2020 2020 2020 2020 2020 2064 7479               dty
-00016560: 7065 3d27 696e 7436 3427 295d 2c0d 0a20  pe='int64')],.. 
-00016570: 2020 2020 2020 2020 2020 206e 6f6e 5f73             non_s
-00016580: 6571 7565 6e63 6573 3d5b 5a5f 782c 206c  equences=[Z_x, l
-00016590: 2c20 6e5f 7375 7266 6163 655f 6f70 5f66  , n_surface_op_f
-000165a0: 6c6f 6174 5f73 6967 6d6f 6964 2c20 6472  loat_sigmoid, dr
-000165b0: 6966 745d 2c0d 0a20 2020 2020 2020 2020  ift],..         
-000165c0: 2020 206e 616d 653d 274c 6f6f 7069 6e67     name='Looping
-000165d0: 2063 6f6d 7061 7265 272c 0d0a 2020 2020   compare',..    
-000165e0: 2020 2020 2020 2020 7072 6f66 696c 653d          profile=
-000165f0: 4661 6c73 652c 0d0a 2020 2020 2020 2020  False,..        
-00016600: 2020 2020 7265 7475 726e 5f6c 6973 743d      return_list=
-00016610: 4661 6c73 6529 0d0a 0d0a 2020 2020 2020  False)....      
-00016620: 2020 2320 466f 7220 6576 6572 7920 7375    # For every su
-00016630: 7266 6163 6520 7765 2067 6574 2061 2076  rface we get a v
-00016640: 6563 746f 7220 736f 2077 6520 6e65 6564  ector so we need
-00016650: 2074 6f20 7375 6d20 636f 6d70 7265 7373   to sum compress
-00016660: 2074 6865 6d20 746f 206f 6e65 2064 696d   them to one dim
-00016670: 656e 7369 6f6e 0d0a 2020 2020 2020 2020  ension..        
-00016680: 666f 726d 6174 696f 6e73 5f62 6c6f 636b  formations_block
-00016690: 203d 2066 6f72 6d61 7469 6f6e 735f 626c   = formations_bl
-000166a0: 6f63 6b2e 7375 6d28 6178 6973 3d30 290d  ock.sum(axis=0).
-000166b0: 0a0d 0a20 2020 2020 2020 2069 6620 7365  ...        if se
-000166c0: 6c66 2e67 7261 6469 656e 7420 6973 2054  lf.gradient is T
-000166d0: 7275 653a 0d0a 2020 2020 2020 2020 2020  rue:..          
-000166e0: 2020 5265 4c55 5f75 7020 3d20 542e 7377    ReLU_up = T.sw
-000166f0: 6974 6368 285a 5f78 203c 2073 6361 6c61  itch(Z_x < scala
-00016700: 725f 6669 656c 645f 6974 6572 5b31 5d2c  r_field_iter[1],
-00016710: 2030 2c0d 0a20 2020 2020 2020 2020 2020   0,..           
-00016720: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016730: 2020 2020 2d20 302e 3031 202a 2028 5a5f      - 0.01 * (Z_
-00016740: 7820 2d20 7363 616c 6172 5f66 6965 6c64  x - scalar_field
-00016750: 5f69 7465 725b 315d 2929 0d0a 2020 2020  _iter[1]))..    
-00016760: 2020 2020 2020 2020 5265 4c55 5f64 6f77          ReLU_dow
-00016770: 6e20 3d20 542e 7377 6974 6368 285a 5f78  n = T.switch(Z_x
-00016780: 203e 2073 6361 6c61 725f 6669 656c 645f   > scalar_field_
-00016790: 6974 6572 5b2d 325d 2c20 302c 0d0a 2020  iter[-2], 0,..  
-000167a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000167b0: 2020 2020 2020 2020 2020 2020 2020 2030                 0
-000167c0: 2e30 3120 2a20 542e 6162 735f 285a 5f78  .01 * T.abs_(Z_x
-000167d0: 202d 2073 6361 6c61 725f 6669 656c 645f   - scalar_field_
-000167e0: 6974 6572 5b2d 325d 2929 0d0a 0d0a 2020  iter[-2]))....  
-000167f0: 2020 2020 2020 2020 2020 6966 2027 7265            if 're
-00016800: 6c75 2720 696e 2073 656c 662e 7665 7262  lu' in self.verb
-00016810: 6f73 653a 0d0a 2020 2020 2020 2020 2020  ose:..          
-00016820: 2020 2020 2020 5265 4c55 5f75 7020 3d20        ReLU_up = 
-00016830: 7468 6561 6e6f 2e70 7269 6e74 696e 672e  theano.printing.
-00016840: 5072 696e 7428 2752 654c 555f 7570 2729  Print('ReLU_up')
-00016850: 2852 654c 555f 7570 290d 0a20 2020 2020  (ReLU_up)..     
-00016860: 2020 2020 2020 2020 2020 2052 654c 555f             ReLU_
-00016870: 646f 776e 203d 2074 6865 616e 6f2e 7072  down = theano.pr
-00016880: 696e 7469 6e67 2e50 7269 6e74 2827 5265  inting.Print('Re
-00016890: 4c55 5f64 6f77 6e27 2928 5265 4c55 5f64  LU_down')(ReLU_d
-000168a0: 6f77 6e29 0d0a 0d0a 2020 2020 2020 2020  own)....        
-000168b0: 2020 2020 666f 726d 6174 696f 6e73 5f62      formations_b
-000168c0: 6c6f 636b 202b 3d20 5265 4c55 5f64 6f77  lock += ReLU_dow
-000168d0: 6e20 2b20 5265 4c55 5f75 700d 0a0d 0a20  n + ReLU_up.... 
-000168e0: 2020 2020 2020 2023 2041 6464 206e 616d         # Add nam
-000168f0: 6520 746f 2074 6865 2074 6865 616e 6f20  e to the theano 
-00016900: 6e6f 6465 0d0a 2020 2020 2020 2020 666f  node..        fo
-00016910: 726d 6174 696f 6e73 5f62 6c6f 636b 2e6e  rmations_block.n
-00016920: 616d 6520 3d20 2754 6865 2063 6875 6e6b  ame = 'The chunk
-00016930: 206f 6620 626c 6f63 6b20 6d6f 6465 6c20   of block model 
-00016940: 6f66 2061 2073 7065 6369 6669 6320 7365  of a specific se
-00016950: 7269 6573 270d 0a20 2020 2020 2020 2069  ries'..        i
-00016960: 6620 7374 7228 7379 732e 5f67 6574 6672  f str(sys._getfr
-00016970: 616d 6528 292e 665f 636f 6465 2e63 6f5f  ame().f_code.co_
-00016980: 6e61 6d65 2920 696e 2073 656c 662e 7665  name) in self.ve
-00016990: 7262 6f73 653a 0d0a 2020 2020 2020 2020  rbose:..        
-000169a0: 2020 2020 666f 726d 6174 696f 6e73 5f62      formations_b
-000169b0: 6c6f 636b 203d 2074 6865 616e 6f2e 7072  lock = theano.pr
-000169c0: 696e 7469 6e67 2e50 7269 6e74 2866 6f72  inting.Print(for
-000169d0: 6d61 7469 6f6e 735f 626c 6f63 6b2e 6e61  mations_block.na
-000169e0: 6d65 2928 0d0a 2020 2020 2020 2020 2020  me)(..          
-000169f0: 2020 2020 2020 666f 726d 6174 696f 6e73        formations
-00016a00: 5f62 6c6f 636b 290d 0a0d 0a20 2020 2020  _block)....     
-00016a10: 2020 2072 6574 7572 6e20 666f 726d 6174     return format
-00016a20: 696f 6e73 5f62 6c6f 636b 0d0a 0d0a 2020  ions_block....  
-00016a30: 2020 2320 656e 6472 6567 696f 6e0d 0a0d    # endregion...
-00016a40: 0a20 2020 2023 2072 6567 696f 6e20 436f  .    # region Co
-00016a50: 6d70 7574 6520 6d6f 6465 6c0d 0a20 2020  mpute model..   
-00016a60: 2064 6566 2063 6f6d 7075 7465 5f61 5f73   def compute_a_s
-00016a70: 6572 6965 7328 7365 6c66 2c0d 0a20 2020  eries(self,..   
+00013df0: 2020 2028 726f 7461 7465 645f 785b 3a2c     (rotated_x[:,
+00013e00: 2031 5d20 2d20 726f 7461 7465 645f 6374   1] - rotated_ct
+00013e10: 725b 315d 2920 2a2a 2032 202f 2062 5f72  r[1]) ** 2 / b_r
+00013e20: 6164 6975 7320 2a2a 2032 0d0a 0d0a 2020  adius ** 2....  
+00013e30: 2020 2020 2020 6966 2022 7365 6c65 6374        if "select
+00013e40: 5f66 696e 6974 655f 6661 756c 7473 2220  _finite_faults" 
+00013e50: 696e 2073 656c 662e 7665 7262 6f73 653a  in self.verbose:
+00013e60: 0d0a 2020 2020 2020 2020 2020 2020 656c  ..            el
+00013e70: 6c69 7073 655f 6661 6374 6f72 203d 2061  lipse_factor = a
+00013e80: 6573 6172 612e 7072 696e 7469 6e67 2e50  esara.printing.P
+00013e90: 7269 6e74 2822 6822 2928 656c 6c69 7073  rint("h")(ellips
+00013ea0: 655f 6661 6374 6f72 290d 0a0d 0a20 2020  e_factor)....   
+00013eb0: 2020 2020 2072 6574 7572 6e20 656c 6c69       return elli
+00013ec0: 7073 655f 6661 6374 6f72 0d0a 0d0a 2020  pse_factor....  
+00013ed0: 2020 6465 6620 636f 6d70 6172 6528 7365    def compare(se
+00013ee0: 6c66 2c20 612c 2062 2c20 736c 6963 655f  lf, a, b, slice_
+00013ef0: 696e 6974 2c20 5a5f 782c 206c 2c20 6e5f  init, Z_x, l, n_
+00013f00: 7375 7266 6163 652c 2064 7269 6674 293a  surface, drift):
+00013f10: 0d0a 2020 2020 2020 2020 2222 220d 0a20  ..        """.. 
+00013f20: 2020 2020 2020 2054 7265 7368 6f6c 6420         Treshold 
+00013f30: 6f66 2074 6865 2070 6f69 6e74 7320 746f  of the points to
+00013f40: 2069 6e74 6572 706f 6c61 7465 2067 6976   interpolate giv
+00013f50: 656e 2032 2070 6f74 656e 7469 616c 2066  en 2 potential f
+00013f60: 6965 6c64 2076 616c 7565 732e 2054 4f44  ield values. TOD
+00013f70: 4f3a 2054 6869 7320 6675 6e63 7469 6f6e  O: This function
+00013f80: 2069 7320 7468 6520 6f6e 6520 7765 0d0a   is the one we..
+00013f90: 2020 2020 2020 2020 6e65 6564 2074 6f20          need to 
+00013fa0: 6368 616e 6765 2066 6f72 2061 2073 6967  change for a sig
+00013fb0: 6d6f 6964 2066 756e 6374 696f 6e0d 0a0d  moid function...
+00013fc0: 0a20 2020 2020 2020 2041 7267 733a 0d0a  .        Args:..
+00013fd0: 2020 2020 2020 2020 2020 2020 6120 2873              a (s
+00013fe0: 6361 6c61 7229 3a20 5570 7065 7220 6c69  calar): Upper li
+00013ff0: 6d69 7420 6f66 2074 6865 2070 6f74 656e  mit of the poten
+00014000: 7469 616c 2066 6965 6c64 0d0a 2020 2020  tial field..    
+00014010: 2020 2020 2020 2020 6220 2873 6361 6c61          b (scala
+00014020: 7229 3a20 4c6f 7765 7220 6c69 6d69 7420  r): Lower limit 
+00014030: 6f66 2074 6865 2070 6f74 656e 7469 616c  of the potential
+00014040: 2066 6965 6c64 0d0a 2020 2020 2020 2020   field..        
+00014050: 2020 2020 6e5f 7375 7266 6163 6520 2873      n_surface (s
+00014060: 6361 6c61 7229 3a20 5661 6c75 6520 6769  calar): Value gi
+00014070: 7665 6e20 746f 2074 6865 2073 6567 6d65  ven to the segme
+00014080: 6e74 6174 696f 6e2c 2069 2e65 2e20 6c69  ntation, i.e. li
+00014090: 7468 6f6c 6f67 7920 6e75 6d62 6572 0d0a  thology number..
+000140a0: 2020 2020 2020 2020 2020 2020 5a78 2028              Zx (
+000140b0: 7665 6374 6f72 293a 2050 6f74 656e 7469  vector): Potenti
+000140c0: 616c 2066 6965 6c64 2076 616c 7565 7320  al field values 
+000140d0: 6174 2061 6c6c 2074 6865 2069 6e74 6572  at all the inter
+000140e0: 706f 6c61 7465 6420 706f 696e 7473 0d0a  polated points..
+000140f0: 0d0a 2020 2020 2020 2020 5265 7475 726e  ..        Return
+00014100: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
+00014110: 6165 7361 7261 2e74 656e 736f 722e 7665  aesara.tensor.ve
+00014120: 6374 6f72 3a20 7365 676d 656e 7465 6420  ctor: segmented 
+00014130: 7661 6c75 6573 0d0a 2020 2020 2020 2020  values..        
+00014140: 2222 220d 0a0d 0a20 2020 2020 2020 2073  """....        s
+00014150: 6c69 6365 5f69 6e69 7420 3d20 736c 6963  lice_init = slic
+00014160: 655f 696e 6974 0d0a 2020 2020 2020 2020  e_init..        
+00014170: 6e5f 7375 7266 6163 655f 3020 3d20 6e5f  n_surface_0 = n_
+00014180: 7375 7266 6163 655b 3a2c 2073 6c69 6365  surface[:, slice
+00014190: 5f69 6e69 743a 736c 6963 655f 696e 6974  _init:slice_init
+000141a0: 202b 2031 5d0d 0a20 2020 2020 2020 206e   + 1]..        n
+000141b0: 5f73 7572 6661 6365 5f31 203d 206e 5f73  _surface_1 = n_s
+000141c0: 7572 6661 6365 5b3a 2c20 736c 6963 655f  urface[:, slice_
+000141d0: 696e 6974 202b 2031 3a73 6c69 6365 5f69  init + 1:slice_i
+000141e0: 6e69 7420 2b20 325d 0d0a 2020 2020 2020  nit + 2]..      
+000141f0: 2020 6472 6966 7420 3d20 6472 6966 745b    drift = drift[
+00014200: 3a2c 2073 6c69 6365 5f69 6e69 743a 736c  :, slice_init:sl
+00014210: 6963 655f 696e 6974 202b 2031 5d0d 0a0d  ice_init + 1]...
+00014220: 0a20 2020 2020 2020 2069 6620 2763 6f6d  .        if 'com
+00014230: 7061 7265 2720 696e 2073 656c 662e 7665  pare' in self.ve
+00014240: 7262 6f73 653a 0d0a 2020 2020 2020 2020  rbose:..        
+00014250: 2020 2020 6120 3d20 6165 7361 7261 2e70      a = aesara.p
+00014260: 7269 6e74 696e 672e 5072 696e 7428 2261  rinting.Print("a
+00014270: 2229 2861 290d 0a20 2020 2020 2020 2020  ")(a)..         
+00014280: 2020 2062 203d 2061 6573 6172 612e 7072     b = aesara.pr
+00014290: 696e 7469 6e67 2e50 7269 6e74 2822 6222  inting.Print("b"
+000142a0: 2928 6229 0d0a 2020 2020 2020 2020 2020  )(b)..          
+000142b0: 2020 2320 6c20 3d20 3230 302f 2028 6120    # l = 200/ (a 
+000142c0: 2d20 6229 0d0a 2020 2020 2020 2020 2020  - b)..          
+000142d0: 2020 736c 6963 655f 696e 6974 203d 2061    slice_init = a
+000142e0: 6573 6172 612e 7072 696e 7469 6e67 2e50  esara.printing.P
+000142f0: 7269 6e74 2822 736c 6963 655f 696e 6974  rint("slice_init
+00014300: 2229 2873 6c69 6365 5f69 6e69 7429 0d0a  ")(slice_init)..
+00014310: 2020 2020 2020 2020 2020 2020 6e5f 7375              n_su
+00014320: 7266 6163 655f 3020 3d20 6165 7361 7261  rface_0 = aesara
+00014330: 2e70 7269 6e74 696e 672e 5072 696e 7428  .printing.Print(
+00014340: 226e 5f73 7572 6661 6365 5f30 2229 286e  "n_surface_0")(n
+00014350: 5f73 7572 6661 6365 5f30 290d 0a20 2020  _surface_0)..   
+00014360: 2020 2020 2020 2020 206e 5f73 7572 6661           n_surfa
+00014370: 6365 5f31 203d 2061 6573 6172 612e 7072  ce_1 = aesara.pr
+00014380: 696e 7469 6e67 2e50 7269 6e74 2822 6e5f  inting.Print("n_
+00014390: 7375 7266 6163 655f 3122 2928 6e5f 7375  surface_1")(n_su
+000143a0: 7266 6163 655f 3129 0d0a 2020 2020 2020  rface_1)..      
+000143b0: 2020 2020 2020 6472 6966 7420 3d20 6165        drift = ae
+000143c0: 7361 7261 2e70 7269 6e74 696e 672e 5072  sara.printing.Pr
+000143d0: 696e 7428 2264 7269 6674 5b73 6c69 6365  int("drift[slice
+000143e0: 5f69 6e69 743a 736c 6963 655f 696e 6974  _init:slice_init
+000143f0: 2b31 5d5b 305d 2229 2864 7269 6674 290d  +1][0]")(drift).
+00014400: 0a0d 0a20 2020 2020 2020 2023 2054 6865  ...        # The
+00014410: 2035 2072 756c 6573 2074 6865 2073 6c6f   5 rules the slo
+00014420: 7065 206f 6620 7468 6520 6675 6e63 7469  pe of the functi
+00014430: 6f6e 0d0a 2020 2020 2020 2020 7369 676d  on..        sigm
+00014440: 203d 2028 2d6e 5f73 7572 6661 6365 5f30   = (-n_surface_0
+00014450: 2e72 6573 6861 7065 2828 2d31 2c20 3129  .reshape((-1, 1)
+00014460: 2920 2f20 2831 202b 2054 2e65 7870 282d  ) / (1 + T.exp(-
+00014470: 6c20 2a20 285a 5f78 202d 2061 2929 2929  l * (Z_x - a))))
+00014480: 205c 0d0a 2020 2020 2020 2020 2020 2020   \..            
+00014490: 2020 202d 2028 6e5f 7375 7266 6163 655f     - (n_surface_
+000144a0: 312e 7265 7368 6170 6528 282d 312c 2031  1.reshape((-1, 1
+000144b0: 2929 202f 2028 3120 2b20 542e 6578 7028  )) / (1 + T.exp(
+000144c0: 6c20 2a20 285a 5f78 202d 2062 2929 2929  l * (Z_x - b))))
+000144d0: 202b 2064 7269 6674 2e72 6573 6861 7065   + drift.reshape
+000144e0: 2828 2d31 2c20 3129 290d 0a20 2020 2020  ((-1, 1))..     
+000144f0: 2020 2069 6620 2773 6967 6d61 2720 696e     if 'sigma' in
+00014500: 2073 656c 662e 7665 7262 6f73 653a 0d0a   self.verbose:..
+00014510: 2020 2020 2020 2020 2020 2020 7369 676d              sigm
+00014520: 203d 2061 6573 6172 612e 7072 696e 7469   = aesara.printi
+00014530: 6e67 2e50 7269 6e74 2822 6d69 6464 6c65  ng.Print("middle
+00014540: 2070 6f69 6e74 2229 2873 6967 6d29 0d0a   point")(sigm)..
+00014550: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+00014560: 6967 6d0d 0a0d 0a20 2020 2064 6566 2065  igm....    def e
+00014570: 7870 6f72 745f 6661 756c 745f 626c 6f63  xport_fault_bloc
+00014580: 6b28 7365 6c66 2c20 5a5f 782c 2073 6361  k(self, Z_x, sca
+00014590: 6c61 725f 6669 656c 645f 6174 5f73 7572  lar_field_at_sur
+000145a0: 6661 6365 5f70 6f69 6e74 732c 0d0a 2020  face_points,..  
+000145b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000145c0: 2020 2020 2020 2020 2076 616c 7565 735f           values_
+000145d0: 7072 6f70 6572 7469 6573 5f6f 702c 2066  properties_op, f
+000145e0: 696e 6974 655f 6661 756c 7473 5f73 656c  inite_faults_sel
+000145f0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00014600: 2020 2020 2020 2020 2020 2020 2020 736c                sl
+00014610: 6f70 653d 3530 2c20 6f66 6673 6574 5f73  ope=50, offset_s
+00014620: 6c6f 7065 3d39 3530 293a 0d0a 2020 2020  lope=950):..    
+00014630: 2020 2020 2222 220d 0a20 2020 2020 2020      """..       
+00014640: 2043 6f6d 7075 7465 2074 6865 2070 6172   Compute the par
+00014650: 7420 6f66 2074 6865 2062 6c6f 636b 206d  t of the block m
+00014660: 6f64 656c 206f 6620 6120 6769 7665 6e20  odel of a given 
+00014670: 7365 7269 6573 2028 6469 6374 6174 6564  series (dictated
+00014680: 2062 7920 7468 6520 626f 6f6c 2061 7272   by the bool arr
+00014690: 6179 2079 6574 2074 6f20 6265 2063 6f6d  ay yet to be com
+000146a0: 7075 7465 6429 0d0a 0d0a 2020 2020 2020  puted)....      
+000146b0: 2020 5265 7475 726e 733a 0d0a 2020 2020    Returns:..    
+000146c0: 2020 2020 2020 2020 6165 7361 7261 2e74          aesara.t
+000146d0: 656e 736f 722e 7665 6374 6f72 3a20 5661  ensor.vector: Va
+000146e0: 6c75 6520 6f66 206c 6974 686f 6c6f 6779  lue of lithology
+000146f0: 2061 7420 6576 6572 7920 696e 7465 7270   at every interp
+00014700: 6f6c 6174 6564 2070 6f69 6e74 0d0a 2020  olated point..  
+00014710: 2020 2020 2020 2222 220d 0a0d 0a20 2020        """....   
+00014720: 2020 2020 2023 2069 6620 5a5f 7820 6973       # if Z_x is
+00014730: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
+00014740: 2320 2020 2020 5a5f 7820 3d20 7365 6c66  #     Z_x = self
+00014750: 2e5a 5f78 0d0a 0d0a 2020 2020 2020 2020  .Z_x....        
+00014760: 2320 4d61 7820 616e 6420 6d69 6e20 7661  # Max and min va
+00014770: 6c75 6573 206f 6620 7468 6520 706f 7465  lues of the pote
+00014780: 6e74 6961 6c20 6669 656c 642e 0d0a 2020  ntial field...  
+00014790: 2020 2020 2020 2320 6d61 785f 706f 7420        # max_pot 
+000147a0: 3d20 542e 6d61 7828 5a5f 7829 202b 2031  = T.max(Z_x) + 1
+000147b0: 0d0a 2020 2020 2020 2020 2320 6d69 6e5f  ..        # min_
+000147c0: 706f 7420 3d20 542e 6d69 6e28 5a5f 7829  pot = T.min(Z_x)
+000147d0: 202d 2031 0d0a 2020 2020 2020 2020 2320   - 1..        # 
+000147e0: 6d61 785f 706f 7420 2b3d 206d 6178 5f70  max_pot += max_p
+000147f0: 6f74 202a 2030 2e31 0d0a 2020 2020 2020  ot * 0.1..      
+00014800: 2020 2320 6d69 6e5f 706f 7420 2d3d 206d    # min_pot -= m
+00014810: 696e 5f70 6f74 202a 2030 2e31 0d0a 0d0a  in_pot * 0.1....
+00014820: 2020 2020 2020 2020 2320 5661 6c75 6520          # Value 
+00014830: 6f66 2074 6865 2070 6f74 656e 7469 616c  of the potential
+00014840: 2066 6965 6c64 2061 7420 7468 6520 7375   field at the su
+00014850: 7266 6163 655f 706f 696e 7473 206f 6620  rface_points of 
+00014860: 7468 6520 636f 6d70 7574 6564 2073 6572  the computed ser
+00014870: 6965 730d 0a20 2020 2020 2020 2023 2054  ies..        # T
+00014880: 4f44 4f20 7469 6d65 6974 2e20 4920 7468  ODO timeit. I th
+00014890: 696e 6b20 7468 650d 0a20 2020 2020 2020  ink the..       
+000148a0: 206d 6178 5f70 6f74 203d 2054 2e6d 6178   max_pot = T.max
+000148b0: 285a 5f78 290d 0a20 2020 2020 2020 2023  (Z_x)..        #
+000148c0: 206d 6178 5f70 6f74 203d 2061 6573 6172   max_pot = aesar
+000148d0: 612e 7072 696e 7469 6e67 2e50 7269 6e74  a.printing.Print
+000148e0: 2822 6d61 785f 706f 7422 2928 6d61 785f  ("max_pot")(max_
+000148f0: 706f 7429 0d0a 0d0a 2020 2020 2020 2020  pot)....        
+00014900: 6d69 6e5f 706f 7420 3d20 542e 6d69 6e28  min_pot = T.min(
+00014910: 5a5f 7829 0d0a 2020 2020 2020 2020 2320  Z_x)..        # 
+00014920: 2020 2020 6d69 6e5f 706f 7420 3d20 6165      min_pot = ae
+00014930: 7361 7261 2e70 7269 6e74 696e 672e 5072  sara.printing.Pr
+00014940: 696e 7428 226d 696e 5f70 6f74 2229 286d  int("min_pot")(m
+00014950: 696e 5f70 6f74 290d 0a0d 0a20 2020 2020  in_pot)....     
+00014960: 2020 2023 206d 6178 5f70 6f74 5f73 6967     # max_pot_sig
+00014970: 6d20 3d20 3220 2a20 6d61 785f 706f 7420  m = 2 * max_pot 
+00014980: 2d20 7365 6c66 2e73 6361 6c61 725f 6669  - self.scalar_fi
+00014990: 656c 645f 6174 5f73 7572 6661 6365 5f70  eld_at_surface_p
+000149a0: 6f69 6e74 735f 7661 6c75 6573 5b30 5d0d  oints_values[0].
+000149b0: 0a20 2020 2020 2020 2023 206d 696e 5f70  .        # min_p
+000149c0: 6f74 5f73 6967 6d20 3d20 3220 2a20 6d69  ot_sigm = 2 * mi
+000149d0: 6e5f 706f 7420 2d20 7365 6c66 2e73 6361  n_pot - self.sca
+000149e0: 6c61 725f 6669 656c 645f 6174 5f73 7572  lar_field_at_sur
+000149f0: 6661 6365 5f70 6f69 6e74 735f 7661 6c75  face_points_valu
+00014a00: 6573 5b2d 315d 0d0a 0d0a 2020 2020 2020  es[-1]....      
+00014a10: 2020 626f 756e 6461 7279 5f70 6164 203d    boundary_pad =
+00014a20: 2028 6d61 785f 706f 7420 2d20 6d69 6e5f   (max_pot - min_
+00014a30: 706f 7429 202a 2030 2e30 310d 0a20 2020  pot) * 0.01..   
+00014a40: 2020 2020 2023 206c 203d 2073 6c6f 7065       # l = slope
+00014a50: 202f 2028 6d61 785f 706f 7420 2d20 6d69   / (max_pot - mi
+00014a60: 6e5f 706f 7429 2020 2320 286d 6178 5f70  n_pot)  # (max_p
+00014a70: 6f74 202d 206d 696e 5f70 6f74 290d 0a0d  ot - min_pot)...
+00014a80: 0a20 2020 2020 2020 2023 2054 6869 7320  .        # This 
+00014a90: 6973 2074 6865 2064 6966 6665 7265 6e74  is the different
+00014aa0: 206c 696e 6520 7769 7468 2072 6573 7065   line with respe
+00014ab0: 6374 206c 6179 6572 730d 0a20 2020 2020  ct layers..     
+00014ac0: 2020 2023 206c 203d 2054 2e73 7769 7463     # l = T.switc
+00014ad0: 6828 6669 6e69 7465 5f66 6175 6c74 735f  h(finite_faults_
+00014ae0: 7365 6c2c 206f 6666 7365 745f 736c 6f70  sel, offset_slop
+00014af0: 6520 2f20 286d 6178 5f70 6f74 202d 206d  e / (max_pot - m
+00014b00: 696e 5f70 6f74 292c 2073 6c6f 7065 202f  in_pot), slope /
+00014b10: 2028 6d61 785f 706f 7420 2d20 6d69 6e5f   (max_pot - min_
+00014b20: 706f 7429 290d 0a20 2020 2020 2020 2023  pot))..        #
+00014b30: 2020 6c20 3d20 6165 7361 7261 2e70 7269    l = aesara.pri
+00014b40: 6e74 696e 672e 5072 696e 7428 226c 2229  nting.Print("l")
+00014b50: 286c 290d 0a0d 0a20 2020 2020 2020 2023  (l)....        #
+00014b60: 202d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d   ---------------
+00014b70: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00014b80: 0d0a 2020 2020 2020 2020 2320 416c 6578  ..        # Alex
+00014b90: 2053 6368 6161 6620 636f 6e74 7269 6275   Schaaf contribu
+00014ba0: 7469 6f6e 3a0d 0a20 2020 2020 2020 2023  tion:..        #
+00014bb0: 2065 6c6c 6970 7365 5f66 6163 746f 7220   ellipse_factor 
+00014bc0: 3d20 7365 6c66 2e73 656c 6563 745f 6669  = self.select_fi
+00014bd0: 6e69 7465 5f66 6175 6c74 7328 290d 0a20  nite_faults().. 
+00014be0: 2020 2020 2020 2065 6c6c 6970 7365 5f66         ellipse_f
+00014bf0: 6163 746f 725f 7265 6374 6966 6965 6420  actor_rectified 
+00014c00: 3d20 542e 7377 6974 6368 2866 696e 6974  = T.switch(finit
+00014c10: 655f 6661 756c 7473 5f73 656c 203c 2031  e_faults_sel < 1
+00014c20: 2e2c 0d0a 2020 2020 2020 2020 2020 2020  .,..            
+00014c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014c50: 6669 6e69 7465 5f66 6175 6c74 735f 7365  finite_faults_se
+00014c60: 6c2c 2031 2e29 0d0a 0d0a 2020 2020 2020  l, 1.)....      
+00014c70: 2020 6966 2022 7365 6c65 6374 5f66 696e    if "select_fin
+00014c80: 6974 655f 6661 756c 7473 2220 696e 2073  ite_faults" in s
+00014c90: 656c 662e 7665 7262 6f73 653a 0d0a 2020  elf.verbose:..  
+00014ca0: 2020 2020 2020 2020 2020 656c 6c69 7073            ellips
+00014cb0: 655f 6661 6374 6f72 5f72 6563 7469 6669  e_factor_rectifi
+00014cc0: 6564 203d 2061 6573 6172 612e 7072 696e  ed = aesara.prin
+00014cd0: 7469 6e67 2e50 7269 6e74 2822 685f 6661  ting.Print("h_fa
+00014ce0: 6374 6f72 5f72 6563 7469 6669 6564 2229  ctor_rectified")
+00014cf0: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+00014d00: 2020 2065 6c6c 6970 7365 5f66 6163 746f     ellipse_facto
+00014d10: 725f 7265 6374 6966 6965 6429 0d0a 0d0a  r_rectified)....
+00014d20: 2020 2020 2020 2020 6966 2022 7365 6c65          if "sele
+00014d30: 6374 5f66 696e 6974 655f 6661 756c 7473  ct_finite_faults
+00014d40: 2220 696e 2073 656c 662e 7665 7262 6f73  " in self.verbos
+00014d50: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+00014d60: 6d69 6e5f 706f 7420 3d20 6165 7361 7261  min_pot = aesara
+00014d70: 2e70 7269 6e74 696e 672e 5072 696e 7428  .printing.Print(
+00014d80: 226d 696e 5f70 6f74 2229 286d 696e 5f70  "min_pot")(min_p
+00014d90: 6f74 290d 0a20 2020 2020 2020 2020 2020  ot)..           
+00014da0: 206d 6178 5f70 6f74 203d 2061 6573 6172   max_pot = aesar
+00014db0: 612e 7072 696e 7469 6e67 2e50 7269 6e74  a.printing.Print
+00014dc0: 2822 6d61 785f 706f 7422 2928 6d61 785f  ("max_pot")(max_
+00014dd0: 706f 7429 0d0a 0d0a 2020 2020 2020 2020  pot)....        
+00014de0: 2320 7369 676d 6f69 645f 736c 6f70 6520  # sigmoid_slope 
+00014df0: 3d20 2873 656c 662e 6e6f 745f 6c20 2a20  = (self.not_l * 
+00014e00: 2831 202f 2065 6c6c 6970 7365 5f66 6163  (1 / ellipse_fac
+00014e10: 746f 725f 7265 6374 6966 6965 6429 2a2a  tor_rectified)**
+00014e20: 3329 202f 2028 6d61 785f 706f 7420 2d20  3) / (max_pot - 
+00014e30: 6d69 6e5f 706f 7429 0d0a 2020 2020 2020  min_pot)..      
+00014e40: 2020 7369 676d 6f69 645f 736c 6f70 6520    sigmoid_slope 
+00014e50: 3d20 6f66 6673 6574 5f73 6c6f 7065 202d  = offset_slope -
+00014e60: 206f 6666 7365 745f 736c 6f70 6520 2a20   offset_slope * 
+00014e70: 656c 6c69 7073 655f 6661 6374 6f72 5f72  ellipse_factor_r
+00014e80: 6563 7469 6669 6564 202a 2a20 7365 6c66  ectified ** self
+00014e90: 2e65 6c6c 6970 7365 5f66 6163 746f 725f  .ellipse_factor_
+00014ea0: 6578 706f 6e65 6e74 202b 2073 656c 662e  exponent + self.
+00014eb0: 6e6f 745f 6c0d 0a20 2020 2020 2020 2023  not_l..        #
+00014ec0: 206c 203d 2054 2e73 7769 7463 6828 7365   l = T.switch(se
+00014ed0: 6c66 2e73 656c 6563 745f 6669 6e69 7465  lf.select_finite
+00014ee0: 5f66 6175 6c74 7328 292c 2035 3030 3020  _faults(), 5000 
+00014ef0: 2f20 286d 6178 5f70 6f74 202d 206d 696e  / (max_pot - min
+00014f00: 5f70 6f74 292c 2035 3020 2f20 286d 6178  _pot), 50 / (max
+00014f10: 5f70 6f74 202d 206d 696e 5f70 6f74 2929  _pot - min_pot))
+00014f20: 0d0a 0d0a 2020 2020 2020 2020 6966 2022  ....        if "
+00014f30: 7365 6c65 6374 5f66 696e 6974 655f 6661  select_finite_fa
+00014f40: 756c 7473 2220 696e 2073 656c 662e 7665  ults" in self.ve
+00014f50: 7262 6f73 653a 0d0a 2020 2020 2020 2020  rbose:..        
+00014f60: 2020 2020 7369 676d 6f69 645f 736c 6f70      sigmoid_slop
+00014f70: 6520 3d20 6165 7361 7261 2e70 7269 6e74  e = aesara.print
+00014f80: 696e 672e 5072 696e 7428 226c 2229 2873  ing.Print("l")(s
+00014f90: 6967 6d6f 6964 5f73 6c6f 7065 290d 0a20  igmoid_slope).. 
+00014fa0: 2020 2020 2020 2023 202d 2d2d 2d2d 2d2d         # -------
+00014fb0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00014fc0: 2d2d 2d2d 2d2d 2d2d 2d0d 0a20 2020 2020  ---------..     
+00014fd0: 2020 2023 2041 2074 656e 736f 7220 7769     # A tensor wi
+00014fe0: 7468 2074 6865 2076 616c 7565 7320 746f  th the values to
+00014ff0: 2073 6567 6d65 6e74 0d0a 2020 2020 2020   segment..      
+00015000: 2020 7363 616c 6172 5f66 6965 6c64 5f69    scalar_field_i
+00015010: 7465 7220 3d20 542e 636f 6e63 6174 656e  ter = T.concaten
+00015020: 6174 6528 280d 0a20 2020 2020 2020 2020  ate((..         
+00015030: 2020 2054 2e73 7461 636b 285b 6d61 785f     T.stack([max_
+00015040: 706f 7420 2b20 626f 756e 6461 7279 5f70  pot + boundary_p
+00015050: 6164 5d2c 2061 7869 733d 3029 2c0d 0a20  ad], axis=0),.. 
+00015060: 2020 2020 2020 2020 2020 2073 6361 6c61             scala
+00015070: 725f 6669 656c 645f 6174 5f73 7572 6661  r_field_at_surfa
+00015080: 6365 5f70 6f69 6e74 732c 0d0a 2020 2020  ce_points,..    
+00015090: 2020 2020 2020 2020 542e 7374 6163 6b28          T.stack(
+000150a0: 5b6d 696e 5f70 6f74 202d 2062 6f75 6e64  [min_pot - bound
+000150b0: 6172 795f 7061 645d 2c20 6178 6973 3d30  ary_pad], axis=0
+000150c0: 290d 0a20 2020 2020 2020 2029 290d 0a0d  )..        ))...
+000150d0: 0a20 2020 2020 2020 2069 6620 2273 6361  .        if "sca
+000150e0: 6c61 725f 6669 656c 645f 6974 6572 2220  lar_field_iter" 
+000150f0: 696e 2073 656c 662e 7665 7262 6f73 653a  in self.verbose:
+00015100: 0d0a 2020 2020 2020 2020 2020 2020 7363  ..            sc
+00015110: 616c 6172 5f66 6965 6c64 5f69 7465 7220  alar_field_iter 
+00015120: 3d20 6165 7361 7261 2e70 7269 6e74 696e  = aesara.printin
+00015130: 672e 5072 696e 7428 2273 6361 6c61 725f  g.Print("scalar_
+00015140: 6669 656c 645f 6974 6572 2229 280d 0a20  field_iter")(.. 
+00015150: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00015160: 6361 6c61 725f 6669 656c 645f 6974 6572  calar_field_iter
+00015170: 290d 0a0d 0a20 2020 2020 2020 2023 2048  )....        # H
+00015180: 6572 6520 7765 206a 7573 7420 7461 6b65  ere we just take
+00015190: 2074 6865 2066 6972 7374 2065 6c65 6d65   the first eleme
+000151a0: 6e74 206f 6620 7661 6c75 6573 2070 726f  nt of values pro
+000151b0: 7065 7274 6965 7320 6265 6361 7573 6520  perties because 
+000151c0: 6174 206c 6561 7374 2073 6f20 6661 7220  at least so far 
+000151d0: 7765 2064 6f20 6e6f 7420 6669 6e64 2061  we do not find a
+000151e0: 2072 6561 736f 6e0d 0a20 2020 2020 2020   reason..       
+000151f0: 2023 2074 6f20 706f 7075 6c61 7465 2066   # to populate f
+00015200: 6175 6c74 2062 6c6f 636b 7320 7769 7468  ault blocks with
+00015210: 2061 6e79 7468 696e 6720 656c 7365 0d0a   anything else..
+00015220: 0d0a 2020 2020 2020 2020 6e5f 7375 7266  ..        n_surf
+00015230: 6163 655f 6f70 5f66 6c6f 6174 5f73 6967  ace_op_float_sig
+00015240: 6d6f 6964 203d 2054 2e72 6570 6561 7428  moid = T.repeat(
+00015250: 7661 6c75 6573 5f70 726f 7065 7274 6965  values_propertie
+00015260: 735f 6f70 5b5b 305d 2c20 3a5d 2c20 322c  s_op[[0], :], 2,
+00015270: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00015280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000152a0: 6178 6973 3d31 290d 0a0d 0a20 2020 2020  axis=1)....     
+000152b0: 2020 2023 2054 4f44 4f3a 2069 6e73 7465     # TODO: inste
+000152c0: 6164 202d 3120 6174 2074 6865 2062 6f72  ad -1 at the bor
+000152d0: 6465 7220 6c6f 6f6b 2066 6f72 2074 6865  der look for the
+000152e0: 2061 7665 7261 6765 2064 6973 7461 6e63   average distanc
+000152f0: 6520 6f66 2074 6865 2069 6e70 7574 210d  e of the input!.
+00015300: 0a20 2020 2020 2020 2023 2054 4f44 4f20  .        # TODO 
+00015310: 4920 7468 696e 6b20 7368 6f75 6c64 2062  I think should b
+00015320: 6520 2d3e 206e 5f73 7572 6661 6365 5f6f  e -> n_surface_o
+00015330: 705f 666c 6f61 745f 7369 676d 6f69 645b  p_float_sigmoid[
+00015340: 3a2c 2032 5d20 2d20 6e5f 7375 7266 6163  :, 2] - n_surfac
+00015350: 655f 6f70 5f66 6c6f 6174 5f73 6967 6d6f  e_op_float_sigmo
+00015360: 6964 5b3a 2c20 315d 0d0a 2020 2020 2020  id[:, 1]..      
+00015370: 2020 6e5f 7375 7266 6163 655f 6f70 5f66    n_surface_op_f
+00015380: 6c6f 6174 5f73 6967 6d6f 6964 203d 2054  loat_sigmoid = T
+00015390: 2e73 6574 5f73 7562 7465 6e73 6f72 280d  .set_subtensor(.
+000153a0: 0a20 2020 2020 2020 2020 2020 206e 5f73  .            n_s
+000153b0: 7572 6661 6365 5f6f 705f 666c 6f61 745f  urface_op_float_
+000153c0: 7369 676d 6f69 645b 3a2c 2031 5d2c 202d  sigmoid[:, 1], -
+000153d0: 3129 0d0a 2020 2020 2020 2020 2320 2d20  1)..        # - 
+000153e0: 542e 7371 7274 2854 2e73 7175 6172 6528  T.sqrt(T.square(
+000153f0: 6e5f 7375 7266 6163 655f 6f70 5f66 6c6f  n_surface_op_flo
+00015400: 6174 5f73 6967 6d6f 6964 5b30 5d20 2d20  at_sigmoid[0] - 
+00015410: 6e5f 7375 7266 6163 655f 6f70 5f66 6c6f  n_surface_op_flo
+00015420: 6174 5f73 6967 6d6f 6964 5b32 5d29 2929  at_sigmoid[2])))
+00015430: 0d0a 0d0a 2020 2020 2020 2020 6e5f 7375  ....        n_su
+00015440: 7266 6163 655f 6f70 5f66 6c6f 6174 5f73  rface_op_float_s
+00015450: 6967 6d6f 6964 203d 2054 2e73 6574 5f73  igmoid = T.set_s
+00015460: 7562 7465 6e73 6f72 280d 0a20 2020 2020  ubtensor(..     
+00015470: 2020 2020 2020 206e 5f73 7572 6661 6365         n_surface
+00015480: 5f6f 705f 666c 6f61 745f 7369 676d 6f69  _op_float_sigmoi
+00015490: 645b 3a2c 202d 315d 2c20 2d31 290d 0a20  d[:, -1], -1).. 
+000154a0: 2020 2020 2020 2023 202d 2054 2e73 7172         # - T.sqr
+000154b0: 7428 542e 7371 7561 7265 286e 5f73 7572  t(T.square(n_sur
+000154c0: 6661 6365 5f6f 705f 666c 6f61 745f 7369  face_op_float_si
+000154d0: 676d 6f69 645b 335d 202d 206e 5f73 7572  gmoid[3] - n_sur
+000154e0: 6661 6365 5f6f 705f 666c 6f61 745f 7369  face_op_float_si
+000154f0: 676d 6f69 645b 2d31 5d29 2929 0d0a 0d0a  gmoid[-1])))....
+00015500: 2020 2020 2020 2020 6472 6966 7420 3d20          drift = 
+00015510: 542e 7365 745f 7375 6274 656e 736f 7228  T.set_subtensor(
+00015520: 6e5f 7375 7266 6163 655f 6f70 5f66 6c6f  n_surface_op_flo
+00015530: 6174 5f73 6967 6d6f 6964 5b3a 2c20 305d  at_sigmoid[:, 0]
+00015540: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00015550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015560: 2020 206e 5f73 7572 6661 6365 5f6f 705f     n_surface_op_
+00015570: 666c 6f61 745f 7369 676d 6f69 645b 3a2c  float_sigmoid[:,
+00015580: 2031 5d29 0d0a 0d0a 2020 2020 2020 2020   1])....        
+00015590: 6966 2027 6e5f 7375 7266 6163 655f 6f70  if 'n_surface_op
+000155a0: 5f66 6c6f 6174 5f73 6967 6d6f 6964 2720  _float_sigmoid' 
+000155b0: 696e 2073 656c 662e 7665 7262 6f73 653a  in self.verbose:
+000155c0: 0d0a 2020 2020 2020 2020 2020 2020 6e5f  ..            n_
+000155d0: 7375 7266 6163 655f 6f70 5f66 6c6f 6174  surface_op_float
+000155e0: 5f73 6967 6d6f 6964 203d 2061 6573 6172  _sigmoid = aesar
+000155f0: 612e 7072 696e 7469 6e67 2e50 7269 6e74  a.printing.Print
+00015600: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+00015610: 2020 2022 6e5f 7375 7266 6163 655f 6f70     "n_surface_op
+00015620: 5f66 6c6f 6174 5f73 6967 6d6f 6964 2229  _float_sigmoid")
+00015630: 205c 0d0a 2020 2020 2020 2020 2020 2020   \..            
+00015640: 2020 2020 286e 5f73 7572 6661 6365 5f6f      (n_surface_o
+00015650: 705f 666c 6f61 745f 7369 676d 6f69 6429  p_float_sigmoid)
+00015660: 0d0a 0d0a 2020 2020 2020 2020 6661 756c  ....        faul
+00015670: 745f 626c 6f63 6b2c 2075 7064 6174 6573  t_block, updates
+00015680: 3220 3d20 6165 7361 7261 2e73 6361 6e28  2 = aesara.scan(
+00015690: 0d0a 2020 2020 2020 2020 2020 2020 666e  ..            fn
+000156a0: 3d73 656c 662e 636f 6d70 6172 652c 0d0a  =self.compare,..
+000156b0: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
+000156c0: 7574 735f 696e 666f 3d4e 6f6e 652c 0d0a  uts_info=None,..
+000156d0: 2020 2020 2020 2020 2020 2020 7365 7175              sequ
+000156e0: 656e 6365 733d 5b64 6963 7428 696e 7075  ences=[dict(inpu
+000156f0: 743d 7363 616c 6172 5f66 6965 6c64 5f69  t=scalar_field_i
+00015700: 7465 722c 2074 6170 733d 5b30 2c20 315d  ter, taps=[0, 1]
+00015710: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
+00015720: 2020 2020 2020 2020 2020 2054 2e61 7261             T.ara
+00015730: 6e67 6528 302c 206e 5f73 7572 6661 6365  nge(0, n_surface
+00015740: 5f6f 705f 666c 6f61 745f 7369 676d 6f69  _op_float_sigmoi
+00015750: 642e 7368 6170 655b 315d 2c20 322c 0d0a  d.shape[1], 2,..
+00015760: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015780: 6474 7970 653d 2769 6e74 3634 2729 5d2c  dtype='int64')],
+00015790: 0d0a 2020 2020 2020 2020 2020 2020 6e6f  ..            no
+000157a0: 6e5f 7365 7175 656e 6365 733d 5b5a 5f78  n_sequences=[Z_x
+000157b0: 2c20 7369 676d 6f69 645f 736c 6f70 652c  , sigmoid_slope,
+000157c0: 206e 5f73 7572 6661 6365 5f6f 705f 666c   n_surface_op_fl
+000157d0: 6f61 745f 7369 676d 6f69 642c 2064 7269  oat_sigmoid, dri
+000157e0: 6674 5d2c 0d0a 2020 2020 2020 2020 2020  ft],..          
+000157f0: 2020 6e61 6d65 3d27 4c6f 6f70 696e 6720    name='Looping 
+00015800: 636f 6d70 6172 6527 2c0d 0a20 2020 2020  compare',..     
+00015810: 2020 2020 2020 2070 726f 6669 6c65 3d46         profile=F
+00015820: 616c 7365 2c0d 0a20 2020 2020 2020 2020  alse,..         
+00015830: 2020 2072 6574 7572 6e5f 6c69 7374 3d46     return_list=F
+00015840: 616c 7365 290d 0a0d 0a20 2020 2020 2020  alse)....       
+00015850: 2023 2046 6f72 2065 7665 7279 2073 7572   # For every sur
+00015860: 6661 6365 2077 6520 6765 7420 6120 7665  face we get a ve
+00015870: 6374 6f72 2073 6f20 7765 206e 6565 6420  ctor so we need 
+00015880: 746f 2073 756d 2063 6f6d 7072 6573 7320  to sum compress 
+00015890: 7468 656d 2074 6f20 6f6e 6520 6469 6d65  them to one dime
+000158a0: 6e73 696f 6e0d 0a20 2020 2020 2020 2066  nsion..        f
+000158b0: 6175 6c74 5f62 6c6f 636b 203d 2066 6175  ault_block = fau
+000158c0: 6c74 5f62 6c6f 636b 2e73 756d 2861 7869  lt_block.sum(axi
+000158d0: 733d 3029 0d0a 0d0a 2020 2020 2020 2020  s=0)....        
+000158e0: 2320 4164 6420 6e61 6d65 2074 6f20 7468  # Add name to th
+000158f0: 6520 6165 7361 7261 206e 6f64 650d 0a20  e aesara node.. 
+00015900: 2020 2020 2020 2066 6175 6c74 5f62 6c6f         fault_blo
+00015910: 636b 2e6e 616d 6520 3d20 2754 6865 2063  ck.name = 'The c
+00015920: 6875 6e6b 206f 6620 626c 6f63 6b20 6d6f  hunk of block mo
+00015930: 6465 6c20 6f66 2061 2073 7065 6369 6669  del of a specifi
+00015940: 6320 7365 7269 6573 270d 0a20 2020 2020  c series'..     
+00015950: 2020 2069 6620 7374 7228 7379 732e 5f67     if str(sys._g
+00015960: 6574 6672 616d 6528 292e 665f 636f 6465  etframe().f_code
+00015970: 2e63 6f5f 6e61 6d65 2920 696e 2073 656c  .co_name) in sel
+00015980: 662e 7665 7262 6f73 653a 0d0a 2020 2020  f.verbose:..    
+00015990: 2020 2020 2020 2020 6661 756c 745f 626c          fault_bl
+000159a0: 6f63 6b20 3d20 6165 7361 7261 2e70 7269  ock = aesara.pri
+000159b0: 6e74 696e 672e 5072 696e 7428 6661 756c  nting.Print(faul
+000159c0: 745f 626c 6f63 6b2e 6e61 6d65 2928 6661  t_block.name)(fa
+000159d0: 756c 745f 626c 6f63 6b29 0d0a 0d0a 2020  ult_block)....  
+000159e0: 2020 2020 2020 7265 7475 726e 2066 6175        return fau
+000159f0: 6c74 5f62 6c6f 636b 0d0a 0d0a 2020 2020  lt_block....    
+00015a00: 6465 6620 6578 706f 7274 5f66 6f72 6d61  def export_forma
+00015a10: 7469 6f6e 5f62 6c6f 636b 2873 656c 662c  tion_block(self,
+00015a20: 205a 5f78 2c20 7363 616c 6172 5f66 6965   Z_x, scalar_fie
+00015a30: 6c64 5f61 745f 7375 7266 6163 655f 706f  ld_at_surface_po
+00015a40: 696e 7473 2c0d 0a20 2020 2020 2020 2020  ints,..         
+00015a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015a60: 2020 2020 2020 7661 6c75 6573 5f70 726f        values_pro
+00015a70: 7065 7274 6965 735f 6f70 293a 0d0a 2020  perties_op):..  
+00015a80: 2020 2020 2020 2222 220d 0a20 2020 2020        """..     
+00015a90: 2020 2043 6f6d 7075 7465 2074 6865 2070     Compute the p
+00015aa0: 6172 7420 6f66 2074 6865 2062 6c6f 636b  art of the block
+00015ab0: 206d 6f64 656c 206f 6620 6120 6769 7665   model of a give
+00015ac0: 6e20 7365 7269 6573 2028 6469 6374 6174  n series (dictat
+00015ad0: 6564 2062 7920 7468 6520 626f 6f6c 2061  ed by the bool a
+00015ae0: 7272 6179 2079 6574 2074 6f20 6265 2063  rray yet to be c
+00015af0: 6f6d 7075 7465 6429 0d0a 0d0a 2020 2020  omputed)....    
+00015b00: 2020 2020 5265 7475 726e 733a 0d0a 2020      Returns:..  
+00015b10: 2020 2020 2020 2020 2020 6165 7361 7261            aesara
+00015b20: 2e74 656e 736f 722e 7665 6374 6f72 3a20  .tensor.vector: 
+00015b30: 5661 6c75 6520 6f66 206c 6974 686f 6c6f  Value of litholo
+00015b40: 6779 2061 7420 6576 6572 7920 696e 7465  gy at every inte
+00015b50: 7270 6f6c 6174 6564 2070 6f69 6e74 0d0a  rpolated point..
+00015b60: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
+00015b70: 2020 2020 2023 2054 4f44 4f3a 2049 4d50       # TODO: IMP
+00015b80: 2073 6574 2073 6f66 7420 6d61 7820 696e   set soft max in
+00015b90: 2074 6865 2062 6f72 6465 7273 3a20 5465   the borders: Te
+00015ba0: 7374 0d0a 2020 2020 2020 2020 2320 544f  st..        # TO
+00015bb0: 444f 3a20 696e 7374 6561 6420 2d31 2061  DO: instead -1 a
+00015bc0: 7420 7468 6520 626f 7264 6572 206c 6f6f  t the border loo
+00015bd0: 6b20 666f 7220 7468 6520 6176 6572 6167  k for the averag
+00015be0: 6520 6469 7374 616e 6365 206f 6620 7468  e distance of th
+00015bf0: 6520 696e 7075 7421 3a20 5465 7374 0d0a  e input!: Test..
+00015c00: 0d0a 2020 2020 2020 2020 736c 6f70 6520  ..        slope 
+00015c10: 3d20 7365 6c66 2e73 6967 5f73 6c6f 7065  = self.sig_slope
+00015c20: 0d0a 2020 2020 2020 2020 6966 2073 656c  ..        if sel
+00015c30: 662e 6d61 785f 7370 6565 6420 3c20 313a  f.max_speed < 1:
+00015c40: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
+00015c50: 6d61 785f 706f 7420 3d20 542e 6d61 7828  max_pot = T.max(
+00015c60: 7363 616c 6172 5f66 6965 6c64 5f61 745f  scalar_field_at_
+00015c70: 7375 7266 6163 655f 706f 696e 7473 290d  surface_points).
+00015c80: 0a20 2020 2020 2020 2020 2020 2023 206d  .            # m
+00015c90: 696e 5f70 6f74 203d 2054 2e6d 696e 2873  in_pot = T.min(s
+00015ca0: 6361 6c61 725f 6669 656c 645f 6174 5f73  calar_field_at_s
+00015cb0: 7572 6661 6365 5f70 6f69 6e74 7329 0d0a  urface_points)..
+00015cc0: 0d0a 2020 2020 2020 2020 2020 2020 6d61  ..            ma
+00015cd0: 785f 706f 7420 3d20 542e 6d61 7828 5a5f  x_pot = T.max(Z_
+00015ce0: 7829 0d0a 2020 2020 2020 2020 2020 2020  x)..            
+00015cf0: 2320 6d61 785f 706f 7420 3d20 6165 7361  # max_pot = aesa
+00015d00: 7261 2e70 7269 6e74 696e 672e 5072 696e  ra.printing.Prin
+00015d10: 7428 226d 6178 5f70 6f74 2229 286d 6178  t("max_pot")(max
+00015d20: 5f70 6f74 290d 0a20 2020 2020 2020 2020  _pot)..         
+00015d30: 2020 206d 696e 5f70 6f74 203d 2054 2e6d     min_pot = T.m
+00015d40: 696e 285a 5f78 290d 0a20 2020 2020 2020  in(Z_x)..       
+00015d50: 2020 2020 2023 206d 696e 5f70 6f74 203d       # min_pot =
+00015d60: 2061 6573 6172 612e 7072 696e 7469 6e67   aesara.printing
+00015d70: 2e50 7269 6e74 2822 6d69 6e5f 706f 7422  .Print("min_pot"
+00015d80: 2928 6d69 6e5f 706f 7429 0d0a 0d0a 2020  )(min_pot)....  
+00015d90: 2020 2020 2020 2020 2020 2320 6d61 785f            # max_
+00015da0: 706f 745f 7369 676d 203d 2032 202a 206d  pot_sigm = 2 * m
+00015db0: 6178 5f70 6f74 202d 2073 656c 662e 7363  ax_pot - self.sc
+00015dc0: 616c 6172 5f66 6965 6c64 5f61 745f 7375  alar_field_at_su
+00015dd0: 7266 6163 655f 706f 696e 7473 5f76 616c  rface_points_val
+00015de0: 7565 735b 305d 0d0a 2020 2020 2020 2020  ues[0]..        
+00015df0: 2020 2020 2320 6d69 6e5f 706f 745f 7369      # min_pot_si
+00015e00: 676d 203d 2032 202a 206d 696e 5f70 6f74  gm = 2 * min_pot
+00015e10: 202d 2073 656c 662e 7363 616c 6172 5f66   - self.scalar_f
+00015e20: 6965 6c64 5f61 745f 7375 7266 6163 655f  ield_at_surface_
+00015e30: 706f 696e 7473 5f76 616c 7565 735b 2d31  points_values[-1
+00015e40: 5d0d 0a0d 0a20 2020 2020 2020 2020 2020  ]....           
+00015e50: 2023 2062 6f75 6e64 6172 795f 7061 6420   # boundary_pad 
+00015e60: 3d20 286d 6178 5f70 6f74 202d 206d 696e  = (max_pot - min
+00015e70: 5f70 6f74 2920 2a20 302e 3031 0d0a 2020  _pot) * 0.01..  
+00015e80: 2020 2020 2020 2020 2020 6c20 3d20 736c            l = sl
+00015e90: 6f70 6520 2f20 286d 6178 5f70 6f74 202d  ope / (max_pot -
+00015ea0: 206d 696e 5f70 6f74 290d 0a20 2020 2020   min_pot)..     
+00015eb0: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
+00015ec0: 2020 2020 2020 6c20 3d20 736c 6f70 650d        l = slope.
+00015ed0: 0a0d 0a20 2020 2020 2020 2023 2041 2074  ...        # A t
+00015ee0: 656e 736f 7220 7769 7468 2074 6865 2076  ensor with the v
+00015ef0: 616c 7565 7320 746f 2073 6567 6d65 6e74  alues to segment
+00015f00: 0d0a 2020 2020 2020 2020 7363 616c 6172  ..        scalar
+00015f10: 5f66 6965 6c64 5f69 7465 7220 3d20 542e  _field_iter = T.
+00015f20: 636f 6e63 6174 656e 6174 6528 280d 0a20  concatenate((.. 
+00015f30: 2020 2020 2020 2020 2020 2023 2020 542e             #  T.
+00015f40: 7374 6163 6b28 5b54 2e6d 6178 285a 5f78  stack([T.max(Z_x
+00015f50: 295d 2c20 6178 6973 3d30 292c 0d0a 2020  )], axis=0),..  
+00015f60: 2020 2020 2020 2020 2020 542e 7374 6163            T.stac
+00015f70: 6b28 5b30 5d2c 2061 7869 733d 3029 2c20  k([0], axis=0), 
+00015f80: 2023 2073 6f6d 6568 6f77 2074 6869 7320   # somehow this 
+00015f90: 616c 736f 2077 6f72 6b73 2e20 4920 646f  also works. I do
+00015fa0: 206e 6f74 2072 656d 656d 6265 7220 7768   not remember wh
+00015fb0: 790d 0a20 2020 2020 2020 2020 2020 2073  y..            s
+00015fc0: 6361 6c61 725f 6669 656c 645f 6174 5f73  calar_field_at_s
+00015fd0: 7572 6661 6365 5f70 6f69 6e74 732c 0d0a  urface_points,..
+00015fe0: 2020 2020 2020 2020 2020 2020 542e 7374              T.st
+00015ff0: 6163 6b28 5b30 5d2c 2061 7869 733d 3029  ack([0], axis=0)
+00016000: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
+00016010: 2020 542e 7374 6163 6b28 5b54 2e6d 696e    T.stack([T.min
+00016020: 285a 5f78 295d 2c20 6178 6973 3d30 290d  (Z_x)], axis=0).
+00016030: 0a20 2020 2020 2020 2029 290d 0a0d 0a20  .        )).... 
+00016040: 2020 2020 2020 2069 6620 2273 6361 6c61         if "scala
+00016050: 725f 6669 656c 645f 6974 6572 2220 696e  r_field_iter" in
+00016060: 2073 656c 662e 7665 7262 6f73 653a 0d0a   self.verbose:..
+00016070: 2020 2020 2020 2020 2020 2020 7363 616c              scal
+00016080: 6172 5f66 6965 6c64 5f69 7465 7220 3d20  ar_field_iter = 
+00016090: 6165 7361 7261 2e70 7269 6e74 696e 672e  aesara.printing.
+000160a0: 5072 696e 7428 2273 6361 6c61 725f 6669  Print("scalar_fi
+000160b0: 656c 645f 6974 6572 2229 280d 0a20 2020  eld_iter")(..   
+000160c0: 2020 2020 2020 2020 2020 2020 2073 6361               sca
+000160d0: 6c61 725f 6669 656c 645f 6974 6572 290d  lar_field_iter).
+000160e0: 0a0d 0a20 2020 2020 2020 2023 204c 6f6f  ...        # Loo
+000160f0: 7020 746f 2073 6567 6d65 6e74 2074 6865  p to segment the
+00016100: 2064 6973 7469 6e63 7420 6c69 7468 6f6c   distinct lithol
+00016110: 6f67 6965 730d 0a0d 0a20 2020 2020 2020  ogies....       
+00016120: 206e 5f73 7572 6661 6365 5f6f 705f 666c   n_surface_op_fl
+00016130: 6f61 745f 7369 676d 6f69 6420 3d20 542e  oat_sigmoid = T.
+00016140: 7265 7065 6174 2876 616c 7565 735f 7072  repeat(values_pr
+00016150: 6f70 6572 7469 6573 5f6f 702c 2032 2c20  operties_op, 2, 
+00016160: 6178 6973 3d31 290d 0a20 2020 2020 2020  axis=1)..       
+00016170: 206e 5f73 7572 6661 6365 5f6f 705f 666c   n_surface_op_fl
+00016180: 6f61 745f 7369 676d 6f69 6420 3d20 542e  oat_sigmoid = T.
+00016190: 7365 745f 7375 6274 656e 736f 7228 0d0a  set_subtensor(..
+000161a0: 2020 2020 2020 2020 2020 2020 6e5f 7375              n_su
+000161b0: 7266 6163 655f 6f70 5f66 6c6f 6174 5f73  rface_op_float_s
+000161c0: 6967 6d6f 6964 5b3a 2c20 305d 2c20 3029  igmoid[:, 0], 0)
+000161d0: 0d0a 2020 2020 2020 2020 6e5f 7375 7266  ..        n_surf
+000161e0: 6163 655f 6f70 5f66 6c6f 6174 5f73 6967  ace_op_float_sig
+000161f0: 6d6f 6964 203d 2054 2e73 6574 5f73 7562  moid = T.set_sub
+00016200: 7465 6e73 6f72 280d 0a20 2020 2020 2020  tensor(..       
+00016210: 2020 2020 206e 5f73 7572 6661 6365 5f6f       n_surface_o
+00016220: 705f 666c 6f61 745f 7369 676d 6f69 645b  p_float_sigmoid[
+00016230: 3a2c 202d 315d 2c20 3029 0d0a 2020 2020  :, -1], 0)..    
+00016240: 2020 2020 6472 6966 7420 3d20 542e 7365      drift = T.se
+00016250: 745f 7375 6274 656e 736f 7228 6e5f 7375  t_subtensor(n_su
+00016260: 7266 6163 655f 6f70 5f66 6c6f 6174 5f73  rface_op_float_s
+00016270: 6967 6d6f 6964 5b3a 2c20 305d 2c0d 0a20  igmoid[:, 0],.. 
+00016280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016290: 2020 2020 2020 2020 2020 2020 2020 206e                 n
+000162a0: 5f73 7572 6661 6365 5f6f 705f 666c 6f61  _surface_op_floa
+000162b0: 745f 7369 676d 6f69 645b 3a2c 2031 5d29  t_sigmoid[:, 1])
+000162c0: 0d0a 0d0a 2020 2020 2020 2020 6966 2027  ....        if '
+000162d0: 6e5f 7375 7266 6163 655f 6f70 5f66 6c6f  n_surface_op_flo
+000162e0: 6174 5f73 6967 6d6f 6964 2720 696e 2073  at_sigmoid' in s
+000162f0: 656c 662e 7665 7262 6f73 653a 0d0a 2020  elf.verbose:..  
+00016300: 2020 2020 2020 2020 2020 6e5f 7375 7266            n_surf
+00016310: 6163 655f 6f70 5f66 6c6f 6174 5f73 6967  ace_op_float_sig
+00016320: 6d6f 6964 203d 2061 6573 6172 612e 7072  moid = aesara.pr
+00016330: 696e 7469 6e67 2e50 7269 6e74 280d 0a20  inting.Print(.. 
+00016340: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00016350: 6e5f 7375 7266 6163 655f 6f70 5f66 6c6f  n_surface_op_flo
+00016360: 6174 5f73 6967 6d6f 6964 2229 205c 0d0a  at_sigmoid") \..
+00016370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016380: 286e 5f73 7572 6661 6365 5f6f 705f 666c  (n_surface_op_fl
+00016390: 6f61 745f 7369 676d 6f69 6429 0d0a 0d0a  oat_sigmoid)....
+000163a0: 2020 2020 2020 2020 666f 726d 6174 696f          formatio
+000163b0: 6e73 5f62 6c6f 636b 2c20 7570 6461 7465  ns_block, update
+000163c0: 7332 203d 2061 6573 6172 612e 7363 616e  s2 = aesara.scan
+000163d0: 280d 0a20 2020 2020 2020 2020 2020 2066  (..            f
+000163e0: 6e3d 7365 6c66 2e63 6f6d 7061 7265 2c0d  n=self.compare,.
+000163f0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+00016400: 7075 7473 5f69 6e66 6f3d 4e6f 6e65 2c0d  puts_info=None,.
+00016410: 0a20 2020 2020 2020 2020 2020 2073 6571  .            seq
+00016420: 7565 6e63 6573 3d5b 6469 6374 2869 6e70  uences=[dict(inp
+00016430: 7574 3d73 6361 6c61 725f 6669 656c 645f  ut=scalar_field_
+00016440: 6974 6572 2c20 7461 7073 3d5b 302c 2031  iter, taps=[0, 1
+00016450: 5d29 2c0d 0a20 2020 2020 2020 2020 2020  ]),..           
+00016460: 2020 2020 2020 2020 2020 2020 542e 6172              T.ar
+00016470: 616e 6765 2830 2c20 6e5f 7375 7266 6163  ange(0, n_surfac
+00016480: 655f 6f70 5f66 6c6f 6174 5f73 6967 6d6f  e_op_float_sigmo
+00016490: 6964 2e73 6861 7065 5b31 5d2c 2032 2c0d  id.shape[1], 2,.
+000164a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000164b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000164c0: 2064 7479 7065 3d27 696e 7436 3427 295d   dtype='int64')]
+000164d0: 2c0d 0a20 2020 2020 2020 2020 2020 206e  ,..            n
+000164e0: 6f6e 5f73 6571 7565 6e63 6573 3d5b 5a5f  on_sequences=[Z_
+000164f0: 782c 206c 2c20 6e5f 7375 7266 6163 655f  x, l, n_surface_
+00016500: 6f70 5f66 6c6f 6174 5f73 6967 6d6f 6964  op_float_sigmoid
+00016510: 2c20 6472 6966 745d 2c0d 0a20 2020 2020  , drift],..     
+00016520: 2020 2020 2020 206e 616d 653d 274c 6f6f         name='Loo
+00016530: 7069 6e67 2063 6f6d 7061 7265 272c 0d0a  ping compare',..
+00016540: 2020 2020 2020 2020 2020 2020 7072 6f66              prof
+00016550: 696c 653d 4661 6c73 652c 0d0a 2020 2020  ile=False,..    
+00016560: 2020 2020 2020 2020 7265 7475 726e 5f6c          return_l
+00016570: 6973 743d 4661 6c73 6529 0d0a 0d0a 2020  ist=False)....  
+00016580: 2020 2020 2020 2320 466f 7220 6576 6572        # For ever
+00016590: 7920 7375 7266 6163 6520 7765 2067 6574  y surface we get
+000165a0: 2061 2076 6563 746f 7220 736f 2077 6520   a vector so we 
+000165b0: 6e65 6564 2074 6f20 7375 6d20 636f 6d70  need to sum comp
+000165c0: 7265 7373 2074 6865 6d20 746f 206f 6e65  ress them to one
+000165d0: 2064 696d 656e 7369 6f6e 0d0a 2020 2020   dimension..    
+000165e0: 2020 2020 666f 726d 6174 696f 6e73 5f62      formations_b
+000165f0: 6c6f 636b 203d 2066 6f72 6d61 7469 6f6e  lock = formation
+00016600: 735f 626c 6f63 6b2e 7375 6d28 6178 6973  s_block.sum(axis
+00016610: 3d30 290d 0a0d 0a20 2020 2020 2020 2069  =0)....        i
+00016620: 6620 7365 6c66 2e67 7261 6469 656e 7420  f self.gradient 
+00016630: 6973 2054 7275 653a 0d0a 2020 2020 2020  is True:..      
+00016640: 2020 2020 2020 5265 4c55 5f75 7020 3d20        ReLU_up = 
+00016650: 542e 7377 6974 6368 285a 5f78 203c 2073  T.switch(Z_x < s
+00016660: 6361 6c61 725f 6669 656c 645f 6974 6572  calar_field_iter
+00016670: 5b31 5d2c 2030 2c0d 0a20 2020 2020 2020  [1], 0,..       
+00016680: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016690: 2020 2020 2020 2020 2d20 302e 3031 202a          - 0.01 *
+000166a0: 2028 5a5f 7820 2d20 7363 616c 6172 5f66   (Z_x - scalar_f
+000166b0: 6965 6c64 5f69 7465 725b 315d 2929 0d0a  ield_iter[1]))..
+000166c0: 2020 2020 2020 2020 2020 2020 5265 4c55              ReLU
+000166d0: 5f64 6f77 6e20 3d20 542e 7377 6974 6368  _down = T.switch
+000166e0: 285a 5f78 203e 2073 6361 6c61 725f 6669  (Z_x > scalar_fi
+000166f0: 656c 645f 6974 6572 5b2d 325d 2c20 302c  eld_iter[-2], 0,
+00016700: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00016710: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016720: 2020 2030 2e30 3120 2a20 542e 6162 735f     0.01 * T.abs_
+00016730: 285a 5f78 202d 2073 6361 6c61 725f 6669  (Z_x - scalar_fi
+00016740: 656c 645f 6974 6572 5b2d 325d 2929 0d0a  eld_iter[-2]))..
+00016750: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
+00016760: 2027 7265 6c75 2720 696e 2073 656c 662e   'relu' in self.
+00016770: 7665 7262 6f73 653a 0d0a 2020 2020 2020  verbose:..      
+00016780: 2020 2020 2020 2020 2020 5265 4c55 5f75            ReLU_u
+00016790: 7020 3d20 6165 7361 7261 2e70 7269 6e74  p = aesara.print
+000167a0: 696e 672e 5072 696e 7428 2752 654c 555f  ing.Print('ReLU_
+000167b0: 7570 2729 2852 654c 555f 7570 290d 0a20  up')(ReLU_up).. 
+000167c0: 2020 2020 2020 2020 2020 2020 2020 2052                 R
+000167d0: 654c 555f 646f 776e 203d 2061 6573 6172  eLU_down = aesar
+000167e0: 612e 7072 696e 7469 6e67 2e50 7269 6e74  a.printing.Print
+000167f0: 2827 5265 4c55 5f64 6f77 6e27 2928 5265  ('ReLU_down')(Re
+00016800: 4c55 5f64 6f77 6e29 0d0a 0d0a 2020 2020  LU_down)....    
+00016810: 2020 2020 2020 2020 666f 726d 6174 696f          formatio
+00016820: 6e73 5f62 6c6f 636b 202b 3d20 5265 4c55  ns_block += ReLU
+00016830: 5f64 6f77 6e20 2b20 5265 4c55 5f75 700d  _down + ReLU_up.
+00016840: 0a0d 0a20 2020 2020 2020 2023 2041 6464  ...        # Add
+00016850: 206e 616d 6520 746f 2074 6865 2061 6573   name to the aes
+00016860: 6172 6120 6e6f 6465 0d0a 2020 2020 2020  ara node..      
+00016870: 2020 666f 726d 6174 696f 6e73 5f62 6c6f    formations_blo
+00016880: 636b 2e6e 616d 6520 3d20 2754 6865 2063  ck.name = 'The c
+00016890: 6875 6e6b 206f 6620 626c 6f63 6b20 6d6f  hunk of block mo
+000168a0: 6465 6c20 6f66 2061 2073 7065 6369 6669  del of a specifi
+000168b0: 6320 7365 7269 6573 270d 0a20 2020 2020  c series'..     
+000168c0: 2020 2069 6620 7374 7228 7379 732e 5f67     if str(sys._g
+000168d0: 6574 6672 616d 6528 292e 665f 636f 6465  etframe().f_code
+000168e0: 2e63 6f5f 6e61 6d65 2920 696e 2073 656c  .co_name) in sel
+000168f0: 662e 7665 7262 6f73 653a 0d0a 2020 2020  f.verbose:..    
+00016900: 2020 2020 2020 2020 666f 726d 6174 696f          formatio
+00016910: 6e73 5f62 6c6f 636b 203d 2061 6573 6172  ns_block = aesar
+00016920: 612e 7072 696e 7469 6e67 2e50 7269 6e74  a.printing.Print
+00016930: 2866 6f72 6d61 7469 6f6e 735f 626c 6f63  (formations_bloc
+00016940: 6b2e 6e61 6d65 2928 0d0a 2020 2020 2020  k.name)(..      
+00016950: 2020 2020 2020 2020 2020 666f 726d 6174            format
+00016960: 696f 6e73 5f62 6c6f 636b 290d 0a0d 0a20  ions_block).... 
+00016970: 2020 2020 2020 2072 6574 7572 6e20 666f         return fo
+00016980: 726d 6174 696f 6e73 5f62 6c6f 636b 0d0a  rmations_block..
+00016990: 0d0a 2020 2020 2320 656e 6472 6567 696f  ..    # endregio
+000169a0: 6e0d 0a0d 0a20 2020 2023 2072 6567 696f  n....    # regio
+000169b0: 6e20 436f 6d70 7574 6520 6d6f 6465 6c0d  n Compute model.
+000169c0: 0a20 2020 2064 6566 2063 6f6d 7075 7465  .    def compute
+000169d0: 5f61 5f73 6572 6965 7328 7365 6c66 2c0d  _a_series(self,.
+000169e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000169f0: 2020 2020 2020 2020 2020 6c65 6e5f 695f            len_i_
+00016a00: 303d 302c 206c 656e 5f69 5f31 3d4e 6f6e  0=0, len_i_1=Non
+00016a10: 652c 0d0a 2020 2020 2020 2020 2020 2020  e,..            
+00016a20: 2020 2020 2020 2020 2020 2020 206c 656e               len
+00016a30: 5f66 5f30 3d30 2c20 6c65 6e5f 665f 313d  _f_0=0, len_f_1=
+00016a40: 4e6f 6e65 2c0d 0a20 2020 2020 2020 2020  None,..         
+00016a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016a60: 6c65 6e5f 775f 303d 302c 206c 656e 5f77  len_w_0=0, len_w
+00016a70: 5f31 3d4e 6f6e 652c 0d0a 2020 2020 2020  _1=None,..      
 00016a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016a90: 2020 2020 2020 6c65 6e5f 695f 303d 302c        len_i_0=0,
-00016aa0: 206c 656e 5f69 5f31 3d4e 6f6e 652c 0d0a   len_i_1=None,..
-00016ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016ac0: 2020 2020 2020 2020 206c 656e 5f66 5f30           len_f_0
-00016ad0: 3d30 2c20 6c65 6e5f 665f 313d 4e6f 6e65  =0, len_f_1=None
-00016ae0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00016af0: 2020 2020 2020 2020 2020 2020 6c65 6e5f              len_
-00016b00: 775f 303d 302c 206c 656e 5f77 5f31 3d4e  w_0=0, len_w_1=N
-00016b10: 6f6e 652c 0d0a 2020 2020 2020 2020 2020  one,..          
-00016b20: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-00016b30: 5f66 6f72 6d5f 7065 725f 7365 7269 655f  _form_per_serie_
-00016b40: 303d 302c 206e 5f66 6f72 6d5f 7065 725f  0=0, n_form_per_
-00016b50: 7365 7269 655f 313d 4e6f 6e65 2c0d 0a20  serie_1=None,.. 
-00016b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016b70: 2020 2020 2020 2020 755f 6772 6164 655f          u_grade_
-00016b80: 6974 6572 3d33 2c0d 0a20 2020 2020 2020  iter=3,..       
-00016b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016ba0: 2020 636f 6d70 7574 655f 7765 6967 6874    compute_weight
-00016bb0: 5f63 7472 3d6e 702e 6172 7261 7928 5472  _ctr=np.array(Tr
-00016bc0: 7565 292c 0d0a 2020 2020 2020 2020 2020  ue),..          
-00016bd0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-00016be0: 6f6d 7075 7465 5f73 6361 6c61 725f 6374  ompute_scalar_ct
-00016bf0: 723d 6e70 2e61 7272 6179 2854 7275 6529  r=np.array(True)
-00016c00: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00016c10: 2020 2020 2020 2020 2020 2020 636f 6d70              comp
-00016c20: 7574 655f 626c 6f63 6b5f 6374 723d 6e70  ute_block_ctr=np
-00016c30: 2e61 7272 6179 2854 7275 6529 2c0d 0a20  .array(True),.. 
-00016c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016c50: 2020 2020 2020 2020 6973 5f66 696e 6974          is_finit
-00016c60: 653d 6e70 2e61 7272 6179 2846 616c 7365  e=np.array(False
-00016c70: 292c 2069 735f 6572 6f73 696f 6e3d 6e70  ), is_erosion=np
-00016c80: 2e61 7272 6179 2854 7275 6529 2c0d 0a20  .array(True),.. 
-00016c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016ca0: 2020 2020 2020 2020 6973 5f6f 6e6c 6170          is_onlap
-00016cb0: 3d6e 702e 6172 7261 7928 4661 6c73 6529  =np.array(False)
-00016cc0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00016cd0: 2020 2020 2020 2020 2020 2020 6e5f 7365              n_se
-00016ce0: 7269 6573 3d30 2c0d 0a20 2020 2020 2020  ries=0,..       
-00016cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016d00: 2020 7261 6e67 653d 3130 2e2c 2063 5f6f    range=10., c_o
-00016d10: 3d31 302e 2c0d 0a20 2020 2020 2020 2020  =10.,..         
-00016d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016d30: 626c 6f63 6b5f 6d61 7472 6978 3d4e 6f6e  block_matrix=Non
-00016d40: 652c 2077 6569 6768 7473 5f76 6563 746f  e, weights_vecto
-00016d50: 723d 4e6f 6e65 2c0d 0a20 2020 2020 2020  r=None,..       
-00016d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016d70: 2020 7363 616c 6172 5f66 6965 6c64 5f6d    scalar_field_m
-00016d80: 6174 7269 783d 4e6f 6e65 2c20 7366 6169  atrix=None, sfai
-00016d90: 3d4e 6f6e 652c 206d 6173 6b5f 6d61 7472  =None, mask_matr
-00016da0: 6978 3d4e 6f6e 652c 0d0a 2020 2020 2020  ix=None,..      
-00016db0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016dc0: 2020 206d 6173 6b5f 6d61 7472 6978 5f66     mask_matrix_f
-00016dd0: 3d4e 6f6e 652c 2066 6175 6c74 5f6d 6174  =None, fault_mat
-00016de0: 7269 783d 4e6f 6e65 2c20 6e73 6c65 3d30  rix=None, nsle=0
-00016df0: 2c20 6772 6964 3d4e 6f6e 652c 0d0a 2020  , grid=None,..  
-00016e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016e10: 2020 2020 2020 2073 6869 6674 3d4e 6f6e         shift=Non
-00016e20: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
-00016e30: 2020 2020 2020 2020 2020 2020 293a 0d0a              ):..
-00016e40: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-00016e50: 2020 2020 2046 756e 6374 696f 6e20 7468       Function th
-00016e60: 6174 206c 6f6f 7073 2065 6163 6820 6661  at loops each fa
-00016e70: 756c 742c 2067 656e 6572 6174 696e 6720  ult, generating 
-00016e80: 6120 706f 7465 6e74 6961 6c20 6669 656c  a potential fiel
-00016e90: 6420 666f 7220 6561 6368 206f 6e20 7468  d for each on th
-00016ea0: 656d 2077 6974 6820 7468 6520 7265 7370  em with the resp
-00016eb0: 6563 7469 7665 2062 6c6f 636b 206d 6f64  ective block mod
-00016ec0: 656c 0d0a 0d0a 2020 2020 2020 2020 4172  el....        Ar
-00016ed0: 6773 3a0d 0a20 2020 2020 2020 2020 2020  gs:..           
-00016ee0: 206c 656e 5f69 5f30 3a20 4c65 6e67 6874   len_i_0: Lenght
-00016ef0: 206f 6620 7265 7374 206f 6620 7072 6576   of rest of prev
-00016f00: 696f 7573 2073 6572 6965 730d 0a20 2020  ious series..   
-00016f10: 2020 2020 2020 2020 206c 656e 5f69 5f31           len_i_1
-00016f20: 3a20 4c65 6e67 6874 206f 6620 7265 7374  : Lenght of rest
-00016f30: 2066 6f72 2074 6865 2063 6f6d 7075 7465   for the compute
-00016f40: 6420 7365 7269 6573 0d0a 2020 2020 2020  d series..      
-00016f50: 2020 2020 2020 6c65 6e5f 665f 303a 204c        len_f_0: L
-00016f60: 656e 6768 7420 6f66 2064 6970 7320 6f66  enght of dips of
-00016f70: 2070 7265 7669 6f75 7320 7365 7269 6573   previous series
-00016f80: 0d0a 2020 2020 2020 2020 2020 2020 6c65  ..            le
-00016f90: 6e5f 665f 313a 204c 656e 6774 6820 6f66  n_f_1: Length of
-00016fa0: 2064 6970 7320 6f66 2074 6865 2063 6f6d   dips of the com
-00016fb0: 7075 7465 6420 7365 7269 6573 0d0a 2020  puted series..  
-00016fc0: 2020 2020 2020 2020 2020 6e5f 666f 726d            n_form
-00016fd0: 5f70 6572 5f73 6572 6965 5f30 3a20 4e75  _per_serie_0: Nu
-00016fe0: 6d62 6572 206f 6620 7375 7266 6163 6573  mber of surfaces
-00016ff0: 206f 6620 7072 6576 696f 7573 2073 6572   of previous ser
-00017000: 6965 730d 0a20 2020 2020 2020 2020 2020  ies..           
-00017010: 206e 5f66 6f72 6d5f 7065 725f 7365 7269   n_form_per_seri
-00017020: 655f 313a 204e 756d 6265 7220 6f66 2073  e_1: Number of s
-00017030: 7572 6661 6365 7320 6f66 2074 6865 2063  urfaces of the c
-00017040: 6f6d 7075 7465 6420 7365 7269 6573 0d0a  omputed series..
-00017050: 0d0a 2020 2020 2020 2020 5265 7475 726e  ..        Return
-00017060: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
-00017070: 7468 6561 6e6f 2e74 656e 736f 722e 6d61  theano.tensor.ma
-00017080: 7472 6978 3a20 626c 6f63 6b20 6d6f 6465  trix: block mode
-00017090: 6c20 6465 7269 7665 6420 6672 6f6d 2074  l derived from t
-000170a0: 6865 2064 6620 7468 6174 2061 6674 6572  he df that after
-000170b0: 7761 7264 7320 6973 2075 7365 6420 6173  wards is used as
-000170c0: 2061 2064 7269 6674 2066 6f72 2074 6865   a drift for the
-000170d0: 2022 7265 616c 220d 0a20 2020 2020 2020   "real"..       
-000170e0: 2020 2020 2064 6174 610d 0a20 2020 2020       data..     
-000170f0: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-00017100: 7365 6c66 2e61 5f54 5f73 6361 6c61 7220  self.a_T_scalar 
-00017110: 3d20 7261 6e67 650d 0a20 2020 2020 2020  = range..       
-00017120: 2073 656c 662e 635f 6f5f 545f 7363 616c   self.c_o_T_scal
-00017130: 6172 203d 2063 5f6f 0d0a 0d0a 2020 2020  ar = c_o....    
-00017140: 2020 2020 7365 6c66 2e6e 756d 6265 725f      self.number_
-00017150: 6f66 5f70 6f69 6e74 735f 7065 725f 7375  of_points_per_su
-00017160: 7266 6163 655f 545f 6f70 203d 2073 656c  rface_T_op = sel
-00017170: 662e 6e75 6d62 6572 5f6f 665f 706f 696e  f.number_of_poin
-00017180: 7473 5f70 6572 5f73 7572 6661 6365 5f54  ts_per_surface_T
-00017190: 5b0d 0a20 2020 2020 2020 2020 2020 2020  [..             
-000171a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000171b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000171c0: 2020 2020 6e5f 666f 726d 5f70 6572 5f73      n_form_per_s
-000171d0: 6572 6965 5f30 3a20 6e5f 666f 726d 5f70  erie_0: n_form_p
-000171e0: 6572 5f73 6572 6965 5f31 5d0d 0a0d 0a20  er_serie_1].... 
-000171f0: 2020 2020 2020 2073 656c 662e 6e70 665f         self.npf_
-00017200: 6f70 203d 2073 656c 662e 6e70 665b 6e5f  op = self.npf[n_
-00017210: 666f 726d 5f70 6572 5f73 6572 6965 5f30  form_per_serie_0
-00017220: 3a20 6e5f 666f 726d 5f70 6572 5f73 6572  : n_form_per_ser
-00017230: 6965 5f31 5d0d 0a20 2020 2020 2020 206e  ie_1]..        n
-00017240: 5f73 7572 6661 6365 5f6f 7020 3d20 7365  _surface_op = se
-00017250: 6c66 2e6e 5f73 7572 6661 6365 5b6e 5f66  lf.n_surface[n_f
-00017260: 6f72 6d5f 7065 725f 7365 7269 655f 303a  orm_per_serie_0:
-00017270: 206e 5f66 6f72 6d5f 7065 725f 7365 7269   n_form_per_seri
-00017280: 655f 315d 0d0a 0d0a 2020 2020 2020 2020  e_1]....        
-00017290: 7365 6c66 2e64 6970 735f 706f 7369 7469  self.dips_positi
-000172a0: 6f6e 203d 2073 656c 662e 6469 7073 5f70  on = self.dips_p
-000172b0: 6f73 6974 696f 6e5f 616c 6c5b 6c65 6e5f  osition_all[len_
-000172c0: 665f 303a 206c 656e 5f66 5f31 2c20 3a5d  f_0: len_f_1, :]
-000172d0: 0d0a 2020 2020 2020 2020 7365 6c66 2e64  ..        self.d
-000172e0: 6970 735f 706f 7369 7469 6f6e 5f74 696c  ips_position_til
-000172f0: 6564 203d 2054 2e74 696c 6528 7365 6c66  ed = T.tile(self
-00017300: 2e64 6970 735f 706f 7369 7469 6f6e 2c20  .dips_position, 
-00017310: 2873 656c 662e 6e5f 6469 6d65 6e73 696f  (self.n_dimensio
-00017320: 6e73 2c20 3129 290d 0a0d 0a20 2020 2020  ns, 1))....     
-00017330: 2020 2073 656c 662e 6469 705f 616e 676c     self.dip_angl
-00017340: 6573 203d 2073 656c 662e 6469 705f 616e  es = self.dip_an
-00017350: 676c 6573 5f61 6c6c 5b6c 656e 5f66 5f30  gles_all[len_f_0
-00017360: 3a20 6c65 6e5f 665f 315d 0d0a 0d0a 2020  : len_f_1]....  
-00017370: 2020 2020 2020 7365 6c66 2e61 7a69 6d75        self.azimu
-00017380: 7468 203d 2073 656c 662e 617a 696d 7574  th = self.azimut
-00017390: 685f 616c 6c5b 6c65 6e5f 665f 303a 206c  h_all[len_f_0: l
-000173a0: 656e 5f66 5f31 5d0d 0a20 2020 2020 2020  en_f_1]..       
-000173b0: 2073 656c 662e 706f 6c61 7269 7479 203d   self.polarity =
-000173c0: 2073 656c 662e 706f 6c61 7269 7479 5f61   self.polarity_a
-000173d0: 6c6c 5b6c 656e 5f66 5f30 3a20 6c65 6e5f  ll[len_f_0: len_
-000173e0: 665f 315d 0d0a 0d0a 2020 2020 2020 2020  f_1]....        
-000173f0: 7365 6c66 2e72 6566 5f6c 6179 6572 5f70  self.ref_layer_p
-00017400: 6f69 6e74 7320 3d20 7365 6c66 2e72 6566  oints = self.ref
-00017410: 5f6c 6179 6572 5f70 6f69 6e74 735f 616c  _layer_points_al
-00017420: 6c5b 6c65 6e5f 695f 303a 206c 656e 5f69  l[len_i_0: len_i
-00017430: 5f31 2c20 3a5d 0d0a 2020 2020 2020 2020  _1, :]..        
-00017440: 7365 6c66 2e72 6573 745f 6c61 7965 725f  self.rest_layer_
-00017450: 706f 696e 7473 203d 2073 656c 662e 7265  points = self.re
-00017460: 7374 5f6c 6179 6572 5f70 6f69 6e74 735f  st_layer_points_
-00017470: 616c 6c5b 6c65 6e5f 695f 303a 206c 656e  all[len_i_0: len
-00017480: 5f69 5f31 2c20 3a5d 0d0a 0d0a 2020 2020  _i_1, :]....    
-00017490: 2020 2020 7365 6c66 2e6e 7567 6765 745f      self.nugget_
-000174a0: 6566 6665 6374 5f73 6361 6c61 725f 545f  effect_scalar_T_
-000174b0: 6f70 203d 2073 656c 662e 6e75 6767 6574  op = self.nugget
-000174c0: 5f65 6666 6563 745f 7363 616c 6172 5f54  _effect_scalar_T
-000174d0: 5f72 6566 5f72 6573 745b 0d0a 2020 2020  _ref_rest[..    
-000174e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000174f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017500: 2020 2020 206c 656e 5f69 5f30 3a20 6c65       len_i_0: le
-00017510: 6e5f 695f 315d 0d0a 0d0a 2020 2020 2020  n_i_1]....      
-00017520: 2020 2320 5468 6520 6772 6164 6965 6e74    # The gradient
-00017530: 7320 6861 7665 2062 6565 6e20 7469 6c65  s have been tile
-00017540: 6420 6f75 7473 6964 650d 0a20 2020 2020  d outside..     
-00017550: 2020 2073 656c 662e 6e75 6767 6574 5f65     self.nugget_e
-00017560: 6666 6563 745f 6772 6164 5f54 5f6f 7020  ffect_grad_T_op 
-00017570: 3d20 7365 6c66 2e6e 7567 6765 745f 6566  = self.nugget_ef
-00017580: 6665 6374 5f67 7261 645f 545b 0d0a 2020  fect_grad_T[..  
-00017590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000175a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000175b0: 2020 2020 206c 656e 5f66 5f30 202a 2033       len_f_0 * 3
-000175c0: 3a20 6c65 6e5f 665f 3120 2a20 335d 0d0a  : len_f_1 * 3]..
-000175d0: 0d0a 2020 2020 2020 2020 7365 6c66 2e6e  ..        self.n
-000175e0: 5f75 6e69 7665 7273 616c 5f65 715f 545f  _universal_eq_T_
-000175f0: 6f70 203d 2075 5f67 7261 6465 5f69 7465  op = u_grade_ite
-00017600: 720d 0a0d 0a20 2020 2020 2020 2078 5f74  r....        x_t
-00017610: 6f5f 696e 7465 7270 6f6c 6174 655f 7368  o_interpolate_sh
-00017620: 6170 6520 3d20 6772 6964 2e73 6861 7065  ape = grid.shape
-00017630: 5b30 5d20 2b20 3220 2a20 7365 6c66 2e6c  [0] + 2 * self.l
-00017640: 656e 5f70 6f69 6e74 730d 0a20 2020 2020  en_points..     
-00017650: 2020 2069 6620 2778 5f74 6f5f 696e 7465     if 'x_to_inte
-00017660: 7270 6f6c 6174 655f 7368 6170 6527 2069  rpolate_shape' i
-00017670: 6e20 7365 6c66 2e76 6572 626f 7365 3a0d  n self.verbose:.
-00017680: 0a20 2020 2020 2020 2020 2020 2078 5f74  .            x_t
-00017690: 6f5f 696e 7465 7270 6f6c 6174 655f 7368  o_interpolate_sh
-000176a0: 6170 6520 3d20 7468 6561 6e6f 2e70 7269  ape = theano.pri
-000176b0: 6e74 696e 672e 5072 696e 7428 2778 5f74  nting.Print('x_t
-000176c0: 6f5f 696e 7465 7270 6f6c 6174 655f 7368  o_interpolate_sh
-000176d0: 6170 6527 2928 0d0a 2020 2020 2020 2020  ape')(..        
-000176e0: 2020 2020 2020 2020 785f 746f 5f69 6e74          x_to_int
-000176f0: 6572 706f 6c61 7465 5f73 6861 7065 290d  erpolate_shape).
-00017700: 0a0d 0a20 2020 2020 2020 2023 2045 7874  ...        # Ext
-00017710: 7261 6374 696e 6720 6661 756c 7473 206d  racting faults m
-00017720: 6174 7269 6365 730d 0a20 2020 2020 2020  atrices..       
-00017730: 2066 6175 6c74 735f 7265 6c61 7469 6f6e   faults_relation
-00017740: 5f6f 7020 3d20 7365 6c66 2e66 6175 6c74  _op = self.fault
-00017750: 5f72 656c 6174 696f 6e5b 3a2c 2054 2e63  _relation[:, T.c
-00017760: 6173 7428 6e5f 7365 7269 6573 2c20 2769  ast(n_series, 'i
-00017770: 6e74 3827 295d 0d0a 2020 2020 2020 2020  nt8')]..        
-00017780: 6661 756c 745f 6d61 7472 6978 5f6f 7020  fault_matrix_op 
-00017790: 3d20 6661 756c 745f 6d61 7472 6978 5b0d  = fault_matrix[.
-000177a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000177b0: 2020 2020 2020 2020 2020 2054 2e6e 6f6e             T.non
-000177c0: 7a65 726f 2854 2e63 6173 7428 6661 756c  zero(T.cast(faul
-000177d0: 7473 5f72 656c 6174 696f 6e5f 6f70 2c20  ts_relation_op, 
-000177e0: 2269 6e74 3822 2929 5b30 5d2c 0d0a 2020  "int8"))[0],..  
-000177f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017800: 2020 2020 2020 2020 302c 2073 6869 6674          0, shift
-00017810: 3a78 5f74 6f5f 696e 7465 7270 6f6c 6174  :x_to_interpolat
-00017820: 655f 7368 6170 6520 2b20 7368 6966 745d  e_shape + shift]
-00017830: 202a 2073 656c 662e 6f66 6673 6574 0d0a   * self.offset..
-00017840: 0d0a 2020 2020 2020 2020 7365 6c66 2e6c  ..        self.l
-00017850: 656e 6768 745f 6f66 5f66 6175 6c74 7320  enght_of_faults 
-00017860: 3d20 542e 6361 7374 2866 6175 6c74 5f6d  = T.cast(fault_m
-00017870: 6174 7269 785f 6f70 2e73 6861 7065 5b30  atrix_op.shape[0
-00017880: 5d2c 2027 696e 7433 3227 290d 0a0d 0a20  ], 'int32').... 
-00017890: 2020 2020 2020 2069 6620 2766 6175 6c74         if 'fault
-000178a0: 5f6d 6174 7269 785f 6c6f 6f70 2720 696e  _matrix_loop' in
-000178b0: 2073 656c 662e 7665 7262 6f73 653a 0d0a   self.verbose:..
-000178c0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-000178d0: 2e66 6175 6c74 5f6d 6174 7269 7820 3d20  .fault_matrix = 
-000178e0: 7468 6561 6e6f 2e70 7269 6e74 696e 672e  theano.printing.
-000178f0: 5072 696e 7428 2773 656c 6620 6661 756c  Print('self faul
-00017900: 7420 6d61 7472 6978 2729 280d 0a20 2020  t matrix')(..   
-00017910: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-00017920: 662e 6661 756c 745f 6d61 7472 6978 290d  f.fault_matrix).
-00017930: 0a20 2020 2020 2020 2023 2054 4f44 4f20  .        # TODO 
-00017940: 7468 6973 2069 7320 7772 6f6e 670d 0a0d  this is wrong...
-00017950: 0a20 2020 2020 2020 2069 6e74 6572 6661  .        interfa
-00017960: 6365 5f6c 6f63 203d 2067 7269 642e 7368  ce_loc = grid.sh
-00017970: 6170 655b 305d 0d0a 0d0a 2020 2020 2020  ape[0]....      
-00017980: 2020 6966 2027 6c65 6e5f 6927 2069 6e20    if 'len_i' in 
-00017990: 7365 6c66 2e76 6572 626f 7365 3a0d 0a20  self.verbose:.. 
-000179a0: 2020 2020 2020 2020 2020 206c 656e 5f69             len_i
-000179b0: 5f30 203d 2074 6865 616e 6f2e 7072 696e  _0 = theano.prin
-000179c0: 7469 6e67 2e50 7269 6e74 2827 6c65 6e5f  ting.Print('len_
-000179d0: 695f 3027 2928 6c65 6e5f 695f 3029 0d0a  i_0')(len_i_0)..
-000179e0: 2020 2020 2020 2020 2020 2020 6c65 6e5f              len_
-000179f0: 695f 3120 3d20 7468 6561 6e6f 2e70 7269  i_1 = theano.pri
-00017a00: 6e74 696e 672e 5072 696e 7428 276c 656e  nting.Print('len
-00017a10: 5f69 5f31 2729 286c 656e 5f69 5f31 290d  _i_1')(len_i_1).
-00017a20: 0a0d 0a20 2020 2020 2020 2073 656c 662e  ...        self.
-00017a30: 6661 756c 745f 6472 6966 745f 6174 5f73  fault_drift_at_s
-00017a40: 7572 6661 6365 5f70 6f69 6e74 735f 7265  urface_points_re
-00017a50: 7374 203d 2066 6175 6c74 5f6d 6174 7269  st = fault_matri
-00017a60: 785f 6f70 5b0d 0a20 2020 2020 2020 2020  x_op[..         
-00017a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017a90: 2020 2020 2020 2020 203a 2c20 696e 7465           :, inte
-00017aa0: 7266 6163 655f 6c6f 6320 2b20 6c65 6e5f  rface_loc + len_
-00017ab0: 695f 303a 0d0a 2020 2020 2020 2020 2020  i_0:..          
+00016a90: 2020 206e 5f66 6f72 6d5f 7065 725f 7365     n_form_per_se
+00016aa0: 7269 655f 303d 302c 206e 5f66 6f72 6d5f  rie_0=0, n_form_
+00016ab0: 7065 725f 7365 7269 655f 313d 4e6f 6e65  per_serie_1=None
+00016ac0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00016ad0: 2020 2020 2020 2020 2020 2020 755f 6772              u_gr
+00016ae0: 6164 655f 6974 6572 3d33 2c0d 0a20 2020  ade_iter=3,..   
+00016af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016b00: 2020 2020 2020 636f 6d70 7574 655f 7765        compute_we
+00016b10: 6967 6874 5f63 7472 3d6e 702e 6172 7261  ight_ctr=np.arra
+00016b20: 7928 5472 7565 292c 0d0a 2020 2020 2020  y(True),..      
+00016b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016b40: 2020 2063 6f6d 7075 7465 5f73 6361 6c61     compute_scala
+00016b50: 725f 6374 723d 6e70 2e61 7272 6179 2854  r_ctr=np.array(T
+00016b60: 7275 6529 2c0d 0a20 2020 2020 2020 2020  rue),..         
+00016b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016b80: 636f 6d70 7574 655f 626c 6f63 6b5f 6374  compute_block_ct
+00016b90: 723d 6e70 2e61 7272 6179 2854 7275 6529  r=np.array(True)
+00016ba0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00016bb0: 2020 2020 2020 2020 2020 2020 6973 5f66              is_f
+00016bc0: 696e 6974 653d 6e70 2e61 7272 6179 2846  inite=np.array(F
+00016bd0: 616c 7365 292c 2069 735f 6572 6f73 696f  alse), is_erosio
+00016be0: 6e3d 6e70 2e61 7272 6179 2854 7275 6529  n=np.array(True)
+00016bf0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00016c00: 2020 2020 2020 2020 2020 2020 6973 5f6f              is_o
+00016c10: 6e6c 6170 3d6e 702e 6172 7261 7928 4661  nlap=np.array(Fa
+00016c20: 6c73 6529 2c0d 0a20 2020 2020 2020 2020  lse),..         
+00016c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016c40: 6e5f 7365 7269 6573 3d30 2c0d 0a20 2020  n_series=0,..   
+00016c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016c60: 2020 2020 2020 7261 6e67 653d 3130 2e2c        range=10.,
+00016c70: 2063 5f6f 3d31 302e 2c0d 0a20 2020 2020   c_o=10.,..     
+00016c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016c90: 2020 2020 626c 6f63 6b5f 6d61 7472 6978      block_matrix
+00016ca0: 3d4e 6f6e 652c 2077 6569 6768 7473 5f76  =None, weights_v
+00016cb0: 6563 746f 723d 4e6f 6e65 2c0d 0a20 2020  ector=None,..   
+00016cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016cd0: 2020 2020 2020 7363 616c 6172 5f66 6965        scalar_fie
+00016ce0: 6c64 5f6d 6174 7269 783d 4e6f 6e65 2c20  ld_matrix=None, 
+00016cf0: 7366 6169 3d4e 6f6e 652c 206d 6173 6b5f  sfai=None, mask_
+00016d00: 6d61 7472 6978 3d4e 6f6e 652c 0d0a 2020  matrix=None,..  
+00016d10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016d20: 2020 2020 2020 206d 6173 6b5f 6d61 7472         mask_matr
+00016d30: 6978 5f66 3d4e 6f6e 652c 2066 6175 6c74  ix_f=None, fault
+00016d40: 5f6d 6174 7269 783d 4e6f 6e65 2c20 6e73  _matrix=None, ns
+00016d50: 6c65 3d30 2c20 6772 6964 3d4e 6f6e 652c  le=0, grid=None,
+00016d60: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00016d70: 2020 2020 2020 2020 2020 2073 6869 6674             shift
+00016d80: 3d4e 6f6e 650d 0a20 2020 2020 2020 2020  =None..         
+00016d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016da0: 293a 0d0a 2020 2020 2020 2020 2222 220d  ):..        """.
+00016db0: 0a20 2020 2020 2020 2046 756e 6374 696f  .        Functio
+00016dc0: 6e20 7468 6174 206c 6f6f 7073 2065 6163  n that loops eac
+00016dd0: 6820 6661 756c 742c 2067 656e 6572 6174  h fault, generat
+00016de0: 696e 6720 6120 706f 7465 6e74 6961 6c20  ing a potential 
+00016df0: 6669 656c 6420 666f 7220 6561 6368 206f  field for each o
+00016e00: 6e20 7468 656d 2077 6974 6820 7468 6520  n them with the 
+00016e10: 7265 7370 6563 7469 7665 2062 6c6f 636b  respective block
+00016e20: 206d 6f64 656c 0d0a 0d0a 2020 2020 2020   model....      
+00016e30: 2020 4172 6773 3a0d 0a20 2020 2020 2020    Args:..       
+00016e40: 2020 2020 206c 656e 5f69 5f30 3a20 4c65       len_i_0: Le
+00016e50: 6e67 6874 206f 6620 7265 7374 206f 6620  nght of rest of 
+00016e60: 7072 6576 696f 7573 2073 6572 6965 730d  previous series.
+00016e70: 0a20 2020 2020 2020 2020 2020 206c 656e  .            len
+00016e80: 5f69 5f31 3a20 4c65 6e67 6874 206f 6620  _i_1: Lenght of 
+00016e90: 7265 7374 2066 6f72 2074 6865 2063 6f6d  rest for the com
+00016ea0: 7075 7465 6420 7365 7269 6573 0d0a 2020  puted series..  
+00016eb0: 2020 2020 2020 2020 2020 6c65 6e5f 665f            len_f_
+00016ec0: 303a 204c 656e 6768 7420 6f66 2064 6970  0: Lenght of dip
+00016ed0: 7320 6f66 2070 7265 7669 6f75 7320 7365  s of previous se
+00016ee0: 7269 6573 0d0a 2020 2020 2020 2020 2020  ries..          
+00016ef0: 2020 6c65 6e5f 665f 313a 204c 656e 6774    len_f_1: Lengt
+00016f00: 6820 6f66 2064 6970 7320 6f66 2074 6865  h of dips of the
+00016f10: 2063 6f6d 7075 7465 6420 7365 7269 6573   computed series
+00016f20: 0d0a 2020 2020 2020 2020 2020 2020 6e5f  ..            n_
+00016f30: 666f 726d 5f70 6572 5f73 6572 6965 5f30  form_per_serie_0
+00016f40: 3a20 4e75 6d62 6572 206f 6620 7375 7266  : Number of surf
+00016f50: 6163 6573 206f 6620 7072 6576 696f 7573  aces of previous
+00016f60: 2073 6572 6965 730d 0a20 2020 2020 2020   series..       
+00016f70: 2020 2020 206e 5f66 6f72 6d5f 7065 725f       n_form_per_
+00016f80: 7365 7269 655f 313a 204e 756d 6265 7220  serie_1: Number 
+00016f90: 6f66 2073 7572 6661 6365 7320 6f66 2074  of surfaces of t
+00016fa0: 6865 2063 6f6d 7075 7465 6420 7365 7269  he computed seri
+00016fb0: 6573 0d0a 0d0a 2020 2020 2020 2020 5265  es....        Re
+00016fc0: 7475 726e 733a 0d0a 2020 2020 2020 2020  turns:..        
+00016fd0: 2020 2020 6165 7361 7261 2e74 656e 736f      aesara.tenso
+00016fe0: 722e 6d61 7472 6978 3a20 626c 6f63 6b20  r.matrix: block 
+00016ff0: 6d6f 6465 6c20 6465 7269 7665 6420 6672  model derived fr
+00017000: 6f6d 2074 6865 2064 6620 7468 6174 2061  om the df that a
+00017010: 6674 6572 7761 7264 7320 6973 2075 7365  fterwards is use
+00017020: 6420 6173 2061 2064 7269 6674 2066 6f72  d as a drift for
+00017030: 2074 6865 2022 7265 616c 220d 0a20 2020   the "real"..   
+00017040: 2020 2020 2020 2020 2064 6174 610d 0a20           data.. 
+00017050: 2020 2020 2020 2022 2222 0d0a 2020 2020         """..    
+00017060: 2020 2020 7365 6c66 2e61 5f54 5f73 6361      self.a_T_sca
+00017070: 6c61 7220 3d20 7261 6e67 650d 0a20 2020  lar = range..   
+00017080: 2020 2020 2073 656c 662e 635f 6f5f 545f       self.c_o_T_
+00017090: 7363 616c 6172 203d 2063 5f6f 0d0a 0d0a  scalar = c_o....
+000170a0: 2020 2020 2020 2020 7365 6c66 2e6e 756d          self.num
+000170b0: 6265 725f 6f66 5f70 6f69 6e74 735f 7065  ber_of_points_pe
+000170c0: 725f 7375 7266 6163 655f 545f 6f70 203d  r_surface_T_op =
+000170d0: 2073 656c 662e 6e75 6d62 6572 5f6f 665f   self.number_of_
+000170e0: 706f 696e 7473 5f70 6572 5f73 7572 6661  points_per_surfa
+000170f0: 6365 5f54 5b0d 0a20 2020 2020 2020 2020  ce_T[..         
+00017100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017110: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017120: 2020 2020 2020 2020 6e5f 666f 726d 5f70          n_form_p
+00017130: 6572 5f73 6572 6965 5f30 3a20 6e5f 666f  er_serie_0: n_fo
+00017140: 726d 5f70 6572 5f73 6572 6965 5f31 5d0d  rm_per_serie_1].
+00017150: 0a0d 0a20 2020 2020 2020 2073 656c 662e  ...        self.
+00017160: 6e70 665f 6f70 203d 2073 656c 662e 6e70  npf_op = self.np
+00017170: 665b 6e5f 666f 726d 5f70 6572 5f73 6572  f[n_form_per_ser
+00017180: 6965 5f30 3a20 6e5f 666f 726d 5f70 6572  ie_0: n_form_per
+00017190: 5f73 6572 6965 5f31 5d0d 0a20 2020 2020  _serie_1]..     
+000171a0: 2020 206e 5f73 7572 6661 6365 5f6f 7020     n_surface_op 
+000171b0: 3d20 7365 6c66 2e6e 5f73 7572 6661 6365  = self.n_surface
+000171c0: 5b6e 5f66 6f72 6d5f 7065 725f 7365 7269  [n_form_per_seri
+000171d0: 655f 303a 206e 5f66 6f72 6d5f 7065 725f  e_0: n_form_per_
+000171e0: 7365 7269 655f 315d 0d0a 0d0a 2020 2020  serie_1]....    
+000171f0: 2020 2020 7365 6c66 2e64 6970 735f 706f      self.dips_po
+00017200: 7369 7469 6f6e 203d 2073 656c 662e 6469  sition = self.di
+00017210: 7073 5f70 6f73 6974 696f 6e5f 616c 6c5b  ps_position_all[
+00017220: 6c65 6e5f 665f 303a 206c 656e 5f66 5f31  len_f_0: len_f_1
+00017230: 2c20 3a5d 0d0a 2020 2020 2020 2020 7365  , :]..        se
+00017240: 6c66 2e64 6970 735f 706f 7369 7469 6f6e  lf.dips_position
+00017250: 5f74 696c 6564 203d 2054 2e74 696c 6528  _tiled = T.tile(
+00017260: 7365 6c66 2e64 6970 735f 706f 7369 7469  self.dips_positi
+00017270: 6f6e 2c20 2873 656c 662e 6e5f 6469 6d65  on, (self.n_dime
+00017280: 6e73 696f 6e73 2c20 3129 290d 0a0d 0a20  nsions, 1)).... 
+00017290: 2020 2020 2020 2073 656c 662e 6469 705f         self.dip_
+000172a0: 616e 676c 6573 203d 2073 656c 662e 6469  angles = self.di
+000172b0: 705f 616e 676c 6573 5f61 6c6c 5b6c 656e  p_angles_all[len
+000172c0: 5f66 5f30 3a20 6c65 6e5f 665f 315d 0d0a  _f_0: len_f_1]..
+000172d0: 0d0a 2020 2020 2020 2020 7365 6c66 2e61  ..        self.a
+000172e0: 7a69 6d75 7468 203d 2073 656c 662e 617a  zimuth = self.az
+000172f0: 696d 7574 685f 616c 6c5b 6c65 6e5f 665f  imuth_all[len_f_
+00017300: 303a 206c 656e 5f66 5f31 5d0d 0a20 2020  0: len_f_1]..   
+00017310: 2020 2020 2073 656c 662e 706f 6c61 7269       self.polari
+00017320: 7479 203d 2073 656c 662e 706f 6c61 7269  ty = self.polari
+00017330: 7479 5f61 6c6c 5b6c 656e 5f66 5f30 3a20  ty_all[len_f_0: 
+00017340: 6c65 6e5f 665f 315d 0d0a 0d0a 2020 2020  len_f_1]....    
+00017350: 2020 2020 7365 6c66 2e72 6566 5f6c 6179      self.ref_lay
+00017360: 6572 5f70 6f69 6e74 7320 3d20 7365 6c66  er_points = self
+00017370: 2e72 6566 5f6c 6179 6572 5f70 6f69 6e74  .ref_layer_point
+00017380: 735f 616c 6c5b 6c65 6e5f 695f 303a 206c  s_all[len_i_0: l
+00017390: 656e 5f69 5f31 2c20 3a5d 0d0a 2020 2020  en_i_1, :]..    
+000173a0: 2020 2020 7365 6c66 2e72 6573 745f 6c61      self.rest_la
+000173b0: 7965 725f 706f 696e 7473 203d 2073 656c  yer_points = sel
+000173c0: 662e 7265 7374 5f6c 6179 6572 5f70 6f69  f.rest_layer_poi
+000173d0: 6e74 735f 616c 6c5b 6c65 6e5f 695f 303a  nts_all[len_i_0:
+000173e0: 206c 656e 5f69 5f31 2c20 3a5d 0d0a 0d0a   len_i_1, :]....
+000173f0: 2020 2020 2020 2020 7365 6c66 2e6e 7567          self.nug
+00017400: 6765 745f 6566 6665 6374 5f73 6361 6c61  get_effect_scala
+00017410: 725f 545f 6f70 203d 2073 656c 662e 6e75  r_T_op = self.nu
+00017420: 6767 6574 5f65 6666 6563 745f 7363 616c  gget_effect_scal
+00017430: 6172 5f54 5f72 6566 5f72 6573 745b 0d0a  ar_T_ref_rest[..
+00017440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017460: 2020 2020 2020 2020 206c 656e 5f69 5f30           len_i_0
+00017470: 3a20 6c65 6e5f 695f 315d 0d0a 0d0a 2020  : len_i_1]....  
+00017480: 2020 2020 2020 2320 5468 6520 6772 6164        # The grad
+00017490: 6965 6e74 7320 6861 7665 2062 6565 6e20  ients have been 
+000174a0: 7469 6c65 6420 6f75 7473 6964 650d 0a20  tiled outside.. 
+000174b0: 2020 2020 2020 2073 656c 662e 6e75 6767         self.nugg
+000174c0: 6574 5f65 6666 6563 745f 6772 6164 5f54  et_effect_grad_T
+000174d0: 5f6f 7020 3d20 7365 6c66 2e6e 7567 6765  _op = self.nugge
+000174e0: 745f 6566 6665 6374 5f67 7261 645f 545b  t_effect_grad_T[
+000174f0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00017500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017510: 2020 2020 2020 2020 206c 656e 5f66 5f30           len_f_0
+00017520: 202a 2033 3a20 6c65 6e5f 665f 3120 2a20   * 3: len_f_1 * 
+00017530: 335d 0d0a 0d0a 2020 2020 2020 2020 7365  3]....        se
+00017540: 6c66 2e6e 5f75 6e69 7665 7273 616c 5f65  lf.n_universal_e
+00017550: 715f 545f 6f70 203d 2075 5f67 7261 6465  q_T_op = u_grade
+00017560: 5f69 7465 720d 0a0d 0a20 2020 2020 2020  _iter....       
+00017570: 2078 5f74 6f5f 696e 7465 7270 6f6c 6174   x_to_interpolat
+00017580: 655f 7368 6170 6520 3d20 6772 6964 2e73  e_shape = grid.s
+00017590: 6861 7065 5b30 5d20 2b20 3220 2a20 7365  hape[0] + 2 * se
+000175a0: 6c66 2e6c 656e 5f70 6f69 6e74 730d 0a20  lf.len_points.. 
+000175b0: 2020 2020 2020 2069 6620 2778 5f74 6f5f         if 'x_to_
+000175c0: 696e 7465 7270 6f6c 6174 655f 7368 6170  interpolate_shap
+000175d0: 6527 2069 6e20 7365 6c66 2e76 6572 626f  e' in self.verbo
+000175e0: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
+000175f0: 2078 5f74 6f5f 696e 7465 7270 6f6c 6174   x_to_interpolat
+00017600: 655f 7368 6170 6520 3d20 6165 7361 7261  e_shape = aesara
+00017610: 2e70 7269 6e74 696e 672e 5072 696e 7428  .printing.Print(
+00017620: 2778 5f74 6f5f 696e 7465 7270 6f6c 6174  'x_to_interpolat
+00017630: 655f 7368 6170 6527 2928 0d0a 2020 2020  e_shape')(..    
+00017640: 2020 2020 2020 2020 2020 2020 785f 746f              x_to
+00017650: 5f69 6e74 6572 706f 6c61 7465 5f73 6861  _interpolate_sha
+00017660: 7065 290d 0a0d 0a20 2020 2020 2020 2023  pe)....        #
+00017670: 2045 7874 7261 6374 696e 6720 6661 756c   Extracting faul
+00017680: 7473 206d 6174 7269 6365 730d 0a20 2020  ts matrices..   
+00017690: 2020 2020 2066 6175 6c74 735f 7265 6c61       faults_rela
+000176a0: 7469 6f6e 5f6f 7020 3d20 7365 6c66 2e66  tion_op = self.f
+000176b0: 6175 6c74 5f72 656c 6174 696f 6e5b 3a2c  ault_relation[:,
+000176c0: 2054 2e63 6173 7428 6e5f 7365 7269 6573   T.cast(n_series
+000176d0: 2c20 2769 6e74 3827 295d 0d0a 2020 2020  , 'int8')]..    
+000176e0: 2020 2020 6661 756c 745f 6d61 7472 6978      fault_matrix
+000176f0: 5f6f 7020 3d20 6661 756c 745f 6d61 7472  _op = fault_matr
+00017700: 6978 5b0d 0a20 2020 2020 2020 2020 2020  ix[..           
+00017710: 2020 2020 2020 2020 2020 2020 2020 2054                 T
+00017720: 2e6e 6f6e 7a65 726f 2854 2e63 6173 7428  .nonzero(T.cast(
+00017730: 6661 756c 7473 5f72 656c 6174 696f 6e5f  faults_relation_
+00017740: 6f70 2c20 2269 6e74 3822 2929 5b30 5d2c  op, "int8"))[0],
+00017750: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00017760: 2020 2020 2020 2020 2020 2020 302c 2073              0, s
+00017770: 6869 6674 3a78 5f74 6f5f 696e 7465 7270  hift:x_to_interp
+00017780: 6f6c 6174 655f 7368 6170 6520 2b20 7368  olate_shape + sh
+00017790: 6966 745d 202a 2073 656c 662e 6f66 6673  ift] * self.offs
+000177a0: 6574 0d0a 0d0a 2020 2020 2020 2020 7365  et....        se
+000177b0: 6c66 2e6c 656e 6768 745f 6f66 5f66 6175  lf.lenght_of_fau
+000177c0: 6c74 7320 3d20 542e 6361 7374 2866 6175  lts = T.cast(fau
+000177d0: 6c74 5f6d 6174 7269 785f 6f70 2e73 6861  lt_matrix_op.sha
+000177e0: 7065 5b30 5d2c 2027 696e 7433 3227 290d  pe[0], 'int32').
+000177f0: 0a0d 0a20 2020 2020 2020 2069 6620 2766  ...        if 'f
+00017800: 6175 6c74 5f6d 6174 7269 785f 6c6f 6f70  ault_matrix_loop
+00017810: 2720 696e 2073 656c 662e 7665 7262 6f73  ' in self.verbos
+00017820: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+00017830: 7365 6c66 2e66 6175 6c74 5f6d 6174 7269  self.fault_matri
+00017840: 7820 3d20 6165 7361 7261 2e70 7269 6e74  x = aesara.print
+00017850: 696e 672e 5072 696e 7428 2773 656c 6620  ing.Print('self 
+00017860: 6661 756c 7420 6d61 7472 6978 2729 280d  fault matrix')(.
+00017870: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00017880: 2073 656c 662e 6661 756c 745f 6d61 7472   self.fault_matr
+00017890: 6978 290d 0a20 2020 2020 2020 2023 2054  ix)..        # T
+000178a0: 4f44 4f20 7468 6973 2069 7320 7772 6f6e  ODO this is wron
+000178b0: 670d 0a0d 0a20 2020 2020 2020 2069 6e74  g....        int
+000178c0: 6572 6661 6365 5f6c 6f63 203d 2067 7269  erface_loc = gri
+000178d0: 642e 7368 6170 655b 305d 0d0a 0d0a 2020  d.shape[0]....  
+000178e0: 2020 2020 2020 6966 2027 6c65 6e5f 6927        if 'len_i'
+000178f0: 2069 6e20 7365 6c66 2e76 6572 626f 7365   in self.verbose
+00017900: 3a0d 0a20 2020 2020 2020 2020 2020 206c  :..            l
+00017910: 656e 5f69 5f30 203d 2061 6573 6172 612e  en_i_0 = aesara.
+00017920: 7072 696e 7469 6e67 2e50 7269 6e74 2827  printing.Print('
+00017930: 6c65 6e5f 695f 3027 2928 6c65 6e5f 695f  len_i_0')(len_i_
+00017940: 3029 0d0a 2020 2020 2020 2020 2020 2020  0)..            
+00017950: 6c65 6e5f 695f 3120 3d20 6165 7361 7261  len_i_1 = aesara
+00017960: 2e70 7269 6e74 696e 672e 5072 696e 7428  .printing.Print(
+00017970: 276c 656e 5f69 5f31 2729 286c 656e 5f69  'len_i_1')(len_i
+00017980: 5f31 290d 0a0d 0a20 2020 2020 2020 2073  _1)....        s
+00017990: 656c 662e 6661 756c 745f 6472 6966 745f  elf.fault_drift_
+000179a0: 6174 5f73 7572 6661 6365 5f70 6f69 6e74  at_surface_point
+000179b0: 735f 7265 7374 203d 2066 6175 6c74 5f6d  s_rest = fault_m
+000179c0: 6174 7269 785f 6f70 5b0d 0a20 2020 2020  atrix_op[..     
+000179d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000179e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000179f0: 2020 2020 2020 2020 2020 2020 203a 2c20               :, 
+00017a00: 696e 7465 7266 6163 655f 6c6f 6320 2b20  interface_loc + 
+00017a10: 6c65 6e5f 695f 303a 0d0a 2020 2020 2020  len_i_0:..      
+00017a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017a30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017a40: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00017a50: 6e74 6572 6661 6365 5f6c 6f63 202b 206c  nterface_loc + l
+00017a60: 656e 5f69 5f31 5d0d 0a0d 0a20 2020 2020  en_i_1]....     
+00017a70: 2020 2073 656c 662e 6661 756c 745f 6472     self.fault_dr
+00017a80: 6966 745f 6174 5f73 7572 6661 6365 5f70  ift_at_surface_p
+00017a90: 6f69 6e74 735f 7265 6620 3d20 6661 756c  oints_ref = faul
+00017aa0: 745f 6d61 7472 6978 5f6f 705b 0d0a 2020  t_matrix_op[..  
+00017ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00017ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017ae0: 2020 2020 2020 2020 2020 2069 6e74 6572             inter
-00017af0: 6661 6365 5f6c 6f63 202b 206c 656e 5f69  face_loc + len_i
-00017b00: 5f31 5d0d 0a0d 0a20 2020 2020 2020 2073  _1]....        s
-00017b10: 656c 662e 6661 756c 745f 6472 6966 745f  elf.fault_drift_
-00017b20: 6174 5f73 7572 6661 6365 5f70 6f69 6e74  at_surface_point
-00017b30: 735f 7265 6620 3d20 6661 756c 745f 6d61  s_ref = fault_ma
-00017b40: 7472 6978 5f6f 705b 0d0a 2020 2020 2020  trix_op[..      
+00017ad0: 2020 2020 2020 2020 2020 2020 2020 203a                 :
+00017ae0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00017af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017b00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017b10: 2020 2020 696e 7465 7266 6163 655f 6c6f      interface_lo
+00017b20: 6320 2b20 7365 6c66 2e6c 656e 5f70 6f69  c + self.len_poi
+00017b30: 6e74 7320 2b20 6c65 6e5f 695f 303a 0d0a  nts + len_i_0:..
+00017b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00017b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00017b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017b70: 2020 2020 2020 2020 2020 203a 2c0d 0a20             :,.. 
-00017b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017bb0: 696e 7465 7266 6163 655f 6c6f 6320 2b20  interface_loc + 
-00017bc0: 7365 6c66 2e6c 656e 5f70 6f69 6e74 7320  self.len_points 
-00017bd0: 2b20 6c65 6e5f 695f 303a 0d0a 2020 2020  + len_i_0:..    
-00017be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017c00: 2020 2020 2020 2020 2020 2020 2069 6e74               int
-00017c10: 6572 6661 6365 5f6c 6f63 202b 2073 656c  erface_loc + sel
-00017c20: 662e 6c65 6e5f 706f 696e 7473 202b 206c  f.len_points + l
-00017c30: 656e 5f69 5f31 5d0d 0a0d 0a20 2020 2020  en_i_1]....     
-00017c40: 2020 2062 203d 2073 656c 662e 625f 7665     b = self.b_ve
-00017c50: 6374 6f72 2873 656c 662e 6469 705f 616e  ctor(self.dip_an
-00017c60: 676c 6573 2c20 7365 6c66 2e61 7a69 6d75  gles, self.azimu
-00017c70: 7468 2c20 7365 6c66 2e70 6f6c 6172 6974  th, self.polarit
-00017c80: 7929 0d0a 0d0a 2020 2020 2020 2020 6966  y)....        if
-00017c90: 2073 656c 662e 7370 6172 7365 5f76 6572   self.sparse_ver
-00017ca0: 7369 6f6e 2069 7320 5472 7565 3a0d 0a20  sion is True:.. 
+00017b70: 2069 6e74 6572 6661 6365 5f6c 6f63 202b   interface_loc +
+00017b80: 2073 656c 662e 6c65 6e5f 706f 696e 7473   self.len_points
+00017b90: 202b 206c 656e 5f69 5f31 5d0d 0a0d 0a20   + len_i_1].... 
+00017ba0: 2020 2020 2020 2062 203d 2073 656c 662e         b = self.
+00017bb0: 625f 7665 6374 6f72 2873 656c 662e 6469  b_vector(self.di
+00017bc0: 705f 616e 676c 6573 2c20 7365 6c66 2e61  p_angles, self.a
+00017bd0: 7a69 6d75 7468 2c20 7365 6c66 2e70 6f6c  zimuth, self.pol
+00017be0: 6172 6974 7929 0d0a 0d0a 2020 2020 2020  arity)....      
+00017bf0: 2020 6966 2073 656c 662e 7370 6172 7365    if self.sparse
+00017c00: 5f76 6572 7369 6f6e 2069 7320 5472 7565  _version is True
+00017c10: 3a0d 0a20 2020 2020 2020 2020 2020 2077  :..            w
+00017c20: 6569 6768 7473 203d 2073 656c 662e 736f  eights = self.so
+00017c30: 6c76 655f 6b72 6967 696e 6728 6229 0d0a  lve_kriging(b)..
+00017c40: 2020 2020 2020 2020 2020 2020 5a5f 7820              Z_x 
+00017c50: 3d20 7365 6c66 2e63 6f6d 7075 7465 5f73  = self.compute_s
+00017c60: 6361 6c61 725f 6669 656c 6428 7765 6967  calar_field(weig
+00017c70: 6874 732c 2067 7269 6429 0d0a 2020 2020  hts, grid)..    
+00017c80: 2020 2020 2020 2020 7765 6967 6874 7320          weights 
+00017c90: 3d20 7765 6967 6874 735b 305d 0d0a 0d0a  = weights[0]....
+00017ca0: 2020 2020 2020 2020 656c 7365 3a0d 0a20          else:.. 
 00017cb0: 2020 2020 2020 2020 2020 2077 6569 6768             weigh
-00017cc0: 7473 203d 2073 656c 662e 736f 6c76 655f  ts = self.solve_
-00017cd0: 6b72 6967 696e 6728 6229 0d0a 2020 2020  kriging(b)..    
-00017ce0: 2020 2020 2020 2020 5a5f 7820 3d20 7365          Z_x = se
-00017cf0: 6c66 2e63 6f6d 7075 7465 5f73 6361 6c61  lf.compute_scala
-00017d00: 725f 6669 656c 6428 7765 6967 6874 732c  r_field(weights,
-00017d10: 2067 7269 6429 0d0a 2020 2020 2020 2020   grid)..        
-00017d20: 2020 2020 7765 6967 6874 7320 3d20 7765      weights = we
-00017d30: 6967 6874 735b 305d 0d0a 0d0a 2020 2020  ights[0]....    
-00017d40: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
-00017d50: 2020 2020 2020 2077 6569 6768 7473 203d         weights =
-00017d60: 2074 6865 616e 6f2e 6966 656c 7365 2e69   theano.ifelse.i
-00017d70: 6665 6c73 6528 636f 6d70 7574 655f 7765  felse(compute_we
-00017d80: 6967 6874 5f63 7472 2c0d 0a20 2020 2020  ight_ctr,..     
-00017d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017db0: 2020 2020 2020 7365 6c66 2e73 6f6c 7665        self.solve
-00017dc0: 5f6b 7269 6769 6e67 2862 292c 0d0a 2020  _kriging(b),..  
-00017dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017df0: 2020 2020 2020 2020 2077 6569 6768 7473           weights
-00017e00: 5f76 6563 746f 725b 6c65 6e5f 775f 303a  _vector[len_w_0:
-00017e10: 6c65 6e5f 775f 315d 290d 0a0d 0a20 2020  len_w_1])....   
-00017e20: 2020 2020 2020 2020 205a 5f78 203d 2074           Z_x = t
-00017e30: 6966 2e69 6665 6c73 6528 636f 6d70 7574  if.ifelse(comput
-00017e40: 655f 7363 616c 6172 5f63 7472 2c0d 0a20  e_scalar_ctr,.. 
+00017cc0: 7473 203d 2061 6573 6172 612e 6966 656c  ts = aesara.ifel
+00017cd0: 7365 2e69 6665 6c73 6528 636f 6d70 7574  se.ifelse(comput
+00017ce0: 655f 7765 6967 6874 5f63 7472 2c0d 0a20  e_weight_ctr,.. 
+00017cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017d10: 2020 2020 2020 2020 2020 7365 6c66 2e73            self.s
+00017d20: 6f6c 7665 5f6b 7269 6769 6e67 2862 292c  olve_kriging(b),
+00017d30: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00017d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017d50: 2020 2020 2020 2020 2020 2020 2077 6569               wei
+00017d60: 6768 7473 5f76 6563 746f 725b 6c65 6e5f  ghts_vector[len_
+00017d70: 775f 303a 6c65 6e5f 775f 315d 290d 0a0d  w_0:len_w_1])...
+00017d80: 0a20 2020 2020 2020 2020 2020 205a 5f78  .            Z_x
+00017d90: 203d 2074 6966 2e69 6665 6c73 6528 636f   = tif.ifelse(co
+00017da0: 6d70 7574 655f 7363 616c 6172 5f63 7472  mpute_scalar_ctr
+00017db0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00017dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017dd0: 7365 6c66 2e63 6f6d 7075 7465 5f73 6361  self.compute_sca
+00017de0: 6c61 725f 6669 656c 6428 7765 6967 6874  lar_field(weight
+00017df0: 732c 2067 7269 642c 0d0a 2020 2020 2020  s, grid,..      
+00017e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017e30: 2066 6175 6c74 5f6d 6174 7269 785f 6f70   fault_matrix_op
+00017e40: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
 00017e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017e60: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00017e70: 2e63 6f6d 7075 7465 5f73 6361 6c61 725f  .compute_scalar_
-00017e80: 6669 656c 6428 7765 6967 6874 732c 2067  field(weights, g
-00017e90: 7269 642c 0d0a 2020 2020 2020 2020 2020  rid,..          
-00017ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017ec0: 2020 2020 2020 2020 2020 2020 2066 6175               fau
-00017ed0: 6c74 5f6d 6174 7269 785f 6f70 292c 0d0a  lt_matrix_op),..
-00017ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017ef0: 2020 2020 2020 2020 2020 2020 2073 6361               sca
-00017f00: 6c61 725f 6669 656c 645f 6d61 7472 6978  lar_field_matrix
-00017f10: 5b6e 5f73 6572 6965 735d 290d 0a0d 0a20  [n_series]).... 
-00017f20: 2020 2020 2020 2069 6620 2777 6569 6768         if 'weigh
-00017f30: 7473 2720 696e 2073 656c 662e 7665 7262  ts' in self.verb
-00017f40: 6f73 653a 0d0a 2020 2020 2020 2020 2020  ose:..          
-00017f50: 2020 7765 6967 6874 7320 3d20 7468 6561    weights = thea
-00017f60: 6e6f 2e70 7269 6e74 696e 672e 5072 696e  no.printing.Prin
-00017f70: 7428 2777 6569 6768 7473 2066 6f6f 2729  t('weights foo')
-00017f80: 2877 6569 6768 7473 290d 0a0d 0a20 2020  (weights)....   
-00017f90: 2020 2020 2073 6361 6c61 725f 6669 656c       scalar_fiel
-00017fa0: 645f 6174 5f73 7572 6661 6365 5f70 6f69  d_at_surface_poi
-00017fb0: 6e74 7320 3d20 7365 6c66 2e67 6574 5f73  nts = self.get_s
-00017fc0: 6361 6c61 725f 6669 656c 645f 6174 5f73  calar_field_at_s
-00017fd0: 7572 6661 6365 5f70 6f69 6e74 7328 5a5f  urface_points(Z_
-00017fe0: 782c 0d0a 2020 2020 2020 2020 2020 2020  x,..            
-00017ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018000: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018010: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018020: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018030: 2020 2020 2073 656c 662e 6e70 665f 6f70       self.npf_op
-00018040: 290d 0a0d 0a20 2020 2020 2020 2069 6620  )....        if 
-00018050: 2773 6661 6927 2069 6e20 7365 6c66 2e76  'sfai' in self.v
-00018060: 6572 626f 7365 3a0d 0a20 2020 2020 2020  erbose:..       
-00018070: 2020 2020 2073 6361 6c61 725f 6669 656c       scalar_fiel
-00018080: 645f 6174 5f73 7572 6661 6365 5f70 6f69  d_at_surface_poi
-00018090: 6e74 7320 3d20 7468 6561 6e6f 2e70 7269  nts = theano.pri
-000180a0: 6e74 696e 672e 5072 696e 7428 2773 6661  nting.Print('sfa
-000180b0: 6927 2928 0d0a 2020 2020 2020 2020 2020  i')(..          
-000180c0: 2020 2020 2020 7363 616c 6172 5f66 6965        scalar_fie
-000180d0: 6c64 5f61 745f 7375 7266 6163 655f 706f  ld_at_surface_po
-000180e0: 696e 7473 290d 0a0d 0a20 2020 2020 2020  ints)....       
-000180f0: 2023 2054 4f44 4f3a 2061 6464 2063 6f6e   # TODO: add con
-00018100: 7472 6f6c 2066 6c6f 7720 666f 7220 7468  trol flow for th
-00018110: 6973 2073 6964 650d 0a20 2020 2020 2020  is side..       
-00018120: 206d 6173 6b5f 6520 3d20 7469 662e 6966   mask_e = tif.if
-00018130: 656c 7365 2869 735f 6572 6f73 696f 6e2c  else(is_erosion,
-00018140: 2020 2320 4966 2069 7320 6572 6f73 696f    # If is erosio
-00018150: 6e0d 0a20 2020 2020 2020 2020 2020 2020  n..             
-00018160: 2020 2020 2020 2020 2020 2020 2020 2054                 T
-00018170: 2e67 7428 5a5f 782c 2054 2e6d 696e 2873  .gt(Z_x, T.min(s
-00018180: 6361 6c61 725f 6669 656c 645f 6174 5f73  calar_field_at_s
-00018190: 7572 6661 6365 5f70 6f69 6e74 7329 292c  urface_points)),
-000181a0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-000181b0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-000181c0: 4974 2069 7320 5472 7565 2074 6865 2076  It is True the v
-000181d0: 616c 7565 7320 6f76 6572 2074 6865 206c  alues over the l
-000181e0: 6173 7420 7375 7266 6163 650d 0a20 2020  ast surface..   
-000181f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018200: 2020 2020 2020 2020 207e 2073 656c 662e           ~ self.
-00018210: 6973 5f66 6175 6c74 5b6e 5f73 6572 6965  is_fault[n_serie
-00018220: 735d 202a 2054 2e6f 6e65 735f 6c69 6b65  s] * T.ones_like
-00018230: 285a 5f78 2c0d 0a20 2020 2020 2020 2020  (Z_x,..         
-00018240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018260: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018270: 2020 2020 2020 2020 2020 2064 7479 7065             dtype
-00018280: 3d27 626f 6f6c 2729 2920 2023 2065 6c73  ='bool'))  # els
-00018290: 653a 2061 6c6c 2046 616c 7365 2069 6620  e: all False if 
-000182a0: 6973 2046 6175 6c74 2065 6c73 6520 616c  is Fault else al
-000182b0: 6c20 6f6e 6573 0d0a 0d0a 2020 2020 2020  l ones....      
-000182c0: 2020 6966 2027 6d61 736b 5f65 2720 696e    if 'mask_e' in
-000182d0: 2073 656c 662e 7665 7262 6f73 653a 0d0a   self.verbose:..
-000182e0: 2020 2020 2020 2020 2020 2020 6d61 736b              mask
-000182f0: 5f65 203d 2074 6865 616e 6f2e 7072 696e  _e = theano.prin
-00018300: 7469 6e67 2e50 7269 6e74 2827 6d61 736b  ting.Print('mask
-00018310: 5f65 2729 286d 6173 6b5f 6529 0d0a 0d0a  _e')(mask_e)....
-00018320: 2020 2020 2020 2020 2320 4e75 6d62 6572          # Number
-00018330: 206f 6620 7365 7269 6573 2073 696e 6365   of series since
-00018340: 206c 6173 7420 6572 6f64 653a 2054 6869   last erode: Thi
-00018350: 7320 6973 206e 6563 6573 7361 7279 2069  s is necessary i
-00018360: 6e20 6361 7365 2074 6865 7265 2061 7265  n case there are
-00018370: 0d0a 2020 2020 2020 2020 2320 6d75 6c74  ..        # mult
-00018380: 6970 6c65 2063 6f6e 7365 6375 7469 7665  iple consecutive
-00018390: 7320 6f6e 6c61 7073 0d0a 0d0a 2020 2020  s onlaps....    
-000183a0: 2020 2020 2320 4572 6f73 696f 6e20 7665      # Erosion ve
-000183b0: 7273 696f 6e0d 0a20 2020 2020 2020 2069  rsion..        i
-000183c0: 735f 6572 6f73 696f 6e5f 203d 2073 656c  s_erosion_ = sel
-000183d0: 662e 6973 5f65 726f 7369 6f6e 5b3a 6e5f  f.is_erosion[:n_
-000183e0: 7365 7269 6573 202b 2031 5d0d 0a20 2020  series + 1]..   
-000183f0: 2020 2020 2061 7267 735f 6973 5f65 726f       args_is_ero
-00018400: 7369 6f6e 203d 2054 2e6e 6f6e 7a65 726f  sion = T.nonzero
-00018410: 2854 2e63 6f6e 6361 7465 6e61 7465 2828  (T.concatenate((
-00018420: 5b31 5d2c 2069 735f 6572 6f73 696f 6e5f  [1], is_erosion_
-00018430: 2929 290d 0a20 2020 2020 2020 206c 6173  )))..        las
-00018440: 745f 6572 6f64 6520 3d20 542e 6172 676d  t_erode = T.argm
-00018450: 6178 2861 7267 735f 6973 5f65 726f 7369  ax(args_is_erosi
-00018460: 6f6e 5b30 5d29 0d0a 0d0a 2020 2020 2020  on[0])....      
-00018470: 2020 2320 4f6e 6c61 7020 7665 7273 696f    # Onlap versio
-00018480: 6e0d 0a20 2020 2020 2020 2069 735f 6f6e  n..        is_on
-00018490: 6c61 705f 6f72 5f66 6175 6c74 203d 2073  lap_or_fault = s
-000184a0: 656c 662e 6973 5f6f 6e6c 6170 5b6e 5f73  elf.is_onlap[n_s
-000184b0: 6572 6965 735d 202b 2073 656c 662e 6973  eries] + self.is
-000184c0: 5f66 6175 6c74 5b6e 5f73 6572 6965 735d  _fault[n_series]
-000184d0: 0d0a 0d0a 2020 2020 2020 2020 2320 5468  ....        # Th
-000184e0: 6973 2061 6464 7320 6120 636f 756e 7465  is adds a counte
-000184f0: 7220 202d 2d2d 2063 6865 636b 2073 6572  r  --- check ser
-00018500: 6965 7320 6f6e 6c61 702d 6661 756c 7420  ies onlap-fault 
-00018510: 2d2d 2d20 6368 6563 6b20 7468 6520 6368  --- check the ch
-00018520: 6169 6e20 7374 6172 7473 2077 6974 6820  ain starts with 
-00018530: 6f6e 6c61 700d 0a20 2020 2020 2020 206e  onlap..        n
-00018540: 736c 6520 3d20 286e 736c 6520 2b20 6973  sle = (nsle + is
-00018550: 5f6f 6e6c 6170 5f6f 725f 6661 756c 7429  _onlap_or_fault)
-00018560: 202a 2069 735f 6f6e 6c61 705f 6f72 5f66   * is_onlap_or_f
-00018570: 6175 6c74 202a 205c 0d0a 2020 2020 2020  ault * \..      
-00018580: 2020 2020 2020 2020 2073 656c 662e 6973           self.is
-00018590: 5f6f 6e6c 6170 5b6e 5f73 6572 6965 7320  _onlap[n_series 
-000185a0: 2d20 6e73 6c65 5d0d 0a20 2020 2020 2020  - nsle]..       
-000185b0: 206e 736c 655f 6f70 203d 206e 736c 6520   nsle_op = nsle 
-000185c0: 2023 2054 2e6d 6178 285b 6e73 6c65 2c20   # T.max([nsle, 
-000185d0: 315d 290d 0a0d 0a20 2020 2020 2020 2069  1])....        i
-000185e0: 6620 276e 736c 6527 2069 6e20 7365 6c66  f 'nsle' in self
-000185f0: 2e76 6572 626f 7365 3a0d 0a20 2020 2020  .verbose:..     
-00018600: 2020 2020 2020 206e 736c 655f 6f70 203d         nsle_op =
-00018610: 2074 6865 616e 6f2e 7072 696e 7469 6e67   theano.printing
-00018620: 2e50 7269 6e74 2827 6e73 6c65 5f6f 7027  .Print('nsle_op'
-00018630: 2928 6e73 6c65 5f6f 7029 0d0a 0d0a 2020  )(nsle_op)....  
-00018640: 2020 2020 2020 6d61 736b 5f6f 203d 2074        mask_o = t
-00018650: 6966 2e69 6665 6c73 6528 6973 5f6f 6e6c  if.ifelse(is_onl
-00018660: 6170 2c0d 0a20 2020 2020 2020 2020 2020  ap,..           
-00018670: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018680: 2054 2e67 7428 5a5f 782c 2054 2e6d 6178   T.gt(Z_x, T.max
-00018690: 2873 6361 6c61 725f 6669 656c 645f 6174  (scalar_field_at
-000186a0: 5f73 7572 6661 6365 5f70 6f69 6e74 7329  _surface_points)
-000186b0: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
-000186c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000186d0: 6d61 736b 5f6d 6174 7269 785b 6e5f 7365  mask_matrix[n_se
-000186e0: 7269 6573 202d 2031 2c0d 0a20 2020 2020  ries - 1,..     
-000186f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018700: 2020 2020 2020 2073 6869 6674 3a78 5f74         shift:x_t
-00018710: 6f5f 696e 7465 7270 6f6c 6174 655f 7368  o_interpolate_sh
-00018720: 6170 6520 2b20 7368 6966 745d 290d 0a0d  ape + shift])...
-00018730: 0a20 2020 2020 2020 206d 6173 6b5f 6620  .        mask_f 
-00018740: 3d20 7469 662e 6966 656c 7365 2873 656c  = tif.ifelse(sel
-00018750: 662e 6973 5f66 6175 6c74 5b6e 5f73 6572  f.is_fault[n_ser
-00018760: 6965 735d 2c0d 0a20 2020 2020 2020 2020  ies],..         
-00018770: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018780: 2020 2054 2e67 7428 5a5f 782c 2054 2e6d     T.gt(Z_x, T.m
-00018790: 696e 2873 6361 6c61 725f 6669 656c 645f  in(scalar_field_
-000187a0: 6174 5f73 7572 6661 6365 5f70 6f69 6e74  at_surface_point
-000187b0: 7329 292c 0d0a 2020 2020 2020 2020 2020  s)),..          
-000187c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000187d0: 2020 542e 7a65 726f 735f 6c69 6b65 285a    T.zeros_like(Z
-000187e0: 5f78 2c20 6474 7970 653d 2762 6f6f 6c27  _x, dtype='bool'
-000187f0: 2929 0d0a 0d0a 2020 2020 2020 2020 6966  ))....        if
-00018800: 2073 656c 662e 6772 6164 6965 6e74 2069   self.gradient i
-00018810: 7320 4661 6c73 653a 0d0a 2020 2020 2020  s False:..      
-00018820: 2020 2020 2020 626c 6f63 6b20 3d20 7469        block = ti
-00018830: 662e 6966 656c 7365 280d 0a20 2020 2020  f.ifelse(..     
-00018840: 2020 2020 2020 2020 2020 2063 6f6d 7075             compu
-00018850: 7465 5f62 6c6f 636b 5f63 7472 2c0d 0a20  te_block_ctr,.. 
-00018860: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-00018870: 6966 2e69 6665 6c73 6528 0d0a 2020 2020  if.ifelse(..    
-00018880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018890: 6973 5f66 696e 6974 652c 0d0a 2020 2020  is_finite,..    
-000188a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000188b0: 7365 6c66 2e63 6f6d 7075 7465 5f66 6175  self.compute_fau
-000188c0: 6c74 5f62 6c6f 636b 280d 0a20 2020 2020  lt_block(..     
+00017e60: 2073 6361 6c61 725f 6669 656c 645f 6d61   scalar_field_ma
+00017e70: 7472 6978 5b6e 5f73 6572 6965 735d 290d  trix[n_series]).
+00017e80: 0a0d 0a20 2020 2020 2020 2069 6620 2777  ...        if 'w
+00017e90: 6569 6768 7473 2720 696e 2073 656c 662e  eights' in self.
+00017ea0: 7665 7262 6f73 653a 0d0a 2020 2020 2020  verbose:..      
+00017eb0: 2020 2020 2020 7765 6967 6874 7320 3d20        weights = 
+00017ec0: 6165 7361 7261 2e70 7269 6e74 696e 672e  aesara.printing.
+00017ed0: 5072 696e 7428 2777 6569 6768 7473 2066  Print('weights f
+00017ee0: 6f6f 2729 2877 6569 6768 7473 290d 0a0d  oo')(weights)...
+00017ef0: 0a20 2020 2020 2020 2073 6361 6c61 725f  .        scalar_
+00017f00: 6669 656c 645f 6174 5f73 7572 6661 6365  field_at_surface
+00017f10: 5f70 6f69 6e74 7320 3d20 7365 6c66 2e67  _points = self.g
+00017f20: 6574 5f73 6361 6c61 725f 6669 656c 645f  et_scalar_field_
+00017f30: 6174 5f73 7572 6661 6365 5f70 6f69 6e74  at_surface_point
+00017f40: 7328 5a5f 782c 0d0a 2020 2020 2020 2020  s(Z_x,..        
+00017f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017f90: 2020 2020 2020 2020 2073 656c 662e 6e70           self.np
+00017fa0: 665f 6f70 290d 0a0d 0a20 2020 2020 2020  f_op)....       
+00017fb0: 2069 6620 2773 6661 6927 2069 6e20 7365   if 'sfai' in se
+00017fc0: 6c66 2e76 6572 626f 7365 3a0d 0a20 2020  lf.verbose:..   
+00017fd0: 2020 2020 2020 2020 2073 6361 6c61 725f           scalar_
+00017fe0: 6669 656c 645f 6174 5f73 7572 6661 6365  field_at_surface
+00017ff0: 5f70 6f69 6e74 7320 3d20 6165 7361 7261  _points = aesara
+00018000: 2e70 7269 6e74 696e 672e 5072 696e 7428  .printing.Print(
+00018010: 2773 6661 6927 2928 0d0a 2020 2020 2020  'sfai')(..      
+00018020: 2020 2020 2020 2020 2020 7363 616c 6172            scalar
+00018030: 5f66 6965 6c64 5f61 745f 7375 7266 6163  _field_at_surfac
+00018040: 655f 706f 696e 7473 290d 0a0d 0a20 2020  e_points)....   
+00018050: 2020 2020 2023 2054 4f44 4f3a 2061 6464       # TODO: add
+00018060: 2063 6f6e 7472 6f6c 2066 6c6f 7720 666f   control flow fo
+00018070: 7220 7468 6973 2073 6964 650d 0a20 2020  r this side..   
+00018080: 2020 2020 206d 6173 6b5f 6520 3d20 7469       mask_e = ti
+00018090: 662e 6966 656c 7365 2869 735f 6572 6f73  f.ifelse(is_eros
+000180a0: 696f 6e2c 2020 2320 4966 2069 7320 6572  ion,  # If is er
+000180b0: 6f73 696f 6e0d 0a20 2020 2020 2020 2020  osion..         
+000180c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000180d0: 2020 2054 2e67 7428 5a5f 782c 2054 2e6d     T.gt(Z_x, T.m
+000180e0: 696e 2873 6361 6c61 725f 6669 656c 645f  in(scalar_field_
+000180f0: 6174 5f73 7572 6661 6365 5f70 6f69 6e74  at_surface_point
+00018100: 7329 292c 0d0a 2020 2020 2020 2020 2020  s)),..          
+00018110: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018120: 2020 2320 4974 2069 7320 5472 7565 2074    # It is True t
+00018130: 6865 2076 616c 7565 7320 6f76 6572 2074  he values over t
+00018140: 6865 206c 6173 7420 7375 7266 6163 650d  he last surface.
+00018150: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00018160: 2020 2020 2020 2020 2020 2020 207e 2073               ~ s
+00018170: 656c 662e 6973 5f66 6175 6c74 5b6e 5f73  elf.is_fault[n_s
+00018180: 6572 6965 735d 202a 2054 2e6f 6e65 735f  eries] * T.ones_
+00018190: 6c69 6b65 285a 5f78 2c20 6474 7970 653d  like(Z_x, dtype=
+000181a0: 2762 6f6f 6c27 290d 0a20 2020 2020 2020  'bool')..       
+000181b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000181c0: 2020 2020 2029 2020 2320 656c 7365 3a20       )  # else: 
+000181d0: 616c 6c20 4661 6c73 6520 6966 2069 7320  all False if is 
+000181e0: 4661 756c 7420 656c 7365 2061 6c6c 206f  Fault else all o
+000181f0: 6e65 730d 0a0d 0a20 2020 2020 2020 2069  nes....        i
+00018200: 6620 276d 6173 6b5f 6527 2069 6e20 7365  f 'mask_e' in se
+00018210: 6c66 2e76 6572 626f 7365 3a0d 0a20 2020  lf.verbose:..   
+00018220: 2020 2020 2020 2020 206d 6173 6b5f 6520           mask_e 
+00018230: 3d20 6165 7361 7261 2e70 7269 6e74 696e  = aesara.printin
+00018240: 672e 5072 696e 7428 276d 6173 6b5f 6527  g.Print('mask_e'
+00018250: 2928 6d61 736b 5f65 290d 0a0d 0a20 2020  )(mask_e)....   
+00018260: 2020 2020 2023 204e 756d 6265 7220 6f66       # Number of
+00018270: 2073 6572 6965 7320 7369 6e63 6520 6c61   series since la
+00018280: 7374 2065 726f 6465 3a20 5468 6973 2069  st erode: This i
+00018290: 7320 6e65 6365 7373 6172 7920 696e 2063  s necessary in c
+000182a0: 6173 6520 7468 6572 6520 6172 650d 0a20  ase there are.. 
+000182b0: 2020 2020 2020 2023 206d 756c 7469 706c         # multipl
+000182c0: 6520 636f 6e73 6563 7574 6976 6573 206f  e consecutives o
+000182d0: 6e6c 6170 730d 0a0d 0a20 2020 2020 2020  nlaps....       
+000182e0: 2023 2045 726f 7369 6f6e 2076 6572 7369   # Erosion versi
+000182f0: 6f6e 0d0a 2020 2020 2020 2020 6973 5f65  on..        is_e
+00018300: 726f 7369 6f6e 5f20 3d20 7365 6c66 2e69  rosion_ = self.i
+00018310: 735f 6572 6f73 696f 6e5b 3a6e 5f73 6572  s_erosion[:n_ser
+00018320: 6965 7320 2b20 315d 0d0a 2020 2020 2020  ies + 1]..      
+00018330: 2020 6172 6773 5f69 735f 6572 6f73 696f    args_is_erosio
+00018340: 6e20 3d20 542e 6e6f 6e7a 6572 6f28 542e  n = T.nonzero(T.
+00018350: 636f 6e63 6174 656e 6174 6528 285b 315d  concatenate(([1]
+00018360: 2c20 6973 5f65 726f 7369 6f6e 5f29 2929  , is_erosion_)))
+00018370: 0d0a 2020 2020 2020 2020 6c61 7374 5f65  ..        last_e
+00018380: 726f 6465 203d 2054 2e61 7267 6d61 7828  rode = T.argmax(
+00018390: 6172 6773 5f69 735f 6572 6f73 696f 6e5b  args_is_erosion[
+000183a0: 305d 290d 0a0d 0a20 2020 2020 2020 2023  0])....        #
+000183b0: 204f 6e6c 6170 2076 6572 7369 6f6e 0d0a   Onlap version..
+000183c0: 2020 2020 2020 2020 6973 5f6f 6e6c 6170          is_onlap
+000183d0: 5f6f 725f 6661 756c 7420 3d20 7365 6c66  _or_fault = self
+000183e0: 2e69 735f 6f6e 6c61 705b 6e5f 7365 7269  .is_onlap[n_seri
+000183f0: 6573 5d20 2b20 7365 6c66 2e69 735f 6661  es] + self.is_fa
+00018400: 756c 745b 6e5f 7365 7269 6573 5d0d 0a0d  ult[n_series]...
+00018410: 0a20 2020 2020 2020 2023 2054 6869 7320  .        # This 
+00018420: 6164 6473 2061 2063 6f75 6e74 6572 2020  adds a counter  
+00018430: 2d2d 2d20 6368 6563 6b20 7365 7269 6573  --- check series
+00018440: 206f 6e6c 6170 2d66 6175 6c74 202d 2d2d   onlap-fault ---
+00018450: 2063 6865 636b 2074 6865 2063 6861 696e   check the chain
+00018460: 2073 7461 7274 7320 7769 7468 206f 6e6c   starts with onl
+00018470: 6170 0d0a 2020 2020 2020 2020 6e73 6c65  ap..        nsle
+00018480: 203d 2028 6e73 6c65 202b 2069 735f 6f6e   = (nsle + is_on
+00018490: 6c61 705f 6f72 5f66 6175 6c74 2920 2a20  lap_or_fault) * 
+000184a0: 6973 5f6f 6e6c 6170 5f6f 725f 6661 756c  is_onlap_or_faul
+000184b0: 7420 2a20 7365 6c66 2e69 735f 6f6e 6c61  t * self.is_onla
+000184c0: 705b 6e5f 7365 7269 6573 202d 206e 736c  p[n_series - nsl
+000184d0: 655d 0d0a 2020 2020 2020 2020 6e73 6c65  e]..        nsle
+000184e0: 5f6f 7020 3d20 6e73 6c65 2020 2320 542e  _op = nsle  # T.
+000184f0: 6d61 7828 5b6e 736c 652c 2031 5d29 0d0a  max([nsle, 1])..
+00018500: 0d0a 2020 2020 2020 2020 6966 2027 6e73  ..        if 'ns
+00018510: 6c65 2720 696e 2073 656c 662e 7665 7262  le' in self.verb
+00018520: 6f73 653a 0d0a 2020 2020 2020 2020 2020  ose:..          
+00018530: 2020 6e73 6c65 5f6f 7020 3d20 6165 7361    nsle_op = aesa
+00018540: 7261 2e70 7269 6e74 696e 672e 5072 696e  ra.printing.Prin
+00018550: 7428 276e 736c 655f 6f70 2729 286e 736c  t('nsle_op')(nsl
+00018560: 655f 6f70 290d 0a0d 0a20 2020 2020 2020  e_op)....       
+00018570: 206d 6173 6b5f 6f20 3d20 7469 662e 6966   mask_o = tif.if
+00018580: 656c 7365 2869 735f 6f6e 6c61 702c 0d0a  else(is_onlap,..
+00018590: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000185a0: 2020 2020 2020 2020 2020 2020 542e 6774              T.gt
+000185b0: 285a 5f78 2c20 542e 6d61 7828 7363 616c  (Z_x, T.max(scal
+000185c0: 6172 5f66 6965 6c64 5f61 745f 7375 7266  ar_field_at_surf
+000185d0: 6163 655f 706f 696e 7473 2929 2c0d 0a20  ace_points)),.. 
+000185e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000185f0: 2020 2020 2020 2020 2020 206d 6173 6b5f             mask_
+00018600: 6d61 7472 6978 5b6e 5f73 6572 6965 7320  matrix[n_series 
+00018610: 2d20 312c 2073 6869 6674 3a78 5f74 6f5f  - 1, shift:x_to_
+00018620: 696e 7465 7270 6f6c 6174 655f 7368 6170  interpolate_shap
+00018630: 6520 2b20 7368 6966 745d 0d0a 2020 2020  e + shift]..    
+00018640: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018650: 2020 2020 2020 2020 290d 0a0d 0a20 2020          )....   
+00018660: 2020 2020 206d 6173 6b5f 6620 3d20 7469       mask_f = ti
+00018670: 662e 6966 656c 7365 2873 656c 662e 6973  f.ifelse(self.is
+00018680: 5f66 6175 6c74 5b6e 5f73 6572 6965 735d  _fault[n_series]
+00018690: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+000186a0: 2020 2020 2020 2020 2020 2020 2020 2054                 T
+000186b0: 2e67 7428 5a5f 782c 2054 2e6d 696e 2873  .gt(Z_x, T.min(s
+000186c0: 6361 6c61 725f 6669 656c 645f 6174 5f73  calar_field_at_s
+000186d0: 7572 6661 6365 5f70 6f69 6e74 7329 292c  urface_points)),
+000186e0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000186f0: 2020 2020 2020 2020 2020 2020 2020 542e                T.
+00018700: 7a65 726f 735f 6c69 6b65 285a 5f78 2c20  zeros_like(Z_x, 
+00018710: 6474 7970 653d 2762 6f6f 6c27 290d 0a20  dtype='bool').. 
+00018720: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018730: 2020 2020 2020 2020 2020 2029 0d0a 0d0a             )....
+00018740: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00018750: 6772 6164 6965 6e74 2069 7320 4661 6c73  gradient is Fals
+00018760: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+00018770: 626c 6f63 6b20 3d20 7469 662e 6966 656c  block = tif.ifel
+00018780: 7365 280d 0a20 2020 2020 2020 2020 2020  se(..           
+00018790: 2020 2020 2063 6f6d 7075 7465 5f62 6c6f       compute_blo
+000187a0: 636b 5f63 7472 2c0d 0a20 2020 2020 2020  ck_ctr,..       
+000187b0: 2020 2020 2020 2020 2074 6966 2e69 6665           tif.ife
+000187c0: 6c73 6528 0d0a 2020 2020 2020 2020 2020  lse(..          
+000187d0: 2020 2020 2020 2020 2020 6973 5f66 696e            is_fin
+000187e0: 6974 652c 0d0a 2020 2020 2020 2020 2020  ite,..          
+000187f0: 2020 2020 2020 2020 2020 7365 6c66 2e63            self.c
+00018800: 6f6d 7075 7465 5f66 6175 6c74 5f62 6c6f  ompute_fault_blo
+00018810: 636b 280d 0a20 2020 2020 2020 2020 2020  ck(..           
+00018820: 2020 2020 2020 2020 2020 2020 205a 5f78               Z_x
+00018830: 2c20 7363 616c 6172 5f66 6965 6c64 5f61  , scalar_field_a
+00018840: 745f 7375 7266 6163 655f 706f 696e 7473  t_surface_points
+00018850: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00018860: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00018870: 7661 6c75 6573 5f70 726f 7065 7274 6965  values_propertie
+00018880: 735f 6f70 5b3a 2c0d 0a20 2020 2020 2020  s_op[:,..       
+00018890: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000188a0: 206e 5f66 6f72 6d5f 7065 725f 7365 7269   n_form_per_seri
+000188b0: 655f 303a 206e 5f66 6f72 6d5f 7065 725f  e_0: n_form_per_
+000188c0: 7365 7269 655f 3120 2b20 315d 2c0d 0a20  serie_1 + 1],.. 
 000188d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000188e0: 2020 205a 5f78 2c20 7363 616c 6172 5f66     Z_x, scalar_f
-000188f0: 6965 6c64 5f61 745f 7375 7266 6163 655f  ield_at_surface_
-00018900: 706f 696e 7473 2c0d 0a20 2020 2020 2020  points,..       
+000188e0: 2020 2020 2020 206e 5f73 6572 6965 732c         n_series,
+000188f0: 2067 7269 640d 0a20 2020 2020 2020 2020   grid..         
+00018900: 2020 2020 2020 2020 2020 2029 2c0d 0a20             ),.. 
 00018910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018920: 2073 656c 662e 7661 6c75 6573 5f70 726f   self.values_pro
-00018930: 7065 7274 6965 735f 6f70 5b3a 2c0d 0a20  perties_op[:,.. 
-00018940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018950: 2020 2020 2020 206e 5f66 6f72 6d5f 7065         n_form_pe
-00018960: 725f 7365 7269 655f 303a 206e 5f66 6f72  r_serie_0: n_for
-00018970: 6d5f 7065 725f 7365 7269 655f 3120 2b20  m_per_serie_1 + 
-00018980: 315d 2c0d 0a20 2020 2020 2020 2020 2020  1],..           
-00018990: 2020 2020 2020 2020 2020 2020 206e 5f73               n_s
-000189a0: 6572 6965 732c 2067 7269 640d 0a20 2020  eries, grid..   
-000189b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000189c0: 2029 2c0d 0a20 2020 2020 2020 2020 2020   ),..           
-000189d0: 2020 2020 2020 2020 2073 656c 662e 636f           self.co
-000189e0: 6d70 7574 655f 666f 726d 6174 696f 6e5f  mpute_formation_
-000189f0: 626c 6f63 6b28 0d0a 2020 2020 2020 2020  block(..        
-00018a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018a10: 5a5f 782c 2073 6361 6c61 725f 6669 656c  Z_x, scalar_fiel
-00018a20: 645f 6174 5f73 7572 6661 6365 5f70 6f69  d_at_surface_poi
-00018a30: 6e74 732c 0d0a 2020 2020 2020 2020 2020  nts,..          
-00018a40: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00018a50: 6c66 2e76 616c 7565 735f 7072 6f70 6572  lf.values_proper
-00018a60: 7469 6573 5f6f 705b 3a2c 0d0a 2020 2020  ties_op[:,..    
-00018a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018a80: 2020 2020 6e5f 666f 726d 5f70 6572 5f73      n_form_per_s
-00018a90: 6572 6965 5f30 3a20 6e5f 666f 726d 5f70  erie_0: n_form_p
-00018aa0: 6572 5f73 6572 6965 5f31 202b 2031 5d29  er_serie_1 + 1])
-00018ab0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00018ac0: 2020 292c 0d0a 2020 2020 2020 2020 2020    ),..          
-00018ad0: 2020 2020 2020 626c 6f63 6b5f 6d61 7472        block_matr
-00018ae0: 6978 5b6e 5f73 6572 6965 732c 203a 5d0d  ix[n_series, :].
-00018af0: 0a20 2020 2020 2020 2020 2020 2029 0d0a  .            )..
-00018b00: 2020 2020 2020 2020 656c 7365 3a0d 0a20          else:.. 
-00018b10: 2020 2020 2020 2020 2020 2062 6c6f 636b             block
-00018b20: 203d 2074 6966 2e69 6665 6c73 6528 636f   = tif.ifelse(co
-00018b30: 6d70 7574 655f 626c 6f63 6b5f 6374 722c  mpute_block_ctr,
-00018b40: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00018b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018b60: 2073 656c 662e 636f 6d70 7574 655f 666f   self.compute_fo
-00018b70: 726d 6174 696f 6e5f 626c 6f63 6b28 0d0a  rmation_block(..
-00018b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018ba0: 2020 205a 5f78 2c20 7363 616c 6172 5f66     Z_x, scalar_f
-00018bb0: 6965 6c64 5f61 745f 7375 7266 6163 655f  ield_at_surface_
-00018bc0: 706f 696e 7473 2c0d 0a20 2020 2020 2020  points,..       
-00018bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018be0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00018bf0: 2e76 616c 7565 735f 7072 6f70 6572 7469  .values_properti
-00018c00: 6573 5f6f 705b 3a2c 0d0a 2020 2020 2020  es_op[:,..      
-00018c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018c20: 2020 2020 2020 2020 2020 2020 206e 5f66               n_f
-00018c30: 6f72 6d5f 7065 725f 7365 7269 655f 303a  orm_per_serie_0:
-00018c40: 206e 5f66 6f72 6d5f 7065 725f 7365 7269   n_form_per_seri
-00018c50: 655f 3120 2b20 315d 292c 0d0a 2020 2020  e_1 + 1]),..    
-00018c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018c70: 2020 2020 2020 2020 2020 2062 6c6f 636b             block
-00018c80: 5f6d 6174 7269 785b 6e5f 7365 7269 6573  _matrix[n_series
-00018c90: 2c20 3a5d 0d0a 2020 2020 2020 2020 2020  , :]..          
-00018ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018cb0: 2020 2020 2029 0d0a 0d0a 2020 2020 2020       )....      
-00018cc0: 2020 7765 6967 6874 735f 7665 6374 6f72    weights_vector
-00018cd0: 203d 2054 2e73 6574 5f73 7562 7465 6e73   = T.set_subtens
-00018ce0: 6f72 2877 6569 6768 7473 5f76 6563 746f  or(weights_vecto
-00018cf0: 725b 6c65 6e5f 775f 303a 6c65 6e5f 775f  r[len_w_0:len_w_
-00018d00: 315d 2c20 7765 6967 6874 7329 0d0a 2020  1], weights)..  
-00018d10: 2020 2020 2020 7363 616c 6172 5f66 6965        scalar_fie
-00018d20: 6c64 5f6d 6174 7269 7820 3d20 542e 7365  ld_matrix = T.se
-00018d30: 745f 7375 6274 656e 736f 7228 0d0a 2020  t_subtensor(..  
-00018d40: 2020 2020 2020 2020 2020 7363 616c 6172            scalar
-00018d50: 5f66 6965 6c64 5f6d 6174 7269 785b 6e5f  _field_matrix[n_
-00018d60: 7365 7269 6573 2c20 7368 6966 743a 785f  series, shift:x_
-00018d70: 746f 5f69 6e74 6572 706f 6c61 7465 5f73  to_interpolate_s
-00018d80: 6861 7065 202b 2073 6869 6674 5d2c 205a  hape + shift], Z
-00018d90: 5f78 290d 0a20 2020 2020 2020 2062 6c6f  _x)..        blo
-00018da0: 636b 5f6d 6174 7269 7820 3d20 542e 7365  ck_matrix = T.se
-00018db0: 745f 7375 6274 656e 736f 7228 0d0a 2020  t_subtensor(..  
-00018dc0: 2020 2020 2020 2020 2020 626c 6f63 6b5f            block_
-00018dd0: 6d61 7472 6978 5b6e 5f73 6572 6965 732c  matrix[n_series,
-00018de0: 203a 2c20 7368 6966 743a 785f 746f 5f69   :, shift:x_to_i
-00018df0: 6e74 6572 706f 6c61 7465 5f73 6861 7065  nterpolate_shape
-00018e00: 202b 2073 6869 6674 5d2c 2062 6c6f 636b   + shift], block
-00018e10: 290d 0a20 2020 2020 2020 2066 6175 6c74  )..        fault
-00018e20: 5f6d 6174 7269 7820 3d20 542e 7365 745f  _matrix = T.set_
-00018e30: 7375 6274 656e 736f 7228 0d0a 2020 2020  subtensor(..    
-00018e40: 2020 2020 2020 2020 6661 756c 745f 6d61          fault_ma
-00018e50: 7472 6978 5b6e 5f73 6572 6965 732c 203a  trix[n_series, :
-00018e60: 2c20 7368 6966 743a 785f 746f 5f69 6e74  , shift:x_to_int
-00018e70: 6572 706f 6c61 7465 5f73 6861 7065 202b  erpolate_shape +
-00018e80: 2073 6869 6674 5d2c 2062 6c6f 636b 290d   shift], block).
-00018e90: 0a0d 0a20 2020 2020 2020 2023 204c 4954  ...        # LIT
-00018ea0: 4820 4d41 534b 0d0a 2020 2020 2020 2020  H MASK..        
-00018eb0: 6d61 736b 5f6d 6174 7269 7820 3d20 542e  mask_matrix = T.
-00018ec0: 7365 745f 7375 6274 656e 736f 7228 6d61  set_subtensor(ma
-00018ed0: 736b 5f6d 6174 7269 785b 6e5f 7365 7269  sk_matrix[n_seri
-00018ee0: 6573 202d 2031 3a20 6e5f 7365 7269 6573  es - 1: n_series
-00018ef0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00018f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018f10: 2020 2020 2020 2020 2073 6869 6674 3a78           shift:x
-00018f20: 5f74 6f5f 696e 7465 7270 6f6c 6174 655f  _to_interpolate_
-00018f30: 7368 6170 6520 2b20 7368 6966 745d 2c20  shape + shift], 
-00018f40: 6d61 736b 5f6f 290d 0a0d 0a20 2020 2020  mask_o)....     
-00018f50: 2020 206d 6173 6b5f 6d61 7472 6978 203d     mask_matrix =
-00018f60: 2054 2e73 6574 5f73 7562 7465 6e73 6f72   T.set_subtensor
-00018f70: 286d 6173 6b5f 6d61 7472 6978 5b6e 5f73  (mask_matrix[n_s
-00018f80: 6572 6965 7320 2d20 6e73 6c65 5f6f 703a  eries - nsle_op:
-00018f90: 206e 5f73 6572 6965 732c 0d0a 2020 2020   n_series,..    
-00018fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018fc0: 2020 7368 6966 743a 785f 746f 5f69 6e74    shift:x_to_int
-00018fd0: 6572 706f 6c61 7465 5f73 6861 7065 202b  erpolate_shape +
-00018fe0: 2073 6869 6674 5d2c 0d0a 2020 2020 2020   shift],..      
-00018ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019000: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019010: 542e 6375 6d70 726f 6428 0d0a 2020 2020  T.cumprod(..    
-00019020: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019030: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019040: 2020 2020 2020 6d61 736b 5f6d 6174 7269        mask_matri
-00019050: 785b 6e5f 7365 7269 6573 202d 206e 736c  x[n_series - nsl
-00019060: 655f 6f70 3a20 6e5f 7365 7269 6573 2c0d  e_op: n_series,.
-00019070: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00019080: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019090: 2020 2020 2020 2020 2020 2073 6869 6674             shift
-000190a0: 3a78 5f74 6f5f 696e 7465 7270 6f6c 6174  :x_to_interpolat
-000190b0: 655f 7368 6170 6520 2b20 7368 6966 745d  e_shape + shift]
-000190c0: 5b0d 0a20 2020 2020 2020 2020 2020 2020  [..             
-000190d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000190e0: 2020 2020 2020 2020 2020 2020 203a 3a2d               ::-
-000190f0: 315d 2c20 6178 6973 3d30 295b 3a3a 2d31  1], axis=0)[::-1
-00019100: 5d29 0d0a 0d0a 2020 2020 2020 2020 6d61  ])....        ma
-00019110: 736b 5f6d 6174 7269 7820 3d20 542e 7365  sk_matrix = T.se
-00019120: 745f 7375 6274 656e 736f 7228 0d0a 2020  t_subtensor(..  
-00019130: 2020 2020 2020 2020 2020 6d61 736b 5f6d            mask_m
-00019140: 6174 7269 785b 6e5f 7365 7269 6573 2c20  atrix[n_series, 
-00019150: 7368 6966 743a 785f 746f 5f69 6e74 6572  shift:x_to_inter
-00019160: 706f 6c61 7465 5f73 6861 7065 202b 2073  polate_shape + s
-00019170: 6869 6674 5d2c 206d 6173 6b5f 6529 0d0a  hift], mask_e)..
-00019180: 0d0a 2020 2020 2020 2020 6966 2027 6d61  ..        if 'ma
-00019190: 736b 5f6d 6174 7269 785f 6c6f 6f70 2720  sk_matrix_loop' 
-000191a0: 696e 2073 656c 662e 7665 7262 6f73 653a  in self.verbose:
-000191b0: 0d0a 2020 2020 2020 2020 2020 2020 6d61  ..            ma
-000191c0: 736b 5f6d 6174 7269 7820 3d20 7468 6561  sk_matrix = thea
-000191d0: 6e6f 2e70 7269 6e74 696e 672e 5072 696e  no.printing.Prin
-000191e0: 7428 276d 6173 6b5f 6d61 7472 6978 5f6c  t('mask_matrix_l
-000191f0: 6f6f 7027 2928 6d61 736b 5f6d 6174 7269  oop')(mask_matri
-00019200: 7829 0d0a 0d0a 2020 2020 2020 2020 2320  x)....        # 
-00019210: 4641 554c 5420 4d41 534b 0d0a 2020 2020  FAULT MASK..    
-00019220: 2020 2020 2320 5468 6973 2063 7265 6174      # This creat
-00019230: 6573 2061 206d 6174 7269 7820 7769 7468  es a matrix with
-00019240: 2054 7275 6573 2069 6e20 7468 6520 706f   Trues in the po
-00019250: 7369 7469 7665 2073 6964 6520 6f66 2074  sitive side of t
-00019260: 6865 2066 6175 6c74 732e 2057 6865 6e20  he faults. When 
-00019270: 6973 206e 6f74 2066 6175 6c74 7320 6973  is not faults is
-00019280: 2030 0d0a 0d0a 2020 2020 2020 2020 2320   0....        # 
-00019290: 5468 6973 2073 656c 6563 7420 7468 6520  This select the 
-000192a0: 696e 6469 6365 7320 7768 6572 6520 6973  indices where is
-000192b0: 2066 6175 6c74 2062 7574 2061 7265 206e   fault but are n
-000192c0: 6f74 206f 6666 7365 7474 696e 670d 0a20  ot offsetting.. 
-000192d0: 2020 2020 2020 2023 2054 4f44 4f20 6861         # TODO ha
-000192e0: 7669 6e67 2061 2062 6574 7465 7220 7761  ving a better wa
-000192f0: 7920 746f 2063 6f6e 7472 6f6c 2074 6865  y to control the
-00019300: 206e 756d 6265 7220 6f66 2073 6572 6965   number of serie
-00019310: 7320 7468 616e 2069 735f 6572 6f73 696f  s than is_erosio
-00019320: 6e0d 0a20 2020 2020 2020 2069 6478 5f65  n..        idx_e
-00019330: 203d 2028 7365 6c66 2e69 735f 6661 756c   = (self.is_faul
-00019340: 7420 2a20 7e54 2e63 6173 7428 6661 756c  t * ~T.cast(faul
-00019350: 7473 5f72 656c 6174 696f 6e5f 6f70 2c20  ts_relation_op, 
-00019360: 2762 6f6f 6c27 2929 5b0d 0a20 2020 2020  'bool'))[..     
-00019370: 2020 2020 2020 2020 2020 203a 7365 6c66             :self
-00019380: 2e69 735f 6572 6f73 696f 6e2e 7368 6170  .is_erosion.shap
-00019390: 655b 305d 5d0d 0a20 2020 2020 2020 2069  e[0]]..        i
-000193a0: 6478 5f6f 203d 2028 7365 6c66 2e69 735f  dx_o = (self.is_
-000193b0: 6661 756c 7420 2a20 7e54 2e63 6173 7428  fault * ~T.cast(
-000193c0: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
-000193d0: 6c66 2e66 6175 6c74 5f72 656c 6174 696f  lf.fault_relatio
-000193e0: 6e5b 3a2c 2054 2e63 6173 7428 6e5f 7365  n[:, T.cast(n_se
-000193f0: 7269 6573 202d 2031 2c20 2769 6e74 3827  ries - 1, 'int8'
-00019400: 295d 2c20 2762 6f6f 6c27 2929 5b0d 0a20  )], 'bool'))[.. 
-00019410: 2020 2020 2020 2020 2020 2020 2020 203a                 :
-00019420: 7365 6c66 2e69 735f 6572 6f73 696f 6e2e  self.is_erosion.
-00019430: 7368 6170 655b 305d 5d0d 0a0d 0a20 2020  shape[0]]....   
-00019440: 2020 2020 206d 6173 6b5f 6d61 7472 6978       mask_matrix
-00019450: 5f66 203d 2054 2e73 6574 5f73 7562 7465  _f = T.set_subte
-00019460: 6e73 6f72 280d 0a20 2020 2020 2020 2020  nsor(..         
-00019470: 2020 206d 6173 6b5f 6d61 7472 6978 5f66     mask_matrix_f
-00019480: 5b69 6478 5f65 2c20 7368 6966 743a 785f  [idx_e, shift:x_
-00019490: 746f 5f69 6e74 6572 706f 6c61 7465 5f73  to_interpolate_s
-000194a0: 6861 7065 202b 2073 6869 6674 5d2c 0d0a  hape + shift],..
-000194b0: 2020 2020 2020 2020 2020 2020 6d61 736b              mask
-000194c0: 5f65 202b 206d 6173 6b5f 6629 0d0a 2020  _e + mask_f)..  
-000194d0: 2020 2020 2020 2320 6d61 736b 5f6d 6174        # mask_mat
-000194e0: 7269 785f 6620 3d20 542e 7365 745f 7375  rix_f = T.set_su
-000194f0: 6274 656e 736f 7228 6d61 736b 5f6d 6174  btensor(mask_mat
-00019500: 7269 785f 665b 6964 785f 6f2c 203a 5d2c  rix_f[idx_o, :],
-00019510: 206d 6173 6b5f 6f20 2b20 6d61 736b 5f6d   mask_o + mask_m
-00019520: 6174 7269 785f 665b 6e5f 7365 7269 6573  atrix_f[n_series
-00019530: 2d31 5d29 0d0a 0d0a 2020 2020 2020 2020  -1])....        
-00019540: 2320 5363 616c 6172 2066 6965 6c64 2061  # Scalar field a
-00019550: 7420 696e 7465 7266 6163 6573 0d0a 2020  t interfaces..  
-00019560: 2020 2020 2020 7366 6169 203d 2054 2e73        sfai = T.s
-00019570: 6574 5f73 7562 7465 6e73 6f72 2873 6661  et_subtensor(sfa
-00019580: 695b 6e5f 7365 7269 6573 2c20 6e5f 7375  i[n_series, n_su
-00019590: 7266 6163 655f 6f70 202d 2031 5d2c 0d0a  rface_op - 1],..
-000195a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000195b0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-000195c0: 6361 6c61 725f 6669 656c 645f 6174 5f73  calar_field_at_s
-000195d0: 7572 6661 6365 5f70 6f69 6e74 7329 0d0a  urface_points)..
-000195e0: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-000195f0: 2062 6c6f 636b 5f6d 6174 7269 782c 2077   block_matrix, w
-00019600: 6569 6768 7473 5f76 6563 746f 722c 2073  eights_vector, s
-00019610: 6361 6c61 725f 6669 656c 645f 6d61 7472  calar_field_matr
-00019620: 6978 2c20 7366 6169 2c20 6d61 736b 5f6d  ix, sfai, mask_m
-00019630: 6174 7269 782c 205c 0d0a 2020 2020 2020  atrix, \..      
-00019640: 2020 2020 2020 2020 206d 6173 6b5f 6d61           mask_ma
-00019650: 7472 6978 5f66 2c20 6661 756c 745f 6d61  trix_f, fault_ma
-00019660: 7472 6978 2c20 6e73 6c65 0d0a 0d0a 2020  trix, nsle....  
-00019670: 2020 6465 6620 636f 6d70 7574 655f 666f    def compute_fo
-00019680: 7277 6172 645f 6772 6176 6974 7928 7365  rward_gravity(se
-00019690: 6c66 2c20 6465 6e73 6974 6965 733d 4e6f  lf, densities=No
-000196a0: 6e65 2c0d 0a20 2020 2020 2020 2020 2020  ne,..           
-000196b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000196c0: 2020 2020 2070 6f73 5f64 656e 7369 7479       pos_density
-000196d0: 3d4e 6f6e 6529 3a20 2023 2064 656e 7369  =None):  # densi
-000196e0: 7469 6573 2c20 747a 2c20 7365 6c65 6374  ties, tz, select
-000196f0: 2c0d 0a0d 0a20 2020 2020 2020 2061 7373  ,....        ass
-00019700: 6572 7420 706f 735f 6465 6e73 6974 7920  ert pos_density 
-00019710: 6973 206e 6f74 204e 6f6e 6520 6f72 2064  is not None or d
-00019720: 656e 7369 7469 6573 2069 7320 6e6f 7420  ensities is not 
-00019730: 4e6f 6e65 2c20 2749 6620 6120 6465 6e73  None, 'If a dens
-00019740: 6974 7920 626c 6f63 6b20 6973 206e 6f74  ity block is not
-00019750: 2070 6173 7365 642c 2079 6f75 206e 6565   passed, you nee
-00019760: 6420 746f 2720 5c0d 0a20 2020 2020 2020  d to' \..       
-00019770: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019790: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000197a0: 2020 2020 2020 2020 2020 2720 7370 6563            ' spec
-000197b0: 6966 7920 7768 6963 6820 696e 7465 7270  ify which interp
-000197c0: 6f6c 6174 6564 2076 616c 7565 2069 7320  olated value is 
-000197d0: 6465 6e73 6974 792e 2720 5c0d 0a20 2020  density.' \..   
-000197e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000197f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019810: 2020 2020 2020 2020 2020 2020 2020 2720                ' 
-00019820: 5365 6520 3a63 6c61 7373 3a60 5375 7266  See :class:`Surf
-00019830: 6163 6560 270d 0a0d 0a20 2020 2020 2020  ace`'....       
-00019840: 2069 6620 6465 6e73 6974 6965 7320 6973   if densities is
-00019850: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
-00019860: 2020 2020 6669 6e61 6c5f 6d6f 6465 6c2c      final_model,
-00019870: 206e 6577 5f62 6c6f 636b 2c20 6e65 775f   new_block, new_
-00019880: 7765 6967 6874 732c 206e 6577 5f73 6361  weights, new_sca
-00019890: 6c61 722c 206e 6577 5f73 6661 692c 206e  lar, new_sfai, n
-000198a0: 6577 5f6d 6173 6b20 3d20 7365 6c66 2e63  ew_mask = self.c
-000198b0: 6f6d 7075 7465 5f73 6572 6965 7328 290d  ompute_series().
-000198c0: 0a20 2020 2020 2020 2020 2020 2064 656e  .            den
-000198d0: 7369 7469 6573 203d 2066 696e 616c 5f6d  sities = final_m
-000198e0: 6f64 656c 5b70 6f73 5f64 656e 7369 7479  odel[pos_density
-000198f0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00019900: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00019910: 6c67 303a 7365 6c66 2e6c 6731 5d20 2023  lg0:self.lg1]  #
-00019920: 202d 2032 202a 2073 656c 662e 6c65 6e5f   - 2 * self.len_
-00019930: 706f 696e 7473 5d0d 0a20 2020 2020 2020  points]..       
-00019940: 2065 6c73 653a 0d0a 2020 2020 2020 2020   else:..        
-00019950: 2020 2020 6669 6e61 6c5f 6d6f 6465 6c2c      final_model,
-00019960: 206e 6577 5f62 6c6f 636b 2c20 6e65 775f   new_block, new_
-00019970: 7765 6967 6874 732c 206e 6577 5f73 6361  weights, new_sca
-00019980: 6c61 722c 206e 6577 5f73 6661 692c 206e  lar, new_sfai, n
-00019990: 6577 5f6d 6173 6b20 3d20 4e6f 6e65 2c20  ew_mask = None, 
-000199a0: 4e6f 6e65 2c20 4e6f 6e65 2c20 4e6f 6e65  None, None, None
-000199b0: 2c20 4e6f 6e65 2c20 4e6f 6e65 0d0a 0d0a  , None, None....
-000199c0: 2020 2020 2020 2020 6966 2027 6465 6e73          if 'dens
-000199d0: 6974 6965 7327 2069 6e20 7365 6c66 2e76  ities' in self.v
-000199e0: 6572 626f 7365 3a0d 0a20 2020 2020 2020  erbose:..       
-000199f0: 2020 2020 2064 656e 7369 7469 6573 203d       densities =
-00019a00: 2074 6865 616e 6f2e 7072 696e 7469 6e67   theano.printing
-00019a10: 2e50 7269 6e74 2827 6465 6e73 6974 7927  .Print('density'
-00019a20: 2928 6465 6e73 6974 6965 7329 0d0a 0d0a  )(densities)....
-00019a30: 2020 2020 2020 2020 6e5f 6465 7669 6365          n_device
-00019a40: 7320 3d20 542e 6361 7374 2828 6465 6e73  s = T.cast((dens
-00019a50: 6974 6965 732e 7368 6170 655b 305d 202f  ities.shape[0] /
-00019a60: 2073 656c 662e 747a 2e73 6861 7065 5b30   self.tz.shape[0
-00019a70: 5d29 2c20 6474 7970 653d 2769 6e74 3332  ]), dtype='int32
-00019a80: 2729 0d0a 0d0a 2020 2020 2020 2020 6966  ')....        if
-00019a90: 2027 6772 6176 5f64 6576 6963 6573 2720   'grav_devices' 
-00019aa0: 696e 2073 656c 662e 7665 7262 6f73 653a  in self.verbose:
-00019ab0: 0d0a 2020 2020 2020 2020 2020 2020 6e5f  ..            n_
-00019ac0: 6465 7669 6365 7320 3d20 7468 6561 6e6f  devices = theano
-00019ad0: 2e70 7269 6e74 696e 672e 5072 696e 7428  .printing.Print(
-00019ae0: 276e 5f64 6576 6963 6573 2729 286e 5f64  'n_devices')(n_d
-00019af0: 6576 6963 6573 290d 0a0d 0a20 2020 2020  evices)....     
-00019b00: 2020 2074 7a5f 7265 7020 3d20 542e 7469     tz_rep = T.ti
-00019b10: 6c65 2873 656c 662e 747a 2c20 6e5f 6465  le(self.tz, n_de
-00019b20: 7669 6365 7329 0d0a 0d0a 2020 2020 2020  vices)....      
-00019b30: 2020 2320 6465 6e73 6974 7920 7469 6d65    # density time
-00019b40: 7320 7468 6520 636f 6d70 6f6e 656e 7420  s the component 
-00019b50: 7a20 6f66 2067 7261 7669 7479 0d0a 2020  z of gravity..  
-00019b60: 2020 2020 2020 6772 6176 203d 2028 6465        grav = (de
-00019b70: 6e73 6974 6965 7320 2a20 747a 5f72 6570  nsities * tz_rep
-00019b80: 292e 7265 7368 6170 6528 286e 5f64 6576  ).reshape((n_dev
-00019b90: 6963 6573 2c20 2d31 2929 2e73 756d 2861  ices, -1)).sum(a
-00019ba0: 7869 733d 3129 0d0a 0d0a 2020 2020 2020  xis=1)....      
-00019bb0: 2020 7265 7475 726e 2066 696e 616c 5f6d    return final_m
-00019bc0: 6f64 656c 2c20 6e65 775f 626c 6f63 6b2c  odel, new_block,
-00019bd0: 206e 6577 5f77 6569 6768 7473 2c20 6e65   new_weights, ne
-00019be0: 775f 7363 616c 6172 2c20 6e65 775f 7366  w_scalar, new_sf
-00019bf0: 6169 2c20 6e65 775f 6d61 736b 2c20 6772  ai, new_mask, gr
-00019c00: 6176 2020 2320 2c20 6d6f 6465 6c5f 736f  av  # , model_so
-00019c10: 6c2e 6170 7065 6e64 2867 7261 7629 0d0a  l.append(grav)..
-00019c20: 0d0a 2020 2020 6465 6620 636f 6d70 7574  ..    def comput
-00019c30: 655f 666f 7277 6172 645f 6772 6176 6974  e_forward_gravit
-00019c40: 795f 7072 6f28 7365 6c66 2c20 6465 6e73  y_pro(self, dens
-00019c50: 6974 6965 733d 4e6f 6e65 293a 2020 2320  ities=None):  # 
-00019c60: 6465 6e73 6974 6965 732c 2074 7a2c 2073  densities, tz, s
-00019c70: 656c 6563 742c 0d0a 0d0a 2020 2020 2020  elect,....      
-00019c80: 2020 6966 2027 6465 6e73 6974 6965 7327    if 'densities'
-00019c90: 2069 6e20 7365 6c66 2e76 6572 626f 7365   in self.verbose
-00019ca0: 3a0d 0a20 2020 2020 2020 2020 2020 2064  :..            d
-00019cb0: 656e 7369 7469 6573 203d 2074 6865 616e  ensities = thean
-00019cc0: 6f2e 7072 696e 7469 6e67 2e50 7269 6e74  o.printing.Print
-00019cd0: 2827 6465 6e73 6974 7927 2928 6465 6e73  ('density')(dens
-00019ce0: 6974 6965 7329 0d0a 0d0a 2020 2020 2020  ities)....      
-00019cf0: 2020 6e5f 6465 7669 6365 7320 3d20 542e    n_devices = T.
-00019d00: 6361 7374 2828 6465 6e73 6974 6965 732e  cast((densities.
-00019d10: 7368 6170 655b 305d 202f 2073 656c 662e  shape[0] / self.
-00019d20: 747a 2e73 6861 7065 5b30 5d29 2c20 6474  tz.shape[0]), dt
-00019d30: 7970 653d 2769 6e74 3332 2729 0d0a 0d0a  ype='int32')....
-00019d40: 2020 2020 2020 2020 6966 2027 6772 6176          if 'grav
-00019d50: 5f64 6576 6963 6573 2720 696e 2073 656c  _devices' in sel
-00019d60: 662e 7665 7262 6f73 653a 0d0a 2020 2020  f.verbose:..    
-00019d70: 2020 2020 2020 2020 6e5f 6465 7669 6365          n_device
-00019d80: 7320 3d20 7468 6561 6e6f 2e70 7269 6e74  s = theano.print
-00019d90: 696e 672e 5072 696e 7428 276e 5f64 6576  ing.Print('n_dev
-00019da0: 6963 6573 2729 286e 5f64 6576 6963 6573  ices')(n_devices
-00019db0: 290d 0a0d 0a20 2020 2020 2020 2074 7a5f  )....        tz_
-00019dc0: 7265 7020 3d20 542e 7469 6c65 2873 656c  rep = T.tile(sel
-00019dd0: 662e 747a 2c20 6e5f 6465 7669 6365 7329  f.tz, n_devices)
-00019de0: 0d0a 0d0a 2020 2020 2020 2020 2320 6465  ....        # de
-00019df0: 6e73 6974 7920 7469 6d65 7320 7468 6520  nsity times the 
-00019e00: 636f 6d70 6f6e 656e 7420 7a20 6f66 2067  component z of g
-00019e10: 7261 7669 7479 0d0a 2020 2020 2020 2020  ravity..        
-00019e20: 6772 6176 203d 2028 6465 6e73 6974 6965  grav = (densitie
-00019e30: 7320 2a20 747a 5f72 6570 292e 7265 7368  s * tz_rep).resh
-00019e40: 6170 6528 286e 5f64 6576 6963 6573 2c20  ape((n_devices, 
-00019e50: 2d31 2929 2e73 756d 2861 7869 733d 3129  -1)).sum(axis=1)
-00019e60: 0d0a 0d0a 2020 2020 2020 2020 7265 7475  ....        retu
-00019e70: 726e 2067 7261 760d 0a0d 0a20 2020 2064  rn grav....    d
-00019e80: 6566 2063 6f6d 7075 7465 5f66 6f72 7761  ef compute_forwa
-00019e90: 7264 5f6d 6167 6e65 7469 6373 2873 656c  rd_magnetics(sel
-00019ea0: 662c 206b 5f76 616c 7329 3a0d 0a20 2020  f, k_vals):..   
-00019eb0: 2020 2020 2022 2222 0d0a 2020 2020 2020       """..      
-00019ec0: 2020 436f 6d70 7574 6520 6d61 676e 6574    Compute magnet
-00019ed0: 6963 730d 0a0d 0a20 2020 2020 2020 2041  ics....        A
-00019ee0: 7267 733a 0d0a 2020 2020 2020 2020 2020  rgs:..          
-00019ef0: 2020 6b5f 7661 6c73 3a20 5375 7363 6570    k_vals: Suscep
-00019f00: 7469 6269 6c69 7479 2076 616c 7565 7320  tibility values 
-00019f10: 7065 7220 766f 7865 6c20 5b2d 5d20 2d20  per voxel [-] - 
-00019f20: 7661 7269 6573 2070 6572 2064 6576 6963  varies per devic
-00019f30: 6521 2047 656d 5079 0d0a 0d0a 2020 2020  e! GemPy....    
-00019f40: 2020 2020 5265 7475 726e 733a 0d0a 0d0a      Returns:....
-00019f50: 2020 2020 2020 2020 2222 220d 0a0d 0a20          """.... 
-00019f60: 2020 2020 2020 2064 6566 206d 6167 6e65         def magne
-00019f70: 7469 635f 6469 7265 6374 696f 6e28 696e  tic_direction(in
-00019f80: 636c 2c20 6465 636c 293a 0d0a 2020 2020  cl, decl):..    
-00019f90: 2020 2020 2020 2020 696e 636c 5f72 6164          incl_rad
-00019fa0: 203d 2069 6e63 6c20 2a20 332e 3134 3135   = incl * 3.1415
-00019fb0: 3932 3635 3335 3920 2f20 3138 302e 2020  9265359 / 180.  
-00019fc0: 2320 6e70 2e64 6567 3272 6164 2869 6e63  # np.deg2rad(inc
-00019fd0: 6c29 0d0a 2020 2020 2020 2020 2020 2020  l)..            
-00019fe0: 6465 636c 5f72 6164 203d 2064 6563 6c20  decl_rad = decl 
-00019ff0: 2a20 332e 3134 3135 3932 3635 3335 3920  * 3.14159265359 
-0001a000: 2f20 3138 302e 2020 2320 6e70 2e64 6567  / 180.  # np.deg
-0001a010: 3272 6164 2864 6563 6c29 0d0a 2020 2020  2rad(decl)..    
-0001a020: 2020 2020 2020 2020 7820 3d20 542e 636f          x = T.co
-0001a030: 7328 696e 636c 5f72 6164 2920 2a20 542e  s(incl_rad) * T.
-0001a040: 636f 7328 6465 636c 5f72 6164 290d 0a20  cos(decl_rad).. 
-0001a050: 2020 2020 2020 2020 2020 2079 203d 2054             y = T
-0001a060: 2e63 6f73 2869 6e63 6c5f 7261 6429 202a  .cos(incl_rad) *
-0001a070: 2054 2e73 696e 2864 6563 6c5f 7261 6429   T.sin(decl_rad)
-0001a080: 0d0a 2020 2020 2020 2020 2020 2020 7a20  ..            z 
-0001a090: 3d20 542e 7369 6e28 696e 636c 5f72 6164  = T.sin(incl_rad
-0001a0a0: 290d 0a20 2020 2020 2020 2020 2020 2072  )..            r
-0001a0b0: 6574 7572 6e20 782c 2079 2c20 7a0d 0a0d  eturn x, y, z...
-0001a0c0: 0a20 2020 2020 2020 2069 6620 276d 6167  .        if 'mag
-0001a0d0: 6e65 7469 6373 2720 696e 2073 656c 662e  netics' in self.
-0001a0e0: 7665 7262 6f73 653a 0d0a 2020 2020 2020  verbose:..      
-0001a0f0: 2020 2020 2020 6b5f 7661 6c73 203d 2074        k_vals = t
-0001a100: 6865 616e 6f2e 7072 696e 7469 6e67 2e50  heano.printing.P
-0001a110: 7269 6e74 2827 5375 732e 2076 616c 7565  rint('Sus. value
-0001a120: 7327 2928 6b5f 7661 6c73 290d 0a0d 0a20  s')(k_vals).... 
-0001a130: 2020 2020 2020 2023 2067 6574 2069 6e64         # get ind
-0001a140: 7563 6564 206d 6167 6e65 7469 7361 7469  uced magnetisati
-0001a150: 6f6e 205b 545d 0d0a 2020 2020 2020 2020  on [T]..        
-0001a160: 4a20 3d20 6b5f 7661 6c73 202a 2073 656c  J = k_vals * sel
-0001a170: 662e 425f 6578 7420 2023 206b 5f76 616c  f.B_ext  # k_val
-0001a180: 7320 636f 6e74 6169 6e73 2073 7573 6365  s contains susce
-0001a190: 7074 6962 696c 6974 7920 7661 6c75 6573  ptibility values
-0001a1a0: 206f 6620 6561 6368 2076 6f78 656c 2066   of each voxel f
-0001a1b0: 6f72 2061 6c6c 2064 6576 6963 6573 3a20  or all devices: 
-0001a1c0: 5b6b 3164 6576 312c 2e2e 2c6b 6e64 6576  [k1dev1,..,kndev
-0001a1d0: 6e5d 0d0a 0d0a 2020 2020 2020 2020 2320  n]....        # 
-0001a1e0: 616e 6420 7468 6520 636f 6d70 6f6e 656e  and the componen
-0001a1f0: 7473 3a0d 0a20 2020 2020 2020 2064 6972  ts:..        dir
-0001a200: 5f78 2c20 6469 725f 792c 2064 6972 5f7a  _x, dir_y, dir_z
-0001a210: 203d 206d 6167 6e65 7469 635f 6469 7265   = magnetic_dire
-0001a220: 6374 696f 6e28 7365 6c66 2e69 6e63 6c2c  ction(self.incl,
-0001a230: 2073 656c 662e 6465 636c 290d 0a20 2020   self.decl)..   
-0001a240: 2020 2020 204a 7820 3d20 6469 725f 7820       Jx = dir_x 
-0001a250: 2a20 4a0d 0a20 2020 2020 2020 204a 7920  * J..        Jy 
-0001a260: 3d20 6469 725f 7920 2a20 4a0d 0a20 2020  = dir_y * J..   
-0001a270: 2020 2020 204a 7a20 3d20 6469 725f 7a20       Jz = dir_z 
-0001a280: 2a20 4a0d 0a0d 0a20 2020 2020 2020 206e  * J....        n
-0001a290: 5f64 6576 6963 6573 203d 2054 2e63 6173  _devices = T.cas
-0001a2a0: 7428 286b 5f76 616c 732e 7368 6170 655b  t((k_vals.shape[
-0001a2b0: 305d 202f 2073 656c 662e 562e 7368 6170  0] / self.V.shap
-0001a2c0: 655b 315d 292c 2064 7479 7065 3d27 696e  e[1]), dtype='in
-0001a2d0: 7433 3227 290d 0a20 2020 2020 2020 2069  t32')..        i
-0001a2e0: 6620 276d 6167 5f64 6576 6963 6573 2720  f 'mag_devices' 
-0001a2f0: 696e 2073 656c 662e 7665 7262 6f73 653a  in self.verbose:
-0001a300: 0d0a 2020 2020 2020 2020 2020 2020 6e5f  ..            n_
-0001a310: 6465 7669 6365 7320 3d20 7468 6561 6e6f  devices = theano
-0001a320: 2e70 7269 6e74 696e 672e 5072 696e 7428  .printing.Print(
-0001a330: 276e 5f64 6576 6963 6573 2729 286e 5f64  'n_devices')(n_d
-0001a340: 6576 6963 6573 290d 0a0d 0a20 2020 2020  evices)....     
-0001a350: 2020 2056 203d 2054 2e74 696c 6528 7365     V = T.tile(se
-0001a360: 6c66 2e56 2c20 2831 2c20 6e5f 6465 7669  lf.V, (1, n_devi
-0001a370: 6365 7329 2920 2023 2072 6570 6561 7420  ces))  # repeat 
-0001a380: 666f 7220 6561 6368 2064 6576 6963 650d  for each device.
-0001a390: 0a0d 0a20 2020 2020 2020 2023 2064 6972  ...        # dir
-0001a3a0: 6563 7469 6f6e 616c 206d 6167 6e65 7469  ectional magneti
-0001a3b0: 6320 6566 6665 6374 206f 6e20 6f6e 6520  c effect on one 
-0001a3c0: 766f 7865 6c20 2833 2e31 3929 0d0a 2020  voxel (3.19)..  
-0001a3d0: 2020 2020 2020 5478 203d 2028 4a78 202a        Tx = (Jx *
-0001a3e0: 2056 5b30 2c20 3a5d 202b 204a 7920 2a20   V[0, :] + Jy * 
-0001a3f0: 565b 312c 203a 5d20 2b20 4a7a 202a 2056  V[1, :] + Jz * V
-0001a400: 5b32 2c20 3a5d 2920 2f20 2834 202a 2073  [2, :]) / (4 * s
-0001a410: 656c 662e 7069 290d 0a20 2020 2020 2020  elf.pi)..       
-0001a420: 2054 7920 3d20 284a 7820 2a20 565b 312c   Ty = (Jx * V[1,
-0001a430: 203a 5d20 2b20 4a79 202a 2056 5b33 2c20   :] + Jy * V[3, 
-0001a440: 3a5d 202b 204a 7a20 2a20 565b 342c 203a  :] + Jz * V[4, :
-0001a450: 5d29 202f 2028 3420 2a20 7365 6c66 2e70  ]) / (4 * self.p
-0001a460: 6929 0d0a 2020 2020 2020 2020 547a 203d  i)..        Tz =
-0001a470: 2028 4a78 202a 2056 5b32 2c20 3a5d 202b   (Jx * V[2, :] +
-0001a480: 204a 7920 2a20 565b 342c 203a 5d20 2b20   Jy * V[4, :] + 
-0001a490: 4a7a 202a 2056 5b35 2c20 3a5d 2920 2f20  Jz * V[5, :]) / 
-0001a4a0: 2834 202a 2073 656c 662e 7069 290d 0a0d  (4 * self.pi)...
-0001a4b0: 0a20 2020 2020 2020 2054 326e 5420 3d20  .        T2nT = 
-0001a4c0: 3165 3920 2023 2074 6f20 6765 7420 7265  1e9  # to get re
-0001a4d0: 7375 6c74 2069 6e20 5b6e 545d 202d 2063  sult in [nT] - c
-0001a4e0: 6f6d 6d6f 6e20 666f 7220 6765 6f70 6879  ommon for geophy
-0001a4f0: 7369 6361 6c20 6170 706c 6963 6174 696f  sical applicatio
-0001a500: 6e73 0d0a 0d0a 2020 2020 2020 2020 5478  ns....        Tx
-0001a510: 203d 2028 542e 7375 6d28 5478 2e72 6573   = (T.sum(Tx.res
-0001a520: 6861 7065 2828 6e5f 6465 7669 6365 732c  hape((n_devices,
-0001a530: 202d 3129 292c 2061 7869 733d 3129 2920   -1)), axis=1)) 
-0001a540: 2a20 5432 6e54 0d0a 2020 2020 2020 2020  * T2nT..        
-0001a550: 5479 203d 2028 542e 7375 6d28 5479 2e72  Ty = (T.sum(Ty.r
-0001a560: 6573 6861 7065 2828 6e5f 6465 7669 6365  eshape((n_device
-0001a570: 732c 202d 3129 292c 2061 7869 733d 3129  s, -1)), axis=1)
-0001a580: 2920 2a20 5432 6e54 0d0a 2020 2020 2020  ) * T2nT..      
-0001a590: 2020 547a 203d 2028 542e 7375 6d28 547a    Tz = (T.sum(Tz
-0001a5a0: 2e72 6573 6861 7065 2828 6e5f 6465 7669  .reshape((n_devi
-0001a5b0: 6365 732c 202d 3129 292c 2061 7869 733d  ces, -1)), axis=
-0001a5c0: 3129 2920 2a20 5432 6e54 0d0a 0d0a 2020  1)) * T2nT....  
-0001a5d0: 2020 2020 2020 2320 2de2 809e 546f 7461        # -...Tota
-0001a5e0: 6c20 6669 656c 6420 6d61 676e 6574 6f6d  l field magnetom
-0001a5f0: 6574 6572 7320 6361 6e20 6d65 6173 7572  eters can measur
-0001a600: 6520 6f6e 6c79 2074 6861 7420 7061 7274  e only that part
-0001a610: 206f 6620 7468 6520 616e 6f6d 616c 6f75   of the anomalou
-0001a620: 7320 6669 656c 6420 7768 6963 6820 6973  s field which is
-0001a630: 2069 6e20 7468 6520 6469 7265 6374 696f   in the directio
-0001a640: 6e20 6f66 0d0a 2020 2020 2020 2020 2320  n of..        # 
-0001a650: 7468 6520 4561 7274 6873 206d 6169 6e20  the Earths main 
-0001a660: 6669 656c 64e2 809c 2028 5369 6d50 4547  field... (SimPEG
-0001a670: 2064 6f63 756d 656e 7461 7469 6f6e 2927   documentation)'
-0001a680: 0d0a 2020 2020 2020 2020 6454 203d 2054  ..        dT = T
-0001a690: 7820 2a20 6469 725f 7820 2b20 5479 202a  x * dir_x + Ty *
-0001a6a0: 2064 6972 5f79 202b 2054 7a20 2a20 6469   dir_y + Tz * di
-0001a6b0: 725f 7a0d 0a20 2020 2020 2020 2072 6574  r_z..        ret
-0001a6c0: 7572 6e20 6454 2020 2320 2c20 5478 2c20  urn dT  # , Tx, 
-0001a6d0: 5479 2c20 547a 0d0a                      Ty, Tz..
+00018920: 2020 2073 656c 662e 636f 6d70 7574 655f     self.compute_
+00018930: 666f 726d 6174 696f 6e5f 626c 6f63 6b28  formation_block(
+00018940: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00018950: 2020 2020 2020 2020 2020 5a5f 782c 2073            Z_x, s
+00018960: 6361 6c61 725f 6669 656c 645f 6174 5f73  calar_field_at_s
+00018970: 7572 6661 6365 5f70 6f69 6e74 732c 0d0a  urface_points,..
+00018980: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018990: 2020 2020 2020 2020 7365 6c66 2e76 616c          self.val
+000189a0: 7565 735f 7072 6f70 6572 7469 6573 5f6f  ues_properties_o
+000189b0: 705b 3a2c 0d0a 2020 2020 2020 2020 2020  p[:,..          
+000189c0: 2020 2020 2020 2020 2020 2020 2020 6e5f                n_
+000189d0: 666f 726d 5f70 6572 5f73 6572 6965 5f30  form_per_serie_0
+000189e0: 3a20 6e5f 666f 726d 5f70 6572 5f73 6572  : n_form_per_ser
+000189f0: 6965 5f31 202b 2031 5d29 0d0a 2020 2020  ie_1 + 1])..    
+00018a00: 2020 2020 2020 2020 2020 2020 292c 0d0a              ),..
+00018a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018a20: 626c 6f63 6b5f 6d61 7472 6978 5b6e 5f73  block_matrix[n_s
+00018a30: 6572 6965 732c 203a 5d0d 0a20 2020 2020  eries, :]..     
+00018a40: 2020 2020 2020 2029 0d0a 2020 2020 2020         )..      
+00018a50: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
+00018a60: 2020 2020 2062 6c6f 636b 203d 2074 6966       block = tif
+00018a70: 2e69 6665 6c73 6528 636f 6d70 7574 655f  .ifelse(compute_
+00018a80: 626c 6f63 6b5f 6374 722c 0d0a 2020 2020  block_ctr,..    
+00018a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018aa0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00018ab0: 636f 6d70 7574 655f 666f 726d 6174 696f  compute_formatio
+00018ac0: 6e5f 626c 6f63 6b28 0d0a 2020 2020 2020  n_block(..      
+00018ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018ae0: 2020 2020 2020 2020 2020 2020 205a 5f78               Z_x
+00018af0: 2c20 7363 616c 6172 5f66 6965 6c64 5f61  , scalar_field_a
+00018b00: 745f 7375 7266 6163 655f 706f 696e 7473  t_surface_points
+00018b10: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00018b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018b30: 2020 2020 2020 7365 6c66 2e76 616c 7565        self.value
+00018b40: 735f 7072 6f70 6572 7469 6573 5f6f 705b  s_properties_op[
+00018b50: 3a2c 0d0a 2020 2020 2020 2020 2020 2020  :,..            
+00018b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018b70: 2020 2020 2020 206e 5f66 6f72 6d5f 7065         n_form_pe
+00018b80: 725f 7365 7269 655f 303a 206e 5f66 6f72  r_serie_0: n_for
+00018b90: 6d5f 7065 725f 7365 7269 655f 3120 2b20  m_per_serie_1 + 
+00018ba0: 315d 292c 0d0a 2020 2020 2020 2020 2020  1]),..          
+00018bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018bc0: 2020 2020 2062 6c6f 636b 5f6d 6174 7269       block_matri
+00018bd0: 785b 6e5f 7365 7269 6573 2c20 3a5d 0d0a  x[n_series, :]..
+00018be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018bf0: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+00018c00: 0d0a 0d0a 2020 2020 2020 2020 7765 6967  ....        weig
+00018c10: 6874 735f 7665 6374 6f72 203d 2054 2e73  hts_vector = T.s
+00018c20: 6574 5f73 7562 7465 6e73 6f72 2877 6569  et_subtensor(wei
+00018c30: 6768 7473 5f76 6563 746f 725b 6c65 6e5f  ghts_vector[len_
+00018c40: 775f 303a 6c65 6e5f 775f 315d 2c20 7765  w_0:len_w_1], we
+00018c50: 6967 6874 7329 0d0a 2020 2020 2020 2020  ights)..        
+00018c60: 7363 616c 6172 5f66 6965 6c64 5f6d 6174  scalar_field_mat
+00018c70: 7269 7820 3d20 542e 7365 745f 7375 6274  rix = T.set_subt
+00018c80: 656e 736f 7228 0d0a 2020 2020 2020 2020  ensor(..        
+00018c90: 2020 2020 7363 616c 6172 5f66 6965 6c64      scalar_field
+00018ca0: 5f6d 6174 7269 785b 6e5f 7365 7269 6573  _matrix[n_series
+00018cb0: 2c20 7368 6966 743a 785f 746f 5f69 6e74  , shift:x_to_int
+00018cc0: 6572 706f 6c61 7465 5f73 6861 7065 202b  erpolate_shape +
+00018cd0: 2073 6869 6674 5d2c 205a 5f78 290d 0a20   shift], Z_x).. 
+00018ce0: 2020 2020 2020 2062 6c6f 636b 5f6d 6174         block_mat
+00018cf0: 7269 7820 3d20 542e 7365 745f 7375 6274  rix = T.set_subt
+00018d00: 656e 736f 7228 0d0a 2020 2020 2020 2020  ensor(..        
+00018d10: 2020 2020 626c 6f63 6b5f 6d61 7472 6978      block_matrix
+00018d20: 5b6e 5f73 6572 6965 732c 203a 2c20 7368  [n_series, :, sh
+00018d30: 6966 743a 785f 746f 5f69 6e74 6572 706f  ift:x_to_interpo
+00018d40: 6c61 7465 5f73 6861 7065 202b 2073 6869  late_shape + shi
+00018d50: 6674 5d2c 2062 6c6f 636b 290d 0a20 2020  ft], block)..   
+00018d60: 2020 2020 2066 6175 6c74 5f6d 6174 7269       fault_matri
+00018d70: 7820 3d20 542e 7365 745f 7375 6274 656e  x = T.set_subten
+00018d80: 736f 7228 0d0a 2020 2020 2020 2020 2020  sor(..          
+00018d90: 2020 6661 756c 745f 6d61 7472 6978 5b6e    fault_matrix[n
+00018da0: 5f73 6572 6965 732c 203a 2c20 7368 6966  _series, :, shif
+00018db0: 743a 785f 746f 5f69 6e74 6572 706f 6c61  t:x_to_interpola
+00018dc0: 7465 5f73 6861 7065 202b 2073 6869 6674  te_shape + shift
+00018dd0: 5d2c 2062 6c6f 636b 290d 0a0d 0a20 2020  ], block)....   
+00018de0: 2020 2020 2023 204c 4954 4820 4d41 534b       # LITH MASK
+00018df0: 0d0a 2020 2020 2020 2020 6d61 736b 5f6d  ..        mask_m
+00018e00: 6174 7269 7820 3d20 542e 7365 745f 7375  atrix = T.set_su
+00018e10: 6274 656e 736f 7228 0d0a 2020 2020 2020  btensor(..      
+00018e20: 2020 2020 2020 783d 6d61 736b 5f6d 6174        x=mask_mat
+00018e30: 7269 785b 6e5f 7365 7269 6573 202d 2031  rix[n_series - 1
+00018e40: 3a20 6e5f 7365 7269 6573 2c20 7368 6966  : n_series, shif
+00018e50: 743a 785f 746f 5f69 6e74 6572 706f 6c61  t:x_to_interpola
+00018e60: 7465 5f73 6861 7065 202b 2073 6869 6674  te_shape + shift
+00018e70: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+00018e80: 793d 6d61 736b 5f6f 0d0a 2020 2020 2020  y=mask_o..      
+00018e90: 2020 290d 0a0d 0a20 2020 2020 2020 206d    )....        m
+00018ea0: 6173 6b5f 6d61 7472 6978 203d 2054 2e73  ask_matrix = T.s
+00018eb0: 6574 5f73 7562 7465 6e73 6f72 280d 0a20  et_subtensor(.. 
+00018ec0: 2020 2020 2020 2020 2020 2078 3d6d 6173             x=mas
+00018ed0: 6b5f 6d61 7472 6978 5b6e 5f73 6572 6965  k_matrix[n_serie
+00018ee0: 7320 2d20 6e73 6c65 5f6f 703a 206e 5f73  s - nsle_op: n_s
+00018ef0: 6572 6965 732c 2073 6869 6674 3a78 5f74  eries, shift:x_t
+00018f00: 6f5f 696e 7465 7270 6f6c 6174 655f 7368  o_interpolate_sh
+00018f10: 6170 6520 2b20 7368 6966 745d 2c0d 0a20  ape + shift],.. 
+00018f20: 2020 2020 2020 2020 2020 2079 3d54 2e63             y=T.c
+00018f30: 756d 7072 6f64 286d 6173 6b5f 6d61 7472  umprod(mask_matr
+00018f40: 6978 5b6e 5f73 6572 6965 7320 2d20 6e73  ix[n_series - ns
+00018f50: 6c65 5f6f 703a 206e 5f73 6572 6965 732c  le_op: n_series,
+00018f60: 2073 6869 6674 3a78 5f74 6f5f 696e 7465   shift:x_to_inte
+00018f70: 7270 6f6c 6174 655f 7368 6170 6520 2b20  rpolate_shape + 
+00018f80: 7368 6966 745d 5b3a 3a2d 315d 2c20 6178  shift][::-1], ax
+00018f90: 6973 3d30 295b 3a3a 2d31 5d0d 0a20 2020  is=0)[::-1]..   
+00018fa0: 2020 2020 2029 0d0a 0d0a 2020 2020 2020       )....      
+00018fb0: 2020 6d61 736b 5f6d 6174 7269 7820 3d20    mask_matrix = 
+00018fc0: 542e 7365 745f 7375 6274 656e 736f 7228  T.set_subtensor(
+00018fd0: 206d 6173 6b5f 6d61 7472 6978 5b6e 5f73   mask_matrix[n_s
+00018fe0: 6572 6965 732c 2073 6869 6674 3a78 5f74  eries, shift:x_t
+00018ff0: 6f5f 696e 7465 7270 6f6c 6174 655f 7368  o_interpolate_sh
+00019000: 6170 6520 2b20 7368 6966 745d 2c20 6d61  ape + shift], ma
+00019010: 736b 5f65 290d 0a0d 0a20 2020 2020 2020  sk_e)....       
+00019020: 2069 6620 276d 6173 6b5f 6d61 7472 6978   if 'mask_matrix
+00019030: 5f6c 6f6f 7027 2069 6e20 7365 6c66 2e76  _loop' in self.v
+00019040: 6572 626f 7365 3a0d 0a20 2020 2020 2020  erbose:..       
+00019050: 2020 2020 206d 6173 6b5f 6d61 7472 6978       mask_matrix
+00019060: 203d 2061 6573 6172 612e 7072 696e 7469   = aesara.printi
+00019070: 6e67 2e50 7269 6e74 2827 6d61 736b 5f6d  ng.Print('mask_m
+00019080: 6174 7269 785f 6c6f 6f70 2729 286d 6173  atrix_loop')(mas
+00019090: 6b5f 6d61 7472 6978 290d 0a0d 0a20 2020  k_matrix)....   
+000190a0: 2020 2020 2023 2046 4155 4c54 204d 4153       # FAULT MAS
+000190b0: 4b0d 0a20 2020 2020 2020 2023 2054 6869  K..        # Thi
+000190c0: 7320 6372 6561 7465 7320 6120 6d61 7472  s creates a matr
+000190d0: 6978 2077 6974 6820 5472 7565 7320 696e  ix with Trues in
+000190e0: 2074 6865 2070 6f73 6974 6976 6520 7369   the positive si
+000190f0: 6465 206f 6620 7468 6520 6661 756c 7473  de of the faults
+00019100: 2e20 5768 656e 2069 7320 6e6f 7420 6661  . When is not fa
+00019110: 756c 7473 2069 7320 300d 0a0d 0a20 2020  ults is 0....   
+00019120: 2020 2020 2023 2054 6869 7320 7365 6c65       # This sele
+00019130: 6374 2074 6865 2069 6e64 6963 6573 2077  ct the indices w
+00019140: 6865 7265 2069 7320 6661 756c 7420 6275  here is fault bu
+00019150: 7420 6172 6520 6e6f 7420 6f66 6673 6574  t are not offset
+00019160: 7469 6e67 0d0a 2020 2020 2020 2020 2320  ting..        # 
+00019170: 544f 444f 2068 6176 696e 6720 6120 6265  TODO having a be
+00019180: 7474 6572 2077 6179 2074 6f20 636f 6e74  tter way to cont
+00019190: 726f 6c20 7468 6520 6e75 6d62 6572 206f  rol the number o
+000191a0: 6620 7365 7269 6573 2074 6861 6e20 6973  f series than is
+000191b0: 5f65 726f 7369 6f6e 0d0a 2020 2020 2020  _erosion..      
+000191c0: 2020 6964 785f 6520 3d20 2873 656c 662e    idx_e = (self.
+000191d0: 6973 5f66 6175 6c74 202a 207e 542e 6361  is_fault * ~T.ca
+000191e0: 7374 2866 6175 6c74 735f 7265 6c61 7469  st(faults_relati
+000191f0: 6f6e 5f6f 702c 2027 626f 6f6c 2729 295b  on_op, 'bool'))[
+00019200: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00019210: 2020 3a73 656c 662e 6973 5f65 726f 7369    :self.is_erosi
+00019220: 6f6e 2e73 6861 7065 5b30 5d5d 0d0a 2020  on.shape[0]]..  
+00019230: 2020 2020 2020 6964 785f 6f20 3d20 2873        idx_o = (s
+00019240: 656c 662e 6973 5f66 6175 6c74 202a 207e  elf.is_fault * ~
+00019250: 542e 6361 7374 280d 0a20 2020 2020 2020  T.cast(..       
+00019260: 2020 2020 2073 656c 662e 6661 756c 745f       self.fault_
+00019270: 7265 6c61 7469 6f6e 5b3a 2c20 542e 6361  relation[:, T.ca
+00019280: 7374 286e 5f73 6572 6965 7320 2d20 312c  st(n_series - 1,
+00019290: 2027 696e 7438 2729 5d2c 2027 626f 6f6c   'int8')], 'bool
+000192a0: 2729 295b 0d0a 2020 2020 2020 2020 2020  '))[..          
+000192b0: 2020 2020 2020 3a73 656c 662e 6973 5f65        :self.is_e
+000192c0: 726f 7369 6f6e 2e73 6861 7065 5b30 5d5d  rosion.shape[0]]
+000192d0: 0d0a 0d0a 2020 2020 2020 2020 6d61 736b  ....        mask
+000192e0: 5f6d 6174 7269 785f 6620 3d20 542e 7365  _matrix_f = T.se
+000192f0: 745f 7375 6274 656e 736f 7228 0d0a 2020  t_subtensor(..  
+00019300: 2020 2020 2020 2020 2020 6d61 736b 5f6d            mask_m
+00019310: 6174 7269 785f 665b 6964 785f 652c 2073  atrix_f[idx_e, s
+00019320: 6869 6674 3a78 5f74 6f5f 696e 7465 7270  hift:x_to_interp
+00019330: 6f6c 6174 655f 7368 6170 6520 2b20 7368  olate_shape + sh
+00019340: 6966 745d 2c0d 0a20 2020 2020 2020 2020  ift],..         
+00019350: 2020 206d 6173 6b5f 6520 2b20 6d61 736b     mask_e + mask
+00019360: 5f66 0d0a 2020 2020 2020 2020 290d 0a20  _f..        ).. 
+00019370: 2020 2020 2020 2023 206d 6173 6b5f 6d61         # mask_ma
+00019380: 7472 6978 5f66 203d 2054 2e73 6574 5f73  trix_f = T.set_s
+00019390: 7562 7465 6e73 6f72 286d 6173 6b5f 6d61  ubtensor(mask_ma
+000193a0: 7472 6978 5f66 5b69 6478 5f6f 2c20 3a5d  trix_f[idx_o, :]
+000193b0: 2c20 6d61 736b 5f6f 202b 206d 6173 6b5f  , mask_o + mask_
+000193c0: 6d61 7472 6978 5f66 5b6e 5f73 6572 6965  matrix_f[n_serie
+000193d0: 732d 315d 290d 0a0d 0a20 2020 2020 2020  s-1])....       
+000193e0: 2023 2053 6361 6c61 7220 6669 656c 6420   # Scalar field 
+000193f0: 6174 2069 6e74 6572 6661 6365 730d 0a20  at interfaces.. 
+00019400: 2020 2020 2020 2073 6661 6920 3d20 542e         sfai = T.
+00019410: 7365 745f 7375 6274 656e 736f 7228 7366  set_subtensor(sf
+00019420: 6169 5b6e 5f73 6572 6965 732c 206e 5f73  ai[n_series, n_s
+00019430: 7572 6661 6365 5f6f 7020 2d20 315d 2c0d  urface_op - 1],.
+00019440: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00019450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019460: 7363 616c 6172 5f66 6965 6c64 5f61 745f  scalar_field_at_
+00019470: 7375 7266 6163 655f 706f 696e 7473 290d  surface_points).
+00019480: 0a0d 0a20 2020 2020 2020 2072 6574 7572  ...        retur
+00019490: 6e20 626c 6f63 6b5f 6d61 7472 6978 2c20  n block_matrix, 
+000194a0: 7765 6967 6874 735f 7665 6374 6f72 2c20  weights_vector, 
+000194b0: 7363 616c 6172 5f66 6965 6c64 5f6d 6174  scalar_field_mat
+000194c0: 7269 782c 2073 6661 692c 206d 6173 6b5f  rix, sfai, mask_
+000194d0: 6d61 7472 6978 2c20 5c0d 0a20 2020 2020  matrix, \..     
+000194e0: 2020 2020 2020 206d 6173 6b5f 6d61 7472         mask_matr
+000194f0: 6978 5f66 2c20 6661 756c 745f 6d61 7472  ix_f, fault_matr
+00019500: 6978 2c20 6e73 6c65 0d0a 0d0a 2020 2020  ix, nsle....    
+00019510: 6465 6620 636f 6d70 7574 655f 666f 7277  def compute_forw
+00019520: 6172 645f 6772 6176 6974 7928 7365 6c66  ard_gravity(self
+00019530: 2c20 6465 6e73 6974 6965 733d 4e6f 6e65  , densities=None
+00019540: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00019550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019560: 2020 2070 6f73 5f64 656e 7369 7479 3d4e     pos_density=N
+00019570: 6f6e 6529 3a20 2023 2064 656e 7369 7469  one):  # densiti
+00019580: 6573 2c20 747a 2c20 7365 6c65 6374 2c0d  es, tz, select,.
+00019590: 0a0d 0a20 2020 2020 2020 2061 7373 6572  ...        asser
+000195a0: 7420 706f 735f 6465 6e73 6974 7920 6973  t pos_density is
+000195b0: 206e 6f74 204e 6f6e 6520 6f72 2064 656e   not None or den
+000195c0: 7369 7469 6573 2069 7320 6e6f 7420 4e6f  sities is not No
+000195d0: 6e65 2c20 2749 6620 6120 6465 6e73 6974  ne, 'If a densit
+000195e0: 7920 626c 6f63 6b20 6973 206e 6f74 2070  y block is not p
+000195f0: 6173 7365 642c 2079 6f75 206e 6565 6420  assed, you need 
+00019600: 746f 2720 5c0d 0a20 2020 2020 2020 2020  to' \..         
+00019610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019640: 2020 2020 2020 2020 2720 7370 6563 6966          ' specif
+00019650: 7920 7768 6963 6820 696e 7465 7270 6f6c  y which interpol
+00019660: 6174 6564 2076 616c 7565 2069 7320 6465  ated value is de
+00019670: 6e73 6974 792e 2720 5c0d 0a20 2020 2020  nsity.' \..     
+00019680: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019690: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000196a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000196b0: 2020 2020 2020 2020 2020 2020 2720 5365              ' Se
+000196c0: 6520 3a63 6c61 7373 3a60 5375 7266 6163  e :class:`Surfac
+000196d0: 6560 270d 0a0d 0a20 2020 2020 2020 2069  e`'....        i
+000196e0: 6620 6465 6e73 6974 6965 7320 6973 204e  f densities is N
+000196f0: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
+00019700: 2020 6669 6e61 6c5f 6d6f 6465 6c2c 206e    final_model, n
+00019710: 6577 5f62 6c6f 636b 2c20 6e65 775f 7765  ew_block, new_we
+00019720: 6967 6874 732c 206e 6577 5f73 6361 6c61  ights, new_scala
+00019730: 722c 206e 6577 5f73 6661 692c 206e 6577  r, new_sfai, new
+00019740: 5f6d 6173 6b20 3d20 7365 6c66 2e63 6f6d  _mask = self.com
+00019750: 7075 7465 5f73 6572 6965 7328 290d 0a20  pute_series().. 
+00019760: 2020 2020 2020 2020 2020 2064 656e 7369             densi
+00019770: 7469 6573 203d 2066 696e 616c 5f6d 6f64  ties = final_mod
+00019780: 656c 5b70 6f73 5f64 656e 7369 7479 2c0d  el[pos_density,.
+00019790: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000197a0: 2020 2020 2020 2020 2073 656c 662e 6c67           self.lg
+000197b0: 303a 7365 6c66 2e6c 6731 5d20 2023 202d  0:self.lg1]  # -
+000197c0: 2032 202a 2073 656c 662e 6c65 6e5f 706f   2 * self.len_po
+000197d0: 696e 7473 5d0d 0a20 2020 2020 2020 2065  ints]..        e
+000197e0: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
+000197f0: 2020 6669 6e61 6c5f 6d6f 6465 6c2c 206e    final_model, n
+00019800: 6577 5f62 6c6f 636b 2c20 6e65 775f 7765  ew_block, new_we
+00019810: 6967 6874 732c 206e 6577 5f73 6361 6c61  ights, new_scala
+00019820: 722c 206e 6577 5f73 6661 692c 206e 6577  r, new_sfai, new
+00019830: 5f6d 6173 6b20 3d20 4e6f 6e65 2c20 4e6f  _mask = None, No
+00019840: 6e65 2c20 4e6f 6e65 2c20 4e6f 6e65 2c20  ne, None, None, 
+00019850: 4e6f 6e65 2c20 4e6f 6e65 0d0a 0d0a 2020  None, None....  
+00019860: 2020 2020 2020 6966 2027 6465 6e73 6974        if 'densit
+00019870: 6965 7327 2069 6e20 7365 6c66 2e76 6572  ies' in self.ver
+00019880: 626f 7365 3a0d 0a20 2020 2020 2020 2020  bose:..         
+00019890: 2020 2064 656e 7369 7469 6573 203d 2061     densities = a
+000198a0: 6573 6172 612e 7072 696e 7469 6e67 2e50  esara.printing.P
+000198b0: 7269 6e74 2827 6465 6e73 6974 7927 2928  rint('density')(
+000198c0: 6465 6e73 6974 6965 7329 0d0a 0d0a 2020  densities)....  
+000198d0: 2020 2020 2020 6e5f 6465 7669 6365 7320        n_devices 
+000198e0: 3d20 542e 6361 7374 2828 6465 6e73 6974  = T.cast((densit
+000198f0: 6965 732e 7368 6170 655b 305d 202f 2073  ies.shape[0] / s
+00019900: 656c 662e 747a 2e73 6861 7065 5b30 5d29  elf.tz.shape[0])
+00019910: 2c20 6474 7970 653d 2769 6e74 3332 2729  , dtype='int32')
+00019920: 0d0a 0d0a 2020 2020 2020 2020 6966 2027  ....        if '
+00019930: 6772 6176 5f64 6576 6963 6573 2720 696e  grav_devices' in
+00019940: 2073 656c 662e 7665 7262 6f73 653a 0d0a   self.verbose:..
+00019950: 2020 2020 2020 2020 2020 2020 6e5f 6465              n_de
+00019960: 7669 6365 7320 3d20 6165 7361 7261 2e70  vices = aesara.p
+00019970: 7269 6e74 696e 672e 5072 696e 7428 276e  rinting.Print('n
+00019980: 5f64 6576 6963 6573 2729 286e 5f64 6576  _devices')(n_dev
+00019990: 6963 6573 290d 0a0d 0a20 2020 2020 2020  ices)....       
+000199a0: 2074 7a5f 7265 7020 3d20 542e 7469 6c65   tz_rep = T.tile
+000199b0: 2873 656c 662e 747a 2c20 6e5f 6465 7669  (self.tz, n_devi
+000199c0: 6365 7329 0d0a 0d0a 2020 2020 2020 2020  ces)....        
+000199d0: 2320 6465 6e73 6974 7920 7469 6d65 7320  # density times 
+000199e0: 7468 6520 636f 6d70 6f6e 656e 7420 7a20  the component z 
+000199f0: 6f66 2067 7261 7669 7479 0d0a 2020 2020  of gravity..    
+00019a00: 2020 2020 6772 6176 203d 2028 6465 6e73      grav = (dens
+00019a10: 6974 6965 7320 2a20 747a 5f72 6570 292e  ities * tz_rep).
+00019a20: 7265 7368 6170 6528 286e 5f64 6576 6963  reshape((n_devic
+00019a30: 6573 2c20 2d31 2929 2e73 756d 2861 7869  es, -1)).sum(axi
+00019a40: 733d 3129 0d0a 0d0a 2020 2020 2020 2020  s=1)....        
+00019a50: 7265 7475 726e 2066 696e 616c 5f6d 6f64  return final_mod
+00019a60: 656c 2c20 6e65 775f 626c 6f63 6b2c 206e  el, new_block, n
+00019a70: 6577 5f77 6569 6768 7473 2c20 6e65 775f  ew_weights, new_
+00019a80: 7363 616c 6172 2c20 6e65 775f 7366 6169  scalar, new_sfai
+00019a90: 2c20 6e65 775f 6d61 736b 2c20 6772 6176  , new_mask, grav
+00019aa0: 2020 2320 2c20 6d6f 6465 6c5f 736f 6c2e    # , model_sol.
+00019ab0: 6170 7065 6e64 2867 7261 7629 0d0a 0d0a  append(grav)....
+00019ac0: 2020 2020 6465 6620 636f 6d70 7574 655f      def compute_
+00019ad0: 666f 7277 6172 645f 6772 6176 6974 795f  forward_gravity_
+00019ae0: 7072 6f28 7365 6c66 2c20 6465 6e73 6974  pro(self, densit
+00019af0: 6965 733d 4e6f 6e65 293a 2020 2320 6465  ies=None):  # de
+00019b00: 6e73 6974 6965 732c 2074 7a2c 2073 656c  nsities, tz, sel
+00019b10: 6563 742c 0d0a 0d0a 2020 2020 2020 2020  ect,....        
+00019b20: 6966 2027 6465 6e73 6974 6965 7327 2069  if 'densities' i
+00019b30: 6e20 7365 6c66 2e76 6572 626f 7365 3a0d  n self.verbose:.
+00019b40: 0a20 2020 2020 2020 2020 2020 2064 656e  .            den
+00019b50: 7369 7469 6573 203d 2061 6573 6172 612e  sities = aesara.
+00019b60: 7072 696e 7469 6e67 2e50 7269 6e74 2827  printing.Print('
+00019b70: 6465 6e73 6974 7927 2928 6465 6e73 6974  density')(densit
+00019b80: 6965 7329 0d0a 0d0a 2020 2020 2020 2020  ies)....        
+00019b90: 6e5f 6465 7669 6365 7320 3d20 542e 6361  n_devices = T.ca
+00019ba0: 7374 2828 6465 6e73 6974 6965 732e 7368  st((densities.sh
+00019bb0: 6170 655b 305d 202f 2073 656c 662e 747a  ape[0] / self.tz
+00019bc0: 2e73 6861 7065 5b30 5d29 2c20 6474 7970  .shape[0]), dtyp
+00019bd0: 653d 2769 6e74 3332 2729 0d0a 0d0a 2020  e='int32')....  
+00019be0: 2020 2020 2020 6966 2027 6772 6176 5f64        if 'grav_d
+00019bf0: 6576 6963 6573 2720 696e 2073 656c 662e  evices' in self.
+00019c00: 7665 7262 6f73 653a 0d0a 2020 2020 2020  verbose:..      
+00019c10: 2020 2020 2020 6e5f 6465 7669 6365 7320        n_devices 
+00019c20: 3d20 6165 7361 7261 2e70 7269 6e74 696e  = aesara.printin
+00019c30: 672e 5072 696e 7428 276e 5f64 6576 6963  g.Print('n_devic
+00019c40: 6573 2729 286e 5f64 6576 6963 6573 290d  es')(n_devices).
+00019c50: 0a0d 0a20 2020 2020 2020 2074 7a5f 7265  ...        tz_re
+00019c60: 7020 3d20 542e 7469 6c65 2873 656c 662e  p = T.tile(self.
+00019c70: 747a 2c20 6e5f 6465 7669 6365 7329 0d0a  tz, n_devices)..
+00019c80: 0d0a 2020 2020 2020 2020 2320 6465 6e73  ..        # dens
+00019c90: 6974 7920 7469 6d65 7320 7468 6520 636f  ity times the co
+00019ca0: 6d70 6f6e 656e 7420 7a20 6f66 2067 7261  mponent z of gra
+00019cb0: 7669 7479 0d0a 2020 2020 2020 2020 6772  vity..        gr
+00019cc0: 6176 203d 2028 6465 6e73 6974 6965 7320  av = (densities 
+00019cd0: 2a20 747a 5f72 6570 292e 7265 7368 6170  * tz_rep).reshap
+00019ce0: 6528 286e 5f64 6576 6963 6573 2c20 2d31  e((n_devices, -1
+00019cf0: 2929 2e73 756d 2861 7869 733d 3129 0d0a  )).sum(axis=1)..
+00019d00: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+00019d10: 2067 7261 760d 0a0d 0a20 2020 2064 6566   grav....    def
+00019d20: 2063 6f6d 7075 7465 5f66 6f72 7761 7264   compute_forward
+00019d30: 5f6d 6167 6e65 7469 6373 2873 656c 662c  _magnetics(self,
+00019d40: 206b 5f76 616c 7329 3a0d 0a20 2020 2020   k_vals):..     
+00019d50: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
+00019d60: 436f 6d70 7574 6520 6d61 676e 6574 6963  Compute magnetic
+00019d70: 730d 0a0d 0a20 2020 2020 2020 2041 7267  s....        Arg
+00019d80: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
+00019d90: 6b5f 7661 6c73 3a20 5375 7363 6570 7469  k_vals: Suscepti
+00019da0: 6269 6c69 7479 2076 616c 7565 7320 7065  bility values pe
+00019db0: 7220 766f 7865 6c20 5b2d 5d20 2d20 7661  r voxel [-] - va
+00019dc0: 7269 6573 2070 6572 2064 6576 6963 6521  ries per device!
+00019dd0: 2047 656d 5079 0d0a 0d0a 2020 2020 2020   GemPy....      
+00019de0: 2020 5265 7475 726e 733a 0d0a 0d0a 2020    Returns:....  
+00019df0: 2020 2020 2020 2222 220d 0a0d 0a20 2020        """....   
+00019e00: 2020 2020 2064 6566 206d 6167 6e65 7469       def magneti
+00019e10: 635f 6469 7265 6374 696f 6e28 696e 636c  c_direction(incl
+00019e20: 2c20 6465 636c 293a 0d0a 2020 2020 2020  , decl):..      
+00019e30: 2020 2020 2020 696e 636c 5f72 6164 203d        incl_rad =
+00019e40: 2069 6e63 6c20 2a20 332e 3134 3135 3932   incl * 3.141592
+00019e50: 3635 3335 3920 2f20 3138 302e 2020 2320  65359 / 180.  # 
+00019e60: 6e70 2e64 6567 3272 6164 2869 6e63 6c29  np.deg2rad(incl)
+00019e70: 0d0a 2020 2020 2020 2020 2020 2020 6465  ..            de
+00019e80: 636c 5f72 6164 203d 2064 6563 6c20 2a20  cl_rad = decl * 
+00019e90: 332e 3134 3135 3932 3635 3335 3920 2f20  3.14159265359 / 
+00019ea0: 3138 302e 2020 2320 6e70 2e64 6567 3272  180.  # np.deg2r
+00019eb0: 6164 2864 6563 6c29 0d0a 2020 2020 2020  ad(decl)..      
+00019ec0: 2020 2020 2020 7820 3d20 542e 636f 7328        x = T.cos(
+00019ed0: 696e 636c 5f72 6164 2920 2a20 542e 636f  incl_rad) * T.co
+00019ee0: 7328 6465 636c 5f72 6164 290d 0a20 2020  s(decl_rad)..   
+00019ef0: 2020 2020 2020 2020 2079 203d 2054 2e63           y = T.c
+00019f00: 6f73 2869 6e63 6c5f 7261 6429 202a 2054  os(incl_rad) * T
+00019f10: 2e73 696e 2864 6563 6c5f 7261 6429 0d0a  .sin(decl_rad)..
+00019f20: 2020 2020 2020 2020 2020 2020 7a20 3d20              z = 
+00019f30: 542e 7369 6e28 696e 636c 5f72 6164 290d  T.sin(incl_rad).
+00019f40: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+00019f50: 7572 6e20 782c 2079 2c20 7a0d 0a0d 0a20  urn x, y, z.... 
+00019f60: 2020 2020 2020 2069 6620 276d 6167 6e65         if 'magne
+00019f70: 7469 6373 2720 696e 2073 656c 662e 7665  tics' in self.ve
+00019f80: 7262 6f73 653a 0d0a 2020 2020 2020 2020  rbose:..        
+00019f90: 2020 2020 6b5f 7661 6c73 203d 2061 6573      k_vals = aes
+00019fa0: 6172 612e 7072 696e 7469 6e67 2e50 7269  ara.printing.Pri
+00019fb0: 6e74 2827 5375 732e 2076 616c 7565 7327  nt('Sus. values'
+00019fc0: 2928 6b5f 7661 6c73 290d 0a0d 0a20 2020  )(k_vals)....   
+00019fd0: 2020 2020 2023 2067 6574 2069 6e64 7563       # get induc
+00019fe0: 6564 206d 6167 6e65 7469 7361 7469 6f6e  ed magnetisation
+00019ff0: 205b 545d 0d0a 2020 2020 2020 2020 4a20   [T]..        J 
+0001a000: 3d20 6b5f 7661 6c73 202a 2073 656c 662e  = k_vals * self.
+0001a010: 425f 6578 7420 2023 206b 5f76 616c 7320  B_ext  # k_vals 
+0001a020: 636f 6e74 6169 6e73 2073 7573 6365 7074  contains suscept
+0001a030: 6962 696c 6974 7920 7661 6c75 6573 206f  ibility values o
+0001a040: 6620 6561 6368 2076 6f78 656c 2066 6f72  f each voxel for
+0001a050: 2061 6c6c 2064 6576 6963 6573 3a20 5b6b   all devices: [k
+0001a060: 3164 6576 312c 2e2e 2c6b 6e64 6576 6e5d  1dev1,..,kndevn]
+0001a070: 0d0a 0d0a 2020 2020 2020 2020 2320 616e  ....        # an
+0001a080: 6420 7468 6520 636f 6d70 6f6e 656e 7473  d the components
+0001a090: 3a0d 0a20 2020 2020 2020 2064 6972 5f78  :..        dir_x
+0001a0a0: 2c20 6469 725f 792c 2064 6972 5f7a 203d  , dir_y, dir_z =
+0001a0b0: 206d 6167 6e65 7469 635f 6469 7265 6374   magnetic_direct
+0001a0c0: 696f 6e28 7365 6c66 2e69 6e63 6c2c 2073  ion(self.incl, s
+0001a0d0: 656c 662e 6465 636c 290d 0a20 2020 2020  elf.decl)..     
+0001a0e0: 2020 204a 7820 3d20 6469 725f 7820 2a20     Jx = dir_x * 
+0001a0f0: 4a0d 0a20 2020 2020 2020 204a 7920 3d20  J..        Jy = 
+0001a100: 6469 725f 7920 2a20 4a0d 0a20 2020 2020  dir_y * J..     
+0001a110: 2020 204a 7a20 3d20 6469 725f 7a20 2a20     Jz = dir_z * 
+0001a120: 4a0d 0a0d 0a20 2020 2020 2020 206e 5f64  J....        n_d
+0001a130: 6576 6963 6573 203d 2054 2e63 6173 7428  evices = T.cast(
+0001a140: 286b 5f76 616c 732e 7368 6170 655b 305d  (k_vals.shape[0]
+0001a150: 202f 2073 656c 662e 562e 7368 6170 655b   / self.V.shape[
+0001a160: 315d 292c 2064 7479 7065 3d27 696e 7433  1]), dtype='int3
+0001a170: 3227 290d 0a20 2020 2020 2020 2069 6620  2')..        if 
+0001a180: 276d 6167 5f64 6576 6963 6573 2720 696e  'mag_devices' in
+0001a190: 2073 656c 662e 7665 7262 6f73 653a 0d0a   self.verbose:..
+0001a1a0: 2020 2020 2020 2020 2020 2020 6e5f 6465              n_de
+0001a1b0: 7669 6365 7320 3d20 6165 7361 7261 2e70  vices = aesara.p
+0001a1c0: 7269 6e74 696e 672e 5072 696e 7428 276e  rinting.Print('n
+0001a1d0: 5f64 6576 6963 6573 2729 286e 5f64 6576  _devices')(n_dev
+0001a1e0: 6963 6573 290d 0a0d 0a20 2020 2020 2020  ices)....       
+0001a1f0: 2056 203d 2054 2e74 696c 6528 7365 6c66   V = T.tile(self
+0001a200: 2e56 2c20 2831 2c20 6e5f 6465 7669 6365  .V, (1, n_device
+0001a210: 7329 2920 2023 2072 6570 6561 7420 666f  s))  # repeat fo
+0001a220: 7220 6561 6368 2064 6576 6963 650d 0a0d  r each device...
+0001a230: 0a20 2020 2020 2020 2023 2064 6972 6563  .        # direc
+0001a240: 7469 6f6e 616c 206d 6167 6e65 7469 6320  tional magnetic 
+0001a250: 6566 6665 6374 206f 6e20 6f6e 6520 766f  effect on one vo
+0001a260: 7865 6c20 2833 2e31 3929 0d0a 2020 2020  xel (3.19)..    
+0001a270: 2020 2020 5478 203d 2028 4a78 202a 2056      Tx = (Jx * V
+0001a280: 5b30 2c20 3a5d 202b 204a 7920 2a20 565b  [0, :] + Jy * V[
+0001a290: 312c 203a 5d20 2b20 4a7a 202a 2056 5b32  1, :] + Jz * V[2
+0001a2a0: 2c20 3a5d 2920 2f20 2834 202a 2073 656c  , :]) / (4 * sel
+0001a2b0: 662e 7069 290d 0a20 2020 2020 2020 2054  f.pi)..        T
+0001a2c0: 7920 3d20 284a 7820 2a20 565b 312c 203a  y = (Jx * V[1, :
+0001a2d0: 5d20 2b20 4a79 202a 2056 5b33 2c20 3a5d  ] + Jy * V[3, :]
+0001a2e0: 202b 204a 7a20 2a20 565b 342c 203a 5d29   + Jz * V[4, :])
+0001a2f0: 202f 2028 3420 2a20 7365 6c66 2e70 6929   / (4 * self.pi)
+0001a300: 0d0a 2020 2020 2020 2020 547a 203d 2028  ..        Tz = (
+0001a310: 4a78 202a 2056 5b32 2c20 3a5d 202b 204a  Jx * V[2, :] + J
+0001a320: 7920 2a20 565b 342c 203a 5d20 2b20 4a7a  y * V[4, :] + Jz
+0001a330: 202a 2056 5b35 2c20 3a5d 2920 2f20 2834   * V[5, :]) / (4
+0001a340: 202a 2073 656c 662e 7069 290d 0a0d 0a20   * self.pi).... 
+0001a350: 2020 2020 2020 2054 326e 5420 3d20 3165         T2nT = 1e
+0001a360: 3920 2023 2074 6f20 6765 7420 7265 7375  9  # to get resu
+0001a370: 6c74 2069 6e20 5b6e 545d 202d 2063 6f6d  lt in [nT] - com
+0001a380: 6d6f 6e20 666f 7220 6765 6f70 6879 7369  mon for geophysi
+0001a390: 6361 6c20 6170 706c 6963 6174 696f 6e73  cal applications
+0001a3a0: 0d0a 0d0a 2020 2020 2020 2020 5478 203d  ....        Tx =
+0001a3b0: 2028 542e 7375 6d28 5478 2e72 6573 6861   (T.sum(Tx.resha
+0001a3c0: 7065 2828 6e5f 6465 7669 6365 732c 202d  pe((n_devices, -
+0001a3d0: 3129 292c 2061 7869 733d 3129 2920 2a20  1)), axis=1)) * 
+0001a3e0: 5432 6e54 0d0a 2020 2020 2020 2020 5479  T2nT..        Ty
+0001a3f0: 203d 2028 542e 7375 6d28 5479 2e72 6573   = (T.sum(Ty.res
+0001a400: 6861 7065 2828 6e5f 6465 7669 6365 732c  hape((n_devices,
+0001a410: 202d 3129 292c 2061 7869 733d 3129 2920   -1)), axis=1)) 
+0001a420: 2a20 5432 6e54 0d0a 2020 2020 2020 2020  * T2nT..        
+0001a430: 547a 203d 2028 542e 7375 6d28 547a 2e72  Tz = (T.sum(Tz.r
+0001a440: 6573 6861 7065 2828 6e5f 6465 7669 6365  eshape((n_device
+0001a450: 732c 202d 3129 292c 2061 7869 733d 3129  s, -1)), axis=1)
+0001a460: 2920 2a20 5432 6e54 0d0a 0d0a 2020 2020  ) * T2nT....    
+0001a470: 2020 2020 2320 2de2 809e 546f 7461 6c20      # -...Total 
+0001a480: 6669 656c 6420 6d61 676e 6574 6f6d 6574  field magnetomet
+0001a490: 6572 7320 6361 6e20 6d65 6173 7572 6520  ers can measure 
+0001a4a0: 6f6e 6c79 2074 6861 7420 7061 7274 206f  only that part o
+0001a4b0: 6620 7468 6520 616e 6f6d 616c 6f75 7320  f the anomalous 
+0001a4c0: 6669 656c 6420 7768 6963 6820 6973 2069  field which is i
+0001a4d0: 6e20 7468 6520 6469 7265 6374 696f 6e20  n the direction 
+0001a4e0: 6f66 0d0a 2020 2020 2020 2020 2320 7468  of..        # th
+0001a4f0: 6520 4561 7274 6873 206d 6169 6e20 6669  e Earths main fi
+0001a500: 656c 64e2 809c 2028 5369 6d50 4547 2064  eld... (SimPEG d
+0001a510: 6f63 756d 656e 7461 7469 6f6e 2927 0d0a  ocumentation)'..
+0001a520: 2020 2020 2020 2020 6454 203d 2054 7820          dT = Tx 
+0001a530: 2a20 6469 725f 7820 2b20 5479 202a 2064  * dir_x + Ty * d
+0001a540: 6972 5f79 202b 2054 7a20 2a20 6469 725f  ir_y + Tz * dir_
+0001a550: 7a0d 0a20 2020 2020 2020 2072 6574 7572  z..        retur
+0001a560: 6e20 6454 2020 2320 2c20 5478 2c20 5479  n dT  # , Tx, Ty
+0001a570: 2c20 547a 0d0a                           , Tz..
```

### Comparing `gempy-2.2b10.dev1/gempy/core/theano_modules/theano_kriging.py` & `gempy-2.3.0/gempy/core/aesara_modules/aesara_kriging.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,485 +1,485 @@
-import theano
-import theano.tensor as T
-import numpy as np
-import sys
-from .theano_graph import TheanoGeometry 
-
-
-class TheanoKriging(TheanoGeometry):
-    """
-    This class is used to help to divide the construction of the graph into sensical parts. All its methods buildDEP2 a part
-    of the graph. Every method can be seen as a branch and collection of branches until the last method that will be the
-    whole tree. Every part of the graph could be compiled separately but as we increase the complexity the input of each
-    of these methods is more and more difficult to provide (if you are in a branch close to the trunk you need all the
-    results of the branches above)
-    """
-    def __init__(self, output='geology', optimizer='fast_compile', verbose=[0], dtype='float32',
-                 is_fault=None, is_lith=None):
-        """
-        In the init we need to create all the symbolic parameters that are used in the process. Most of the variables
-        are shared parameters initialized with random values. At this stage we only care about the type and shape of the
-        parameters. After we have the graph built we can update the value of these shared parameters to our data (in the
-        interpolatorClass).
-
-        Args:
-            u_grade: grade of the drift to compile the right graph. I found out that we can make a graph that takes this
-            as variable so this argument will be deprecated soon
-            verbose (list): name of the nodes you want to print
-            dtype (str): type of float either 32 or 64
-        """
-        
-        super(TheanoKriging, self).__init__(output='geology', optimizer='fast_compile', verbose=[0], dtype='float32',
-                 is_fault=None, is_lith=None)
-        # Pass the verbose list as property
-
-        # Creation of symbolic parameters
-        # =============
-        # Constants
-        # =============
-
-
-
-
-        # # This is not accumulative
-        # self.number_of_points_per_surface_T = theano.shared(np.zeros(3, dtype='int32')) #TODO is DEP?
-        # self.number_of_points_per_surface_T_op = self.number_of_points_per_surface_T
-        # This is accumulative
-        #self.npf = theano.shared(np.zeros(3, dtype='int32'), 'Number of points per surface accumulative')
-        #self.npf_op = self.npf[[0, -2]]
-
-    def input_parameters_kriging(self):
-        """
-        Create a list with the symbolic variables to use when we compile the theano function
-
-        Returns:
-            list: [self.dips_position_all, self.dip_angles_all, self.azimuth_all, self.polarity_all,
-                   self.ref_layer_points_all, self.rest_layer_points_all]
-        """
-        ipl = [self.dips_position_all, self.dip_angles_all, self.azimuth_all, self.polarity_all, self.surface_points_all,
-               self.fault_drift, self.number_of_points_per_surface_T_op]
-        # self.ref_layer_points_all, self.rest_layer_points_all]
-        return ipl
-
-    def cov_surface_points(self):
-        """
-        Create covariance function for the surface_points
-
-        Returns:
-            theano.tensor.matrix: covariance of the surface_points. Shape number of points in rest x number of
-            points in rest
-
-        """
-
-        # Compute euclidian distances
-        sed_rest_rest = self.squared_euclidean_distances(self.rest_layer_points, self.rest_layer_points)
-        sed_ref_rest = self.squared_euclidean_distances(self.ref_layer_points, self.rest_layer_points)
-        sed_rest_ref = self.squared_euclidean_distances(self.rest_layer_points, self.ref_layer_points)
-        sed_ref_ref = self.squared_euclidean_distances(self.ref_layer_points, self.ref_layer_points)
-
-        # Covariance matrix for surface_points
-        C_I = (self.c_o_T * self.i_reescale * (
-                (sed_rest_rest < self.a_T) *  # Rest - Rest Covariances Matrix
-                (1 - 7 * (sed_rest_rest / self.a_T) ** 2 +
-                 35 / 4 * (sed_rest_rest / self.a_T) ** 3 -
-                 7 / 2 * (sed_rest_rest / self.a_T) ** 5 +
-                 3 / 4 * (sed_rest_rest / self.a_T) ** 7) -
-                ((sed_ref_rest < self.a_T) *  # Reference - Rest
-                 (1 - 7 * (sed_ref_rest / self.a_T) ** 2 +
-                  35 / 4 * (sed_ref_rest / self.a_T) ** 3 -
-                  7 / 2 * (sed_ref_rest / self.a_T) ** 5 +
-                  3 / 4 * (sed_ref_rest / self.a_T) ** 7)) -
-                ((sed_rest_ref < self.a_T) *  # Rest - Reference
-                 (1 - 7 * (sed_rest_ref / self.a_T) ** 2 +
-                  35 / 4 * (sed_rest_ref / self.a_T) ** 3 -
-                  7 / 2 * (sed_rest_ref / self.a_T) ** 5 +
-                  3 / 4 * (sed_rest_ref / self.a_T) ** 7)) +
-                ((sed_ref_ref < self.a_T) *  # Reference - References
-                 (1 - 7 * (sed_ref_ref / self.a_T) ** 2 +
-                  35 / 4 * (sed_ref_ref / self.a_T) ** 3 -
-                  7 / 2 * (sed_ref_ref / self.a_T) ** 5 +
-                  3 / 4 * (sed_ref_ref / self.a_T) ** 7))))
-
-        C_I += T.eye(C_I.shape[0]) * 2 * self.nugget_effect_scalar_T
-        # Add name to the theano node
-        C_I.name = 'Covariance SurfacePoints'
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            C_I = theano.printing.Print('Cov surface_points')(C_I)
-
-        return C_I
-
-    def cov_gradients(self, verbose=0):
-        """
-         Create covariance function for the gradients
-
-         Returns:
-             theano.tensor.matrix: covariance of the gradients. Shape number of points in dip_pos x number of
-             points in dip_pos
-
-         """
-
-        # Euclidean distances
-        sed_dips_dips = self.squared_euclidean_distances(self.dips_position_tiled, self.dips_position_tiled)
-
-        if 'sed_dips_dips' in self.verbose:
-            sed_dips_dips = theano.printing.Print('sed_dips_dips')(sed_dips_dips)
-
-        # Cartesian distances between dips positions
-        h_u = T.vertical_stack(
-            T.tile(self.dips_position[:, 0] - self.dips_position[:, 0].reshape((self.dips_position[:, 0].shape[0], 1)),
-                   self.n_dimensions),
-            T.tile(self.dips_position[:, 1] - self.dips_position[:, 1].reshape((self.dips_position[:, 1].shape[0], 1)),
-                   self.n_dimensions),
-            T.tile(self.dips_position[:, 2] - self.dips_position[:, 2].reshape((self.dips_position[:, 2].shape[0], 1)),
-                   self.n_dimensions))
-
-        # Transpose
-        h_v = h_u.T
-
-        # Perpendicularity matrix. Boolean matrix to separate cross-covariance and
-        # every gradient direction covariance (block diagonal)
-        perpendicularity_matrix = T.zeros_like(sed_dips_dips)
-
-        # Cross-covariances of x
-        perpendicularity_matrix = T.set_subtensor(
-            perpendicularity_matrix[0:self.dips_position.shape[0], 0:self.dips_position.shape[0]], 1)
-
-        # Cross-covariances of y
-        perpendicularity_matrix = T.set_subtensor(
-            perpendicularity_matrix[self.dips_position.shape[0]:self.dips_position.shape[0] * 2,
-            self.dips_position.shape[0]:self.dips_position.shape[0] * 2], 1)
-
-        # Cross-covariances of z
-        perpendicularity_matrix = T.set_subtensor(
-            perpendicularity_matrix[self.dips_position.shape[0] * 2:self.dips_position.shape[0] * 3,
-            self.dips_position.shape[0] * 2:self.dips_position.shape[0] * 3], 1)
-
-        # Covariance matrix for gradients at every xyz direction and their cross-covariances
-        C_G = T.switch(
-            T.eq(sed_dips_dips, 0),  # This is the condition
-            0,  # If true it is equal to 0. This is how a direction affect another
-            (  # else, following Chiles book
-                    (h_u * h_v / sed_dips_dips ** 2) *
-                    ((
-                             (sed_dips_dips < self.a_T) *  # first derivative
-                             (-self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_dips / self.a_T ** 3 -
-                                             35 / 2 * sed_dips_dips ** 3 / self.a_T ** 5 +
-                                             21 / 4 * sed_dips_dips ** 5 / self.a_T ** 7))) +
-                     (sed_dips_dips < self.a_T) *  # Second derivative
-                     self.c_o_T * 7 * (9 * sed_dips_dips ** 5 - 20 * self.a_T ** 2 * sed_dips_dips ** 3 +
-                                       15 * self.a_T ** 4 * sed_dips_dips - 4 * self.a_T ** 5) / (2 * self.a_T ** 7)) -
-                    (perpendicularity_matrix *
-                     (sed_dips_dips < self.a_T) *  # first derivative
-                     self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_dips / self.a_T ** 3 -
-                                   35 / 2 * sed_dips_dips ** 3 / self.a_T ** 5 +
-                                   21 / 4 * sed_dips_dips ** 5 / self.a_T ** 7)))
-        )
-
-        # Setting nugget effect of the gradients
-        # TODO: This function can be substitued by simply adding the nugget effect to the diag if I remove the condition
-        C_G += T.eye(C_G.shape[0]) * self.nugget_effect_grad_T
-
-        # Add name to the theano node
-        C_G.name = 'Covariance Gradient'
-
-        if verbose > 1:
-            theano.printing.pydotprint(C_G, outfile="graphs/" + sys._getframe().f_code.co_name + ".png",
-                                       var_with_name_simple=True)
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            C_G = theano.printing.Print('Cov Gradients')(C_G)
-
-        return C_G
-
-    def cov_interface_gradients(self):
-        """
-        Create covariance function for the gradiens
-        Returns:
-            theano.tensor.matrix: covariance of the gradients. Shape number of points in rest x number of
-              points in dip_pos
-        """
-
-        # Euclidian distances
-        sed_dips_rest = self.squared_euclidean_distances(self.dips_position_tiled, self.rest_layer_points)
-        sed_dips_ref = self.squared_euclidean_distances(self.dips_position_tiled, self.ref_layer_points)
-
-        # Cartesian distances between dips and interface points
-        # Rest
-        hu_rest = T.vertical_stack(
-            (self.dips_position[:, 0] - self.rest_layer_points[:, 0].reshape(
-                (self.rest_layer_points[:, 0].shape[0], 1))).T,
-            (self.dips_position[:, 1] - self.rest_layer_points[:, 1].reshape(
-                (self.rest_layer_points[:, 1].shape[0], 1))).T,
-            (self.dips_position[:, 2] - self.rest_layer_points[:, 2].reshape(
-                (self.rest_layer_points[:, 2].shape[0], 1))).T
-        )
-
-        # Reference point
-        hu_ref = T.vertical_stack(
-            (self.dips_position[:, 0] - self.ref_layer_points[:, 0].reshape(
-                (self.ref_layer_points[:, 0].shape[0], 1))).T,
-            (self.dips_position[:, 1] - self.ref_layer_points[:, 1].reshape(
-                (self.ref_layer_points[:, 1].shape[0], 1))).T,
-            (self.dips_position[:, 2] - self.ref_layer_points[:, 2].reshape(
-                (self.ref_layer_points[:, 2].shape[0], 1))).T
-        )
-
-        # Cross-Covariance gradients-surface_points
-        C_GI = self.gi_reescale * (
-                (hu_rest *
-                 (sed_dips_rest < self.a_T) *  # first derivative
-                 (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_rest / self.a_T ** 3 -
-                                  35 / 2 * sed_dips_rest ** 3 / self.a_T ** 5 +
-                                  21 / 4 * sed_dips_rest ** 5 / self.a_T ** 7))) -
-                (hu_ref *
-                 (sed_dips_ref < self.a_T) *  # first derivative
-                 (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_ref / self.a_T ** 3 -
-                                  35 / 2 * sed_dips_ref ** 3 / self.a_T ** 5 +
-                                  21 / 4 * sed_dips_ref ** 5 / self.a_T ** 7)))
-        ).T
-
-        # Add name to the theano node
-        C_GI.name = 'Covariance gradient interface'
-
-        if str(sys._getframe().f_code.co_name) + '_g' in self.verbose:
-            theano.printing.pydotprint(C_GI, outfile="graphs/" + sys._getframe().f_code.co_name + ".png",
-                                       var_with_name_simple=True)
-        return C_GI
-
-    def universal_matrix(self):
-        """
-        Create the drift matrices for the potential field and its gradient
-
-        Returns:
-            theano.tensor.matrix: Drift matrix for the surface_points. Shape number of points in rest x 3**degree drift
-            (except degree 0 that is 0)
-
-            theano.tensor.matrix: Drift matrix for the gradients. Shape number of points in dips x 3**degree drift
-            (except degree 0 that is 0)
-        """
-
-        # Condition of universality 2 degree
-        # Gradients
-
-        n = self.dips_position.shape[0]
-        U_G = T.zeros((n * self.n_dimensions, 3 * self.n_dimensions))
-        # x
-        U_G = T.set_subtensor(U_G[:n, 0], 1)
-        # y
-        U_G = T.set_subtensor(U_G[n * 1:n * 2, 1], 1)
-        # z
-        U_G = T.set_subtensor(U_G[n * 2: n * 3, 2], 1)
-        # x**2
-        U_G = T.set_subtensor(U_G[:n, 3], 2 * self.gi_reescale * self.dips_position[:, 0])
-        # y**2
-        U_G = T.set_subtensor(U_G[n * 1:n * 2, 4], 2 * self.gi_reescale * self.dips_position[:, 1])
-        # z**2
-        U_G = T.set_subtensor(U_G[n * 2: n * 3, 5], 2 * self.gi_reescale * self.dips_position[:, 2])
-        # xy
-        U_G = T.set_subtensor(U_G[:n, 6], self.gi_reescale * self.dips_position[:, 1])  # This is y
-        U_G = T.set_subtensor(U_G[n * 1:n * 2, 6], self.gi_reescale * self.dips_position[:, 0])  # This is x
-        # xz
-        U_G = T.set_subtensor(U_G[:n, 7], self.gi_reescale * self.dips_position[:, 2])  # This is z
-        U_G = T.set_subtensor(U_G[n * 2: n * 3, 7], self.gi_reescale * self.dips_position[:, 0])  # This is x
-        # yz
-        U_G = T.set_subtensor(U_G[n * 1:n * 2, 8], self.gi_reescale * self.dips_position[:, 2])  # This is z
-        U_G = T.set_subtensor(U_G[n * 2:n * 3, 8], self.gi_reescale * self.dips_position[:, 1])  # This is y
-
-        # Interface
-        U_I = - T.stack(
-            (self.gi_reescale * (self.rest_layer_points[:, 0] - self.ref_layer_points[:, 0]),
-             self.gi_reescale * (self.rest_layer_points[:, 1] - self.ref_layer_points[:, 1]),
-             self.gi_reescale * (self.rest_layer_points[:, 2] - self.ref_layer_points[:, 2]),
-             self.gi_reescale ** 2 * (self.rest_layer_points[:, 0] ** 2 - self.ref_layer_points[:, 0] ** 2),
-             self.gi_reescale ** 2 * (self.rest_layer_points[:, 1] ** 2 - self.ref_layer_points[:, 1] ** 2),
-             self.gi_reescale ** 2 * (self.rest_layer_points[:, 2] ** 2 - self.ref_layer_points[:, 2] ** 2),
-             self.gi_reescale ** 2 * (
-                     self.rest_layer_points[:, 0] * self.rest_layer_points[:, 1] - self.ref_layer_points[:, 0] *
-                     self.ref_layer_points[:, 1]),
-             self.gi_reescale ** 2 * (
-                     self.rest_layer_points[:, 0] * self.rest_layer_points[:, 2] - self.ref_layer_points[:, 0] *
-                     self.ref_layer_points[:, 2]),
-             self.gi_reescale ** 2 * (
-                     self.rest_layer_points[:, 1] * self.rest_layer_points[:, 2] - self.ref_layer_points[:, 1] *
-                     self.ref_layer_points[:, 2]),
-             )).T
-
-        if 'U_I' in self.verbose:
-            U_I = theano.printing.Print('U_I')(U_I)
-
-        if 'U_G' in self.verbose:
-            U_G = theano.printing.Print('U_G')(U_G)
-
-        if str(sys._getframe().f_code.co_name) + '_g' in self.verbose:
-            theano.printing.pydotprint(U_I, outfile="graphs/" + sys._getframe().f_code.co_name + "_i.png",
-                                       var_with_name_simple=True)
-
-            theano.printing.pydotprint(U_G, outfile="graphs/" + sys._getframe().f_code.co_name + "_g.png",
-                                       var_with_name_simple=True)
-
-        # Add name to the theano node
-        if U_I:
-            U_I.name = 'Drift surface_points'
-            U_G.name = 'Drift foliations'
-
-        return U_I[:, :self.n_universal_eq_T_op], U_G[:, :self.n_universal_eq_T_op]
-
-    def faults_matrix(self):
-        """
-        This function creates the part of the graph that generates the df function creating a "block model" at the
-        references and the rest of the points. Then this vector has to be appended to the covariance function
-
-        Returns:
-
-            list:
-
-            - theano.tensor.matrix: Drift matrix for the surface_points. Shape number of points in rest x n df. This drif
-              is a simple addition of an arbitrary number
-
-            - theano.tensor.matrix: Drift matrix for the gradients. Shape number of points in dips x n df. For
-              discrete values this matrix will be null since the derivative of a constant is 0
-        """
-
-        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults = self.matrices_shapes()[:4]
-
-        # self.fault_drift contains the df volume of the grid and the rest and ref points. For the drift we need
-        # to make it relative to the reference point
-        if 'fault matrix' in self.verbose:
-            self.fault_drift = theano.printing.Print('self.fault_drift')(self.fault_drift)
-        interface_loc = self.fault_drift.shape[1] - 2 * self.len_points
-
-        fault_drift_at_surface_points_rest = self.fault_drift
-        fault_drift_at_surface_points_ref = self.fault_drift
-
-        F_I = (fault_drift_at_surface_points_ref - fault_drift_at_surface_points_rest) + 0.0001
-
-        # As long as the drift is a constant F_G is null
-        F_G = T.zeros((length_of_faults, length_of_CG)) + 0.0001
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            F_I = theano.printing.Print('Faults surface_points matrix')(F_I)
-            F_G = theano.printing.Print('Faults gradients matrix')(F_G)
-
-        return F_I, F_G
-
-    def covariance_matrix(self):
-        """
-        Set all the previous covariances together in the universal cokriging matrix
-
-        Returns:
-            theano.tensor.matrix: Multivariate covariance
-        """
-
-        # Lengths
-        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C = self.matrices_shapes()
-
-        # Individual matrices
-        C_G = self.cov_gradients()
-        C_I = self.cov_surface_points()
-        C_GI = self.cov_interface_gradients()
-        U_I, U_G = self.universal_matrix()
-        F_I, F_G = self.faults_matrix()
-
-        # =================================
-        # Creation of the Covariance Matrix
-        # =================================
-        C_matrix = T.zeros((length_of_C, length_of_C))
-
-        # First row of matrices
-        # Set C_G
-        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG, 0:length_of_CG], C_G)
-        # Set CGI
-        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG, length_of_CG:length_of_CG + length_of_CGI], C_GI.T)
-        # Set UG
-        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG,
-                                   length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I], U_G)
-        # Set FG. I cannot use -index because when is -0 is equivalent to 0
-        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG, length_of_CG + length_of_CGI + length_of_U_I:], F_G.T)
-        # Second row of matrices
-        # Set C_IG
-        C_matrix = T.set_subtensor(C_matrix[length_of_CG:length_of_CG + length_of_CGI, 0:length_of_CG], C_GI)
-        # Set C_I
-        C_matrix = T.set_subtensor(C_matrix[length_of_CG:length_of_CG + length_of_CGI,
-                                   length_of_CG:length_of_CG + length_of_CGI], C_I)
-        # Set U_I
-        # if not self.u_grade_T.get_value() == 0:
-        C_matrix = T.set_subtensor(C_matrix[length_of_CG:length_of_CG + length_of_CGI,
-                                   length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I], U_I)
-        # Set F_I
-        C_matrix = T.set_subtensor(
-            C_matrix[length_of_CG:length_of_CG + length_of_CGI, length_of_CG + length_of_CGI + length_of_U_I:], F_I.T)
-        # Third row of matrices
-        # Set U_G
-        C_matrix = T.set_subtensor(
-            C_matrix[length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I, 0:length_of_CG], U_G.T)
-        # Set U_I
-        C_matrix = T.set_subtensor(C_matrix[length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I,
-                                   length_of_CG:length_of_CG + length_of_CGI], U_I.T)
-        # Fourth row of matrices
-        # Set F_G
-        C_matrix = T.set_subtensor(C_matrix[length_of_CG + length_of_CGI + length_of_U_I:, 0:length_of_CG], F_G)
-        # Set F_I
-        C_matrix = T.set_subtensor(
-            C_matrix[length_of_CG + length_of_CGI + length_of_U_I:, length_of_CG:length_of_CG + length_of_CGI], F_I)
-        # Add name to the theano node
-        C_matrix.name = 'Block Covariance Matrix'
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            C_matrix = theano.printing.Print('cov_function')(C_matrix)
-
-        return C_matrix
-
-    def b_vector(self):
-        """
-        Creation of the independent vector b to solve the kriging system
-
-        Args:
-            verbose: -deprecated-
-
-        Returns:
-            theano.tensor.vector: independent vector
-        """
-
-        length_of_C = self.matrices_shapes()[-1]
-        # =====================
-        # Creation of the gradients G vector
-        # Calculation of the cartesian components of the dips assuming the unit module
-        G_x = T.sin(T.deg2rad(self.dip_angles)) * T.sin(T.deg2rad(self.azimuth)) * self.polarity
-        G_y = T.sin(T.deg2rad(self.dip_angles)) * T.cos(T.deg2rad(self.azimuth)) * self.polarity
-        G_z = T.cos(T.deg2rad(self.dip_angles)) * self.polarity
-
-        G = T.concatenate((G_x, G_y, G_z))
-
-        # Creation of the Dual Kriging vector
-        b = T.zeros((length_of_C,))
-        b = T.set_subtensor(b[0:G.shape[0]], G)
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            b = theano.printing.Print('b vector')(b)
-
-        # Add name to the theano node
-        b.name = 'b vector'
-        return b
-
-    def solve_kriging(self):
-        """
-        Solve the kriging system. This has to get substituted by a more efficient and stable method QR
-        decomposition in all likelihood
-
-        Returns:
-            theano.tensor.vector: Dual kriging parameters
-
-        """
-        C_matrix = self.covariance_matrix()
-        b = self.b_vector()
-        # Solving the kriging system
-        import theano.tensor.slinalg
-        b2 = T.tile(b, (1, 1)).T
-        DK_parameters = theano.tensor.slinalg.solve(C_matrix, b2)
-        DK_parameters = DK_parameters.reshape((DK_parameters.shape[0],))
-
-        # Add name to the theano node
-        DK_parameters.name = 'Dual Kriging parameters'
-
-        if str(sys._getframe().f_code.co_name) in self.verbose:
-            DK_parameters = theano.printing.Print(DK_parameters.name)(DK_parameters)
-        return DK_parameters
+import aesara
+import aesara.tensor  as T
+import numpy as np
+import sys
+from .aesara_graph import aesaraGeometry 
+
+
+class aesaraKriging(aesaraGeometry):
+    """
+    This class is used to help to divide the construction of the graph into sensical parts. All its methods buildDEP2 a part
+    of the graph. Every method can be seen as a branch and collection of branches until the last method that will be the
+    whole tree. Every part of the graph could be compiled separately but as we increase the complexity the input of each
+    of these methods is more and more difficult to provide (if you are in a branch close to the trunk you need all the
+    results of the branches above)
+    """
+    def __init__(self, output='geology', optimizer='fast_compile', verbose=[0], dtype='float32',
+                 is_fault=None, is_lith=None):
+        """
+        In the init we need to create all the symbolic parameters that are used in the process. Most of the variables
+        are shared parameters initialized with random values. At this stage we only care about the type and shape of the
+        parameters. After we have the graph built we can update the value of these shared parameters to our data (in the
+        interpolatorClass).
+
+        Args:
+            u_grade: grade of the drift to compile the right graph. I found out that we can make a graph that takes this
+            as variable so this argument will be deprecated soon
+            verbose (list): name of the nodes you want to print
+            dtype (str): type of float either 32 or 64
+        """
+        
+        super(aesaraKriging, self).__init__(output='geology', optimizer='fast_compile', verbose=[0], dtype='float32',
+                 is_fault=None, is_lith=None)
+        # Pass the verbose list as property
+
+        # Creation of symbolic parameters
+        # =============
+        # Constants
+        # =============
+
+
+
+
+        # # This is not accumulative
+        # self.number_of_points_per_surface_T = aesara.shared(np.zeros(3, dtype='int32')) #TODO is DEP?
+        # self.number_of_points_per_surface_T_op = self.number_of_points_per_surface_T
+        # This is accumulative
+        #self.npf = aesara.shared(np.zeros(3, dtype='int32'), 'Number of points per surface accumulative')
+        #self.npf_op = self.npf[[0, -2]]
+
+    def input_parameters_kriging(self):
+        """
+        Create a list with the symbolic variables to use when we compile the aesara function
+
+        Returns:
+            list: [self.dips_position_all, self.dip_angles_all, self.azimuth_all, self.polarity_all,
+                   self.ref_layer_points_all, self.rest_layer_points_all]
+        """
+        ipl = [self.dips_position_all, self.dip_angles_all, self.azimuth_all, self.polarity_all, self.surface_points_all,
+               self.fault_drift, self.number_of_points_per_surface_T_op]
+        # self.ref_layer_points_all, self.rest_layer_points_all]
+        return ipl
+
+    def cov_surface_points(self):
+        """
+        Create covariance function for the surface_points
+
+        Returns:
+            aesara.tensor.matrix: covariance of the surface_points. Shape number of points in rest x number of
+            points in rest
+
+        """
+
+        # Compute euclidian distances
+        sed_rest_rest = self.squared_euclidean_distances(self.rest_layer_points, self.rest_layer_points)
+        sed_ref_rest = self.squared_euclidean_distances(self.ref_layer_points, self.rest_layer_points)
+        sed_rest_ref = self.squared_euclidean_distances(self.rest_layer_points, self.ref_layer_points)
+        sed_ref_ref = self.squared_euclidean_distances(self.ref_layer_points, self.ref_layer_points)
+
+        # Covariance matrix for surface_points
+        C_I = (self.c_o_T * self.i_reescale * (
+                (sed_rest_rest < self.a_T) *  # Rest - Rest Covariances Matrix
+                (1 - 7 * (sed_rest_rest / self.a_T) ** 2 +
+                 35 / 4 * (sed_rest_rest / self.a_T) ** 3 -
+                 7 / 2 * (sed_rest_rest / self.a_T) ** 5 +
+                 3 / 4 * (sed_rest_rest / self.a_T) ** 7) -
+                ((sed_ref_rest < self.a_T) *  # Reference - Rest
+                 (1 - 7 * (sed_ref_rest / self.a_T) ** 2 +
+                  35 / 4 * (sed_ref_rest / self.a_T) ** 3 -
+                  7 / 2 * (sed_ref_rest / self.a_T) ** 5 +
+                  3 / 4 * (sed_ref_rest / self.a_T) ** 7)) -
+                ((sed_rest_ref < self.a_T) *  # Rest - Reference
+                 (1 - 7 * (sed_rest_ref / self.a_T) ** 2 +
+                  35 / 4 * (sed_rest_ref / self.a_T) ** 3 -
+                  7 / 2 * (sed_rest_ref / self.a_T) ** 5 +
+                  3 / 4 * (sed_rest_ref / self.a_T) ** 7)) +
+                ((sed_ref_ref < self.a_T) *  # Reference - References
+                 (1 - 7 * (sed_ref_ref / self.a_T) ** 2 +
+                  35 / 4 * (sed_ref_ref / self.a_T) ** 3 -
+                  7 / 2 * (sed_ref_ref / self.a_T) ** 5 +
+                  3 / 4 * (sed_ref_ref / self.a_T) ** 7))))
+
+        C_I += T.eye(C_I.shape[0]) * 2 * self.nugget_effect_scalar_T
+        # Add name to the aesara node
+        C_I.name = 'Covariance SurfacePoints'
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            C_I = aesara.printing.Print('Cov surface_points')(C_I)
+
+        return C_I
+
+    def cov_gradients(self, verbose=0):
+        """
+         Create covariance function for the gradients
+
+         Returns:
+             aesara.tensor.matrix: covariance of the gradients. Shape number of points in dip_pos x number of
+             points in dip_pos
+
+         """
+
+        # Euclidean distances
+        sed_dips_dips = self.squared_euclidean_distances(self.dips_position_tiled, self.dips_position_tiled)
+
+        if 'sed_dips_dips' in self.verbose:
+            sed_dips_dips = aesara.printing.Print('sed_dips_dips')(sed_dips_dips)
+
+        # Cartesian distances between dips positions
+        h_u = T.vertical_stack(
+            T.tile(self.dips_position[:, 0] - self.dips_position[:, 0].reshape((self.dips_position[:, 0].shape[0], 1)),
+                   self.n_dimensions),
+            T.tile(self.dips_position[:, 1] - self.dips_position[:, 1].reshape((self.dips_position[:, 1].shape[0], 1)),
+                   self.n_dimensions),
+            T.tile(self.dips_position[:, 2] - self.dips_position[:, 2].reshape((self.dips_position[:, 2].shape[0], 1)),
+                   self.n_dimensions))
+
+        # Transpose
+        h_v = h_u.T
+
+        # Perpendicularity matrix. Boolean matrix to separate cross-covariance and
+        # every gradient direction covariance (block diagonal)
+        perpendicularity_matrix = T.zeros_like(sed_dips_dips)
+
+        # Cross-covariances of x
+        perpendicularity_matrix = T.set_subtensor(
+            perpendicularity_matrix[0:self.dips_position.shape[0], 0:self.dips_position.shape[0]], 1)
+
+        # Cross-covariances of y
+        perpendicularity_matrix = T.set_subtensor(
+            perpendicularity_matrix[self.dips_position.shape[0]:self.dips_position.shape[0] * 2,
+            self.dips_position.shape[0]:self.dips_position.shape[0] * 2], 1)
+
+        # Cross-covariances of z
+        perpendicularity_matrix = T.set_subtensor(
+            perpendicularity_matrix[self.dips_position.shape[0] * 2:self.dips_position.shape[0] * 3,
+            self.dips_position.shape[0] * 2:self.dips_position.shape[0] * 3], 1)
+
+        # Covariance matrix for gradients at every xyz direction and their cross-covariances
+        C_G = T.switch(
+            T.eq(sed_dips_dips, 0),  # This is the condition
+            0,  # If true it is equal to 0. This is how a direction affect another
+            (  # else, following Chiles book
+                    (h_u * h_v / sed_dips_dips ** 2) *
+                    ((
+                             (sed_dips_dips < self.a_T) *  # first derivative
+                             (-self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_dips / self.a_T ** 3 -
+                                             35 / 2 * sed_dips_dips ** 3 / self.a_T ** 5 +
+                                             21 / 4 * sed_dips_dips ** 5 / self.a_T ** 7))) +
+                     (sed_dips_dips < self.a_T) *  # Second derivative
+                     self.c_o_T * 7 * (9 * sed_dips_dips ** 5 - 20 * self.a_T ** 2 * sed_dips_dips ** 3 +
+                                       15 * self.a_T ** 4 * sed_dips_dips - 4 * self.a_T ** 5) / (2 * self.a_T ** 7)) -
+                    (perpendicularity_matrix *
+                     (sed_dips_dips < self.a_T) *  # first derivative
+                     self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_dips / self.a_T ** 3 -
+                                   35 / 2 * sed_dips_dips ** 3 / self.a_T ** 5 +
+                                   21 / 4 * sed_dips_dips ** 5 / self.a_T ** 7)))
+        )
+
+        # Setting nugget effect of the gradients
+        # TODO: This function can be substitued by simply adding the nugget effect to the diag if I remove the condition
+        C_G += T.eye(C_G.shape[0]) * self.nugget_effect_grad_T
+
+        # Add name to the aesara node
+        C_G.name = 'Covariance Gradient'
+
+        if verbose > 1:
+            aesara.printing.pydotprint(C_G, outfile="graphs/" + sys._getframe().f_code.co_name + ".png",
+                                       var_with_name_simple=True)
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            C_G = aesara.printing.Print('Cov Gradients')(C_G)
+
+        return C_G
+
+    def cov_interface_gradients(self):
+        """
+        Create covariance function for the gradiens
+        Returns:
+            aesara.tensor.matrix: covariance of the gradients. Shape number of points in rest x number of
+              points in dip_pos
+        """
+
+        # Euclidian distances
+        sed_dips_rest = self.squared_euclidean_distances(self.dips_position_tiled, self.rest_layer_points)
+        sed_dips_ref = self.squared_euclidean_distances(self.dips_position_tiled, self.ref_layer_points)
+
+        # Cartesian distances between dips and interface points
+        # Rest
+        hu_rest = T.vertical_stack(
+            (self.dips_position[:, 0] - self.rest_layer_points[:, 0].reshape(
+                (self.rest_layer_points[:, 0].shape[0], 1))).T,
+            (self.dips_position[:, 1] - self.rest_layer_points[:, 1].reshape(
+                (self.rest_layer_points[:, 1].shape[0], 1))).T,
+            (self.dips_position[:, 2] - self.rest_layer_points[:, 2].reshape(
+                (self.rest_layer_points[:, 2].shape[0], 1))).T
+        )
+
+        # Reference point
+        hu_ref = T.vertical_stack(
+            (self.dips_position[:, 0] - self.ref_layer_points[:, 0].reshape(
+                (self.ref_layer_points[:, 0].shape[0], 1))).T,
+            (self.dips_position[:, 1] - self.ref_layer_points[:, 1].reshape(
+                (self.ref_layer_points[:, 1].shape[0], 1))).T,
+            (self.dips_position[:, 2] - self.ref_layer_points[:, 2].reshape(
+                (self.ref_layer_points[:, 2].shape[0], 1))).T
+        )
+
+        # Cross-Covariance gradients-surface_points
+        C_GI = self.gi_reescale * (
+                (hu_rest *
+                 (sed_dips_rest < self.a_T) *  # first derivative
+                 (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_rest / self.a_T ** 3 -
+                                  35 / 2 * sed_dips_rest ** 3 / self.a_T ** 5 +
+                                  21 / 4 * sed_dips_rest ** 5 / self.a_T ** 7))) -
+                (hu_ref *
+                 (sed_dips_ref < self.a_T) *  # first derivative
+                 (- self.c_o_T * ((-14 / self.a_T ** 2) + 105 / 4 * sed_dips_ref / self.a_T ** 3 -
+                                  35 / 2 * sed_dips_ref ** 3 / self.a_T ** 5 +
+                                  21 / 4 * sed_dips_ref ** 5 / self.a_T ** 7)))
+        ).T
+
+        # Add name to the aesara node
+        C_GI.name = 'Covariance gradient interface'
+
+        if str(sys._getframe().f_code.co_name) + '_g' in self.verbose:
+            aesara.printing.pydotprint(C_GI, outfile="graphs/" + sys._getframe().f_code.co_name + ".png",
+                                       var_with_name_simple=True)
+        return C_GI
+
+    def universal_matrix(self):
+        """
+        Create the drift matrices for the potential field and its gradient
+
+        Returns:
+            aesara.tensor.matrix: Drift matrix for the surface_points. Shape number of points in rest x 3**degree drift
+            (except degree 0 that is 0)
+
+            aesara.tensor.matrix: Drift matrix for the gradients. Shape number of points in dips x 3**degree drift
+            (except degree 0 that is 0)
+        """
+
+        # Condition of universality 2 degree
+        # Gradients
+
+        n = self.dips_position.shape[0]
+        U_G = T.zeros((n * self.n_dimensions, 3 * self.n_dimensions))
+        # x
+        U_G = T.set_subtensor(U_G[:n, 0], 1)
+        # y
+        U_G = T.set_subtensor(U_G[n * 1:n * 2, 1], 1)
+        # z
+        U_G = T.set_subtensor(U_G[n * 2: n * 3, 2], 1)
+        # x**2
+        U_G = T.set_subtensor(U_G[:n, 3], 2 * self.gi_reescale * self.dips_position[:, 0])
+        # y**2
+        U_G = T.set_subtensor(U_G[n * 1:n * 2, 4], 2 * self.gi_reescale * self.dips_position[:, 1])
+        # z**2
+        U_G = T.set_subtensor(U_G[n * 2: n * 3, 5], 2 * self.gi_reescale * self.dips_position[:, 2])
+        # xy
+        U_G = T.set_subtensor(U_G[:n, 6], self.gi_reescale * self.dips_position[:, 1])  # This is y
+        U_G = T.set_subtensor(U_G[n * 1:n * 2, 6], self.gi_reescale * self.dips_position[:, 0])  # This is x
+        # xz
+        U_G = T.set_subtensor(U_G[:n, 7], self.gi_reescale * self.dips_position[:, 2])  # This is z
+        U_G = T.set_subtensor(U_G[n * 2: n * 3, 7], self.gi_reescale * self.dips_position[:, 0])  # This is x
+        # yz
+        U_G = T.set_subtensor(U_G[n * 1:n * 2, 8], self.gi_reescale * self.dips_position[:, 2])  # This is z
+        U_G = T.set_subtensor(U_G[n * 2:n * 3, 8], self.gi_reescale * self.dips_position[:, 1])  # This is y
+
+        # Interface
+        U_I = - T.stack(
+            (self.gi_reescale * (self.rest_layer_points[:, 0] - self.ref_layer_points[:, 0]),
+             self.gi_reescale * (self.rest_layer_points[:, 1] - self.ref_layer_points[:, 1]),
+             self.gi_reescale * (self.rest_layer_points[:, 2] - self.ref_layer_points[:, 2]),
+             self.gi_reescale ** 2 * (self.rest_layer_points[:, 0] ** 2 - self.ref_layer_points[:, 0] ** 2),
+             self.gi_reescale ** 2 * (self.rest_layer_points[:, 1] ** 2 - self.ref_layer_points[:, 1] ** 2),
+             self.gi_reescale ** 2 * (self.rest_layer_points[:, 2] ** 2 - self.ref_layer_points[:, 2] ** 2),
+             self.gi_reescale ** 2 * (
+                     self.rest_layer_points[:, 0] * self.rest_layer_points[:, 1] - self.ref_layer_points[:, 0] *
+                     self.ref_layer_points[:, 1]),
+             self.gi_reescale ** 2 * (
+                     self.rest_layer_points[:, 0] * self.rest_layer_points[:, 2] - self.ref_layer_points[:, 0] *
+                     self.ref_layer_points[:, 2]),
+             self.gi_reescale ** 2 * (
+                     self.rest_layer_points[:, 1] * self.rest_layer_points[:, 2] - self.ref_layer_points[:, 1] *
+                     self.ref_layer_points[:, 2]),
+             )).T
+
+        if 'U_I' in self.verbose:
+            U_I = aesara.printing.Print('U_I')(U_I)
+
+        if 'U_G' in self.verbose:
+            U_G = aesara.printing.Print('U_G')(U_G)
+
+        if str(sys._getframe().f_code.co_name) + '_g' in self.verbose:
+            aesara.printing.pydotprint(U_I, outfile="graphs/" + sys._getframe().f_code.co_name + "_i.png",
+                                       var_with_name_simple=True)
+
+            aesara.printing.pydotprint(U_G, outfile="graphs/" + sys._getframe().f_code.co_name + "_g.png",
+                                       var_with_name_simple=True)
+
+        # Add name to the aesara node
+        if U_I:
+            U_I.name = 'Drift surface_points'
+            U_G.name = 'Drift foliations'
+
+        return U_I[:, :self.n_universal_eq_T_op], U_G[:, :self.n_universal_eq_T_op]
+
+    def faults_matrix(self):
+        """
+        This function creates the part of the graph that generates the df function creating a "block model" at the
+        references and the rest of the points. Then this vector has to be appended to the covariance function
+
+        Returns:
+
+            list:
+
+            - aesara.tensor.matrix: Drift matrix for the surface_points. Shape number of points in rest x n df. This drif
+              is a simple addition of an arbitrary number
+
+            - aesara.tensor.matrix: Drift matrix for the gradients. Shape number of points in dips x n df. For
+              discrete values this matrix will be null since the derivative of a constant is 0
+        """
+
+        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults = self.matrices_shapes()[:4]
+
+        # self.fault_drift contains the df volume of the grid and the rest and ref points. For the drift we need
+        # to make it relative to the reference point
+        if 'fault matrix' in self.verbose:
+            self.fault_drift = aesara.printing.Print('self.fault_drift')(self.fault_drift)
+        interface_loc = self.fault_drift.shape[1] - 2 * self.len_points
+
+        fault_drift_at_surface_points_rest = self.fault_drift
+        fault_drift_at_surface_points_ref = self.fault_drift
+
+        F_I = (fault_drift_at_surface_points_ref - fault_drift_at_surface_points_rest) + 0.0001
+
+        # As long as the drift is a constant F_G is null
+        F_G = T.zeros((length_of_faults, length_of_CG)) + 0.0001
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            F_I = aesara.printing.Print('Faults surface_points matrix')(F_I)
+            F_G = aesara.printing.Print('Faults gradients matrix')(F_G)
+
+        return F_I, F_G
+
+    def covariance_matrix(self):
+        """
+        Set all the previous covariances together in the universal cokriging matrix
+
+        Returns:
+            aesara.tensor.matrix: Multivariate covariance
+        """
+
+        # Lengths
+        length_of_CG, length_of_CGI, length_of_U_I, length_of_faults, length_of_C = self.matrices_shapes()
+
+        # Individual matrices
+        C_G = self.cov_gradients()
+        C_I = self.cov_surface_points()
+        C_GI = self.cov_interface_gradients()
+        U_I, U_G = self.universal_matrix()
+        F_I, F_G = self.faults_matrix()
+
+        # =================================
+        # Creation of the Covariance Matrix
+        # =================================
+        C_matrix = T.zeros((length_of_C, length_of_C))
+
+        # First row of matrices
+        # Set C_G
+        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG, 0:length_of_CG], C_G)
+        # Set CGI
+        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG, length_of_CG:length_of_CG + length_of_CGI], C_GI.T)
+        # Set UG
+        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG,
+                                   length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I], U_G)
+        # Set FG. I cannot use -index because when is -0 is equivalent to 0
+        C_matrix = T.set_subtensor(C_matrix[0:length_of_CG, length_of_CG + length_of_CGI + length_of_U_I:], F_G.T)
+        # Second row of matrices
+        # Set C_IG
+        C_matrix = T.set_subtensor(C_matrix[length_of_CG:length_of_CG + length_of_CGI, 0:length_of_CG], C_GI)
+        # Set C_I
+        C_matrix = T.set_subtensor(C_matrix[length_of_CG:length_of_CG + length_of_CGI,
+                                   length_of_CG:length_of_CG + length_of_CGI], C_I)
+        # Set U_I
+        # if not self.u_grade_T.get_value() == 0:
+        C_matrix = T.set_subtensor(C_matrix[length_of_CG:length_of_CG + length_of_CGI,
+                                   length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I], U_I)
+        # Set F_I
+        C_matrix = T.set_subtensor(
+            C_matrix[length_of_CG:length_of_CG + length_of_CGI, length_of_CG + length_of_CGI + length_of_U_I:], F_I.T)
+        # Third row of matrices
+        # Set U_G
+        C_matrix = T.set_subtensor(
+            C_matrix[length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I, 0:length_of_CG], U_G.T)
+        # Set U_I
+        C_matrix = T.set_subtensor(C_matrix[length_of_CG + length_of_CGI:length_of_CG + length_of_CGI + length_of_U_I,
+                                   length_of_CG:length_of_CG + length_of_CGI], U_I.T)
+        # Fourth row of matrices
+        # Set F_G
+        C_matrix = T.set_subtensor(C_matrix[length_of_CG + length_of_CGI + length_of_U_I:, 0:length_of_CG], F_G)
+        # Set F_I
+        C_matrix = T.set_subtensor(
+            C_matrix[length_of_CG + length_of_CGI + length_of_U_I:, length_of_CG:length_of_CG + length_of_CGI], F_I)
+        # Add name to the aesara node
+        C_matrix.name = 'Block Covariance Matrix'
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            C_matrix = aesara.printing.Print('cov_function')(C_matrix)
+
+        return C_matrix
+
+    def b_vector(self):
+        """
+        Creation of the independent vector b to solve the kriging system
+
+        Args:
+            verbose: -deprecated-
+
+        Returns:
+            aesara.tensor.vector: independent vector
+        """
+
+        length_of_C = self.matrices_shapes()[-1]
+        # =====================
+        # Creation of the gradients G vector
+        # Calculation of the cartesian components of the dips assuming the unit module
+        G_x = T.sin(T.deg2rad(self.dip_angles)) * T.sin(T.deg2rad(self.azimuth)) * self.polarity
+        G_y = T.sin(T.deg2rad(self.dip_angles)) * T.cos(T.deg2rad(self.azimuth)) * self.polarity
+        G_z = T.cos(T.deg2rad(self.dip_angles)) * self.polarity
+
+        G = T.concatenate((G_x, G_y, G_z))
+
+        # Creation of the Dual Kriging vector
+        b = T.zeros((length_of_C,))
+        b = T.set_subtensor(b[0:G.shape[0]], G)
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            b = aesara.printing.Print('b vector')(b)
+
+        # Add name to the aesara node
+        b.name = 'b vector'
+        return b
+
+    def solve_kriging(self):
+        """
+        Solve the kriging system. This has to get substituted by a more efficient and stable method QR
+        decomposition in all likelihood
+
+        Returns:
+            aesara.tensor.vector: Dual kriging parameters
+
+        """
+        C_matrix = self.covariance_matrix()
+        b = self.b_vector()
+        # Solving the kriging system
+        import aesara.tensor .slinalg
+        b2 = T.tile(b, (1, 1)).T
+        DK_parameters = aesara.tensor.slinalg.solve(C_matrix, b2)
+        DK_parameters = DK_parameters.reshape((DK_parameters.shape[0],))
+
+        # Add name to the aesara node
+        DK_parameters.name = 'Dual Kriging parameters'
+
+        if str(sys._getframe().f_code.co_name) in self.verbose:
+            DK_parameters = aesara.printing.Print(DK_parameters.name)(DK_parameters)
+        return DK_parameters
```

### Comparing `gempy-2.2b10.dev1/gempy/core/xsolution.py` & `gempy-2.3.0/gempy/core/xsolution.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,343 +1,350 @@
-from typing import Union
-
-from gempy.core.data_modules.stack import Stack
-from gempy.core.data import Grid, Surfaces
-import xarray as xr
-import subsurface
-import numpy as np
-import pandas as pd
-
-
-class XSolution(object):
-    """This class stores the output of the interpolation and the necessary objects
-    to visualize and manipulate this data using xarray as backend.
-
-    Depending on the activated grid (see :class:`Grid`) a different number of
-     properties are returned returned:
-
-    Args:
-        grid (Grid): [s0]
-        surfaces (Surfaces): [s1]
-        series (Series): [s2]
-
-    Attributes:
-        grid (Grid)
-        surfaces (Surfaces)
-        series (Series)
-        weights_vector (numpy.array): [s3]
-        scalar_field_at_surface_points (numpy.array): [s4]
-        block_at_surface_points (numpy.array): [s5]
-        mask_at_surface_points (numpy.array): [s6]
-        values_at_surface_points (numpy.array): [s7]
-        lith_block (numpy.array): [s8]
-        scalar_field_matrix (numpy.array): [s9]
-        block_matrix (numpy.array): [s10]
-        mask_matrix (numpy.array): [s11]
-        mask_matrix_pad (numpy.array): mask matrix padded 2 block in order to guarantee that the layers intersect each
-         other after marching cubes
-        values_matrix (numpy.array): [s12]
-        vertices (list[numpy.array]): [s13]
-        edges (list[numpy.array]): [s14]
-        geological_map (numpy.array): [s15]
-
-    """
-
-    def __init__(self, grid: Grid,
-                 surfaces: Surfaces = None,
-                 stack: Stack = None,
-                 ):
-
-        self.grid = grid
-        self.stack = stack
-        self.surfaces = surfaces  # Used to store ver/sim there
-
-        # Define xarrays
-        self.weights_vector = None
-        self.at_surface_points = None
-        self.s_regular_grid = None  # xr.Dataset()
-        self.s_custom_grid = None  # xr.Dataset()
-        self.s_topography = None  # xr.Dataset()
-        self.s_at_surface_points = None  # xr.Dataset()
-        self.s_sections = dict()
-        self.meshes = None  # xr.Dataset()
-
-    def set_meshes(self, surfaces: Surfaces = None):
-        """Create xarray from the Surfaces object. In GemPy Engine we will set
-         them directly.
-        """
-
-        surf_ver_sim = surfaces.df[['id', 'vertices', 'edges']]
-        vertex = []
-        simplex = []
-        ids = []
-        last_idx = 0
-        self.extract_each_surface_representations(ids, last_idx, simplex,
-                                                  surf_ver_sim, vertex)
-
-        vertex_array = np.concatenate(vertex)
-        simplex_array = np.concatenate(simplex)
-        ids_array = np.concatenate(ids)
-
-        self.meshes = subsurface.UnstructuredData.from_array(
-            vertex=vertex_array,
-            cells=simplex_array,
-            attributes=pd.DataFrame(ids_array, columns=['id'])
-        )
-
-        return self.meshes
-
-    @staticmethod
-    def extract_each_surface_representations(ids, last_idx, simplex,
-                                             surf_ver_sim, vertex):
-        for index, row in surf_ver_sim.iterrows():
-            v_ = row['vertices']
-            e_ = row['edges'] + last_idx
-            if v_ is not np.nan and e_ is not np.nan:
-                i_ = np.ones(e_.shape[0]) * row['id']
-                vertex.append(v_)
-                simplex.append(e_)
-                ids.append(i_)
-                last_idx = e_[-20:].max() + 1
-
-    def set_values(self,
-                   values: list,
-                   active_features=None,
-                   surf_properties=None,
-                   ):
-        """ At this stage we should split values into the different grids
-
-        Args:
-            values:
-
-        Returns:
-
-        """
-
-        # Get an array with all the indices for each grid
-        l = self.grid.length
-
-        coords_base, xyz = self.prepare_common_args(active_features,
-                                                    surf_properties)
-        self.weights_vector = values[3]
-
-        if self.grid.active_grids[0]:
-            self.set_values_to_regular_grid_(values, l[0], l[1], coords_base.copy())
-        if self.grid.active_grids[1]:
-            self.set_values_to_custom_grid(values, l[1], l[2], coords_base.copy(),
-                                           xyz=xyz)
-        if self.grid.active_grids[2]:
-            self.set_values_to_topography(values, l[2], l[3], coords_base.copy())
-        if self.grid.active_grids[3]:
-            self.set_values_to_sections(values, l[3], l[4], coords_base.copy())
-        if self.grid.active_grids[4]:
-            self.set_values_to_centered()
-
-        # TODO: Add xyz from surface points
-        self.set_values_to_surface_points_(values, l[-1], coords_base, xyz=None)
-
-    def prepare_common_args(self, active_features, surf_properties):
-        if active_features is None and self.stack is not None:
-            active_features = self.stack.df.groupby('isActive').get_group(True).index
-        if surf_properties is None and self.surfaces is not None:
-            surf_properties = self.surfaces.properties_val
-        coords_base = dict()
-        if active_features is not None:
-            coords_base['Features'] = active_features.to_list()
-        if surf_properties is not None:
-            coords_base['Properties'] = surf_properties.to_list()
-        if self.grid.custom_grid is not None:
-            xyz = self.grid.custom_grid.values
-        else:
-            xyz = None
-        return coords_base, xyz
-
-    def set_values_to_centered(self):
-        return
-
-    def set_values_to_surface_points_(self, values, l0, coords_base, xyz=None):
-        coords = coords_base
-        l1 = values[0].shape[-1]
-        arrays = self.create_unstruct_xarray(values, l0, l1, xyz)
-
-        self.s_at_surface_points = xr.Dataset(
-            data_vars=arrays,
-            coords=coords
-        )
-        return self.s_at_surface_points
-
-    @staticmethod
-    def create_struc_xarrays(values, l0, l1, res: Union[list, np.ndarray]):
-        arrays = dict()
-
-        n_dim = len(res)
-        xyz = ['X', 'Y', 'Z'][:n_dim]
-        if values[0] is not None:
-            # This encompass lith_block and values matrix
-            property_matrix = xr.DataArray(
-                data=values[0][:, l0:l1].reshape(-1, *res),
-                dims=['Properties', *xyz],
-            )
-            arrays['property_matrix'] = property_matrix
-
-        if values[1] is not None:
-            # This is the block matrix
-            i, j, _ = values[1].shape
-            block_matrix = xr.DataArray(
-                data=values[1][:, :, l0:l1].reshape(i, j, *res),
-                dims=['Features', 'Properties', *xyz],
-            )
-            arrays['block_matrix'] = block_matrix
-
-            # Fault block?
-
-        if values[4] is not None:
-            # Scalar field matrix
-            scalar_matrix = xr.DataArray(
-                data=values[4][:, l0:l1].reshape(-1, *res),
-                dims=['Features', *xyz],
-            )
-            arrays['scalar_field_matrix'] = scalar_matrix
-
-        if values[6] is not None:
-            # Mask matrix
-            mask_matrix = xr.DataArray(
-                data=values[6][:, l0:l1].reshape(-1, *res),
-                dims=['Features', *xyz],
-            )
-            arrays['mask_matrix'] = mask_matrix
-
-        if values[7] is not None:
-            # Fault mask matrix
-            fault_mask = xr.DataArray(
-                data=values[7][:, l0:l1].reshape(-1, *res),
-                dims=['Features', *xyz],
-            )
-            arrays['fault_mask'] = fault_mask
-
-        return arrays
-
-    @staticmethod
-    def create_unstruct_xarray(values, l0, l1, xyz):
-        arrays = dict()
-        if xyz is not None:
-            cartesian_matrix = xr.DataArray(
-                data=xyz,
-                dims=['Point', 'XYZ'],
-                coords={'XYZ': ['X', 'Y', 'Z']}
-            )
-            arrays['cartesian_matrix'] = cartesian_matrix
-
-        if values[0] is not None:
-            # Values and lith block
-            property_v3 = xr.DataArray(
-                data=values[0][:, l0:l1],
-                dims=['cell_attr', 'cell'],
-            )
-
-            arrays['property'] = property_v3
-
-        if values[1] is not None:
-            # block
-            block_v3 = xr.DataArray(
-                data=values[1][:, :, l0:l1],
-                dims=['Features', 'cell_attr', 'cell'],
-            )
-
-            arrays['block'] = block_v3
-
-        if values[4] is not None:
-            # Scalar field
-            scalar_field_v3 = xr.DataArray(
-                data=values[4][:, l0:l1],
-                dims=['Features', 'cell'],
-            )
-            arrays['scalar_field'] = scalar_field_v3
-
-        if values[6] is not None:
-            # Scalar field
-            mask_v3 = xr.DataArray(
-                data=values[6][:, l0:l1],
-                dims=['Features', 'cell'],
-            )
-            arrays['mask'] = mask_v3
-
-        return arrays
-
-    def set_values_to_custom_grid(self, values: list, l0, l1,
-                                  coords_base: dict, xyz=None):
-
-        coords = coords_base
-        arrays = self.create_unstruct_xarray(values, l0, l1, xyz=None)
-
-        self.s_custom_grid = subsurface.UnstructuredData.from_array(
-            vertex=xyz,
-            cells="points",
-            cells_attr=arrays,
-            coords=coords,
-            default_cells_attr_name="block"
-        )
-
-        return self.s_custom_grid
-
-    def set_values_to_regular_grid_(self, values: list, l0, l1,
-                                    coords_base: dict):
-
-        coords = self.add_cartesian_coords(coords_base)
-
-        arrays = self.create_struc_xarrays(values, l0, l1,
-                                           self.grid.regular_grid.resolution)
-
-        self.s_regular_grid = subsurface.StructuredData.from_dict(data_dict=arrays, coords=coords)
-
-    def add_cartesian_coords(self, coords_base):
-        coords = coords_base
-        coords['X'] = self.grid.regular_grid.x
-        coords['Y'] = self.grid.regular_grid.y
-        coords['Z'] = self.grid.regular_grid.z
-        return coords
-
-    def set_values_to_topography(self,
-                                 values: list,
-                                 l0, l1,
-                                 coords_base):
-        coords = coords_base
-        coords['X'] = self.grid.topography.x
-        coords['Y'] = self.grid.topography.y
-        resolution = self.grid.topography.resolution
-        arrays = self.create_struc_xarrays(values, l0, l1, resolution)
-
-        self.s_topography = subsurface.StructuredData.from_dict(data_dict=arrays, coords=coords)
-        return self.s_topography
-
-    def set_values_to_sections(self,
-                               values: list,
-                               l0, l1,
-                               coords_base):
-        coords = coords_base
-        sections = self.grid.sections
-
-        for e, axis_coord in enumerate(sections.generate_axis_coord()):
-            resolution = sections.resolution[e]
-            l0_s = sections.length[e]
-            l1_s = sections.length[e + 1]
-            name, xy = axis_coord
-            coords['X'] = xy[:, 0]
-            coords['Y'] = xy[:, 1]
-
-            arrays = self.create_struc_xarrays(values, l0 + l0_s, l0 + l1_s, resolution)
-
-            self.s_sections[name] = subsurface.StructuredData.from_dict(data_dict=arrays, coords=coords)
-        return self.s_sections
-
-    @property
-    def data_structures(self):
-        # TODO: Add sections
-        args = [self.s_regular_grid, self.s_custom_grid, self.s_topography, self.meshes]
-        names = ['regular_grid', 'custom_grid', 'topography', 'meshes']
-        return zip(args, names)
-
-    def to_netcdf(self, path, name, **kwargs):
-        from subsurface.structs.base_structures.common_data_utils import to_netcdf
-        for a, n in self.data_structures:
-            if a is not None:
-                to_netcdf(a, f'{path}/{name}_{n}.nc', **kwargs)
+from typing import Union
+
+from gempy.core.data_modules.stack import Stack
+from gempy import Surfaces, Grid
+
+try:
+    import xarray as xr
+    import subsurface
+    from subsurface.structs.base_structures.common_data_utils import to_netcdf
+except:
+    print("Not subsurface compatibility available")
+
+
+
+import numpy as np
+import pandas as pd
+
+
+class XSolution(object):
+    """This class stores the output of the interpolation and the necessary objects
+    to visualize and manipulate this data using xarray as backend.
+
+    Depending on the activated grid (see :class:`Grid`) a different number of
+     properties are returned returned:
+
+    Args:
+        grid (Grid): [s0]
+        surfaces (Surfaces): [s1]
+        series (Series): [s2]
+
+    Attributes:
+        grid (Grid)
+        surfaces (Surfaces)
+        series (Series)
+        weights_vector (numpy.array): [s3]
+        scalar_field_at_surface_points (numpy.array): [s4]
+        block_at_surface_points (numpy.array): [s5]
+        mask_at_surface_points (numpy.array): [s6]
+        values_at_surface_points (numpy.array): [s7]
+        lith_block (numpy.array): [s8]
+        scalar_field_matrix (numpy.array): [s9]
+        block_matrix (numpy.array): [s10]
+        mask_matrix (numpy.array): [s11]
+        mask_matrix_pad (numpy.array): mask matrix padded 2 block in order to guarantee that the layers intersect each
+         other after marching cubes
+        values_matrix (numpy.array): [s12]
+        vertices (list[numpy.array]): [s13]
+        edges (list[numpy.array]): [s14]
+        geological_map (numpy.array): [s15]
+
+    """
+
+    def __init__(self, grid: Grid,
+                 surfaces: Surfaces = None,
+                 stack: Stack = None,
+                 ):
+
+        self.grid = grid
+        self.stack = stack
+        self.surfaces = surfaces  # Used to store ver/sim there
+
+        # Define xarrays
+        self.weights_vector = None
+        self.at_surface_points = None
+        self.s_regular_grid = None  # xr.Dataset()
+        self.s_custom_grid = None  # xr.Dataset()
+        self.s_topography = None  # xr.Dataset()
+        self.s_at_surface_points = None  # xr.Dataset()
+        self.s_sections = dict()
+        self.meshes = None  # xr.Dataset()
+
+    def set_meshes(self, surfaces: Surfaces = None):
+        """Create xarray from the Surfaces object. In GemPy Engine we will set
+         them directly.
+        """
+
+        surf_ver_sim = surfaces.df[['id', 'vertices', 'edges']]
+        vertex = []
+        simplex = []
+        ids = []
+        last_idx = 0
+        self.extract_each_surface_representations(ids, last_idx, simplex,
+                                                  surf_ver_sim, vertex)
+
+        vertex_array = np.concatenate(vertex)
+        simplex_array = np.concatenate(simplex)
+        ids_array = np.concatenate(ids)
+
+        self.meshes = subsurface.UnstructuredData.from_array(
+            vertex=vertex_array,
+            cells=simplex_array,
+            attributes=pd.DataFrame(ids_array, columns=['id'])
+        )
+
+        return self.meshes
+
+    @staticmethod
+    def extract_each_surface_representations(ids, last_idx, simplex,
+                                             surf_ver_sim, vertex):
+        for index, row in surf_ver_sim.iterrows():
+            v_ = row['vertices']
+            e_ = row['edges'] + last_idx
+            if v_ is not np.nan and e_ is not np.nan:
+                i_ = np.ones(e_.shape[0]) * row['id']
+                vertex.append(v_)
+                simplex.append(e_)
+                ids.append(i_)
+                last_idx = e_[-20:].max() + 1
+
+    def set_values(self,
+                   values: list,
+                   active_features=None,
+                   surf_properties=None,
+                   ):
+        """ At this stage we should split values into the different grids
+
+        Args:
+            values:
+
+        Returns:
+
+        """
+
+        # Get an array with all the indices for each grid
+        l = self.grid.length
+
+        coords_base, xyz = self.prepare_common_args(active_features,
+                                                    surf_properties)
+        self.weights_vector = values[3]
+
+        if self.grid.active_grids[0]:
+            self.set_values_to_regular_grid_(values, l[0], l[1], coords_base.copy())
+        if self.grid.active_grids[1]:
+            self.set_values_to_custom_grid(values, l[1], l[2], coords_base.copy(),
+                                           xyz=xyz)
+        if self.grid.active_grids[2]:
+            self.set_values_to_topography(values, l[2], l[3], coords_base.copy())
+        if self.grid.active_grids[3]:
+            self.set_values_to_sections(values, l[3], l[4], coords_base.copy())
+        if self.grid.active_grids[4]:
+            self.set_values_to_centered()
+
+        # TODO: Add xyz from surface points
+        self.set_values_to_surface_points_(values, l[-1], coords_base, xyz=None)
+
+    def prepare_common_args(self, active_features, surf_properties):
+        if active_features is None and self.stack is not None:
+            active_features = self.stack.df.groupby('isActive').get_group(True).index
+        if surf_properties is None and self.surfaces is not None:
+            surf_properties = self.surfaces.properties_val
+        coords_base = dict()
+        if active_features is not None:
+            coords_base['Features'] = active_features.to_list()
+        if surf_properties is not None:
+            coords_base['Properties'] = surf_properties.to_list()
+        if self.grid.custom_grid is not None:
+            xyz = self.grid.custom_grid.values
+        else:
+            xyz = None
+        return coords_base, xyz
+
+    def set_values_to_centered(self):
+        return
+
+    def set_values_to_surface_points_(self, values, l0, coords_base, xyz=None):
+        coords = coords_base
+        l1 = values[0].shape[-1]
+        arrays = self.create_unstruct_xarray(values, l0, l1, xyz)
+
+        self.s_at_surface_points = xr.Dataset(
+            data_vars=arrays,
+            coords=coords
+        )
+        return self.s_at_surface_points
+
+    @staticmethod
+    def create_struc_xarrays(values, l0, l1, res: Union[list, np.ndarray]):
+        arrays = dict()
+
+        n_dim = len(res)
+        xyz = ['X', 'Y', 'Z'][:n_dim]
+        if values[0] is not None:
+            # This encompass lith_block and values matrix
+            property_matrix = xr.DataArray(
+                data=values[0][:, l0:l1].reshape(-1, *res),
+                dims=['Properties', *xyz],
+            )
+            arrays['property_matrix'] = property_matrix
+
+        if values[1] is not None:
+            # This is the block matrix
+            i, j, _ = values[1].shape
+            block_matrix = xr.DataArray(
+                data=values[1][:, :, l0:l1].reshape(i, j, *res),
+                dims=['Features', 'Properties', *xyz],
+            )
+            arrays['block_matrix'] = block_matrix
+
+            # Fault block?
+
+        if values[4] is not None:
+            # Scalar field matrix
+            scalar_matrix = xr.DataArray(
+                data=values[4][:, l0:l1].reshape(-1, *res),
+                dims=['Features', *xyz],
+            )
+            arrays['scalar_field_matrix'] = scalar_matrix
+
+        if values[6] is not None:
+            # Mask matrix
+            mask_matrix = xr.DataArray(
+                data=values[6][:, l0:l1].reshape(-1, *res),
+                dims=['Features', *xyz],
+            )
+            arrays['mask_matrix'] = mask_matrix
+
+        if values[7] is not None:
+            # Fault mask matrix
+            fault_mask = xr.DataArray(
+                data=values[7][:, l0:l1].reshape(-1, *res),
+                dims=['Features', *xyz],
+            )
+            arrays['fault_mask'] = fault_mask
+
+        return arrays
+
+    @staticmethod
+    def create_unstruct_xarray(values, l0, l1, xyz):
+        arrays = dict()
+        if xyz is not None:
+            cartesian_matrix = xr.DataArray(
+                data=xyz,
+                dims=['Point', 'XYZ'],
+                coords={'XYZ': ['X', 'Y', 'Z']}
+            )
+            arrays['cartesian_matrix'] = cartesian_matrix
+
+        if values[0] is not None:
+            # Values and lith block
+            property_v3 = xr.DataArray(
+                data=values[0][:, l0:l1],
+                dims=['cell_attr', 'cell'],
+            )
+
+            arrays['property'] = property_v3
+
+        if values[1] is not None:
+            # block
+            block_v3 = xr.DataArray(
+                data=values[1][:, :, l0:l1],
+                dims=['Features', 'cell_attr', 'cell'],
+            )
+
+            arrays['block'] = block_v3
+
+        if values[4] is not None:
+            # Scalar field
+            scalar_field_v3 = xr.DataArray(
+                data=values[4][:, l0:l1],
+                dims=['Features', 'cell'],
+            )
+            arrays['scalar_field'] = scalar_field_v3
+
+        if values[6] is not None:
+            # Scalar field
+            mask_v3 = xr.DataArray(
+                data=values[6][:, l0:l1],
+                dims=['Features', 'cell'],
+            )
+            arrays['mask'] = mask_v3
+
+        return arrays
+
+    def set_values_to_custom_grid(self, values: list, l0, l1,
+                                  coords_base: dict, xyz=None):
+
+        coords = coords_base
+        arrays = self.create_unstruct_xarray(values, l0, l1, xyz=None)
+
+        self.s_custom_grid = subsurface.UnstructuredData.from_array(
+            vertex=xyz,
+            cells="points",
+            cells_attr=arrays,
+            coords=coords,
+            default_cells_attr_name="block"
+        )
+
+        return self.s_custom_grid
+
+    def set_values_to_regular_grid_(self, values: list, l0, l1,
+                                    coords_base: dict):
+
+        coords = self.add_cartesian_coords(coords_base)
+
+        arrays = self.create_struc_xarrays(values, l0, l1,
+                                           self.grid.regular_grid.resolution)
+
+        self.s_regular_grid = subsurface.StructuredData.from_dict(data_dict=arrays, coords=coords)
+
+    def add_cartesian_coords(self, coords_base):
+        coords = coords_base
+        coords['X'] = self.grid.regular_grid.x
+        coords['Y'] = self.grid.regular_grid.y
+        coords['Z'] = self.grid.regular_grid.z
+        return coords
+
+    def set_values_to_topography(self,
+                                 values: list,
+                                 l0, l1,
+                                 coords_base):
+        coords = coords_base
+        coords['X'] = self.grid.topography.x
+        coords['Y'] = self.grid.topography.y
+        resolution = self.grid.topography.resolution
+        arrays = self.create_struc_xarrays(values, l0, l1, resolution)
+
+        self.s_topography = subsurface.StructuredData.from_dict(data_dict=arrays, coords=coords)
+        return self.s_topography
+
+    def set_values_to_sections(self,
+                               values: list,
+                               l0, l1,
+                               coords_base):
+        coords = coords_base
+        sections = self.grid.sections
+
+        for e, axis_coord in enumerate(sections.generate_axis_coord()):
+            resolution = sections.resolution[e]
+            l0_s = sections.length[e]
+            l1_s = sections.length[e + 1]
+            name, xy = axis_coord
+            coords['X'] = xy[:, 0]
+            coords['Y'] = xy[:, 1]
+
+            arrays = self.create_struc_xarrays(values, l0 + l0_s, l0 + l1_s, resolution)
+
+            self.s_sections[name] = subsurface.StructuredData.from_dict(data_dict=arrays, coords=coords)
+        return self.s_sections
+
+    @property
+    def data_structures(self):
+        # TODO: Add sections
+        args = [self.s_regular_grid, self.s_custom_grid, self.s_topography, self.meshes]
+        names = ['regular_grid', 'custom_grid', 'topography', 'meshes']
+        return zip(args, names)
+
+    def to_netcdf(self, path, name, **kwargs):
+        for a, n in self.data_structures:
+            if a is not None:
+                to_netcdf(a, f'{path}/{name}_{n}.nc', **kwargs)
```

### Comparing `gempy-2.2b10.dev1/gempy/gempy_api.py` & `gempy-2.3.0/gempy/gempy_api.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,397 +1,397 @@
-"""
-This file is part of gempy.
-
-gempy is free software. For license details, see the LICENSE.md file supplied
- with gempy
-
-Created on 10/10 /2018
-
-@author: Miguel de la Varga
-"""
-
-import numpy as np
-import pandas as pn
-from numpy import ndarray
-from typing import Union
-import warnings
-from gempy.core.model import Project
-from gempy.core.solution import Solution
-from gempy.utils.meta import _setdoc, _setdoc_pro
-
-
-# region get
-def get():
-    pass
-
-
-# endregion
-
-# region edit
-def edit(model: Project,  method: str, data_object: str = None, **kwargs):
-    """Function to edit any of the data_objects of gempy. Check
-        https://www.gempy.org/documentation data for documentation.
-
-    Args:
-        model (Project):
-        data_object (str): Object that you want to edit
-        method (str): Method you want to use
-        **kwargs:
-    """
-    if data_object is not None:
-        data_object = getattr(model, '_' + data_object)
-    else:
-        data_object = model
-    m = getattr(data_object, method)
-    return m(**kwargs)
-
-
-# endregion
-
-
-# region mapping
-@_setdoc_pro(Project.__doc__)
-def map_series_to_surfaces(geo_model: Project, mapping_object: Union[dict, pn.Categorical] = None,
-                           set_series=True, sort_geometric_data: bool = True, remove_unused_series=True):
-    """Mapping which surfaces belongs to which geological feature
-
-    Args:
-        geo_model (:class:`gempy.core.model.Project`): [s0]
-        mapping_object: [s_mapping_object]
-        set_series (bool): If True set missing series from the mapping object
-        sort_geometric_data (bool): If True sort the geometric_data according to the new
-         order of the stack
-        remove_unused_series(bool):
-
-    Returns
-        :class:`gempy.core.data.Surfaces`
-    """
-    warnings.warn('Series is going to get renamed to Stack. Please use'
-                  '`map_stack_to_surfaces` instead.', DeprecationWarning)
-
-    geo_model.map_stack_to_surfaces(mapping_object, set_series, sort_geometric_data, remove_unused_series)
-    return geo_model._surfaces
-
-
-@_setdoc_pro(Project.__doc__)
-def map_stack_to_surfaces(geo_model: Project, mapping_object: Union[dict, pn.Categorical] = None,
-                          set_features=True, sort_geometric_data: bool = True, remove_unused_series=True):
-    """Mapping which surfaces belongs to which geological feature
-
-    Args:
-        geo_model (:class:`gempy.core.model.Project`): [s0]
-        mapping_object: [s_mapping_object]
-        set_features (bool): If True set missing features from the mapping object
-        sort_geometric_data (bool): If True sort the geometric_data according to the new
-         order of the stack
-        remove_unused_series(bool):
-
-    Returns
-        :class:`gempy.core.data.Surfaces`
-    """
-
-    geo_model.map_stack_to_surfaces(mapping_object, set_features, sort_geometric_data, remove_unused_series)
-    return geo_model._surfaces
-
-# endregion
-
-
-# region create
-def create_model(project_name='default_project') -> Project:
-    """Create a Project object.
-
-    Args:
-        project_name (str): Name of the project
-
-    Returns:
-        :class:`gempy.core.model.Project`
-
-    See Also:
-        :class:`gempy.core.model.Project`
-
-    Notes:
-        TODO: Adding saving address
-    """
-    return Project(project_name)
-
-
-def create_data(project_name: str = 'default_project',
-                extent: Union[list, ndarray] = None,
-                resolution: Union[list, ndarray] = None,
-                **kwargs) -> Project:
-    """Create a :class:`gempy.core.model.Project` object and initialize some of
-    the main functions such as:
-
-    - Grid :class:`gempy.core.data.GridClass`: To regular grid.
-    - read_csv: SurfacePoints and orientations: From csv files
-    - set_values to default
-
-
-
-    Args:
-        project_name (str):
-        extent (list or array): [x_min, x_max, y_min, y_max, z_min, z_max].
-            Extent for the visualization of data and default of for the grid
-            class.
-        resolution (list or array): [nx, ny, nz]. Resolution for the
-            visualization of data and default of for the grid class.
-        **kwargs:
-
-    Keyword:
-        path_i: Path to the data bases of surface_points. Default os.getcwd(),
-        path_o: Path to the data bases of orientations. Default os.getcwd()
-
-    Returns:
-        :class:`Project`
-    """
-
-    geo_model = create_model(project_name)
-    return init_data(geo_model, extent=extent, resolution=resolution,
-                     project_name=project_name, **kwargs)
-
-
-# TODO We need to decide how to initialize a model. Having create_data and init
-#  data  does not seem too robust
-@_setdoc_pro([Project.__doc__])
-def init_data(geo_model: Project, extent: Union[list, ndarray] = None,
-              resolution: Union[list, ndarray] = None,
-              **kwargs) -> Project:
-    """Initialize some of the main functions such as:
-
-     - Regular grid (:class:`gempy.core.data.Grid`).
-     - read_csv: :class:`gempy.core.data_modules.geometric_data.SurfacePoints`
-       and :class:`gempy.core.data_modules.geometric_data.Orientations` From csv files
-     - set_values to default
-
-    Args:
-        geo_model (Project): [s0]
-        extent: [s_extent]
-        resolution: [s_resolution]
-
-    Keyword Args:
-        path_i: [s_path_i]
-        path_o: [s_path_o]
-        surface_points_df: [s_surface_points_df]
-        orientations_df: [s_orientations_df]
-    Returns:
-        :class:`gempy.core.model.Project`
-    """
-
-    if extent is None or resolution is None:
-        warnings.warn('Regular grid won\'t be initialize, you will have to create a gridafterwards. See gempy.set_grid')
-    else:
-        geo_model.set_regular_grid(extent, resolution)
-
-    if 'path_i' in kwargs or 'path_o' in kwargs:
-        read_csv(geo_model, **kwargs)
-
-    if 'surface_points_df' in kwargs:
-        geo_model.set_surface_points(kwargs['surface_points_df'], **kwargs)
-        # if we set the surfaces names with surfaces they cannot be set again on orientations or pandas will complain.
-        kwargs['update_surfaces'] = False
-    if 'orientations_df' in kwargs:
-        geo_model.set_orientations(kwargs['orientations_df'], **kwargs)
-
-    return geo_model
-
-
-# endregion
-
-
-# If everything works out properly update. Should happen automatically. Therefore
-# we will keep it just as a method
-# region update
-def update_additional_data(model: Project, update_structure=True, update_kriging=True):
-    """
-    Args:
-        model (Project):
-        update_structure:
-        update_kriging:
-    """
-    warnings.warn('This function is going to be deprecated. Use Project.update_additional_data instead',
-                  DeprecationWarning)
-    return model.update_additional_data(update_structure, update_kriging)
-
-
-# endregion
-
-
-# region io
-# @_setdoc([Project.read_data.__doc__])
-def read_csv(geo_model: Project, path_i=None, path_o=None, **kwargs):
-    """
-    Args:
-        geo_model (Project):
-        path_i:
-        path_o:
-        **kwargs:
-    """
-    if path_i is not None or path_o is not None:
-        try:
-            geo_model.read_data(path_i, path_o, **kwargs)
-        except KeyError as e:
-            raise KeyError('Loading of CSV file failed. Check if you use commas '
-                           'to separate your data.' + str(e))
-    return True
-
-
-# endregion
-
-
-# region Computing the model
-@_setdoc_pro([Project.__doc__, Solution.compute_marching_cubes_regular_grid.__doc__,
-              Project.set_surface_order_from_solution.__doc__])
-def compute_model(model: Project, output=None, at: np.ndarray = None, compute_mesh=True,
-                  reset_weights=False, reset_scalar=False,
-                  reset_block=False, sort_surfaces=True,
-                  debug=False, set_solutions=True,
-                  **kwargs) -> Solution:
-    """Computes the geological model and any extra output given in the
-    additional data option.
-
-    Args:
-        model (Project): [s0]
-        output (str {'geology', 'gravity'}): Compute the lithologies or gravity
-        at (np.ndarray):
-        compute_mesh (bool): if True compute marching cubes: [s1]
-        reset_weights (bool): Not Implemented
-        reset_scalar (bool): Not Implemented
-        reset_block (bool): Not Implemented
-        sort_surfaces (bool): if True call
-            Project.set_surface_order_from_solution: [s2]
-        debug (bool): if True, the computed interpolation are not stored in any
-            object but instead returned
-        set_solutions (bool): Default True. If True set the results into the
-            :class:`Solutions` linked object.
-        **kwargs:
-
-    Keyword Args:
-        compute_mesh_options (dict): options for the marching cube function. 1)
-            rescale: True
-
-    Returns:
-        :class:`Solutions`
-    """
-
-    # Check config
-    # ------------
-    _check_valid_model_input(model)
-
-    if output is not None:
-        warnings.warn('Argument output has no effect anymore and will be deprecated in GemPy 2.2.'
-                      'Set the output only in gempy.set_interpolator.', DeprecationWarning, )
-    if at is not None:
-        model._grid.deactivate_all_grids()
-        model.set_custom_grid(at)
-
-    # ------------
-
-    i = model._interpolator.get_python_input_block(append_control=True, fault_drift=None)
-    model._interpolator.reset_flow_control_initial_results(reset_weights, reset_scalar, reset_block)
-
-    sol = model._interpolator.theano_function(*i)
-
-    if debug is True or set_solutions is False:
-        return sol
-
-    elif set_solutions is True:
-
-        model.solutions.set_solutions(
-            sol,
-            compute_mesh,
-            sort_surfaces,
-            **kwargs)
-
-        if sort_surfaces:
-            model.set_surface_order_from_solution()
-        return model.solutions
-
-
-def _check_valid_model_input(model):
-    if model._interpolator.theano_function is None:
-        raise ValueError('You need to compile graph before. '
-                         'See `gempy.set_interpolator`.')
-    if model._additional_data.structure_data.df.loc[
-        'values', 'len surfaces surface_points'].min() < 1:
-        raise ValueError('To compute the model is necessary at least 2 interface '
-                         'points per layer')
-    if len(model._interpolator.len_series_i) != len(
-        model._interpolator.len_series_o):
-        raise ValueError('Every Series/Fault need at least 1 orientation and 2 '
-                         'surfaces points.')
-    is_basement_in_sp = model._surfaces.basement.isin(
-        model._surface_points.df['surface']).any()
-    is_basement_in_ori = model._surfaces.basement.isin(
-        model._orientations.df['surface']).any()
-
-    if is_basement_in_ori or is_basement_in_sp:
-        raise ValueError('There are surface points or orientations assigned to the '
-                         'Surface defined as basement (bottom of the stack). The '
-                         'basement surface only refers to the volume below the last '
-                         'surface and is not supposed to be interpolated. '
-                         'Add a "basement" surface (`model.add_surface("basement")`)'
-                         ' or delete the discordant surface points or orientations')
-
-    last_feature_is_fault = model._stack.df['BottomRelation'].last == 'fault'
-    if last_feature_is_fault:
-        raise ValueError('Last feature of the stack should not be a fault. '
-                         'Reorder the stack using geo_model.reorder_features(List)')
-
-
-def compute_model_at(new_grid: Union[ndarray], model: Project, **kwargs):
-    """This function creates a new custom grid and deactivate all the other
-    grids and compute the model there:
-
-    This function does the same as  plus the addition functionality of
-        :func:`compute_model`
-        passing a given array of points where evaluate the model instead of
-        using the :class:`gempy.core.data.GridClass`.
-
-    Args:
-        new_grid:
-        model (Project):
-        kwargs: :func:`compute_model` arguments
-
-    Returns:
-        :class:`Solution`
-    """
-    # #TODO create backup of the mesh and a method to go back to it
-    #     set_grid(model, Grid('custom_grid', custom_grid=new_grid))
-    warnings.warn('compute_model_at will be deprecated.'
-                  'Use argument `at` in compute_model instead', DeprecationWarning)
-    model._grid.deactivate_all_grids()
-    model.set_custom_grid(new_grid)
-
-    # Now we are good to compute the model again only in the new point
-    sol = compute_model(model, set_solutions=False, **kwargs)
-    return sol
-
-# endregion
-
-
-# region activate
-@_setdoc_pro([Project.__doc__], )
-def activate_interactive_df(geo_model: Project, plot_object=None):
-    """Experimental: Activate the use of the QgridProjectIntegration: TODO
-    evaluate the use of this functionality
-
-    Notes: Since this feature is for advance levels we will keep only object
-    oriented functionality. Should we add in the future,
-
-    TODO: copy docstrings to QgridModelIntegration :param geo_model: [s0]
-    :param plot_object: GemPy plot object (so far only vtk is available)
-
-    Args:
-        geo_model (Project):
-        plot_object:
-
-    Returns:
-        :class:`QgridModelIntegration`
-    """
-    try:
-        from gempy.core.qgrid_integration import QgridModelIntegration
-    except ImportError:
-        raise ImportError('qgrid package is not installed. No interactive dataframes available.')
-    geo_model.qi = QgridModelIntegration(geo_model, plot_object)
-    return geo_model.qi
-# endregion
-
+"""
+This file is part of gempy.
+
+gempy is free software. For license details, see the LICENSE.md file supplied
+ with gempy
+
+Created on 10/10 /2018
+
+@author: Miguel de la Varga
+"""
+
+import numpy as np
+import pandas as pn
+from numpy import ndarray
+from typing import Union
+import warnings
+from gempy.core.model import Project
+from gempy.core.solution import Solution
+from gempy.utils.meta import _setdoc, _setdoc_pro
+
+
+# region get
+def get():
+    pass
+
+
+# endregion
+
+# region edit
+def edit(model: Project,  method: str, data_object: str = None, **kwargs):
+    """Function to edit any of the data_objects of gempy. Check
+        https://www.gempy.org/documentation data for documentation.
+
+    Args:
+        model (Project):
+        data_object (str): Object that you want to edit
+        method (str): Method you want to use
+        **kwargs:
+    """
+    if data_object is not None:
+        data_object = getattr(model, '_' + data_object)
+    else:
+        data_object = model
+    m = getattr(data_object, method)
+    return m(**kwargs)
+
+
+# endregion
+
+
+# region mapping
+@_setdoc_pro(Project.__doc__)
+def map_series_to_surfaces(geo_model: Project, mapping_object: Union[dict, pn.Categorical] = None,
+                           set_series=True, sort_geometric_data: bool = True, remove_unused_series=True):
+    """Mapping which surfaces belongs to which geological feature
+
+    Args:
+        geo_model (:class:`gempy.core.model.Project`): [s0]
+        mapping_object: [s_mapping_object]
+        set_series (bool): If True set missing series from the mapping object
+        sort_geometric_data (bool): If True sort the geometric_data according to the new
+         order of the stack
+        remove_unused_series(bool):
+
+    Returns
+        :class:`gempy.core.data.Surfaces`
+    """
+    warnings.warn('Series is going to get renamed to Stack. Please use'
+                  '`map_stack_to_surfaces` instead.', DeprecationWarning)
+
+    geo_model.map_stack_to_surfaces(mapping_object, set_series, sort_geometric_data, remove_unused_series)
+    return geo_model._surfaces
+
+
+@_setdoc_pro(Project.__doc__)
+def map_stack_to_surfaces(geo_model: Project, mapping_object: Union[dict, pn.Categorical] = None,
+                          set_features=True, sort_geometric_data: bool = True, remove_unused_series=True):
+    """Mapping which surfaces belongs to which geological feature
+
+    Args:
+        geo_model (:class:`gempy.core.model.Project`): [s0]
+        mapping_object: [s_mapping_object]
+        set_features (bool): If True set missing features from the mapping object
+        sort_geometric_data (bool): If True sort the geometric_data according to the new
+         order of the stack
+        remove_unused_series(bool):
+
+    Returns
+        :class:`gempy.core.data.Surfaces`
+    """
+
+    geo_model.map_stack_to_surfaces(mapping_object, set_features, sort_geometric_data, remove_unused_series)
+    return geo_model._surfaces
+
+# endregion
+
+
+# region create
+def create_model(project_name='default_project') -> Project:
+    """Create a Project object.
+
+    Args:
+        project_name (str): Name of the project
+
+    Returns:
+        :class:`gempy.core.model.Project`
+
+    See Also:
+        :class:`gempy.core.model.Project`
+
+    Notes:
+        TODO: Adding saving address
+    """
+    return Project(project_name)
+
+
+def create_data(project_name: str = 'default_project',
+                extent: Union[list, ndarray] = None,
+                resolution: Union[list, ndarray] = None,
+                **kwargs) -> Project:
+    """Create a :class:`gempy.core.model.Project` object and initialize some of
+    the main functions such as:
+
+    - Grid :class:`gempy.core.data.GridClass`: To regular grid.
+    - read_csv: SurfacePoints and orientations: From csv files
+    - set_values to default
+
+
+
+    Args:
+        project_name (str):
+        extent (list or array): [x_min, x_max, y_min, y_max, z_min, z_max].
+            Extent for the visualization of data and default of for the grid
+            class.
+        resolution (list or array): [nx, ny, nz]. Resolution for the
+            visualization of data and default of for the grid class.
+        **kwargs:
+
+    Keyword:
+        path_i: Path to the data bases of surface_points. Default os.getcwd(),
+        path_o: Path to the data bases of orientations. Default os.getcwd()
+
+    Returns:
+        :class:`Project`
+    """
+
+    geo_model = create_model(project_name)
+    return init_data(geo_model, extent=extent, resolution=resolution,
+                     project_name=project_name, **kwargs)
+
+
+# TODO We need to decide how to initialize a model. Having create_data and init
+#  data  does not seem too robust
+@_setdoc_pro([Project.__doc__])
+def init_data(geo_model: Project, extent: Union[list, ndarray] = None,
+              resolution: Union[list, ndarray] = None,
+              **kwargs) -> Project:
+    """Initialize some of the main functions such as:
+
+     - Regular grid (:class:`gempy.core.data.Grid`).
+     - read_csv: :class:`gempy.core.data_modules.geometric_data.SurfacePoints`
+       and :class:`gempy.core.data_modules.geometric_data.Orientations` From csv files
+     - set_values to default
+
+    Args:
+        geo_model (Project): [s0]
+        extent: [s_extent]
+        resolution: [s_resolution]
+
+    Keyword Args:
+        path_i: [s_path_i]
+        path_o: [s_path_o]
+        surface_points_df: [s_surface_points_df]
+        orientations_df: [s_orientations_df]
+    Returns:
+        :class:`gempy.core.model.Project`
+    """
+
+    if extent is None or resolution is None:
+        warnings.warn('Regular grid won\'t be initialized, you will have to create a grid afterwards. See gempy.set_grid')
+    else:
+        geo_model.set_regular_grid(extent, resolution)
+
+    if 'path_i' in kwargs or 'path_o' in kwargs:
+        read_csv(geo_model, **kwargs)
+
+    if 'surface_points_df' in kwargs:
+        geo_model.set_surface_points(kwargs['surface_points_df'], **kwargs)
+        # if we set the surfaces names with surfaces they cannot be set again on orientations or pandas will complain.
+        kwargs['update_surfaces'] = False
+    if 'orientations_df' in kwargs:
+        geo_model.set_orientations(kwargs['orientations_df'], **kwargs)
+
+    return geo_model
+
+
+# endregion
+
+
+# If everything works out properly update. Should happen automatically. Therefore
+# we will keep it just as a method
+# region update
+def update_additional_data(model: Project, update_structure=True, update_kriging=True):
+    """
+    Args:
+        model (Project):
+        update_structure:
+        update_kriging:
+    """
+    warnings.warn('This function is going to be deprecated. Use Project.update_additional_data instead',
+                  DeprecationWarning)
+    return model.update_additional_data(update_structure, update_kriging)
+
+
+# endregion
+
+
+# region io
+# @_setdoc([Project.read_data.__doc__])
+def read_csv(geo_model: Project, path_i=None, path_o=None, **kwargs):
+    """
+    Args:
+        geo_model (Project):
+        path_i:
+        path_o:
+        **kwargs:
+    """
+    if path_i is not None or path_o is not None:
+        try:
+            geo_model.read_data(path_i, path_o, **kwargs)
+        except KeyError as e:
+            raise KeyError('Loading of CSV file failed. Check if you use commas '
+                           'to separate your data.' + str(e))
+    return True
+
+
+# endregion
+
+
+# region Computing the model
+@_setdoc_pro([Project.__doc__, Solution.compute_marching_cubes_regular_grid.__doc__,
+              Project.set_surface_order_from_solution.__doc__])
+def compute_model(model: Project, output=None, at: np.ndarray = None, compute_mesh=True,
+                  reset_weights=False, reset_scalar=False,
+                  reset_block=False, sort_surfaces=True,
+                  debug=False, set_solutions=True,
+                  **kwargs) -> Solution:
+    """Computes the geological model and any extra output given in the
+    additional data option.
+
+    Args:
+        model (Project): [s0]
+        output (str {'geology', 'gravity'}): Compute the lithologies or gravity
+        at (np.ndarray):
+        compute_mesh (bool): if True compute marching cubes: [s1]
+        reset_weights (bool): Not Implemented
+        reset_scalar (bool): Not Implemented
+        reset_block (bool): Not Implemented
+        sort_surfaces (bool): if True call
+            Project.set_surface_order_from_solution: [s2]
+        debug (bool): if True, the computed interpolation are not stored in any
+            object but instead returned
+        set_solutions (bool): Default True. If True set the results into the
+            :class:`Solutions` linked object.
+        **kwargs:
+
+    Keyword Args:
+        compute_mesh_options (dict): options for the marching cube function. 1)
+            rescale: True
+
+    Returns:
+        :class:`Solutions`
+    """
+
+    # Check config
+    # ------------
+    _check_valid_model_input(model)
+
+    if output is not None:
+        warnings.warn('Argument output has no effect anymore and will be deprecated in GemPy 2.2.'
+                      'Set the output only in gempy.set_interpolator.', DeprecationWarning, )
+    if at is not None:
+        model._grid.deactivate_all_grids()
+        model.set_custom_grid(at)
+
+    # ------------
+
+    i = model._interpolator.get_python_input_block(append_control=True, fault_drift=None)
+    model._interpolator.reset_flow_control_initial_results(reset_weights, reset_scalar, reset_block)
+
+    sol = model._interpolator.aesara_function(*i)
+
+    if debug is True or set_solutions is False:
+        return sol
+
+    elif set_solutions is True:
+
+        model.solutions.set_solutions(
+            sol,
+            compute_mesh,
+            sort_surfaces,
+            **kwargs)
+
+        if sort_surfaces:
+            model.set_surface_order_from_solution()
+        return model.solutions
+
+
+def _check_valid_model_input(model):
+    if model._interpolator.aesara_function is None:
+        raise ValueError('You need to compile graph before. '
+                         'See `gempy.set_interpolator`.')
+    if model._additional_data.structure_data.df.loc[
+        'values', 'len surfaces surface_points'].min() < 1:
+        raise ValueError('To compute the model is necessary at least 2 interface '
+                         'points per layer')
+    if len(model._interpolator.len_series_i) != len(
+        model._interpolator.len_series_o):
+        raise ValueError('Every Series/Fault need at least 1 orientation and 2 '
+                         'surfaces points.')
+    is_basement_in_sp = model._surfaces.basement.isin(
+        model._surface_points.df['surface']).any()
+    is_basement_in_ori = model._surfaces.basement.isin(
+        model._orientations.df['surface']).any()
+
+    if is_basement_in_ori or is_basement_in_sp:
+        raise ValueError('There are surface points or orientations assigned to the '
+                         'Surface defined as basement (bottom of the stack). The '
+                         'basement surface only refers to the volume below the last '
+                         'surface and is not supposed to be interpolated. '
+                         'Add a "basement" surface (`model.add_surface("basement")`)'
+                         ' or delete the discordant surface points or orientations')
+
+    last_feature_is_fault = model._stack.df['BottomRelation'].last == 'fault'
+    if last_feature_is_fault:
+        raise ValueError('Last feature of the stack should not be a fault. '
+                         'Reorder the stack using geo_model.reorder_features(List)')
+
+
+def compute_model_at(new_grid: Union[ndarray], model: Project, **kwargs):
+    """This function creates a new custom grid and deactivate all the other
+    grids and compute the model there:
+
+    This function does the same as  plus the addition functionality of
+        :func:`compute_model`
+        passing a given array of points where evaluate the model instead of
+        using the :class:`gempy.core.data.GridClass`.
+
+    Args:
+        new_grid:
+        model (Project):
+        kwargs: :func:`compute_model` arguments
+
+    Returns:
+        :class:`Solution`
+    """
+    # #TODO create backup of the mesh and a method to go back to it
+    #     set_grid(model, Grid('custom_grid', custom_grid=new_grid))
+    warnings.warn('compute_model_at will be deprecated.'
+                  'Use argument `at` in compute_model instead', DeprecationWarning)
+    model._grid.deactivate_all_grids()
+    model.set_custom_grid(new_grid)
+
+    # Now we are good to compute the model again only in the new point
+    sol = compute_model(model, set_solutions=False, **kwargs)
+    return sol
+
+# endregion
+
+
+# region activate
+@_setdoc_pro([Project.__doc__], )
+def activate_interactive_df(geo_model: Project, plot_object=None):
+    """Experimental: Activate the use of the QgridProjectIntegration: TODO
+    evaluate the use of this functionality
+
+    Notes: Since this feature is for advance levels we will keep only object
+    oriented functionality. Should we add in the future,
+
+    TODO: copy docstrings to QgridModelIntegration :param geo_model: [s0]
+    :param plot_object: GemPy plot object (so far only vtk is available)
+
+    Args:
+        geo_model (Project):
+        plot_object:
+
+    Returns:
+        :class:`QgridModelIntegration`
+    """
+    try:
+        from gempy.core.qgrid_integration import QgridModelIntegration
+    except ImportError:
+        raise ImportError('qgrid package is not installed. No interactive dataframes available.')
+    geo_model.qi = QgridModelIntegration(geo_model, plot_object)
+    return geo_model.qi
+# endregion
+
```

### Comparing `gempy-2.2b10.dev1/gempy/plot/_plot.py` & `gempy-2.3.0/gempy/plot/_plot.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,425 +1,425 @@
-"""
-    This file is part of gempy.
-
-    gempy is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    gempy is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
-
-    Module with classes and methods to perform implicit regional modelling based on
-    the potential field method.
-    Tested on Ubuntu 16
-
-    Created on 10/04/2018
-
-    @author: Elisa Heim, Miguel de la Varga
-"""
-
-# This is for sphenix to find the packages
-# sys.path.append( path.dirname( path.dirname( path.abspath(__file__) ) ) )
-
-from typing import Set, Tuple, Dict, Union
-import gempy as _gempy
-from ._visualization_2d import PlotData2D, PlotSolution
-from .visualization_3d import GemPyvtkInteract
-
-
-def plot_data_3D(geo_data, ve=1, **kwargs):
-    """
-    Plot in vtk all the input data of a model
-    Args:
-        geo_data (gempy.DataManagement.InputData): Input data of the model
-
-    Returns:
-        None
-    """
-    vv = GemPyvtkInteract(geo_data, ve=ve, **kwargs)
-    # vv.restart()
-    vv.set_surface_points()
-    vv.set_orientations()
-    vv.render_model(**kwargs)
-
-    return vv
-
-
-def plot_3D(geo_model, render_surfaces=True, render_data=True,
-            render_topography=True,
-            real_time=False, **kwargs):
-    """
-        Plot in vtk all the input data of a model
-        Args:
-            geo_model (gempy.DataManagement.InputData): Input data of the model
-
-        Returns:
-            None
-        """
-    vv = GemPyvtkInteract(geo_model, real_time=real_time, **kwargs)
-    # vv.restart()
-    if render_data is True:
-        vv.set_surface_points()
-        vv.set_orientations()
-    if render_surfaces is True:
-        vv.set_surfaces(geo_model._surfaces)
-    if render_topography is True and geo_model._grid.topography is not None:
-        vv.set_topography()
-
-    vv.render_model(**kwargs)
-
-    return vv
-
-
-def export_to_vtk(geo_data, path=None, name=None, voxels=True, block=None, surfaces=True):
-    """
-      Export data to a vtk file for posterior visualizations
-
-      Args:
-          geo_data(:class:`Model`)
-          path(str): path to the location of the vtk
-          name(str): Name of the files. Default name: Default
-          voxels(bool): if True export lith_block
-          block(Optional[np.array]): One of the solutions of the regular grid. This can be used if for
-           example you want to export an scalar field or an specific series block. If None is passed, lith_block
-           will be exported.
-          surfaces(bool): If True, export the polydata surfaces.
-
-      Returns:
-          None
-      """
-
-    if voxels is True:
-        GemPyvtkInteract.export_vtk_lith_block(geo_data, lith_block=block,
-                                               path=path)
-    if surfaces is True:
-        geo_data.solutions.compute_all_surfaces()
-        ver, sim = _gempy.get_surfaces(geo_data)
-        GemPyvtkInteract.export_vtk_surfaces(geo_data, ver, sim, path=path,
-                                             name=name)
-    return True
-
-
-def plot_data(geo_data, direction="y", data_type='all', series="all",
-              show_legend=True, **kwargs):
-    """
-    Plot the projection of the raw data (surface_points and orientations) in 2D following a
-    specific directions
-
-    Args:
-        direction(str): xyz. Caartesian direction to be plotted
-        series(str): series to plot
-        ve(float): Vertical exageration
-        **kwargs: seaborn lmplot key arguments. (TODO: adding the link to them)
-
-    Returns:
-        None
-    """
-    plot = PlotData2D(geo_data)
-    p = plot.plot_data(direction=direction, data_type=data_type, series=series,
-                       show_legend=show_legend, **kwargs)
-    # TODO saving options
-    return plot
-
-
-def plot_stereonet(geo_data, litho=None, planes=True, poles=True,
-                   single_plots=False,
-                   show_density=False):
-    '''
-    Plot an equal-area projection of the orientations dataframe using mplstereonet.
-
-    Args:
-        geo_model (gempy.DataManagement.InputData): Input data of the model
-        series_only: To select whether a stereonet is plotted perries or per formation
-        litho: selection of formation or series names, as list. If None, all are plotted
-        planes: If True, azimuth and dip are plotted as great circles
-        poles: If True, pole points (plane normal vectors) of azimuth and dip are plotted
-        single_plots: If True, each formation is plotted in a single stereonet
-        show_density: If True, density contour plot around the pole points is shown
-
-    Returns:
-        None
-    '''
-
-    plot = PlotData2D(geo_data)
-    plot.plot_stereonet(litho=litho, planes=planes, poles=poles,
-                        single_plots=single_plots,
-                        show_density=show_density)
-
-
-def plot_map(model, contour_lines=True, show_data=True, show_hillshades: bool = False, figsize=(12, 12), **kwargs):
-    """
-
-    Args:
-        figsize:
-        show_hillshades:
-        model:
-        contour_lines:
-        show_faults:
-        show_data:
-        **kwargs
-
-    Returns:
-
-    """
-    plot = PlotSolution(model)
-    plot.plot_map(contour_lines=contour_lines, show_data=show_data, show_hillshades=show_hillshades,
-                  figsize=figsize, **kwargs)
-
-
-def plot_section_traces(model, section_names=None, contour_lines=False,
-                        show_data=True, show_all_data=False):
-    """
-
-    Args:
-        model:
-        show_data:
-        section_names:
-        contour_lines:
-
-    Returns:
-
-    """
-    plot = PlotSolution(model)
-    if plot.model.solutions.geological_map is not None:
-        plot.plot_map(contour_lines=contour_lines, show_data=show_data,
-                      show_all_data=show_all_data)
-    # else:
-    # fig = plt.figure()
-    # plt.title('Section traces, z direction')
-
-    plot.plot_section_traces(show_data=show_data, section_names=section_names,
-                             contour_lines=contour_lines,
-                             show_all_data=show_all_data)
-
-
-"""
-def plot_predef_sections(model, show_traces=True, show_data=False, section_names=None, show_faults=True,
-                         show_topo=True, figsize=(12, 12)):
-
-
-    Args:
-        model:
-        show_traces:
-        show_data:
-        section_names:
-        show_faults:
-        show_topo:
-        figsize:
-
-    Returns:
-
-
-    plot = PlotSolution(model)
-    plot.plot_sections(show_traces=show_traces, show_data=show_data, section_names=section_names,
-                       show_faults=show_faults, show_topo=show_topo, figsize=figsize)
-
-"""
-
-
-def plot_section_by_name(model, section_name, show_faults=True, show_topo=True,
-                         show_data=True,
-                         show_all_data=False, radius='default',
-                         contourplot=True):
-    # Todo needs more keywords:
-    ### if show_data: radius, data_type
-    plot = PlotSolution(model)
-    plot.plot_section_by_name(section_name=section_name, show_topo=show_topo,
-                              show_faults=show_faults,
-                              show_data=show_data, show_all_data=show_all_data,
-                              radius=radius, contourplot=contourplot)
-
-
-def plot_all_sections(model, show_data=False, section_names=None,
-                      show_topo=True, figsize=(12, 12)):
-    plot = PlotSolution(model)
-    plot.plot_all_sections(show_data=show_data, section_names=section_names,
-                           show_topo=show_topo,
-                           figsize=figsize)
-
-
-def plot_section(model, cell_number=13, block=None, direction="y",
-                 interpolation='none',
-                 show_data=True, show_faults=True, show_topo=False,
-                 block_type=None, ve=1,
-                 show_all_data=False, show_legend=True, **kwargs):
-    """
-    Plot a section of the block model
-
-    Args:
-        cell_number(int): position of the array to plot
-        direction(str): xyz. Caartesian direction to be plotted
-        interpolation(str): Type of interpolation of plt.imshow. Default 'none'.  Acceptable values are 'none'
-        ,'nearest', 'bilinear', 'bicubic',
-        'spline16', 'spline36', 'hanning', 'hamming', 'hermite', 'kaiser',
-        'quadric', 'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc',
-        'lanczos'
-        ve(float): Vertical exageration
-        **kwargs: imshow keywargs
-
-    Returns:
-        None
-    """
-    plot = PlotSolution(model)
-    plot.fig = plot.plot_block_section(model.solutions, cell_number, block,
-                                       direction, interpolation,
-                                       show_data, show_faults, show_topo,
-                                       block_type, ve,
-                                       show_all_data=show_all_data,
-                                       show_legend=show_legend, **kwargs)
-    return plot
-
-
-def plot_scalar_field(model, cell_number, N=20,
-                      direction="y", block=None, alpha=0.6, show_data=True,
-                      show_all_data=False, series=0, *args, **kwargs):
-    """
-    Plot a potential field in a given direction.
-
-    Args:
-        cell_number(int): position of the array to plot
-        potential_field(str): name of the potential field (or series) to plot
-        n_pf(int): number of the  potential field (or series) to plot
-        direction(str): xyz. Caartesian direction to be plotted
-        serie: *Deprecated*
-        **kwargs: plt.contour kwargs
-
-    Returns:
-        None
-    """
-    plot = PlotSolution(model)
-    if block is not None:
-        block = block
-    else:
-        block = model.solutions
-
-    plot.plot_scalar_field(block, cell_number, N=N,
-                           direction=direction, show_data=show_data,
-                           series=series, alpha=alpha,
-                           show_all_data=show_all_data,
-                           *args, **kwargs)
-
-
-def plot_section_scalarfield(model, section_name, sn, levels=50,
-                             show_faults=True, show_topo=True, lithback=True):
-    """
-    Plot the potential field in the predefined sections.
-    Args:
-        model:
-        section_name: name of the section
-        sn: scalar field number, order like in model.series
-        levels: number of isolines you want to plot
-        show_faults: whether or not faults should be plotted
-        show_topo: whether or not the topography should be plotted
-        lithback: lithology background
-
-    Returns:
-        None
-    """
-    plot = PlotSolution(model)
-    plot.plot_section_scalarfield(section_name=section_name, sn=sn,
-                                  levels=levels, show_faults=show_faults,
-                                  show_topo=show_topo, lithback=lithback)
-
-
-def plot_gradient(geo_data, scalar_field, gx, gy, gz, cell_number, q_stepsize=5,
-                  direction="y", plot_scalar=True, **kwargs):
-    """
-        Plot the gradient of the scalar field in a given direction.
-
-        Args:
-            geo_data (gempy.DataManagement.InputData): Input data of the model
-            scalar_field(numpy.array): scalar field to plot with the gradient
-            gx(numpy.array): gradient in x-direction
-            gy(numpy.array): gradient in y-direction
-            gz(numpy.array): gradient in z-direction
-            cell_number(int): position of the array to plot
-            q_stepsize(int): step size between arrows to indicate gradient
-            direction(str): xyz. Caartesian direction to be plotted
-            plot_scalar(bool): boolean to plot scalar field
-            **kwargs: plt.contour kwargs
-
-        Returns:
-            None
-    """
-    plot = PlotSolution(geo_data)
-    plot.plot_gradient(scalar_field, gx, gy, gz, cell_number,
-                       q_stepsize=q_stepsize,
-                       direction=direction, plot_scalar=plot_scalar,
-                       **kwargs)
-
-
-def plot_topology(
-        geo_model,
-        edges: Set[Tuple[int, int]],
-        centroids: Dict,
-        direction: Union["x", "y", "z"] = "y",
-        scale: bool = True,
-        label_kwargs: dict = None,
-        edge_kwargs: dict = None
-):
-    """Plot the topology adjacency graph in 2-D.
-
-    Args:
-        geo_model ([type]): GemPy geomodel instance.
-        edges (Set[Tuple[int, int]]): Set of topology edges.
-        centroids (Dict[int, Array[int, 3]]): Dictionary of topology id's and
-            their centroids.
-        direction (Union["x", "y", "z", optional): Section direction.
-            Defaults to "y".
-        label_kwargs (dict, optional): Keyword arguments for topology labels.
-            Defaults to None.
-        edge_kwargs (dict, optional): Keyword arguments for topology edges.
-            Defaults to None.
-    """
-    PlotSolution.plot_topo_g(
-        geo_model,
-        edges,
-        centroids,
-        direction=direction,
-        scale=scale,
-        label_kwargs=label_kwargs,
-        edge_kwargs=edge_kwargs
-    )
-
-
-def plot_ar(geo_model, path=None, project_name=None, api_token=None, secret=None):
-    """ Create, upload and retrieve tag to visualize the model in AR in rexview
-
-    https://www.rexos.org/getting-started/
-
-    Args:
-        geo_model (gempy.Model):
-        path: Location for rex files. Default cwd
-        project_name: Name of the project in rexos
-        api_token: rexos api token
-        secret: rexos secret
-
-    Returns:
-        gempy.addons.rex_api.Rextag
-    """
-    from gempy.addons.rex_api import upload_to_rexcloud
-    from gempy.addons.gempy_to_rexfile import write_rex, geomodel_to_rex
-    if project_name is None:
-        project_name = geo_model.meta.project_name
-
-    if path is None:
-        path = './'
-
-    rex_bytes = geomodel_to_rex(geo_model)
-    files_path = write_rex(rex_bytes, path)
-    project_name_ = project_name
-    for i in range(40):
-        try:
-            tag = upload_to_rexcloud(files_path, project_name=project_name_, api_token=api_token, secret=secret)
-            break
-        except ConnectionError:
-            project_name_ = project_name + str(i)
-            pass
-
-    return tag
+"""
+    This file is part of gempy.
+
+    gempy is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    gempy is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
+
+    Module with classes and methods to perform implicit regional modelling based on
+    the potential field method.
+    Tested on Ubuntu 16
+
+    Created on 10/04/2018
+
+    @author: Elisa Heim, Miguel de la Varga
+"""
+
+# This is for sphenix to find the packages
+# sys.path.append( path.dirname( path.dirname( path.abspath(__file__) ) ) )
+
+from typing import Set, Tuple, Dict, Union
+import gempy as _gempy
+from ._visualization_2d import PlotData2D, PlotSolution
+from .visualization_3d import GemPyvtkInteract
+
+
+def plot_data_3D(geo_data, ve=1, **kwargs):
+    """
+    Plot in vtk all the input data of a model
+    Args:
+        geo_data (gempy.DataManagement.InputData): Input data of the model
+
+    Returns:
+        None
+    """
+    vv = GemPyvtkInteract(geo_data, ve=ve, **kwargs)
+    # vv.restart()
+    vv.set_surface_points()
+    vv.set_orientations()
+    vv.render_model(**kwargs)
+
+    return vv
+
+
+def plot_3D(geo_model, render_surfaces=True, render_data=True,
+            render_topography=True,
+            real_time=False, **kwargs):
+    """
+        Plot in vtk all the input data of a model
+        Args:
+            geo_model (gempy.DataManagement.InputData): Input data of the model
+
+        Returns:
+            None
+        """
+    vv = GemPyvtkInteract(geo_model, real_time=real_time, **kwargs)
+    # vv.restart()
+    if render_data is True:
+        vv.set_surface_points()
+        vv.set_orientations()
+    if render_surfaces is True:
+        vv.set_surfaces(geo_model._surfaces)
+    if render_topography is True and geo_model._grid.topography is not None:
+        vv.set_topography()
+
+    vv.render_model(**kwargs)
+
+    return vv
+
+
+def export_to_vtk(geo_data, path=None, name=None, voxels=True, block=None, surfaces=True):
+    """
+      Export data to a vtk file for posterior visualizations
+
+      Args:
+          geo_data(:class:`Model`)
+          path(str): path to the location of the vtk
+          name(str): Name of the files. Default name: Default
+          voxels(bool): if True export lith_block
+          block(Optional[np.array]): One of the solutions of the regular grid. This can be used if for
+           example you want to export an scalar field or an specific series block. If None is passed, lith_block
+           will be exported.
+          surfaces(bool): If True, export the polydata surfaces.
+
+      Returns:
+          None
+      """
+
+    if voxels is True:
+        GemPyvtkInteract.export_vtk_lith_block(geo_data, lith_block=block,
+                                               path=path)
+    if surfaces is True:
+        geo_data.solutions.compute_all_surfaces()
+        ver, sim = _gempy.get_surfaces(geo_data)
+        GemPyvtkInteract.export_vtk_surfaces(geo_data, ver, sim, path=path,
+                                             name=name)
+    return True
+
+
+def plot_data(geo_data, direction="y", data_type='all', series="all",
+              show_legend=True, **kwargs):
+    """
+    Plot the projection of the raw data (surface_points and orientations) in 2D following a
+    specific directions
+
+    Args:
+        direction(str): xyz. Caartesian direction to be plotted
+        series(str): series to plot
+        ve(float): Vertical exageration
+        **kwargs: seaborn lmplot key arguments. (TODO: adding the link to them)
+
+    Returns:
+        None
+    """
+    plot = PlotData2D(geo_data)
+    p = plot.plot_data(direction=direction, data_type=data_type, series=series,
+                       show_legend=show_legend, **kwargs)
+    # TODO saving options
+    return plot
+
+
+def plot_stereonet(geo_data, litho=None, planes=True, poles=True,
+                   single_plots=False,
+                   show_density=False):
+    '''
+    Plot an equal-area projection of the orientations dataframe using mplstereonet.
+
+    Args:
+        geo_model (gempy.DataManagement.InputData): Input data of the model
+        series_only: To select whether a stereonet is plotted perries or per formation
+        litho: selection of formation or series names, as list. If None, all are plotted
+        planes: If True, azimuth and dip are plotted as great circles
+        poles: If True, pole points (plane normal vectors) of azimuth and dip are plotted
+        single_plots: If True, each formation is plotted in a single stereonet
+        show_density: If True, density contour plot around the pole points is shown
+
+    Returns:
+        None
+    '''
+
+    plot = PlotData2D(geo_data)
+    plot.plot_stereonet(litho=litho, planes=planes, poles=poles,
+                        single_plots=single_plots,
+                        show_density=show_density)
+
+
+def plot_map(model, contour_lines=True, show_data=True, show_hillshades: bool = False, figsize=(12, 12), **kwargs):
+    """
+
+    Args:
+        figsize:
+        show_hillshades:
+        model:
+        contour_lines:
+        show_faults:
+        show_data:
+        **kwargs
+
+    Returns:
+
+    """
+    plot = PlotSolution(model)
+    plot.plot_map(contour_lines=contour_lines, show_data=show_data, show_hillshades=show_hillshades,
+                  figsize=figsize, **kwargs)
+
+
+def plot_section_traces(model, section_names=None, contour_lines=False,
+                        show_data=True, show_all_data=False):
+    """
+
+    Args:
+        model:
+        show_data:
+        section_names:
+        contour_lines:
+
+    Returns:
+
+    """
+    plot = PlotSolution(model)
+    if plot.model.solutions.geological_map is not None:
+        plot.plot_map(contour_lines=contour_lines, show_data=show_data,
+                      show_all_data=show_all_data)
+    # else:
+    # fig = plt.figure()
+    # plt.title('Section traces, z direction')
+
+    plot.plot_section_traces(show_data=show_data, section_names=section_names,
+                             contour_lines=contour_lines,
+                             show_all_data=show_all_data)
+
+
+"""
+def plot_predef_sections(model, show_traces=True, show_data=False, section_names=None, show_faults=True,
+                         show_topo=True, figsize=(12, 12)):
+
+
+    Args:
+        model:
+        show_traces:
+        show_data:
+        section_names:
+        show_faults:
+        show_topo:
+        figsize:
+
+    Returns:
+
+
+    plot = PlotSolution(model)
+    plot.plot_sections(show_traces=show_traces, show_data=show_data, section_names=section_names,
+                       show_faults=show_faults, show_topo=show_topo, figsize=figsize)
+
+"""
+
+
+def plot_section_by_name(model, section_name, show_faults=True, show_topo=True,
+                         show_data=True,
+                         show_all_data=False, radius='default',
+                         contourplot=True):
+    # Todo needs more keywords:
+    ### if show_data: radius, data_type
+    plot = PlotSolution(model)
+    plot.plot_section_by_name(section_name=section_name, show_topo=show_topo,
+                              show_faults=show_faults,
+                              show_data=show_data, show_all_data=show_all_data,
+                              radius=radius, contourplot=contourplot)
+
+
+def plot_all_sections(model, show_data=False, section_names=None,
+                      show_topo=True, figsize=(12, 12)):
+    plot = PlotSolution(model)
+    plot.plot_all_sections(show_data=show_data, section_names=section_names,
+                           show_topo=show_topo,
+                           figsize=figsize)
+
+
+def plot_section(model, cell_number=13, block=None, direction="y",
+                 interpolation='none',
+                 show_data=True, show_faults=True, show_topo=False,
+                 block_type=None, ve=1,
+                 show_all_data=False, show_legend=True, **kwargs):
+    """
+    Plot a section of the block model
+
+    Args:
+        cell_number(int): position of the array to plot
+        direction(str): xyz. Caartesian direction to be plotted
+        interpolation(str): Type of interpolation of plt.imshow. Default 'none'.  Acceptable values are 'none'
+        ,'nearest', 'bilinear', 'bicubic',
+        'spline16', 'spline36', 'hanning', 'hamming', 'hermite', 'kaiser',
+        'quadric', 'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc',
+        'lanczos'
+        ve(float): Vertical exageration
+        **kwargs: imshow keywargs
+
+    Returns:
+        None
+    """
+    plot = PlotSolution(model)
+    plot.fig = plot.plot_block_section(model.solutions, cell_number, block,
+                                       direction, interpolation,
+                                       show_data, show_faults, show_topo,
+                                       block_type, ve,
+                                       show_all_data=show_all_data,
+                                       show_legend=show_legend, **kwargs)
+    return plot
+
+
+def plot_scalar_field(model, cell_number, N=20,
+                      direction="y", block=None, alpha=0.6, show_data=True,
+                      show_all_data=False, series=0, *args, **kwargs):
+    """
+    Plot a potential field in a given direction.
+
+    Args:
+        cell_number(int): position of the array to plot
+        potential_field(str): name of the potential field (or series) to plot
+        n_pf(int): number of the  potential field (or series) to plot
+        direction(str): xyz. Caartesian direction to be plotted
+        serie: *Deprecated*
+        **kwargs: plt.contour kwargs
+
+    Returns:
+        None
+    """
+    plot = PlotSolution(model)
+    if block is not None:
+        block = block
+    else:
+        block = model.solutions
+
+    plot.plot_scalar_field(block, cell_number, N=N,
+                           direction=direction, show_data=show_data,
+                           series=series, alpha=alpha,
+                           show_all_data=show_all_data,
+                           *args, **kwargs)
+
+
+def plot_section_scalarfield(model, section_name, sn, levels=50,
+                             show_faults=True, show_topo=True, lithback=True):
+    """
+    Plot the potential field in the predefined sections.
+    Args:
+        model:
+        section_name: name of the section
+        sn: scalar field number, order like in model.series
+        levels: number of isolines you want to plot
+        show_faults: whether or not faults should be plotted
+        show_topo: whether or not the topography should be plotted
+        lithback: lithology background
+
+    Returns:
+        None
+    """
+    plot = PlotSolution(model)
+    plot.plot_section_scalarfield(section_name=section_name, sn=sn,
+                                  levels=levels, show_faults=show_faults,
+                                  show_topo=show_topo, lithback=lithback)
+
+
+def plot_gradient(geo_data, scalar_field, gx, gy, gz, cell_number, q_stepsize=5,
+                  direction="y", plot_scalar=True, **kwargs):
+    """
+        Plot the gradient of the scalar field in a given direction.
+
+        Args:
+            geo_data (gempy.DataManagement.InputData): Input data of the model
+            scalar_field(numpy.array): scalar field to plot with the gradient
+            gx(numpy.array): gradient in x-direction
+            gy(numpy.array): gradient in y-direction
+            gz(numpy.array): gradient in z-direction
+            cell_number(int): position of the array to plot
+            q_stepsize(int): step size between arrows to indicate gradient
+            direction(str): xyz. Caartesian direction to be plotted
+            plot_scalar(bool): boolean to plot scalar field
+            **kwargs: plt.contour kwargs
+
+        Returns:
+            None
+    """
+    plot = PlotSolution(geo_data)
+    plot.plot_gradient(scalar_field, gx, gy, gz, cell_number,
+                       q_stepsize=q_stepsize,
+                       direction=direction, plot_scalar=plot_scalar,
+                       **kwargs)
+
+
+def plot_topology(
+        geo_model,
+        edges: Set[Tuple[int, int]],
+        centroids: Dict,
+        direction: Union["x", "y", "z"] = "y",
+        scale: bool = True,
+        label_kwargs: dict = None,
+        edge_kwargs: dict = None
+):
+    """Plot the topology adjacency graph in 2-D.
+
+    Args:
+        geo_model ([type]): GemPy geomodel instance.
+        edges (Set[Tuple[int, int]]): Set of topology edges.
+        centroids (Dict[int, Array[int, 3]]): Dictionary of topology id's and
+            their centroids.
+        direction (Union["x", "y", "z", optional): Section direction.
+            Defaults to "y".
+        label_kwargs (dict, optional): Keyword arguments for topology labels.
+            Defaults to None.
+        edge_kwargs (dict, optional): Keyword arguments for topology edges.
+            Defaults to None.
+    """
+    PlotSolution.plot_topo_g(
+        geo_model,
+        edges,
+        centroids,
+        direction=direction,
+        scale=scale,
+        label_kwargs=label_kwargs,
+        edge_kwargs=edge_kwargs
+    )
+
+
+def plot_ar(geo_model, path=None, project_name=None, api_token=None, secret=None):
+    """ Create, upload and retrieve tag to visualize the model in AR in rexview
+
+    https://www.rexos.org/getting-started/
+
+    Args:
+        geo_model (gempy.Model):
+        path: Location for rex files. Default cwd
+        project_name: Name of the project in rexos
+        api_token: rexos api token
+        secret: rexos secret
+
+    Returns:
+        gempy.addons.rex_api.Rextag
+    """
+    from gempy.addons.rex_api import upload_to_rexcloud
+    from gempy.addons.gempy_to_rexfile import write_rex, geomodel_to_rex
+    if project_name is None:
+        project_name = geo_model.meta.project_name
+
+    if path is None:
+        path = './'
+
+    rex_bytes = geomodel_to_rex(geo_model)
+    files_path = write_rex(rex_bytes, path)
+    project_name_ = project_name
+    for i in range(40):
+        try:
+            tag = upload_to_rexcloud(files_path, project_name=project_name_, api_token=api_token, secret=secret)
+            break
+        except ConnectionError:
+            project_name_ = project_name + str(i)
+            pass
+
+    return tag
```

### Comparing `gempy-2.2b10.dev1/gempy/plot/_vista.py` & `gempy-2.3.0/gempy/plot/_vista.py`

 * *Files 1% similar despite different names*

```diff
@@ -32,15 +32,14 @@
 import matplotlib.colors as mcolors
 from matplotlib import cm
 import numpy as np
 import pandas as pn
 try:
     import pyvista as pv
     import pyvistaqt as pvqt
-    from pyvista.plotting import parse_color
     PYVISTA_IMPORT = True
 except ImportError:
     PYVISTA_IMPORT = False
 
 import gempy as gp
 
 warnings.filterwarnings("ignore",
@@ -310,17 +309,17 @@
 
             plane1 = self.p_widget.loc[index, 'val']
             #  plane1.SetInputData(new_source.GetOutput())
             plane1.SetNormal(new_normal)
             plane1.SetCenter(new_center[0], new_center[1], new_center[2])
 
             plane1.GetPlaneProperty().SetColor(
-                parse_color(self.model._surfaces.df.set_index('id')['color'][new_values_df['id']]))  # self.C_LOT[new_values_df['id']])
+                pv.Color(self.model._surfaces.df.set_index('id')['color'][new_values_df['id']]).float_rgb)  # self.C_LOT[new_values_df['id']])
             plane1.GetHandleProperty().SetColor(
-                parse_color(self.model._surfaces.df.set_index('id')['color'][new_values_df['id']]))
+                pv.Color(self.model._surfaces.df.set_index('id')['color'][new_values_df['id']]).float_rgb)
         return True
 
     def plot_orientations(self, orientations=None, clear=True, **kwargs):
         self.update_colot_lot()
         if clear is True:
             self.p.clear_plane_widgets()
         factor = kwargs.get('factor', 0.1)
@@ -350,15 +349,15 @@
             surfaces = self.model._surfaces.df
 
         select_active = surfaces['isActive']
         for idx, val in surfaces[select_active][['vertices', 'edges', 'color']].dropna().iterrows():
 
             surf = pv.PolyData(val['vertices'], np.insert(val['edges'], 0, 3, axis=1).ravel())
             self.surf_polydata.at[idx] = surf
-            self.vista_surf_actor[idx] = self.p.add_mesh(surf, parse_color(val['color']), **kwargs)
+            self.vista_surf_actor[idx] = self.p.add_mesh(surf, pv.Color(val['color']).float_rgb, **kwargs)
 
         self.set_bounds()
         return self.surf_polydata
 
     def update_surfaces(self):
         surfaces = self.model._surfaces
         # TODO add the option of update specific surfaces
```

### Comparing `gempy-2.2b10.dev1/gempy/plot/decorators.py` & `gempy-2.3.0/gempy/plot/decorators.py`

 * *Ordering differences only*

 * *Files 17% similar despite different names*

```diff
@@ -1,117 +1,117 @@
-from .visualization_3d import GemPyvtkInteract
-from gempy.plot.vista import GemPyToVista
-from functools import wraps
-
-
-def plot_add_surface_points(func):
-    @wraps(func)
-    def pasp(*args, **kwargs):
-        plot_object = kwargs.pop('plot_object') if 'plot_object' in kwargs else None
-        surface_points, idx = func(*args, **kwargs)
-        if plot_object is not None:
-            if isinstance(plot_object, GemPyToVista):
-                if plot_object.live_updating is True:
-                    plot_object.render_add_surface_points(idx)
-            else:
-                raise AttributeError('plot_object must be one GemPy compatible plot')
-        return surface_points
-    return pasp
-
-
-def plot_delete_surface_points(func):
-    @wraps(func)
-    def pdsp(*args, **kwargs):
-        plot_object = kwargs.pop('plot_object') if 'plot_object' in kwargs else None
-        surface_points = func(*args, **kwargs)
-        if plot_object is not None:
-            if isinstance(plot_object, GemPyToVista):
-                if plot_object.live_updating is True:
-                    plot_object.render_delete_surface_points(args[1])
-            else:
-                raise AttributeError('plot_object must be one GemPy compatible plot')
-        return surface_points
-    return pdsp
-
-
-def plot_move_surface_points(func):
-    @wraps(func)
-    def pmsp(*args, **kwargs):
-        # TODO: Add this thing with the indices to all the decorators of this
-        # module
-        if 'indices' not in kwargs:
-            indices = args[1]
-        else:
-            indices = kwargs['indices']
-
-        plot_object = kwargs.pop('plot_object') if 'plot_object' in kwargs else None
-        surface_points = func(*args, **kwargs)
-        if plot_object is not None:
-            if isinstance(plot_object, GemPyToVista):
-                if plot_object.live_updating is True:
-                    plot_object.render_move_surface_points(indices)
-            else:
-                raise AttributeError('plot_object must be one GemPy compatible plot')
-        return surface_points
-    return pmsp
-
-
-def plot_add_orientation(func):
-    @wraps(func)
-    def pao(*args, **kwargs):
-        plot_object = kwargs.pop('plot_object') if 'plot_object' in kwargs else None
-        orientation, idx = func(*args, **kwargs)
-        if plot_object is not None:
-            if isinstance(plot_object, GemPyToVista):
-                if plot_object.live_updating is True:
-                    plot_object.render_add_orientations(idx)
-            else:
-                raise AttributeError('plot_object must be one GemPy compatible plot')
-        return orientation
-    return pao
-
-
-def plot_delete_orientations(func):
-    @wraps(func)
-    def pdo(*args, **kwargs):
-        plot_object = kwargs.pop('plot_object') if 'plot_object' in kwargs else None
-        orientations = func(*args, **kwargs)
-        if plot_object is not None:
-            if isinstance(plot_object, GemPyToVista):
-                if plot_object.live_updating is True:
-                    plot_object.render_delete_orientations(args[1])
-            else:
-                raise AttributeError('plot_object must be one GemPy compatible plot')
-        return orientations
-    return pdo
-
-
-def plot_move_orientations(func):
-    @wraps(func)
-    def pmo(*args, **kwargs):
-        plot_object = kwargs.pop('plot_object') if 'plot_object' in kwargs else None
-        orientations = func(*args, **kwargs)
-
-        if plot_object is not None:
-            if isinstance(plot_object, GemPyToVista):
-                if plot_object.live_updating is True:
-                    plot_object.render_move_orientations(args[1])
-            else:
-                raise AttributeError('plot_object must be one GemPy compatible plot')
-        return orientations
-    return pmo
-
-
-def plot_set_topography(func):
-    @wraps(func)
-    def pst(*args, **kwargs):
-        plot_object = kwargs.pop('plot_object') if 'plot_object' in kwargs else None
-        topography = func(*args, **kwargs)
-
-        if plot_object is not None:
-            if isinstance(plot_object, GemPyToVista):
-                if plot_object.live_updating is True:
-                    plot_object.render_topography()
-            else:
-                raise AttributeError('plot_object must be one GemPy compatible plot')
-        return topography
-    return pst
+from .visualization_3d import GemPyvtkInteract
+from gempy.plot.vista import GemPyToVista
+from functools import wraps
+
+
+def plot_add_surface_points(func):
+    @wraps(func)
+    def pasp(*args, **kwargs):
+        plot_object = kwargs.pop('plot_object') if 'plot_object' in kwargs else None
+        surface_points, idx = func(*args, **kwargs)
+        if plot_object is not None:
+            if isinstance(plot_object, GemPyToVista):
+                if plot_object.live_updating is True:
+                    plot_object.render_add_surface_points(idx)
+            else:
+                raise AttributeError('plot_object must be one GemPy compatible plot')
+        return surface_points
+    return pasp
+
+
+def plot_delete_surface_points(func):
+    @wraps(func)
+    def pdsp(*args, **kwargs):
+        plot_object = kwargs.pop('plot_object') if 'plot_object' in kwargs else None
+        surface_points = func(*args, **kwargs)
+        if plot_object is not None:
+            if isinstance(plot_object, GemPyToVista):
+                if plot_object.live_updating is True:
+                    plot_object.render_delete_surface_points(args[1])
+            else:
+                raise AttributeError('plot_object must be one GemPy compatible plot')
+        return surface_points
+    return pdsp
+
+
+def plot_move_surface_points(func):
+    @wraps(func)
+    def pmsp(*args, **kwargs):
+        # TODO: Add this thing with the indices to all the decorators of this
+        # module
+        if 'indices' not in kwargs:
+            indices = args[1]
+        else:
+            indices = kwargs['indices']
+
+        plot_object = kwargs.pop('plot_object') if 'plot_object' in kwargs else None
+        surface_points = func(*args, **kwargs)
+        if plot_object is not None:
+            if isinstance(plot_object, GemPyToVista):
+                if plot_object.live_updating is True:
+                    plot_object.render_move_surface_points(indices)
+            else:
+                raise AttributeError('plot_object must be one GemPy compatible plot')
+        return surface_points
+    return pmsp
+
+
+def plot_add_orientation(func):
+    @wraps(func)
+    def pao(*args, **kwargs):
+        plot_object = kwargs.pop('plot_object') if 'plot_object' in kwargs else None
+        orientation, idx = func(*args, **kwargs)
+        if plot_object is not None:
+            if isinstance(plot_object, GemPyToVista):
+                if plot_object.live_updating is True:
+                    plot_object.render_add_orientations(idx)
+            else:
+                raise AttributeError('plot_object must be one GemPy compatible plot')
+        return orientation
+    return pao
+
+
+def plot_delete_orientations(func):
+    @wraps(func)
+    def pdo(*args, **kwargs):
+        plot_object = kwargs.pop('plot_object') if 'plot_object' in kwargs else None
+        orientations = func(*args, **kwargs)
+        if plot_object is not None:
+            if isinstance(plot_object, GemPyToVista):
+                if plot_object.live_updating is True:
+                    plot_object.render_delete_orientations(args[1])
+            else:
+                raise AttributeError('plot_object must be one GemPy compatible plot')
+        return orientations
+    return pdo
+
+
+def plot_move_orientations(func):
+    @wraps(func)
+    def pmo(*args, **kwargs):
+        plot_object = kwargs.pop('plot_object') if 'plot_object' in kwargs else None
+        orientations = func(*args, **kwargs)
+
+        if plot_object is not None:
+            if isinstance(plot_object, GemPyToVista):
+                if plot_object.live_updating is True:
+                    plot_object.render_move_orientations(args[1])
+            else:
+                raise AttributeError('plot_object must be one GemPy compatible plot')
+        return orientations
+    return pmo
+
+
+def plot_set_topography(func):
+    @wraps(func)
+    def pst(*args, **kwargs):
+        plot_object = kwargs.pop('plot_object') if 'plot_object' in kwargs else None
+        topography = func(*args, **kwargs)
+
+        if plot_object is not None:
+            if isinstance(plot_object, GemPyToVista):
+                if plot_object.live_updating is True:
+                    plot_object.render_topography()
+            else:
+                raise AttributeError('plot_object must be one GemPy compatible plot')
+        return topography
+    return pst
```

### Comparing `gempy-2.2b10.dev1/gempy/plot/helpers.py` & `gempy-2.3.0/gempy/plot/helpers.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,34 +1,30 @@
-from mpl_toolkits import axes_grid1
-import matplotlib.pyplot as plt
-
-
-def add_colorbar(im=None, axes=None, cs=None, label = None, aspect=30, location="right", pad_fraction=1, **kwargs):
-    """
-    Add a colorbar to a plot (im).
-    Args:
-        im:             plt imshow
-        label:          label of the colorbar
-        axes:
-        cs:             Contourset
-        aspect:         the higher, the smaller the colorbar is
-        pad_fraction:
-        **kwargs:
-
-    Returns: A perfect colorbar, no matter the plot.
-
-    """
-    if axes is None:
-        axes = im.axes
-    divider = axes_grid1.make_axes_locatable(axes)
-    width = axes_grid1.axes_size.AxesY(axes, aspect=2. / aspect)
-    pad = axes_grid1.axes_size.Fraction(pad_fraction, width)
-    current_ax = plt.gca()
-    cax = divider.append_axes(location, size=width, pad=pad)
-    plt.sca(current_ax)
-    if cs:
-        cbar = axes.figure.colorbar(cs, cax=cax, **kwargs)
-    else:
-        if im is not None:
-            cbar = axes.figure.colorbar(im, cax=cax, **kwargs)
-    cbar.set_label(label)
+from mpl_toolkits import axes_grid1
+import matplotlib.pyplot as plt
+
+
+def add_colorbar(im=None, axes=None, cs=None, label = None, aspect=30, location="right", pad_fraction=1, **kwargs):
+    """
+    Add a colorbar to a plot (im).
+    Args:
+        im:             plt imshow
+        label:          label of the colorbar
+        axes:
+        cs:             Contourset
+        aspect:         the higher, the smaller the colorbar is
+        pad_fraction:
+        **kwargs:
+
+    Returns: A perfect colorbar, no matter the plot.
+
+    """
+    if axes is None:
+        axes = im.axes
+  
+    cax = axes.inset_axes([1.04, 0.2, 0.05, 0.6])
+    if cs:
+        cbar = axes.figure.colorbar(cs, ax=axes, cax=cax, location="right", **kwargs)
+    else:
+        if im is not None:
+            cbar = axes.figure.colorbar(im, cax=cax, location="right",  **kwargs)
+    cbar.set_label(label)
     return cbar
```

### Comparing `gempy-2.2b10.dev1/gempy/plot/plot_api.py` & `gempy-2.3.0/gempy/plot/plot_api.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,582 +1,583 @@
-"""
-    This file is part of gempy.
-
-    gempy is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    gempy is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
-
-    Module with classes and methods to perform implicit regional modelling based on
-    the potential field method.
-    Tested on Ubuntu 16
-
-    Created on 10/11/2019
-
-    @author: Alex Schaaf, Elisa Heim, Miguel de la Varga
-"""
-
-# This is for sphenix to find the packages
-# sys.path.append( path.dirname( path.dirname( path.abspath(__file__) ) ) )
-
-from typing import Union, List, Any
-
-import matplotlib.pyplot as plt
-# from .vista import Vista
-# import gempy as _gempy
-import numpy as np
-import pandas as pn
-from gempy.plot.vista import GemPyToVista
-
-# Keep Alex code hidden until we merge it properly
-try:
-    import pyvista as pv
-    from ._vista import Vista as Vista
-
-    PYVISTA_IMPORT = True
-except ImportError:
-    PYVISTA_IMPORT = False
-
-from .visualization_2d import Plot2D
-
-try:
-    import mplstereonet
-
-    mplstereonet_import = True
-except ImportError:
-    mplstereonet_import = False
-
-
-def plot_2d(model, n_axis=None, section_names: list = None,
-            cell_number: list = None, direction: list = 'y',
-            show_data: Union[bool, list] = True,
-            show_results: Union[bool, list] = True,
-            show_lith: Union[bool, list] = True,
-            show_values: Union[bool, list] = False,
-            show_block: Union[bool, list] = False,
-            show_scalar: Union[bool, list] = False,
-            show_boundaries: Union[bool, list] = True,
-            show_topography: Union[bool, list] = False,
-            show_section_traces: Union[bool, list] = True,
-            series_n: Union[int, List[int]] = 0,
-            ve=1,
-            block=None,
-            regular_grid=None,
-            kwargs_topography=None,
-            kwargs_regular_grid=None,
-            **kwargs):
-    """Plot 2-D sections of geomodel.
-
-    Plot cross sections either based on custom section traces or cell number in xyz direction.
-    Options to plot lithology block, scalar field or rendered surface lines.
-    Input data and topography can be included.
-
-    Args:
-        show_block (bool): If True and model has been computed, plot cross section
-         of the final model.
-        show_values (bool): If True and model has been computed, plot cross section
-         of the value... TODO need to add attribute to choose which value to be plot
-        model: Geomodel object with solutions.
-        n_axis (int): Subplot axis for multiple sections
-        section_names (list): Names of predefined custom section traces
-        cell_number (list): Position of the array to plot
-        direction (str): Cartesian direction to be plotted (xyz)
-        show_data (bool): Show original input data. Defaults to True.
-        show_results (bool): If False, override show lith, show_calar, show_values
-        show_lith (bool): Show lithological block volumes. Defaults to True.
-        show_scalar (bool): Show scalar field isolines. Defaults to False.
-        show_boundaries (bool): Show surface boundaries as lines. Defaults to True.
-        show_topography (bool): Show topography on plot. Defaults to False.
-        series_n (int): number of the scalar field.
-        ve (float): vertical exageration
-        regular_grid (numpy.ndarray): Numpy array of the size of model.grid.regular_grid
-        kwargs_topography (dict):
-            * fill_contour
-            * hillshade (bool): Calculate and add hillshading using elevation data
-            * azdeg (float): azimuth of sun for hillshade
-            * altdeg (float): altitude in degrees of sun for hillshade
-
-
-    Keyword Args:
-        legend (bool): If True plot legend. Default True
-        show (bool): Call matplotlib show
-
-    Returns:
-        :class:`gempy.plot.visualization_2d.Plot2D`: Plot2D object
-
-    """
-    if kwargs_regular_grid is None:
-        kwargs_regular_grid = dict()
-    if kwargs_topography is None:
-        kwargs_topography = dict()
-    if section_names is None and cell_number is None and direction is not None:
-        cell_number = ['mid']
-
-    show = kwargs.get('show', True)
-
-    if block is not None:
-        import warnings
-        regular_grid = block
-        warnings.warn('block is going to be deprecated. Use regular grid instead',
-                      DeprecationWarning)
-
-    section_names = [] if section_names is None else section_names
-    section_names = np.atleast_1d(section_names)
-    if cell_number is None:
-        cell_number = []
-    elif cell_number == 'mid':
-        cell_number = ['mid']
-    direction = [] if direction is None else direction
-
-    if type(cell_number) != list:
-        cell_number = [cell_number]
-
-    if type(direction) != list:
-        direction = [direction]
-
-    if n_axis is None:
-        n_axis = len(section_names) + len(cell_number)
-
-    if show_results is False:
-        show_lith = False
-        show_values = False
-        show_block = False
-        show_scalar = False
-        show_boundaries = False
-
-    if type(show_data) is bool:
-        show_data = [show_data] * n_axis
-    if type(show_lith) is bool:
-        show_lith = [show_lith] * n_axis
-    if type(show_values) is bool:
-        show_values = [show_values] * n_axis
-    if type(show_block) is bool:
-        show_block = [show_block] * n_axis
-    if type(show_scalar) is bool:
-        show_scalar = [show_scalar] * n_axis
-    if type(show_boundaries) is bool:
-        show_boundaries = [show_boundaries] * n_axis
-    if type(show_topography) is bool:
-        show_topography = [show_topography] * n_axis
-    if type(series_n) is int:
-        series_n = [series_n] * n_axis
-
-    # init e
-    e = 0
-    # is 10 and 10 because in the ax pos is the second digit
-    n_columns_ = 1 if len(section_names) + len(cell_number) < 2 else 2
-    n_columns = n_columns_ * 10  # This is for the axis location syntax
-    n_rows = (len(section_names) + len(cell_number)) / n_columns_
-
-    n_columns_ = np.max([n_columns_, 1])
-    n_rows = np.max([n_rows, 1])
-
-    p = Plot2D(model, **kwargs)
-    p.create_figure(cols=n_columns_, rows=n_rows, **kwargs)
-
-    for e, sn in enumerate(section_names):
-        # Check if a plot that fills all pixels is plotted
-        _is_filled = False
-        assert e < 10, 'Reached maximum of axes'
-
-        ax_pos = (round(n_axis / 2 + 0.1)) * 100 + n_columns + e + 1
-        temp_ax = p.add_section(section_name=sn, ax_pos=ax_pos, ve=ve, **kwargs)
-        if show_data[e] is True:
-            p.plot_data(temp_ax, section_name=sn, **kwargs)
-        if show_lith[e] is True and model.solutions.lith_block.shape[0] != 0:
-            _is_filled = True
-            p.plot_lith(temp_ax, section_name=sn, **kwargs)
-        elif show_values[e] is True and model.solutions.values_matrix.shape[0] != 0:
-            _is_filled = True
-            p.plot_values(temp_ax, series_n=series_n[e], section_name=sn, **kwargs)
-        elif show_block[e] is True and model.solutions.block_matrix.shape[0] != 0:
-            _is_filled = True
-            p.plot_block(temp_ax, series_n=series_n[e], section_name=sn, **kwargs)
-        if show_scalar[e] is True and model.solutions.scalar_field_matrix.shape[0] != 0:
-            _is_filled = True
-            p.plot_scalar_field(temp_ax, series_n=series_n[e], section_name=sn, **kwargs)
-        if show_boundaries[e] is True and model.solutions.scalar_field_matrix.shape[0] != 0:
-            p.plot_contacts(temp_ax, section_name=sn, **kwargs)
-        if show_topography[e] is True:
-            # Check if anything dense is plot. If not plot dense topography
-            f_c_ = not _is_filled
-            # f_c = kwargs_topography.get('fill_contour', f_c_)
-            if 'fill_contour' not in kwargs_topography:
-                kwargs_topography['fill_contour'] = f_c_
-            p.plot_topography(temp_ax, section_name=sn,  # fill_contour=f_c,
-                              **kwargs_topography)
-            if show_section_traces is True and sn == 'topography':
-                p.plot_section_traces(temp_ax)
-
-        if regular_grid is not None:
-            p.plot_regular_grid(temp_ax, block=regular_grid, section_name=sn,
-                                **kwargs_regular_grid)
-
-        temp_ax.set_aspect(ve)
-
-        # If there are section we need to shift one axis for the perpendicular
-        e = e + 1
-
-    for e2 in range(len(cell_number)):
-        assert (e + e2) < 10, 'Reached maximum of axes'
-
-        ax_pos = (round(n_axis / 2 + 0.1)) * 100 + n_columns + e + e2 + 1
-        temp_ax = p.add_section(cell_number=cell_number[e2],
-                                direction=direction[e2], ax_pos=ax_pos, ve=ve)
-        if show_data[e + e2] is True:
-            p.plot_data(temp_ax, cell_number=cell_number[e2],
-                        direction=direction[e2], **kwargs)
-        if show_lith[e + e2] is True and model.solutions.lith_block.shape[0] != 0:
-            p.plot_lith(temp_ax, cell_number=cell_number[e2],
-                        direction=direction[e2], **kwargs)
-        elif show_values[e + e2] is True and model.solutions.values_matrix.shape[0] != 0:
-            p.plot_values(temp_ax, series_n=series_n[e], cell_number=cell_number[e2],
-                          direction=direction[e2], **kwargs)
-        elif show_block[e + e2] is True and model.solutions.block_matrix.shape[0] != 0:
-            p.plot_block(temp_ax, series_n=series_n[e], cell_number=cell_number[e2],
-                         direction=direction[e2], **kwargs)
-        if show_scalar[e + e2] is True and model.solutions.scalar_field_matrix.shape[0] != 0:
-            p.plot_scalar_field(temp_ax, series_n=series_n[e], cell_number=cell_number[e2],
-                                direction=direction[e2], **kwargs)
-        if show_boundaries[e + e2] is True and model.solutions.scalar_field_matrix.shape[0] != 0:
-            p.plot_contacts(temp_ax, cell_number=cell_number[e2],
-                            direction=direction[e2], **kwargs)
-        if show_topography[e + e2] is True:
-            p.plot_topography(temp_ax, cell_number=cell_number[e2],
-                              direction=direction[e2], **kwargs_topography)
-        if regular_grid is not None:
-            p.plot_regular_grid(temp_ax, block=regular_grid, cell_number=cell_number[e2],
-                                direction=direction[e2], **kwargs_regular_grid)
-
-        temp_ax.set_aspect(ve)
-
-    if show is True:
-        p.fig.show()
-
-    return p
-
-
-def plot_3d(model, plotter_type='basic',
-            show_data: bool = True,
-            show_results: bool = True,
-            show_surfaces: bool = True,
-            show_lith: bool = True,
-            show_scalar: bool = False,
-            show_boundaries: bool = True,
-            show_topography: Union[bool, list] = False,
-            scalar_field: str = None,
-            ve=None,
-            kwargs_plot_structured_grid=None,
-            kwargs_plot_topography=None,
-            kwargs_plot_data=None,
-            image=False,
-            off_screen=False, **kwargs) -> GemPyToVista:
-    """foobar
-
-    Args:
-
-        model (:class:`gempy.core.model.Project`): Container class of all
-         objects that constitute a GemPy model.
-        plotter_type: PyVista plotter types. Supported plotters are:
-         'basic', 'background', and 'notebook'.
-        show_data (bool): Show original input data. Defaults to True.
-        show_results (bool): If False, override show lith, show_scalar, show_values
-        show_lith (bool): Show lithological block volumes. Defaults to True.
-        show_scalar (bool): Show scalar field isolines. Defaults to False.
-        show_boundaries (bool): Show surface boundaries as lines. Defaults to True.
-        show_topography (bool): Show topography on plot. Defaults to False.
-        scalar_field (str): Name of the field to be activated
-        series_n (int): number of the scalar field.
-        ve (float): Vertical Exaggeration
-        kwargs_plot_structured_grid:
-        kwargs_plot_topography:
-        **kwargs:
-
-    Returns:
-        :class:`gempy.plot.vista.GemPyToVista`
-
-    """
-    if image is True:
-        off_screen = True
-        kwargs['off_screen'] = True
-        plotter_type = 'basic'
-    if show_results is False:
-        show_surfaces = False
-        show_scalar = False
-        show_lith = False
-
-    if kwargs_plot_topography is None:
-        kwargs_plot_topography = dict()
-    if kwargs_plot_structured_grid is None:
-        kwargs_plot_structured_grid = dict()
-    if kwargs_plot_data is None:
-        kwargs_plot_data = dict()
-
-    fig_path: str = kwargs.get('fig_path', None)
-
-    gpv = GemPyToVista(model, plotter_type=plotter_type, **kwargs)
-    if show_surfaces and len(model.solutions.vertices) != 0:
-        gpv.plot_surfaces()
-    if show_lith is True and model.solutions.lith_block.shape[0] != 0:
-        gpv.plot_structured_grid('lith', **kwargs_plot_structured_grid)
-    if show_scalar is True and model.solutions.scalar_field_matrix.shape[0] != 0:
-        gpv.plot_structured_grid("scalar", series=scalar_field)
-
-    if show_data:
-        gpv.plot_data(**kwargs_plot_data)
-
-    if show_topography and model._grid.topography is not None:
-        gpv.plot_topography(**kwargs_plot_topography)
-
-    if ve is not None:
-        gpv.p.set_scale(zscale=ve)
-
-    if fig_path is not None:
-        gpv.p.show(screenshot=fig_path)
-
-    if image is True:
-        img = gpv.p.show(screenshot=True)
-        plt.imshow(img[1])
-        plt.axis('off')
-        plt.show(block=False)
-        gpv.p.close()
-
-    if off_screen is False:
-        gpv.p.show()
-
-    return gpv
-
-
-def plot_interactive_3d(
-        geo_model,
-        scalar_field: str = 'all',
-        series=None,
-        show_topography: bool = False,
-        **kwargs,
-):
-    """Plot interactive 3-D geomodel with three cross sections in subplots.
-    Args:
-        geo_model: Geomodel object with solutions.
-        name (str): Can be either one of the following
-                'lith' - Lithology id block.
-                'scalar' - Scalar field block.
-                'values' - Values matrix block.
-        render_topography: Render topography. Defaults to False.
-        **kwargs:
-    Returns:
-        :class:`gempy.plot.vista.GemPyToVista`
-
-    """
-    gpv = GemPyToVista(geo_model, plotter_type='background', shape="1|3")
-    gpv.plot_data()
-    gpv.plot_structured_grid_interactive(scalar_field=scalar_field, series=series,
-                                         render_topography=show_topography, **kwargs)
-
-    return gpv
-
-
-def plot_section_traces(model):
-    """Plot section traces of section grid in 2-D topview (xy).
-
-    Args:
-        model: Geomodel object with solutions.
-
-    Returns:
-        (Plot2D) Plot2D object
-    """
-    pst = plot_2d(model, n_axis=1, direction=['z'], cell_number=[-1],
-                  show_data=False, show_boundaries=False, show_lith=False, show=False)
-    pst.plot_section_traces(pst.axes[0], show_data=False)
-    return pst
-
-
-def plot_stereonet(self, litho=None, planes=True, poles=True,
-                   single_plots=False,
-                   show_density=False):
-    if mplstereonet_import is False:
-        raise ImportError(
-            'mplstereonet package is not installed. No stereographic projection available.')
-
-    from collections import OrderedDict
-
-    if litho is None:
-        litho = self.model._orientations.df['surface'].unique()
-
-    if single_plots is False:
-        fig, ax = mplstereonet.subplots(figsize=(5, 5))
-        df_sub2 = pn.DataFrame()
-        for i in litho:
-            df_sub2 = df_sub2.append(self.model._orientations.df[
-                                         self.model._orientations.df[
-                                             'surface'] == i])
-
-    for formation in litho:
-        if single_plots:
-            fig = plt.figure(figsize=(5, 5))
-            ax = fig.add_subplot(111, projection='stereonet')
-            ax.set_title(formation, y=1.1)
-
-        # if series_only:
-        # df_sub = self.model.orientations.df[self.model.orientations.df['series'] == formation]
-        # else:
-        df_sub = self.model._orientations.df[
-            self.model._orientations.df['surface'] == formation]
-
-        if poles:
-            ax.pole(df_sub['azimuth'] - 90, df_sub['dip'], marker='o',
-                    markersize=7,
-                    markerfacecolor=self._color_lot[formation],
-                    markeredgewidth=1.1, markeredgecolor='gray',
-                    label=formation + ': ' + 'pole point')
-        if planes:
-            ax.plane(df_sub['azimuth'] - 90, df_sub['dip'],
-                     color=self._color_lot[formation],
-                     linewidth=1.5, label=formation + ': ' + 'azimuth/dip')
-        if show_density:
-            if single_plots:
-                ax.density_contourf(df_sub['azimuth'] - 90, df_sub['dip'],
-                                    measurement='poles', cmap='viridis',
-                                    alpha=.5)
-            else:
-                ax.density_contourf(df_sub2['azimuth'] - 90, df_sub2['dip'],
-                                    measurement='poles', cmap='viridis',
-                                    alpha=.5)
-
-        fig.subplots_adjust(top=0.8)
-        handles, labels = ax.get_legend_handles_labels()
-        by_label = OrderedDict(zip(labels, handles))
-        ax.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(1.9, 1.1))
-        ax._grid(True, color='black', alpha=0.25)
-
-
-def plot_topology(geo_model, edges, centroids, direction="y", scale=True,
-                  label_kwargs=None, edge_kwargs=None):
-    """Plot the topology adjacency graph in 2-D.
-
-        Args:
-            geo_model ([type]): GemPy geomodel instance.
-            edges (Set[Tuple[int, int]]): Set of topology edges.
-            centroids (Dict[int, Array[int, 3]]): Dictionary of topology id's and
-                their centroids.
-            direction (Union["x", "y", "z", optional): Section direction.
-                Defaults to "y".
-            label_kwargs (dict, optional): Keyword arguments for topology labels.
-                Defaults to None.
-            edge_kwargs (dict, optional): Keyword arguments for topology edges.
-                Defaults to None.
-
-        """
-    res = geo_model._grid.regular_grid.resolution
-    if direction == "y":
-        c1, c2 = (0, 2)
-        e1 = geo_model._grid.regular_grid.extent[1] - geo_model._grid.regular_grid.extent[0]
-        e2 = geo_model._grid.regular_grid.extent[5] - geo_model._grid.regular_grid.extent[4]
-        d1 = geo_model._grid.regular_grid.extent[0]
-        d2 = geo_model._grid.regular_grid.extent[4]
-        # if len(list(centroids.items())[0][1]) == 2:
-        #     c1, c2 = (0, 1)
-        r1 = res[0]
-        r2 = res[2]
-    elif direction == "x":
-        c1, c2 = (1, 2)
-        e1 = geo_model._grid.regular_grid.extent[3] - geo_model._grid.regular_grid.extent[2]
-        e2 = geo_model._grid.regular_grid.extent[5] - geo_model._grid.regular_grid.extent[4]
-        d1 = geo_model._grid.regular_grid.extent[2]
-        d2 = geo_model._grid.regular_grid.extent[4]
-        # if len(list(centroids.items())[0][1]) == 2:
-        #     c1, c2 = (0, 1)
-        r1 = res[1]
-        r2 = res[2]
-    elif direction == "z":
-        c1, c2 = (0, 1)
-        e1 = geo_model._grid.regular_grid.extent[1] - geo_model._grid.regular_grid.extent[0]
-        e2 = geo_model._grid.regular_grid.extent[3] - geo_model._grid.regular_grid.extent[2]
-        d1 = geo_model._grid.regular_grid.extent[0]
-        d2 = geo_model._grid.regular_grid.extent[2]
-        # if len(list(centroids.items())[0][1]) == 2:
-        #     c1, c2 = (0, 1)
-        r1 = res[0]
-        r2 = res[1]
-
-    tkw = {
-        "color": "white",
-        "fontsize": 13,
-        "ha": "center",
-        "va": "center",
-        "weight": "ultralight",
-        "family": "monospace",
-        "verticalalignment": "center",
-        "horizontalalignment": "center",
-        "bbox": dict(boxstyle='round', facecolor='black', alpha=1),
-    }
-    if label_kwargs is not None:
-        tkw.update(label_kwargs)
-
-    lkw = {
-        "linewidth": 1,
-        "color": "black"
-    }
-    if edge_kwargs is not None:
-        lkw.update(edge_kwargs)
-
-    for a, b in edges:
-        # plot edges
-        x = np.array([centroids[a][c1], centroids[b][c1]])
-        y = np.array([centroids[a][c2], centroids[b][c2]])
-        if scale:
-            x = x * e1 / r1 + d1
-            y = y * e2 / r2 + d2
-        plt.plot(x, y, **lkw)
-
-    for node in np.unique(list(edges)):
-        x = centroids[node][c1]
-        y = centroids[node][c2]
-        if scale:
-            x = x * e1 / r1 + d1
-            y = y * e2 / r2 + d2
-        plt.text(x, y, str(node), **tkw)
-
-
-def plot_ar(geo_model, path=None, project_name=None, api_token=None, secret=None):
-    """ Create, upload and retrieve tag to visualize the model in AR in rexview
-
-    https://www.rexos.org/getting-started/
-
-    Args:
-        geo_model (gempy.Model):
-        path: Location for rex files. Default cwd
-        project_name: Name of the project in rexos
-        api_token: rexos api token
-        secret: rexos secret
-
-    Returns:
-        gempy.addons.rex_api.Rextag
-    """
-    from gempy.addons.rex_api import upload_to_rexcloud
-    from gempy.addons.gempy_to_rexfile import write_rex, geomodel_to_rex
-    if project_name is None:
-        project_name = geo_model.meta.project_name
-
-    if path is None:
-        path = './'
-
-    rex_bytes = geomodel_to_rex(geo_model)
-    files_path = write_rex(rex_bytes, path)
-    project_name_ = project_name
-    for i in range(40):
-        try:
-            tag = upload_to_rexcloud(files_path, project_name=project_name_,
-                                     api_token=api_token, secret=secret)
-            break
-        except ConnectionError:
-            project_name_ = project_name + str(i)
-            pass
-
-    return tag
+"""
+    This file is part of gempy.
+
+    gempy is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    gempy is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
+
+    Module with classes and methods to perform implicit regional modelling based on
+    the potential field method.
+    Tested on Ubuntu 16
+
+    Created on 10/11/2019
+
+    @author: Alex Schaaf, Elisa Heim, Miguel de la Varga
+"""
+
+# This is for sphenix to find the packages
+# sys.path.append( path.dirname( path.dirname( path.abspath(__file__) ) ) )
+
+from typing import Union, List, Any
+
+import matplotlib.pyplot as plt
+# from .vista import Vista
+# import gempy as _gempy
+import numpy as np
+import pandas as pn
+from gempy.plot.vista import GemPyToVista
+
+# Keep Alex code hidden until we merge it properly
+try:
+    import pyvista as pv
+    from ._vista import Vista as Vista
+
+    PYVISTA_IMPORT = True
+except ImportError:
+    PYVISTA_IMPORT = False
+
+from .visualization_2d import Plot2D
+
+try:
+    import mplstereonet
+
+    mplstereonet_import = True
+except ImportError:
+    mplstereonet_import = False
+
+
+def plot_2d(model, n_axis=None, section_names: list = None,
+            cell_number: int = None, direction: str = 'y',
+            show_data: Union[bool, list] = True,
+            show_results: Union[bool, list] = True,
+            show_lith: Union[bool, list] = True,
+            show_values: Union[bool, list] = False,
+            show_block: Union[bool, list] = False,
+            show_scalar: Union[bool, list] = False,
+            show_boundaries: Union[bool, list] = True,
+            show_topography: Union[bool, list] = False,
+            show_section_traces: Union[bool, list] = True,
+            series_n: Union[int, List[int]] = 0,
+            ve=1,
+            block=None,
+            regular_grid=None,
+            kwargs_topography=None,
+            kwargs_regular_grid=None,
+            **kwargs):
+    """Plot 2-D sections of geomodel.
+
+    Plot cross sections either based on custom section traces or cell number in xyz direction.
+    Options to plot lithology block, scalar field or rendered surface lines.
+    Input data and topography can be included.
+
+    Args:
+        show_block (bool): If True and model has been computed, plot cross section
+         of the final model.
+        show_values (bool): If True and model has been computed, plot cross section
+         of the value... TODO need to add attribute to choose which value to be plot
+        model: Geomodel object with solutions.
+        n_axis (int): Subplot axis for multiple sections
+        section_names (list): Names of predefined custom section traces
+        cell_number (list): Position of the array to plot
+        direction (str): Cartesian direction to be plotted (xyz)
+        show_data (bool): Show original input data. Defaults to True.
+        show_results (bool): If False, override show lith, show_calar, show_values
+        show_lith (bool): Show lithological block volumes. Defaults to True.
+        show_scalar (bool): Show scalar field isolines. Defaults to False.
+        show_boundaries (bool): Show surface boundaries as lines. Defaults to True.
+        show_topography (bool): Show topography on plot. Defaults to False.
+        series_n (int): number of the scalar field.
+        ve (float): vertical exageration
+        regular_grid (numpy.ndarray): Numpy array of the size of model.grid.regular_grid
+        kwargs_topography (dict):
+            * fill_contour
+            * hillshade (bool): Calculate and add hillshading using elevation data
+            * azdeg (float): azimuth of sun for hillshade
+            * altdeg (float): altitude in degrees of sun for hillshade
+
+
+    Keyword Args:
+        legend (bool): If True plot legend. Default True
+        show (bool): Call matplotlib show
+
+    Returns:
+        :class:`gempy.plot.visualization_2d.Plot2D`: Plot2D object
+
+    """
+    if kwargs_regular_grid is None:
+        kwargs_regular_grid = dict()
+    if kwargs_topography is None:
+        kwargs_topography = dict()
+    if section_names is None and cell_number is None and direction is not None:
+        cell_number = ['mid']
+
+    show = kwargs.get('show', True)
+
+    if block is not None:
+        import warnings
+        regular_grid = block
+        warnings.warn('block is going to be deprecated. Use regular grid instead',
+                      DeprecationWarning)
+
+    section_names = [] if section_names is None else section_names
+    section_names = np.atleast_1d(section_names)
+    if cell_number is None:
+        cell_number = []
+    elif cell_number == 'mid':
+        cell_number = ['mid']
+    direction = [] if direction is None else direction
+
+    if type(cell_number) != list:
+        cell_number = [cell_number]
+
+    if type(direction) != list:
+        direction = [direction]
+
+    if n_axis is None:
+        n_axis = len(section_names) + len(cell_number)
+
+    if show_results is False:
+        show_lith = False
+        show_values = False
+        show_block = False
+        show_scalar = False
+        show_boundaries = False
+
+    if type(show_data) is bool:
+        show_data = [show_data] * n_axis
+    if type(show_lith) is bool:
+        show_lith = [show_lith] * n_axis
+    if type(show_values) is bool:
+        show_values = [show_values] * n_axis
+    if type(show_block) is bool:
+        show_block = [show_block] * n_axis
+    if type(show_scalar) is bool:
+        show_scalar = [show_scalar] * n_axis
+    if type(show_boundaries) is bool:
+        show_boundaries = [show_boundaries] * n_axis
+    if type(show_topography) is bool:
+        show_topography = [show_topography] * n_axis
+    if type(series_n) is int:
+        series_n = [series_n] * n_axis
+
+    # init e
+    e = 0
+    # is 10 and 10 because in the ax pos is the second digit
+    n_columns_ = 1 if len(section_names) + len(cell_number) < 2 else 2
+    n_columns = n_columns_ * 10  # This is for the axis location syntax
+    n_rows = (len(section_names) + len(cell_number)) / n_columns_
+
+    n_columns_ = np.max([n_columns_, 1])
+    n_rows = np.max([n_rows, 1])
+
+    p = Plot2D(model, **kwargs)
+    p.create_figure(cols=n_columns_, rows=n_rows, **kwargs)
+
+    for e, sn in enumerate(section_names):
+        # Check if a plot that fills all pixels is plotted
+        _is_filled = False
+        assert e < 10, 'Reached maximum of axes'
+
+        ax_pos = (round(n_axis / 2 + 0.1)) * 100 + n_columns + e + 1
+        temp_ax = p.add_section(section_name=sn, ax_pos=ax_pos, ve=ve, **kwargs)
+        if show_data[e] is True:
+            p.plot_data(temp_ax, section_name=sn, **kwargs)
+        if show_lith[e] is True and model.solutions.lith_block.shape[0] != 0:
+            _is_filled = True
+            p.plot_lith(temp_ax, section_name=sn, **kwargs)
+        elif show_values[e] is True and model.solutions.values_matrix.shape[0] != 0:
+            _is_filled = True
+            p.plot_values(temp_ax, series_n=series_n[e], section_name=sn, **kwargs)
+        elif show_block[e] is True and model.solutions.block_matrix.shape[0] != 0:
+            _is_filled = True
+            p.plot_block(temp_ax, series_n=series_n[e], section_name=sn, **kwargs)
+        if show_scalar[e] is True and model.solutions.scalar_field_matrix.shape[0] != 0:
+            _is_filled = True
+            p.plot_scalar_field(temp_ax, series_n=series_n[e], section_name=sn, **kwargs)
+        if show_boundaries[e] is True and model.solutions.scalar_field_matrix.shape[0] != 0:
+            p.plot_contacts(temp_ax, section_name=sn, **kwargs)
+        if show_topography[e] is True:
+            # Check if anything dense is plot. If not plot dense topography
+            f_c_ = not _is_filled
+            # f_c = kwargs_topography.get('fill_contour', f_c_)
+            if 'fill_contour' not in kwargs_topography:
+                kwargs_topography['fill_contour'] = f_c_
+            p.plot_topography(temp_ax, section_name=sn,  # fill_contour=f_c,
+                              **kwargs_topography)
+            if show_section_traces is True and sn == 'topography':
+                p.plot_section_traces(temp_ax)
+
+        if regular_grid is not None:
+            p.plot_regular_grid(temp_ax, block=regular_grid, section_name=sn,
+                                **kwargs_regular_grid)
+
+        temp_ax.set_aspect(ve)
+
+        # If there are section we need to shift one axis for the perpendicular
+        e = e + 1
+
+    for e2 in range(len(cell_number)):
+        assert (e + e2) < 10, 'Reached maximum of axes'
+
+        ax_pos = (round(n_axis / 2 + 0.1)) * 100 + n_columns + e + e2 + 1
+        temp_ax = p.add_section(cell_number=cell_number[e2],
+                                direction=direction[e2], ax_pos=ax_pos, ve=ve)
+        if show_data[e + e2] is True:
+            p.plot_data(temp_ax, cell_number=cell_number[e2],
+                        direction=direction[e2], **kwargs)
+        if show_lith[e + e2] is True and model.solutions.lith_block.shape[0] != 0:
+            p.plot_lith(temp_ax, cell_number=cell_number[e2],
+                        direction=direction[e2], **kwargs)
+        elif show_values[e + e2] is True and model.solutions.values_matrix.shape[0] != 0:
+            p.plot_values(temp_ax, series_n=series_n[e], cell_number=cell_number[e2],
+                          direction=direction[e2], **kwargs)
+        elif show_block[e + e2] is True and model.solutions.block_matrix.shape[0] != 0:
+            p.plot_block(temp_ax, series_n=series_n[e], cell_number=cell_number[e2],
+                         direction=direction[e2], **kwargs)
+        if show_scalar[e + e2] is True and model.solutions.scalar_field_matrix.shape[0] != 0:
+            p.plot_scalar_field(temp_ax, series_n=series_n[e], cell_number=cell_number[e2],
+                                direction=direction[e2], **kwargs)
+        if show_boundaries[e + e2] is True and model.solutions.scalar_field_matrix.shape[0] != 0:
+            p.plot_contacts(temp_ax, cell_number=cell_number[e2],
+                            direction=direction[e2], **kwargs)
+        if show_topography[e + e2] is True:
+            p.plot_topography(temp_ax, cell_number=cell_number[e2],
+                              direction=direction[e2], **kwargs_topography)
+        if regular_grid is not None:
+            p.plot_regular_grid(temp_ax, block=regular_grid, cell_number=cell_number[e2],
+                                direction=direction[e2], **kwargs_regular_grid)
+
+        temp_ax.set_aspect(ve)
+
+    if show is True:
+        p.fig.show()
+
+    return p
+
+
+def plot_3d(model, plotter_type='basic',
+            show_data: bool = True,
+            show_results: bool = True,
+            show_surfaces: bool = True,
+            show_lith: bool = True,
+            show_scalar: bool = False,
+            show_boundaries: bool = True,
+            show_topography: Union[bool, list] = False,
+            scalar_field: str = None,
+            ve=None,
+            kwargs_plot_structured_grid=None,
+            kwargs_plot_topography=None,
+            kwargs_plot_data=None,
+            image=False,
+            off_screen=False, **kwargs) -> GemPyToVista:
+    """foobar
+
+    Args:
+
+        model (:class:`gempy.core.model.Project`): Container class of all
+         objects that constitute a GemPy model.
+        plotter_type: PyVista plotter types. Supported plotters are:
+         'basic', 'background', and 'notebook'.
+        show_data (bool): Show original input data. Defaults to True.
+        show_results (bool): If False, override show lith, show_scalar, show_values
+        show_lith (bool): Show lithological block volumes. Defaults to True.
+        show_scalar (bool): Show scalar field isolines. Defaults to False.
+        show_boundaries (bool): Show surface boundaries as lines. Defaults to True.
+        show_topography (bool): Show topography on plot. Defaults to False.
+        scalar_field (str): Name of the field to be activated
+        series_n (int): number of the scalar field.
+        ve (float): Vertical Exaggeration
+        kwargs_plot_structured_grid:
+        kwargs_plot_topography:
+        **kwargs:
+
+    Returns:
+        :class:`gempy.plot.vista.GemPyToVista`
+
+    """
+    if image is True:
+        off_screen = True
+        kwargs['off_screen'] = True
+        plotter_type = 'basic'
+    if show_results is False:
+        show_surfaces = False
+        show_scalar = False
+        show_lith = False
+
+    if kwargs_plot_topography is None:
+        kwargs_plot_topography = dict()
+    if kwargs_plot_structured_grid is None:
+        kwargs_plot_structured_grid = dict()
+    if kwargs_plot_data is None:
+        kwargs_plot_data = dict()
+
+    fig_path: str = kwargs.get('fig_path', None)
+
+    gpv = GemPyToVista(model, plotter_type=plotter_type, **kwargs)
+    if show_surfaces and len(model.solutions.vertices) != 0:
+        gpv.plot_surfaces()
+    if show_lith is True and model.solutions.lith_block.shape[0] != 0:
+        gpv.plot_structured_grid('lith', **kwargs_plot_structured_grid)
+    if show_scalar is True and model.solutions.scalar_field_matrix.shape[0] != 0:
+        gpv.plot_structured_grid("scalar", series=scalar_field)
+
+    if show_data:
+        gpv.plot_data(**kwargs_plot_data)
+
+    if show_topography and model._grid.topography is not None:
+        gpv.plot_topography(**kwargs_plot_topography)
+
+    if ve is not None:
+        gpv.p.set_scale(zscale=ve)
+
+    if fig_path is not None:
+        gpv.p.show(screenshot=fig_path)
+
+    if image is True:
+        img = gpv.p.show(screenshot=True)
+        img = gpv.p.last_image
+        plt.imshow(img[1])
+        plt.axis('off')
+        plt.show(block=False)
+        gpv.p.close()
+
+    if off_screen is False:
+        gpv.p.show()
+
+    return gpv
+
+
+def plot_interactive_3d(
+        geo_model,
+        scalar_field: str = 'all',
+        series=None,
+        show_topography: bool = False,
+        **kwargs,
+):
+    """Plot interactive 3-D geomodel with three cross sections in subplots.
+    Args:
+        geo_model: Geomodel object with solutions.
+        name (str): Can be either one of the following
+                'lith' - Lithology id block.
+                'scalar' - Scalar field block.
+                'values' - Values matrix block.
+        render_topography: Render topography. Defaults to False.
+        **kwargs:
+    Returns:
+        :class:`gempy.plot.vista.GemPyToVista`
+
+    """
+    gpv = GemPyToVista(geo_model, plotter_type='background', shape="1|3")
+    gpv.plot_data()
+    gpv.plot_structured_grid_interactive(scalar_field=scalar_field, series=series,
+                                         render_topography=show_topography, **kwargs)
+
+    return gpv
+
+
+def plot_section_traces(model):
+    """Plot section traces of section grid in 2-D topview (xy).
+
+    Args:
+        model: Geomodel object with solutions.
+
+    Returns:
+        (Plot2D) Plot2D object
+    """
+    pst = plot_2d(model, n_axis=1, direction=['z'], cell_number=[-1],
+                  show_data=False, show_boundaries=False, show_lith=False, show=False)
+    pst.plot_section_traces(pst.axes[0], show_data=False)
+    return pst
+
+
+def plot_stereonet(self, litho=None, planes=True, poles=True,
+                   single_plots=False,
+                   show_density=False):
+    if mplstereonet_import is False:
+        raise ImportError(
+            'mplstereonet package is not installed. No stereographic projection available.')
+
+    from collections import OrderedDict
+
+    if litho is None:
+        litho = self.model._orientations.df['surface'].unique()
+
+    if single_plots is False:
+        fig, ax = mplstereonet.subplots(figsize=(5, 5))
+        df_sub2 = pn.DataFrame()
+        for i in litho:
+            df_sub2 = df_sub2.append(self.model._orientations.df[
+                                         self.model._orientations.df[
+                                             'surface'] == i])
+
+    for formation in litho:
+        if single_plots:
+            fig = plt.figure(figsize=(5, 5))
+            ax = fig.add_subplot(111, projection='stereonet')
+            ax.set_title(formation, y=1.1)
+
+        # if series_only:
+        # df_sub = self.model.orientations.df[self.model.orientations.df['series'] == formation]
+        # else:
+        df_sub = self.model._orientations.df[
+            self.model._orientations.df['surface'] == formation]
+
+        if poles:
+            ax.pole(df_sub['azimuth'] - 90, df_sub['dip'], marker='o',
+                    markersize=7,
+                    markerfacecolor=self._color_lot[formation],
+                    markeredgewidth=1.1, markeredgecolor='gray',
+                    label=formation + ': ' + 'pole point')
+        if planes:
+            ax.plane(df_sub['azimuth'] - 90, df_sub['dip'],
+                     color=self._color_lot[formation],
+                     linewidth=1.5, label=formation + ': ' + 'azimuth/dip')
+        if show_density:
+            if single_plots:
+                ax.density_contourf(df_sub['azimuth'] - 90, df_sub['dip'],
+                                    measurement='poles', cmap='viridis',
+                                    alpha=.5)
+            else:
+                ax.density_contourf(df_sub2['azimuth'] - 90, df_sub2['dip'],
+                                    measurement='poles', cmap='viridis',
+                                    alpha=.5)
+
+        fig.subplots_adjust(top=0.8)
+        handles, labels = ax.get_legend_handles_labels()
+        by_label = OrderedDict(zip(labels, handles))
+        ax.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(1.9, 1.1))
+        ax._grid(True, color='black', alpha=0.25)
+
+
+def plot_topology(geo_model, edges, centroids, direction="y", scale=True,
+                  label_kwargs=None, edge_kwargs=None):
+    """Plot the topology adjacency graph in 2-D.
+
+        Args:
+            geo_model ([type]): GemPy geomodel instance.
+            edges (Set[Tuple[int, int]]): Set of topology edges.
+            centroids (Dict[int, Array[int, 3]]): Dictionary of topology id's and
+                their centroids.
+            direction (Union["x", "y", "z", optional): Section direction.
+                Defaults to "y".
+            label_kwargs (dict, optional): Keyword arguments for topology labels.
+                Defaults to None.
+            edge_kwargs (dict, optional): Keyword arguments for topology edges.
+                Defaults to None.
+
+        """
+    res = geo_model._grid.regular_grid.resolution
+    if direction == "y":
+        c1, c2 = (0, 2)
+        e1 = geo_model._grid.regular_grid.extent[1] - geo_model._grid.regular_grid.extent[0]
+        e2 = geo_model._grid.regular_grid.extent[5] - geo_model._grid.regular_grid.extent[4]
+        d1 = geo_model._grid.regular_grid.extent[0]
+        d2 = geo_model._grid.regular_grid.extent[4]
+        # if len(list(centroids.items())[0][1]) == 2:
+        #     c1, c2 = (0, 1)
+        r1 = res[0]
+        r2 = res[2]
+    elif direction == "x":
+        c1, c2 = (1, 2)
+        e1 = geo_model._grid.regular_grid.extent[3] - geo_model._grid.regular_grid.extent[2]
+        e2 = geo_model._grid.regular_grid.extent[5] - geo_model._grid.regular_grid.extent[4]
+        d1 = geo_model._grid.regular_grid.extent[2]
+        d2 = geo_model._grid.regular_grid.extent[4]
+        # if len(list(centroids.items())[0][1]) == 2:
+        #     c1, c2 = (0, 1)
+        r1 = res[1]
+        r2 = res[2]
+    elif direction == "z":
+        c1, c2 = (0, 1)
+        e1 = geo_model._grid.regular_grid.extent[1] - geo_model._grid.regular_grid.extent[0]
+        e2 = geo_model._grid.regular_grid.extent[3] - geo_model._grid.regular_grid.extent[2]
+        d1 = geo_model._grid.regular_grid.extent[0]
+        d2 = geo_model._grid.regular_grid.extent[2]
+        # if len(list(centroids.items())[0][1]) == 2:
+        #     c1, c2 = (0, 1)
+        r1 = res[0]
+        r2 = res[1]
+
+    tkw = {
+        "color": "white",
+        "fontsize": 13,
+        "ha": "center",
+        "va": "center",
+        "weight": "ultralight",
+        "family": "monospace",
+        "verticalalignment": "center",
+        "horizontalalignment": "center",
+        "bbox": dict(boxstyle='round', facecolor='black', alpha=1),
+    }
+    if label_kwargs is not None:
+        tkw.update(label_kwargs)
+
+    lkw = {
+        "linewidth": 1,
+        "color": "black"
+    }
+    if edge_kwargs is not None:
+        lkw.update(edge_kwargs)
+
+    for a, b in edges:
+        # plot edges
+        x = np.array([centroids[a][c1], centroids[b][c1]])
+        y = np.array([centroids[a][c2], centroids[b][c2]])
+        if scale:
+            x = x * e1 / r1 + d1
+            y = y * e2 / r2 + d2
+        plt.plot(x, y, **lkw)
+
+    for node in np.unique(list(edges)):
+        x = centroids[node][c1]
+        y = centroids[node][c2]
+        if scale:
+            x = x * e1 / r1 + d1
+            y = y * e2 / r2 + d2
+        plt.text(x, y, str(node), **tkw)
+
+
+def plot_ar(geo_model, path=None, project_name=None, api_token=None, secret=None):
+    """ Create, upload and retrieve tag to visualize the model in AR in rexview
+
+    https://www.rexos.org/getting-started/
+
+    Args:
+        geo_model (gempy.Model):
+        path: Location for rex files. Default cwd
+        project_name: Name of the project in rexos
+        api_token: rexos api token
+        secret: rexos secret
+
+    Returns:
+        gempy.addons.rex_api.Rextag
+    """
+    from gempy.addons.rex_api import upload_to_rexcloud
+    from gempy.addons.gempy_to_rexfile import write_rex, geomodel_to_rex
+    if project_name is None:
+        project_name = geo_model.meta.project_name
+
+    if path is None:
+        path = './'
+
+    rex_bytes = geomodel_to_rex(geo_model)
+    files_path = write_rex(rex_bytes, path)
+    project_name_ = project_name
+    for i in range(40):
+        try:
+            tag = upload_to_rexcloud(files_path, project_name=project_name_,
+                                     api_token=api_token, secret=secret)
+            break
+        except ConnectionError:
+            project_name_ = project_name + str(i)
+            pass
+
+    return tag
```

### Comparing `gempy-2.2b10.dev1/gempy/plot/plot_utils.py` & `gempy-2.3.0/gempy/plot/plot_utils.py`

 * *Ordering differences only*

 * *Files 27% similar despite different names*

```diff
@@ -1,433 +1,433 @@
-"""
-Modify after arviz 0.4!
-
-Utilities for plotting."""
-from itertools import product
-
-import numpy as np
-import matplotlib.pyplot as plt
-import matplotlib as mpl
-import xarray as xr
-
-
-def make_2d(ary):
-    """Convert any array into a 2d numpy array.
-
-    In case the array is already more than 2 dimensional, will ravel the
-    dimensions after the first.
-    """
-    dim_0, *_ = np.atleast_1d(ary).shape
-    return ary.reshape(dim_0, -1, order="F")
-
-
-def _scale_fig_size(figsize, textsize, rows=1, cols=1):
-    """Scale figure properties according to rows and cols.
-
-    Parameters
-    ----------
-    figsize : float or None
-        Size of figure in inches
-    textsize : float or None
-        fontsize
-    rows : int
-        Number of rows
-    cols : int
-        Number of columns
-
-    Returns
-    -------
-    figsize : float or None
-        Size of figure in inches
-    ax_labelsize : int
-        fontsize for axes label
-    titlesize : int
-        fontsize for title
-    xt_labelsize : int
-        fontsize for axes ticks
-    linewidth : int
-        linewidth
-    markersize : int
-        markersize
-    """
-    params = mpl.rcParams
-    rc_width, rc_height = tuple(params["figure.figsize"])
-    rc_ax_labelsize = params["axes.labelsize"]
-    rc_titlesize = params["axes.titlesize"]
-    rc_xt_labelsize = params["xtick.labelsize"]
-    rc_linewidth = params["lines.linewidth"]
-    rc_markersize = params["lines.markersize"]
-    if isinstance(rc_ax_labelsize, str):
-        rc_ax_labelsize = 15
-    if isinstance(rc_titlesize, str):
-        rc_titlesize = 16
-    if isinstance(rc_xt_labelsize, str):
-        rc_xt_labelsize = 14
-
-    if figsize is None:
-        width, height = rc_width, rc_height
-        sff = 1 if (rows == cols == 1) else 1.15
-        width = width * cols * sff
-        height = height * rows * sff
-    else:
-        width, height = figsize
-
-    if textsize is not None:
-        scale_factor = textsize / rc_xt_labelsize
-    elif rows == cols == 1:
-        scale_factor = ((width * height) / (rc_width * rc_height)) ** 0.5
-    else:
-        scale_factor = 1
-
-    ax_labelsize = rc_ax_labelsize * scale_factor
-    titlesize = rc_titlesize * scale_factor
-    xt_labelsize = rc_xt_labelsize * scale_factor
-    linewidth = rc_linewidth * scale_factor
-    markersize = rc_markersize * scale_factor
-
-    return (width, height), ax_labelsize, titlesize, xt_labelsize, linewidth, markersize
-
-
-def get_bins(values):
-    """
-    Automatically compute the number of bins for discrete variables.
-
-    Parameters
-    ----------
-    values = numpy array
-        values
-
-    Returns
-    -------
-    array with the bins
-
-    Notes
-    -----
-    Computes the width of the bins by taking the maximun of the Sturges and the Freedman-Diaconis
-    estimators. Acording to numpy `np.histogram` this provides good all around performance.
-
-    The Sturges is a very simplistic estimator based on the assumption of normality of the data.
-    This estimator has poor performance for non-normal data, which becomes especially obvious for
-    large data sets. The estimate depends only on size of the data.
-
-    The Freedman-Diaconis rule uses interquartile range (IQR) to estimate the binwidth.
-    It is considered a robusts version of the Scott rule as the IQR is less affected by outliers
-    than the standard deviation. However, the IQR depends on fewer points than the standard
-    deviation, so it is less accurate, especially for long tailed distributions.
-    """
-    x_min = values.min().astype(int)
-    x_max = values.max().astype(int)
-
-    # Sturges histogram bin estimator
-    bins_sturges = (x_max - x_min) / (np.log2(values.size) + 1)
-
-    # The Freedman-Diaconis histogram bin estimator.
-    iqr = np.subtract(*np.percentile(values, [75, 25]))  # pylint: disable=assignment-from-no-return
-    bins_fd = 2 * iqr * values.size ** (-1 / 3)
-
-    width = round(np.max([1, bins_sturges, bins_fd])).astype(int)
-
-    return np.arange(x_min, x_max + width + 1, width)
-
-
-def default_grid(n_items, max_cols=4, min_cols=3):  # noqa: D202
-    """Make a grid for subplots.
-
-    Tries to get as close to sqrt(n_items) x sqrt(n_items) as it can,
-    but allows for custom logic
-
-    Parameters
-    ----------
-    n_items : int
-        Number of panels required
-    max_cols : int
-        Maximum number of columns, inclusive
-    min_cols : int
-        Minimum number of columns, inclusive
-
-    Returns
-    -------
-    (int, int)
-        Rows and columns, so that rows * columns >= n_items
-    """
-
-    def in_bounds(val):
-        return np.clip(val, min_cols, max_cols)
-
-    if n_items <= max_cols:
-        return 1, n_items
-    ideal = in_bounds(round(n_items ** 0.5))
-
-    for offset in (0, 1, -1, 2, -2):
-        cols = in_bounds(ideal + offset)
-        rows, extra = divmod(n_items, cols)
-        if extra == 0:
-            return rows, cols
-    return n_items // ideal + 1, ideal
-
-
-def _create_axes_grid(length_plotters, rows, cols, **kwargs):
-    """Create figure and axes for grids with multiple plots.
-
-    Parameters
-    ----------
-    n_items : int
-        Number of panels required
-    rows : int
-        Number of rows
-    cols : int
-        Number of columns
-
-    Returns
-    -------
-    fig : matplotlib figure
-    ax : matplotlib axes
-    """
-    kwargs.setdefault("constrained_layout", True)
-    fig, ax = plt.subplots(rows, cols, **kwargs)
-    ax = np.ravel(ax)
-    extra = (rows * cols) - length_plotters
-    if extra:
-        for i in range(1, extra + 1):
-            ax[-i].set_axis_off()
-        ax = ax[:-extra]
-    return fig, ax
-
-
-def selection_to_string(selection):
-    """Convert dictionary of coordinates to a string for labels.
-
-    Parameters
-    ----------
-    selection : dict[Any] -> Any
-
-    Returns
-    -------
-    str
-        key1: value1, key2: value2, ...
-    """
-    return ", ".join(["{}".format(v) for _, v in selection.items()])
-
-
-def make_label(var_name, selection, position="below"):
-    """Consistent labelling for plots.
-
-    Parameters
-    ----------
-    var_name : str
-       Name of the variable
-
-    selection : dict[Any] -> Any
-        Coordinates of the variable
-    position : whether to position the coordinates' label "below" (default) or "beside" the name
-               of the variable
-
-    Returns
-    -------
-    label
-        A text representation of the label
-    """
-    if selection:
-        sel = selection_to_string(selection)
-        if position == "below":
-            sep = "\n"
-        elif position == "beside":
-            sep = " "
-    else:
-        sep = sel = ""
-    return "{}{}{}".format(var_name, sep, sel)
-
-
-def purge_duplicates(list_in):
-    """Remove duplicates from list while preserving order.
-
-    Parameters
-    ----------
-    list_in: Iterable
-
-    Returns
-    -------
-    list
-        List of first occurences in order
-    """
-    _list = []
-    for item in list_in:
-        if item not in _list:
-            _list.append(item)
-    return _list
-
-
-def xarray_var_iter(data, var_names=None, combined=False, skip_dims=None, reverse_selections=False):
-    """Convert xarray data to an iterator over vectors.
-
-    Iterates over each var_name and all of its coordinates, returning the 1d
-    data.
-
-    Parameters
-    ----------
-    data : xarray.Dataset
-        Posterior data in an xarray
-
-    var_names : iterator of strings (optional)
-        Should be a subset of data.data_vars. Defaults to all of them.
-
-    combined : bool
-        Whether to combine chains or leave them separate
-
-    skip_dims : set
-        dimensions to not iterate over
-
-    reverse_selections : bool
-        Whether to reverse selections before iterating.
-
-    Returns
-    -------
-    Iterator of (str, dict(str, any), np.array)
-        The string is the variable name, the dictionary are coordinate names to values,
-        and the array are the values of the variable at those coordinates.
-    """
-    if skip_dims is None:
-        skip_dims = set()
-
-    if combined:
-        skip_dims = skip_dims.union({"chain", "draw"})
-    else:
-        skip_dims.add("draw")
-
-    if var_names is None:
-        if isinstance(data, xr.Dataset):
-            var_names = list(data.data_vars)
-        elif isinstance(data, xr.DataArray):
-            var_names = [data.name]
-            data = {data.name: data}
-
-    for var_name in var_names:
-        if var_name in data:
-            new_dims = [dim for dim in data[var_name].dims if dim not in skip_dims]
-            vals = [purge_duplicates(data[var_name][dim].values) for dim in new_dims]
-            dims = [{k: v for k, v in zip(new_dims, prod)} for prod in product(*vals)]
-            if reverse_selections:
-                dims = reversed(dims)
-
-            for selection in dims:
-                yield var_name, selection, data[var_name].sel(**selection).values
-
-
-def xarray_to_ndarray(data, *, var_names=None, combined=True):
-    """Take xarray data and unpacks into variables and data into list and numpy array respectively.
-
-    Assumes that chain and draw are in coordinates
-
-    Parameters
-    ----------
-    data: xarray.DataSet
-        Data in an xarray from an InferenceData object. Examples include posterior or sample_stats
-
-    var_names: iter
-        Should be a subset of data.data_vars not including chain and draws. Defaults to all of them
-
-    combined: bool
-        Whether to combine chain into one array
-
-    Returns
-    -------
-    var_names: list
-        List of variable names
-    data: np.array
-        Data values
-    """
-    unpacked_data, unpacked_var_names, = [], []
-
-    # Merge chains and variables
-    for var_name, selection, data_array in xarray_var_iter(
-        data, var_names=var_names, combined=combined
-    ):
-        unpacked_data.append(data_array.flatten())
-        unpacked_var_names.append(make_label(var_name, selection))
-
-    return unpacked_var_names, np.array(unpacked_data)
-
-
-def get_coords(data, coords):
-    """Subselects xarray DataSet or DataArray object to provided coords. Raises exception if fails.
-
-    Raises
-    ------
-    ValueError
-        If coords name are not available in data
-
-    KeyError
-        If coords dims are not available in data
-
-    Returns
-    -------
-    data: xarray
-        xarray.DataSet or xarray.DataArray object, same type as input
-    """
-    try:
-        return data.sel(**coords)
-
-    except ValueError:
-        invalid_coords = set(coords.keys()) - set(data.coords.keys())
-        raise ValueError("Coords {} are invalid coordinate keys".format(invalid_coords))
-
-    except KeyError as err:
-        raise KeyError(
-            (
-                "Coords should follow mapping format {{coord_name:[dim1, dim2]}}. "
-                "Check that coords structure is correct and"
-                " dimensions are valid. {}"
-            ).format(err)
-        )
-
-
-def color_from_dim(dataarray, dim_name):
-    """Return colors and color mapping of a DataArray using coord values as color code.
-
-    Parameters
-    ----------
-    dataarray : xarray.DataArray
-    dim_name : str
-        dimension whose coordinates will be used as color code.
-
-    Returns
-    -------
-    colors : array of floats
-        Array of colors (as floats for use with a cmap) for each element in the dataarray.
-    color_mapping : mapping coord_value -> float
-        Mapping from coord values to corresponding color
-    """
-    present_dims = dataarray.dims
-    coord_values = dataarray[dim_name].values
-    unique_coords = set(coord_values)
-    color_mapping = {coord: num / len(unique_coords) for num, coord in enumerate(unique_coords)}
-    if len(present_dims) > 1:
-        multi_coords = dataarray.coords.to_index()
-        coord_idx = present_dims.index(dim_name)
-        colors = [color_mapping[coord[coord_idx]] for coord in multi_coords]
-    else:
-        colors = [color_mapping[coord] for coord in coord_values]
-    return colors, color_mapping
-
-
-def format_coords_as_labels(dataarray):
-    """Format 1d or multi-d dataarray coords as strings."""
-    coord_labels = dataarray.coords.to_index().values
-    if isinstance(coord_labels[0], tuple):
-        fmt = ", ".join(["{}" for _ in coord_labels[0]])
-        coord_labels[:] = [fmt.format(*x) for x in coord_labels]
-    else:
-        coord_labels[:] = ["{}".format(s) for s in coord_labels]
-    return coord_labels
-
-
-def set_xticklabels(ax, coord_labels):
-    """Set xticklabels to label list using Matplotlib default formatter."""
-    ax.xaxis.get_major_locator().set_params(nbins=9, steps=[1, 2, 5, 10])
-    xticks = ax.get_xticks().astype(np.int64)
-    xticks = xticks[(xticks >= 0) & (xticks < len(coord_labels))]
-    if len(xticks) > len(coord_labels):
-        ax.set_xticks(np.arange(len(coord_labels)))
-        ax.set_xticklabels(coord_labels)
-    else:
-        ax.set_xticks(xticks)
-        ax.set_xticklabels(coord_labels[xticks])
+"""
+Modify after arviz 0.4!
+
+Utilities for plotting."""
+from itertools import product
+
+import numpy as np
+import matplotlib.pyplot as plt
+import matplotlib as mpl
+import xarray as xr
+
+
+def make_2d(ary):
+    """Convert any array into a 2d numpy array.
+
+    In case the array is already more than 2 dimensional, will ravel the
+    dimensions after the first.
+    """
+    dim_0, *_ = np.atleast_1d(ary).shape
+    return ary.reshape(dim_0, -1, order="F")
+
+
+def _scale_fig_size(figsize, textsize, rows=1, cols=1):
+    """Scale figure properties according to rows and cols.
+
+    Parameters
+    ----------
+    figsize : float or None
+        Size of figure in inches
+    textsize : float or None
+        fontsize
+    rows : int
+        Number of rows
+    cols : int
+        Number of columns
+
+    Returns
+    -------
+    figsize : float or None
+        Size of figure in inches
+    ax_labelsize : int
+        fontsize for axes label
+    titlesize : int
+        fontsize for title
+    xt_labelsize : int
+        fontsize for axes ticks
+    linewidth : int
+        linewidth
+    markersize : int
+        markersize
+    """
+    params = mpl.rcParams
+    rc_width, rc_height = tuple(params["figure.figsize"])
+    rc_ax_labelsize = params["axes.labelsize"]
+    rc_titlesize = params["axes.titlesize"]
+    rc_xt_labelsize = params["xtick.labelsize"]
+    rc_linewidth = params["lines.linewidth"]
+    rc_markersize = params["lines.markersize"]
+    if isinstance(rc_ax_labelsize, str):
+        rc_ax_labelsize = 15
+    if isinstance(rc_titlesize, str):
+        rc_titlesize = 16
+    if isinstance(rc_xt_labelsize, str):
+        rc_xt_labelsize = 14
+
+    if figsize is None:
+        width, height = rc_width, rc_height
+        sff = 1 if (rows == cols == 1) else 1.15
+        width = width * cols * sff
+        height = height * rows * sff
+    else:
+        width, height = figsize
+
+    if textsize is not None:
+        scale_factor = textsize / rc_xt_labelsize
+    elif rows == cols == 1:
+        scale_factor = ((width * height) / (rc_width * rc_height)) ** 0.5
+    else:
+        scale_factor = 1
+
+    ax_labelsize = rc_ax_labelsize * scale_factor
+    titlesize = rc_titlesize * scale_factor
+    xt_labelsize = rc_xt_labelsize * scale_factor
+    linewidth = rc_linewidth * scale_factor
+    markersize = rc_markersize * scale_factor
+
+    return (width, height), ax_labelsize, titlesize, xt_labelsize, linewidth, markersize
+
+
+def get_bins(values):
+    """
+    Automatically compute the number of bins for discrete variables.
+
+    Parameters
+    ----------
+    values = numpy array
+        values
+
+    Returns
+    -------
+    array with the bins
+
+    Notes
+    -----
+    Computes the width of the bins by taking the maximun of the Sturges and the Freedman-Diaconis
+    estimators. Acording to numpy `np.histogram` this provides good all around performance.
+
+    The Sturges is a very simplistic estimator based on the assumption of normality of the data.
+    This estimator has poor performance for non-normal data, which becomes especially obvious for
+    large data sets. The estimate depends only on size of the data.
+
+    The Freedman-Diaconis rule uses interquartile range (IQR) to estimate the binwidth.
+    It is considered a robusts version of the Scott rule as the IQR is less affected by outliers
+    than the standard deviation. However, the IQR depends on fewer points than the standard
+    deviation, so it is less accurate, especially for long tailed distributions.
+    """
+    x_min = values.min().astype(int)
+    x_max = values.max().astype(int)
+
+    # Sturges histogram bin estimator
+    bins_sturges = (x_max - x_min) / (np.log2(values.size) + 1)
+
+    # The Freedman-Diaconis histogram bin estimator.
+    iqr = np.subtract(*np.percentile(values, [75, 25]))  # pylint: disable=assignment-from-no-return
+    bins_fd = 2 * iqr * values.size ** (-1 / 3)
+
+    width = round(np.max([1, bins_sturges, bins_fd])).astype(int)
+
+    return np.arange(x_min, x_max + width + 1, width)
+
+
+def default_grid(n_items, max_cols=4, min_cols=3):  # noqa: D202
+    """Make a grid for subplots.
+
+    Tries to get as close to sqrt(n_items) x sqrt(n_items) as it can,
+    but allows for custom logic
+
+    Parameters
+    ----------
+    n_items : int
+        Number of panels required
+    max_cols : int
+        Maximum number of columns, inclusive
+    min_cols : int
+        Minimum number of columns, inclusive
+
+    Returns
+    -------
+    (int, int)
+        Rows and columns, so that rows * columns >= n_items
+    """
+
+    def in_bounds(val):
+        return np.clip(val, min_cols, max_cols)
+
+    if n_items <= max_cols:
+        return 1, n_items
+    ideal = in_bounds(round(n_items ** 0.5))
+
+    for offset in (0, 1, -1, 2, -2):
+        cols = in_bounds(ideal + offset)
+        rows, extra = divmod(n_items, cols)
+        if extra == 0:
+            return rows, cols
+    return n_items // ideal + 1, ideal
+
+
+def _create_axes_grid(length_plotters, rows, cols, **kwargs):
+    """Create figure and axes for grids with multiple plots.
+
+    Parameters
+    ----------
+    n_items : int
+        Number of panels required
+    rows : int
+        Number of rows
+    cols : int
+        Number of columns
+
+    Returns
+    -------
+    fig : matplotlib figure
+    ax : matplotlib axes
+    """
+    kwargs.setdefault("constrained_layout", True)
+    fig, ax = plt.subplots(rows, cols, **kwargs)
+    ax = np.ravel(ax)
+    extra = (rows * cols) - length_plotters
+    if extra:
+        for i in range(1, extra + 1):
+            ax[-i].set_axis_off()
+        ax = ax[:-extra]
+    return fig, ax
+
+
+def selection_to_string(selection):
+    """Convert dictionary of coordinates to a string for labels.
+
+    Parameters
+    ----------
+    selection : dict[Any] -> Any
+
+    Returns
+    -------
+    str
+        key1: value1, key2: value2, ...
+    """
+    return ", ".join(["{}".format(v) for _, v in selection.items()])
+
+
+def make_label(var_name, selection, position="below"):
+    """Consistent labelling for plots.
+
+    Parameters
+    ----------
+    var_name : str
+       Name of the variable
+
+    selection : dict[Any] -> Any
+        Coordinates of the variable
+    position : whether to position the coordinates' label "below" (default) or "beside" the name
+               of the variable
+
+    Returns
+    -------
+    label
+        A text representation of the label
+    """
+    if selection:
+        sel = selection_to_string(selection)
+        if position == "below":
+            sep = "\n"
+        elif position == "beside":
+            sep = " "
+    else:
+        sep = sel = ""
+    return "{}{}{}".format(var_name, sep, sel)
+
+
+def purge_duplicates(list_in):
+    """Remove duplicates from list while preserving order.
+
+    Parameters
+    ----------
+    list_in: Iterable
+
+    Returns
+    -------
+    list
+        List of first occurences in order
+    """
+    _list = []
+    for item in list_in:
+        if item not in _list:
+            _list.append(item)
+    return _list
+
+
+def xarray_var_iter(data, var_names=None, combined=False, skip_dims=None, reverse_selections=False):
+    """Convert xarray data to an iterator over vectors.
+
+    Iterates over each var_name and all of its coordinates, returning the 1d
+    data.
+
+    Parameters
+    ----------
+    data : xarray.Dataset
+        Posterior data in an xarray
+
+    var_names : iterator of strings (optional)
+        Should be a subset of data.data_vars. Defaults to all of them.
+
+    combined : bool
+        Whether to combine chains or leave them separate
+
+    skip_dims : set
+        dimensions to not iterate over
+
+    reverse_selections : bool
+        Whether to reverse selections before iterating.
+
+    Returns
+    -------
+    Iterator of (str, dict(str, any), np.array)
+        The string is the variable name, the dictionary are coordinate names to values,
+        and the array are the values of the variable at those coordinates.
+    """
+    if skip_dims is None:
+        skip_dims = set()
+
+    if combined:
+        skip_dims = skip_dims.union({"chain", "draw"})
+    else:
+        skip_dims.add("draw")
+
+    if var_names is None:
+        if isinstance(data, xr.Dataset):
+            var_names = list(data.data_vars)
+        elif isinstance(data, xr.DataArray):
+            var_names = [data.name]
+            data = {data.name: data}
+
+    for var_name in var_names:
+        if var_name in data:
+            new_dims = [dim for dim in data[var_name].dims if dim not in skip_dims]
+            vals = [purge_duplicates(data[var_name][dim].values) for dim in new_dims]
+            dims = [{k: v for k, v in zip(new_dims, prod)} for prod in product(*vals)]
+            if reverse_selections:
+                dims = reversed(dims)
+
+            for selection in dims:
+                yield var_name, selection, data[var_name].sel(**selection).values
+
+
+def xarray_to_ndarray(data, *, var_names=None, combined=True):
+    """Take xarray data and unpacks into variables and data into list and numpy array respectively.
+
+    Assumes that chain and draw are in coordinates
+
+    Parameters
+    ----------
+    data: xarray.DataSet
+        Data in an xarray from an InferenceData object. Examples include posterior or sample_stats
+
+    var_names: iter
+        Should be a subset of data.data_vars not including chain and draws. Defaults to all of them
+
+    combined: bool
+        Whether to combine chain into one array
+
+    Returns
+    -------
+    var_names: list
+        List of variable names
+    data: np.array
+        Data values
+    """
+    unpacked_data, unpacked_var_names, = [], []
+
+    # Merge chains and variables
+    for var_name, selection, data_array in xarray_var_iter(
+        data, var_names=var_names, combined=combined
+    ):
+        unpacked_data.append(data_array.flatten())
+        unpacked_var_names.append(make_label(var_name, selection))
+
+    return unpacked_var_names, np.array(unpacked_data)
+
+
+def get_coords(data, coords):
+    """Subselects xarray DataSet or DataArray object to provided coords. Raises exception if fails.
+
+    Raises
+    ------
+    ValueError
+        If coords name are not available in data
+
+    KeyError
+        If coords dims are not available in data
+
+    Returns
+    -------
+    data: xarray
+        xarray.DataSet or xarray.DataArray object, same type as input
+    """
+    try:
+        return data.sel(**coords)
+
+    except ValueError:
+        invalid_coords = set(coords.keys()) - set(data.coords.keys())
+        raise ValueError("Coords {} are invalid coordinate keys".format(invalid_coords))
+
+    except KeyError as err:
+        raise KeyError(
+            (
+                "Coords should follow mapping format {{coord_name:[dim1, dim2]}}. "
+                "Check that coords structure is correct and"
+                " dimensions are valid. {}"
+            ).format(err)
+        )
+
+
+def color_from_dim(dataarray, dim_name):
+    """Return colors and color mapping of a DataArray using coord values as color code.
+
+    Parameters
+    ----------
+    dataarray : xarray.DataArray
+    dim_name : str
+        dimension whose coordinates will be used as color code.
+
+    Returns
+    -------
+    colors : array of floats
+        Array of colors (as floats for use with a cmap) for each element in the dataarray.
+    color_mapping : mapping coord_value -> float
+        Mapping from coord values to corresponding color
+    """
+    present_dims = dataarray.dims
+    coord_values = dataarray[dim_name].values
+    unique_coords = set(coord_values)
+    color_mapping = {coord: num / len(unique_coords) for num, coord in enumerate(unique_coords)}
+    if len(present_dims) > 1:
+        multi_coords = dataarray.coords.to_index()
+        coord_idx = present_dims.index(dim_name)
+        colors = [color_mapping[coord[coord_idx]] for coord in multi_coords]
+    else:
+        colors = [color_mapping[coord] for coord in coord_values]
+    return colors, color_mapping
+
+
+def format_coords_as_labels(dataarray):
+    """Format 1d or multi-d dataarray coords as strings."""
+    coord_labels = dataarray.coords.to_index().values
+    if isinstance(coord_labels[0], tuple):
+        fmt = ", ".join(["{}" for _ in coord_labels[0]])
+        coord_labels[:] = [fmt.format(*x) for x in coord_labels]
+    else:
+        coord_labels[:] = ["{}".format(s) for s in coord_labels]
+    return coord_labels
+
+
+def set_xticklabels(ax, coord_labels):
+    """Set xticklabels to label list using Matplotlib default formatter."""
+    ax.xaxis.get_major_locator().set_params(nbins=9, steps=[1, 2, 5, 10])
+    xticks = ax.get_xticks().astype(np.int64)
+    xticks = xticks[(xticks >= 0) & (xticks < len(coord_labels))]
+    if len(xticks) > len(coord_labels):
+        ax.set_xticks(np.arange(len(coord_labels)))
+        ax.set_xticklabels(coord_labels)
+    else:
+        ax.set_xticks(xticks)
+        ax.set_xticklabels(coord_labels[xticks])
```

### Comparing `gempy-2.2b10.dev1/gempy/plot/sequential_pile.py` & `gempy-2.3.0/gempy/plot/sequential_pile.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,336 +1,336 @@
-"""
-    This file is part of gempy.
-
-    gempy is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    gempy is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
-"""
-
-import numpy as np
-import pandas as pn
-import matplotlib.pyplot as plt
-#from gempy.plot.colors import *
-#import matplotlib.cm as cm
-#from gempy.plot.colors import color_lot, cmap, norm
-from typing import TYPE_CHECKING
-if TYPE_CHECKING:
-    from gempy import Series
-
-
-#import matplotlib.colors as mcolors
-
-def set_anchor_points(series_object, surface_object):
-    """
-    Compute the location of each series and surface depending on the number of those
-
-    Args:
-        geo_model (gempy.data_management.InputData):
-
-    Returns:
-        list:
-        - DataFrame: location of the series
-
-        - DataFrame: location of the surfaces
-
-        - float: thickness of the series
-
-        - list, floats:
-
-    """
-    # Surfaces per serie
-    series_names = series_object.df.index
-    # Get number of series
-    n_series = len(series_object.df.index)
-
-    # Make anchor points for each serie
-    anch_series_pos_aux = np.linspace(10, 0, n_series, endpoint=True)
-    anch_series_pos = pn.DataFrame(anch_series_pos_aux.reshape(1, -1),
-                                   columns=series_names)
-
-    # Thicknes of series. We just make sure we have white space in between
-    thick_series = 11.5 / n_series
-
-    # Setting surfaces anchor
-    anch_surfaces_pos = pn.DataFrame()
-    thick_surfaces = []
-    for series in series_names:
-        try:
-            surfaces = surface_object.set_index('series').loc[series, 'surface']
-            #if type(surfaces) is not str or type(surfaces) is not np.str_:
-            try:
-                surfaces = surfaces.values
-            except AttributeError:
-                pass
-        except KeyError:
-            surfaces = np.empty(0, dtype='object')
-
-        surfaces = np.insert(surfaces, 0, '0_aux' + series)
-        surfaces = np.append(surfaces, '1_aux' + series)
-        anch_for_df = pn.DataFrame(
-            np.linspace(anch_series_pos[series][0] + thick_series / 2,
-                        anch_series_pos[series][0] - thick_series / 2,
-                        surfaces.shape[0],
-                        endpoint=True).reshape(1, -1),
-            columns=surfaces)
-
-        anch_surfaces_pos = pn.concat([anch_surfaces_pos, anch_for_df],
-                                        axis=1)
-        thick_surfaces = np.append(thick_surfaces,
-                                     (np.tile((thick_series - 2) / surfaces.shape[0], surfaces.shape[0])))
-
-    return anch_series_pos, anch_surfaces_pos, thick_series, thick_surfaces
-
-plt.style.use(['seaborn-white', 'seaborn-talk'])
-
-
-class StratigraphicPile(object):
-    """
-    Class to create the interactive stratigraphic pile
-    """
-    def __init__(self, series_class, surface_class):
-
-        # Set the values of matplotlib
-        fig = plt.figure()
-        ax = fig.add_subplot(111)
-        ax.set_xlim(0, 7)
-        ax.get_yaxis().set_visible(False)
-        ax.get_xaxis().set_visible(False)
-        ax.axis('off')
-
-        # Compute the anchor values for the number of series. This is a DataFrame
-        self.anch_series, self.anch_surfaces, self.thick_series, self.thick_surfaces = set_anchor_points(series_class,
-                                                                                                             surface_class)
-
-        # We create the list that contains rectangles that represent our series ang are global
-        global series_rect
-        series_rect = {}
-
-        # Define the initial value of each rectangle
-        pos_anch = np.squeeze(self.anch_series.values)
-        rects = ax.barh(pos_anch, np.ones_like(pos_anch)*2, self.thick_series, )
-
-        stratcols = ['#400505', '#7D050E', '#646363', '#878786', '#AFAEAE', '#D9D9D8', '#EAEA3B', '#DDAF19']
-        # We connect each rectangle
-        for e, series in enumerate(series_class.df.index):
-            # TODO Alex set the colors of the series accordingly
-
-            rects[e].set_color(stratcols[e])
-            rects[e].set_label(series)
-            dr = DraggableRectangle(rects[e], series_class, surface_class)
-            dr.connect()
-            dr.rect.f = None
-            dr.rect.s = series
-
-            series_rect[series] = dr
-
-        global surface_rect
-        surface_rect = {}
-
-        # Define the initial value of each rectangle
-        pos_anch = np.squeeze(self.anch_surfaces.values)
-        rects = ax.barh(pos_anch, np.ones_like(pos_anch)*2, .5, left=3.)
-
-        color_lot = dict(zip(surface_class['surface'], surface_class['color']))
-        #color_lot = surface_class.colors.colordict
-        # We connect each rectangle
-        for e, surface in enumerate(self.anch_surfaces.columns):
-            if 'aux' in surface:
-                rects[e].set_alpha(.1)
-                rects[e].set_color('gray')
-            else:
-                try:
-                    rects[e].set_color(color_lot[surface])
-                    rects[e].set_label(surface)
-                except KeyError:
-                    pass
-            dr = DraggableRectangle(rects[e], series_class, surface_class)
-            dr.connect()
-            dr.rect.f = surface
-            dr.rect.s = None
-
-            surface_rect[surface] = dr
-        plt.legend(bbox_to_anchor=(1.1, 1.05))
-        plt.ion()
-        ax.text(1, self.anch_series.max().values.max() + self.thick_series/2 + 2, r'Series', fontsize=15,
-                fontweight='bold', bbox={'facecolor':'gray', 'alpha':0.5, 'pad':10}, horizontalalignment='center')
-        ax.text(4, self.anch_series.max().values.max() + self.thick_series/2 + 2, r'Faults/Surfaces', fontsize=15,
-                fontweight='bold', bbox={'facecolor':'gray', 'alpha':0.5, 'pad':10}, horizontalalignment='center')
-
-        self.figure = plt.gcf()
-        plt.close(self.figure)
-
-
-class DraggableRectangle:
-    def __init__(self, rect, series, surface_df):
-        # The idea of passing geodata is to update the dataframes in place
-        self.series = series
-        self.surface = surface_df
-        self.rect = rect
-
-        # We add the name of the series as attribute of the rectangle
-        self.press = None
-
-        # We initalize the placement of the anchors
-        self.anch_series, self.anch_surfaces, self.thick_series, self.thick_surfaces = set_anchor_points(self.series,
-                                                                                                             surface_df)
-
-    def connect(self):
-        'connect to all the events we need'
-        self.cidpress = self.rect.figure.canvas.mpl_connect(
-            'button_press_event', self.on_press)
-        self.cidrelease = self.rect.figure.canvas.mpl_connect(
-            'button_release_event', self.on_release)
-        self.cidmotion = self.rect.figure.canvas.mpl_connect(
-            'motion_notify_event', self.on_motion)
-
-    def on_press(self, event):
-        'on button press we will see if the mouse is over us and store some data'
-        if event.inaxes != self.rect.axes: return
-
-        contains, attrd = self.rect.contains(event)
-
-        if not contains: return
-
-        x0, y0 = self.rect.xy
-
-        # We detect the series that has been touched.
-        self.selected_rectangle_s = self.rect.s
-        self.selected_rectangle_f = self.rect.f
-
-        # We pass all the important attributes through this property
-        self.press = x0, y0, event.xdata, event.ydata, self.selected_rectangle_s, self.selected_rectangle_f
-
-    def on_motion(self, event):
-        'on motion we will move the rect if the mouse is over us'
-        if self.press is None: return
-        if event.inaxes != self.rect.axes: return
-        x0, y0, xpress, ypress = self.press[:-2]
-
-        # We forbid movement in x
-        dy = event.ydata - ypress
-        self.rect.set_y(y0 + dy)
-        self.rect.figure.canvas.draw()
-
-    def on_release(self, event):
-        'on release we reset the press data'
-
-        # We extract the rectangle that was clicked
-        if self.press is None: return
-        selected_rectangle_s = self.press[-2]
-        selected_rectangle_f = self.press[-1]
-        self.press = None
-        self.rect.figure.canvas.draw()
-
-        if self.selected_rectangle_s is not None:
-            # Make a copy of the position where the selected rectangle was
-            selected_arch_position_s = np.copy(self.anch_series[selected_rectangle_s].values)
-
-            # Compute the position of the closes anchor point and the argument of the rectangle which was there
-            dropping_arch_position, dropping_arg = self.compute_new_arch_series()
-
-            # Here we change the selected rectangle to the position to the dropping position
-            self.anch_series[selected_rectangle_s] = dropping_arch_position
-
-            # Here we change the rectangle that was on the dropping position to the original position of the selected
-            # rectangle
-            self.anch_series.iloc[0, dropping_arg] = selected_arch_position_s
-
-            self.update_data_frame()
-            self.anch_series, self.anch_surfaces, self.thick_series, self.thick_surfaces = set_anchor_points(
-                self.series, self.surface)
-
-            # We update the visualization of all the rectangles
-            for series_name in self.anch_series.columns:
-                series_rect[series_name].rect.set_y(self.anch_series[series_rect[series_name].rect.s].values-self.thick_series/2)
-                series_rect[series_name].rect.set_animated(False)
-                series_rect[series_name].rect.background = None
-
-                # redraw the full figure
-                series_rect[series_name].rect.figure.canvas.draw()
-
-        if self.selected_rectangle_f is not None:
-
-            # Make a copy of the position where the selected rectangle was
-            selected_arch_position_f = np.copy(self.anch_surfaces[selected_rectangle_f].values)
-            # selected_arch_position_f = np.copy(self.anch_surfaces[selected_rectangle].values)
-
-            # Compute the position of the closes anchor point and the argument of the rectangle which was there
-            dropping_arch_position, dropping_arg = self.compute_new_arch_surface()
-
-            # Here we change the selected rectangle to the position to the dropping position
-            self.anch_surfaces[selected_rectangle_f] = dropping_arch_position
-
-            # Here we change the rectangle that was on the dropping position to the original position of the selected
-            # rectangle
-            self.anch_surfaces.iloc[0, dropping_arg] = selected_arch_position_f
-
-            self.update_data_frame()
-            self.anch_series, self.anch_surfaces, self.thick_series, self.thick_surfaces = set_anchor_points(
-                self.series, self.surface)
-
-        # We update the visualization of all the rectangles
-        for surfaces_name in self.anch_surfaces.columns:
-            surface_rect[surfaces_name].anch_surfaces = self.anch_surfaces
-            new_pos = self.anch_surfaces[surface_rect[surfaces_name].rect.f].values
-            surface_rect[surfaces_name].rect.set_y(new_pos - 0.5/2)
-            surface_rect[surfaces_name].rect.set_animated(False)
-            surface_rect[surfaces_name].rect.background = None
-
-            # redraw the full figure
-            surface_rect[surfaces_name].rect.figure.canvas.draw()
-
-        self.selected_rectangle_s = None
-        self.selected_rectangle_r = None
-
-    def compute_new_arch_series(self):
-
-        dist = np.abs(self.anch_series.values - self.rect.get_y())
-        arg_min = np.argmin(dist)
-        new_arch = self.anch_series.iloc[0, arg_min]
-        return new_arch, arg_min
-
-    def compute_new_arch_surface(self):
-
-        dist = np.abs(self.anch_surfaces.values - self.rect.get_y())
-        arg_min = np.argmin(dist)
-        new_arch = self.anch_surfaces.iloc[0, arg_min]
-        return new_arch, arg_min
-
-    def update_data_frame(self):
-
-        order_series = self.anch_series.sort_values(by=0, axis=1, ascending=False).columns.values
-        order_surfaces = self.anch_surfaces.sort_values(by=0, axis=1, ascending=False)
-
-        # drop aux
-        aux_columns = ['aux' in i for i in order_surfaces.columns]
-        order_surfaces.drop(order_surfaces.columns[aux_columns], axis=1, inplace=True)
-
-        series_dict = {}
-        # divide surfaces to their series
-        for name, value in self.anch_series.iteritems():
-             cond = ((order_surfaces <= value.get_values()+self.thick_series/2) & \
-                    (order_surfaces >= value.get_values()-self.thick_series/2))
-             format_in_series = order_surfaces.columns[cond.values[0, :]]
-             # Passing from array to tuple what a pain
-             series_dict[name] = format_in_series.values
-
-        self.surface.map_series(series_dict)
-        #self.series.set_surface_number(order_surfaces.columns.values)
-        #self.geo_model.order_table()
-
-    def disconnect(self):
-        'disconnect all the stored connection ids'
-        self.rect.figure.canvas.mpl_disconnect(self.cidpress)
-        self.rect.figure.canvas.mpl_disconnect(self.cidrelease)
-        self.rect.figure.canvas.mpl_disconnect(self.cidmotion)
-
-
+"""
+    This file is part of gempy.
+
+    gempy is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    gempy is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
+"""
+
+import numpy as np
+import pandas as pn
+import matplotlib.pyplot as plt
+#from gempy.plot.colors import *
+#import matplotlib.cm as cm
+#from gempy.plot.colors import color_lot, cmap, norm
+from typing import TYPE_CHECKING
+if TYPE_CHECKING:
+    from gempy import Series
+
+
+#import matplotlib.colors as mcolors
+
+def set_anchor_points(series_object, surface_object):
+    """
+    Compute the location of each series and surface depending on the number of those
+
+    Args:
+        geo_model (gempy.data_management.InputData):
+
+    Returns:
+        list:
+        - DataFrame: location of the series
+
+        - DataFrame: location of the surfaces
+
+        - float: thickness of the series
+
+        - list, floats:
+
+    """
+    # Surfaces per serie
+    series_names = series_object.df.index
+    # Get number of series
+    n_series = len(series_object.df.index)
+
+    # Make anchor points for each serie
+    anch_series_pos_aux = np.linspace(10, 0, n_series, endpoint=True)
+    anch_series_pos = pn.DataFrame(anch_series_pos_aux.reshape(1, -1),
+                                   columns=series_names)
+
+    # Thicknes of series. We just make sure we have white space in between
+    thick_series = 11.5 / n_series
+
+    # Setting surfaces anchor
+    anch_surfaces_pos = pn.DataFrame()
+    thick_surfaces = []
+    for series in series_names:
+        try:
+            surfaces = surface_object.set_index('series').loc[series, 'surface']
+            #if type(surfaces) is not str or type(surfaces) is not np.str_:
+            try:
+                surfaces = surfaces.values
+            except AttributeError:
+                pass
+        except KeyError:
+            surfaces = np.empty(0, dtype='object')
+
+        surfaces = np.insert(surfaces, 0, '0_aux' + series)
+        surfaces = np.append(surfaces, '1_aux' + series)
+        anch_for_df = pn.DataFrame(
+            np.linspace(anch_series_pos[series][0] + thick_series / 2,
+                        anch_series_pos[series][0] - thick_series / 2,
+                        surfaces.shape[0],
+                        endpoint=True).reshape(1, -1),
+            columns=surfaces)
+
+        anch_surfaces_pos = pn.concat([anch_surfaces_pos, anch_for_df],
+                                        axis=1)
+        thick_surfaces = np.append(thick_surfaces,
+                                     (np.tile((thick_series - 2) / surfaces.shape[0], surfaces.shape[0])))
+
+    return anch_series_pos, anch_surfaces_pos, thick_series, thick_surfaces
+
+plt.style.use(['seaborn-white', 'seaborn-talk'])
+
+
+class StratigraphicPile(object):
+    """
+    Class to create the interactive stratigraphic pile
+    """
+    def __init__(self, series_class, surface_class):
+
+        # Set the values of matplotlib
+        fig = plt.figure()
+        ax = fig.add_subplot(111)
+        ax.set_xlim(0, 7)
+        ax.get_yaxis().set_visible(False)
+        ax.get_xaxis().set_visible(False)
+        ax.axis('off')
+
+        # Compute the anchor values for the number of series. This is a DataFrame
+        self.anch_series, self.anch_surfaces, self.thick_series, self.thick_surfaces = set_anchor_points(series_class,
+                                                                                                             surface_class)
+
+        # We create the list that contains rectangles that represent our series ang are global
+        global series_rect
+        series_rect = {}
+
+        # Define the initial value of each rectangle
+        pos_anch = np.squeeze(self.anch_series.values)
+        rects = ax.barh(pos_anch, np.ones_like(pos_anch)*2, self.thick_series, )
+
+        stratcols = ['#400505', '#7D050E', '#646363', '#878786', '#AFAEAE', '#D9D9D8', '#EAEA3B', '#DDAF19']
+        # We connect each rectangle
+        for e, series in enumerate(series_class.df.index):
+            # TODO Alex set the colors of the series accordingly
+
+            rects[e].set_color(stratcols[e])
+            rects[e].set_label(series)
+            dr = DraggableRectangle(rects[e], series_class, surface_class)
+            dr.connect()
+            dr.rect.f = None
+            dr.rect.s = series
+
+            series_rect[series] = dr
+
+        global surface_rect
+        surface_rect = {}
+
+        # Define the initial value of each rectangle
+        pos_anch = np.squeeze(self.anch_surfaces.values)
+        rects = ax.barh(pos_anch, np.ones_like(pos_anch)*2, .5, left=3.)
+
+        color_lot = dict(zip(surface_class['surface'], surface_class['color']))
+        #color_lot = surface_class.colors.colordict
+        # We connect each rectangle
+        for e, surface in enumerate(self.anch_surfaces.columns):
+            if 'aux' in surface:
+                rects[e].set_alpha(.1)
+                rects[e].set_color('gray')
+            else:
+                try:
+                    rects[e].set_color(color_lot[surface])
+                    rects[e].set_label(surface)
+                except KeyError:
+                    pass
+            dr = DraggableRectangle(rects[e], series_class, surface_class)
+            dr.connect()
+            dr.rect.f = surface
+            dr.rect.s = None
+
+            surface_rect[surface] = dr
+        plt.legend(bbox_to_anchor=(1.1, 1.05))
+        plt.ion()
+        ax.text(1, self.anch_series.max().values.max() + self.thick_series/2 + 2, r'Series', fontsize=15,
+                fontweight='bold', bbox={'facecolor':'gray', 'alpha':0.5, 'pad':10}, horizontalalignment='center')
+        ax.text(4, self.anch_series.max().values.max() + self.thick_series/2 + 2, r'Faults/Surfaces', fontsize=15,
+                fontweight='bold', bbox={'facecolor':'gray', 'alpha':0.5, 'pad':10}, horizontalalignment='center')
+
+        self.figure = plt.gcf()
+        plt.close(self.figure)
+
+
+class DraggableRectangle:
+    def __init__(self, rect, series, surface_df):
+        # The idea of passing geodata is to update the dataframes in place
+        self.series = series
+        self.surface = surface_df
+        self.rect = rect
+
+        # We add the name of the series as attribute of the rectangle
+        self.press = None
+
+        # We initalize the placement of the anchors
+        self.anch_series, self.anch_surfaces, self.thick_series, self.thick_surfaces = set_anchor_points(self.series,
+                                                                                                             surface_df)
+
+    def connect(self):
+        'connect to all the events we need'
+        self.cidpress = self.rect.figure.canvas.mpl_connect(
+            'button_press_event', self.on_press)
+        self.cidrelease = self.rect.figure.canvas.mpl_connect(
+            'button_release_event', self.on_release)
+        self.cidmotion = self.rect.figure.canvas.mpl_connect(
+            'motion_notify_event', self.on_motion)
+
+    def on_press(self, event):
+        'on button press we will see if the mouse is over us and store some data'
+        if event.inaxes != self.rect.axes: return
+
+        contains, attrd = self.rect.contains(event)
+
+        if not contains: return
+
+        x0, y0 = self.rect.xy
+
+        # We detect the series that has been touched.
+        self.selected_rectangle_s = self.rect.s
+        self.selected_rectangle_f = self.rect.f
+
+        # We pass all the important attributes through this property
+        self.press = x0, y0, event.xdata, event.ydata, self.selected_rectangle_s, self.selected_rectangle_f
+
+    def on_motion(self, event):
+        'on motion we will move the rect if the mouse is over us'
+        if self.press is None: return
+        if event.inaxes != self.rect.axes: return
+        x0, y0, xpress, ypress = self.press[:-2]
+
+        # We forbid movement in x
+        dy = event.ydata - ypress
+        self.rect.set_y(y0 + dy)
+        self.rect.figure.canvas.draw()
+
+    def on_release(self, event):
+        'on release we reset the press data'
+
+        # We extract the rectangle that was clicked
+        if self.press is None: return
+        selected_rectangle_s = self.press[-2]
+        selected_rectangle_f = self.press[-1]
+        self.press = None
+        self.rect.figure.canvas.draw()
+
+        if self.selected_rectangle_s is not None:
+            # Make a copy of the position where the selected rectangle was
+            selected_arch_position_s = np.copy(self.anch_series[selected_rectangle_s].values)
+
+            # Compute the position of the closes anchor point and the argument of the rectangle which was there
+            dropping_arch_position, dropping_arg = self.compute_new_arch_series()
+
+            # Here we change the selected rectangle to the position to the dropping position
+            self.anch_series[selected_rectangle_s] = dropping_arch_position
+
+            # Here we change the rectangle that was on the dropping position to the original position of the selected
+            # rectangle
+            self.anch_series.iloc[0, dropping_arg] = selected_arch_position_s
+
+            self.update_data_frame()
+            self.anch_series, self.anch_surfaces, self.thick_series, self.thick_surfaces = set_anchor_points(
+                self.series, self.surface)
+
+            # We update the visualization of all the rectangles
+            for series_name in self.anch_series.columns:
+                series_rect[series_name].rect.set_y(self.anch_series[series_rect[series_name].rect.s].values-self.thick_series/2)
+                series_rect[series_name].rect.set_animated(False)
+                series_rect[series_name].rect.background = None
+
+                # redraw the full figure
+                series_rect[series_name].rect.figure.canvas.draw()
+
+        if self.selected_rectangle_f is not None:
+
+            # Make a copy of the position where the selected rectangle was
+            selected_arch_position_f = np.copy(self.anch_surfaces[selected_rectangle_f].values)
+            # selected_arch_position_f = np.copy(self.anch_surfaces[selected_rectangle].values)
+
+            # Compute the position of the closes anchor point and the argument of the rectangle which was there
+            dropping_arch_position, dropping_arg = self.compute_new_arch_surface()
+
+            # Here we change the selected rectangle to the position to the dropping position
+            self.anch_surfaces[selected_rectangle_f] = dropping_arch_position
+
+            # Here we change the rectangle that was on the dropping position to the original position of the selected
+            # rectangle
+            self.anch_surfaces.iloc[0, dropping_arg] = selected_arch_position_f
+
+            self.update_data_frame()
+            self.anch_series, self.anch_surfaces, self.thick_series, self.thick_surfaces = set_anchor_points(
+                self.series, self.surface)
+
+        # We update the visualization of all the rectangles
+        for surfaces_name in self.anch_surfaces.columns:
+            surface_rect[surfaces_name].anch_surfaces = self.anch_surfaces
+            new_pos = self.anch_surfaces[surface_rect[surfaces_name].rect.f].values
+            surface_rect[surfaces_name].rect.set_y(new_pos - 0.5/2)
+            surface_rect[surfaces_name].rect.set_animated(False)
+            surface_rect[surfaces_name].rect.background = None
+
+            # redraw the full figure
+            surface_rect[surfaces_name].rect.figure.canvas.draw()
+
+        self.selected_rectangle_s = None
+        self.selected_rectangle_r = None
+
+    def compute_new_arch_series(self):
+
+        dist = np.abs(self.anch_series.values - self.rect.get_y())
+        arg_min = np.argmin(dist)
+        new_arch = self.anch_series.iloc[0, arg_min]
+        return new_arch, arg_min
+
+    def compute_new_arch_surface(self):
+
+        dist = np.abs(self.anch_surfaces.values - self.rect.get_y())
+        arg_min = np.argmin(dist)
+        new_arch = self.anch_surfaces.iloc[0, arg_min]
+        return new_arch, arg_min
+
+    def update_data_frame(self):
+
+        order_series = self.anch_series.sort_values(by=0, axis=1, ascending=False).columns.values
+        order_surfaces = self.anch_surfaces.sort_values(by=0, axis=1, ascending=False)
+
+        # drop aux
+        aux_columns = ['aux' in i for i in order_surfaces.columns]
+        order_surfaces.drop(order_surfaces.columns[aux_columns], axis=1, inplace=True)
+
+        series_dict = {}
+        # divide surfaces to their series
+        for name, value in self.anch_series.iteritems():
+             cond = ((order_surfaces <= value.get_values()+self.thick_series/2) & \
+                    (order_surfaces >= value.get_values()-self.thick_series/2))
+             format_in_series = order_surfaces.columns[cond.values[0, :]]
+             # Passing from array to tuple what a pain
+             series_dict[name] = format_in_series.values
+
+        self.surface.map_series(series_dict)
+        #self.series.set_surface_number(order_surfaces.columns.values)
+        #self.geo_model.order_table()
+
+    def disconnect(self):
+        'disconnect all the stored connection ids'
+        self.rect.figure.canvas.mpl_disconnect(self.cidpress)
+        self.rect.figure.canvas.mpl_disconnect(self.cidrelease)
+        self.rect.figure.canvas.mpl_disconnect(self.cidmotion)
+
+
```

### Comparing `gempy-2.2b10.dev1/gempy/plot/vista.py` & `gempy-2.3.0/gempy/plot/vista.py`

 * *Files 2% similar despite different names*

```diff
@@ -25,22 +25,22 @@
 """
 from __future__ import annotations
 
 import warnings
 from typing import Union, Dict, List, Iterable, Set, Tuple
 
 import matplotlib.colors as mcolors
-from matplotlib import cm
 import numpy as np
 import pandas as pd
 import pyvista as pv
-from pyvista.plotting import parse_color
+
 # TODO Check if this is necessary if it is implemented in the API
 try:
     import pyvistaqt as pvqt
+
     PYVISTA_IMPORT = True
 except ImportError:
     PYVISTA_IMPORT = False
 
 import gempy as gp
 from gempy.plot.vista_aux import WidgetsCallbacks, RenderChanges
 import matplotlib
@@ -120,27 +120,26 @@
 
         self.orientations_actor = None
         self.orientations_mesh = None
         self.orientations_widgets = {}
 
         # Private attributes
         self._grid_values = None
-        col = matplotlib.cm.get_cmap('viridis')(np.linspace(0, 1, 255)) * 255
+        col = matplotlib.colormaps['viridis'](np.linspace(0, 1, 255)) * 255
         nv = numpy_to_vtk(col, array_type=3)
         self._cmaps = {'viridis': nv}
 
         # Topology properties
         self.topo_edges = None
         self.topo_ctrs = None
 
     def _get_color_lot(self, lith_c: pd.DataFrame = None,
                        index='surface',
                        is_faults: bool = True,
-                       is_basement: bool = False) -> \
-            pd.Series:
+                       is_basement: bool = False) -> pd.Series:
         """Method to get the right color list depending on the type of plot.
 
         Args:
             lith_c (pd.DataFrame): Pandas series with index surface names and
                 values hex strings with the colors
             is_faults (bool): Return the colors of the faults. This should be
                 true for surfaces and input data and false for scalar values.
@@ -158,16 +157,15 @@
                 surf_df['isActive'] = (surf_df['isActive'] | bool_surf_points)
 
                 if is_faults is True and is_basement is True:
                     lith_c = surf_df.groupby('isActive').get_group(True)['color']
                 elif is_faults is True and is_basement is False:
                     lith_c = surf_df.groupby(['isActive', 'isBasement']).get_group((True, False))['color']
                 else:
-                    lith_c = surf_df.groupby(['isActive', 'isFault']).get_group((True, False))[
-                        'color']
+                    lith_c = surf_df.groupby(['isActive', 'isFault']).get_group((True, False))['color']
 
         color_lot = lith_c
         return color_lot
 
     @property
     def scalar_bar_options(self):
         sargs = dict(
@@ -234,16 +232,15 @@
             self.plot_surface_points(surfaces=surfaces, surface_points=surface_points, **kwargs)
             self.set_scalar_bar()
         if self.model.orientations.df.shape[0] != 0:
             self.plot_orientations(surfaces=surfaces, orientations=orientations, **kwargs)
 
     @staticmethod
     def _select_surfaces_data(data_df: pd.core.frame.DataFrame,
-                              surfaces: Union[str, List[str]] = 'all') -> \
-            pd.core.frame.DataFrame:
+                              surfaces: Union[str, List[str]] = 'all') -> pd.core.frame.DataFrame:
         """Select the surfaces that has to be plot.
 
         Args:
             data_df (pd.core.frame.DataFrame): GemPy data df that contains
                 surface property. E.g Surfaces, SurfacePoints or Orientations.
             surfaces: If 'all' select all the active data. If a list of surface
                 names or a surface name is passed, plot only those.
@@ -302,15 +299,15 @@
                                          indices=surface_points.index.values,
                                          radius=radius, **kwargs)
             if type(s) is not list:
                 s = [s]
             return s
 
     def create_orientations_widget(self,
-                                   orientations: pd.core.frame.DataFrame)\
+                                   orientations: pd.core.frame.DataFrame) \
             -> List[vtk.vtkInteractionWidgetsPython.vtkPlaneWidget]:
         """Create plane widget for each orientation with interactive recompute
         of the model
 
         Args:
             orientations (pd.core.frame.DataFrame):
 
@@ -372,21 +369,25 @@
         if self.live_updating is True:
 
             sphere_widgets = self.create_sphere_widgets(surface_points, colors, **kwargs)
             self.surface_points_widgets.update(dict(zip(surface_points.index, sphere_widgets)))
             r = self.surface_points_widgets
         else:
             poly = pv.PolyData(surface_points[["X", "Y", "Z"]].values)
-            poly['id'] = surface_points['id']
+            poly['id'] = surface_points['id'] - 1  # TODO: Check if this is the final solution
             self.surface_points_mesh = poly
             cmap = mcolors.ListedColormap(list(self._get_color_lot(is_faults=True, is_basement=True)))
-            self.surface_points_actor = self.p.add_mesh(poly, cmap=cmap,
-                                                        scalars='id',
-                                                        render_points_as_spheres=render_points_as_spheres,
-                                                        point_size=point_size, show_scalar_bar=False)
+            self.surface_points_actor = self.p.add_mesh(
+                mesh=poly,
+                cmap=cmap,
+                scalars='id',
+                render_points_as_spheres=render_points_as_spheres,
+                point_size=point_size,
+                show_scalar_bar=False
+            )
             self.set_scalar_bar()
 
             r = self.surface_points_actor
         self.set_bounds()
         return r
 
     def plot_orientations(self, surfaces: Union[str, Iterable[str]] = 'all',
@@ -414,15 +415,15 @@
 
         if self.live_updating is True:
             orientations_widgets = self.create_orientations_widget(orientations)
             self.orientations_widgets.update(dict(zip(orientations.index, orientations_widgets)))
             r = self.orientations_widgets
         else:
             poly = pv.PolyData(orientations[["X", "Y", "Z"]].values)
-            poly['id'] = orientations['id']
+            poly['id'] = orientations['id'] - 1
             poly['vectors'] = orientations[['G_x', 'G_y', 'G_z']].values
 
             min_axes = np.min(np.diff(self.extent)[[0, 2, 4]])
 
             arrows = poly.glyph(orient='vectors', scale=False,
                                 factor=min_axes / (100 / arrow_size))
 
@@ -446,31 +447,41 @@
         Args:
             surfaces:
             surfaces_df (pd.DataFrame):
             clear:
             **kwargs:
         """
         cmap = mcolors.ListedColormap(list(self._get_color_lot(is_faults=True, is_basement=True)))
-        if clear is True and self.plotter_type !='notebook':
+        if clear is True and self.plotter_type != 'notebook':
             try:
                 [self.p.remove_actor(actor) for actor in self.surface_actors.items()]
             except KeyError:
                 pass
 
         if surfaces_df is None:
             surfaces_df = self._select_surfaces_data(self.model._surfaces.df, surfaces)
 
         select_active = surfaces_df['isActive']
         for idx, val in surfaces_df[select_active][['vertices', 'edges', 'color', 'surface', 'id']].dropna().iterrows():
-            surf = pv.PolyData(val['vertices'], np.insert(val['edges'], 0, 3, axis=1).ravel())
-            # surf['id'] = val['id']
+            vertices_ = val['vertices']
+            edges_ = val['edges']
+            if isinstance(vertices_, list): vertices_ = vertices_[0]
+            if isinstance(edges_, list): edges_ = edges_[0]
+            
+            if vertices_.shape[0] == 0 or edges_.shape[0] == 0:
+                continue
+            surf = pv.PolyData(vertices_, np.insert(edges_, 0, 3, axis=1).ravel())
             self.surface_poly[val['surface']] = surf
             self.surface_actors[val['surface']] = self.p.add_mesh(
-                surf, parse_color(val['color']), show_scalar_bar=True,
-                cmap=cmap, **kwargs)
+                surf,
+                pv.Color(val['color']).float_rgb,
+                show_scalar_bar=True,
+                cmap=cmap,
+                **kwargs
+            )
         self.set_bounds()
 
         # In order to set the scalar bar to only surfaces we would need to map
         # every vertex of each layer with the right id. So far I am going to avoid
         # the overhead since usually surfaces will be plotted either with data
         # or the regular grid.
         # self.set_scalar_bar()
@@ -524,17 +535,17 @@
             topography:
             scalars:
             clear:
             **kwargs:
         """
         rgb = False
         if clear is True and 'topography' in self.surface_actors and self.plotter_type != 'notebook':
-                self.p._scalar_bar_slot_lookup['height'] = None
-                self.p.remove_actor(self.surface_actors['topography'])
-                self.p.remove_actor(self.surface_actors["topography_cont"])
+            self.p._scalar_bar_slot_lookup['height'] = None
+            self.p.remove_actor(self.surface_actors['topography'])
+            self.p.remove_actor(self.surface_actors["topography_cont"])
 
         if not topography:
             try:
                 topography = self.model._grid.topography.values
             except AttributeError:
                 raise AttributeError("Unable to plot topography: Given geomodel instance "
                                      "does not contain topography grid.")
@@ -548,15 +559,15 @@
 
         if scalars == "geomap":
 
             colors_hex = self._get_color_lot(is_faults=False, is_basement=True, index='id')
             colors_rgb_ = colors_hex.apply(lambda val: list(mcolors.hex2color(val)))
             colors_rgb = pd.DataFrame(colors_rgb_.to_list(), index=colors_hex.index) * 255
 
-            sel = np.round(self.model.solutions.geological_map[0]).astype(int)[0]
+            sel = np.round(self.model.solutions.geological_map[0]).astype(int)
 
             scalars_val = numpy_to_vtk(colors_rgb.loc[sel], array_type=3)
             cm = mcolors.ListedColormap(list(self._get_color_lot(is_faults=True, is_basement=True)))
             rgb = True
 
         elif scalars == "topography":
             scalars_val = topography[:, 2]
@@ -625,49 +636,50 @@
             **kwargs:
         """
         if clear is True:
             try:
                 self.p.remove_actor(self.regular_grid_actor)
             except KeyError:
                 pass
-        regular_grid, cmap = self.create_regular_mesh(scalar_field, data,
-                                                      series, render_topography)
-        
+        regular_grid, cmap = self.create_regular_mesh(scalar_field, data, series, render_topography)
+
         return self.add_regular_grid_mesh(regular_grid, cmap, scalar_field, series,
                                           opacity, **kwargs)
-    
+
     def create_regular_mesh(self, scalar_field: str = 'all',
-                             data: Union[dict, str] = 'Default',
-                             series: str = '',
-                             render_topography: bool = True,
-                        ):
-        
+                            data: Union[dict, str] = 'Default',
+                            series: str = '',
+                            render_topography: bool = True,
+                            ):
+
         regular_grid = self.model._grid.regular_grid
 
         if regular_grid.values is self._grid_values:
             regular_grid_mesh = self.regular_grid_mesh
         else:
             # If the regular grid changes we need to create a new grid. Otherwise we can append it to the
             # previous
             self._grid_values = regular_grid.values
 
             grid_3d = self._grid_values.reshape(*regular_grid.resolution, 3).T
             regular_grid_mesh = pv.StructuredGrid(*grid_3d)
-        
+
         # Set the scalar field-Activate it-getting cmap?
-        regular_grid_mesh, cmap = self.set_scalar_data(regular_grid_mesh,
-                                                       data=data, scalar_field=scalar_field,
-                                                       series=series)
+        regular_grid_mesh, cmap = self.set_scalar_data(
+            regular_grid=regular_grid_mesh,
+            data=data,
+            scalar_field=scalar_field,
+            series=series
+        )
 
         if render_topography == True and regular_grid.mask_topo.shape[0] != 0 and True:
-
             main_scalar = 'id' if scalar_field == 'all' else regular_grid_mesh.array_names[-1]
             regular_grid_mesh[main_scalar][regular_grid.mask_topo.ravel(order='C')] = -100
             regular_grid_mesh = regular_grid_mesh.threshold(-99, scalars=main_scalar)
-        
+
         return regular_grid_mesh, cmap
 
     def add_regular_grid_mesh(self,
                               regular_grid_mesh,
                               cmap,
                               scalar_field: str = 'all',
                               series: str = '',
@@ -683,67 +695,63 @@
             sargs['title'] = scalar_field + ': ' + series
             show_scalar_bar = True
             main_scalar_prefix = 'sf_' if scalar_field == 'scalar' else 'values_'
             main_scalar = main_scalar_prefix + series
             if series == '':
                 main_scalar = regular_grid_mesh.array_names[-1]
 
-        self.regular_grid_actor = self.p.add_mesh(regular_grid_mesh, cmap=cmap,
-                                                  scalars=main_scalar,
-                                                  show_scalar_bar=show_scalar_bar,
-                                                  scalar_bar_args=sargs,
-                                                  opacity=opacity,
-                                                  **kwargs)
+        self.regular_grid_actor = self.p.add_mesh(
+            mesh=regular_grid_mesh,
+            cmap=cmap,
+            scalars=main_scalar,
+            show_scalar_bar=show_scalar_bar,
+            scalar_bar_args=sargs,
+            opacity=opacity,
+            **kwargs
+        )
 
         if scalar_field == 'all' or scalar_field == 'lith':
             self.set_scalar_bar()
         self.regular_grid_mesh = regular_grid_mesh
         return [regular_grid_mesh, cmap]
-    
+
     def set_scalar_data(self, regular_grid, data: Union[dict, gp.Solution, str] = 'Default',
                         scalar_field='all', series='', cmap='viridis'):
         """
         Args:
-            regular_grid:
-            data: dictionary or solution
             scalar_field: if data is a gp.Solutions object, name of the grid
                 that you want to plot.
-            series:
-            cmap:
         """
         if data == 'Default':
             data = self.model.solutions
 
         if isinstance(data, gp.Solution):
             if scalar_field == 'lith' or scalar_field == 'all':
-                regular_grid['id'] = data.lith_block
+                regular_grid['id'] = data.lith_block - 1  # TODO: check out if the -1 is the actual fix
                 hex_colors = list(self._get_color_lot(is_faults=True, is_basement=True))
                 cmap = mcolors.ListedColormap(hex_colors)
             if scalar_field == 'scalar' or scalar_field == 'all' or 'sf_' in scalar_field:
                 scalar_field_ = 'sf_'
                 for e, series in enumerate(self.model._stack.df.groupby('isActive').groups[True]):
                     regular_grid[scalar_field_ + series] = data.scalar_field_matrix[e]
 
-            if (scalar_field == 'values' or scalar_field == 'all' or 'values_' in scalar_field) and\
+            if (scalar_field == 'values' or scalar_field == 'all' or 'values_' in scalar_field) and \
                     data.values_matrix.shape[0] \
                     != 0:
                 scalar_field_ = 'values_'
                 for e, lith_property in enumerate(self.model._surfaces.df.columns[self.model._surfaces._n_properties:]):
                     regular_grid[scalar_field_ + lith_property] = data.values_matrix[e]
 
         if type(data) == dict:
             for key in data:
                 regular_grid[key] = data[key]
 
         if scalar_field == 'all' or scalar_field == 'lith':
             scalar_field_ = 'lith'
             series = ''
-        # else:
-        #     scalar_field_ = regular_grid.scalar_names[-1]
-        #     series = ''
 
         self.set_active_scalar_fields(scalar_field_ + series, regular_grid, update_cmap=False)
 
         return regular_grid, cmap
 
     def set_active_scalar_fields(self, scalar_field, regular_grid=None, update_cmap=True):
         """
@@ -770,15 +778,15 @@
             self.set_scalar_field_cmap(cmap=cmap)
             arr_ = regular_grid.get_array(scalar_field)
             if scalar_field != 'lith':
                 self.p.add_scalar_bar(title='values')
                 self.p.update_scalar_bar_range((arr_.min(), arr_.max()))
 
     def set_scalar_field_cmap(self, cmap: Union[str, dict] = 'viridis',
-                              regular_grid_actor = None) -> None:
+                              regular_grid_actor=None) -> None:
         """
         Args:
             cmap:
             regular_grid_actor (Union[None, vtkRenderingOpenGL2Python.vtkOpenGLActor):
         """
         if regular_grid_actor is None:
             regular_grid_actor = self.regular_grid_actor
@@ -802,15 +810,15 @@
                                  'rgb values')
         # Set the scalar field color map
         regular_grid_actor.GetMapper().GetLookupTable().SetTable(self._cmaps[cmap])
 
     def plot_structured_grid_interactive(
             self,
             scalar_field: str,
-            series = None,
+            series=None,
             render_topography: bool = False,
             **kwargs,
     ):
         """Plot interactive 3-D geomodel with three cross sections in subplot.
 
         Args:
             geo_model: Geomodel object with solutions.
@@ -837,19 +845,19 @@
             main_scalar = main_scalar_prefix + series
 
         # callback functions for subplots
         def xcallback(normal, origin):
             self.p.subplot(1)
             self.p.add_mesh(mesh.slice(normal=normal, origin=origin),
                             scalars=main_scalar, name="xslc", cmap=cmap)
-                
+
         def ycallback(normal, origin):
             self.p.subplot(2)
             self.p.add_mesh(mesh.slice(normal=normal, origin=origin), name="yslc", cmap=cmap)
-        
+
         def zcallback(normal, origin):
             self.p.subplot(3)
             self.p.add_mesh(mesh.slice(normal=normal, origin=origin), name="zslc", cmap=cmap)
 
         self.add_regular_grid_mesh(mesh, cmap, scalar_field, series, **kwargs)
 
         # cross section widgets
```

### Comparing `gempy-2.2b10.dev1/gempy/plot/vista_qt.py` & `gempy-2.3.0/gempy/plot/vista_qt.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,81 +1,81 @@
-import pyvista as pv
-import pyvistaqt as pvqt
-from PyQt5.QtCore import *
-from PyQt5.QtGui import *
-from PyQt5.QtWidgets import *
-
-from gempy.plot._vista import Vista
-
-
-class MainWindow(QMainWindow):  # QtWidgets.QWidget
-    def __init__(self, geo_model, parent=None):
-        super(MainWindow, self).__init__(parent)
-
-        self.create_menu_bar()
-        self.bar = None
-
-        self.main_widget = MainWidget(geo_model, parent=self)
-        self.setCentralWidget(self.main_widget)
-
-    def create_menu_bar(self):
-        self.bar = self.menuBar()
-
-        file = self.bar.addMenu("File")
-        _quit = QAction("Quit", self)
-        file.addAction(_quit)
-
-
-class MainWidget(QWidget):
-    def __init__(self, geo_model, parent=None):
-        super(MainWidget, self).__init__(parent)
-        self.model = geo_model
-
-        # init base ui
-        hbox = QHBoxLayout(self)
-        splitter = QSplitter(Qt.Horizontal)
-
-        self.init_tree()
-        splitter.addWidget(self.tree)
-
-        plot = QFrame()
-        self.Vista = Vista(geo_model,
-                           plotter_type="basic")  # init Vista plotter
-        self.vtk_widget = pvqt.QtInteractor(plot)
-        self.Vista.p = self.vtk_widget  # set Plotter to the vtk widget Plotter
-
-        splitter.addWidget(self.vtk_widget)
-        hbox.addWidget(splitter)
-        self.setLayout(hbox)
-
-        # self.Vista.plot_surface_points_all()
-
-    def init_tree(self):
-        self.tree = QTreeWidget()
-        self.tree.setColumnCount(1)
-
-        self.tree_items = {"surfaces": {}}
-        self.tree_actors = {"surfaces": {}}
-
-        for id_, row in self.model._surfaces.df.iterrows():
-            item = QTreeWidgetItem([row.surface])
-            item.setCheckState(0, Qt.Unchecked)
-            self.tree.addTopLevelItem(item)
-            self.tree_items["surfaces"][row.surface] = item
-
-        self.tree.itemClicked.connect(self._check_tree_status)
-
-    def _check_tree_status(self):
-        for name, item in self.tree_items["surfaces"].items():
-
-            if item.checkState(0) == Qt.Checked:
-                actor = self.Vista.plot_surface(name)
-                # self.Vista.p.renderer.add_actor(actor)
-                self.tree_actors["surfaces"][name] = actor
-
-
-            elif item.checkState(0) == Qt.Unchecked:
-                actor = self.tree_actors["surfaces"].get(name)
-                if actor:
-                    self.Vista.p.remove_actor(actor)
-                    # self.Vista.p.renderer.remove_actor(actor)
-                    self.tree_actors["surfaces"][name] = None
+import pyvista as pv
+import pyvistaqt as pvqt
+from PyQt5.QtCore import *
+from PyQt5.QtGui import *
+from PyQt5.QtWidgets import *
+
+from gempy.plot._vista import Vista
+
+
+class MainWindow(QMainWindow):  # QtWidgets.QWidget
+    def __init__(self, geo_model, parent=None):
+        super(MainWindow, self).__init__(parent)
+
+        self.create_menu_bar()
+        self.bar = None
+
+        self.main_widget = MainWidget(geo_model, parent=self)
+        self.setCentralWidget(self.main_widget)
+
+    def create_menu_bar(self):
+        self.bar = self.menuBar()
+
+        file = self.bar.addMenu("File")
+        _quit = QAction("Quit", self)
+        file.addAction(_quit)
+
+
+class MainWidget(QWidget):
+    def __init__(self, geo_model, parent=None):
+        super(MainWidget, self).__init__(parent)
+        self.model = geo_model
+
+        # init base ui
+        hbox = QHBoxLayout(self)
+        splitter = QSplitter(Qt.Horizontal)
+
+        self.init_tree()
+        splitter.addWidget(self.tree)
+
+        plot = QFrame()
+        self.Vista = Vista(geo_model,
+                           plotter_type="basic")  # init Vista plotter
+        self.vtk_widget = pvqt.QtInteractor(plot)
+        self.Vista.p = self.vtk_widget  # set Plotter to the vtk widget Plotter
+
+        splitter.addWidget(self.vtk_widget)
+        hbox.addWidget(splitter)
+        self.setLayout(hbox)
+
+        # self.Vista.plot_surface_points_all()
+
+    def init_tree(self):
+        self.tree = QTreeWidget()
+        self.tree.setColumnCount(1)
+
+        self.tree_items = {"surfaces": {}}
+        self.tree_actors = {"surfaces": {}}
+
+        for id_, row in self.model._surfaces.df.iterrows():
+            item = QTreeWidgetItem([row.surface])
+            item.setCheckState(0, Qt.Unchecked)
+            self.tree.addTopLevelItem(item)
+            self.tree_items["surfaces"][row.surface] = item
+
+        self.tree.itemClicked.connect(self._check_tree_status)
+
+    def _check_tree_status(self):
+        for name, item in self.tree_items["surfaces"].items():
+
+            if item.checkState(0) == Qt.Checked:
+                actor = self.Vista.plot_surface(name)
+                # self.Vista.p.renderer.add_actor(actor)
+                self.tree_actors["surfaces"][name] = actor
+
+
+            elif item.checkState(0) == Qt.Unchecked:
+                actor = self.tree_actors["surfaces"].get(name)
+                if actor:
+                    self.Vista.p.remove_actor(actor)
+                    # self.Vista.p.renderer.remove_actor(actor)
+                    self.tree_actors["surfaces"][name] = None
```

### Comparing `gempy-2.2b10.dev1/gempy/plot/visualization_2d.py` & `gempy-2.3.0/gempy/plot/visualization_2d.py`

 * *Files 1% similar despite different names*

```diff
@@ -32,15 +32,15 @@
 from matplotlib.ticker import FixedFormatter, FixedLocator
 import matplotlib.gridspec as gridspect
 import matplotlib as mpl
 import scipy.spatial.distance as dd
 import seaborn as sns
 
 sns.set_context('talk')
-plt.style.use(['seaborn-white', 'seaborn-talk'])
+plt.style.use(['seaborn-v0_8-white', 'seaborn-v0_8-talk'])
 
 warnings.filterwarnings("ignore", message="No contour levels were found")
 
 
 class Plot2D:
     """
     Class with functionality to plot 2D gempy sections
@@ -152,15 +152,15 @@
             figure, list axes, subgrid values
         """
         cols = kwargs.get('cols', 1)
         rows = kwargs.get('rows', 1)
 
         figsize, self.ax_labelsize, _, self.xt_labelsize, self.linewidth, _ = _scale_fig_size(
             figsize, textsize, rows, cols)
-        self.fig = plt.figure( figsize=figsize, constrained_layout=False)
+        self.fig = plt.figure(figsize=figsize, constrained_layout=False)
         self.fig.is_legend = False
         # TODO make grid variable
         # self.gs_0 = gridspect.GridSpec(2, 2, figure=self.fig, hspace=.9)
 
         return self.fig, self.axes  # , self.gs_0
 
     def add_section(self, section_name=None, cell_number=None, direction='y', ax=None, ax_pos=111,
@@ -260,32 +260,30 @@
 
         section_name, cell_number, direction = self._check_default_section(ax, section_name, cell_number, direction)
 
         if section_name is not None:
             if section_name == 'topography':
                 try:
                     image = self.model.solutions.geological_map[0].reshape(
-                        self.model._grid.topography.values_2d[:, :, 2].shape)
+                        self.model._grid.topography.values_2d[:, :, 2].shape).T
 
                 except AttributeError:
                     raise AttributeError('Geological map not computed. Activate the topography grid.')
             else:
                 assert type(section_name) == str or type(
                     section_name) == np.str_, 'section name must be a string of the name of the section'
                 assert self.model.solutions.sections is not None, 'no sections for plotting defined'
 
                 l0, l1 = self.model._grid.sections.get_section_args(section_name)
                 shape = self.model._grid.sections.df.loc[section_name, 'resolution']
-                image = self.model.solutions.sections[0][0][l0:l1].reshape(shape[0], shape[1]).T
+                image = self.model.solutions.sections[0][l0:l1].reshape(shape[0], shape[1]).T
 
         elif cell_number is not None or block is not None:
             _a, _b, _c, _, x, y = self._slice(direction, cell_number)[:-2]
-            if resolution is None:
-                resolution = self.model._grid.regular_grid.resolution
-
+            
             plot_block = block.reshape(self.model._grid.regular_grid.resolution)
             image = plot_block[_a, _b, _c].T
         else:
             raise AttributeError
 
         ax.imshow(image, origin='lower', zorder=-100,
                   cmap=cmap, norm=norm, extent=extent_val)
@@ -383,32 +381,33 @@
 
         points = self.model._surface_points.df.copy()
         orientations = self.model._orientations.df.copy()
         section_name, cell_number, direction = self._check_default_section(ax, section_name, cell_number, direction)
 
         if section_name is not None:
             if section_name == 'topography':
-
                 topo_comp = kwargs.get('topo_comp', 5000)
                 decimation_aux = int(self.model._grid.topography.values.shape[0] / topo_comp)
                 tpp = self.model._grid.topography.values[::decimation_aux + 1, :]
-                cartesian_point_dist = (dd.cdist(tpp, self.model._surface_points.df[['X', 'Y', 'Z']])
-                                        < projection_distance).sum(axis=0).astype(bool)
-                cartesian_ori_dist = (dd.cdist(tpp, self.model._orientations.df[['X', 'Y', 'Z']])
-                                      < projection_distance).sum(axis=0).astype(bool)
-                x, y, Gx, Gy = 'X', 'Y', 'G_x', 'G_y'
+                
+                cdist_sp = dd.cdist(tpp, self.model._surface_points.df[['X', 'Y', 'Z']])
+                cartesian_point_dist = (cdist_sp < projection_distance).sum(axis=0).astype(bool)
 
+                cdist_ori = dd.cdist(tpp, self.model._orientations.df[['X', 'Y', 'Z']])
+                cartesian_ori_dist = (cdist_ori < projection_distance).sum(axis=0).astype(bool)
+
+                x, y, Gx, Gy = 'X', 'Y', 'G_x', 'G_y'
             else:
                 # Project points:
                 shift = np.asarray(self.model._grid.sections.df.loc[section_name, 'start'])
                 end_point = np.atleast_2d(np.asarray(self.model._grid.sections.df.loc[section_name, 'stop']) - shift)
                 A_rotate = np.dot(end_point.T, end_point) / self.model._grid.sections.df.loc[section_name, 'dist'] ** 2
 
-                cartesian_point_dist = np.sqrt(((np.dot(
-                    A_rotate, (points[['X', 'Y']]).T).T - points[['X', 'Y']]) ** 2).sum(axis=1))
+                perpe_sqdist = ((np.dot(A_rotate, (points[['X', 'Y']]).T).T - points[['X', 'Y']]) ** 2).sum(axis=1)
+                cartesian_point_dist = np.sqrt(perpe_sqdist)
 
                 cartesian_ori_dist = np.sqrt(((np.dot(
                     A_rotate, (orientations[['X', 'Y']]).T).T - orientations[['X', 'Y']]) ** 2).sum(axis=1))
 
                 # This are the coordinates of the data projected on the section
                 cartesian_point = np.dot(A_rotate, (points[['X', 'Y']] - shift).T).T
                 cartesian_ori = np.dot(A_rotate, (orientations[['X', 'Y']] - shift).T).T
@@ -449,27 +448,28 @@
         select_projected_p = cartesian_point_dist < projection_distance
         select_projected_o = cartesian_ori_dist < projection_distance
 
         # Hack to keep the right X label:
         temp_label = copy.copy(ax.xaxis.label)
 
         points_df = points[select_projected_p]
-        points_df['colors'] = points_df['surface'].map(self._color_lot)
-
-        points_df.plot.scatter(x=x, y=y, ax=ax, c='colors', s=70,  zorder=102,
+        
+        _colors = points_df['surface'].map(self._color_lot)
+        points_df['colors'] = _colors
+
+        points_df.plot.scatter(x=x, y=y, ax=ax,
+                               c=_colors,
+                               s=70, 
+                               zorder=102,
                                edgecolors='white',
-                               colorbar=False)
-        # points_df.plot.scatter(x=x, y=y, ax=ax, c='white', s=80,  zorder=101,
-        #                        colorbar=False)
-
+                               colorbar=False
+                               )
+        
         if self.fig.is_legend is False and legend is True or legend == 'force':
-
-            markers = [plt.Line2D([0, 0], [0, 0], color=color, marker='o',
-                                  linestyle='') for color in
-                       self._color_lot.values()]
+            markers = [plt.Line2D([0, 0], [0, 0], color=color, marker='o', linestyle='') for color in self._color_lot.values()]
             ax.legend(markers, self._color_lot.keys(), numpoints=1)
             self.fig.is_legend = True
         ax.xaxis.label = temp_label
 
         sel_ori = orientations[select_projected_o]
 
         aspect = np.subtract(*ax.get_ylim()) / np.subtract(*ax.get_xlim())
@@ -551,14 +551,15 @@
                              self.model._grid.regular_grid.extent[5]],
                             [0, self.model._grid.regular_grid.extent[5]],
                             [0, a[:, 1][0]])).reshape(-1, 2)
 
             ax.fill(xy[:, 0], xy[:, 1], 'k', zorder=10)
 
         elif section_name == 'topography':
+            
             import skimage
             from gempy.plot.helpers import add_colorbar
             topo = self.model._grid.topography
             topo_super_res = skimage.transform.resize(
                 topo.values_2d,
                 (1600, 1600),
                 order=3,
@@ -602,15 +603,15 @@
                                [ext[1], self.model._grid.regular_grid.extent[5]],
                                [ext[0], self.model._grid.regular_grid.extent[5]],
                                [ext[0], a[:, 1][0]]))
                 line = a.reshape(-1, 2)
                 ax.fill(line[:, 0], line[:, 1], color='k')
             except IndexError:
                 warnings.warn('Topography needs to be a raster to be able to plot it'
-                                     'in 2D sections')
+                              'in 2D sections')
         return ax
 
     def plot_contacts(self, ax, section_name=None, cell_number=None, direction='y', block=None,
                       only_faults=False, **kwargs):
         self.update_colot_lot()
         section_name, cell_number, direction = self._check_default_section(ax, section_name, cell_number, direction)
 
@@ -621,33 +622,37 @@
         extent_val = [*ax.get_xlim(), *ax.get_ylim()]
         zorder = kwargs.get('zorder', 100)
 
         if section_name is not None:
             if section_name == 'topography':
                 shape = self.model._grid.topography.resolution
 
-                scalar_fields = self.model.solutions.geological_map[1]
+                scalar_fields = self.model.solutions.geological_map[1:]
                 c_id = 0  # color id startpoint
 
                 for e, block in enumerate(scalar_fields):
                     level = self.model.solutions.scalar_field_at_surface_points[e][np.where(
                         self.model.solutions.scalar_field_at_surface_points[e] != 0)]
 
                     c_id2 = c_id + len(level)  # color id endpoint
-                    ax.contour(block.reshape(shape), 0, levels=np.sort(level),
-                               colors=self.cmap.colors[c_id:c_id2][::-1],
-                               linestyles='solid', origin='lower',
-                               extent=extent_val, zorder=zorder - (e + len(level))
-                               )
+                    ax.contour(
+                        block.reshape(shape).T, 0,
+                        levels=np.sort(level),
+                        colors=self.cmap.colors[c_id:c_id2][::-1],
+                        linestyles='solid',
+                        origin='lower',
+                        extent=extent_val,
+                        zorder=zorder - (e + len(level))
+                    )
                     c_id = c_id2
 
             else:
                 l0, l1 = self.model._grid.sections.get_section_args(section_name)
                 shape = self.model._grid.sections.df.loc[section_name, 'resolution']
-                scalar_fields = self.model.solutions.sections[1][:, l0:l1]
+                scalar_fields = self.model.solutions.sections[1:][:, l0:l1]
 
                 c_id = 0  # color id startpoint
 
                 for e, block in enumerate(scalar_fields):
                     level = self.model.solutions.scalar_field_at_surface_points[e][np.where(
                         self.model.solutions.scalar_field_at_surface_points[e] != 0)]
 
@@ -663,22 +668,20 @@
                                extent=extent_val, zorder=zorder - (e + len(level))
                                )
                     c_id = c_id2
 
         elif cell_number is not None or block is not None:
             _slice = self._slice(direction, cell_number)[:3]
             shape = self.model._grid.regular_grid.resolution
-            c_id = 0  # color id startpoint
+            c_id = 0  # * color id startpoint
 
             for e, block in enumerate(self.model.solutions.scalar_field_matrix):
                 level = self.model.solutions.scalar_field_at_surface_points[e][np.where(
                     self.model.solutions.scalar_field_at_surface_points[e] != 0)]
-                # c_id = e
                 c_id2 = c_id + len(level)
-                #    print(c_id, c_id2)
 
                 color_list = self.model._surfaces.df.groupby('isActive').get_group(True)['color'][c_id:c_id2][::-1]
                 #    print(color_list)
 
                 ax.contour(block.reshape(shape)[_slice].T, 0, levels=np.sort(level),
                            colors=color_list,
                            linestyles='solid', origin='lower',
```

### Comparing `gempy-2.2b10.dev1/gempy/plot/visualization_3d.py` & `gempy-2.3.0/gempy/plot/visualization_3d.py`

 * *Files 1% similar despite different names*

```diff
@@ -204,42 +204,42 @@
         render_window.Finalize()
         self.interactor.TerminateApp()
         del self.renwin, self.interactor
 
     def key_callbacks(self, obj, event):
         key = self.interactor.GetKeySym()
 
-        if key is 'h' or key is 'p':
+        if key == 'h' or key == 'p':
             print('holding... Use vtk.resume to go back to the interactive window')
             self.interactor.ExitCallback()
             self.interactor.holding = True
 
-        if key is 'l':
+        if key == 'l':
             if self.layer_visualization is True:
                 for layer in self.surf_rend_1:
                     layer.VisibilityOff()
                 self.layer_visualization = False
                 self.interactor.Render()
             elif self.layer_visualization is False:
                 for layer in self.surf_rend_1:
                     layer.VisibilityOn()
                 self.layer_visualization = True
                 self.interactor.Render()
 
-        if key is 't':
+        if key == 't':
             if self.topo_visualization is True:
                 self.topography_surface.VisibilityOff()
                 self.topo_visualization = False
                 self.interactor.Render()
             elif self.topo_visualization is False:
                 self.topography_surface.VisibilityOn()
                 self.topo_visualization = True
                 self.interactor.Render()
 
-        if key is 'q':
+        if key == 'q':
             print('closing vtk')
             self.close_window()
 
             # TODO: Decide if this even matter
             # # create render window, settings
             # self.renwin = vtk.vtkRenderWindow()
             # self.renwin.SetWindowName(self.ren_name)
@@ -261,15 +261,15 @@
             # for e, r in enumerate(self.ren_list):
             #     # add axes actor to all renderer
             #     axe = self._create_axes(self.camera_list[e])
             #
             #     r.AddActor(axe)
             #     r.ResetCamera()
 
-        if key is 'r':
+        if key == 'r':
             self.real_time = self.real_time ^ True
 
     def create_surface_points(self, vertices):
         """
         Method to create the points that form the surfaces
         Args:
             vertices (numpy.array): 2D array (XYZ) with the coordinates of the points
@@ -666,15 +666,15 @@
         self.slider_w.SetCurrentRenderer(self.ren_list[0])
         self.slider_w.SetAnimationModeToJump()
 
         self.slider_w.On()
         self.slider_w.AddObserver('EndInteractionEvent', self.sliderCallback_interactor)
 
     def sliderCallback_interactor(self, obj, event):
-        if int(obj.GetRepresentation().GetValue()) is 0:
+        if int(obj.GetRepresentation().GetValue()) == 0:
             self.interactor.ExitCallback()
 
     def sliderCallback_traces(self, obj, event):
         # TODO Check post class
         self.post.change_input_data(self.geo_model, obj.GetRepresentation().GetValue())
         try:
             # for surf in self.surf_rend_1:
@@ -1379,15 +1379,15 @@
 
         if plot:
             return vol.plot()
 
     def plot3D_steno_surface(self, ver, sim):
 
         for surface in self.surfaces.iterrows():
-            if surface[1].values[0] is 0:
+            if surface[1].values[0] == 0:
                 pass
 
             #for vertices, simpleces in zip(ver[surface[1].values[0]], sim[surface[1].values[0]]):
             surface_mesh = steno3d.Mesh2D(
                 vertices=ver[surface[1].values[0]-1],
                 triangles=sim[surface[1].values[0]-1],
                 opts=dict(wireframe=False)
```

### Comparing `gempy-2.2b10.dev1/gempy/utils/analysis.py` & `gempy-2.3.0/gempy/utils/analysis.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,181 +1,181 @@
-"""
-    This file is part of gempy.
-
-    gempy is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    gempy is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
-
-
-@author: Alexander Schaaf
-"""
-from warnings import warn
-import numpy as np
-try:
-    from skimage.measure import regionprops, label
-except ImportError:
-    warn("skimage package is not installed, which is required for geomodel complexity analysis.")
-
-
-def get_nearestneighbor_block(lb):
-    """
-    Simplest 3D nearest neighbor comparison to (6-stamp) for lithology values.
-
-    Args:
-        lb (np.ndarray): lb[0].reshape(*geo_data.resolution).astype(int)
-
-    Returns:
-        (np.ndarray)
-    """
-    shp = lb.shape
-    nn = np.zeros((shp[0] - 1, shp[0] - 1, shp[0] - 1))
-    # x
-    nn += np.abs(lb[1:, :-1, :-1] ^ lb[:-1, :-1, :-1])
-    nn += np.abs(lb[:-1, :-1, :-1] ^ lb[1:, :-1, :-1])
-    # y
-    nn += np.abs(lb[:-1, 1:, :-1] ^ lb[:-1, :-1, :-1])
-    nn += np.abs(lb[:-1, :-1, :-1] ^ lb[:-1, 1:, :-1])
-    # z
-    nn += np.abs(lb[:-1, :-1, 1:] ^ lb[:-1, :-1, :-1])
-    nn += np.abs(lb[:-1, :-1, :-1] ^ lb[:-1, :-1, 1:])
-
-    return nn
-
-
-def get_geobody_volume(rprops, geo_data=None):
-    """Compute voxel counts per unique integer body in given block model
-
-    Args:
-        rprops (list): List of regionprops object for each unique region of the model.
-        (skimage.measure._regionprops._RegionProperties object)
-
-    Returns:
-        (dict): Dict with node labels as keys and geobody volume values.
-    """
-    if geo_data is None:
-        return {rprop.label:rprop.area for rprop in rprops}
-    else:
-        return {rprop.label:rprop.area * np.product(geo_data.extent[1::2] / geo_data.resolution) for rprop in rprops}
-
-
-def get_geobody_tops(rprops, geo_data=None):
-    """Get the top vertical limit coordinate of geobodies (via bbox).
-
-    Args:
-        rprops (list): List of regionprops object for each unique region of the model.
-        (skimage.measure._regionprops._RegionProperties object)
-        geo_data (gempy.data_management.InputData):
-
-    Returns:
-        (dict): Dict with node labels as keys and geobody top coordinates as values.
-    """
-
-    if geo_data is None:
-        return {rprop.label: rprop.bbox[5] for rprop in rprops}
-    else:
-        return {rprop.label: rprop.bbox[5] * geo_data.extent[5] / geo_data.resolution[2] for rprop in rprops}
-
-
-def get_geobody_bots(rprops, geo_data=None):
-    """Get the bottom vertical limit coordinate of geobodies (via bbox).
-
-    Args:
-        rprops (list): List of regionprops object for each unique region of the model.
-        (skimage.measure._regionprops._RegionProperties object)
-        geo_data (gempy.data_management.InputData):
-
-    Returns:
-        (dict): Dict with node labels as keys and geobody bottom coordinates as values.
-    """
-    if geo_data is None:
-        return {rprop.label: rprop.bbox[2] for rprop in rprops}
-    else:
-        return {rprop.label: rprop.bbox[2] * geo_data.extent[5] / geo_data.resolution[2] for rprop in rprops}
-
-
-def get_centroids(rprops):
-    """Get node centroids in 2d and 3d as {node id (int): tuple(x,y,z)}."""
-    centroids = {}
-    for rp in rprops:
-            centroids[rp.label] = rp.centroid
-    return centroids
-
-
-def get_unique_regions(lith_block, fault_block, n_faults, neighbors=8, noddy=False):
-    """
-
-    Args:
-        lith_block (np.ndarray): Lithology block model
-        fault_block (np.ndarray): Fault block model
-        n_faults (int): Number of faults.
-        neighbors (int, optional): Specifies the neighbor voxel connectivity taken into account for the topology
-            analysis. Must be either 4 or 8 (default: 8)
-        noddy (bool): If a noddy block is handed to the function, equalizes the results to be comparable with GemPy
-
-    Returns:
-        (np.ndarray): Model block with uniquely labeled regions.
-    """
-    lith_block = np.round(lith_block).astype(int)
-    fault_block = np.round(fault_block).astype(int)
-
-    # label the fault block for normalization (comparability of e.g. pynoddy and gempy models)
-    fault_block = label(fault_block, neighbors=neighbors, background=9999)
-
-    if noddy:
-        # then this is a gempy model, numpy starts with 1
-        lith_block[lith_block == 0] = int(np.max(lith_block) + 1)  # set the 0 to highest value + 1
-        lith_block -= n_faults  # lower by n_faults to equal with pynoddy models
-        # so the block starts at 1 and goes continuously to max
-
-    ublock = (lith_block.max() + 1) * fault_block + lith_block
-    labels_block, labels_n = label(ublock, neighbors=neighbors, return_num=True, background=9999)
-    if 0 in np.unique(labels_block):
-        labels_block += 1
-
-    return labels_block
-
-
-def calculate_probability_lithology(lith_blocks):
-    """Blocks must be just the lith blocks!"""
-    lith_id = np.unique(lith_blocks)
-    # lith_count = np.zeros_like(lith_blocks[0:len(lith_id)])
-    lith_count = np.zeros((len(np.unique(lith_blocks)), lith_blocks.shape[1]))
-    for i, l_id in enumerate(lith_id):
-        lith_count[i] = np.sum(lith_blocks == l_id, axis=0)
-    lith_prob = lith_count / len(lith_blocks)
-    return lith_prob
-
-
-def calculate_information_entropy(lith_prob):
-    """Calculates information entropy for the given probability array."""
-    ie = np.zeros_like(lith_prob[0])
-    for l in lith_prob:
-        pm = np.ma.masked_equal(l, 0)  # mask where layer prob is 0
-        ie -= (pm * np.ma.log2(pm)).filled(0)
-    return ie
-
-
-def calculate_information_entropy_total(ie, absolute=False):
-    """Calculate total information entropy (float) from an information entropy array."""
-    if absolute:
-        return np.sum(ie)
-    else:
-        return np.sum(ie) / np.size(ie)
-
-
-def calculate_ie(lbs):
-    """Computes the per-voxel and total information entropy of given block models."""
-
-    lith_prob = calculate_probability_lithology(lbs)
-    ie = calculate_information_entropy(lith_prob)
-    ie_total = calculate_information_entropy_total(ie)
-
+"""
+    This file is part of gempy.
+
+    gempy is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    gempy is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
+
+
+@author: Alexander Schaaf
+"""
+from warnings import warn
+import numpy as np
+try:
+    from skimage.measure import regionprops, label
+except ImportError:
+    warn("skimage package is not installed, which is required for geomodel complexity analysis.")
+
+
+def get_nearestneighbor_block(lb):
+    """
+    Simplest 3D nearest neighbor comparison to (6-stamp) for lithology values.
+
+    Args:
+        lb (np.ndarray): lb[0].reshape(*geo_data.resolution).astype(int)
+
+    Returns:
+        (np.ndarray)
+    """
+    shp = lb.shape
+    nn = np.zeros((shp[0] - 1, shp[0] - 1, shp[0] - 1))
+    # x
+    nn += np.abs(lb[1:, :-1, :-1] ^ lb[:-1, :-1, :-1])
+    nn += np.abs(lb[:-1, :-1, :-1] ^ lb[1:, :-1, :-1])
+    # y
+    nn += np.abs(lb[:-1, 1:, :-1] ^ lb[:-1, :-1, :-1])
+    nn += np.abs(lb[:-1, :-1, :-1] ^ lb[:-1, 1:, :-1])
+    # z
+    nn += np.abs(lb[:-1, :-1, 1:] ^ lb[:-1, :-1, :-1])
+    nn += np.abs(lb[:-1, :-1, :-1] ^ lb[:-1, :-1, 1:])
+
+    return nn
+
+
+def get_geobody_volume(rprops, geo_data=None):
+    """Compute voxel counts per unique integer body in given block model
+
+    Args:
+        rprops (list): List of regionprops object for each unique region of the model.
+        (skimage.measure._regionprops._RegionProperties object)
+
+    Returns:
+        (dict): Dict with node labels as keys and geobody volume values.
+    """
+    if geo_data is None:
+        return {rprop.label:rprop.area for rprop in rprops}
+    else:
+        return {rprop.label:rprop.area * np.product(geo_data.extent[1::2] / geo_data.resolution) for rprop in rprops}
+
+
+def get_geobody_tops(rprops, geo_data=None):
+    """Get the top vertical limit coordinate of geobodies (via bbox).
+
+    Args:
+        rprops (list): List of regionprops object for each unique region of the model.
+        (skimage.measure._regionprops._RegionProperties object)
+        geo_data (gempy.data_management.InputData):
+
+    Returns:
+        (dict): Dict with node labels as keys and geobody top coordinates as values.
+    """
+
+    if geo_data is None:
+        return {rprop.label: rprop.bbox[5] for rprop in rprops}
+    else:
+        return {rprop.label: rprop.bbox[5] * geo_data.extent[5] / geo_data.resolution[2] for rprop in rprops}
+
+
+def get_geobody_bots(rprops, geo_data=None):
+    """Get the bottom vertical limit coordinate of geobodies (via bbox).
+
+    Args:
+        rprops (list): List of regionprops object for each unique region of the model.
+        (skimage.measure._regionprops._RegionProperties object)
+        geo_data (gempy.data_management.InputData):
+
+    Returns:
+        (dict): Dict with node labels as keys and geobody bottom coordinates as values.
+    """
+    if geo_data is None:
+        return {rprop.label: rprop.bbox[2] for rprop in rprops}
+    else:
+        return {rprop.label: rprop.bbox[2] * geo_data.extent[5] / geo_data.resolution[2] for rprop in rprops}
+
+
+def get_centroids(rprops):
+    """Get node centroids in 2d and 3d as {node id (int): tuple(x,y,z)}."""
+    centroids = {}
+    for rp in rprops:
+            centroids[rp.label] = rp.centroid
+    return centroids
+
+
+def get_unique_regions(lith_block, fault_block, n_faults, neighbors=8, noddy=False):
+    """
+
+    Args:
+        lith_block (np.ndarray): Lithology block model
+        fault_block (np.ndarray): Fault block model
+        n_faults (int): Number of faults.
+        neighbors (int, optional): Specifies the neighbor voxel connectivity taken into account for the topology
+            analysis. Must be either 4 or 8 (default: 8)
+        noddy (bool): If a noddy block is handed to the function, equalizes the results to be comparable with GemPy
+
+    Returns:
+        (np.ndarray): Model block with uniquely labeled regions.
+    """
+    lith_block = np.round(lith_block).astype(int)
+    fault_block = np.round(fault_block).astype(int)
+
+    # label the fault block for normalization (comparability of e.g. pynoddy and gempy models)
+    fault_block = label(fault_block, neighbors=neighbors, background=9999)
+
+    if noddy:
+        # then this is a gempy model, numpy starts with 1
+        lith_block[lith_block == 0] = int(np.max(lith_block) + 1)  # set the 0 to highest value + 1
+        lith_block -= n_faults  # lower by n_faults to equal with pynoddy models
+        # so the block starts at 1 and goes continuously to max
+
+    ublock = (lith_block.max() + 1) * fault_block + lith_block
+    labels_block, labels_n = label(ublock, neighbors=neighbors, return_num=True, background=9999)
+    if 0 in np.unique(labels_block):
+        labels_block += 1
+
+    return labels_block
+
+
+def calculate_probability_lithology(lith_blocks):
+    """Blocks must be just the lith blocks!"""
+    lith_id = np.unique(lith_blocks)
+    # lith_count = np.zeros_like(lith_blocks[0:len(lith_id)])
+    lith_count = np.zeros((len(np.unique(lith_blocks)), lith_blocks.shape[1]))
+    for i, l_id in enumerate(lith_id):
+        lith_count[i] = np.sum(lith_blocks == l_id, axis=0)
+    lith_prob = lith_count / len(lith_blocks)
+    return lith_prob
+
+
+def calculate_information_entropy(lith_prob):
+    """Calculates information entropy for the given probability array."""
+    ie = np.zeros_like(lith_prob[0])
+    for l in lith_prob:
+        pm = np.ma.masked_equal(l, 0)  # mask where layer prob is 0
+        ie -= (pm * np.ma.log2(pm)).filled(0)
+    return ie
+
+
+def calculate_information_entropy_total(ie, absolute=False):
+    """Calculate total information entropy (float) from an information entropy array."""
+    if absolute:
+        return np.sum(ie)
+    else:
+        return np.sum(ie) / np.size(ie)
+
+
+def calculate_ie(lbs):
+    """Computes the per-voxel and total information entropy of given block models."""
+
+    lith_prob = calculate_probability_lithology(lbs)
+    ie = calculate_information_entropy(lith_prob)
+    ie_total = calculate_information_entropy_total(ie)
+
     return ie, ie_total
```

### Comparing `gempy-2.2b10.dev1/gempy/utils/docstring.py` & `gempy-2.3.0/gempy/utils/docstring.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,90 +1,90 @@
-extent = ' (numpy.ndarray[float]): [x_min, x_max, y_min, y_max, z_min, z_max]. Extent for the visualization of data ' \
-         'and ' \
-         'default of for the ' \
-         'regular grid class.'
-resolution = '(numpy.ndarray[int]): [nx, ny, nz]'
-
-coord = '(numpy.ndarray[float, 3]): XYZ 2D array. Axis 1 is the coordinates while axis 0 is n number of input '
-coord_ori = coord + 'Notice that orientations may be place anywhere in the 3D space.'
-
-pole_vector = '(numpy.ndarray[float, 3]): 2D numpy array where axis 1 is the gradient values G_x, G_y, G_z of the pole while axis 0 is n number of' \
-              ' orientations.'
-
-orientations = '(numpy.ndarray[float, 3]): 2D numpy array where axis 1 is are orientation values [dip, azimuth, polarity] of the pole while axis 0' \
-               ' is n number of orientations. --- ' \
-               '*Dip* is the inclination angle of 0 to 90 degrees measured from the horizontal plane downwards. ' \
-               '*Azimuth* is the dip direction defined by a 360 degrees clockwise rotation, i.e. 0 = North,' \
-               ' 90 = East, 180 = South, and 270 = West.' \
-               '*Polarity* defines where the upper (geologically younger) side of the orientation plane ' \
-               'is and can be declared to be either normal (1) or reversed (-1).' \
-               'The orientation plane is perpendicular to the gradient.'
-
-surface_sp = '(str, Iterable[str]): list with the surface names for each input point. They must exist in the surfaces ' \
-             'object linked to SurfacePoints.'
-
-x = '(float, Iterable[float]): values or list of values for the x coordinates'
-y = '(float, Iterable[float]): values or list of values for the y coordinates'
-z = '(float, Iterable[float]): values or list of values for the z coordinates'
-idx_sp = '(int, list, numpy.ndarray): If passed, list of indices where the function will be applied.'
-
-file_path = 'Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3,' \
-            ' and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv. ' \
-            'If you want to pass in a path object, pandas accepts either pathlib.Path or py._path.local.LocalPath.' \
-            ' By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin ' \
-            'open function) or StringIO.'
-
-debug = 'of debug is True the method will return the result without modify any related object'
-inplace = 'if True, perform operation in-place'
-
-centers = '(numpy.ndarray[float, 3]): XYZ array with the center of the data. This controls how much we shift the ' \
-          'input coordinates'
-
-rescaling_factor = 'Scaling factor by which all the parameters will be rescaled.'
-
-theano_graph_pro = 'GemPy object that contains all graph structure of theano'
-
-ctrl = 'List that controls what parts of the graph for each series have to be recomputed.'
-
-weights_vector = 'Numpy array that containing the kriging weights for each input data sorted by series.'
-sfai = 'Value of the scalar field at each interface. Axis 0 is each series and axis 1 contain each surface in order'
-bai = '3D array with all interpolated values for a given series and at the interfaces'
-mai = 'Boolean array containing the logic to combine multiple series to obtain the final model at each interface.'
-vai = '2D array with the final values once the superposition of series has been carried out at each interface.'
-
-lith_block = ' Array with the id of each layer evaluated in each point of the regular grid. '
-sfm = 'Value of the scalar field at each value of the regular grid. '
-bm = '3D array with all interpolated values for a given series and at each value of the regular grid. '
-mm = 'Boolean array containing the logic to combine multiple series to obtain the final model at each value of the' \
-     ' regular grid. '
-vm = '2D array with the final values once the superposition of series has been carried out at each value of the ' \
-     'regular grid.'
-
-vertices = 'List of numpy arrays containing the XYZ coordinates of each triangle vertex.'
-edges = 'List of numpy arrays containing the indices of the vertices numpy arrays that compose each individual' \
-        ' triangle. '
-geological_map = '2D array containing the lithologies at the surfaces. '
-
-recompute_rf = '(bool): if True recompute the rescaling factor'
-
-compile_theano = 'Default true. Either if the theano graph must be compiled or not'
-theano_optimizer = 'Type of theano compilation. This rules the number ' \
-                   'optimizations theano performs at compilation time: fast_run will take longer \
-             to compile but at run time will be faster and will consume significantly less memory. fast_compile will \
-             compile faster.'
-
-path_i = '(str): Path to the data bases of surface_points. Default os.getcwd()'
-path_o = '(str): Path to the data bases of orientations. Default os.getcwd()'
-surface_points_df = '(pandas.DataFrame): A pn.Dataframe object with X, Y, Z, and surface columns'
-orientations_df = '(pandas.DataFrame): A pn.Dataframe object with X, Y, Z, surface columns and pole or orientation ' \
-                  'columns.'
-
-mapping_object = '(dict, :class:`pandas.DataFrame`):\n                * dict: keys are the series and values the ' \
-                 'surfaces ' \
-                 'belonging to that series\n\n                * pn.DataFrame: Dataframe with surfaces as index and a ' \
-                 'column series with the correspondent series name\n                  of each surface '
-
-geo_model = '(:class:`gempy.core.model.Project`): Container class of all objects that constitute a GemPy model.'
-
-itype = "(str{'all', 'surface_points', 'orientations', 'surfaces', 'series', 'faults', 'faults_relations','additional data'}): input data type to be retrieved."
-
-section_dict = "(dict):  'section name': ([p1_x, p1_y], [p2_x, p2_y], [xyres, zres])"
+extent = ' (numpy.ndarray[float]): [x_min, x_max, y_min, y_max, z_min, z_max]. Extent for the visualization of data ' \
+         'and ' \
+         'default of for the ' \
+         'regular grid class.'
+resolution = '(numpy.ndarray[int]): [nx, ny, nz]'
+
+coord = '(numpy.ndarray[float, 3]): XYZ 2D array. Axis 1 is the coordinates while axis 0 is n number of input '
+coord_ori = coord + 'Notice that orientations may be place anywhere in the 3D space.'
+
+pole_vector = '(numpy.ndarray[float, 3]): 2D numpy array where axis 1 is the gradient values G_x, G_y, G_z of the pole while axis 0 is n number of' \
+              ' orientations.'
+
+orientations = '(numpy.ndarray[float, 3]): 2D numpy array where axis 1 is are orientation values [azimuth, dip, polarity] of the pole while axis 0' \
+               ' is n number of orientations. --- ' \
+               '*Dip* is the inclination angle of 0 to 90 degrees measured from the horizontal plane downwards. ' \
+               '*Azimuth* is the dip direction defined by a 360 degrees clockwise rotation, i.e. 0 = North,' \
+               ' 90 = East, 180 = South, and 270 = West.' \
+               '*Polarity* defines where the upper (geologically younger) side of the orientation plane ' \
+               'is and can be declared to be either normal (1) or reversed (-1).' \
+               'The orientation plane is perpendicular to the gradient.'
+
+surface_sp = '(str, Iterable[str]): list with the surface names for each input point. They must exist in the surfaces ' \
+             'object linked to SurfacePoints.'
+
+x = '(float, Iterable[float]): values or list of values for the x coordinates'
+y = '(float, Iterable[float]): values or list of values for the y coordinates'
+z = '(float, Iterable[float]): values or list of values for the z coordinates'
+idx_sp = '(int, list, numpy.ndarray): If passed, list of indices where the function will be applied.'
+
+file_path = 'Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3,' \
+            ' and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv. ' \
+            'If you want to pass in a path object, pandas accepts either pathlib.Path or py._path.local.LocalPath.' \
+            ' By file-like object, we refer to objects with a read() method, such as a file handler (e.g. via builtin ' \
+            'open function) or StringIO.'
+
+debug = 'of debug is True the method will return the result without modify any related object'
+inplace = 'if True, perform operation in-place'
+
+centers = '(numpy.ndarray[float, 3]): XYZ array with the center of the data. This controls how much we shift the ' \
+          'input coordinates'
+
+rescaling_factor = 'Scaling factor by which all the parameters will be rescaled.'
+
+aesara_graph_pro = 'GemPy object that contains all graph structure of aesara'
+
+ctrl = 'List that controls what parts of the graph for each series have to be recomputed.'
+
+weights_vector = 'Numpy array that containing the kriging weights for each input data sorted by series.'
+sfai = 'Value of the scalar field at each interface. Axis 0 is each series and axis 1 contain each surface in order'
+bai = '3D array with all interpolated values for a given series and at the interfaces'
+mai = 'Boolean array containing the logic to combine multiple series to obtain the final model at each interface.'
+vai = '2D array with the final values once the superposition of series has been carried out at each interface.'
+
+lith_block = ' Array with the id of each layer evaluated in each point of the regular grid. '
+sfm = 'Value of the scalar field at each value of the regular grid. '
+bm = '3D array with all interpolated values for a given series and at each value of the regular grid. '
+mm = 'Boolean array containing the logic to combine multiple series to obtain the final model at each value of the' \
+     ' regular grid. '
+vm = '2D array with the final values once the superposition of series has been carried out at each value of the ' \
+     'regular grid.'
+
+vertices = 'List of numpy arrays containing the XYZ coordinates of each triangle vertex.'
+edges = 'List of numpy arrays containing the indices of the vertices numpy arrays that compose each individual' \
+        ' triangle. '
+geological_map = '2D array containing the lithologies at the surfaces. '
+
+recompute_rf = '(bool): if True recompute the rescaling factor'
+
+compile_aesara = 'Default true. Either if the aesara graph must be compiled or not'
+aesara_optimizer = 'Type of aesara compilation. This rules the number ' \
+                   'optimizations aesara performs at compilation time: fast_run will take longer \
+             to compile but at run time will be faster and will consume significantly less memory. fast_compile will \
+             compile faster.'
+
+path_i = '(str): Path to the data bases of surface_points. Default os.getcwd()'
+path_o = '(str): Path to the data bases of orientations. Default os.getcwd()'
+surface_points_df = '(pandas.DataFrame): A pn.Dataframe object with X, Y, Z, and surface columns'
+orientations_df = '(pandas.DataFrame): A pn.Dataframe object with X, Y, Z, surface columns and pole or orientation ' \
+                  'columns.'
+
+mapping_object = '(dict, :class:`pandas.DataFrame`):\n                * dict: keys are the series and values the ' \
+                 'surfaces ' \
+                 'belonging to that series\n\n                * pn.DataFrame: Dataframe with surfaces as index and a ' \
+                 'column series with the correspondent series name\n                  of each surface '
+
+geo_model = '(:class:`gempy.core.model.Project`): Container class of all objects that constitute a GemPy model.'
+
+itype = "(str{'all', 'surface_points', 'orientations', 'surfaces', 'series', 'faults', 'faults_relations','additional data'}): input data type to be retrieved."
+
+section_dict = "(dict):  'section name': ([p1_x, p1_y], [p2_x, p2_y], [xyres, zres])"
```

### Comparing `gempy-2.2b10.dev1/gempy/utils/extract_geomodeller_data.py` & `gempy-2.3.0/gempy/utils/extract_geomodeller_data.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,262 +1,262 @@
-
-from pylab import *
-import copy
-import pandas as pn
-import gempy as gp
-import numpy as np
-
-try:
-    import xml.etree.cElementTree as ET
-except ImportError:
-    import xml.etree.ElementTree as ET
-
-
-class ReadGeoModellerXML:
-    def __init__(self, fp):
-        """
-        Reads in and parses a GeoModeller XML file to extract interface and orientation data and the overall model
-        settings (e.g. extent and sequential pile). It uses ElementTree to parse the XML and the tree's root can
-        be accessed using self.root for more direct access to the file.
-
-        Todo: - extract faults
-
-        Args:
-            fp (str): Filepath for the GeoModeller xml file to be read.
-
-        """
-        self.tree = ET.ElementTree(file=fp)  # load xml as tree
-        self.root = self.tree.getroot()
-
-        self.xmlns = "http://www.geomodeller.com/geo"
-        self.gml = "http://www.opengis.net/gml"
-
-        self.extent = self._get_extent()
-        self.data = self.extract_data()
-
-        self.series = list(self.data.keys())
-        self.stratigraphic_column, self.surface_points, self.orientations = self.get_dataframes()
-
-        self.series_info = self._get_series_fmt_dict()
-
-        self.faults = self.get_faults()
-
-        self.series_distribution = self.get_series_distribution()
-
-        self.fault_matrix = self.get_fault_matrix()
-
-    def _get_extent(self):
-        """
-        Extracts model extent from ElementTree root and returns it as tuple of floats.
-
-        Returns:
-            tuple: Model extent as (xmin, xmax, ymin, ymax, zmin, zmax).
-        """
-        xy = self.root[0][0][0][0].attrib
-        z = self.root[0][0][0][1].attrib
-        return tuple(np.array([xy["Xmin"], xy["Xmax"],
-                               xy["Ymin"], xy["Ymax"],
-                               z["Zmin"], z["Zmax"]]).astype(float))
-
-    def extract_data(self):
-        """
-        Extracts relevant data from the GeoModeller XML file ElementTree root (self.root) and returns it as a dictionary.
-
-
-        Returns:
-            (dict): Data dictionary
-        """
-        data = {}
-        for s in self.get_psc():
-            sn = s.get("name")
-            data[sn] = {}  # create a dict for each series
-            data[sn]["formations"] = []
-            data[sn]["InfluencedByFault"] = []
-            data[sn]["relation"] = s.get("relation")  # add relation, whatever that is
-
-            for c in s:
-                if c.tag == "{" + self.xmlns + "}Data":  # append formation names to list of formations
-                    data[sn]["formations"].append(c.get("Name"))
-
-                if c.tag == "{" + self.xmlns + "}InfluencedByFault":  # add fault influences
-                    data[sn]["InfluencedByFault"].append(c.get("Name"))
-
-                if c.tag == "{" + self.xmlns + "}PotentialField":
-
-                    data[sn]["gradients"] = []
-                    data[sn]["interfaces"] = []
-                    data[sn]["interfaces_counters"] = []
-                    data[sn]["solutions"] = []
-                    data[sn]["constraints"] = []
-
-                    for cc in c:
-                        # COVARIANCE
-                        if cc.tag == "{" + self.xmlns + "}covariance":
-                            data[sn]["covariance"] = cc.attrib
-
-                        # GRADIENTS
-                        if cc.tag == "{" + self.xmlns + "}Gradients":
-                            for gr in cc:
-                                data[sn]["gradients"].append([gr.get("Gx"), gr.get("Gy"), gr.get("Gz"),
-                                                              gr.get("XGr"), gr.get("YGr"), gr.get("ZGr")])
-
-                        # INTERFACES
-                        if cc.tag == "{" + self.xmlns + "}Points":
-                            for co in cc:
-                                data[sn]["interfaces"].append([float(co[0].text), float(co[1].text), float(co[2].text)])
-
-                        # INTERFACE COUNTERS
-                        if cc.tag == "{" + self.xmlns + "}InterfacePoints":
-                            for ip in cc:
-                                data[sn]["interfaces_counters"].append([int(ip.get("npnt")), int(ip.get("pnt"))])
-
-                        # CONSTRAINTS
-                        if cc.tag == "{" + self.xmlns + "}Constraints":
-                            for co in cc:
-                                data[sn]["constraints"].append(float(co.get("value")))
-
-                        # SOLUTIONS
-                        if cc.tag == "{" + self.xmlns + "}Solutions":
-                            for sol in cc:
-                                data[sn]["solutions"].append(float(sol.get("sol")))
-
-                        if cc.tag == "{" + self.xmlns + "}ModelFaults":
-                            print('hey')
-
-                    # convert from str to float
-                    data[sn]["gradients"] = np.array(data[sn]["gradients"]).astype(float)
-                    data[sn]["interfaces"] = np.array(data[sn]["interfaces"]).astype(float)
-                    data[sn]["interfaces_counters"] = np.array(data[sn]["interfaces_counters"]).astype(float)
-                    data[sn]["solutions"] = np.array(data[sn]["solutions"]).astype(float)
-
-        return data
-
-    def get_dataframes(self):
-
-        strat_pile = dict.fromkeys(self.series)
-        surface_points = pn.DataFrame()
-        orientations = pn.DataFrame()
-
-        for serie in self.series:
-            strat_pile[serie] = self.data[serie]['formations']
-
-            interf_s = self.data[serie].get('interfaces')
-            orient_s = self.data[serie].get('gradients')
-
-            formations = self.data[serie].get('formations')
-            if interf_s is not None:
-                interf = pn.DataFrame(columns=['X', 'Y', 'Z'], data=interf_s)
-                interf['series'] = serie
-
-                if len(formations) > 1:
-                    interf_formations = []
-                    for j, fmt in enumerate(formations):
-                        for n in range(int(self.data[serie].get('interfaces_counters')[j, 0])):
-                            interf_formations.append(fmt)
-                    interf['formation'] = interf_formations
-
-                else:
-                    interf['formation'] = formations[0]
-
-                surface_points = pn.DataFrame.append(surface_points, interf)
-
-            if orient_s is not None:
-                orient = pn.DataFrame(columns=['G_x', 'G_y', 'G_z', 'X', 'Y', 'Z'], data=orient_s)
-                orient['series'] = serie
-                orient['formation'] = formations[0]  # formation is wrong here but does not matter for orientations
-
-                orientations = pn.DataFrame.append(orientations, orient)
-
-        return strat_pile, surface_points, orientations
-
-    def get_psc(self):
-        """Returns the ProjectStratigraphicColumn tree element used for several data extractions."""
-        return self.root.find("{" + self.xmlns + "}GeologicalModel").find(
-            "{" + self.xmlns + "}ProjectStratigraphicColumn")
-
-
-    def get_order_formations(self):
-        order_formations = []
-        for entry in self.series_distribution.values():
-            if type(entry) is str:
-                order_formations.append(entry)
-            elif type(entry) is tuple:
-                for e in entry:
-                    order_formations.append(e)
-
-        return order_formations
-
-    def get_faults(self):
-        """
-        Extracts fault names from ElementTree root.
-
-        Returns:
-            tuple: Fault names (str) ordered as in the GeoModeller XML.
-        """
-        faults = []
-        for c in self.root[2]:
-            faults.append(c.get("Name"))
-        return tuple(faults)
-
-    def get_series_distribution(self):
-        """
-        Combines faults and stratigraphic series into an unordered dictionary as keys and maps the correct
-        formations to them as a list value. Faults series get a list of their own string assigned as formation.
-
-        Returns:
-            (dict): maps Series (str) -> Formations (list of str)
-        """
-        series_distribution = {}
-        for key in self.series_info.keys():
-            fmts = self.series_info[key]["formations"]
-            if len(fmts) == 1:
-                series_distribution[key] = fmts[0]
-            else:
-                series_distribution[key] = tuple(fmts)
-
-        for f in self.stratigraphic_column:
-            if "Fault" in f or "fault" in f:
-                series_distribution[f] = f
-
-        return series_distribution
-
-    def _get_series_fmt_dict(self):
-        sp = {}
-        for i, s in enumerate(self.stratigraphic_column):  # loop over all series
-            fmts = []  # init formation storage list
-            influenced_by = []  # init influenced by list
-            for c in self.root.find("{" + self.xmlns + "}GeologicalModel").find(
-                    "{" + self.xmlns + "}ProjectStratigraphicColumn")[i]:
-                if "Data" in c.tag:
-                    fmts.append(c.attrib["Name"])
-                elif "InfluencedByFault" in c.tag:
-                    influenced_by.append(c.attrib["Name"])
-            # print(fmts)
-            sp[s] = {}
-            sp[s]["formations"] = fmts
-            sp[s]["InfluencedByFault"] = influenced_by
-
-        return sp
-
-
-    def _where_do_faults_stop(self):
-        fstop = {}
-        for i, f in enumerate(self.root[2]):
-
-            stops_on = []
-            for c in self.root[2][i][2:]:
-                stops_on.append(c.get("Name"))
-
-            fstop[f.get("Name")] = stops_on
-
-        return fstop
-
-    def get_fault_matrix(self):
-        nf = len(self.faults)
-        fm = np.zeros((nf, nf))  # zero matrix of n_faults²
-        fstop = self._where_do_faults_stop()
-        for i, f in enumerate(self.faults):
-            for fs in fstop[f]:
-                j = np.where(np.array(self.faults) == fs)[0][0]
-                fm[i, j] = 1
-
-        return fm
+
+from pylab import *
+import copy
+import pandas as pn
+import gempy as gp
+import numpy as np
+
+try:
+    import xml.etree.cElementTree as ET
+except ImportError:
+    import xml.etree.ElementTree as ET
+
+
+class ReadGeoModellerXML:
+    def __init__(self, fp):
+        """
+        Reads in and parses a GeoModeller XML file to extract interface and orientation data and the overall model
+        settings (e.g. extent and sequential pile). It uses ElementTree to parse the XML and the tree's root can
+        be accessed using self.root for more direct access to the file.
+
+        Todo: - extract faults
+
+        Args:
+            fp (str): Filepath for the GeoModeller xml file to be read.
+
+        """
+        self.tree = ET.ElementTree(file=fp)  # load xml as tree
+        self.root = self.tree.getroot()
+
+        self.xmlns = "http://www.geomodeller.com/geo"
+        self.gml = "http://www.opengis.net/gml"
+
+        self.extent = self._get_extent()
+        self.data = self.extract_data()
+
+        self.series = list(self.data.keys())
+        self.stratigraphic_column, self.surface_points, self.orientations = self.get_dataframes()
+
+        self.series_info = self._get_series_fmt_dict()
+
+        self.faults = self.get_faults()
+
+        self.series_distribution = self.get_series_distribution()
+
+        self.fault_matrix = self.get_fault_matrix()
+
+    def _get_extent(self):
+        """
+        Extracts model extent from ElementTree root and returns it as tuple of floats.
+
+        Returns:
+            tuple: Model extent as (xmin, xmax, ymin, ymax, zmin, zmax).
+        """
+        xy = self.root[0][0][0][0].attrib
+        z = self.root[0][0][0][1].attrib
+        return tuple(np.array([xy["Xmin"], xy["Xmax"],
+                               xy["Ymin"], xy["Ymax"],
+                               z["Zmin"], z["Zmax"]]).astype(float))
+
+    def extract_data(self):
+        """
+        Extracts relevant data from the GeoModeller XML file ElementTree root (self.root) and returns it as a dictionary.
+
+
+        Returns:
+            (dict): Data dictionary
+        """
+        data = {}
+        for s in self.get_psc():
+            sn = s.get("name")
+            data[sn] = {}  # create a dict for each series
+            data[sn]["formations"] = []
+            data[sn]["InfluencedByFault"] = []
+            data[sn]["relation"] = s.get("relation")  # add relation, whatever that is
+
+            for c in s:
+                if c.tag == "{" + self.xmlns + "}Data":  # append formation names to list of formations
+                    data[sn]["formations"].append(c.get("Name"))
+
+                if c.tag == "{" + self.xmlns + "}InfluencedByFault":  # add fault influences
+                    data[sn]["InfluencedByFault"].append(c.get("Name"))
+
+                if c.tag == "{" + self.xmlns + "}PotentialField":
+
+                    data[sn]["gradients"] = []
+                    data[sn]["interfaces"] = []
+                    data[sn]["interfaces_counters"] = []
+                    data[sn]["solutions"] = []
+                    data[sn]["constraints"] = []
+
+                    for cc in c:
+                        # COVARIANCE
+                        if cc.tag == "{" + self.xmlns + "}covariance":
+                            data[sn]["covariance"] = cc.attrib
+
+                        # GRADIENTS
+                        if cc.tag == "{" + self.xmlns + "}Gradients":
+                            for gr in cc:
+                                data[sn]["gradients"].append([gr.get("Gx"), gr.get("Gy"), gr.get("Gz"),
+                                                              gr.get("XGr"), gr.get("YGr"), gr.get("ZGr")])
+
+                        # INTERFACES
+                        if cc.tag == "{" + self.xmlns + "}Points":
+                            for co in cc:
+                                data[sn]["interfaces"].append([float(co[0].text), float(co[1].text), float(co[2].text)])
+
+                        # INTERFACE COUNTERS
+                        if cc.tag == "{" + self.xmlns + "}InterfacePoints":
+                            for ip in cc:
+                                data[sn]["interfaces_counters"].append([int(ip.get("npnt")), int(ip.get("pnt"))])
+
+                        # CONSTRAINTS
+                        if cc.tag == "{" + self.xmlns + "}Constraints":
+                            for co in cc:
+                                data[sn]["constraints"].append(float(co.get("value")))
+
+                        # SOLUTIONS
+                        if cc.tag == "{" + self.xmlns + "}Solutions":
+                            for sol in cc:
+                                data[sn]["solutions"].append(float(sol.get("sol")))
+
+                        if cc.tag == "{" + self.xmlns + "}ModelFaults":
+                            print('hey')
+
+                    # convert from str to float
+                    data[sn]["gradients"] = np.array(data[sn]["gradients"]).astype(float)
+                    data[sn]["interfaces"] = np.array(data[sn]["interfaces"]).astype(float)
+                    data[sn]["interfaces_counters"] = np.array(data[sn]["interfaces_counters"]).astype(float)
+                    data[sn]["solutions"] = np.array(data[sn]["solutions"]).astype(float)
+
+        return data
+
+    def get_dataframes(self):
+
+        strat_pile = dict.fromkeys(self.series)
+        surface_points = pn.DataFrame()
+        orientations = pn.DataFrame()
+
+        for serie in self.series:
+            strat_pile[serie] = self.data[serie]['formations']
+
+            interf_s = self.data[serie].get('interfaces')
+            orient_s = self.data[serie].get('gradients')
+
+            formations = self.data[serie].get('formations')
+            if interf_s is not None:
+                interf = pn.DataFrame(columns=['X', 'Y', 'Z'], data=interf_s)
+                interf['series'] = serie
+
+                if len(formations) > 1:
+                    interf_formations = []
+                    for j, fmt in enumerate(formations):
+                        for n in range(int(self.data[serie].get('interfaces_counters')[j, 0])):
+                            interf_formations.append(fmt)
+                    interf['formation'] = interf_formations
+
+                else:
+                    interf['formation'] = formations[0]
+
+                surface_points = pn.DataFrame.append(surface_points, interf)
+
+            if orient_s is not None:
+                orient = pn.DataFrame(columns=['G_x', 'G_y', 'G_z', 'X', 'Y', 'Z'], data=orient_s)
+                orient['series'] = serie
+                orient['formation'] = formations[0]  # formation is wrong here but does not matter for orientations
+
+                orientations = pn.DataFrame.append(orientations, orient)
+
+        return strat_pile, surface_points, orientations
+
+    def get_psc(self):
+        """Returns the ProjectStratigraphicColumn tree element used for several data extractions."""
+        return self.root.find("{" + self.xmlns + "}GeologicalModel").find(
+            "{" + self.xmlns + "}ProjectStratigraphicColumn")
+
+
+    def get_order_formations(self):
+        order_formations = []
+        for entry in self.series_distribution.values():
+            if type(entry) is str:
+                order_formations.append(entry)
+            elif type(entry) is tuple:
+                for e in entry:
+                    order_formations.append(e)
+
+        return order_formations
+
+    def get_faults(self):
+        """
+        Extracts fault names from ElementTree root.
+
+        Returns:
+            tuple: Fault names (str) ordered as in the GeoModeller XML.
+        """
+        faults = []
+        for c in self.root[2]:
+            faults.append(c.get("Name"))
+        return tuple(faults)
+
+    def get_series_distribution(self):
+        """
+        Combines faults and stratigraphic series into an unordered dictionary as keys and maps the correct
+        formations to them as a list value. Faults series get a list of their own string assigned as formation.
+
+        Returns:
+            (dict): maps Series (str) -> Formations (list of str)
+        """
+        series_distribution = {}
+        for key in self.series_info.keys():
+            fmts = self.series_info[key]["formations"]
+            if len(fmts) == 1:
+                series_distribution[key] = fmts[0]
+            else:
+                series_distribution[key] = tuple(fmts)
+
+        for f in self.stratigraphic_column:
+            if "Fault" in f or "fault" in f:
+                series_distribution[f] = f
+
+        return series_distribution
+
+    def _get_series_fmt_dict(self):
+        sp = {}
+        for i, s in enumerate(self.stratigraphic_column):  # loop over all series
+            fmts = []  # init formation storage list
+            influenced_by = []  # init influenced by list
+            for c in self.root.find("{" + self.xmlns + "}GeologicalModel").find(
+                    "{" + self.xmlns + "}ProjectStratigraphicColumn")[i]:
+                if "Data" in c.tag:
+                    fmts.append(c.attrib["Name"])
+                elif "InfluencedByFault" in c.tag:
+                    influenced_by.append(c.attrib["Name"])
+            # print(fmts)
+            sp[s] = {}
+            sp[s]["formations"] = fmts
+            sp[s]["InfluencedByFault"] = influenced_by
+
+        return sp
+
+
+    def _where_do_faults_stop(self):
+        fstop = {}
+        for i, f in enumerate(self.root[2]):
+
+            stops_on = []
+            for c in self.root[2][i][2:]:
+                stops_on.append(c.get("Name"))
+
+            fstop[f.get("Name")] = stops_on
+
+        return fstop
+
+    def get_fault_matrix(self):
+        nf = len(self.faults)
+        fm = np.zeros((nf, nf))  # zero matrix of n_faults²
+        fstop = self._where_do_faults_stop()
+        for i, f in enumerate(self.faults):
+            for fs in fstop[f]:
+                j = np.where(np.array(self.faults) == fs)[0][0]
+                fm[i, j] = 1
+
+        return fm
```

### Comparing `gempy-2.2b10.dev1/gempy/utils/geogrid.py` & `gempy-2.3.0/gempy/utils/geogrid.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,615 +1,615 @@
-'''Module with classes and methods to analyse and process exported geomodel grids
-Created on 21/03/2014
-@author: Florian Wellmann (some parts originally developed by Erik Schaeffer)
-'''
-import numpy as np
-#import pynoddy
-import subprocess
-import os.path
-import platform
-
-try:
-    import matplotlib.pyplot as plt
-except ImportError:
-    print("\n\n\tMatplotlib not installed - plotting functions will not work!\n\n\n")
-
-# import mpl_toolkits
-# from matplotlib.ticker import MultipleLocator, FormatStrFormatter
-
-# to convert python variable types to cpp types
-import ctypes
-# to create array
-from numpy.ctypeslib import ndpointer
-# to create folder
-import os
-
-import pyvista as pv
-# read out and change xml file (here only used to read out model boundary information)
-import geomodeller_xml_obj as GO
-
-
-class GeoGrid():
-    """Object definition for exported geomodel grids"""
-
-    def __init__(self, **kwds):
-        """GeoGrid contains methods to load, analyse, and process exported geomodel grids
-        **Optional Keywords**:
-            - *grid_filename* = string : filename of exported grid
-            - *delxyz_filename* = string : file with model discretisation
-            - *dimensions_filename* = string : file with model dimension (coordinates)
-        """
-
-        if 'grid_filename' in kwds:
-            self.grid_filename = kwds['grid_filename']
-        if 'delxyz_filename' in kwds:
-            self.delxyz_filename = kwds['delxyz_filename']
-        if 'dimensions_filename' in kwds:
-            self.dimensions_filename = kwds['dimensions_filename']
-
-    def __add__(self, G_other):
-        """Combine grid with another GeoGrid if regions are overlapping"""
-        # check overlap
-        print (self.ymin, self.ymax)
-        print (G_other.ymin, G_other.ymax)
-        if (G_other.ymin < self.ymax and G_other.ymin > self.ymin):
-            print("Grids overlapping in y-direction between %.0f and %.0f" %
-                  (G_other.ymin, self.ymax))
-
-    def load_grid(self):
-        """Load exported grid, discretisation and dimensions from file"""
-        if not hasattr(self, 'grid_filename'):
-            raise AttributeError("Grid filename is not defined!")
-        self.grid = np.loadtxt(self.grid_filename,
-                               delimiter = ',',
-                               dtype='int',
-                               unpack=False)
-        if hasattr(self, 'delxyz_filename'):
-            self.load_delxyz(self.delxyz_filename)
-            self.adjust_gridshape()
-        if hasattr(self, 'dimensions_filename'):
-            self.load_dimensions(self.dimensions_filename)
-
-    def load_delxyz(self, delxyz_filename):
-        """Load grid discretisation from file"""
-        del_lines = open(delxyz_filename, 'r').readlines()
-        d0 = del_lines[0].split("*")
-        self.delx = np.array([float(d0[1]) for _ in range(int(d0[0]))])
-        d1 = del_lines[1].split("*")
-        self.dely = np.array([float(d1[1]) for _ in range(int(d1[0]))])
-        d2 = del_lines[2].split(",")[:-1]
-        self.delz = np.array([float(d) for d in d2])
-        (self.nx, self.ny, self.nz) = (len(self.delx), len(self.dely), len(self.delz))
-        (self.extent_x, self.extent_y, self.extent_z) = (sum(self.delx), sum(self.dely), sum(self.delz))
-
-    def set_delxyz(self, delxyz):
-        """Set delx, dely, delz arrays explicitly and update additional attributes
-        **Arguments**:
-            - *delxyz* = (delx-array, dely-array, delz-array): arrays with cell dimensions
-        """
-        self.delx, self.dely, self.delz = delxyz
-        (self.nx, self.ny, self.nz) = (len(self.delx), len(self.dely), len(self.delz))
-        (self.extent_x, self.extent_y, self.extent_z) = (sum(self.delx), sum(self.dely), sum(self.delz))
-
-    def set_basename(self, name):
-        """Set basename for grid exports, etc.
-        **Arguments**:
-            - *name* = string: basename
-        """
-        self.basename = name
-
-    def load_dimensions(self, dimensions_filename):
-        """Load project dimensions from file"""
-        dim = [float(d) for d in open(dimensions_filename, 'r').readlines()[1].split(",")]
-        (self.xmin, self.xmax, self.ymin, self.ymax, self.zmin, self.zmax) = dim
-        # calculate cell centre positions in real world coordinates
-
-    def define_regular_grid(self, nx, ny, nz):
-        """Define a regular grid from defined project boundaries and given discretisations"""
-        self.nx = nx
-        self.ny = ny
-        self.nz = nz
-        self.delx = np.ones(nx) * (self.xmax - self.xmin) / nx
-        self.dely = np.ones(ny) * (self.ymax - self.ymin) / ny
-        self.delz = np.ones(nz) * (self.zmax - self.zmin) / nz
-        # create (empty) grid object
-        self.grid = np.ndarray((nx, ny, nz))
-        # update model extent
-        (self.extent_x, self.extent_y, self.extent_z) = (sum(self.delx), sum(self.dely), sum(self.delz))
-
-
-    def define_irregular_grid(self, delx, dely, delz):
-        """Set irregular grid according to delimter arrays in each direction"""
-        self.delx = delx
-        self.dely = dely
-        self.delz = delz
-        self.nx = len(delx)
-        self.ny = len(dely)
-        self.nz = len(delz)
-        # create (empty) grid object
-        self.grid = np.ndarray((self.nx, self.ny, self.nz))
-        # update model extent
-        (self.extent_x, self.extent_y, self.extent_z) = (sum(self.delx), sum(self.dely), sum(self.delz))
-
-    def get_dimensions_from_geomodeller_xml_project(self, xml_filename):
-        """Get grid dimensions from Geomodeller project
-        **Arguments**:
-            - *xml_filename* = string: filename of Geomodeller XML file
-        """
-        # Note: this implementation is based on the Geomodeller API
-        # The boundaries could theoretically also be extracted from the XML file
-        # directly, e.g. using the geomodeller_xml_obj module - but this would
-        # require an additional module being loaded, so avoid here!
-        filename_ctypes = ctypes.c_char_p(xml_filename)
-        # get model boundaries
-            #Detection of operative system:
-        if platform.system() == "Linux":
-            lib = ctypes.CDLL('./libgeomod.so') #linux
-        elif platform.system() == "Windows":
-            lib = ctypes.windll.LoadLibrary(os.path.dirname(os.path.abspath(__file__)) + os.path.sep + "libgeomodwin_leak6.dll")     #windows
-        else:
-            print("Your operative system is not supported")
-        lib.get_model_bounds.restype = ndpointer(dtype=ctypes.c_int, shape=(6,))
-        boundaries = lib.get_model_bounds(filename_ctypes)
-        (self.xmin, self.xmax, self.ymin, self.ymax, self.zmin, self.zmax) = boundaries
-        self.extent_x = self.xmax - self.xmin
-        self.extent_y = self.ymax - self.ymin
-        self.extent_z = self.zmax - self.zmin
-
-
-    def set_densities(self, densities):
-        """Set layer densities
-        **Arguments**:
-            - *densities* = dictionary of floats: densities for geology ids
-        """
-        self.densities = densities
-
-    def set_sus(self, sus):
-        """Set layer susceptibilities
-        **Arguments**:
-            - *us* = dictionary of floats: magnetic susceptibilities for geology ids
-        """
-        self.sus = sus
-
-    def set_dimensions(self, **kwds):
-        """Set model dimensions, if no argument provided: xmin = 0, max = sum(delx) and accordingly for y,z
-        **Optional keywords**:
-            - *dim* = (xmin, xmax, ymin, ymax, zmin, zmax) : set dimensions explicitly
-        """
-        if "dim" in kwds:
-            (self.xmin, self.xmax, self.ymin, self.ymax, self.zmin, self.zmax) = kwds['dim']
-        else:
-            self.xmin, self.ymin, self.zmin = (0., 0., 0.)
-            self.xmax, self.ymax, self.zmax = (sum(self.delx), sum(self.dely), sum(self.delz))
-
-    def determine_cell_centers(self):
-        """Determine cell centers for all coordinate directions in "real-world" coordinates"""
-        if not hasattr(self, 'xmin'):
-            raise AttributeError("Please define grid dimensions first")
-        sum_delx = np.cumsum(self.delx)
-        sum_dely = np.cumsum(self.dely)
-        sum_delz = np.cumsum(self.delz)
-        self.cell_centers_x = np.array([sum_delx[i] - self.delx[i] / 2. for i in range(self.nx)]) + self.xmin
-        self.cell_centers_y = np.array([sum_dely[i] - self.dely[i] / 2. for i in range(self.ny)]) + self.ymin
-        self.cell_centers_z = np.array([sum_delz[i] - self.delz[i] / 2. for i in range(self.nz)]) + self.zmin
-
-    def determine_cell_boundaries(self):
-        """Determine cell boundaries for all coordinates in "real-world" coordinates"""
-        if not hasattr(self, 'xmin'):
-            raise AttributeError("Please define grid dimensions first")
-        sum_delx = np.cumsum(self.delx)
-        sum_dely = np.cumsum(self.dely)
-        sum_delz = np.cumsum(self.delz)
-        self.boundaries_x = np.ndarray((self.nx+1))
-        self.boundaries_x[0] = 0
-        self.boundaries_x[1:] = sum_delx
-        self.boundaries_y = np.ndarray((self.ny+1))
-        self.boundaries_y[0] = 0
-        self.boundaries_y[1:] = sum_dely
-        self.boundaries_z = np.ndarray((self.nz+1))
-        self.boundaries_z[0] = 0
-        self.boundaries_z[1:] = sum_delz
-
-        # create a list with all bounds
-        self.bounds = [self.boundaries_y[0], self.boundaries_y[-1],
-                       self.boundaries_x[0], self.boundaries_x[-1],
-                       self.boundaries_z[0], self.boundaries_z[-1]]
-
-
-    def adjust_gridshape(self):
-        """Reshape numpy array to reflect model dimensions"""
-        self.grid = np.reshape(self.grid, (self.nz, self.ny, self.nx))
-        self.grid = np.swapaxes(self.grid, 0, 2)
-        # self.grid = np.swapaxes(self.grid, 0, 1)
-
-
-    def export_to_vtk(self, vtk_filename="geo_grid.vtr", real_coords = True, **kwds):
-        """Export grid to VTK for visualisation
-        **Arguments**:
-            - *vtk_filename* = string : vtk filename (obviously...)
-            - *real_coords* = bool : model extent in "real world" coordinates
-        **Optional Keywords**:
-            - *grid* = numpy grid : grid to save to vtk (default: self.grid)
-            - *var_name* = string : name of variable to plot (default: Geology)
-        """
-        grid = kwds.get("grid", self.grid)
-        var_name = kwds.get("var_name", "Geology")
-        # define coordinates
-        x = np.zeros(self.nx + 1)
-        y = np.zeros(self.ny + 1)
-        z = np.zeros(self.nz + 1)
-        x[1:] = np.cumsum(self.delx)
-        y[1:] = np.cumsum(self.dely)
-        z[1:] = np.cumsum(self.delz)
-
-        # plot in coordinates
-        if real_coords:
-            x += self.xmin
-            y += self.ymin
-            z += self.zmin
-            
-        out = pv.RectilinearGrid(x,y,z)
-        out['var_name'] = grid
-        out.save(vtk_filename)
-
-    def export_to_csv(self, filename = "geo_grid.csv"):
-        """Export grid to x,y,z,value pairs in a csv file
-        Ordering is x-dominant (first increase in x, then y, then z)
-        **Arguments**:
-            - *filename* = string : filename of csv file (default: geo_grid.csv)
-        """
-        f = open(filename, 'w')
-        for zz in self.delz:
-            for yy in self.dely:
-                for xx in self.delx:
-                    f.write("%.1f,%.1f,%.1f,%.d" % (xx,yy,zz,self.grid[xx,yy,zz]))
-        f.close()
-
-
-    def determine_geology_ids(self):
-        """Determine all ids assigned to cells in the grid"""
-        self.unit_ids = np.unique(self.grid)
-
-    def get_name_mapping_from_file(self, filename):
-        """Get the mapping between unit_ids in the model and real geological names
-        from a csv file (e.g. the SHEMAT property file)
-        **Arguments**:
-            - *filename* = string : filename of csv file with id, name entries
-        """
-        self.unit_name = {}
-        filelines = open(filename, 'r').readlines()[1:]
-        for line in filelines:
-            l = line.split(",")
-            self.unit_name[int(l[1])] = l[0]
-
-    def get_name_mapping_from_dict(self, unit_name_dict):
-        """Get the name mapping directly from a dictionary
-        **Arguments**:
-            - *unit_name_dict* = dict with "name" : unit_id (int) pairs
-        """
-        self.unit_name = unit_name_dict
-
-
-    def remap_ids(self, mapping_dictionary):
-        """Remap geological unit ids to new ids as defined in mapping dictionary
-        **Arguments**:
-            - *mapping_dictionary* = dict : {1 : 1, 2 : 3, ...} : e.g.: retain
-            id 1, but map id 2 to 3 (note: if id not specified, it will be retained)
-        """
-        # first step: create a single mesh for each id to avoid accidential
-        # overwriting below (there might be a better solution...)
-        if not hasattr(self, 'unit_ids'):
-            self.determine_geology_ids()
-        geol_grid_ind = {}
-        for k,v in mapping_dictionary.items():
-            geol_grid_ind[k] = self.grid == k
-            print("Remap id %d -> %d" % (k,v))
-        # now reassign values in actual grid
-        for k,v in mapping_dictionary.items():
-            print("Reassign id %d to grid" % v)
-            self.grid[geol_grid_ind[k]] = v
-        # update global geology ids
-        self.determine_geology_ids()
-
-    def determine_cell_volumes(self):
-        """Determine cell volumes for each cell (e.g. for total formation volume calculation)"""
-        self.cell_volume = np.ndarray(np.shape(self.grid))
-        for k,dz in enumerate(self.delz):
-            for j,dy in enumerate(self.dely):
-                for i,dx in enumerate(self.delx):
-                    self.cell_volume[i,j,k] = dx * dy * dz
-
-
-    def determine_indicator_grids(self):
-        """Determine indicator grids for all geological units"""
-        self.indicator_grids = {}
-        if not hasattr(self, 'unit_ids'):
-            self.determine_geology_ids()
-        grid_ones = np.ones(np.shape(self.grid))
-        for unit_id in self.unit_ids:
-            self.indicator_grids[unit_id] = grid_ones * (self.grid == unit_id)
-
-    def determine_id_volumes(self):
-        """Determine the total volume of each unit id in the grid
-        (for example for cell discretisation studies, etc."""
-        if not hasattr(self, 'cell_volume'):
-            self.determine_cell_volumes()
-        if not hasattr(self, 'indicator_grids'):
-            self.determine_indicator_grids()
-        self.id_volumes = {}
-        for unit_id in self.unit_ids:
-            self.id_volumes[unit_id] = np.sum(self.indicator_grids[unit_id] * self.cell_volume)
-
-    def print_unit_names_volumes(self):
-        """Formatted output to STDOUT of unit names (or ids, if names are note
-        defined) and calculated volumes
-        """
-        if not hasattr(self, 'id_vikumes'):
-            self.determine_id_volumes()
-
-        if hasattr(self, "unit_name"):
-            # print with real geological names
-            print("Total volumes of modelled geological units:\n")
-            for unit_id in self.unit_ids:
-                print("%26s : %.2f km^3" % (self.unit_name[unit_id],
-                                            self.id_volumes[unit_id]/1E9))
-        else:
-            # print with unit ids only
-            print("Total volumes of modelled geological units:\n")
-            for unit_id in self.unit_ids:
-                print("%3d : %.2f km^3" % (unit_id,
-                                            self.id_volumes[unit_id]/1E9))
-
-
-    def extract_subgrid(self, subrange, **kwds):
-        """Extract a subgrid model from existing grid
-        **Arguments**:
-            - *subrange* = (x_from, x_to, y_from, y_to, z_from, z_to) : range for submodel in either cell or world coords
-        **Optional keywords**:
-            - *range_type* = 'cell', 'world' : define if subrange in cell ids (default) or real-world coordinates
-        """
-        range_type = kwds.get('range_type', 'cell')
-
-        if not hasattr(self, 'boundaries_x'):
-            self.determine_cell_boundaries()
-
-        if range_type == 'world':
-            # determine cells
-            subrange[0] = np.argwhere(self.boundaries_x > subrange[0])[0][0]
-            subrange[1] = np.argwhere(self.boundaries_x < subrange[1])[-1][0]
-            subrange[2] = np.argwhere(self.boundaries_y > subrange[2])[0][0]
-            subrange[3] = np.argwhere(self.boundaries_y < subrange[3])[-1][0]
-            subrange[4] = np.argwhere(self.boundaries_z > subrange[4])[0][0]
-            subrange[5] = np.argwhere(self.boundaries_z < subrange[5])[-1][0]
-
-        # create a copy of the original grid
-        import copy
-        subgrid = copy.deepcopy(self)
-
-        # extract grid
-        subgrid.grid = self.grid[subrange[0]:subrange[1],
-                                 subrange[2]:subrange[3],
-                                 subrange[4]:subrange[5]]
-
-        subgrid.nx = subrange[1] - subrange[0]
-        subgrid.ny = subrange[3] - subrange[2]
-        subgrid.nz = subrange[5] - subrange[4]
-
-        # update extent
-        subgrid.xmin = self.boundaries_x[subrange[0]]
-        subgrid.xmax = self.boundaries_x[subrange[1]]
-        subgrid.ymin = self.boundaries_y[subrange[2]]
-        subgrid.ymax = self.boundaries_y[subrange[3]]
-        subgrid.zmin = self.boundaries_z[subrange[4]]
-        subgrid.zmax = self.boundaries_z[subrange[5]]
-
-        subgrid.extent_x = subgrid.xmax - subgrid.xmin
-        subgrid.extent_y = subgrid.ymax - subgrid.ymin
-        subgrid.extent_z = subgrid.zmax - subgrid.zmin
-
-        # update cell spacings
-        subgrid.delx = self.delx[subrange[0]:subrange[1]]
-        subgrid.dely = self.dely[subrange[2]:subrange[3]]
-        subgrid.delz = self.delz[subrange[4]:subrange[5]]
-
-        # now: update other attributes:
-        subgrid.determine_cell_centers()
-        subgrid.determine_cell_boundaries()
-        subgrid.determine_cell_volumes()
-        subgrid.determine_geology_ids()
-
-        # finally: return subgrid
-        return subgrid
-
-
-
-# ******************************************************************************
-#  Some additional helper functions
-# ******************************************************************************
-
-def combine_grids(G1, G2, direction, merge_type = 'keep_first', **kwds):
-    """Combine two grids along one axis
-    ..Note: this implementation assumes (for now) that the overlap is perfectly matching,
-    i.e. grid cell sizes identical and at equal positions, or that they are perfectly adjacent!
-    **Arguments**:
-        - G1, G2 = GeoGrid : grids to be combined
-        - direction = 'x', 'y', 'z': direction in which grids are combined
-        - merge_type = method to combine grid:
-            'keep_first' : keep elements of first grid (default)
-            'keep_second' : keep elements of second grid
-            'random' : randomly choose an element to retain
-        ..Note: all other dimensions must be matching perfectly!!
-    **Optional keywords**:
-        - *overlap_analysis* = bool : perform a detailed analysis of the overlapping area, including
-        mismatch. Also returns a second item, a GeoGrid with information on mismatch!
-    **Returns**:
-        - *G_comb* = GeoGrid with combined grid
-        - *G_overlap* = Geogrid with analysis of overlap (of overlap_analysis=True)
-    """
-    overlap_analysis = kwds.get("overlap_analysis", False)
-    # first step: determine overlap
-    if direction == 'x':
-        if G2.xmax > G1.xmax:
-            overlap_min = G2.xmin
-            overlap_max = G1.xmax
-            # identifier alias for grids with higher/ lower values
-            G_high = G2
-            G_low = G1
-        else:
-            overlap_min = G1.xmin
-            overlap_max = G2.xmax
-            # identifier alias for grids with higher/ lower values
-            G_high = G1
-            G_low = G2
-
-        # check if all other dimensions are perfectly matching
-        if (G1.ymin != G2.ymin) or (G1.zmin != G2.zmin) or \
-            (G1.ymax != G2.ymax) or (G1.zmax != G2.zmax):
-            raise ValueError("Other dimensions (apart from %s) not perfectly matching! Check and try again!" % direction)
-
-    elif direction == 'y':
-        if G2.ymax > G1.ymax:
-            overlap_min = G2.ymin
-            overlap_max = G1.ymax
-            # identifier alias for grids with higher/ lower values
-            G_high = G2
-            G_low = G1
-        else:
-            overlap_min = G1.ymin
-            overlap_max = G2.ymax
-            # identifier alias for grids with higher/ lower values
-            G_high = G1
-            G_low = G2
-
-        # check if all other dimensions are perfectly matching
-        if (G1.xmin != G2.xmin) or (G1.zmin != G2.zmin) or \
-            (G1.xmax != G2.xmax) or (G1.zmax != G2.zmax):
-            raise ValueError("Other dimensions (apart from %s) not perfectly matching! Check and try again!" % direction)
-
-    elif direction == 'z':
-        if G2.zmax > G1.zmax:
-            overlap_min = G2.zmin
-            overlap_max = G1.zmax
-            # identifier alias for grids with higher/ lower values
-            G_high = G2
-            G_low = G1
-        else:
-            overlap_min = G1.zmin
-            overlap_max = G2.zmax
-            # identifier alias for grids with higher/ lower values
-            G_high = G1
-            G_low = G2
-
-        # check if all other dimensions are perfectly matching
-        if (G1.ymin != G2.ymin) or (G1.xmin != G2.xmin) or \
-            (G1.ymax != G2.ymax) or (G1.xmax != G2.xmax):
-            raise ValueError("Other dimensions (apart from %s) not perfectly matching! Check and try again!" % direction)
-
-    overlap = overlap_max - overlap_min
-
-    if overlap == 0:
-        print("Grids perfectly adjacent")
-    elif overlap < 0:
-        raise ValueError("No overlap between grids! Check and try again!")
-    else:
-        print("Positive overlap in %s direction of %f meters" % (direction, overlap))
-
-    # determine cell centers
-    G1.determine_cell_centers()
-    G2.determine_cell_centers()
-
-    # intialise new grid
-    G_comb = GeoGrid()
-    # initialise overlap grid, if analyis performed
-    if overlap_analysis:
-        G_overlap = GeoGrid()
-
-    if direction == 'x':
-        pass
-    elif direction == 'y':
-        #=======================================================================
-        # Perform overlap analysis
-        #=======================================================================
-
-        # initialise overlap grid with dimensions of overlap
-        G_overlap.set_dimensions(dim = (G1.xmin, G1.xmax, overlap_min, overlap_max, G1.zmin, G1.zmax))
-        G_low_ids = np.where(G_low.cell_centers_y > overlap_min)[0]
-        G_high_ids = np.where(G_high.cell_centers_y < overlap_max)[0]
-        delx = G1.delx
-        dely = G_low.dely[G_low_ids]
-        delz = G1.delz
-        G_overlap.set_delxyz((delx, dely, delz))
-        # check if overlap region is identical
-        if not (len(G_low_ids) == len(G_high_ids)):
-            raise ValueError("Overlap length not identical, please check and try again!")
-        # now: determine overlap mismatch
-        G_overlap.grid = G_low.grid[:,G_low_ids,:] - G_high.grid[:,G_high_ids,:]
-        # for some very strange reason, this next step is necessary to enable the VTK
-        G_overlap.grid = G_overlap.grid + np.zeros(G_overlap.grid.shape)
-        #
-
-        #=======================================================================
-        # Set up combined grid
-        #=======================================================================
-
-        G_comb.set_dimensions(dim = (G1.xmin, G1.xmax, G_low.ymin, G_high.ymax, G1.zmin, G1.zmax))
-        # combine dely arrays
-        dely = np.hstack((G_low.dely[:G_low_ids[0]], G_high.dely))
-        G_comb.set_delxyz((delx, dely, delz))
-
-        #=======================================================================
-        # Now merge grids
-        #=======================================================================
-        if merge_type == 'keep_first':
-            if G1.ymax > G2.ymax:
-                G_comb.grid = np.concatenate((G2._grid[:, :G_low_ids[0], :], G1._grid), axis=1)
-            else:
-                G_comb.grid = np.concatenate((G1._grid, G2._grid[:, :G_low_ids[0], :]), axis=1)
-
-        elif merge_type == 'keep_second':
-            pass
-        elif merge_type == 'random':
-            pass
-        else:
-            raise ValueError("Merge type %s not recognised! Please check and try again!" % merge_type)
-
-    elif direction == 'z':
-        pass
-
-
-
-
-    # Return combined grid and results of overlap analysis, if determined
-    if overlap_analysis:
-        return G_comb, G_overlap
-    else:
-        return G_comb
-
-
-def optimial_cell_increase(starting_cell_width, n_cells, width):
-    """Determine an array with optimal cell width for a defined starting cell width,
-    total number of cells, and total width
-    Basically, this function optimised a factor between two cells to obtain a total
-    width
-    **Arguments**:
-    	- *starting_cell_width* = float : width of starting/ inner cell
-	- *n_cells* = int : total number of cells
-	- *total_width* = float : total width (sum over all elements in array)
-    **Returns**:
-        del_array : numpy.ndarray with cell discretisations
-    Note: optmisation with scipy.optimize - better (analytical?) methods might exist but
-    I can't think of them at the moment
-    """
-    import scipy.optimize
-    # define some helper functions
-
-    def width_sum(inc_factor, inner_cell, n_cells, total_width):
-        return sum(del_array(inc_factor, inner_cell, n_cells)) - total_width
-
-    def del_array(inc_factor, inner_cell, n_cells):
-        return np.array([inner_cell * inc_factor**i for i in range(n_cells)])
-
-    # now the actual optimisation step:
-    opti_factor = scipy.optimize.fsolve(width_sum, 1.1, (starting_cell_width, n_cells, width))
-
-    # return the discretisation array
-    return del_array(opti_factor, starting_cell_width, n_cells).flatten()
+'''Module with classes and methods to analyse and process exported geomodel grids
+Created on 21/03/2014
+@author: Florian Wellmann (some parts originally developed by Erik Schaeffer)
+'''
+import numpy as np
+#import pynoddy
+import subprocess
+import os.path
+import platform
+
+try:
+    import matplotlib.pyplot as plt
+except ImportError:
+    print("\n\n\tMatplotlib not installed - plotting functions will not work!\n\n\n")
+
+# import mpl_toolkits
+# from matplotlib.ticker import MultipleLocator, FormatStrFormatter
+
+# to convert python variable types to cpp types
+import ctypes
+# to create array
+from numpy.ctypeslib import ndpointer
+# to create folder
+import os
+
+import pyvista as pv
+# read out and change xml file (here only used to read out model boundary information)
+import geomodeller_xml_obj as GO
+
+
+class GeoGrid():
+    """Object definition for exported geomodel grids"""
+
+    def __init__(self, **kwds):
+        """GeoGrid contains methods to load, analyse, and process exported geomodel grids
+        **Optional Keywords**:
+            - *grid_filename* = string : filename of exported grid
+            - *delxyz_filename* = string : file with model discretisation
+            - *dimensions_filename* = string : file with model dimension (coordinates)
+        """
+
+        if 'grid_filename' in kwds:
+            self.grid_filename = kwds['grid_filename']
+        if 'delxyz_filename' in kwds:
+            self.delxyz_filename = kwds['delxyz_filename']
+        if 'dimensions_filename' in kwds:
+            self.dimensions_filename = kwds['dimensions_filename']
+
+    def __add__(self, G_other):
+        """Combine grid with another GeoGrid if regions are overlapping"""
+        # check overlap
+        print (self.ymin, self.ymax)
+        print (G_other.ymin, G_other.ymax)
+        if (G_other.ymin < self.ymax and G_other.ymin > self.ymin):
+            print("Grids overlapping in y-direction between %.0f and %.0f" %
+                  (G_other.ymin, self.ymax))
+
+    def load_grid(self):
+        """Load exported grid, discretisation and dimensions from file"""
+        if not hasattr(self, 'grid_filename'):
+            raise AttributeError("Grid filename is not defined!")
+        self.grid = np.loadtxt(self.grid_filename,
+                               delimiter = ',',
+                               dtype='int',
+                               unpack=False)
+        if hasattr(self, 'delxyz_filename'):
+            self.load_delxyz(self.delxyz_filename)
+            self.adjust_gridshape()
+        if hasattr(self, 'dimensions_filename'):
+            self.load_dimensions(self.dimensions_filename)
+
+    def load_delxyz(self, delxyz_filename):
+        """Load grid discretisation from file"""
+        del_lines = open(delxyz_filename, 'r').readlines()
+        d0 = del_lines[0].split("*")
+        self.delx = np.array([float(d0[1]) for _ in range(int(d0[0]))])
+        d1 = del_lines[1].split("*")
+        self.dely = np.array([float(d1[1]) for _ in range(int(d1[0]))])
+        d2 = del_lines[2].split(",")[:-1]
+        self.delz = np.array([float(d) for d in d2])
+        (self.nx, self.ny, self.nz) = (len(self.delx), len(self.dely), len(self.delz))
+        (self.extent_x, self.extent_y, self.extent_z) = (sum(self.delx), sum(self.dely), sum(self.delz))
+
+    def set_delxyz(self, delxyz):
+        """Set delx, dely, delz arrays explicitly and update additional attributes
+        **Arguments**:
+            - *delxyz* = (delx-array, dely-array, delz-array): arrays with cell dimensions
+        """
+        self.delx, self.dely, self.delz = delxyz
+        (self.nx, self.ny, self.nz) = (len(self.delx), len(self.dely), len(self.delz))
+        (self.extent_x, self.extent_y, self.extent_z) = (sum(self.delx), sum(self.dely), sum(self.delz))
+
+    def set_basename(self, name):
+        """Set basename for grid exports, etc.
+        **Arguments**:
+            - *name* = string: basename
+        """
+        self.basename = name
+
+    def load_dimensions(self, dimensions_filename):
+        """Load project dimensions from file"""
+        dim = [float(d) for d in open(dimensions_filename, 'r').readlines()[1].split(",")]
+        (self.xmin, self.xmax, self.ymin, self.ymax, self.zmin, self.zmax) = dim
+        # calculate cell centre positions in real world coordinates
+
+    def define_regular_grid(self, nx, ny, nz):
+        """Define a regular grid from defined project boundaries and given discretisations"""
+        self.nx = nx
+        self.ny = ny
+        self.nz = nz
+        self.delx = np.ones(nx) * (self.xmax - self.xmin) / nx
+        self.dely = np.ones(ny) * (self.ymax - self.ymin) / ny
+        self.delz = np.ones(nz) * (self.zmax - self.zmin) / nz
+        # create (empty) grid object
+        self.grid = np.ndarray((nx, ny, nz))
+        # update model extent
+        (self.extent_x, self.extent_y, self.extent_z) = (sum(self.delx), sum(self.dely), sum(self.delz))
+
+
+    def define_irregular_grid(self, delx, dely, delz):
+        """Set irregular grid according to delimter arrays in each direction"""
+        self.delx = delx
+        self.dely = dely
+        self.delz = delz
+        self.nx = len(delx)
+        self.ny = len(dely)
+        self.nz = len(delz)
+        # create (empty) grid object
+        self.grid = np.ndarray((self.nx, self.ny, self.nz))
+        # update model extent
+        (self.extent_x, self.extent_y, self.extent_z) = (sum(self.delx), sum(self.dely), sum(self.delz))
+
+    def get_dimensions_from_geomodeller_xml_project(self, xml_filename):
+        """Get grid dimensions from Geomodeller project
+        **Arguments**:
+            - *xml_filename* = string: filename of Geomodeller XML file
+        """
+        # Note: this implementation is based on the Geomodeller API
+        # The boundaries could theoretically also be extracted from the XML file
+        # directly, e.g. using the geomodeller_xml_obj module - but this would
+        # require an additional module being loaded, so avoid here!
+        filename_ctypes = ctypes.c_char_p(xml_filename)
+        # get model boundaries
+            #Detection of operative system:
+        if platform.system() == "Linux":
+            lib = ctypes.CDLL('./libgeomod.so') #linux
+        elif platform.system() == "Windows":
+            lib = ctypes.windll.LoadLibrary(os.path.dirname(os.path.abspath(__file__)) + os.path.sep + "libgeomodwin_leak6.dll")     #windows
+        else:
+            print("Your operative system is not supported")
+        lib.get_model_bounds.restype = ndpointer(dtype=ctypes.c_int, shape=(6,))
+        boundaries = lib.get_model_bounds(filename_ctypes)
+        (self.xmin, self.xmax, self.ymin, self.ymax, self.zmin, self.zmax) = boundaries
+        self.extent_x = self.xmax - self.xmin
+        self.extent_y = self.ymax - self.ymin
+        self.extent_z = self.zmax - self.zmin
+
+
+    def set_densities(self, densities):
+        """Set layer densities
+        **Arguments**:
+            - *densities* = dictionary of floats: densities for geology ids
+        """
+        self.densities = densities
+
+    def set_sus(self, sus):
+        """Set layer susceptibilities
+        **Arguments**:
+            - *us* = dictionary of floats: magnetic susceptibilities for geology ids
+        """
+        self.sus = sus
+
+    def set_dimensions(self, **kwds):
+        """Set model dimensions, if no argument provided: xmin = 0, max = sum(delx) and accordingly for y,z
+        **Optional keywords**:
+            - *dim* = (xmin, xmax, ymin, ymax, zmin, zmax) : set dimensions explicitly
+        """
+        if "dim" in kwds:
+            (self.xmin, self.xmax, self.ymin, self.ymax, self.zmin, self.zmax) = kwds['dim']
+        else:
+            self.xmin, self.ymin, self.zmin = (0., 0., 0.)
+            self.xmax, self.ymax, self.zmax = (sum(self.delx), sum(self.dely), sum(self.delz))
+
+    def determine_cell_centers(self):
+        """Determine cell centers for all coordinate directions in "real-world" coordinates"""
+        if not hasattr(self, 'xmin'):
+            raise AttributeError("Please define grid dimensions first")
+        sum_delx = np.cumsum(self.delx)
+        sum_dely = np.cumsum(self.dely)
+        sum_delz = np.cumsum(self.delz)
+        self.cell_centers_x = np.array([sum_delx[i] - self.delx[i] / 2. for i in range(self.nx)]) + self.xmin
+        self.cell_centers_y = np.array([sum_dely[i] - self.dely[i] / 2. for i in range(self.ny)]) + self.ymin
+        self.cell_centers_z = np.array([sum_delz[i] - self.delz[i] / 2. for i in range(self.nz)]) + self.zmin
+
+    def determine_cell_boundaries(self):
+        """Determine cell boundaries for all coordinates in "real-world" coordinates"""
+        if not hasattr(self, 'xmin'):
+            raise AttributeError("Please define grid dimensions first")
+        sum_delx = np.cumsum(self.delx)
+        sum_dely = np.cumsum(self.dely)
+        sum_delz = np.cumsum(self.delz)
+        self.boundaries_x = np.ndarray((self.nx+1))
+        self.boundaries_x[0] = 0
+        self.boundaries_x[1:] = sum_delx
+        self.boundaries_y = np.ndarray((self.ny+1))
+        self.boundaries_y[0] = 0
+        self.boundaries_y[1:] = sum_dely
+        self.boundaries_z = np.ndarray((self.nz+1))
+        self.boundaries_z[0] = 0
+        self.boundaries_z[1:] = sum_delz
+
+        # create a list with all bounds
+        self.bounds = [self.boundaries_y[0], self.boundaries_y[-1],
+                       self.boundaries_x[0], self.boundaries_x[-1],
+                       self.boundaries_z[0], self.boundaries_z[-1]]
+
+
+    def adjust_gridshape(self):
+        """Reshape numpy array to reflect model dimensions"""
+        self.grid = np.reshape(self.grid, (self.nz, self.ny, self.nx))
+        self.grid = np.swapaxes(self.grid, 0, 2)
+        # self.grid = np.swapaxes(self.grid, 0, 1)
+
+
+    def export_to_vtk(self, vtk_filename="geo_grid.vtr", real_coords = True, **kwds):
+        """Export grid to VTK for visualisation
+        **Arguments**:
+            - *vtk_filename* = string : vtk filename (obviously...)
+            - *real_coords* = bool : model extent in "real world" coordinates
+        **Optional Keywords**:
+            - *grid* = numpy grid : grid to save to vtk (default: self.grid)
+            - *var_name* = string : name of variable to plot (default: Geology)
+        """
+        grid = kwds.get("grid", self.grid)
+        var_name = kwds.get("var_name", "Geology")
+        # define coordinates
+        x = np.zeros(self.nx + 1)
+        y = np.zeros(self.ny + 1)
+        z = np.zeros(self.nz + 1)
+        x[1:] = np.cumsum(self.delx)
+        y[1:] = np.cumsum(self.dely)
+        z[1:] = np.cumsum(self.delz)
+
+        # plot in coordinates
+        if real_coords:
+            x += self.xmin
+            y += self.ymin
+            z += self.zmin
+            
+        out = pv.RectilinearGrid(x,y,z)
+        out['var_name'] = grid
+        out.save(vtk_filename)
+
+    def export_to_csv(self, filename = "geo_grid.csv"):
+        """Export grid to x,y,z,value pairs in a csv file
+        Ordering is x-dominant (first increase in x, then y, then z)
+        **Arguments**:
+            - *filename* = string : filename of csv file (default: geo_grid.csv)
+        """
+        f = open(filename, 'w')
+        for zz in self.delz:
+            for yy in self.dely:
+                for xx in self.delx:
+                    f.write("%.1f,%.1f,%.1f,%.d" % (xx,yy,zz,self.grid[xx,yy,zz]))
+        f.close()
+
+
+    def determine_geology_ids(self):
+        """Determine all ids assigned to cells in the grid"""
+        self.unit_ids = np.unique(self.grid)
+
+    def get_name_mapping_from_file(self, filename):
+        """Get the mapping between unit_ids in the model and real geological names
+        from a csv file (e.g. the SHEMAT property file)
+        **Arguments**:
+            - *filename* = string : filename of csv file with id, name entries
+        """
+        self.unit_name = {}
+        filelines = open(filename, 'r').readlines()[1:]
+        for line in filelines:
+            l = line.split(",")
+            self.unit_name[int(l[1])] = l[0]
+
+    def get_name_mapping_from_dict(self, unit_name_dict):
+        """Get the name mapping directly from a dictionary
+        **Arguments**:
+            - *unit_name_dict* = dict with "name" : unit_id (int) pairs
+        """
+        self.unit_name = unit_name_dict
+
+
+    def remap_ids(self, mapping_dictionary):
+        """Remap geological unit ids to new ids as defined in mapping dictionary
+        **Arguments**:
+            - *mapping_dictionary* = dict : {1 : 1, 2 : 3, ...} : e.g.: retain
+            id 1, but map id 2 to 3 (note: if id not specified, it will be retained)
+        """
+        # first step: create a single mesh for each id to avoid accidential
+        # overwriting below (there might be a better solution...)
+        if not hasattr(self, 'unit_ids'):
+            self.determine_geology_ids()
+        geol_grid_ind = {}
+        for k,v in mapping_dictionary.items():
+            geol_grid_ind[k] = self.grid == k
+            print("Remap id %d -> %d" % (k,v))
+        # now reassign values in actual grid
+        for k,v in mapping_dictionary.items():
+            print("Reassign id %d to grid" % v)
+            self.grid[geol_grid_ind[k]] = v
+        # update global geology ids
+        self.determine_geology_ids()
+
+    def determine_cell_volumes(self):
+        """Determine cell volumes for each cell (e.g. for total formation volume calculation)"""
+        self.cell_volume = np.ndarray(np.shape(self.grid))
+        for k,dz in enumerate(self.delz):
+            for j,dy in enumerate(self.dely):
+                for i,dx in enumerate(self.delx):
+                    self.cell_volume[i,j,k] = dx * dy * dz
+
+
+    def determine_indicator_grids(self):
+        """Determine indicator grids for all geological units"""
+        self.indicator_grids = {}
+        if not hasattr(self, 'unit_ids'):
+            self.determine_geology_ids()
+        grid_ones = np.ones(np.shape(self.grid))
+        for unit_id in self.unit_ids:
+            self.indicator_grids[unit_id] = grid_ones * (self.grid == unit_id)
+
+    def determine_id_volumes(self):
+        """Determine the total volume of each unit id in the grid
+        (for example for cell discretisation studies, etc."""
+        if not hasattr(self, 'cell_volume'):
+            self.determine_cell_volumes()
+        if not hasattr(self, 'indicator_grids'):
+            self.determine_indicator_grids()
+        self.id_volumes = {}
+        for unit_id in self.unit_ids:
+            self.id_volumes[unit_id] = np.sum(self.indicator_grids[unit_id] * self.cell_volume)
+
+    def print_unit_names_volumes(self):
+        """Formatted output to STDOUT of unit names (or ids, if names are note
+        defined) and calculated volumes
+        """
+        if not hasattr(self, 'id_vikumes'):
+            self.determine_id_volumes()
+
+        if hasattr(self, "unit_name"):
+            # print with real geological names
+            print("Total volumes of modelled geological units:\n")
+            for unit_id in self.unit_ids:
+                print("%26s : %.2f km^3" % (self.unit_name[unit_id],
+                                            self.id_volumes[unit_id]/1E9))
+        else:
+            # print with unit ids only
+            print("Total volumes of modelled geological units:\n")
+            for unit_id in self.unit_ids:
+                print("%3d : %.2f km^3" % (unit_id,
+                                            self.id_volumes[unit_id]/1E9))
+
+
+    def extract_subgrid(self, subrange, **kwds):
+        """Extract a subgrid model from existing grid
+        **Arguments**:
+            - *subrange* = (x_from, x_to, y_from, y_to, z_from, z_to) : range for submodel in either cell or world coords
+        **Optional keywords**:
+            - *range_type* = 'cell', 'world' : define if subrange in cell ids (default) or real-world coordinates
+        """
+        range_type = kwds.get('range_type', 'cell')
+
+        if not hasattr(self, 'boundaries_x'):
+            self.determine_cell_boundaries()
+
+        if range_type == 'world':
+            # determine cells
+            subrange[0] = np.argwhere(self.boundaries_x > subrange[0])[0][0]
+            subrange[1] = np.argwhere(self.boundaries_x < subrange[1])[-1][0]
+            subrange[2] = np.argwhere(self.boundaries_y > subrange[2])[0][0]
+            subrange[3] = np.argwhere(self.boundaries_y < subrange[3])[-1][0]
+            subrange[4] = np.argwhere(self.boundaries_z > subrange[4])[0][0]
+            subrange[5] = np.argwhere(self.boundaries_z < subrange[5])[-1][0]
+
+        # create a copy of the original grid
+        import copy
+        subgrid = copy.deepcopy(self)
+
+        # extract grid
+        subgrid.grid = self.grid[subrange[0]:subrange[1],
+                                 subrange[2]:subrange[3],
+                                 subrange[4]:subrange[5]]
+
+        subgrid.nx = subrange[1] - subrange[0]
+        subgrid.ny = subrange[3] - subrange[2]
+        subgrid.nz = subrange[5] - subrange[4]
+
+        # update extent
+        subgrid.xmin = self.boundaries_x[subrange[0]]
+        subgrid.xmax = self.boundaries_x[subrange[1]]
+        subgrid.ymin = self.boundaries_y[subrange[2]]
+        subgrid.ymax = self.boundaries_y[subrange[3]]
+        subgrid.zmin = self.boundaries_z[subrange[4]]
+        subgrid.zmax = self.boundaries_z[subrange[5]]
+
+        subgrid.extent_x = subgrid.xmax - subgrid.xmin
+        subgrid.extent_y = subgrid.ymax - subgrid.ymin
+        subgrid.extent_z = subgrid.zmax - subgrid.zmin
+
+        # update cell spacings
+        subgrid.delx = self.delx[subrange[0]:subrange[1]]
+        subgrid.dely = self.dely[subrange[2]:subrange[3]]
+        subgrid.delz = self.delz[subrange[4]:subrange[5]]
+
+        # now: update other attributes:
+        subgrid.determine_cell_centers()
+        subgrid.determine_cell_boundaries()
+        subgrid.determine_cell_volumes()
+        subgrid.determine_geology_ids()
+
+        # finally: return subgrid
+        return subgrid
+
+
+
+# ******************************************************************************
+#  Some additional helper functions
+# ******************************************************************************
+
+def combine_grids(G1, G2, direction, merge_type = 'keep_first', **kwds):
+    """Combine two grids along one axis
+    ..Note: this implementation assumes (for now) that the overlap is perfectly matching,
+    i.e. grid cell sizes identical and at equal positions, or that they are perfectly adjacent!
+    **Arguments**:
+        - G1, G2 = GeoGrid : grids to be combined
+        - direction = 'x', 'y', 'z': direction in which grids are combined
+        - merge_type = method to combine grid:
+            'keep_first' : keep elements of first grid (default)
+            'keep_second' : keep elements of second grid
+            'random' : randomly choose an element to retain
+        ..Note: all other dimensions must be matching perfectly!!
+    **Optional keywords**:
+        - *overlap_analysis* = bool : perform a detailed analysis of the overlapping area, including
+        mismatch. Also returns a second item, a GeoGrid with information on mismatch!
+    **Returns**:
+        - *G_comb* = GeoGrid with combined grid
+        - *G_overlap* = Geogrid with analysis of overlap (of overlap_analysis=True)
+    """
+    overlap_analysis = kwds.get("overlap_analysis", False)
+    # first step: determine overlap
+    if direction == 'x':
+        if G2.xmax > G1.xmax:
+            overlap_min = G2.xmin
+            overlap_max = G1.xmax
+            # identifier alias for grids with higher/ lower values
+            G_high = G2
+            G_low = G1
+        else:
+            overlap_min = G1.xmin
+            overlap_max = G2.xmax
+            # identifier alias for grids with higher/ lower values
+            G_high = G1
+            G_low = G2
+
+        # check if all other dimensions are perfectly matching
+        if (G1.ymin != G2.ymin) or (G1.zmin != G2.zmin) or \
+            (G1.ymax != G2.ymax) or (G1.zmax != G2.zmax):
+            raise ValueError("Other dimensions (apart from %s) not perfectly matching! Check and try again!" % direction)
+
+    elif direction == 'y':
+        if G2.ymax > G1.ymax:
+            overlap_min = G2.ymin
+            overlap_max = G1.ymax
+            # identifier alias for grids with higher/ lower values
+            G_high = G2
+            G_low = G1
+        else:
+            overlap_min = G1.ymin
+            overlap_max = G2.ymax
+            # identifier alias for grids with higher/ lower values
+            G_high = G1
+            G_low = G2
+
+        # check if all other dimensions are perfectly matching
+        if (G1.xmin != G2.xmin) or (G1.zmin != G2.zmin) or \
+            (G1.xmax != G2.xmax) or (G1.zmax != G2.zmax):
+            raise ValueError("Other dimensions (apart from %s) not perfectly matching! Check and try again!" % direction)
+
+    elif direction == 'z':
+        if G2.zmax > G1.zmax:
+            overlap_min = G2.zmin
+            overlap_max = G1.zmax
+            # identifier alias for grids with higher/ lower values
+            G_high = G2
+            G_low = G1
+        else:
+            overlap_min = G1.zmin
+            overlap_max = G2.zmax
+            # identifier alias for grids with higher/ lower values
+            G_high = G1
+            G_low = G2
+
+        # check if all other dimensions are perfectly matching
+        if (G1.ymin != G2.ymin) or (G1.xmin != G2.xmin) or \
+            (G1.ymax != G2.ymax) or (G1.xmax != G2.xmax):
+            raise ValueError("Other dimensions (apart from %s) not perfectly matching! Check and try again!" % direction)
+
+    overlap = overlap_max - overlap_min
+
+    if overlap == 0:
+        print("Grids perfectly adjacent")
+    elif overlap < 0:
+        raise ValueError("No overlap between grids! Check and try again!")
+    else:
+        print("Positive overlap in %s direction of %f meters" % (direction, overlap))
+
+    # determine cell centers
+    G1.determine_cell_centers()
+    G2.determine_cell_centers()
+
+    # intialise new grid
+    G_comb = GeoGrid()
+    # initialise overlap grid, if analyis performed
+    if overlap_analysis:
+        G_overlap = GeoGrid()
+
+    if direction == 'x':
+        pass
+    elif direction == 'y':
+        #=======================================================================
+        # Perform overlap analysis
+        #=======================================================================
+
+        # initialise overlap grid with dimensions of overlap
+        G_overlap.set_dimensions(dim = (G1.xmin, G1.xmax, overlap_min, overlap_max, G1.zmin, G1.zmax))
+        G_low_ids = np.where(G_low.cell_centers_y > overlap_min)[0]
+        G_high_ids = np.where(G_high.cell_centers_y < overlap_max)[0]
+        delx = G1.delx
+        dely = G_low.dely[G_low_ids]
+        delz = G1.delz
+        G_overlap.set_delxyz((delx, dely, delz))
+        # check if overlap region is identical
+        if not (len(G_low_ids) == len(G_high_ids)):
+            raise ValueError("Overlap length not identical, please check and try again!")
+        # now: determine overlap mismatch
+        G_overlap.grid = G_low.grid[:,G_low_ids,:] - G_high.grid[:,G_high_ids,:]
+        # for some very strange reason, this next step is necessary to enable the VTK
+        G_overlap.grid = G_overlap.grid + np.zeros(G_overlap.grid.shape)
+        #
+
+        #=======================================================================
+        # Set up combined grid
+        #=======================================================================
+
+        G_comb.set_dimensions(dim = (G1.xmin, G1.xmax, G_low.ymin, G_high.ymax, G1.zmin, G1.zmax))
+        # combine dely arrays
+        dely = np.hstack((G_low.dely[:G_low_ids[0]], G_high.dely))
+        G_comb.set_delxyz((delx, dely, delz))
+
+        #=======================================================================
+        # Now merge grids
+        #=======================================================================
+        if merge_type == 'keep_first':
+            if G1.ymax > G2.ymax:
+                G_comb.grid = np.concatenate((G2._grid[:, :G_low_ids[0], :], G1._grid), axis=1)
+            else:
+                G_comb.grid = np.concatenate((G1._grid, G2._grid[:, :G_low_ids[0], :]), axis=1)
+
+        elif merge_type == 'keep_second':
+            pass
+        elif merge_type == 'random':
+            pass
+        else:
+            raise ValueError("Merge type %s not recognised! Please check and try again!" % merge_type)
+
+    elif direction == 'z':
+        pass
+
+
+
+
+    # Return combined grid and results of overlap analysis, if determined
+    if overlap_analysis:
+        return G_comb, G_overlap
+    else:
+        return G_comb
+
+
+def optimial_cell_increase(starting_cell_width, n_cells, width):
+    """Determine an array with optimal cell width for a defined starting cell width,
+    total number of cells, and total width
+    Basically, this function optimised a factor between two cells to obtain a total
+    width
+    **Arguments**:
+    	- *starting_cell_width* = float : width of starting/ inner cell
+	- *n_cells* = int : total number of cells
+	- *total_width* = float : total width (sum over all elements in array)
+    **Returns**:
+        del_array : numpy.ndarray with cell discretisations
+    Note: optmisation with scipy.optimize - better (analytical?) methods might exist but
+    I can't think of them at the moment
+    """
+    import scipy.optimize
+    # define some helper functions
+
+    def width_sum(inc_factor, inner_cell, n_cells, total_width):
+        return sum(del_array(inc_factor, inner_cell, n_cells)) - total_width
+
+    def del_array(inc_factor, inner_cell, n_cells):
+        return np.array([inner_cell * inc_factor**i for i in range(n_cells)])
+
+    # now the actual optimisation step:
+    opti_factor = scipy.optimize.fsolve(width_sum, 1.1, (starting_cell_width, n_cells, width))
+
+    # return the discretisation array
+    return del_array(opti_factor, starting_cell_width, n_cells).flatten()
```

### Comparing `gempy-2.2b10.dev1/gempy/utils/geomodeller_integration.py` & `gempy-2.3.0/gempy/utils/geomodeller_integration.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,1217 +1,1217 @@
-"""Class definition for GeoModeller XML-Files
-This version includes drillholes
-Specific methods are defined for the uncertainty analysis (in combination
-with Uncertainty_Obj module)
-
-(c) J. Florian Wellmann, 2009-2013
-"""
-
-# try:
-#     import elementtree.ElementTree as ET
-# except ImportError:
-#     try:
-#         import etree.ElementTree as ET
-#     except ImportError:
-#         try:
-#             import xml.etree.ElementTree as ET
-#         except ImportError:
-#             import ElementTree as ET
-# import Latex_output_5 as LO
-from pylab import *
-import copy
-import pandas as pn
-import gempy as gp
-import numpy as np
-
-# python module to wrap GeoModeller XML file and perform all kinds of data
-# procedures, e.g.:
-# - Stochastic data modeling
-# - TWT to depth conversion
-# - Documentation module
-#
-# To Do:
-# - exception handling and passing
-# - log file?
-# - check validity of xml-code, test, if past-processing with sax neccessary?
-# - implement auto-documentation
-# - clear-up spaghetti code!!!!! Check dependencies and other modules
-#    to get a consistent lay-out
-
-try:
-    import xml.etree.cElementTree as ET
-except ImportError:
-    import xml.etree.ElementTree as ET
-
-# TODO fix this function and importing it to gempy.utils.create_from_geomodeller_xml
-def create_from_geomodeller_xml(fp, resolution=(50, 50, 50), return_xml=False, **kwargs):
-    """
-    EXPERIMENTAL
-    Creates InputData object from a GeoModeller xml file. Automatically extracts and sets model extent, interface
-    and orientation data as well as the stratigraphic pile.
-
-    Args:
-        fp (str): Filepath for the GeoModeller xml file to be read.
-        resolution (tuple, optional): Tuple containing the number of voxels in dimensions (x,y,z). Defaults to 50.
-        return_xml (bool, optional): Toggles returning the ReadGeoModellerXML instance to leverage further info from the
-            xml file (e.g. for stratigraphic pile ordering). Defaults to True.
-        **kwargs: Keyword arguments for create_data function.
-
-    Returns:
-        gp.data_management.InputData
-    """
-    gmx = _ReadGeoModellerXML(fp)  # instantiate parser class with filepath of xml
-
-    # instantiate InputData object with extent and resolution
-    geo_data = create_data(gmx.extent, resolution, **kwargs)
-
-    # set interface and orientation dataframes
-    geo_data._surface_points = gmx._surface_points
-    geo_data._orientations = gmx._orientations
-
-    if return_xml:
-        return geo_data, gmx
-    else:
-        return geo_data
-
-
-
-class ReadGeoModellerXML:
-    def __init__(self, fp):
-        """
-        Reads in and parses a GeoModeller XML file to extract interface and orientation data and the overall model
-        settings (e.g. extent and sequential pile). It uses ElementTree to parse the XML and the tree's root can
-        be accessed using self.root for more direct access to the file.
-
-        Args:
-            fp (str): Filepath for the GeoModeller xml file to be read.
-
-        """
-        self.tree = ET.ElementTree(file=fp)  # load xml as tree
-        self.root = self.tree.getroot()
-
-        self.xmlns = "http://www.geomodeller.com/geo"
-        self.gml = "http://www.opengis.net/gml"
-
-        self.extent = self._get_extent()
-
-        self.data = self.extract_data()
-        self.surface_points, self.orientations = self.get_dataframes()
-
-        # self.stratigraphic_column = self.get_stratigraphic_column()
-        # self.df = self.get_faults()
-        #
-        # self.series_info = self._get_series_fmt_dict()
-        # self.series_distribution = self.get_series_distribution()
-        #
-        # self.fault_matrix = self.get_fault_matrix()
-
-    def get_psc(self):
-        """Returns the ProjectStratigraphicColumn tree element used for several data extractions."""
-        return self.root.find("{" + self.xmlns + "}GeologicalModel").find("{"+self.xmlns+"}ProjectStratigraphicColumn")
-
-    def extract_data(self):
-        """
-        Extracts relevant data from the GeoModeller XML file ElementTree root (self.root) and returns it as a dictionary.
-
-
-        Returns:
-            (dict): Data dictionary
-        """
-        data = {}
-        for s in self.get_psc():
-            sn = s.get("name")
-            data[sn] = {}  # create a dict for each series
-            data[sn]["formations"] = []
-            data[sn]["InfluencedByFault"] = []
-            data[sn]["relation"] = s.get("relation")  # add relation, whatever that is
-
-            for c in s:
-                if c.tag == "{"+self.xmlns+"}Data":  # append formation names to list of formations
-                    data[sn]["formations"].append(c.get("Name"))
-
-                if c.tag == "{"+self.xmlns+"}InfluencedByFault":  # add fault influences
-                    data[sn]["InfluencedByFault"].append(c.get("Name"))
-
-                if c.tag == "{"+self.xmlns+"}PotentialField":
-
-                    data[sn]["gradients"] = []
-                    data[sn]["surface_points"] = []
-                    data[sn]["surface_points_counters"] = []
-                    data[sn]["solutions"] = []
-                    data[sn]["constraints"] = []
-
-                    for cc in c:
-                        # COVARIANCE
-                        if cc.tag == "{" + self.xmlns + "}covariance":
-                            data[sn]["covariance"] = cc.attrib
-
-                        # GRADIENTS
-                        if cc.tag == "{" + self.xmlns + "}Gradients":
-                            for gr in cc:
-                                data[sn]["gradients"].append([gr.get("Gx"), gr.get("Gy"), gr.get("Gz"),
-                                                              gr.get("XGr"), gr.get("YGr"), gr.get("ZGr")])
-
-                        # surface_points
-                        if cc.tag == "{" + self.xmlns + "}Points":
-                            for co in cc:
-                                data[sn]["surface_points"].append([float(co[0].text), float(co[1].text), float(co[2].text)])
-
-                        # INTERFACE COUNTERS
-                        if cc.tag == "{" + self.xmlns + "}InterfacePoints":
-                            for ip in cc:
-                                data[sn]["surface_points_counters"].append([int(ip.get("npnt")), int(ip.get("pnt"))])
-
-                        # CONSTRAINTS
-                        if cc.tag == "{" + self.xmlns + "}Constraints":
-                            for co in cc:
-                                data[sn]["constraints"].append(float(co.get("value")))
-
-                        # SOLUTIONS
-                        if cc.tag == "{" + self.xmlns + "}Solutions":
-                            for sol in cc:
-                                data[sn]["solutions"].append(float(sol.get("sol")))
-
-                    # convert from str to float
-                    data[sn]["gradients"] = np.array(data[sn]["gradients"]).astype(float)
-                    data[sn]["surface_points"] = np.array(data[sn]["surface_points"]).astype(float)
-                    data[sn]["surface_points_counters"] = np.array(data[sn]["surface_points_counters"]).astype(float)
-                    data[sn]["solutions"] = np.array(data[sn]["solutions"]).astype(float)
-
-        return data
-
-    def get_dataframes(self):
-        """
-        Extracts dataframe information from the self.data dictionary and returns GemPy-compatible surface_points and
-        orientations dataframes.
-
-        Returns:
-            (tuple) of GemPy dataframes (surface_points, orientations)
-        """
-        interf_formation = []
-        interf_series = []
-
-        orient_series = []
-
-        for i, s in enumerate(self.data.keys()):  # loop over all series
-            if i == 0:
-                coords = self.data[s]["surface_points"]
-                grads = self.data[s]["gradients"]
-            else:
-                coords = np.append(coords, self.data[s]["surface_points"])
-                grads = np.append(grads, self.data[s]["gradients"])
-
-            for j, fmt in enumerate(self.data[s]["formations"]):
-                for n in range(int(self.data[s]["surface_points_counters"][j, 0])):
-                    interf_formation.append(fmt)
-                    interf_series.append(s)
-
-            for k in range(len(grads)):
-                orient_series.append(s)
-
-        surface_points = pn.DataFrame(coords, columns=['X', 'Y', 'Z'])
-        surface_points["formation"] = interf_formation
-        surface_points["series"] = interf_series
-
-        orientations = pn.DataFrame(grads, columns=['G_x', 'G_y', 'G_z', 'X', 'Y', 'Z'])
-        orientations["series"] = orient_series
-
-        dips = []
-        azs = []
-        pols = []
-        for i, row in orientations.iterrows():
-            dip, az, pol = gp.data_management.get_orientation((row["G_x"], row["G_y"], row["G_z"]))
-            dips.append(dip)
-            azs.append(az)
-            pols.append(pol)
-
-        orientations["dip"] = dips
-        orientations["azimuth"] = azs
-        orientations["polarity"] = pols
-
-        return surface_points, orientations
-
-
-    def get_stratigraphic_column(self):
-        """
-        Extracts series names from ElementTree root.
-
-        Returns:
-            tuple: Series names (str) in stratigraphic order.
-        """
-        stratigraphic_column = []
-        for s in self.get_psc():
-            stratigraphic_column.append(s.get("name"))
-        return tuple(stratigraphic_column)
-
-    def get_order_formations(self):
-        order_formations = []
-        for entry in self.series_distribution.values():
-            if type(entry) is str:
-                order_formations.append(entry)
-            elif type(entry) is tuple:
-                for e in entry:
-                    order_formations.append(e)
-
-        return order_formations
-
-    def get_faults(self):
-        """
-        Extracts fault names from ElementTree root.
-
-        Returns:
-            tuple: Fault names (str) ordered as in the GeoModeller XML.
-        """
-        faults = []
-        for c in self.root[2]:
-            faults.append(c.get("Name"))
-        return tuple(faults)
-
-    def get_series_distribution(self):
-        """
-        Combines df and stratigraphic series into an unordered dictionary as keys and maps the correct
-        formations to them as a list value. Faults series get a list of their own string assigned as formation.
-
-        Returns:
-            (dict): maps Series (str) -> Surfaces (list of str)
-        """
-        series_distribution = {}
-        for key in self.series_info.keys():
-            fmts = self.series_info[key]["formations"]
-            if len(fmts) == 1:
-                series_distribution[key] = fmts[0]
-            else:
-                series_distribution[key] = tuple(fmts)
-
-        for f in self.stratigraphic_column:
-            if "Fault" in f or "fault" in f:
-                series_distribution[f] = f
-
-        return series_distribution
-
-    def _get_extent(self):
-        """
-        Extracts model extent from ElementTree root and returns it as tuple of floats.
-
-        Returns:
-            tuple: Model extent as (xmin, xmax, ymin, ymax, zmin, zmax).
-        """
-        xy = self.root[0][0][0][0].attrib
-        z = self.root[0][0][0][1].attrib
-        return tuple(np.array([xy["Xmin"], xy["Xmax"],
-                               xy["Ymin"], xy["Ymax"],
-                                z["Zmin"],  z["Zmax"]]).astype(float))
-
-    def get_surface_points_df(self):
-        """
-        Extracts the interface data points stored in the GeoModeller xml file and returns it as a GemPy surface_points
-        dataframe.
-
-        Returns:
-            pandas.DataFrame: InputData.surface_points dataframe
-        """
-        if self.root.find("{" + self.xmlns + "}Structural3DData") is None:
-            print("No 3D data stored in given xml file.")
-            return None
-        else:
-            fmts = [c.attrib["Name"] for c in self.root.find("{" + self.xmlns + "}Structural3DData")[0]]  # use formations
-            xyzf = []
-
-            for i, fmt in enumerate(fmts):  # loop over all formations
-                for p in self.root[5][0][i]:  # loop over every point
-                    entry = p[0].text.split(",")  # split the string by its seperator into coord strings
-                    entry.append(fmt)
-
-                    for s in self.series_info.keys():
-                        if fmt in self.series_info[s]["formations"]:
-                            series = s
-                        else:
-                            series = fmt
-
-                    entry.append(series)
-                    xyzf.append(entry)
-
-            surface_points = pn.DataFrame(np.array(xyzf), columns=['X', 'Y', 'Z', "formation", "series"])
-            surface_points[["X", "Y", "Z"]] = surface_points[["X", "Y", "Z"]].astype(float)
-            return surface_points
-
-    def get_orientation_df(self):
-        """
-        Extracts the orientation data points sotred in the GeoModeller xml file and returns it as a GemPy
-        orientations dataframe.
-
-        Returns:
-            pandas.DataFrame: InputData.orientations dataframe
-        """
-        if self.root.find("{" + self.xmlns + "}Structural3DData") is None:
-            print("No 3D data stored in given xml file.")
-            return None
-        else:
-            fol = []
-            for i, s in enumerate(self.root.find("{" + self.xmlns + "}Structural3DData")[1]):
-                for c in self.root.find("{" + self.xmlns + "}Structural3DData")[1][i]:
-                    entry = c[0][0].text.split(",")
-                    entry.append(c.get("Dip"))
-                    entry.append(c.get("Azimuth"))
-                    # correct polarity from bool str to int
-                    pol = c.get("NormalPolarity")
-                    if pol == "true":
-                        entry.append(1)
-                    else:
-                        entry.append(-1)
-                    entry.append(s.get("Name"))
-                    for series in self.series_distribution.keys():
-                        if s.get("Name") in self.series_distribution[series]:
-                            entry.append(series)
-
-                    fol.append(entry)
-
-            orientations = pn.DataFrame(np.array(fol), columns=['X', 'Y', 'Z', 'dip', 'azimuth', 'polarity', 'formation', 'series'])
-            orientations[["X", "Y", "Z", "dip", "azimuth"]] = orientations[["X", "Y", "Z", "dip", "azimuth"]].astype(float)
-            orientations["polarity"] = orientations["polarity"].astype(int)
-
-            return orientations
-
-    def _get_series_fmt_dict(self):
-        sp = {}
-        for i, s in enumerate(self.stratigraphic_column):  # loop over all series
-            fmts = []  # init formation storage list
-            influenced_by = []  # init influenced by list
-            for c in self.root.find("{" + self.xmlns + "}GeologicalModel").find("{"+self.xmlns+"}ProjectStratigraphicColumn")[i]:
-                if "Data" in c.tag:
-                    fmts.append(c.attrib["Name"])
-                elif "InfluencedByFault" in c.tag:
-                    influenced_by.append(c.attrib["Name"])
-            # print(fmts)
-            sp[s] = {}
-            sp[s]["formations"] = fmts
-            sp[s]["InfluencedByFault"] = influenced_by
-
-        return sp
-
-    def _where_do_faults_stop(self):
-        fstop = {}
-        for i, f in enumerate(self.root[2]):
-
-            stops_on = []
-            for c in self.root[2][i][2:]:
-                stops_on.append(c.get("Name"))
-
-            fstop[f.get("Name")] = stops_on
-
-        return fstop
-
-    def get_fault_matrix(self):
-        nf = len(self.faults)
-        fm = np.zeros((nf, nf))  # zero matrix of n_faults²
-        fstop = self._where_do_faults_stop()
-        for i, f in enumerate(self.faults):
-            for fs in fstop[f]:
-                j = np.where(np.array(self.faults) == fs)[0][0]
-                fm[i, j] = 1
-
-        return fm
-
-
-# TODO think where this function should go
-def read_vox(geo_data, path):
-    """
-    read vox from geomodeller and transform it to gempy format
-    Returns:
-        numpy.array: block model
-    """
-    import pandas as pn
-    geo_res = pn.read_csv(path)
-
-    geo_res = geo_res.iloc[9:]
-
-    # ip_addresses = geo_res['nx 50'].unique()  # geo_model.surface_points["formation"].unique()
-    ip_dict = geo_data.get_formation_number()
-  #  ip_dict = geo_model.surface_points['formation_number'].unique()
-
-    geo_res_num = geo_res.iloc[:, 0].replace(ip_dict)
-    block_geomodeller = np.ravel(geo_res_num.values.reshape(
-        geo_data.resolution[0], geo_data.resolution[1], geo_data.resolution[2], order='C').T)
-    return block_geomodeller
-
-
-class GeomodellerClass:
-    """Wrapper for GeoModeller XML-datafiles to perform all kinds of data
-    manipulation and analysis on low level basis, e.g.:
-    - Uncertainty Simulation
-    - TWT to depth conversion
-    - Data analysis, e.g. Auto-documentation"""
-
-    def __init__(self):
-        """Wrapper for GeoModeller XML-datafiles to perform all kinds of data
-    manipulation and analysis on low level basis, e.g.:
-    - Uncertainty Simulation
-    - TWT to depth conversion
-    - Data analysis, e.g. Auto-documentation"""
-
-    def load_geomodeller_file(self, xml_file):
-        self.xml_file_name = xml_file
-        try:
-            tree = ET.parse(xml_file)
-        except IOError:
-            print(("Can not open xml File " + xml_file + ": " + string_err))
-            print ("Please check file name and directory and try again")
-            raise IOError
-        # safe tree on local varibale
-        self.tree = tree
-        # get rootelement
-        self.rootelement = tree.getroot()
-        # set other class variables
-        self.xmlns = "http://www.geomodeller.com/geo"
-        self.gml = "http://www.opengis.net/gml"
-
-    def load_deepcopy_tree(self, deepcopy_tree):
-        """load tree information from deepcopied tree into object"""
-        self.tree = deepcopy_tree
-        self.rootelement = deepcopy_tree.getroot()
-        # set other class variables
-        self.xmlns = "http://www.geomodeller.com/geo"
-        self.gml = "http://www.opengis.net/gml"
-
-    def deepcopy_tree(self):
-        """create a deep copy of original tree to restore later, e.g. for uncertainty evaluation"""
-
-        deepcopy_tree = copy.deepcopy(self.tree)
-        deepcopy_tree.parent = None
-        return deepcopy_tree
-
-    def reload_geomodeller_file(self, deepcopy_tree):
-        """restore original tree root from deep copy of orignial tree
-        deep copy can be created (not automatically to save memory!) with
-        self.deepcopy_tree()
-        """
-        try:
-            self.tree = deepcopy_tree
-            self.rootelement = self.tree.getroot()
-        except NameError:
-            print ("No deep copy of original tree available, please create with self.deepcopy_tree()")
-
-    def get_model_extent(self):
-        """get extent of model
-        returns (x_min, x_max, y_min, y_max, z_min, z_max)
-        and saves extent in self.x_min, self.x_max, etc.
-        """
-        extent_parent = self.rootelement.find("{"+self.xmlns+"}Extent3DOfProject")
-        extentbox3D = extent_parent.find("{"+self.xmlns+"}ExtentBox3D")
-        extent3D = extentbox3D.find("{"+self.xmlns+"}Extent3D")
-        extent_xy = extent3D.find("{"+self.xmlns+"}ExtentXY")
-        extent_z = extent3D.find("{"+self.xmlns+"}ExtentZ")
-        self.x_min = float(extent_xy.get("Xmin"))
-        self.x_max = float(extent_xy.get("Xmax"))
-        self.y_min = float(extent_xy.get("Ymin"))
-        self.y_max = float(extent_xy.get("Ymax"))
-        self.z_min = float(extent_z.get("Zmin"))
-        self.z_max = float(extent_z.get("Zmax"))
-        return (self.x_min, self.x_max, self.y_min, self.y_max, self.z_min, self.z_max)
-
-    # def get_model_range(self):
-    #     """get model range from model extent, e.g. for automatic mesh generation"""
-    #     (x_min, x_max, y_min, y_max, z_min, z_max) = self.get_model_extent()
-    #     from numpy import abs
-    #     self.range_x = abs(x_max - x_min)
-    #     self.range_y = abs(y_max - y_min)
-    #     self.range_z = abs(z_max - z_min)
-    #     return (self.range_x, self.range_y, self.range_z)
-
-    def get_sections(self):
-        """get sections out of rootelement, safe array with section elements
-        in local variable"""
-        sections_parent = self.rootelement.findall("{"+self.xmlns+"}Sections")[0]
-        self.sections = sections_parent.findall("{"+self.xmlns+"}Section")
-        return self.sections
-
-    def get_faults(self):
-        """get fault elements out of rootelement and safe as local list"""
-        try:
-            faults_parent = self.rootelement.findall("{"+self.xmlns+"}Faults")[0]
-            self.faults = faults_parent.findall("{"+self.xmlns+"}Fault")
-        except IndexError:
-            print("No df found in model")
-        return self.faults
-
-    def get_formations(self):
-        """get formation elements out of rootelement and safe as local list"""
-        formations_parent = self.rootelement.findall("{"+self.xmlns+"}Surfaces")[0]
-        self.formations = formations_parent.findall("{"+self.xmlns+"}Formation")
-
-    def get_stratigraphy_list(self, **kwds):
-        """get project stratigraphy and return as list; lowermost formation: 1
-        for GeoModeller dll access (this ist the formation_number that is returned with
-        the GetComputedLithologyXYZ function in the geomodeller dll
-        optional keywords:
-        out = string : set 'out' formation to this name (might be necessary for TOUGH2 simulation!)
-        """
-        series_list = []
-        strati_column = self.rootelement.find("{"+self.xmlns+"}GeologicalModel").find("{"+self.xmlns+"}ProjectStratigraphicColumn")#.findall("{"+self.xmlns+"Series")
-        series = strati_column.findall("{"+self.xmlns+"}Series")
-        for s in series:
-            data = s.findall("{"+self.xmlns+"}Data")
-            for d in data:
-                series_list.append(d.get("Name"))
-        # append "out" as uppermost formation for "out values
-        if "tough2" in kwds:
-            if 'out' in kwds:
-                series_list.append(kwds['out'])
-            else:
-                series_list.append("out")
-        self.stratigraphy_list = series_list
-        return series_list
-
-    def get_section_names(self):
-        """get all section names out of local variable self.sections"""
-        # todo: return section names as dictionary with element and name?
-        # test if self.sections defined, if not -> create
-        try:
-            self.sections
-        except AttributeError:
-            # print "Create sections Data array"
-            self.get_sections()
-        section_names = []
-        for section in self.sections:
-            section_names.append(section.get("Name"))
-        return section_names
-
-    def get_formation_names(self):
-        """get formation names and return as list"""
-        forms=[]
-        try:
-            self.formations
-        except AttributeError:
-            self.get_formations()
-        for formation in self.formations:
-            forms.append(formation.get("Name"))
-        return forms
-
-    def get_fault_names(self):
-        """get fault names and return as list"""
-        faults_list=[]
-        try:
-            self.faults
-        except AttributeError:
-            self.get_faults()
-        for fault in self.faults:
-            faults_list.append(fault.get("Name"))
-        return faults_list
-
-    def get_points_in_sections(self):
-        """Create dictionary of all points (with obs-id) in all sections"""
-        self.create_sections_dict()
-        for sec in list(self.section_dict.keys()):
-            forms = self.get_formation_point_data(self.section_dict[sec])
-            if forms == None:
-                print ("\t\t\tNo Formation Points in this section")
-            else:
-                for form in forms:
-                    #print form.get("ObservationID")
-                #    if form.get("ObservationID") == None: continue
-                    data = form.find("{"+self.xmlns+"}Data")
-                    print(("\nObsID = %s" % form.get("ObservationID")))
-                    print(("\tFormation name\t= %s" % data.get("Name")))
-                    element_point = form.find("{"+self.gml+"}LineString")
-                    element_coords = element_point.find("{"+self.gml+"}coordinates")
-                    tmp = element_coords.text.split(" ")
-                    for tmp1 in tmp:
-                        if tmp1 == '': continue
-                        tmp_cds = tmp1.split(",")
-                        print(("\tX = %.1f, Y = %.1f" % (float(tmp_cds[0]), float(tmp_cds[1]))))
-
-
-                    fol = form.find("{"+self.xmlns+"}FoliationObservation")
-                    if fol is not None:
-                        print(("\tFoliation defined: azimuth = %.1f, dip = %.1f" % (float(fol.get("Azimuth")), float(fol.get("Dip")))))
-                        # get position of foliation (yet another point)
-                        pt = fol.find("{"+self.gml+"}Point")
-                        c = pt.find("{"+self.gml+"}coordinates")
-                        cds = c.text.split(",")
-                        print(("\t\tX = %.1f, Y = %.1f" % (float(cds[0]), float(cds[1]))))
-
-            print ("\n")
-            print((80*"-"))
-            print(("Foliations in section %s:" % sec))
-            print((80*"-"))
-            foliations = self.get_foliations(self.section_dict[sec])
-            if foliations == None:
-                print ("\t\t\tNo foliations in this section")
-            else:
-                for fol1 in foliations:
-                    print(("\nObsID = %s" % fol1.get("ObservationID")))
-                    data = fol1.find("{"+self.xmlns+"}Data")
-                    fol = fol1.find("{"+self.xmlns+"}FoliationObservation")
-                    print(( "\tFormation name\t= %s" % data.get("Name")))
-                    print(("\tAzimuth = %.1f, dip = %.1f" % (float(fol.get("Azimuth")), float(fol.get("Dip")))))
-                    pt = fol.find("{"+self.gml+"}Point")
-                    c = pt.find("{"+self.gml+"}coordinates")
-                    cds = c.text.split(",")
-                    print(("\tX = %.1f, Y = %.1f" % (float(cds[0]), float(cds[1]))))
-        return
-
-    def get_formation_parameters(self):
-        """read formation parameters; physical
-        properties, density, th. cond etc... store in dict"""
-        #
-        # To do: re-write in a more elegant way and keep original
-        # structure and key-words?
-        #
-        self.formation_params = {}
-        try:
-            self.formations
-        except AttributeError:
-            #            print "Create sections Data array"
-            self.get_formations()
-        for formation in self.formations:
-            self.formation_params[formation.get("Name")] = {}
-            geophys = formation.find("{"+self.xmlns+"}Geophysics")
-            dens = geophys.find("{"+self.xmlns+"}DensityCompoundDistribution")
-            dens_simple = dens.find("{"+self.xmlns+"}SimpleDistribution")
-            self.formation_params[formation.get("Name")]["dens_mean"] = dens_simple.get("Mean")
-            self.formation_params[formation.get("Name")]["dens_law"] = dens_simple.get("LawType")
-            self.formation_params[formation.get("Name")]["dens_dev"] = dens_simple.get("Deviation")
-            #             print geophys.getchildren()
-            mag = geophys.find("{"+self.xmlns+"}RemanantMagnetizationCompoundDistribution")
-            mag_simple = mag.find("{"+self.xmlns+"}SimpleDistributionVector")
-            self.formation_params[formation.get("Name")]["mag"] = mag_simple.get("Mean")
-            velocity = geophys.find("{"+self.xmlns+"}VelocityCompoundDistribution")
-            velocity_simple = velocity.find("{"+self.xmlns+"}SimpleDistribution")
-            self.formation_params[formation.get("Name")]["vel_mean"] = velocity_simple.get("Mean")
-            self.formation_params[formation.get("Name")]["vel_law"] = velocity_simple.get("LawType")
-            self.formation_params[formation.get("Name")]["vel_dev"] = velocity_simple.get("Deviation")
-            # Thermal properties are only defined in newer versions of GeoModeller! thus check!
-
-            th_cond = geophys.find("{"+self.xmlns+"}ThermalConductivityCompoundDistribution")
-            if th_cond == None: continue
-            th_cond_simple = th_cond.find("{"+self.xmlns+"}SimpleDistribution")
-            self.formation_params[formation.get("Name")]["th_cond_mean"] = th_cond_simple.get("Mean")
-            self.formation_params[formation.get("Name")]["th_cond_law"] = th_cond_simple.get("LawType")
-            self.formation_params[formation.get("Name")]["th_cond_dev"] = th_cond_simple.get("Deviation")
-            heat_prod = geophys.find("{"+self.xmlns+"}HeatProductionRateCompoundDistribution")
-            heat_prod_simple = heat_prod.find("{"+self.xmlns+"}SimpleDistribution")
-            self.formation_params[formation.get("Name")]["heat_prod_mean"] = heat_prod_simple.get("Mean")
-            self.formation_params[formation.get("Name")]["heat_prod_law"] = heat_prod_simple.get("LawType")
-            self.formation_params[formation.get("Name")]["heat_prod_dev"] = heat_prod_simple.get("Deviation")
-
-            # same for other properties
-        #    print th_cond
-            #
-            # !!! only simple distributions yet impl.
-            #
-
-    def create_fault_dict(self):
-        """create dictionary for fault elements with names as keys"""
-        # test if self.formations defined, if not -> create
-        try:
-            self.faults
-        except AttributeError:
-            print ("Create Surfaces list")
-            self.get_faults()
-        self.fault_dict = {}
-        for fault in self.faults:
-            self.fault_dict[fault.get("Name")] = fault
-        return self.fault_dict
-
-    def create_formation_dict(self):
-        """create dictionary for formation elements with formation names as keys"""
-        # test if self.formations defined, if not -> create
-        try:
-            self.formations
-        except AttributeError:
-            print ("Create formation dictionary")
-            self.get_formations()
-        self.formation_dict = {}
-        for formation in self.formations:
-            self.formation_dict[formation.get("Name")] = formation
-        return self.formation_dict
-
-    def create_sections_dict(self):
-        """create dictionary for section elements with section names as keys
-        (for easier use...)"""
-        # test if self.sections defined, if not -> create
-        try:
-            self.sections
-        except AttributeError:
-            # print "Create sections dictionary"
-            self.get_sections()
-        self.section_dict = {}
-        for section in self.sections:
-            self.section_dict[section.get("Name")] = section
-        return self.section_dict
-
-    def get_foliations(self, section_element):
-        """get all foliation data elements from a for section"""
-        tmp_element = section_element.find("{"+self.xmlns+"}Structural2DData")
-        # check in case there is no foliation defined in this section
-        # tmp_element2 = tmp_element.find("{"+self.xmlns+"}Foliations")
-        try:
-            tmp_element2 = tmp_element.find("{"+self.xmlns+"}Foliations")
-        except AttributeError:
-            return None
-        try:
-            foliations = tmp_element2.findall("{"+self.xmlns+"}Foliation")
-        except AttributeError:
-            return None
-        return foliations
-
-    def get_foliation_dip(self, foliation_element):
-        """get dip of foliation element"""
-        return float(foliation_element.find("{"+self.xmlns+"}FoliationObservation").get("Dip"))
-
-    def get_foliation_azimuth(self, foliation_element):
-        """get dip of foliation element"""
-        return float(foliation_element.find("{"+self.xmlns+"}FoliationObservation").get("Azimuth"))
-
-    def get_folation_polarity(self, foliation_element):
-        """get polarity of foliation element; return true if Normal Polarity"""
-        return foliation_element.find("{"+self.xmlns+"}FoliationObservation").get("NormalPolarity")
-
-    def get_foliation_coordinates(self, foliation_element):
-        """get coordinates of foliation element"""
-        element_fol = foliation_element.find("{"+self.xmlns+"}FoliationObservation")
-        element_point = element_fol.find("{"+self.gml+"}Point")
-        element_coords = element_point.find("{"+self.gml+"}coordinates")
-        return str(element_coords.text)
-
-    def get_formation_data(self, section_element):
-        """not used any more! use get_formation_point_data(section_element) instead"""
-        print ("not used any more! use get_formation_point_data(section_element) instead")
-        return None
-
-    def get_formation_point_data(self, section_element):
-        """get all formation point data elements from a for section"""
-        tmp_element = section_element.find("{"+self.xmlns+"}Structural2DData")
-        # check in case there is no formation points defined in this section
-        try:
-            tmp_element2 = tmp_element.find("{"+self.xmlns+"}SurfacePoints")
-        except AttributeError:
-            return None
-        return tmp_element2.findall("{"+self.xmlns+"}Interface")
-
-    def get_name(self, section_element):
-        """get the name of any section element (if defined)"""
-        return section_element.find("{"+self.xmlns+"}Name")
-
-    def get_interface_name(self, interface_element):
-        """get name of interface, i.e. the formation"""
-        return interface_element.find("{"+self.xmlns+"}Data").get("Name")
-
-    def get_point_coordinates(self, point_elements, **args):
-        """get the coordinates of a specific point memory locations"""
-        point_list = list()
-
-        for element in point_elements:
-          name = element.find("{"+self.xmlns+"}Data").get("Name")
-          #if args.has_key("if_name"):
-          if "if_name" in args:
-            if args["if_name"] != name: continue
-          element_point = element.find("{"+self.gml+"}LineString")
-          element_coords = element_point.find("{"+self.gml+"}coordinates")
-          point_list.append((name+ " " + str(element_coords.text)))
-        return point_list
-
-    def change_formation_values_PyMC(self, **args):
-        """ -So far is ready only to changes points in coordinates y. It is not difficult to add a new
-        dimension
-
-            - The dips and azimuth ObservationID must contain _d or _a respectively"""
-
-        if "info" in args:
-            section_dict = self.create_sections_dict()
-            contact_points_dict = {}
-            foliation_dict = {}
-            for i in range(len(section_dict)):
-                print(("\n\n\n", list(section_dict.keys())[i], "\n"))
-                print ("Elements and their ID \n")
-                contact_points = self.get_formation_point_data(list(section_dict.values())[i])
-
-                try:
-                    for contact_point in contact_points:
-                        contact_points_dict[contact_point.get("ObservationID")] = contact_point
-                        print((contact_point, contact_point.get("ObservationID")))
-                except TypeError:
-                    print ("No contact points in the section")
-                #ObsID = contact_points.get("ObservationID")
-                foliations = self.get_foliations(list(section_dict.values())[i])
-                try:
-                    for foliation in foliations:
-                        # dictionary to access with azimth name
-                        foliation_dict[foliation.get("ObservationID")+"_a"] = foliation
-                        # dictionary to access with dip name
-                        foliation_dict[foliation.get("ObservationID")+"_d"] = foliation
-                        print((foliation, foliation.get("ObservationID")))
-
-                except TypeError:
-                    print ("No foliation in the section")
-                try:
-                    coord_interface = self.get_point_coordinates(contact_points)
-                except TypeError:
-                    print ("Element does not have iterable objects")
-
-                print(("\nDictionaries:\n ", contact_points_dict, "\n", foliation_dict))
-
-                print(("\n Contact points", contact_points, "\n", coord_interface, "\n"))
-
-                print(("foliations" , foliations,  "\n"))
-                try:
-                    for i in range(len(foliations)):
-                        print(("azimut:",self.get_foliation_azimuth(foliations[i])))
-                        print(("dip",self.get_foliation_dip(foliations[i])))
-                        print(("coordinates", self.get_foliation_coordinates(foliations[i])))
-                except TypeError:
-                    print ("No foliation in the section")
-            return None
-        #========================
-        # change the stuff
-        #=======================
-        section_dict = self.create_sections_dict()
-        contact_points_dict = {}
-        foliation_dict = {}
-
-        #Creation of dictionaries according to the ObservationID
-        for i in range(len(section_dict)):
-            # Contact points:
-            try:
-                contact_points = self.get_formation_point_data(list(section_dict.values())[i])
-                for contact_point in contact_points:
-                    contact_points_dict[contact_point.get("ObservationID")] = contact_point
-            except TypeError:
-                continue
-            # Foliation Points
-            try:
-                foliations = self.get_foliations(list(section_dict.values())[i])
-                for foliation in foliations:
-                    # dictionary to access with azimth name
-                    foliation_dict[foliation.get("ObservationID")+"_a"] = foliation
-                    # dictionary to access with dip name
-                    foliation_dict[foliation.get("ObservationID")+"_d"] = foliation
-            except TypeError:
-                continue
-
-        # Passing our chain values:
-            # Contact_points
-        if "contact_points_mc" in args:
-            for contac_point_mc in args["contact_points_mc"]:
-                try:
-
-                    element = contact_points_dict[str(contac_point_mc)]
-                    element_point = element.find("{"+self.gml+"}LineString")
-                    element_coords = element_point.find("{"+self.gml+"}coordinates")
-                    point_list = element_coords.text.split(" ")
-                    if point_list[-1] == '':
-                        point_list = point_list[0:-1]
-
-                    if len(point_list) == 1:
-                        self.change_formation_point_pos(element, y_coord = contac_point_mc.value)
-                    #Specific case of the Graben:
-                    elif len(point_list) == 2:
-                        self.change_formation_point_pos(element, y_coord = [contac_point_mc.value, contac_point_mc.value])
-                    else:
-                        print ("The lenght of the points to change does not fit with the number of changes in the input (>2)")
-                except KeyError:
-                    print(("The name of your PyMC variables (%s) does not agree with the ObservationID in the xml. Check misspellings." % str(contac_point_mc)))
-                    continue
-            # Azimuths
-        if "azimuths_mc" in args:
-            for azimuth_mc in args["azimuths_mc"]:
-                #print azimuth_mc, type(azimuth_mc)
-                try:
-                    self.change_foliation(foliation_dict[str(azimuth_mc)], azimuth = str(azimuth_mc.value))
-                except KeyError:
-                    print(("The name of your PyMC variables (%s) does not agree with the ObservationID in the xml. Check misspellings." % str(azimuth_mc)))
-                    continue
-            # Dips
-        if "dips_mc" in args:
-            for dip_mc in args["dips_mc"]:
-                try:
-                    self.change_foliation(foliation_dict[str(dip_mc)], dip = str(dip_mc.value))
-                except KeyError:
-                    print(("The name of your PyMC variables (%s) does not agree with the ObservationID in the xml. Check misspellings." % str(dip_mc)))
-                    continue
-
-
-    # To do: vectorize this
-    def change_formation_point_pos(self, element, **args):
-        """change position of formation point in section element
-        arguments:
-        x_coord, y_coord : set to this coordinates
-        add_x_coord, add_y_coord : add values to existing coordinates
-        use if_name = and if_provenance = to add conditions!
-        print_points = bool: print the list of points that will be modified (default: False)"""
-        #    print "I am here"
-        #print_points = kwds.get('print_points', False)
-        prov = element.get("Provenance")
-
-        name = element.find("{"+self.xmlns+"}Data").get("Name")
-
-        #if args.has_key("if_name"):
-        if "if_name" in args:
-            if args["if_name"] != name: return
-        # if args.has_key("if_provenance"):
-        if "if_provenance" in args:
-            if args["if_provenance"] != prov: return
-        # element_fol = element.find("{"+self.xmlns+"}")
-        element_point = element.find("{"+self.gml+"}LineString")
-        element_coords = element_point.find("{"+self.gml+"}coordinates")
-        point_list = element_coords.text.split(" ")
-        #    print "poitn lits", point_list
-        if point_list[-1] == '':
-            point_list = point_list[0:-1]
-        if len(point_list) > 1:
-            x_coords = []
-            y_coords = []
-            if "print_points" in args:
-                print (point_list)
-            for point in point_list:
-                # if point == '': continue
-                a = point.split(',')
-                #print a
-                [x_coord, y_coord] = [float(a[0]), float(a[1])]
-                x_coords.append(x_coord)
-                y_coords.append(y_coord)
-            # convert to arrays for calculation
-            x_coords = array(x_coords)
-            y_coords = array(y_coords)
-            # Here  y_coord, and x_coord
-            if "x_coord" in args:
-                if shape(point_list) == shape(args["x_coord"]):
-                #except TypeError:
-                    x_coords = array(args["x_coord"])
-                else:
-                    print ("length of the points you want to change do not match with input dimensions")
-            if "y_coord" in args:
-                #print (args["y_coord"])
-                #print array(args["y_coord"])
-                if shape(point_list) == shape(args["y_coord"]):
-                    y_coords = array(args["y_coord"])
-                    #            print "ycoords", y_coords
-                else:
-                    print ("length of the points you want to change do not match with input dimensions")
-            #print "Coordenates", x_coords, y_coords
-            # Here add coords
-            if "add_x_coord" in args:
-                x_coords = x_coords + float(args["add_x_coord"])
-            if "add_y_coord" in args:
-                y_coords = y_coords + float(args["add_y_coord"])
-            #    print y_coords
-            # now, reconstruct output format strings
-            out_text = ''
-            for (i, x_coord) in enumerate(x_coords):
-                out_text += "%f,%f " % (x_coords[i],y_coords[i])
-            element_coords.text = out_text
-
-        else:
-            [x_coord, y_coord] = point_list[0].split(",")
-            [x_coord, y_coord] = [float(x_coord), float(y_coord)]
-            if "x_coord" in args:
-                x_coord = float(args["x_coord"])
-            if "y_coord" in args:
-                y_coord = float(args["y_coord"])
-            if "add_x_coord" in args:
-                x_coord = x_coord + float(args["add_x_coord"])
-            if "add_y_coord" in args:
-                y_coord = y_coord + float(args["add_y_coord"])
-            element_coords.text = "%f,%f" % (x_coord, y_coord)
-        return None
-
-    def change_foliation_polarity(self, element):
-        """change polarity of foliation element"""
-        if element.get("NormalPolarity") == "true":
-            element.set("NormalPolarity", "false")
-        else:
-            element.set("NormalPolarity", "true")
-
-    def change_foliation(self, element, **args):
-        """change foliation data, argument one or more of: azimuth, dip,
-        normalpolarity = true/false, x_coord, y_coord" or: add_dip, add_azimuth,
-        add_x_coord, add_y_coord to add values to existing values!
-        use if_name = and if_provenance = to add conditions!"""
-        prov = element.get("Provenance")
-        name = element.find("{"+self.xmlns+"}Data").get("Name")
-        if "if_name" in args:
-            if args["if_name"] != name: return
-        if "if_provenance" in args:
-            if args["if_provenance"] != prov: return
-        element_fol = element.find("{"+self.xmlns+"}FoliationObservation")
-        if "dip" in args:
-            element_fol.set("Dip", args["dip"])
-        if "azimuth" in args:
-            element_fol.set("Azimuth", args["azimuth"])
-        if "nomalpolarity" in args:
-            element_fol.set("NormalPolarity", args["normalpolarity"])
-        #
-        # To Do: logfile, if dip >90, azi > 360, ...
-        #
-        if "add_dip" in args:
-            dip_org = float(element_fol.get("Dip"))
-            dip_new = dip_org + float(args["add_dip"])
-            if dip_new > 90:
-                dip_new = 180 - dip_new
-                self.change_foliation_polarity(element_fol)
-                azi_org = float(element_fol.get("Azimuth"))
-                if azi_org < 180:
-                    element_fol.set("Azimuth", str(azi_org+180))
-                else:
-                    element_fol.set("Azimuth", str(azi_org-180))
-            element_fol.set("Dip", str(dip_new))
-        if "add_azimuth" in args:
-            azi_org = float(element_fol.get("Azimuth"))
-            azi_new = azi_org + float(args["add_azimuth"])
-            if azi_new > 360.0: azi_new -= 360
-            element_fol.set("Azimuth", str(azi_new))
-        element_point = element_fol.find("{"+self.gml+"}Point")
-        element_coords = element_point.find("{"+self.gml+"}coordinates")
-        [x_coord, y_coord] = element_coords.text.split(",")
-        [x_coord, y_coord] = [float(x_coord), float(y_coord)]
-        if "x_coord" in args:
-            x_coord = float(args["x_coord"])
-        if "y_coord" in args:
-            y_coord = float(args["y_coord"])
-        if "add_x_coord" in args:
-            x_coord = x_coord + float(args["add_x_coord"])
-        if "add_y_coord" in args:
-            y_coord = y_coord + float(args["add_y_coord"])
-        element_coords.text = "%f,%f" % (x_coord, y_coord)
-        return None
-
-    def twt_to_depth(self, sec_element, formula, **args):
-        """Convert all data within a section from twt to depth (including
-        orientation data!!
-        Input: section element with data points, conversion function as
-        string with 't' as placeholder for twt-time, e.g. '2 * (-t) ** 2 + 18 * (-t)'
-        ATTENTION: check if t negative
-        optional arguments:
-        change_dip (boolean) : change dip angle in foliation data
-        according to first derivative of twt-to-depth formula
-        create_plot (boolean) : create summary plot with twt and converted depth
-        for conversion formula control
-        """
-        # Idea: stoachstic apporach to twt -> depth conversion: apply several
-        # possible formulae for quality estimation of resulting model?
-        struct_data = sec_element.find("{"+self.xmlns+"}Structural2DData")
-        surface_points = struct_data.find("{"+self.xmlns+"}SurfacePoints").findall("{"+self.xmlns+"}Interface")
-        # save data in list to create a plot to check validity of conversion
-        t_list = []
-        v_list = []
-        for interface in surface_points:
-            gml_coords_element = interface.find("{"+self.gml+"}LineString").find("{"+self.gml+"}coordinates")
-            # check for correct decimal, column (cs) and text separator (ts)
-            ts = gml_coords_element.get("ts")
-            cs = gml_coords_element.get("cs")
-            data_array = gml_coords_element.text.split(ts)
-            # check if last entry is empty (seems to happen often), if so: delete!
-            # print gml_coords_element.text
-            if data_array[-1] == "": del data_array[-1]
-            text_new = ""
-            # apply conversion formula for z-direction, i.e. dv;
-            # no change in x-direction -> du = 0 (but: maybe neccessary for specific situations?)
-            for entry in data_array:
-                parts = entry.split(cs)
-                # get original values
-                # t as varibale, as defined in formula (input)
-                t = float(parts[1])
-                v_new = eval(formula)
-                du = 0
-                text_new += "%f%s%f%s" % (float(parts[0])+du, cs, v_new, ts)
-                # append to list for check-plot
-                t_list.append(-t)
-                v_list.append(v_new)
-            # print text_new
-            gml_coords_element.text = text_new
-            # print gml_coords_element.text
-        # now change foliation position and dip angle! (check: given as argument?)
-        # for dip angle: numerical determination of first derivative for
-        # twt to depth conversion formula?
-        if "change_dip" in args and args["change_dip"]:
-            print ("change dip in seismic profile")
-
-        # create check-plot
-        if "create_plot" in args and args["create_plot"]:
-            print ("Create plot with twt, converted depth pairs")
-            plot(t_list,v_list,'.', label = formula)
-            title("TWT to depth: Converted data points\nSection: " + sec_element.get("Name"))
-            xlabel("TWT [ms]")
-            ylabel("Converted depth [m]")
-            legend()
-            grid(True)
-            show()
-
-    def get_pole_points(self, element):
-        # function to plot data points in geomodeller element
-        u = []
-        v = []
-        poles = element.getiterator("{"+self.xmlns+"}Pole-Weight")
-        for pole in poles:
-            u.append(pole.get("U"))
-            v.append(pole.get("V"))
-
-        return (u,v)
-
-    def plot_points(self, element):
-        # plot u,v points in simple 2D plot
-        (u,v) = self.get_pole_points(element)
-        plot(u,v,'o')
-        name = element.get("Name")
-        title(name)
-        savefig(name+"_points.png")
-
-    def write_xml(self, save_dir, **args):
-        """Write elementtree to xml-file
-        arguments:
-        print_path: Print the path where the xml is created"""
-        # to do: filename (and directory?) as optional argument"""
-        # flo, 10/2008
-        #file = "changed_model.xml"
-        tree_new = ET.ElementTree(self.rootelement)
-        if "print_path" in args:
-            print(("Write tree to file " + save_dir))
-        tree_new.write(save_dir)
-        #self.tree.write("changed_model.xml")
-        self.tree.write(save_dir)
-
-    def add_to_project_name(self, s):
-        """add string s to project name, e.g. Number of uncertainty run"""
-        name = self.rootelement.get("projectName")
-        name_new = name + " " + s
-        self.rootelement.set("projectName",name_new)
-
-    def create_TOUGH_formation_names(self, **kwds):
-        """create formation names that are compatible with format required by TOUGH,
-        i.e. String of length 5
-        returns and stores as dictionary with Geomodeller Names as key and TOUGH names as entry
-        (self.tough_formation_names)
-        simply cuts original formation name to a name length of 5;
-        if cut name already exists: create new name, three first string values followed by two integers
-        that are subsequently increased
-        optional keywods:
-        out = string : set out formation to this name (for TOUGH2: no leading spaces allowed! set to 5 chars!)
-        """
-        # import str
-        self.tough_formation_names = {}
-        # check if self.formation_names list already exists, if not: create
-        try: self.formation_names
-        except AttributeError:
-            self.formation_names = self.get_stratigraphy_list(**kwds)
-        # create list with tough names to check if name already exists
-        tough_name_list = []
-        for i,name in enumerate(self.formation_names):
-            #    if self.formation_names[i] == '  out' or self.formation_names[i] == '  OUT':
-            #   tough_name_list.append("OUT  ")
-            #   continue
-            cut_name = self.formation_names[i][0:5]
-            if cut_name in tough_name_list:
-                for j in range(100):
-                    if "%3s%02d" % (cut_name[0:3],j) in tough_name_list:
-                        continue
-                    else:
-                        cut_name = "%3s%02d" % (cut_name[0:3],j)
-                        tough_name_list.append(cut_name)
-                        break
-            else:
-                tough_name_list.append(cut_name)
-            self.tough_formation_names[name] = "%5s" % str.upper(cut_name)
-        return self.tough_formation_names
-
-
-if __name__ == '__main__':
-    print ("main")
+"""Class definition for GeoModeller XML-Files
+This version includes drillholes
+Specific methods are defined for the uncertainty analysis (in combination
+with Uncertainty_Obj module)
+
+(c) J. Florian Wellmann, 2009-2013
+"""
+
+# try:
+#     import elementtree.ElementTree as ET
+# except ImportError:
+#     try:
+#         import etree.ElementTree as ET
+#     except ImportError:
+#         try:
+#             import xml.etree.ElementTree as ET
+#         except ImportError:
+#             import ElementTree as ET
+# import Latex_output_5 as LO
+from pylab import *
+import copy
+import pandas as pn
+import gempy as gp
+import numpy as np
+
+# python module to wrap GeoModeller XML file and perform all kinds of data
+# procedures, e.g.:
+# - Stochastic data modeling
+# - TWT to depth conversion
+# - Documentation module
+#
+# To Do:
+# - exception handling and passing
+# - log file?
+# - check validity of xml-code, test, if past-processing with sax neccessary?
+# - implement auto-documentation
+# - clear-up spaghetti code!!!!! Check dependencies and other modules
+#    to get a consistent lay-out
+
+try:
+    import xml.etree.cElementTree as ET
+except ImportError:
+    import xml.etree.ElementTree as ET
+
+# TODO fix this function and importing it to gempy.utils.create_from_geomodeller_xml
+def create_from_geomodeller_xml(fp, resolution=(50, 50, 50), return_xml=False, **kwargs):
+    """
+    EXPERIMENTAL
+    Creates InputData object from a GeoModeller xml file. Automatically extracts and sets model extent, interface
+    and orientation data as well as the stratigraphic pile.
+
+    Args:
+        fp (str): Filepath for the GeoModeller xml file to be read.
+        resolution (tuple, optional): Tuple containing the number of voxels in dimensions (x,y,z). Defaults to 50.
+        return_xml (bool, optional): Toggles returning the ReadGeoModellerXML instance to leverage further info from the
+            xml file (e.g. for stratigraphic pile ordering). Defaults to True.
+        **kwargs: Keyword arguments for create_data function.
+
+    Returns:
+        gp.data_management.InputData
+    """
+    gmx = _ReadGeoModellerXML(fp)  # instantiate parser class with filepath of xml
+
+    # instantiate InputData object with extent and resolution
+    geo_data = create_data(gmx.extent, resolution, **kwargs)
+
+    # set interface and orientation dataframes
+    geo_data._surface_points = gmx._surface_points
+    geo_data._orientations = gmx._orientations
+
+    if return_xml:
+        return geo_data, gmx
+    else:
+        return geo_data
+
+
+
+class ReadGeoModellerXML:
+    def __init__(self, fp):
+        """
+        Reads in and parses a GeoModeller XML file to extract interface and orientation data and the overall model
+        settings (e.g. extent and sequential pile). It uses ElementTree to parse the XML and the tree's root can
+        be accessed using self.root for more direct access to the file.
+
+        Args:
+            fp (str): Filepath for the GeoModeller xml file to be read.
+
+        """
+        self.tree = ET.ElementTree(file=fp)  # load xml as tree
+        self.root = self.tree.getroot()
+
+        self.xmlns = "http://www.geomodeller.com/geo"
+        self.gml = "http://www.opengis.net/gml"
+
+        self.extent = self._get_extent()
+
+        self.data = self.extract_data()
+        self.surface_points, self.orientations = self.get_dataframes()
+
+        # self.stratigraphic_column = self.get_stratigraphic_column()
+        # self.df = self.get_faults()
+        #
+        # self.series_info = self._get_series_fmt_dict()
+        # self.series_distribution = self.get_series_distribution()
+        #
+        # self.fault_matrix = self.get_fault_matrix()
+
+    def get_psc(self):
+        """Returns the ProjectStratigraphicColumn tree element used for several data extractions."""
+        return self.root.find("{" + self.xmlns + "}GeologicalModel").find("{"+self.xmlns+"}ProjectStratigraphicColumn")
+
+    def extract_data(self):
+        """
+        Extracts relevant data from the GeoModeller XML file ElementTree root (self.root) and returns it as a dictionary.
+
+
+        Returns:
+            (dict): Data dictionary
+        """
+        data = {}
+        for s in self.get_psc():
+            sn = s.get("name")
+            data[sn] = {}  # create a dict for each series
+            data[sn]["formations"] = []
+            data[sn]["InfluencedByFault"] = []
+            data[sn]["relation"] = s.get("relation")  # add relation, whatever that is
+
+            for c in s:
+                if c.tag == "{"+self.xmlns+"}Data":  # append formation names to list of formations
+                    data[sn]["formations"].append(c.get("Name"))
+
+                if c.tag == "{"+self.xmlns+"}InfluencedByFault":  # add fault influences
+                    data[sn]["InfluencedByFault"].append(c.get("Name"))
+
+                if c.tag == "{"+self.xmlns+"}PotentialField":
+
+                    data[sn]["gradients"] = []
+                    data[sn]["surface_points"] = []
+                    data[sn]["surface_points_counters"] = []
+                    data[sn]["solutions"] = []
+                    data[sn]["constraints"] = []
+
+                    for cc in c:
+                        # COVARIANCE
+                        if cc.tag == "{" + self.xmlns + "}covariance":
+                            data[sn]["covariance"] = cc.attrib
+
+                        # GRADIENTS
+                        if cc.tag == "{" + self.xmlns + "}Gradients":
+                            for gr in cc:
+                                data[sn]["gradients"].append([gr.get("Gx"), gr.get("Gy"), gr.get("Gz"),
+                                                              gr.get("XGr"), gr.get("YGr"), gr.get("ZGr")])
+
+                        # surface_points
+                        if cc.tag == "{" + self.xmlns + "}Points":
+                            for co in cc:
+                                data[sn]["surface_points"].append([float(co[0].text), float(co[1].text), float(co[2].text)])
+
+                        # INTERFACE COUNTERS
+                        if cc.tag == "{" + self.xmlns + "}InterfacePoints":
+                            for ip in cc:
+                                data[sn]["surface_points_counters"].append([int(ip.get("npnt")), int(ip.get("pnt"))])
+
+                        # CONSTRAINTS
+                        if cc.tag == "{" + self.xmlns + "}Constraints":
+                            for co in cc:
+                                data[sn]["constraints"].append(float(co.get("value")))
+
+                        # SOLUTIONS
+                        if cc.tag == "{" + self.xmlns + "}Solutions":
+                            for sol in cc:
+                                data[sn]["solutions"].append(float(sol.get("sol")))
+
+                    # convert from str to float
+                    data[sn]["gradients"] = np.array(data[sn]["gradients"]).astype(float)
+                    data[sn]["surface_points"] = np.array(data[sn]["surface_points"]).astype(float)
+                    data[sn]["surface_points_counters"] = np.array(data[sn]["surface_points_counters"]).astype(float)
+                    data[sn]["solutions"] = np.array(data[sn]["solutions"]).astype(float)
+
+        return data
+
+    def get_dataframes(self):
+        """
+        Extracts dataframe information from the self.data dictionary and returns GemPy-compatible surface_points and
+        orientations dataframes.
+
+        Returns:
+            (tuple) of GemPy dataframes (surface_points, orientations)
+        """
+        interf_formation = []
+        interf_series = []
+
+        orient_series = []
+
+        for i, s in enumerate(self.data.keys()):  # loop over all series
+            if i == 0:
+                coords = self.data[s]["surface_points"]
+                grads = self.data[s]["gradients"]
+            else:
+                coords = np.append(coords, self.data[s]["surface_points"])
+                grads = np.append(grads, self.data[s]["gradients"])
+
+            for j, fmt in enumerate(self.data[s]["formations"]):
+                for n in range(int(self.data[s]["surface_points_counters"][j, 0])):
+                    interf_formation.append(fmt)
+                    interf_series.append(s)
+
+            for k in range(len(grads)):
+                orient_series.append(s)
+
+        surface_points = pn.DataFrame(coords, columns=['X', 'Y', 'Z'])
+        surface_points["formation"] = interf_formation
+        surface_points["series"] = interf_series
+
+        orientations = pn.DataFrame(grads, columns=['G_x', 'G_y', 'G_z', 'X', 'Y', 'Z'])
+        orientations["series"] = orient_series
+
+        dips = []
+        azs = []
+        pols = []
+        for i, row in orientations.iterrows():
+            dip, az, pol = gp.data_management.get_orientation((row["G_x"], row["G_y"], row["G_z"]))
+            dips.append(dip)
+            azs.append(az)
+            pols.append(pol)
+
+        orientations["dip"] = dips
+        orientations["azimuth"] = azs
+        orientations["polarity"] = pols
+
+        return surface_points, orientations
+
+
+    def get_stratigraphic_column(self):
+        """
+        Extracts series names from ElementTree root.
+
+        Returns:
+            tuple: Series names (str) in stratigraphic order.
+        """
+        stratigraphic_column = []
+        for s in self.get_psc():
+            stratigraphic_column.append(s.get("name"))
+        return tuple(stratigraphic_column)
+
+    def get_order_formations(self):
+        order_formations = []
+        for entry in self.series_distribution.values():
+            if type(entry) is str:
+                order_formations.append(entry)
+            elif type(entry) is tuple:
+                for e in entry:
+                    order_formations.append(e)
+
+        return order_formations
+
+    def get_faults(self):
+        """
+        Extracts fault names from ElementTree root.
+
+        Returns:
+            tuple: Fault names (str) ordered as in the GeoModeller XML.
+        """
+        faults = []
+        for c in self.root[2]:
+            faults.append(c.get("Name"))
+        return tuple(faults)
+
+    def get_series_distribution(self):
+        """
+        Combines df and stratigraphic series into an unordered dictionary as keys and maps the correct
+        formations to them as a list value. Faults series get a list of their own string assigned as formation.
+
+        Returns:
+            (dict): maps Series (str) -> Surfaces (list of str)
+        """
+        series_distribution = {}
+        for key in self.series_info.keys():
+            fmts = self.series_info[key]["formations"]
+            if len(fmts) == 1:
+                series_distribution[key] = fmts[0]
+            else:
+                series_distribution[key] = tuple(fmts)
+
+        for f in self.stratigraphic_column:
+            if "Fault" in f or "fault" in f:
+                series_distribution[f] = f
+
+        return series_distribution
+
+    def _get_extent(self):
+        """
+        Extracts model extent from ElementTree root and returns it as tuple of floats.
+
+        Returns:
+            tuple: Model extent as (xmin, xmax, ymin, ymax, zmin, zmax).
+        """
+        xy = self.root[0][0][0][0].attrib
+        z = self.root[0][0][0][1].attrib
+        return tuple(np.array([xy["Xmin"], xy["Xmax"],
+                               xy["Ymin"], xy["Ymax"],
+                                z["Zmin"],  z["Zmax"]]).astype(float))
+
+    def get_surface_points_df(self):
+        """
+        Extracts the interface data points stored in the GeoModeller xml file and returns it as a GemPy surface_points
+        dataframe.
+
+        Returns:
+            pandas.DataFrame: InputData.surface_points dataframe
+        """
+        if self.root.find("{" + self.xmlns + "}Structural3DData") is None:
+            print("No 3D data stored in given xml file.")
+            return None
+        else:
+            fmts = [c.attrib["Name"] for c in self.root.find("{" + self.xmlns + "}Structural3DData")[0]]  # use formations
+            xyzf = []
+
+            for i, fmt in enumerate(fmts):  # loop over all formations
+                for p in self.root[5][0][i]:  # loop over every point
+                    entry = p[0].text.split(",")  # split the string by its seperator into coord strings
+                    entry.append(fmt)
+
+                    for s in self.series_info.keys():
+                        if fmt in self.series_info[s]["formations"]:
+                            series = s
+                        else:
+                            series = fmt
+
+                    entry.append(series)
+                    xyzf.append(entry)
+
+            surface_points = pn.DataFrame(np.array(xyzf), columns=['X', 'Y', 'Z', "formation", "series"])
+            surface_points[["X", "Y", "Z"]] = surface_points[["X", "Y", "Z"]].astype(float)
+            return surface_points
+
+    def get_orientation_df(self):
+        """
+        Extracts the orientation data points sotred in the GeoModeller xml file and returns it as a GemPy
+        orientations dataframe.
+
+        Returns:
+            pandas.DataFrame: InputData.orientations dataframe
+        """
+        if self.root.find("{" + self.xmlns + "}Structural3DData") is None:
+            print("No 3D data stored in given xml file.")
+            return None
+        else:
+            fol = []
+            for i, s in enumerate(self.root.find("{" + self.xmlns + "}Structural3DData")[1]):
+                for c in self.root.find("{" + self.xmlns + "}Structural3DData")[1][i]:
+                    entry = c[0][0].text.split(",")
+                    entry.append(c.get("Dip"))
+                    entry.append(c.get("Azimuth"))
+                    # correct polarity from bool str to int
+                    pol = c.get("NormalPolarity")
+                    if pol == "true":
+                        entry.append(1)
+                    else:
+                        entry.append(-1)
+                    entry.append(s.get("Name"))
+                    for series in self.series_distribution.keys():
+                        if s.get("Name") in self.series_distribution[series]:
+                            entry.append(series)
+
+                    fol.append(entry)
+
+            orientations = pn.DataFrame(np.array(fol), columns=['X', 'Y', 'Z', 'dip', 'azimuth', 'polarity', 'formation', 'series'])
+            orientations[["X", "Y", "Z", "dip", "azimuth"]] = orientations[["X", "Y", "Z", "dip", "azimuth"]].astype(float)
+            orientations["polarity"] = orientations["polarity"].astype(int)
+
+            return orientations
+
+    def _get_series_fmt_dict(self):
+        sp = {}
+        for i, s in enumerate(self.stratigraphic_column):  # loop over all series
+            fmts = []  # init formation storage list
+            influenced_by = []  # init influenced by list
+            for c in self.root.find("{" + self.xmlns + "}GeologicalModel").find("{"+self.xmlns+"}ProjectStratigraphicColumn")[i]:
+                if "Data" in c.tag:
+                    fmts.append(c.attrib["Name"])
+                elif "InfluencedByFault" in c.tag:
+                    influenced_by.append(c.attrib["Name"])
+            # print(fmts)
+            sp[s] = {}
+            sp[s]["formations"] = fmts
+            sp[s]["InfluencedByFault"] = influenced_by
+
+        return sp
+
+    def _where_do_faults_stop(self):
+        fstop = {}
+        for i, f in enumerate(self.root[2]):
+
+            stops_on = []
+            for c in self.root[2][i][2:]:
+                stops_on.append(c.get("Name"))
+
+            fstop[f.get("Name")] = stops_on
+
+        return fstop
+
+    def get_fault_matrix(self):
+        nf = len(self.faults)
+        fm = np.zeros((nf, nf))  # zero matrix of n_faults²
+        fstop = self._where_do_faults_stop()
+        for i, f in enumerate(self.faults):
+            for fs in fstop[f]:
+                j = np.where(np.array(self.faults) == fs)[0][0]
+                fm[i, j] = 1
+
+        return fm
+
+
+# TODO think where this function should go
+def read_vox(geo_data, path):
+    """
+    read vox from geomodeller and transform it to gempy format
+    Returns:
+        numpy.array: block model
+    """
+    import pandas as pn
+    geo_res = pn.read_csv(path)
+
+    geo_res = geo_res.iloc[9:]
+
+    # ip_addresses = geo_res['nx 50'].unique()  # geo_model.surface_points["formation"].unique()
+    ip_dict = geo_data.get_formation_number()
+  #  ip_dict = geo_model.surface_points['formation_number'].unique()
+
+    geo_res_num = geo_res.iloc[:, 0].replace(ip_dict)
+    block_geomodeller = np.ravel(geo_res_num.values.reshape(
+        geo_data.resolution[0], geo_data.resolution[1], geo_data.resolution[2], order='C').T)
+    return block_geomodeller
+
+
+class GeomodellerClass:
+    """Wrapper for GeoModeller XML-datafiles to perform all kinds of data
+    manipulation and analysis on low level basis, e.g.:
+    - Uncertainty Simulation
+    - TWT to depth conversion
+    - Data analysis, e.g. Auto-documentation"""
+
+    def __init__(self):
+        """Wrapper for GeoModeller XML-datafiles to perform all kinds of data
+    manipulation and analysis on low level basis, e.g.:
+    - Uncertainty Simulation
+    - TWT to depth conversion
+    - Data analysis, e.g. Auto-documentation"""
+
+    def load_geomodeller_file(self, xml_file):
+        self.xml_file_name = xml_file
+        try:
+            tree = ET.parse(xml_file)
+        except IOError:
+            print(("Can not open xml File " + xml_file + ": " + string_err))
+            print ("Please check file name and directory and try again")
+            raise IOError
+        # safe tree on local varibale
+        self.tree = tree
+        # get rootelement
+        self.rootelement = tree.getroot()
+        # set other class variables
+        self.xmlns = "http://www.geomodeller.com/geo"
+        self.gml = "http://www.opengis.net/gml"
+
+    def load_deepcopy_tree(self, deepcopy_tree):
+        """load tree information from deepcopied tree into object"""
+        self.tree = deepcopy_tree
+        self.rootelement = deepcopy_tree.getroot()
+        # set other class variables
+        self.xmlns = "http://www.geomodeller.com/geo"
+        self.gml = "http://www.opengis.net/gml"
+
+    def deepcopy_tree(self):
+        """create a deep copy of original tree to restore later, e.g. for uncertainty evaluation"""
+
+        deepcopy_tree = copy.deepcopy(self.tree)
+        deepcopy_tree.parent = None
+        return deepcopy_tree
+
+    def reload_geomodeller_file(self, deepcopy_tree):
+        """restore original tree root from deep copy of orignial tree
+        deep copy can be created (not automatically to save memory!) with
+        self.deepcopy_tree()
+        """
+        try:
+            self.tree = deepcopy_tree
+            self.rootelement = self.tree.getroot()
+        except NameError:
+            print ("No deep copy of original tree available, please create with self.deepcopy_tree()")
+
+    def get_model_extent(self):
+        """get extent of model
+        returns (x_min, x_max, y_min, y_max, z_min, z_max)
+        and saves extent in self.x_min, self.x_max, etc.
+        """
+        extent_parent = self.rootelement.find("{"+self.xmlns+"}Extent3DOfProject")
+        extentbox3D = extent_parent.find("{"+self.xmlns+"}ExtentBox3D")
+        extent3D = extentbox3D.find("{"+self.xmlns+"}Extent3D")
+        extent_xy = extent3D.find("{"+self.xmlns+"}ExtentXY")
+        extent_z = extent3D.find("{"+self.xmlns+"}ExtentZ")
+        self.x_min = float(extent_xy.get("Xmin"))
+        self.x_max = float(extent_xy.get("Xmax"))
+        self.y_min = float(extent_xy.get("Ymin"))
+        self.y_max = float(extent_xy.get("Ymax"))
+        self.z_min = float(extent_z.get("Zmin"))
+        self.z_max = float(extent_z.get("Zmax"))
+        return (self.x_min, self.x_max, self.y_min, self.y_max, self.z_min, self.z_max)
+
+    # def get_model_range(self):
+    #     """get model range from model extent, e.g. for automatic mesh generation"""
+    #     (x_min, x_max, y_min, y_max, z_min, z_max) = self.get_model_extent()
+    #     from numpy import abs
+    #     self.range_x = abs(x_max - x_min)
+    #     self.range_y = abs(y_max - y_min)
+    #     self.range_z = abs(z_max - z_min)
+    #     return (self.range_x, self.range_y, self.range_z)
+
+    def get_sections(self):
+        """get sections out of rootelement, safe array with section elements
+        in local variable"""
+        sections_parent = self.rootelement.findall("{"+self.xmlns+"}Sections")[0]
+        self.sections = sections_parent.findall("{"+self.xmlns+"}Section")
+        return self.sections
+
+    def get_faults(self):
+        """get fault elements out of rootelement and safe as local list"""
+        try:
+            faults_parent = self.rootelement.findall("{"+self.xmlns+"}Faults")[0]
+            self.faults = faults_parent.findall("{"+self.xmlns+"}Fault")
+        except IndexError:
+            print("No df found in model")
+        return self.faults
+
+    def get_formations(self):
+        """get formation elements out of rootelement and safe as local list"""
+        formations_parent = self.rootelement.findall("{"+self.xmlns+"}Surfaces")[0]
+        self.formations = formations_parent.findall("{"+self.xmlns+"}Formation")
+
+    def get_stratigraphy_list(self, **kwds):
+        """get project stratigraphy and return as list; lowermost formation: 1
+        for GeoModeller dll access (this ist the formation_number that is returned with
+        the GetComputedLithologyXYZ function in the geomodeller dll
+        optional keywords:
+        out = string : set 'out' formation to this name (might be necessary for TOUGH2 simulation!)
+        """
+        series_list = []
+        strati_column = self.rootelement.find("{"+self.xmlns+"}GeologicalModel").find("{"+self.xmlns+"}ProjectStratigraphicColumn")#.findall("{"+self.xmlns+"Series")
+        series = strati_column.findall("{"+self.xmlns+"}Series")
+        for s in series:
+            data = s.findall("{"+self.xmlns+"}Data")
+            for d in data:
+                series_list.append(d.get("Name"))
+        # append "out" as uppermost formation for "out values
+        if "tough2" in kwds:
+            if 'out' in kwds:
+                series_list.append(kwds['out'])
+            else:
+                series_list.append("out")
+        self.stratigraphy_list = series_list
+        return series_list
+
+    def get_section_names(self):
+        """get all section names out of local variable self.sections"""
+        # todo: return section names as dictionary with element and name?
+        # test if self.sections defined, if not -> create
+        try:
+            self.sections
+        except AttributeError:
+            # print "Create sections Data array"
+            self.get_sections()
+        section_names = []
+        for section in self.sections:
+            section_names.append(section.get("Name"))
+        return section_names
+
+    def get_formation_names(self):
+        """get formation names and return as list"""
+        forms=[]
+        try:
+            self.formations
+        except AttributeError:
+            self.get_formations()
+        for formation in self.formations:
+            forms.append(formation.get("Name"))
+        return forms
+
+    def get_fault_names(self):
+        """get fault names and return as list"""
+        faults_list=[]
+        try:
+            self.faults
+        except AttributeError:
+            self.get_faults()
+        for fault in self.faults:
+            faults_list.append(fault.get("Name"))
+        return faults_list
+
+    def get_points_in_sections(self):
+        """Create dictionary of all points (with obs-id) in all sections"""
+        self.create_sections_dict()
+        for sec in list(self.section_dict.keys()):
+            forms = self.get_formation_point_data(self.section_dict[sec])
+            if forms == None:
+                print ("\t\t\tNo Formation Points in this section")
+            else:
+                for form in forms:
+                    #print form.get("ObservationID")
+                #    if form.get("ObservationID") == None: continue
+                    data = form.find("{"+self.xmlns+"}Data")
+                    print(("\nObsID = %s" % form.get("ObservationID")))
+                    print(("\tFormation name\t= %s" % data.get("Name")))
+                    element_point = form.find("{"+self.gml+"}LineString")
+                    element_coords = element_point.find("{"+self.gml+"}coordinates")
+                    tmp = element_coords.text.split(" ")
+                    for tmp1 in tmp:
+                        if tmp1 == '': continue
+                        tmp_cds = tmp1.split(",")
+                        print(("\tX = %.1f, Y = %.1f" % (float(tmp_cds[0]), float(tmp_cds[1]))))
+
+
+                    fol = form.find("{"+self.xmlns+"}FoliationObservation")
+                    if fol is not None:
+                        print(("\tFoliation defined: azimuth = %.1f, dip = %.1f" % (float(fol.get("Azimuth")), float(fol.get("Dip")))))
+                        # get position of foliation (yet another point)
+                        pt = fol.find("{"+self.gml+"}Point")
+                        c = pt.find("{"+self.gml+"}coordinates")
+                        cds = c.text.split(",")
+                        print(("\t\tX = %.1f, Y = %.1f" % (float(cds[0]), float(cds[1]))))
+
+            print ("\n")
+            print((80*"-"))
+            print(("Foliations in section %s:" % sec))
+            print((80*"-"))
+            foliations = self.get_foliations(self.section_dict[sec])
+            if foliations == None:
+                print ("\t\t\tNo foliations in this section")
+            else:
+                for fol1 in foliations:
+                    print(("\nObsID = %s" % fol1.get("ObservationID")))
+                    data = fol1.find("{"+self.xmlns+"}Data")
+                    fol = fol1.find("{"+self.xmlns+"}FoliationObservation")
+                    print(( "\tFormation name\t= %s" % data.get("Name")))
+                    print(("\tAzimuth = %.1f, dip = %.1f" % (float(fol.get("Azimuth")), float(fol.get("Dip")))))
+                    pt = fol.find("{"+self.gml+"}Point")
+                    c = pt.find("{"+self.gml+"}coordinates")
+                    cds = c.text.split(",")
+                    print(("\tX = %.1f, Y = %.1f" % (float(cds[0]), float(cds[1]))))
+        return
+
+    def get_formation_parameters(self):
+        """read formation parameters; physical
+        properties, density, th. cond etc... store in dict"""
+        #
+        # To do: re-write in a more elegant way and keep original
+        # structure and key-words?
+        #
+        self.formation_params = {}
+        try:
+            self.formations
+        except AttributeError:
+            #            print "Create sections Data array"
+            self.get_formations()
+        for formation in self.formations:
+            self.formation_params[formation.get("Name")] = {}
+            geophys = formation.find("{"+self.xmlns+"}Geophysics")
+            dens = geophys.find("{"+self.xmlns+"}DensityCompoundDistribution")
+            dens_simple = dens.find("{"+self.xmlns+"}SimpleDistribution")
+            self.formation_params[formation.get("Name")]["dens_mean"] = dens_simple.get("Mean")
+            self.formation_params[formation.get("Name")]["dens_law"] = dens_simple.get("LawType")
+            self.formation_params[formation.get("Name")]["dens_dev"] = dens_simple.get("Deviation")
+            #             print geophys.getchildren()
+            mag = geophys.find("{"+self.xmlns+"}RemanantMagnetizationCompoundDistribution")
+            mag_simple = mag.find("{"+self.xmlns+"}SimpleDistributionVector")
+            self.formation_params[formation.get("Name")]["mag"] = mag_simple.get("Mean")
+            velocity = geophys.find("{"+self.xmlns+"}VelocityCompoundDistribution")
+            velocity_simple = velocity.find("{"+self.xmlns+"}SimpleDistribution")
+            self.formation_params[formation.get("Name")]["vel_mean"] = velocity_simple.get("Mean")
+            self.formation_params[formation.get("Name")]["vel_law"] = velocity_simple.get("LawType")
+            self.formation_params[formation.get("Name")]["vel_dev"] = velocity_simple.get("Deviation")
+            # Thermal properties are only defined in newer versions of GeoModeller! thus check!
+
+            th_cond = geophys.find("{"+self.xmlns+"}ThermalConductivityCompoundDistribution")
+            if th_cond == None: continue
+            th_cond_simple = th_cond.find("{"+self.xmlns+"}SimpleDistribution")
+            self.formation_params[formation.get("Name")]["th_cond_mean"] = th_cond_simple.get("Mean")
+            self.formation_params[formation.get("Name")]["th_cond_law"] = th_cond_simple.get("LawType")
+            self.formation_params[formation.get("Name")]["th_cond_dev"] = th_cond_simple.get("Deviation")
+            heat_prod = geophys.find("{"+self.xmlns+"}HeatProductionRateCompoundDistribution")
+            heat_prod_simple = heat_prod.find("{"+self.xmlns+"}SimpleDistribution")
+            self.formation_params[formation.get("Name")]["heat_prod_mean"] = heat_prod_simple.get("Mean")
+            self.formation_params[formation.get("Name")]["heat_prod_law"] = heat_prod_simple.get("LawType")
+            self.formation_params[formation.get("Name")]["heat_prod_dev"] = heat_prod_simple.get("Deviation")
+
+            # same for other properties
+        #    print th_cond
+            #
+            # !!! only simple distributions yet impl.
+            #
+
+    def create_fault_dict(self):
+        """create dictionary for fault elements with names as keys"""
+        # test if self.formations defined, if not -> create
+        try:
+            self.faults
+        except AttributeError:
+            print ("Create Surfaces list")
+            self.get_faults()
+        self.fault_dict = {}
+        for fault in self.faults:
+            self.fault_dict[fault.get("Name")] = fault
+        return self.fault_dict
+
+    def create_formation_dict(self):
+        """create dictionary for formation elements with formation names as keys"""
+        # test if self.formations defined, if not -> create
+        try:
+            self.formations
+        except AttributeError:
+            print ("Create formation dictionary")
+            self.get_formations()
+        self.formation_dict = {}
+        for formation in self.formations:
+            self.formation_dict[formation.get("Name")] = formation
+        return self.formation_dict
+
+    def create_sections_dict(self):
+        """create dictionary for section elements with section names as keys
+        (for easier use...)"""
+        # test if self.sections defined, if not -> create
+        try:
+            self.sections
+        except AttributeError:
+            # print "Create sections dictionary"
+            self.get_sections()
+        self.section_dict = {}
+        for section in self.sections:
+            self.section_dict[section.get("Name")] = section
+        return self.section_dict
+
+    def get_foliations(self, section_element):
+        """get all foliation data elements from a for section"""
+        tmp_element = section_element.find("{"+self.xmlns+"}Structural2DData")
+        # check in case there is no foliation defined in this section
+        # tmp_element2 = tmp_element.find("{"+self.xmlns+"}Foliations")
+        try:
+            tmp_element2 = tmp_element.find("{"+self.xmlns+"}Foliations")
+        except AttributeError:
+            return None
+        try:
+            foliations = tmp_element2.findall("{"+self.xmlns+"}Foliation")
+        except AttributeError:
+            return None
+        return foliations
+
+    def get_foliation_dip(self, foliation_element):
+        """get dip of foliation element"""
+        return float(foliation_element.find("{"+self.xmlns+"}FoliationObservation").get("Dip"))
+
+    def get_foliation_azimuth(self, foliation_element):
+        """get dip of foliation element"""
+        return float(foliation_element.find("{"+self.xmlns+"}FoliationObservation").get("Azimuth"))
+
+    def get_folation_polarity(self, foliation_element):
+        """get polarity of foliation element; return true if Normal Polarity"""
+        return foliation_element.find("{"+self.xmlns+"}FoliationObservation").get("NormalPolarity")
+
+    def get_foliation_coordinates(self, foliation_element):
+        """get coordinates of foliation element"""
+        element_fol = foliation_element.find("{"+self.xmlns+"}FoliationObservation")
+        element_point = element_fol.find("{"+self.gml+"}Point")
+        element_coords = element_point.find("{"+self.gml+"}coordinates")
+        return str(element_coords.text)
+
+    def get_formation_data(self, section_element):
+        """not used any more! use get_formation_point_data(section_element) instead"""
+        print ("not used any more! use get_formation_point_data(section_element) instead")
+        return None
+
+    def get_formation_point_data(self, section_element):
+        """get all formation point data elements from a for section"""
+        tmp_element = section_element.find("{"+self.xmlns+"}Structural2DData")
+        # check in case there is no formation points defined in this section
+        try:
+            tmp_element2 = tmp_element.find("{"+self.xmlns+"}SurfacePoints")
+        except AttributeError:
+            return None
+        return tmp_element2.findall("{"+self.xmlns+"}Interface")
+
+    def get_name(self, section_element):
+        """get the name of any section element (if defined)"""
+        return section_element.find("{"+self.xmlns+"}Name")
+
+    def get_interface_name(self, interface_element):
+        """get name of interface, i.e. the formation"""
+        return interface_element.find("{"+self.xmlns+"}Data").get("Name")
+
+    def get_point_coordinates(self, point_elements, **args):
+        """get the coordinates of a specific point memory locations"""
+        point_list = list()
+
+        for element in point_elements:
+          name = element.find("{"+self.xmlns+"}Data").get("Name")
+          #if args.has_key("if_name"):
+          if "if_name" in args:
+            if args["if_name"] != name: continue
+          element_point = element.find("{"+self.gml+"}LineString")
+          element_coords = element_point.find("{"+self.gml+"}coordinates")
+          point_list.append((name+ " " + str(element_coords.text)))
+        return point_list
+
+    def change_formation_values_PyMC(self, **args):
+        """ -So far is ready only to changes points in coordinates y. It is not difficult to add a new
+        dimension
+
+            - The dips and azimuth ObservationID must contain _d or _a respectively"""
+
+        if "info" in args:
+            section_dict = self.create_sections_dict()
+            contact_points_dict = {}
+            foliation_dict = {}
+            for i in range(len(section_dict)):
+                print(("\n\n\n", list(section_dict.keys())[i], "\n"))
+                print ("Elements and their ID \n")
+                contact_points = self.get_formation_point_data(list(section_dict.values())[i])
+
+                try:
+                    for contact_point in contact_points:
+                        contact_points_dict[contact_point.get("ObservationID")] = contact_point
+                        print((contact_point, contact_point.get("ObservationID")))
+                except TypeError:
+                    print ("No contact points in the section")
+                #ObsID = contact_points.get("ObservationID")
+                foliations = self.get_foliations(list(section_dict.values())[i])
+                try:
+                    for foliation in foliations:
+                        # dictionary to access with azimth name
+                        foliation_dict[foliation.get("ObservationID")+"_a"] = foliation
+                        # dictionary to access with dip name
+                        foliation_dict[foliation.get("ObservationID")+"_d"] = foliation
+                        print((foliation, foliation.get("ObservationID")))
+
+                except TypeError:
+                    print ("No foliation in the section")
+                try:
+                    coord_interface = self.get_point_coordinates(contact_points)
+                except TypeError:
+                    print ("Element does not have iterable objects")
+
+                print(("\nDictionaries:\n ", contact_points_dict, "\n", foliation_dict))
+
+                print(("\n Contact points", contact_points, "\n", coord_interface, "\n"))
+
+                print(("foliations" , foliations,  "\n"))
+                try:
+                    for i in range(len(foliations)):
+                        print(("azimut:",self.get_foliation_azimuth(foliations[i])))
+                        print(("dip",self.get_foliation_dip(foliations[i])))
+                        print(("coordinates", self.get_foliation_coordinates(foliations[i])))
+                except TypeError:
+                    print ("No foliation in the section")
+            return None
+        #========================
+        # change the stuff
+        #=======================
+        section_dict = self.create_sections_dict()
+        contact_points_dict = {}
+        foliation_dict = {}
+
+        #Creation of dictionaries according to the ObservationID
+        for i in range(len(section_dict)):
+            # Contact points:
+            try:
+                contact_points = self.get_formation_point_data(list(section_dict.values())[i])
+                for contact_point in contact_points:
+                    contact_points_dict[contact_point.get("ObservationID")] = contact_point
+            except TypeError:
+                continue
+            # Foliation Points
+            try:
+                foliations = self.get_foliations(list(section_dict.values())[i])
+                for foliation in foliations:
+                    # dictionary to access with azimth name
+                    foliation_dict[foliation.get("ObservationID")+"_a"] = foliation
+                    # dictionary to access with dip name
+                    foliation_dict[foliation.get("ObservationID")+"_d"] = foliation
+            except TypeError:
+                continue
+
+        # Passing our chain values:
+            # Contact_points
+        if "contact_points_mc" in args:
+            for contac_point_mc in args["contact_points_mc"]:
+                try:
+
+                    element = contact_points_dict[str(contac_point_mc)]
+                    element_point = element.find("{"+self.gml+"}LineString")
+                    element_coords = element_point.find("{"+self.gml+"}coordinates")
+                    point_list = element_coords.text.split(" ")
+                    if point_list[-1] == '':
+                        point_list = point_list[0:-1]
+
+                    if len(point_list) == 1:
+                        self.change_formation_point_pos(element, y_coord = contac_point_mc.value)
+                    #Specific case of the Graben:
+                    elif len(point_list) == 2:
+                        self.change_formation_point_pos(element, y_coord = [contac_point_mc.value, contac_point_mc.value])
+                    else:
+                        print ("The lenght of the points to change does not fit with the number of changes in the input (>2)")
+                except KeyError:
+                    print(("The name of your PyMC variables (%s) does not agree with the ObservationID in the xml. Check misspellings." % str(contac_point_mc)))
+                    continue
+            # Azimuths
+        if "azimuths_mc" in args:
+            for azimuth_mc in args["azimuths_mc"]:
+                #print azimuth_mc, type(azimuth_mc)
+                try:
+                    self.change_foliation(foliation_dict[str(azimuth_mc)], azimuth = str(azimuth_mc.value))
+                except KeyError:
+                    print(("The name of your PyMC variables (%s) does not agree with the ObservationID in the xml. Check misspellings." % str(azimuth_mc)))
+                    continue
+            # Dips
+        if "dips_mc" in args:
+            for dip_mc in args["dips_mc"]:
+                try:
+                    self.change_foliation(foliation_dict[str(dip_mc)], dip = str(dip_mc.value))
+                except KeyError:
+                    print(("The name of your PyMC variables (%s) does not agree with the ObservationID in the xml. Check misspellings." % str(dip_mc)))
+                    continue
+
+
+    # To do: vectorize this
+    def change_formation_point_pos(self, element, **args):
+        """change position of formation point in section element
+        arguments:
+        x_coord, y_coord : set to this coordinates
+        add_x_coord, add_y_coord : add values to existing coordinates
+        use if_name = and if_provenance = to add conditions!
+        print_points = bool: print the list of points that will be modified (default: False)"""
+        #    print "I am here"
+        #print_points = kwds.get('print_points', False)
+        prov = element.get("Provenance")
+
+        name = element.find("{"+self.xmlns+"}Data").get("Name")
+
+        #if args.has_key("if_name"):
+        if "if_name" in args:
+            if args["if_name"] != name: return
+        # if args.has_key("if_provenance"):
+        if "if_provenance" in args:
+            if args["if_provenance"] != prov: return
+        # element_fol = element.find("{"+self.xmlns+"}")
+        element_point = element.find("{"+self.gml+"}LineString")
+        element_coords = element_point.find("{"+self.gml+"}coordinates")
+        point_list = element_coords.text.split(" ")
+        #    print "poitn lits", point_list
+        if point_list[-1] == '':
+            point_list = point_list[0:-1]
+        if len(point_list) > 1:
+            x_coords = []
+            y_coords = []
+            if "print_points" in args:
+                print (point_list)
+            for point in point_list:
+                # if point == '': continue
+                a = point.split(',')
+                #print a
+                [x_coord, y_coord] = [float(a[0]), float(a[1])]
+                x_coords.append(x_coord)
+                y_coords.append(y_coord)
+            # convert to arrays for calculation
+            x_coords = array(x_coords)
+            y_coords = array(y_coords)
+            # Here  y_coord, and x_coord
+            if "x_coord" in args:
+                if shape(point_list) == shape(args["x_coord"]):
+                #except TypeError:
+                    x_coords = array(args["x_coord"])
+                else:
+                    print ("length of the points you want to change do not match with input dimensions")
+            if "y_coord" in args:
+                #print (args["y_coord"])
+                #print array(args["y_coord"])
+                if shape(point_list) == shape(args["y_coord"]):
+                    y_coords = array(args["y_coord"])
+                    #            print "ycoords", y_coords
+                else:
+                    print ("length of the points you want to change do not match with input dimensions")
+            #print "Coordenates", x_coords, y_coords
+            # Here add coords
+            if "add_x_coord" in args:
+                x_coords = x_coords + float(args["add_x_coord"])
+            if "add_y_coord" in args:
+                y_coords = y_coords + float(args["add_y_coord"])
+            #    print y_coords
+            # now, reconstruct output format strings
+            out_text = ''
+            for (i, x_coord) in enumerate(x_coords):
+                out_text += "%f,%f " % (x_coords[i],y_coords[i])
+            element_coords.text = out_text
+
+        else:
+            [x_coord, y_coord] = point_list[0].split(",")
+            [x_coord, y_coord] = [float(x_coord), float(y_coord)]
+            if "x_coord" in args:
+                x_coord = float(args["x_coord"])
+            if "y_coord" in args:
+                y_coord = float(args["y_coord"])
+            if "add_x_coord" in args:
+                x_coord = x_coord + float(args["add_x_coord"])
+            if "add_y_coord" in args:
+                y_coord = y_coord + float(args["add_y_coord"])
+            element_coords.text = "%f,%f" % (x_coord, y_coord)
+        return None
+
+    def change_foliation_polarity(self, element):
+        """change polarity of foliation element"""
+        if element.get("NormalPolarity") == "true":
+            element.set("NormalPolarity", "false")
+        else:
+            element.set("NormalPolarity", "true")
+
+    def change_foliation(self, element, **args):
+        """change foliation data, argument one or more of: azimuth, dip,
+        normalpolarity = true/false, x_coord, y_coord" or: add_dip, add_azimuth,
+        add_x_coord, add_y_coord to add values to existing values!
+        use if_name = and if_provenance = to add conditions!"""
+        prov = element.get("Provenance")
+        name = element.find("{"+self.xmlns+"}Data").get("Name")
+        if "if_name" in args:
+            if args["if_name"] != name: return
+        if "if_provenance" in args:
+            if args["if_provenance"] != prov: return
+        element_fol = element.find("{"+self.xmlns+"}FoliationObservation")
+        if "dip" in args:
+            element_fol.set("Dip", args["dip"])
+        if "azimuth" in args:
+            element_fol.set("Azimuth", args["azimuth"])
+        if "nomalpolarity" in args:
+            element_fol.set("NormalPolarity", args["normalpolarity"])
+        #
+        # To Do: logfile, if dip >90, azi > 360, ...
+        #
+        if "add_dip" in args:
+            dip_org = float(element_fol.get("Dip"))
+            dip_new = dip_org + float(args["add_dip"])
+            if dip_new > 90:
+                dip_new = 180 - dip_new
+                self.change_foliation_polarity(element_fol)
+                azi_org = float(element_fol.get("Azimuth"))
+                if azi_org < 180:
+                    element_fol.set("Azimuth", str(azi_org+180))
+                else:
+                    element_fol.set("Azimuth", str(azi_org-180))
+            element_fol.set("Dip", str(dip_new))
+        if "add_azimuth" in args:
+            azi_org = float(element_fol.get("Azimuth"))
+            azi_new = azi_org + float(args["add_azimuth"])
+            if azi_new > 360.0: azi_new -= 360
+            element_fol.set("Azimuth", str(azi_new))
+        element_point = element_fol.find("{"+self.gml+"}Point")
+        element_coords = element_point.find("{"+self.gml+"}coordinates")
+        [x_coord, y_coord] = element_coords.text.split(",")
+        [x_coord, y_coord] = [float(x_coord), float(y_coord)]
+        if "x_coord" in args:
+            x_coord = float(args["x_coord"])
+        if "y_coord" in args:
+            y_coord = float(args["y_coord"])
+        if "add_x_coord" in args:
+            x_coord = x_coord + float(args["add_x_coord"])
+        if "add_y_coord" in args:
+            y_coord = y_coord + float(args["add_y_coord"])
+        element_coords.text = "%f,%f" % (x_coord, y_coord)
+        return None
+
+    def twt_to_depth(self, sec_element, formula, **args):
+        """Convert all data within a section from twt to depth (including
+        orientation data!!
+        Input: section element with data points, conversion function as
+        string with 't' as placeholder for twt-time, e.g. '2 * (-t) ** 2 + 18 * (-t)'
+        ATTENTION: check if t negative
+        optional arguments:
+        change_dip (boolean) : change dip angle in foliation data
+        according to first derivative of twt-to-depth formula
+        create_plot (boolean) : create summary plot with twt and converted depth
+        for conversion formula control
+        """
+        # Idea: stoachstic apporach to twt -> depth conversion: apply several
+        # possible formulae for quality estimation of resulting model?
+        struct_data = sec_element.find("{"+self.xmlns+"}Structural2DData")
+        surface_points = struct_data.find("{"+self.xmlns+"}SurfacePoints").findall("{"+self.xmlns+"}Interface")
+        # save data in list to create a plot to check validity of conversion
+        t_list = []
+        v_list = []
+        for interface in surface_points:
+            gml_coords_element = interface.find("{"+self.gml+"}LineString").find("{"+self.gml+"}coordinates")
+            # check for correct decimal, column (cs) and text separator (ts)
+            ts = gml_coords_element.get("ts")
+            cs = gml_coords_element.get("cs")
+            data_array = gml_coords_element.text.split(ts)
+            # check if last entry is empty (seems to happen often), if so: delete!
+            # print gml_coords_element.text
+            if data_array[-1] == "": del data_array[-1]
+            text_new = ""
+            # apply conversion formula for z-direction, i.e. dv;
+            # no change in x-direction -> du = 0 (but: maybe neccessary for specific situations?)
+            for entry in data_array:
+                parts = entry.split(cs)
+                # get original values
+                # t as varibale, as defined in formula (input)
+                t = float(parts[1])
+                v_new = eval(formula)
+                du = 0
+                text_new += "%f%s%f%s" % (float(parts[0])+du, cs, v_new, ts)
+                # append to list for check-plot
+                t_list.append(-t)
+                v_list.append(v_new)
+            # print text_new
+            gml_coords_element.text = text_new
+            # print gml_coords_element.text
+        # now change foliation position and dip angle! (check: given as argument?)
+        # for dip angle: numerical determination of first derivative for
+        # twt to depth conversion formula?
+        if "change_dip" in args and args["change_dip"]:
+            print ("change dip in seismic profile")
+
+        # create check-plot
+        if "create_plot" in args and args["create_plot"]:
+            print ("Create plot with twt, converted depth pairs")
+            plot(t_list,v_list,'.', label = formula)
+            title("TWT to depth: Converted data points\nSection: " + sec_element.get("Name"))
+            xlabel("TWT [ms]")
+            ylabel("Converted depth [m]")
+            legend()
+            grid(True)
+            show()
+
+    def get_pole_points(self, element):
+        # function to plot data points in geomodeller element
+        u = []
+        v = []
+        poles = element.getiterator("{"+self.xmlns+"}Pole-Weight")
+        for pole in poles:
+            u.append(pole.get("U"))
+            v.append(pole.get("V"))
+
+        return (u,v)
+
+    def plot_points(self, element):
+        # plot u,v points in simple 2D plot
+        (u,v) = self.get_pole_points(element)
+        plot(u,v,'o')
+        name = element.get("Name")
+        title(name)
+        savefig(name+"_points.png")
+
+    def write_xml(self, save_dir, **args):
+        """Write elementtree to xml-file
+        arguments:
+        print_path: Print the path where the xml is created"""
+        # to do: filename (and directory?) as optional argument"""
+        # flo, 10/2008
+        #file = "changed_model.xml"
+        tree_new = ET.ElementTree(self.rootelement)
+        if "print_path" in args:
+            print(("Write tree to file " + save_dir))
+        tree_new.write(save_dir)
+        #self.tree.write("changed_model.xml")
+        self.tree.write(save_dir)
+
+    def add_to_project_name(self, s):
+        """add string s to project name, e.g. Number of uncertainty run"""
+        name = self.rootelement.get("projectName")
+        name_new = name + " " + s
+        self.rootelement.set("projectName",name_new)
+
+    def create_TOUGH_formation_names(self, **kwds):
+        """create formation names that are compatible with format required by TOUGH,
+        i.e. String of length 5
+        returns and stores as dictionary with Geomodeller Names as key and TOUGH names as entry
+        (self.tough_formation_names)
+        simply cuts original formation name to a name length of 5;
+        if cut name already exists: create new name, three first string values followed by two integers
+        that are subsequently increased
+        optional keywods:
+        out = string : set out formation to this name (for TOUGH2: no leading spaces allowed! set to 5 chars!)
+        """
+        # import str
+        self.tough_formation_names = {}
+        # check if self.formation_names list already exists, if not: create
+        try: self.formation_names
+        except AttributeError:
+            self.formation_names = self.get_stratigraphy_list(**kwds)
+        # create list with tough names to check if name already exists
+        tough_name_list = []
+        for i,name in enumerate(self.formation_names):
+            #    if self.formation_names[i] == '  out' or self.formation_names[i] == '  OUT':
+            #   tough_name_list.append("OUT  ")
+            #   continue
+            cut_name = self.formation_names[i][0:5]
+            if cut_name in tough_name_list:
+                for j in range(100):
+                    if "%3s%02d" % (cut_name[0:3],j) in tough_name_list:
+                        continue
+                    else:
+                        cut_name = "%3s%02d" % (cut_name[0:3],j)
+                        tough_name_list.append(cut_name)
+                        break
+            else:
+                tough_name_list.append(cut_name)
+            self.tough_formation_names[name] = "%5s" % str.upper(cut_name)
+        return self.tough_formation_names
+
+
+if __name__ == '__main__':
+    print ("main")
```

### Comparing `gempy-2.2b10.dev1/gempy/utils/gradient.py` & `gempy-2.3.0/gempy/utils/gradient.py`

 * *Ordering differences only*

 * *Files 21% similar despite different names*

```diff
@@ -1,87 +1,87 @@
-import numpy as np
-import matplotlib.pyplot as plt
-import gempy as gp
-
-
-def plot_sig(n_surface_0, n_surface_1, a, b, drift,
-             l=50, Z_x=None, sf_max=None, sf_min=None, sf_at_scalar=None, relu=None, **kwargs):
-    """
-    Plot the sigmoid function used by gempy to discretize space
-
-    Args:
-        n_surface_0 (list, int): Activation value
-        n_surface_1 (list, int): Deactivation value
-        a (list, float): value of the scalar field to trigger the activation
-        b (list, float): value of the scalar field to trigger the deactivation
-        drift (list, float): drift of the function
-        l (float): sigmoid slope
-        Z_x (ndarray): scalar field vector
-        sf_max (Optional[float]): Maximum scalar field of the model. This represent the boundaries
-        sf_min (Optional[float]): Minimum scalar field of the model. This represent the boundaries
-        sf_at_scalar (Optional[ndarray]): Values where the layers are found
-
-    Keyword Args:
-        colors: List with the colors for the layers
-
-    Returns:
-
-    """
-    if 'colors' not in kwargs:
-        colors = ['#015482','#9f0052','#ffbe00','#728f02','#443988','#ff3f20','#325916','#5DA629']
-
-    if Z_x is None:
-        Z_x = np.linspace(-3, 3, 2000)
-    f_x_s = np.zeros_like(Z_x)
-    relu_up = np.copy(Z_x)
-    relu_up -= b[0]
-    relu_up[relu_up < 0] = 0
-    relu_up = relu_up * -.01
-
-    # print(relu_up)
-    relu_down = np.copy(Z_x)
-    relu_down -= a[-1]
-    relu_down[relu_down > 0] = 0
-    relu_down = relu_down * -.01
-
-    relu = relu_up + relu_down
-
-    if len(n_surface_0) == 1:
-
-        f_x = -n_surface_0 / (1 + np.exp(-l * (Z_x - a))) - \
-              (n_surface_1 / (1 + np.exp(l * (Z_x - b)))) + drift
-        f_x += relu
-
-        plt.plot(f_x, Z_x)
-
-    else:
-        len_ = len(n_surface_0)
-        fig = plt.figure(figsize=(7, 12))
-        for e in range(len_):
-            f_x = - n_surface_0[e] / (1 + np.exp(-l * (Z_x - a[e]))) - \
-                  (n_surface_1[e] / (1 + np.exp(l * (Z_x - b[e])))) + drift[e]
-            f_x_s += f_x + relu
-            # fig.add_subplot(len_, 1, e+1)
-            plt.plot(f_x, Z_x, '--', label='Layer ' + str(drift[e]))
-
-        if sf_max is not None:
-            plt.hlines(sf_max, 0, f_x_s.max(), label='Model Extent')
-        if sf_min is not None:
-            plt.hlines(sf_min, 0, f_x_s.max())
-        if sf_at_scalar is not None:
-            plt.hlines(sf_at_scalar, 0, f_x_s.max(), linewidth=3,
-                       color=colors[:len(sf_at_scalar)], label='Scalar value interfaces')
-
-        plt.plot(f_x_s, Z_x, linewidth=5, alpha=.7, label='Actual exporty')
-        plt.ylabel('Scalar field')
-        plt.xlabel('Lith block')
-        #  plt.gca().invert_yaxis()
-
-        plt.legend(bbox_to_anchor=(1.8, 1))
-
-    return plt.gcf()
-
-
-
-
-
-
+import numpy as np
+import matplotlib.pyplot as plt
+import gempy as gp
+
+
+def plot_sig(n_surface_0, n_surface_1, a, b, drift,
+             l=50, Z_x=None, sf_max=None, sf_min=None, sf_at_scalar=None, relu=None, **kwargs):
+    """
+    Plot the sigmoid function used by gempy to discretize space
+
+    Args:
+        n_surface_0 (list, int): Activation value
+        n_surface_1 (list, int): Deactivation value
+        a (list, float): value of the scalar field to trigger the activation
+        b (list, float): value of the scalar field to trigger the deactivation
+        drift (list, float): drift of the function
+        l (float): sigmoid slope
+        Z_x (ndarray): scalar field vector
+        sf_max (Optional[float]): Maximum scalar field of the model. This represent the boundaries
+        sf_min (Optional[float]): Minimum scalar field of the model. This represent the boundaries
+        sf_at_scalar (Optional[ndarray]): Values where the layers are found
+
+    Keyword Args:
+        colors: List with the colors for the layers
+
+    Returns:
+
+    """
+    if 'colors' not in kwargs:
+        colors = ['#015482','#9f0052','#ffbe00','#728f02','#443988','#ff3f20','#325916','#5DA629']
+
+    if Z_x is None:
+        Z_x = np.linspace(-3, 3, 2000)
+    f_x_s = np.zeros_like(Z_x)
+    relu_up = np.copy(Z_x)
+    relu_up -= b[0]
+    relu_up[relu_up < 0] = 0
+    relu_up = relu_up * -.01
+
+    # print(relu_up)
+    relu_down = np.copy(Z_x)
+    relu_down -= a[-1]
+    relu_down[relu_down > 0] = 0
+    relu_down = relu_down * -.01
+
+    relu = relu_up + relu_down
+
+    if len(n_surface_0) == 1:
+
+        f_x = -n_surface_0 / (1 + np.exp(-l * (Z_x - a))) - \
+              (n_surface_1 / (1 + np.exp(l * (Z_x - b)))) + drift
+        f_x += relu
+
+        plt.plot(f_x, Z_x)
+
+    else:
+        len_ = len(n_surface_0)
+        fig = plt.figure(figsize=(7, 12))
+        for e in range(len_):
+            f_x = - n_surface_0[e] / (1 + np.exp(-l * (Z_x - a[e]))) - \
+                  (n_surface_1[e] / (1 + np.exp(l * (Z_x - b[e])))) + drift[e]
+            f_x_s += f_x + relu
+            # fig.add_subplot(len_, 1, e+1)
+            plt.plot(f_x, Z_x, '--', label='Layer ' + str(drift[e]))
+
+        if sf_max is not None:
+            plt.hlines(sf_max, 0, f_x_s.max(), label='Model Extent')
+        if sf_min is not None:
+            plt.hlines(sf_min, 0, f_x_s.max())
+        if sf_at_scalar is not None:
+            plt.hlines(sf_at_scalar, 0, f_x_s.max(), linewidth=3,
+                       color=colors[:len(sf_at_scalar)], label='Scalar value interfaces')
+
+        plt.plot(f_x_s, Z_x, linewidth=5, alpha=.7, label='Actual exporty')
+        plt.ylabel('Scalar field')
+        plt.xlabel('Lith block')
+        #  plt.gca().invert_yaxis()
+
+        plt.legend(bbox_to_anchor=(1.8, 1))
+
+    return plt.gcf()
+
+
+
+
+
+
```

### Comparing `gempy-2.2b10.dev1/gempy/utils/input_manipulation.py` & `gempy-2.3.0/gempy/utils/input_manipulation.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,225 +1,225 @@
-"""
-    This file is part of gempy.
-
-    gempy is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    gempy is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
-
-Tested on Ubuntu 16
-
-Created on 23/06/2018
-
-@author: Miguel de la Varga, Alexander Schaaf
-"""
-import numpy as np
-import pandas as pn
-
-
-def find_surface_points_from_block(block, value):
-    """
-    TODO: Is this dep by find_interfaces_from_block_bottoms?
-    Find the voxel at an interface. We shift left since gempy is based on bottoms
-
-    Args:
-        block (ndarray):
-        value:
-
-    Returns:
-
-    """
-    A = block > value
-    # Matrix shifting along axis
-    B = A  #
-    x_shift = B[:-1, :, :] ^ B[1:, :, :]
-
-    # Matrix shifting along axis
-    y_shift = B[:, :-1, :] ^ B[:, 1:, :]
-
-    # Matrix shifting along axis
-    z_shift = B[:, :, :-1] ^ B[:, :, 1:]
-
-    final_bool = np.zeros_like(block, dtype=bool)
-    final_bool[:-1, :-1, :-1] = x_shift[:, :-1, :-1] + y_shift[:-1, :, :-1] + z_shift[-1:, -1:, :]
-
-    return final_bool
-
-
-def find_interfaces_from_block_bottoms(block, value, shift=2):
-    """
-    Find the voxel at an interface. We shift left since gempy is based on bottoms
-
-    Args:
-        block (ndarray): matrix with the scalar values
-        value: value of which you are looking the interfaces
-        shift (int): Number of elements shifted
-
-    Returns:
-
-    """
-    A = block == value
-    final_bool = np.zeros_like(block, dtype=bool)
-
-    # Matrix shifting along axis 0
-    x_shift = A[:-shift, :, :] ^ A[shift:, :, :]
-
-    # Matrix shifting along axis 1
-    y_shift = A[:, :-shift, :] ^ A[:, shift:, :]
-
-    # Matrix shifting along axis 2
-    z_shift = A[:, :, :-shift] ^ A[:, :, shift:]
-    final_bool[shift:, shift:, shift:] = (x_shift[:, shift:, shift:] +
-                                          y_shift[shift:, :, shift:] +
-                                          z_shift[shift:, shift:, :])
-    return final_bool
-
-
-def surface_points_from_surface_points_block(block_bool, block_grid, formation='default_formation', series='Default_series',
-                                     formation_number=1, order_series=1, n_points=20):
-
-    assert np.ravel(block_bool).shape[0] == block_grid.shape[0], 'Grid and block block must have the same size. If you' \
-                                                           'are importing a model from noddy make sure that the' \
-                                                           'resolution is the same'
-    coord_select = block_grid[np.ravel(block_bool)]
-
-    loc_points = np.linspace(0, coord_select.shape[0]-1, n_points, dtype=int)
-
-    # Init dataframe
-    p = pn.DataFrame(columns=['X', 'Y', 'Z', 'formation', 'series', 'formation_number',
-                              'order_series', 'isFault'])
-
-    p[['X', 'Y', 'Z']] = pn.DataFrame(coord_select[loc_points])
-    p['formation'] = formation
-    p['series'] = series
-    p['formation_number'] = formation_number
-    p['order_series'] = order_series
-
-    return p
-
-
-def set_surface_points_from_block(geo_data, block, block_grid=None, n_points=20, reset_index=False):
-    values = np.unique(np.round(block))
-    values.sort()
-    values = values[:-1]
-
-    if block_grid is None:
-        block_grid = geo_data._grid.values
-
-    for e, value in enumerate(values):
-        block_bool = find_surface_points_from_block(block, value)
-
-        geo_data.set_interface_object(surface_points_from_surface_points_block(block_bool, block_grid,
-                                                                       formation='formation_'+str(e), series='Default_series',
-                                                                       formation_number=e, order_series=1,
-                                                                       n_points=n_points), append=True)
-        if reset_index:
-            geo_data._surface_points.reset_index(drop=True, inplace=True)
-
-    return geo_data
-
-
-class VanMisesFisher:
-    def __init__(self, mu, kappa, dim=3):
-        """van Mises-Fisher distribution for sampling vector components from n-dimensional spheres.
-
-        Adapted from source: https://github.com/pymc-devs/pymc3/issues/2458
-        
-        a von Mises-Fisher distribution can be fit using scipy.stats.vonmises
-
-        Args:
-            mu (np.ndarray): Mean direction of vector [Gx, Gy, Gz]
-            kappa (float): Concentration parameter (the lower the higher the spread on the sphere)
-            dim (int, optional): Dimensionality of the Sphere
-        """
-        self.mu = mu
-        self.kappa = kappa
-        self.dim = dim
-
-    def rvs(self, n=1):
-        """Obtain n samples from van Mises-Fisher distribution.
-
-        Args:
-            n (int): Number of samples to draw
-
-        Returns:
-            np.ndarray with shape (n, 3) containing samples.
-
-        """
-        result = np.zeros((n, self.dim))
-        for nn in range(n):
-            # sample offset from center (on sphere) with spread kappa
-            w = self._sample_weight()
-            # sample a point v on the unit sphere that's orthogonal to mu
-            v = self._sample_orthonormal_to()
-            # compute new point
-            result[nn, :] = v * np.sqrt(1. - w** 2) + w * self.mu
-        return result
-
-    def _sample_weight(self):
-        """Who likes documentation anyways. This is totally intuitive and trivial."""
-        dim = self.dim - 1  # since S^{n-1}
-        b = dim / (np.sqrt(4. * self.kappa ** 2 + dim ** 2) + 2 * self.kappa)
-        x = (1. - b) / (1. + b)
-        c = self.kappa * x + dim * np.log(1 - x ** 2)
-
-        while True:
-            z = np.random.beta(dim / 2., dim / 2.)
-            w = (1. - (1. + b) * z) / (1. - (1. - b) * z)
-            u = np.random.uniform(low=0, high=1)
-            if self.kappa * w + dim * np.log(1. - x * w) - c >= np.log(u):
-                return w
-
-    def _sample_orthonormal_to(self):
-        """Who likes documentation anyways. This is totally intuitive and trivial."""
-        v = np.random.randn(self.mu.shape[0])
-        proj_mu_v = self.mu * np.dot(self.mu, v) / np.linalg.norm(self.mu)
-        orthto = v - proj_mu_v
-        return orthto / np.linalg.norm(orthto)
-
-    def stats(self):
-        return self.mu, self.kappa
-
-
-def change_data(interp_data, geo_data_stoch, priors):
-    """Changes input data with prior distributions (scipy.stats distributions) given in list.
-    Prior distribution objects must contain .rvs() method for drawing samples.
-
-    Args:
-        interp_data:
-        geo_data_stoch:
-        priors:
-        verbose:
-
-    Returns:
-
-    """
-    prior_draws = []
-    for prior in priors:
-        if hasattr(prior, "gradient"):
-            value = prior.rvs()
-        else:
-            value = prior.rvs() / interp_data.rescaling_factor
-        prior_draws.append(value)
-
-        if prior.index_interf is not None:
-            if prior.replace:  # replace the value
-                # geo_data.interfaces.set_value(prior.index_interf, prior.column, prior.rvs() / rf)
-                interp_data.geo_data_res.interfaces.loc[prior.index_interf, prior.column] = value
-            else:  # add value
-                interp_data.geo_data_res.interfaces.loc[prior.index_interf, prior.column] = geo_data_stoch.interfaces.loc[
-                                                                                prior.index_interf, prior.column] + value
-        if prior.index_orient is not None:
-            if prior.replace:  # replace the value
-                interp_data.geo_data_res._orientations.loc[prior.index_orient, prior.column] = value
-            else:  # add value
-                interp_data.geo_data_res._orientations.loc[prior.index_orient, prior.column] = geo_data_stoch._orientations.loc[
-                                                                                  prior.index_orient, prior.column] + value
-    return prior_draws
+"""
+    This file is part of gempy.
+
+    gempy is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    gempy is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with gempy.  If not, see <http://www.gnu.org/licenses/>.
+
+Tested on Ubuntu 16
+
+Created on 23/06/2018
+
+@author: Miguel de la Varga, Alexander Schaaf
+"""
+import numpy as np
+import pandas as pn
+
+
+def find_surface_points_from_block(block, value):
+    """
+    TODO: Is this dep by find_interfaces_from_block_bottoms?
+    Find the voxel at an interface. We shift left since gempy is based on bottoms
+
+    Args:
+        block (ndarray):
+        value:
+
+    Returns:
+
+    """
+    A = block > value
+    # Matrix shifting along axis
+    B = A  #
+    x_shift = B[:-1, :, :] ^ B[1:, :, :]
+
+    # Matrix shifting along axis
+    y_shift = B[:, :-1, :] ^ B[:, 1:, :]
+
+    # Matrix shifting along axis
+    z_shift = B[:, :, :-1] ^ B[:, :, 1:]
+
+    final_bool = np.zeros_like(block, dtype=bool)
+    final_bool[:-1, :-1, :-1] = x_shift[:, :-1, :-1] + y_shift[:-1, :, :-1] + z_shift[-1:, -1:, :]
+
+    return final_bool
+
+
+def find_interfaces_from_block_bottoms(block, value, shift=2):
+    """
+    Find the voxel at an interface. We shift left since gempy is based on bottoms
+
+    Args:
+        block (ndarray): matrix with the scalar values
+        value: value of which you are looking the interfaces
+        shift (int): Number of elements shifted
+
+    Returns:
+
+    """
+    A = block == value
+    final_bool = np.zeros_like(block, dtype=bool)
+
+    # Matrix shifting along axis 0
+    x_shift = A[:-shift, :, :] ^ A[shift:, :, :]
+
+    # Matrix shifting along axis 1
+    y_shift = A[:, :-shift, :] ^ A[:, shift:, :]
+
+    # Matrix shifting along axis 2
+    z_shift = A[:, :, :-shift] ^ A[:, :, shift:]
+    final_bool[shift:, shift:, shift:] = (x_shift[:, shift:, shift:] +
+                                          y_shift[shift:, :, shift:] +
+                                          z_shift[shift:, shift:, :])
+    return final_bool
+
+
+def surface_points_from_surface_points_block(block_bool, block_grid, formation='default_formation', series='Default_series',
+                                     formation_number=1, order_series=1, n_points=20):
+
+    assert np.ravel(block_bool).shape[0] == block_grid.shape[0], 'Grid and block block must have the same size. If you' \
+                                                           'are importing a model from noddy make sure that the' \
+                                                           'resolution is the same'
+    coord_select = block_grid[np.ravel(block_bool)]
+
+    loc_points = np.linspace(0, coord_select.shape[0]-1, n_points, dtype=int)
+
+    # Init dataframe
+    p = pn.DataFrame(columns=['X', 'Y', 'Z', 'formation', 'series', 'formation_number',
+                              'order_series', 'isFault'])
+
+    p[['X', 'Y', 'Z']] = pn.DataFrame(coord_select[loc_points])
+    p['formation'] = formation
+    p['series'] = series
+    p['formation_number'] = formation_number
+    p['order_series'] = order_series
+
+    return p
+
+
+def set_surface_points_from_block(geo_data, block, block_grid=None, n_points=20, reset_index=False):
+    values = np.unique(np.round(block))
+    values.sort()
+    values = values[:-1]
+
+    if block_grid is None:
+        block_grid = geo_data._grid.values
+
+    for e, value in enumerate(values):
+        block_bool = find_surface_points_from_block(block, value)
+
+        geo_data.set_interface_object(surface_points_from_surface_points_block(block_bool, block_grid,
+                                                                       formation='formation_'+str(e), series='Default_series',
+                                                                       formation_number=e, order_series=1,
+                                                                       n_points=n_points), append=True)
+        if reset_index:
+            geo_data._surface_points.reset_index(drop=True, inplace=True)
+
+    return geo_data
+
+
+class VanMisesFisher:
+    def __init__(self, mu, kappa, dim=3):
+        """van Mises-Fisher distribution for sampling vector components from n-dimensional spheres.
+
+        Adapted from source: https://github.com/pymc-devs/pymc3/issues/2458
+        
+        a von Mises-Fisher distribution can be fit using scipy.stats.vonmises
+
+        Args:
+            mu (np.ndarray): Mean direction of vector [Gx, Gy, Gz]
+            kappa (float): Concentration parameter (the lower the higher the spread on the sphere)
+            dim (int, optional): Dimensionality of the Sphere
+        """
+        self.mu = mu
+        self.kappa = kappa
+        self.dim = dim
+
+    def rvs(self, n=1):
+        """Obtain n samples from van Mises-Fisher distribution.
+
+        Args:
+            n (int): Number of samples to draw
+
+        Returns:
+            np.ndarray with shape (n, 3) containing samples.
+
+        """
+        result = np.zeros((n, self.dim))
+        for nn in range(n):
+            # sample offset from center (on sphere) with spread kappa
+            w = self._sample_weight()
+            # sample a point v on the unit sphere that's orthogonal to mu
+            v = self._sample_orthonormal_to()
+            # compute new point
+            result[nn, :] = v * np.sqrt(1. - w** 2) + w * self.mu
+        return result
+
+    def _sample_weight(self):
+        """Who likes documentation anyways. This is totally intuitive and trivial."""
+        dim = self.dim - 1  # since S^{n-1}
+        b = dim / (np.sqrt(4. * self.kappa ** 2 + dim ** 2) + 2 * self.kappa)
+        x = (1. - b) / (1. + b)
+        c = self.kappa * x + dim * np.log(1 - x ** 2)
+
+        while True:
+            z = np.random.beta(dim / 2., dim / 2.)
+            w = (1. - (1. + b) * z) / (1. - (1. - b) * z)
+            u = np.random.uniform(low=0, high=1)
+            if self.kappa * w + dim * np.log(1. - x * w) - c >= np.log(u):
+                return w
+
+    def _sample_orthonormal_to(self):
+        """Who likes documentation anyways. This is totally intuitive and trivial."""
+        v = np.random.randn(self.mu.shape[0])
+        proj_mu_v = self.mu * np.dot(self.mu, v) / np.linalg.norm(self.mu)
+        orthto = v - proj_mu_v
+        return orthto / np.linalg.norm(orthto)
+
+    def stats(self):
+        return self.mu, self.kappa
+
+
+def change_data(interp_data, geo_data_stoch, priors):
+    """Changes input data with prior distributions (scipy.stats distributions) given in list.
+    Prior distribution objects must contain .rvs() method for drawing samples.
+
+    Args:
+        interp_data:
+        geo_data_stoch:
+        priors:
+        verbose:
+
+    Returns:
+
+    """
+    prior_draws = []
+    for prior in priors:
+        if hasattr(prior, "gradient"):
+            value = prior.rvs()
+        else:
+            value = prior.rvs() / interp_data.rescaling_factor
+        prior_draws.append(value)
+
+        if prior.index_interf is not None:
+            if prior.replace:  # replace the value
+                # geo_data.interfaces.set_value(prior.index_interf, prior.column, prior.rvs() / rf)
+                interp_data.geo_data_res.interfaces.loc[prior.index_interf, prior.column] = value
+            else:  # add value
+                interp_data.geo_data_res.interfaces.loc[prior.index_interf, prior.column] = geo_data_stoch.interfaces.loc[
+                                                                                prior.index_interf, prior.column] + value
+        if prior.index_orient is not None:
+            if prior.replace:  # replace the value
+                interp_data.geo_data_res._orientations.loc[prior.index_orient, prior.column] = value
+            else:  # add value
+                interp_data.geo_data_res._orientations.loc[prior.index_orient, prior.column] = geo_data_stoch._orientations.loc[
+                                                                                  prior.index_orient, prior.column] + value
+    return prior_draws
```

### Comparing `gempy-2.2b10.dev1/gempy/utils/meta.py` & `gempy-2.3.0/gempy/utils/meta.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,107 +1,107 @@
-from . import docstring as doc_args
-import re
-
-# region Auxiliary
-
-
-def _setdoc(docstring, indent=True, position='end'):
-    """Copy the doc of a function or method into the decorated function.
-
-    Args:
-        docstring: docstring of to be added
-        indent:
-        position:
-
-    Returns:
-
-    """
-    if type(docstring) is list:
-        try:
-            docstring = '----'.join(docstring)
-        except TypeError:
-            raise TypeError(str(docstring))
-
-    def decor(func):
-
-        if func.__doc__ is None:
-
-            func.__doc__ = docstring
-        else:
-
-            if indent is True:
-                aux = docstring.replace('\n', '\n\n        ')
-                stop = aux.find('\nExamples\n-----')
-                func.__doc__ += ' (inserted) \n        ' + aux[:stop]
-            else:
-                stop = docstring.find('\nExamples\n-----')
-                if position == 'end':
-
-                    func.__doc__ += docstring[:stop]
-                else:
-                    func.__doc__ = docstring[:stop] + '\n'+ func.__doc__
-        return func
-
-    return decor
-
-
-def _setdoc_pro(docstring=[]):
-    """This takes a list and places where it finds [s+0]"""
-    if type(docstring) is not list:
-        docstring = [docstring]
-
-    def decor(func):
-
-        if func.__doc__ is None:
-            raise AttributeError('Add """"""" to the docstring')
-           # print(func.__doc__)
-        else:
-            # Loop for the docstrings we pass looking for numbers
-            for e, i in enumerate(docstring):
-                # Find the location on the target method to insert comment
-                marker = '[s'+str(e)+']'
-                loc_0 = func.__doc__.find(marker) + len(marker)
-                if loc_0 == -1:
-                    print('marker not found')
-                break_loc = i.find('\n\n')
-                if break_loc == 0:
-                    break_loc = i[2:].find('\n\n') + 2
-
-                text = i[:break_loc]
-                if text == -1:
-                    text = 'No break found'
-                text = text.replace('\n    ', '')
-                func.__doc__ = func.__doc__[:loc_0] + ' '+ text + func.__doc__[loc_0:]
-
-        # Find all the arg_string markers
-        loc_1 = 0
-        text = []
-        marker = '[s_'
-        for e in range(10):
-            #print(len(func.__doc__), func.__doc__)
-            #print('loc_1', loc_1)
-            #print(func.__doc__)
-            loc_0 = func.__doc__[loc_1:].find(marker)
-            if loc_0 == -1:
-                break
-            else:
-                loc_0 +=  loc_1
-            #print('Here it is: ', func.__doc__[loc_1+len(text):loc_1+len(text)+50])
-            #print(loc_0)
-
-            end_marker = func.__doc__[loc_0:].find(']')
-            loc_1 = loc_0 + end_marker
-            arg_string = func.__doc__[loc_0 + 3:loc_1]
-            #print('arg_string ',arg_string)
-            try:
-                text = getattr(doc_args, arg_string)
-            except AttributeError as e:
-                 print(e, func)
-
-            # This 2 is to add the type to the string
-            loc_1 = loc_0 + end_marker
-            func.__doc__ = func.__doc__[:loc_0 - 2] + ' ' + text + func.__doc__[loc_1+1:]
-
-        return func
-
-    return decor
-# endregion
+from . import docstring as doc_args
+import re
+
+# region Auxiliary
+
+
+def _setdoc(docstring, indent=True, position='end'):
+    """Copy the doc of a function or method into the decorated function.
+
+    Args:
+        docstring: docstring of to be added
+        indent:
+        position:
+
+    Returns:
+
+    """
+    if type(docstring) is list:
+        try:
+            docstring = '----'.join(docstring)
+        except TypeError:
+            raise TypeError(str(docstring))
+
+    def decor(func):
+
+        if func.__doc__ is None:
+
+            func.__doc__ = docstring
+        else:
+
+            if indent is True:
+                aux = docstring.replace('\n', '\n\n        ')
+                stop = aux.find('\nExamples\n-----')
+                func.__doc__ += ' (inserted) \n        ' + aux[:stop]
+            else:
+                stop = docstring.find('\nExamples\n-----')
+                if position == 'end':
+
+                    func.__doc__ += docstring[:stop]
+                else:
+                    func.__doc__ = docstring[:stop] + '\n'+ func.__doc__
+        return func
+
+    return decor
+
+
+def _setdoc_pro(docstring=[]):
+    """This takes a list and places where it finds [s+0]"""
+    if type(docstring) is not list:
+        docstring = [docstring]
+
+    def decor(func):
+
+        if func.__doc__ is None:
+            raise AttributeError('Add """"""" to the docstring')
+           # print(func.__doc__)
+        else:
+            # Loop for the docstrings we pass looking for numbers
+            for e, i in enumerate(docstring):
+                # Find the location on the target method to insert comment
+                marker = '[s'+str(e)+']'
+                loc_0 = func.__doc__.find(marker) + len(marker)
+                if loc_0 == -1:
+                    print('marker not found')
+                break_loc = i.find('\n\n')
+                if break_loc == 0:
+                    break_loc = i[2:].find('\n\n') + 2
+
+                text = i[:break_loc]
+                if text == -1:
+                    text = 'No break found'
+                text = text.replace('\n    ', '')
+                func.__doc__ = func.__doc__[:loc_0] + ' '+ text + func.__doc__[loc_0:]
+
+        # Find all the arg_string markers
+        loc_1 = 0
+        text = []
+        marker = '[s_'
+        for e in range(10):
+            #print(len(func.__doc__), func.__doc__)
+            #print('loc_1', loc_1)
+            #print(func.__doc__)
+            loc_0 = func.__doc__[loc_1:].find(marker)
+            if loc_0 == -1:
+                break
+            else:
+                loc_0 +=  loc_1
+            #print('Here it is: ', func.__doc__[loc_1+len(text):loc_1+len(text)+50])
+            #print(loc_0)
+
+            end_marker = func.__doc__[loc_0:].find(']')
+            loc_1 = loc_0 + end_marker
+            arg_string = func.__doc__[loc_0 + 3:loc_1]
+            #print('arg_string ',arg_string)
+            try:
+                text = getattr(doc_args, arg_string)
+            except AttributeError as e:
+                 print(e, func)
+
+            # This 2 is to add the type to the string
+            loc_1 = loc_0 + end_marker
+            func.__doc__ = func.__doc__[:loc_0 - 2] + ' ' + text + func.__doc__[loc_1+1:]
+
+        return func
+
+    return decor
+# endregion
```

### Comparing `gempy-2.2b10.dev1/gempy/utils/qgrid_api.py` & `gempy-2.3.0/gempy/utils/qgrid_api.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,362 +1,362 @@
-
-import warnings
-try:
-    import qgrid
-except ImportError:
-    warnings.warn('qgrid package is not installed. No interactive dataframes available.')
-#
-#
-# # =============================================================
-# # This are functions that modify the data objects independently
-#
-# def create_faults_qgrid(faults_object):
-#     qgrid_widget = qgrid.show_grid(faults_object.df,
-#                                    show_toolbar=False,
-#                                    column_options={'editable': True},
-#                                    column_definitions={'isFinite': {'editable': False}})
-#
-#     def handle_set_is_fault(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#
-#         if event['column'] == 'isFault':
-#             idx = event['index']
-#             #      cat_idx = qgrid_widget.df.loc[idx, 'series_names']
-#
-#             faults_object.set_is_fault([idx])
-#             qgrid_widget._update_df()
-#
-#     qgrid_widget.on('cell_edited', handle_set_is_fault)
-#
-#     return qgrid_widget
-#
-#
-# def create_rescaling_data_qgrid(rescaling_object):
-#     qgrid_widget = qgrid.show_grid(rescaling_object.df,
-#                                    show_toolbar=False,
-#                                    grid_options={'sortable': False, 'highlightSelectedCell': True})
-#
-#     def handle_row_edit(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#             print(qgrid_widget._df)
-#
-#         if event['column'] == 'centers':
-#             try:
-#                 value = event['new']
-#                 assert value.shape[0] is 3
-#
-#                 #rescaling_object.df.loc['values', event['column']] = value
-#                 rescaling_object.modify_rescaling_parameters(event['column'], value)
-#                 qgrid_widget._update_df()
-#
-#             except AssertionError:
-#                 print('centers length must be 3: XYZ')
-#                 qgrid_widget._update_df()
-#
-#     qgrid_widget.on('cell_edited', handle_row_edit)
-#     return qgrid_widget
-#
-#
-# def create_options_qgrid(options_object):
-#     qgrid_widget = qgrid.show_grid(options_object.df,
-#                                    show_toolbar=False,
-#                                    grid_options={'sortable': False, 'highlightSelectedCell': True})
-#
-#     def handle_row_edit(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#             print(qgrid_widget._df)
-#
-#         if event['column'] == 'verbosity':
-#             import numpy as np
-#             value = np.fromstring(event['new'][1:-1], sep=',')
-#         else:
-#             value = event['new']
-#
-#         options_object.df.loc['values', event['column']] = value
-#         qgrid_widget._update_df()
-#
-#     qgrid_widget.on('cell_edited', handle_row_edit)
-#     return qgrid_widget
-#
-#
-# def create_kriging_parameters_qgrid(kriging_parameters_object):
-#     qgrid_widget = qgrid.show_grid(kriging_parameters_object.df,
-#                                    show_toolbar=False,
-#                                    grid_options={'sortable': False, 'highlightSelectedCell': True},
-#                                    )
-#
-#     def handle_row_edit(event, widget, debug=False):
-#         import numpy as np
-#
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#             print(qgrid_widget._df)
-#
-#         if event['column'] == 'drift equations':
-#             value = np.fromstring(event['new'][1:-1], sep=',')
-#             try:
-#                 assert value.shape[0] is kriging_parameters_object.structure.df.loc[
-#                     'values', 'len series surface_points'].shape[0]
-#
-#                 kriging_parameters_object.df.loc['values', event['column']] = value
-#                 qgrid_widget._update_df()
-#
-#             except AssertionError:
-#                 print('u_grade length must be the same as the number of series')
-#                 qgrid_widget._update_df()
-#
-#         else:
-#
-#             kriging_parameters_object.df.loc['values', event['column']] = event['new']
-#             qgrid_widget._update_df()
-#
-#     qgrid_widget.on('cell_edited', handle_row_edit)
-#     return qgrid_widget
-#
-#
-# def create_faults_relations_qgrid(faults_object):
-#     # We need to add the qgrid special columns to categories
-#     faults_object.faults_relations_df.columns = faults_object.faults_relations_df.columns.add_categories(
-#         ['index', 'qgrid_unfiltered_index'])
-#
-#     qgrid_widget = qgrid.show_grid(faults_object.faults_relations_df,
-#                                    show_toolbar=False)
-#
-#     def handle_set_fault_relation(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#
-#         faults_object.faults_relations_df = qgrid_widget.get_changed_df()
-#         qgrid_widget._update_df()
-#
-#     qgrid_widget.on('cell_edited', handle_set_fault_relation)
-#     return qgrid_widget
-#
-#
-# def create_surface_points_qgrid(surface_points_object):
-#     if surface_points_object.df.shape[0] == 0:
-#         # TODO DEBUG: I am not sure that formations always has at least one entry. Check it
-#         surface_points_object.add_surface_points(0, 0, 0, surface_points_object.formations.df['formation'].iloc[0])
-#
-#     qgrid_widget = qgrid.show_grid(
-#         surface_points_object.df,
-#         show_toolbar=True,
-#         grid_options={'sortable': False, 'highlightSelectedCell': True},
-#         column_options={'editable': False},
-#         column_definitions={'X': {'editable': True},
-#                             'Y': {'editable': True},
-#                             'Z': {'editable': True},
-#                             'surface': {'editable': True}})
-#
-#     def handle_row_surface_points_add(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#             print(qgrid_widget._df)
-#         idx = event['index']
-#         xyzs = qgrid_widget._df.loc[idx, ['X', 'Y', 'Z', 'surface']]
-#
-#         self._geo.add_surface_points(*xyzs)
-#         qgrid_widget._update_df()
-#
-#     def handle_row_surface_points_delete(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#         idx = event['indices']
-#
-#         surface_points_object.del_surface_points(idx)
-#         qgrid_widget._update_df()
-#
-#     def handle_cell_surface_points_edit(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#
-#         column = event['column']
-#         idx = event['index']
-#         value = event['new']
-#
-#         surface_points_object.modify_surface_points(idx, **{column: value})
-#
-#         qgrid_widget._update_df()
-#
-#     qgrid_widget.on('row_removed', handle_row_surface_points_delete)
-#     qgrid_widget.on('row_added', handle_row_surface_points_add)
-#     qgrid_widget.on('cell_edited', handle_cell_surface_points_edit)
-#     return qgrid_widget
-#
-#
-# def create_orientations_qgrid(orientations_object):
-#     if orientations_object.df.shape[0] == 0:
-#         # TODO DEBUG: I am not sure that formations always has at least one entry. Check it
-#         orientations_object.add_orientations(0, 0, 0,
-#                                              orientations_object.formations.df['formation'].iloc[0],
-#                                              0, 0, 1,
-#                                              )
-#
-#     qgrid_widget = qgrid.show_grid(
-#         orientations_object.df,
-#         show_toolbar=True,
-#         grid_options={'sortable': False, 'highlightSelectedCell': True},
-#         column_options={'editable': False},
-#         column_definitions={'X': {'editable': True},
-#                             'Y': {'editable': True},
-#                             'Z': {'editable': True},
-#                             'G_x': {'editable': True},
-#                             'G_y': {'editable': True},
-#                             'G_z': {'editable': True},
-#                             'azimuth': {'editable': True},
-#                             'dip': {'editable': True},
-#                             'pole': {'editable': True},
-#                             'surface': {'editable': True}})
-#
-#     def handle_row_orientations_add(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#             print(qgrid_widget._df)
-#         idx = event['index']
-#         xyzs = qgrid_widget._df.loc[idx, ['X', 'Y', 'Z','surface', 'G_x', 'G_y', 'G_z']]
-#
-#         orientations_object.add_orientation(*xyzs)
-#         qgrid_widget._update_df()
-#
-#     def handle_row_orientations_delete(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#         idx = event['indices']
-#
-#         orientations_object.del_orientation(idx)
-#         qgrid_widget._update_df()
-#
-#     def handle_cell_orientations_edit(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#
-#         column = event['column']
-#         idx = event['index']
-#         value = event['new']
-#
-#         orientations_object.modify_orientation(idx, **{column: value})
-#         qgrid_widget._update_df()
-#
-#     qgrid_widget.on('row_removed', handle_row_orientations_delete)
-#     qgrid_widget.on('row_added', handle_row_orientations_add)
-#     qgrid_widget.on('cell_edited', handle_cell_orientations_edit)
-#     return qgrid_widget
-#
-#
-# def create_formations_qgrid(formation_object):
-#     if formation_object.df.shape[0] == 0:
-#         # TODO DEBUG: I am not sure that formations always has at least one entry. Check it
-#         formation_object.set_surfaces_names(['surface1'])
-#
-#     qgrid_widget = qgrid.show_grid(formation_object.df, show_toolbar=True,
-#                                    column_options={'editable': True},
-#                                    column_definitions={'id': {'editable': False},
-#                                                        'basement': {'editable': False}})
-#
-#     def handle_row_formation_add(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#         idx = event['index']
-#         formation_object.add_surface(['surface' + str(idx)])
-#         qgrid_widget._update_df()
-#
-#     def handle_row_formation_delete(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#         idx = event['indices']
-#         formation_object.delete_surface(idx)
-#         qgrid_widget._update_df()
-#
-#     def handle_cell_formation_edit(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#         if event['column'] == 'formation':
-#             formation_object.rename_formations(event['old'], event['new'])
-#         if event['column'] == 'series':
-#             idx = event['index']
-#             new_series = event['new']
-#             formation_object.map_series({new_series:formation_object.df.loc[idx, ['formation']]})
-#         if event['column'] == 'isBasement':
-#             idx = event['index']
-#             formation_object.set_basement(formation_object.df.loc[idx, ['formation']])
-#         qgrid_widget._update_df()
-#
-#     qgrid_widget.on('row_removed', handle_row_formation_delete)
-#     qgrid_widget.on('row_added', handle_row_formation_add)
-#     qgrid_widget.on('cell_edited', handle_cell_formation_edit)
-#
-#     return qgrid_widget
-#
-#
-# def create_series_qgrid(series_object):
-#     # I need to do a serious hack because qgrid does not accept categorical index yet
-#     qgrid_widget = qgrid.show_grid(
-#         series_object.df.reset_index().rename(columns={'index': 'series_names'}).astype({'series_names': str}),
-#         show_toolbar=True,
-#         column_options={'editable': True},
-#         column_definitions={'order_series': {'editable': False},
-#                             })
-#
-#     def handle_row_series_add(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#             print(series_object.df.reset_index())
-#
-#         idx = event['index']
-#         series_object.add_series(['series' + str(idx)])
-#         qgrid_widget.df = series_object.df.reset_index().rename(columns={'index': 'series_names'}).astype(
-#             {'series_names': str})
-#         qgrid_widget._update_df()
-#
-#     def handle_row_series_delete(event, widget, debug=False):
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#         idx = event['indices']
-#         cat_idx = qgrid_widget.df.loc[idx, 'series_names']
-#
-#         series_object.delete_series(cat_idx)
-#
-#         qgrid_widget.df = series_object.df.reset_index().rename(columns={'index': 'series_names'}).astype(
-#             {'series_names': str})
-#         qgrid_widget._update_df()
-#
-#     def handle_cell_series_edit(event, widget, debug=False):
-#         idx = event['index']
-#         cat_idx = qgrid_widget.df.loc[idx, 'series_names']
-#         if debug is True:
-#             print(event)
-#             print(widget)
-#             print(cat_idx)
-#             print(series_object.df.index)
-#         if event['column'] == 'series_names':
-#             series_object.rename_series({event['old']: event['new']})
-#         if event['column'] == 'BottomRelation':
-#             series_object.df.loc[cat_idx, 'BottomRelation'] = event['new']
-#
-#         qgrid_widget.df = series_object.df.reset_index().rename(columns={'index': 'series_names'}).astype(
-#             {'series_names': str})
-#         qgrid_widget._update_df()
-#
-#     qgrid_widget.on('row_removed', handle_row_series_delete)
-#     qgrid_widget.on('row_added', handle_row_series_add)
-#     qgrid_widget.on('cell_edited', handle_cell_series_edit)
-#
-#     return qgrid_widget
+
+import warnings
+try:
+    import qgrid
+except ImportError:
+    warnings.warn('qgrid package is not installed. No interactive dataframes available.')
+#
+#
+# # =============================================================
+# # This are functions that modify the data objects independently
+#
+# def create_faults_qgrid(faults_object):
+#     qgrid_widget = qgrid.show_grid(faults_object.df,
+#                                    show_toolbar=False,
+#                                    column_options={'editable': True},
+#                                    column_definitions={'isFinite': {'editable': False}})
+#
+#     def handle_set_is_fault(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#
+#         if event['column'] == 'isFault':
+#             idx = event['index']
+#             #      cat_idx = qgrid_widget.df.loc[idx, 'series_names']
+#
+#             faults_object.set_is_fault([idx])
+#             qgrid_widget._update_df()
+#
+#     qgrid_widget.on('cell_edited', handle_set_is_fault)
+#
+#     return qgrid_widget
+#
+#
+# def create_rescaling_data_qgrid(rescaling_object):
+#     qgrid_widget = qgrid.show_grid(rescaling_object.df,
+#                                    show_toolbar=False,
+#                                    grid_options={'sortable': False, 'highlightSelectedCell': True})
+#
+#     def handle_row_edit(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#             print(qgrid_widget._df)
+#
+#         if event['column'] == 'centers':
+#             try:
+#                 value = event['new']
+#                 assert value.shape[0] is 3
+#
+#                 #rescaling_object.df.loc['values', event['column']] = value
+#                 rescaling_object.modify_rescaling_parameters(event['column'], value)
+#                 qgrid_widget._update_df()
+#
+#             except AssertionError:
+#                 print('centers length must be 3: XYZ')
+#                 qgrid_widget._update_df()
+#
+#     qgrid_widget.on('cell_edited', handle_row_edit)
+#     return qgrid_widget
+#
+#
+# def create_options_qgrid(options_object):
+#     qgrid_widget = qgrid.show_grid(options_object.df,
+#                                    show_toolbar=False,
+#                                    grid_options={'sortable': False, 'highlightSelectedCell': True})
+#
+#     def handle_row_edit(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#             print(qgrid_widget._df)
+#
+#         if event['column'] == 'verbosity':
+#             import numpy as np
+#             value = np.fromstring(event['new'][1:-1], sep=',')
+#         else:
+#             value = event['new']
+#
+#         options_object.df.loc['values', event['column']] = value
+#         qgrid_widget._update_df()
+#
+#     qgrid_widget.on('cell_edited', handle_row_edit)
+#     return qgrid_widget
+#
+#
+# def create_kriging_parameters_qgrid(kriging_parameters_object):
+#     qgrid_widget = qgrid.show_grid(kriging_parameters_object.df,
+#                                    show_toolbar=False,
+#                                    grid_options={'sortable': False, 'highlightSelectedCell': True},
+#                                    )
+#
+#     def handle_row_edit(event, widget, debug=False):
+#         import numpy as np
+#
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#             print(qgrid_widget._df)
+#
+#         if event['column'] == 'drift equations':
+#             value = np.fromstring(event['new'][1:-1], sep=',')
+#             try:
+#                 assert value.shape[0] is kriging_parameters_object.structure.df.loc[
+#                     'values', 'len series surface_points'].shape[0]
+#
+#                 kriging_parameters_object.df.loc['values', event['column']] = value
+#                 qgrid_widget._update_df()
+#
+#             except AssertionError:
+#                 print('u_grade length must be the same as the number of series')
+#                 qgrid_widget._update_df()
+#
+#         else:
+#
+#             kriging_parameters_object.df.loc['values', event['column']] = event['new']
+#             qgrid_widget._update_df()
+#
+#     qgrid_widget.on('cell_edited', handle_row_edit)
+#     return qgrid_widget
+#
+#
+# def create_faults_relations_qgrid(faults_object):
+#     # We need to add the qgrid special columns to categories
+#     faults_object.faults_relations_df.columns = faults_object.faults_relations_df.columns.add_categories(
+#         ['index', 'qgrid_unfiltered_index'])
+#
+#     qgrid_widget = qgrid.show_grid(faults_object.faults_relations_df,
+#                                    show_toolbar=False)
+#
+#     def handle_set_fault_relation(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#
+#         faults_object.faults_relations_df = qgrid_widget.get_changed_df()
+#         qgrid_widget._update_df()
+#
+#     qgrid_widget.on('cell_edited', handle_set_fault_relation)
+#     return qgrid_widget
+#
+#
+# def create_surface_points_qgrid(surface_points_object):
+#     if surface_points_object.df.shape[0] == 0:
+#         # TODO DEBUG: I am not sure that formations always has at least one entry. Check it
+#         surface_points_object.add_surface_points(0, 0, 0, surface_points_object.formations.df['formation'].iloc[0])
+#
+#     qgrid_widget = qgrid.show_grid(
+#         surface_points_object.df,
+#         show_toolbar=True,
+#         grid_options={'sortable': False, 'highlightSelectedCell': True},
+#         column_options={'editable': False},
+#         column_definitions={'X': {'editable': True},
+#                             'Y': {'editable': True},
+#                             'Z': {'editable': True},
+#                             'surface': {'editable': True}})
+#
+#     def handle_row_surface_points_add(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#             print(qgrid_widget._df)
+#         idx = event['index']
+#         xyzs = qgrid_widget._df.loc[idx, ['X', 'Y', 'Z', 'surface']]
+#
+#         self._geo.add_surface_points(*xyzs)
+#         qgrid_widget._update_df()
+#
+#     def handle_row_surface_points_delete(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#         idx = event['indices']
+#
+#         surface_points_object.del_surface_points(idx)
+#         qgrid_widget._update_df()
+#
+#     def handle_cell_surface_points_edit(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#
+#         column = event['column']
+#         idx = event['index']
+#         value = event['new']
+#
+#         surface_points_object.modify_surface_points(idx, **{column: value})
+#
+#         qgrid_widget._update_df()
+#
+#     qgrid_widget.on('row_removed', handle_row_surface_points_delete)
+#     qgrid_widget.on('row_added', handle_row_surface_points_add)
+#     qgrid_widget.on('cell_edited', handle_cell_surface_points_edit)
+#     return qgrid_widget
+#
+#
+# def create_orientations_qgrid(orientations_object):
+#     if orientations_object.df.shape[0] == 0:
+#         # TODO DEBUG: I am not sure that formations always has at least one entry. Check it
+#         orientations_object.add_orientations(0, 0, 0,
+#                                              orientations_object.formations.df['formation'].iloc[0],
+#                                              0, 0, 1,
+#                                              )
+#
+#     qgrid_widget = qgrid.show_grid(
+#         orientations_object.df,
+#         show_toolbar=True,
+#         grid_options={'sortable': False, 'highlightSelectedCell': True},
+#         column_options={'editable': False},
+#         column_definitions={'X': {'editable': True},
+#                             'Y': {'editable': True},
+#                             'Z': {'editable': True},
+#                             'G_x': {'editable': True},
+#                             'G_y': {'editable': True},
+#                             'G_z': {'editable': True},
+#                             'azimuth': {'editable': True},
+#                             'dip': {'editable': True},
+#                             'pole': {'editable': True},
+#                             'surface': {'editable': True}})
+#
+#     def handle_row_orientations_add(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#             print(qgrid_widget._df)
+#         idx = event['index']
+#         xyzs = qgrid_widget._df.loc[idx, ['X', 'Y', 'Z','surface', 'G_x', 'G_y', 'G_z']]
+#
+#         orientations_object.add_orientation(*xyzs)
+#         qgrid_widget._update_df()
+#
+#     def handle_row_orientations_delete(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#         idx = event['indices']
+#
+#         orientations_object.del_orientation(idx)
+#         qgrid_widget._update_df()
+#
+#     def handle_cell_orientations_edit(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#
+#         column = event['column']
+#         idx = event['index']
+#         value = event['new']
+#
+#         orientations_object.modify_orientation(idx, **{column: value})
+#         qgrid_widget._update_df()
+#
+#     qgrid_widget.on('row_removed', handle_row_orientations_delete)
+#     qgrid_widget.on('row_added', handle_row_orientations_add)
+#     qgrid_widget.on('cell_edited', handle_cell_orientations_edit)
+#     return qgrid_widget
+#
+#
+# def create_formations_qgrid(formation_object):
+#     if formation_object.df.shape[0] == 0:
+#         # TODO DEBUG: I am not sure that formations always has at least one entry. Check it
+#         formation_object.set_surfaces_names(['surface1'])
+#
+#     qgrid_widget = qgrid.show_grid(formation_object.df, show_toolbar=True,
+#                                    column_options={'editable': True},
+#                                    column_definitions={'id': {'editable': False},
+#                                                        'basement': {'editable': False}})
+#
+#     def handle_row_formation_add(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#         idx = event['index']
+#         formation_object.add_surface(['surface' + str(idx)])
+#         qgrid_widget._update_df()
+#
+#     def handle_row_formation_delete(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#         idx = event['indices']
+#         formation_object.delete_surface(idx)
+#         qgrid_widget._update_df()
+#
+#     def handle_cell_formation_edit(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#         if event['column'] == 'formation':
+#             formation_object.rename_formations(event['old'], event['new'])
+#         if event['column'] == 'series':
+#             idx = event['index']
+#             new_series = event['new']
+#             formation_object.map_series({new_series:formation_object.df.loc[idx, ['formation']]})
+#         if event['column'] == 'isBasement':
+#             idx = event['index']
+#             formation_object.set_basement(formation_object.df.loc[idx, ['formation']])
+#         qgrid_widget._update_df()
+#
+#     qgrid_widget.on('row_removed', handle_row_formation_delete)
+#     qgrid_widget.on('row_added', handle_row_formation_add)
+#     qgrid_widget.on('cell_edited', handle_cell_formation_edit)
+#
+#     return qgrid_widget
+#
+#
+# def create_series_qgrid(series_object):
+#     # I need to do a serious hack because qgrid does not accept categorical index yet
+#     qgrid_widget = qgrid.show_grid(
+#         series_object.df.reset_index().rename(columns={'index': 'series_names'}).astype({'series_names': str}),
+#         show_toolbar=True,
+#         column_options={'editable': True},
+#         column_definitions={'order_series': {'editable': False},
+#                             })
+#
+#     def handle_row_series_add(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#             print(series_object.df.reset_index())
+#
+#         idx = event['index']
+#         series_object.add_series(['series' + str(idx)])
+#         qgrid_widget.df = series_object.df.reset_index().rename(columns={'index': 'series_names'}).astype(
+#             {'series_names': str})
+#         qgrid_widget._update_df()
+#
+#     def handle_row_series_delete(event, widget, debug=False):
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#         idx = event['indices']
+#         cat_idx = qgrid_widget.df.loc[idx, 'series_names']
+#
+#         series_object.delete_series(cat_idx)
+#
+#         qgrid_widget.df = series_object.df.reset_index().rename(columns={'index': 'series_names'}).astype(
+#             {'series_names': str})
+#         qgrid_widget._update_df()
+#
+#     def handle_cell_series_edit(event, widget, debug=False):
+#         idx = event['index']
+#         cat_idx = qgrid_widget.df.loc[idx, 'series_names']
+#         if debug is True:
+#             print(event)
+#             print(widget)
+#             print(cat_idx)
+#             print(series_object.df.index)
+#         if event['column'] == 'series_names':
+#             series_object.rename_series({event['old']: event['new']})
+#         if event['column'] == 'BottomRelation':
+#             series_object.df.loc[cat_idx, 'BottomRelation'] = event['new']
+#
+#         qgrid_widget.df = series_object.df.reset_index().rename(columns={'index': 'series_names'}).astype(
+#             {'series_names': str})
+#         qgrid_widget._update_df()
+#
+#     qgrid_widget.on('row_removed', handle_row_series_delete)
+#     qgrid_widget.on('row_added', handle_row_series_add)
+#     qgrid_widget.on('cell_edited', handle_cell_series_edit)
+#
+#     return qgrid_widget
```

### Comparing `gempy-2.2b10.dev1/gempy.egg-info/SOURCES.txt` & `gempy-2.3.0/gempy.egg-info/SOURCES.txt`

 * *Files 5% similar despite different names*

```diff
@@ -21,14 +21,15 @@
 examples/examples/real/Moureze.py
 examples/examples/real/Perth_basin.py
 examples/examples/real/__init__.py
 examples/getting_started/__init__.py
 examples/getting_started/get_started.py
 examples/integrations/__init__.py
 examples/integrations/gempy_export_MOOSE.py
+examples/integrations/gempy_export_perth_bassin_pflotran.py
 examples/integrations/gempy_striplog.py
 examples/integrations/gempy_subsurface.py
 examples/tutorials/__init__.py
 examples/tutorials/ch2-Geophysics/__init__.py
 examples/tutorials/ch2-Geophysics/ch2_1_gravity.py
 examples/tutorials/ch2-Geophysics/ch2_2_cell_selection.py
 examples/tutorials/ch4-Topology/__init__.py
@@ -54,43 +55,51 @@
 gempy/assets/coKriging.py
 gempy/assets/decision_making.py
 gempy/assets/geophysics.py
 gempy/assets/kriging.py
 gempy/assets/spill_analysis.py
 gempy/assets/topology.py
 gempy/bayesian/__init__.py
+gempy/bayesian/aesara_op.py
 gempy/bayesian/axes_utils.py
 gempy/bayesian/fields.py
 gempy/bayesian/joyplot.py
 gempy/bayesian/plot_posterior.py
 gempy/bayesian/posterior_analysis_DEP.py
 gempy/bayesian/posterior_analysis_elisa.py
-gempy/bayesian/theano_op.py
 gempy/core/__init__.py
 gempy/core/checkers.py
+gempy/core/colors.py
 gempy/core/data.py
+gempy/core/grid.py
 gempy/core/interpolator.py
+gempy/core/meta_data.py
 gempy/core/model.py
 gempy/core/qgrid_integration.py
 gempy/core/solution.py
+gempy/core/structure.py
+gempy/core/surfaces.py
 gempy/core/xsolution.py
+gempy/core/aesara_modules/__init__.py
+gempy/core/aesara_modules/aesara_export.py
+gempy/core/aesara_modules/aesara_graph.py
+gempy/core/aesara_modules/aesara_graph_pro.py
+gempy/core/aesara_modules/aesara_kriging.py
 gempy/core/data_modules/__init__.py
 gempy/core/data_modules/geometric_data.py
+gempy/core/data_modules/orientations.py
+gempy/core/data_modules/scaling_system.py
 gempy/core/data_modules/stack.py
+gempy/core/data_modules/surface_points.py
 gempy/core/grid_modules/__init__.py
 gempy/core/grid_modules/create_topography.py
 gempy/core/grid_modules/diamond_square.py
 gempy/core/grid_modules/grid_types.py
 gempy/core/grid_modules/section_utils.py
 gempy/core/grid_modules/topography.py
-gempy/core/theano_modules/__init__.py
-gempy/core/theano_modules/theano_export.py
-gempy/core/theano_modules/theano_graph.py
-gempy/core/theano_modules/theano_graph_pro.py
-gempy/core/theano_modules/theano_kriging.py
 gempy/plot/__init__.py
 gempy/plot/_plot.py
 gempy/plot/_vista.py
 gempy/plot/_visualization_2d.py
 gempy/plot/decorators.py
 gempy/plot/helpers.py
 gempy/plot/plot_api.py
@@ -109,20 +118,30 @@
 gempy/utils/extract_geomodeller_data.py
 gempy/utils/geogrid.py
 gempy/utils/geomodeller_integration.py
 gempy/utils/gradient.py
 gempy/utils/input_manipulation.py
 gempy/utils/meta.py
 gempy/utils/qgrid_api.py
+gempy_3/__init__.py
+gempy_3/api/__init__.py
+gempy_3/api/gp2_to_gp3_input.py
+gempy_3/api/gp3_to_gp2_output.py
+gempy_3/api/test_api/__init__.py
+gempy_3/api/test_api/_gp2togp3_test_utils.py
+gempy_3/api/test_api/test_basic_model_gempy2_to_gempy3.py
+gempy_3/api/test_api/test_unconformities_gempy2_to_gempy3.py
 test/figs/__init__.py
 test/input_data/__init__.py
 test/test_addons/__init__.py
-test/test_addons/test_gempy_to_rexfile.py
-test/test_addons/test_rex_cloud_api.py
-test/test_addons/rexfiles/__init__.py
+test/test_addons/DEP/__init__.py
+test/test_addons/DEP/_test_google_earth.py
+test/test_addons/DEP/est_rex_cloud_api.py
+test/test_addons/DEP/te_gempy_to_rexfile.py
+test/test_addons/DEP/rexfiles/__init__.py
 test/test_anisotropies/__init__.py
 test/test_anisotropies/test_anisotropies.py
 test/test_api/__init__.py
 test/test_api/test_api.py
 test/test_api/test_geometry_api.py
 test/test_assets/__init__.py
 test/test_assets/test_gravity.py
```

### Comparing `gempy-2.2b10.dev1/setup.py` & `gempy-2.3.0/setup.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,32 +1,37 @@
-from setuptools import setup, find_packages
-version = '2.2b10.dev1'
+from setuptools import setup, find_packages, Extension
+
+version = '2.3.0'
 
 with open("README.md", "r") as fh:
     long_description = fh.read()
 
 setup(
     name='gempy',
     version=version,
     packages=find_packages(exclude=('test', 'docs', 'examples')),
     include_package_data=True,
     install_requires=[
-        'pandas>=1.0.5',
-        'Theano>=1.0.4',
+        'pandas==2.0.1',
+        'aesara',
+        'pymc',
         'matplotlib',
         'numpy',
         'pytest',
         'seaborn>=0.9',
         'networkx',
         'scikit-image>=0.17',
-        'pyvista>=0.25',
-        'pyvistaqt',
+        'scikit-learn',
+        'pyvista==0.39.1',
+        'pyvistaqt==0.10.0',
         'pyqt5',
         'iPython',
+        'xarray'
     ],
     url='https://github.com/cgre-aachen/gempy',
     license='LGPL v3',
-    author='Miguel de la Varga, Alexander Zimmerman, Elisa Heim, Alexander Schaaf, Fabian Stamm, Florian Wellmann',
-    author_email='varga@aices.rwth-aachen.de',
+    author='Miguel de la Varga, Alexander Zimmerman, Elisa Heim, Alexander Schaaf, Fabian Stamm, Florian Wellmann, Jan Niederau, Andrew Annex, Alexander Juestel',
+    author_email='miguel@terranigma-solutions.com',
     description='An Open-source, Python-based 3-D structural geological modeling software.',
+    long_description='GemPy is a Python-based, open-source geomodeling library. It is capable of constructing complex 3D geological models of folded structures, fault networks and unconformities, based on the underlying powerful implicit representation approach.' ,
     keywords=['geology', '3-D modeling', 'structural geology', 'uncertainty']
 )
```

### Comparing `gempy-2.2b10.dev1/test/test_addons/test_gempy_to_rexfile.py` & `gempy-2.3.0/test/test_addons/DEP/te_gempy_to_rexfile.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,44 +1,44 @@
-import pooch
-import pytest
-import sys, os
-
-from gempy.addons.gempy_to_rexfile import GemPyToRex, geomodel_to_rex
-
-import gempy
-
-input_path = os.path.dirname(__file__)+'/../input_data'
-
-
-@pytest.mark.skipif("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true",
-                    reason="Skipping this test on Travis CI.")
-class TestGemPyToRexClass:
-    """Test the class that control the rexfile encoding"""
-
-    def test_grab_mesh(self, unconformity_model_topo):
-        gempy_to_rex = GemPyToRex()
-        surfaces = gempy_to_rex.grab_meshes(unconformity_model_topo)
-        print(surfaces)
-
-    def test_gempymesh_to_rex(self, unconformity_model_topo):
-        gempy_to_rex = GemPyToRex()
-        surfaces = gempy_to_rex.grab_meshes(unconformity_model_topo)
-
-        gempy_to_rex.gempy_meshes_to_rex(surfaces)
-
-    def test_gempy_to_rex(self, unconformity_model_topo):
-        gempy_to_rex = GemPyToRex()
-        bytes = gempy_to_rex(unconformity_model_topo, app='RexView')
-
-        print(bytes)
-
-    def test_gempy_to_rex_old(self, unconformity_model_topo):
-        bytes2 = geomodel_to_rex(unconformity_model_topo, False)
-
-    def test_gempy_to_rex_with_topo(self):
-        model_file = pooch.retrieve(url="https://github.com/cgre-aachen/gempy_data/raw/master/data/gempy_models/combination.zip",
-                                    known_hash=None)
-
-        geo_model = gempy.load_model(name='combination', path=model_file)
-        gempy_to_rex = GemPyToRex()
-        bytes = gempy_to_rex(geo_model)
+import pytest
+import sys, os
+
+from gempy.addons.gempy_to_rexfile import GemPyToRex, geomodel_to_rex
+
+import gempy
+
+input_path = os.path.dirname(__file__)+'/../input_data'
+
+
+@pytest.mark.skipif("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true",
+                    reason="Skipping this test on Travis CI.")
+class TestGemPyToRexClass:
+    """Test the class that control the rexfile encoding"""
+
+    def test_grab_mesh(self, unconformity_model_topo):
+        gempy_to_rex = GemPyToRex()
+        surfaces = gempy_to_rex.grab_meshes(unconformity_model_topo)
+        print(surfaces)
+
+    def test_gempymesh_to_rex(self, unconformity_model_topo):
+        gempy_to_rex = GemPyToRex()
+        surfaces = gempy_to_rex.grab_meshes(unconformity_model_topo)
+
+        gempy_to_rex.gempy_meshes_to_rex(surfaces)
+
+    def test_gempy_to_rex(self, unconformity_model_topo):
+        gempy_to_rex = GemPyToRex()
+        bytes = gempy_to_rex(unconformity_model_topo, app='RexView')
+
+        print(bytes)
+
+    def test_gempy_to_rex_old(self, unconformity_model_topo):
+        bytes2 = geomodel_to_rex(unconformity_model_topo, False)
+
+    def test_gempy_to_rex_with_topo(self):
+        import pooch
+        model_file = pooch.retrieve(url="https://github.com/cgre-aachen/gempy_data/raw/aesara_data/data/gempy_models/combination.zip",
+                                    known_hash="e2fa667f2ad64d6027f513c4f801557681b0e318ee1e1fcf30fc1c7ed0c60faf")
+
+        geo_model = gempy.load_model(name='combination', path=model_file)
+        gempy_to_rex = GemPyToRex()
+        bytes = gempy_to_rex(geo_model)
         print(bytes)
```

### Comparing `gempy-2.2b10.dev1/test/test_addons/test_rex_cloud_api.py` & `gempy-2.3.0/test/test_addons/DEP/est_rex_cloud_api.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,93 +1,96 @@
-import pytest
-import sys, os
-
-from gempy.addons.gempy_to_rexfile import GemPyToRex
-
-sys.path.append("../..")
-import gempy
-request = pytest.importorskip("requests")
-from gempy.addons import gempy_to_rexfile as gtr
-from gempy.addons import rex_api
-pyqrcode = pytest.importorskip("pyqrcode")
-input_path = os.path.dirname(__file__)+'/../input_data'
-
-
-@pytest.mark.skipif("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true",
-                    reason="Skipping this test on Travis CI.")
-class TestGemPyToREX:
-    @pytest.fixture(scope='module')
-    def geo_model(self, model_horizontal_two_layers):
-        geo_data = model_horizontal_two_layers
-
-        # Compute model
-        sol = gempy.compute_model(geo_data, compute_mesh_options={'rescale': True})
-
-        return geo_data
-
-    def test_write_header(self):
-        header_bytes = gtr.write_file_header_block(3, 1)
-        if False:
-            gtr.write_file(header_bytes, './rexfiles/header_test')
-
-    def test_write_mesh(self, geo_model):
-        mesh_header_size = 128
-        file_header_size = 86
-        ver, tri = geo_model.solutions.vertices[0], geo_model.solutions.edges[0]
-
-        ver_ravel, tri_ravel, n_vtx_coord, n_triangles = gtr.mesh_preprocess(ver, tri)
-        data_block_size_no_header = (n_vtx_coord + n_triangles) * 4 + mesh_header_size
-
-        # Write header
-        header_bytes = gtr.write_file_header_block(n_data_blocks=1,
-                                            size_data_blocks=data_block_size_no_header+gtr.rexDataBlockHeaderSize,
-                                            start_data=file_header_size)
-
-        # Write data block
-        data_bytes = gtr.write_data_block_header(size_data=data_block_size_no_header,
-                                          data_id=1, data_type=3, version_data=1)
-
-        # Write mesh block
-        mesh_header_bytes = gtr.write_mesh_header(n_vtx_coord/3, n_triangles/3,
-                                                  start_vtx_coord=gtr.mesh_header_size,
-                                                  start_nor_coord=gtr.mesh_header_size + n_vtx_coord*4,
-                                                  start_tex_coord=gtr.mesh_header_size + n_vtx_coord*4,
-                                                  start_vtx_colors=gtr.mesh_header_size + n_vtx_coord*4,
-                                                  start_triangles=gtr.mesh_header_size + n_vtx_coord*4,
-                                                  name='test_a')
-
-        mesh_block_bytes = gtr.write_mesh_coordinates(ver_ravel, tri_ravel)
-
-        all_bytes = header_bytes + data_bytes + mesh_header_bytes + mesh_block_bytes
-
-        if False:
-            gtr.write_file(all_bytes, './rexfiles/one_mesh_test')
-
-    def TEST_rex_cloud_api(self):
-        import datetime
-        timestamp = datetime.datetime.now()
-        project_name = str(timestamp)
-        rex_api.RexAPI(project_name)
-
-    def test_geo_model_to_rex(self, geo_model):
-        rex_bytes = gtr.geomodel_to_rex(geo_model)
-        print(len(rex_bytes['A']))
-        assert len(rex_bytes['A']) == 235706
-
-    def test_rex_bytes_to_file(self, geo_model):
-        rex_bytes = gtr.geomodel_to_rex(geo_model)
-        gtr.write_rex(rex_bytes, path=os.path.dirname(__file__) + '/rexfiles/gtr_test')
-
-    def test_rex_bytes_to_file_except(self):
-        model = gempy.create_data(extent=[0,10,0,10,0,10])
-        model.set_default_surfaces()
-        model._surfaces.df['isActive'] = False
-        with pytest.raises(RuntimeError):
-            rex_bytes = gtr.geomodel_to_rex(model)
-
-    @pytest.mark.skip(reason="Needs token and secret. (@leguark they are in notion)")
-    def test_plot_ar(self, geo_model):
-        tag = gempy.plot.plot_ar(geo_model,
-                                 api_token='foo', \
-                                 project_name='Alesmodel',
-                                 secret='bar')
-        print(tag.display_tag(reverse=False))
+import pytest
+import sys, os
+
+from gempy.addons.gempy_to_rexfile import GemPyToRex
+
+sys.path.append("../../..")
+import gempy
+
+request = pytest.importorskip("requests")
+from gempy.addons import gempy_to_rexfile as gtr
+from gempy.addons import rex_api
+
+pyqrcode = pytest.importorskip("pyqrcode")
+input_path = os.path.dirname(__file__) + '/../input_data'
+
+
+@pytest.mark.skipif("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true",
+                    reason="Skipping this test on Travis CI.")
+class TestGemPyToREX:
+    @pytest.fixture(scope='module')
+    def geo_model(self, model_horizontal_two_layers):
+        geo_data = model_horizontal_two_layers
+
+        # Compute model
+        sol = gempy.compute_model(geo_data, compute_mesh_options={'rescale': True})
+
+        return geo_data
+
+    def test_write_header(self):
+        header_bytes = gtr.write_file_header_block(3, 1)
+        if False:
+            gtr.write_file(header_bytes, 'DEP/rexfiles/header_test')
+
+    def test_write_mesh(self, geo_model):
+        mesh_header_size = 128
+        file_header_size = 86
+        ver, tri = geo_model.solutions.vertices[0], geo_model.solutions.edges[0]
+
+        ver_ravel, tri_ravel, n_vtx_coord, n_triangles = gtr.mesh_preprocess(ver, tri)
+        data_block_size_no_header = (n_vtx_coord + n_triangles) * 4 + mesh_header_size
+
+        # Write header
+        header_bytes = gtr.write_file_header_block(n_data_blocks=1,
+                                                   size_data_blocks=data_block_size_no_header + gtr.rexDataBlockHeaderSize,
+                                                   start_data=file_header_size)
+
+        # Write data block
+        data_bytes = gtr.write_data_block_header(size_data=data_block_size_no_header,
+                                                 data_id=1, data_type=3, version_data=1)
+
+        # Write mesh block
+        mesh_header_bytes = gtr.write_mesh_header(n_vtx_coord / 3, n_triangles / 3,
+                                                  start_vtx_coord=gtr.mesh_header_size,
+                                                  start_nor_coord=gtr.mesh_header_size + n_vtx_coord * 4,
+                                                  start_tex_coord=gtr.mesh_header_size + n_vtx_coord * 4,
+                                                  start_vtx_colors=gtr.mesh_header_size + n_vtx_coord * 4,
+                                                  start_triangles=gtr.mesh_header_size + n_vtx_coord * 4,
+                                                  name='test_a')
+
+        mesh_block_bytes = gtr.write_mesh_coordinates(ver_ravel, tri_ravel)
+
+        all_bytes = header_bytes + data_bytes + mesh_header_bytes + mesh_block_bytes
+
+        if False:
+            gtr.write_file(all_bytes, 'DEP/rexfiles/one_mesh_test')
+
+    def TEST_rex_cloud_api(self):
+        import datetime
+        timestamp = datetime.datetime.now()
+        project_name = str(timestamp)
+        rex_api.RexAPI(project_name)
+
+    def test_geo_model_to_rex(self, geo_model):
+        rex_bytes = gtr.geomodel_to_rex(geo_model)
+        print(len(rex_bytes['A']))
+        assert len(rex_bytes['A']) == 235706
+
+    def test_rex_bytes_to_file(self, geo_model):
+        rex_bytes = gtr.geomodel_to_rex(geo_model)
+        gtr.write_rex(rex_bytes, path=os.path.dirname(__file__) + '/rexfiles/gtr_test')
+
+    def test_rex_bytes_to_file_except(self):
+        model = gempy.create_data(extent=[0, 10, 0, 10, 0, 10],
+                                  resolution=[50, 50, 50])
+        model.set_default_surfaces()
+        model._surfaces.df['isActive'] = False
+        with pytest.raises(RuntimeError):
+            rex_bytes = gtr.geomodel_to_rex(model)
+
+    @pytest.mark.skip(reason="Needs token and secret. (@leguark they are in notion)")
+    def test_plot_ar(self, geo_model):
+        tag = gempy.plot.plot_ar(geo_model,
+                                 api_token='foo', \
+                                 project_name='Alesmodel',
+                                 secret='bar')
+        print(tag.display_tag(reverse=False))
```

### Comparing `gempy-2.2b10.dev1/test/test_anisotropies/test_anisotropies.py` & `gempy-2.3.0/test/test_anisotropies/test_anisotropies.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,134 +1,136 @@
-import numpy as np
-import pytest
-
-import gempy as gp
-import matplotlib.pyplot as plt
-import os
-
-# Input files
-root = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/turner_syncline/'
-path = os.path.dirname(__file__) + '/../input_data/'
-orientations_file = root + 'orientations_clean.csv'
-contacts_file = root + 'contacts_clean.csv'
-fp = path + 'dtm_rp.tif'
-series_file = root + 'all_sorts_clean.csv'
-
-bbox = (500000, 7490000, 545000, 7520000)
-model_base = -1500  # Original 3200
-model_top = 800
-
-gdal = pytest.importorskip("gdal")
-
-
-@pytest.fixture(scope='module')
-def model():
-    geo_model = gp.create_model('test_map2Loop')
-    gp.init_data(
-        geo_model,
-        extent=[bbox[0], bbox[2], bbox[1], bbox[3], model_base, model_top],
-        resolution=[50, 50, 80],
-        path_o=orientations_file,
-        path_i=contacts_file
-    )
-
-    # Load Topology
-
-    geo_model.set_topography(source='gdal', filepath=fp)
-
-    # Stack Processing
-    contents = np.genfromtxt(series_file,
-                             delimiter=',', dtype='U100')[1:, 4:-1]
-
-    map_series_to_surfaces = {}
-    for pair in contents:
-        map_series_to_surfaces.setdefault(pair[1], []).append(pair[0])
-
-    gp.map_stack_to_surfaces(geo_model, map_series_to_surfaces,
-                             remove_unused_series=False)
-
-    gp.plot_3d(geo_model, ve=None, show_topography=False
-               , image=True, show_lith=False,
-               kwargs_plot_data={'arrow_size': 300})
-
-    return geo_model
-
-
-def test_axial_anisotropy_type_data(model):
-    geo_model = model
-
-    geo_model._rescaling.toggle_axial_anisotropy()
-    # gp.compute_model(geo_model, compute_mesh_options={'mask_topography': False})
-
-    geo_model.surface_points.df[['X', 'Y', 'Z']] = geo_model.surface_points.df[['X_c', 'Y_c',
-                                                                                'Z_c']]
-    geo_model.orientations.df[['X', 'Y', 'Z']] = geo_model.orientations.df[['X_c', 'Y_c',
-                                                                            'Z_c']]
-
-    # This is a hack
-    geo_model._grid.topography.extent = geo_model._grid.extent_c
-
-    geo_model.set_regular_grid(geo_model._grid.extent_c, [50, 50, 50])
-
-    gp.plot_3d(geo_model, ve=None, show_topography=False
-               , image=True, show_lith=False,
-               kwargs_plot_data={'arrow_size': 10})
-
-
-def test_axial_anisotropy_type_extent(model):
-    geo_model = model
-
-    geo_model._rescaling.toggle_axial_anisotropy(type='extent')
-    # gp.compute_model(geo_model, compute_mesh_options={'mask_topography': False})
-
-    geo_model.surface_points.df[['X', 'Y', 'Z']] = geo_model.surface_points.df[['X_c', 'Y_c',
-                                                                                'Z_c']]
-    geo_model.orientations.df[['X', 'Y', 'Z']] = geo_model.orientations.df[['X_c', 'Y_c',
-                                                                            'Z_c']]
-
-    # This is a hack
-    geo_model._grid.topography.extent = geo_model._grid.extent_c
-
-    geo_model.set_regular_grid(geo_model._grid.extent_c, [50, 50, 50])
-
-    gp.plot_3d(geo_model, ve=None, show_topography=False
-               , image=True, show_lith=False,
-               kwargs_plot_data={'arrow_size': 10})
-
-
-def test_axial_anisotropy(model):
-    # Location box
-
-    geo_model = model
-    geo_model._rescaling.toggle_axial_anisotropy()
-    # gp.compute_model(geo_model, compute_mesh_options={'mask_topography': False})
-
-    geo_model.surface_points.df[['X', 'Y', 'Z']] = geo_model.surface_points.df[['X_c', 'Y_c',
-                                                                                'Z_c']]
-    geo_model.orientations.df[['X', 'Y', 'Z']] = geo_model.orientations.df[['X_c', 'Y_c',
-                                                                            'Z_c']]
-
-    # This is a hack
-    geo_model._grid.topography.extent = geo_model._grid.extent_c
-
-    geo_model.set_regular_grid(geo_model._grid.extent_c, [50, 50, 50])
-    geo_model.modify_kriging_parameters('range', 0.1)
-    geo_model.modify_kriging_parameters('drift equations', [9, 9, 9, 9, 9])
-
-    geo_model.modify_surface_points(
-        geo_model.surface_points.df.index,
-        smooth=0.001
-    )
-
-    gp.set_interpolator(geo_model, theano_optimizer='fast_run', dtype='float64')
-    gp.compute_model(geo_model, compute_mesh_options={'mask_topography': False,
-                                                      'masked_marching_cubes': False})
-
-    gp.plot_2d(geo_model,
-               section_names=['topography'],
-               show_topography=True,
-               )
-    plt.show()
-
-    gp.plot_3d(geo_model, ve=None, show_topography=False, image=True, show_lith=False,
-               kwargs_plot_data={'arrow_size': 10}
-               )
+import numpy as np
+import pytest
+
+import gempy as gp
+import matplotlib as mpl
+mpl.use('Agg')
+import matplotlib.pyplot as plt
+import os
+
+# Input files
+root = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/turner_syncline/'
+path = os.path.dirname(__file__) + '/../input_data/'
+orientations_file = root + 'orientations_clean.csv'
+contacts_file = root + 'contacts_clean.csv'
+fp = path + 'dtm_rp.tif'
+series_file = root + 'all_sorts_clean.csv'
+
+bbox = (500000, 7490000, 545000, 7520000)
+model_base = -1500  # Original 3200
+model_top = 800
+
+gdal = pytest.importorskip("gdal")
+
+
+@pytest.fixture(scope='module')
+def model():
+    geo_model = gp.create_model('test_map2Loop')
+    gp.init_data(
+        geo_model,
+        extent=[bbox[0], bbox[2], bbox[1], bbox[3], model_base, model_top],
+        resolution=[50, 50, 80],
+        path_o=orientations_file,
+        path_i=contacts_file
+    )
+
+    # Load Topology
+
+    geo_model.set_topography(source='gdal', filepath=fp)
+
+    # Stack Processing
+    contents = np.genfromtxt(series_file,
+                             delimiter=',', dtype='U100')[1:, 4:-1]
+
+    map_series_to_surfaces = {}
+    for pair in contents:
+        map_series_to_surfaces.setdefault(pair[1], []).append(pair[0])
+
+    gp.map_stack_to_surfaces(geo_model, map_series_to_surfaces,
+                             remove_unused_series=False)
+
+    gp.plot_3d(geo_model, ve=None, show_topography=False
+               , image=True, show_lith=False,
+               kwargs_plot_data={'arrow_size': 300})
+
+    return geo_model
+
+
+def test_axial_anisotropy_type_data(model):
+    geo_model = model
+
+    geo_model._rescaling.toggle_axial_anisotropy()
+    # gp.compute_model(geo_model, compute_mesh_options={'mask_topography': False})
+
+    geo_model.surface_points.df[['X', 'Y', 'Z']] = geo_model.surface_points.df[['X_c', 'Y_c',
+                                                                                'Z_c']]
+    geo_model.orientations.df[['X', 'Y', 'Z']] = geo_model.orientations.df[['X_c', 'Y_c',
+                                                                            'Z_c']]
+
+    # This is a hack
+    geo_model._grid.topography.extent = geo_model._grid.extent_c
+
+    geo_model.set_regular_grid(geo_model._grid.extent_c, [50, 50, 50])
+
+    gp.plot_3d(geo_model, ve=None, show_topography=False
+               , image=True, show_lith=False,
+               kwargs_plot_data={'arrow_size': 10})
+
+
+def test_axial_anisotropy_type_extent(model):
+    geo_model = model
+
+    geo_model._rescaling.toggle_axial_anisotropy(type='extent')
+    # gp.compute_model(geo_model, compute_mesh_options={'mask_topography': False})
+
+    geo_model.surface_points.df[['X', 'Y', 'Z']] = geo_model.surface_points.df[['X_c', 'Y_c',
+                                                                                'Z_c']]
+    geo_model.orientations.df[['X', 'Y', 'Z']] = geo_model.orientations.df[['X_c', 'Y_c',
+                                                                            'Z_c']]
+
+    # This is a hack
+    geo_model._grid.topography.extent = geo_model._grid.extent_c
+
+    geo_model.set_regular_grid(geo_model._grid.extent_c, [50, 50, 50])
+
+    gp.plot_3d(geo_model, ve=None, show_topography=False
+               , image=True, show_lith=False,
+               kwargs_plot_data={'arrow_size': 10})
+
+
+def test_axial_anisotropy(model):
+    # Location box
+
+    geo_model = model
+    geo_model._rescaling.toggle_axial_anisotropy()
+    # gp.compute_model(geo_model, compute_mesh_options={'mask_topography': False})
+
+    geo_model.surface_points.df[['X', 'Y', 'Z']] = geo_model.surface_points.df[['X_c', 'Y_c',
+                                                                                'Z_c']]
+    geo_model.orientations.df[['X', 'Y', 'Z']] = geo_model.orientations.df[['X_c', 'Y_c',
+                                                                            'Z_c']]
+
+    # This is a hack
+    geo_model._grid.topography.extent = geo_model._grid.extent_c
+
+    geo_model.set_regular_grid(geo_model._grid.extent_c, [50, 50, 50])
+    geo_model.modify_kriging_parameters('range', 0.1)
+    geo_model.modify_kriging_parameters('drift equations', [9, 9, 9, 9, 9])
+
+    geo_model.modify_surface_points(
+        geo_model.surface_points.df.index,
+        smooth=0.001
+    )
+
+    gp.set_interpolator(geo_model, aesara_optimizer='fast_run', dtype='float64')
+    gp.compute_model(geo_model, compute_mesh_options={'mask_topography': False,
+                                                      'masked_marching_cubes': False})
+
+    gp.plot_2d(geo_model,
+               section_names=['topography'],
+               show_topography=True,
+               )
+    plt.show()
+
+    gp.plot_3d(geo_model, ve=None, show_topography=False, image=True, show_lith=False,
+               kwargs_plot_data={'arrow_size': 10}
+               )
```

### Comparing `gempy-2.2b10.dev1/test/test_api/test_geometry_api.py` & `gempy-2.3.0/test/test_api/test_geometry_api.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,111 +1,113 @@
-import gempy as gp
-import numpy as np
-import os
-input_path = os.path.dirname(__file__) + '/../../examples/data'
-
-
-def test_set_orientations():
-    # Importing the data from CSV-files and setting extent and resolution
-    geo_data = gp.create_data(extent=[0, 2000, 0, 2000, 0, 2000], resolution=[50, 50, 50],
-                              path_o=input_path + '/input_data/tut_chapter1/simple_fault_model_orientations.csv',
-                              path_i=input_path + '/input_data/tut_chapter1/simple_fault_model_points.csv')
-
-    gp.get_data(geo_data)
-
-    # Assigning series to formations as well as their order (timewise)
-    gp.map_stack_to_surfaces(geo_data, {"Fault_Series": 'Main_Fault',
-                                         "Strat_Series": ('Sandstone_2', 'Siltstone')})
-
-    geo_data._orientations.create_orientation_from_surface_points(geo_data.surface_points, [0, 1, 2])
-
-    gp.set_orientation_from_surface_points(geo_data, [0, 1, 2])
-
-def test_select_nearest_surface_points():
-    data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
-    path_to_data = data_path + "/data/input_data/jan_models/"
-
-    geo_data = gp.create_data('fault', extent=[0, 1000, 0, 1000, 0, 1000],
-                              resolution=[50, 50, 50],
-                              path_o=path_to_data + "model5_orientations.csv",
-                              path_i=path_to_data + "model5_surface_points.csv")
-
-    # Assigning series to formations as well as their order (timewise)
-    gp.map_stack_to_surfaces(geo_data, {"Fault_Series": 'fault',
-                                        "Strat_Series": ('rock2', 'rock1')})
-    geo_data.set_is_fault(['Fault_Series'])
-
-    # detect fault names
-    f_id = geo_data._faults.df.index.categories[
-        geo_data._faults.df.isFault.values]
-    # find fault points
-    fault_poi = geo_data._surface_points.df[
-        geo_data._surface_points.df.series.isin(f_id)]
-
-    # find neighbours
-    knn = gp.select_nearest_surfaces_points(geo_data, fault_poi, 1)
-    radius = gp.select_nearest_surfaces_points(geo_data, fault_poi, 200.)
-
-    # sort neighbours, necessary for equal testing
-    knn = [k.sort_values() for k in knn]
-    radius = [r.sort_values() for r in radius]
-
-    # define reference
-    reference = [[16,17],[16,17],[18,19],[18,19],[20,21],[20,21]]
-
-    assert np.array_equal(reference, knn) and np.array_equal(reference, radius)
-
-
-def test_set_orientation_from_neighbours():
-    data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
-    path_to_data = data_path + "/data/input_data/jan_models/"
-
-    geo_data = gp.create_data('fault', extent=[0, 1000, 0, 1000, 0, 1000],
-                              resolution=[50, 50, 50],
-                          path_o=path_to_data + "model5_orientations.csv",
-                          path_i=path_to_data + "model5_surface_points.csv")
-
-    # Assigning series to formations as well as their order (timewise)
-    gp.map_stack_to_surfaces(geo_data, {"Fault_Series": 'fault',
-                                    "Strat_Series": ('rock2', 'rock1')})
-    geo_data.set_is_fault(['Fault_Series'])
-
-    # detect fault names
-    f_id = geo_data._faults.df.index.categories[
-        geo_data._faults.df.isFault.values]
-    # find fault points
-    fault_poi = geo_data._surface_points.df[
-        geo_data._surface_points.df.series.isin(f_id)]
-    # find neighbours
-    neighbours = gp.select_nearest_surfaces_points(geo_data, fault_poi, 5)
-    # calculate one fault orientation
-    gp.set_orientation_from_neighbours(geo_data, neighbours[1])
-    # find the calculated orientation
-    test = geo_data._orientations.df.sort_index().iloc[-1][['dip', 'azimuth']].values
-
-    # calculate reference
-    reference = [90-np.arctan(0.5)/np.pi*180, 90]
-
-    assert np.array_equal(reference, test)
-
-def test_set_orientation_from_neighbours_all():
-    data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
-    path_to_data = data_path + "/data/input_data/jan_models/"
-
-    geo_data = gp.create_data('fault', extent=[0, 1000, 0, 1000, 0, 1000],
-                              resolution=[50, 50, 50],
-                          path_o=path_to_data + "model5_orientations.csv",
-                          path_i=path_to_data + "model5_surface_points.csv")
-
-    # count orientations before orientation calculation
-    length_pre = geo_data._orientations.df.shape[0]
-
-    # find neighbours
-    neighbours = gp.select_nearest_surfaces_points(geo_data, geo_data._surface_points.df, 2)
-    # calculate all fault orientations
-    gp.set_orientation_from_neighbours_all(geo_data, neighbours)
-
-    # count orientations after orientation calculation
-    length_after = geo_data._orientations.df.shape[0]
-
-    assert np.array_equal(geo_data._surface_points.df.shape[0],
-                          length_after-length_pre)
+import gempy as gp
+import numpy as np
+import os
+input_path = os.path.dirname(__file__) + '/../../examples/data'
+
+
+def test_set_orientations():
+    # Importing the data from CSV-files and setting extent and resolution
+    geo_data = gp.create_data(extent=[0, 2000, 0, 2000, 0, 2000], resolution=[50, 50, 50],
+                              path_o=input_path + '/input_data/tut_chapter1/simple_fault_model_orientations.csv',
+                              path_i=input_path + '/input_data/tut_chapter1/simple_fault_model_points.csv')
+
+    gp.get_data(geo_data)
+
+    # Assigning series to formations as well as their order (timewise)
+    gp.map_stack_to_surfaces(geo_data, {"Fault_Series": 'Main_Fault',
+                                         "Strat_Series": ('Sandstone_2', 'Siltstone')})
+
+    geo_data._orientations.create_orientation_from_surface_points(geo_data.surface_points, [0, 1, 2])
+
+    gp.set_orientation_from_surface_points(geo_data, [0, 1, 2])
+    
+
+def test_select_nearest_surface_points():
+    data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
+    path_to_data = data_path + "/data/input_data/jan_models/"
+
+    geo_data = gp.create_data('fault', extent=[0, 1000, 0, 1000, 0, 1000],
+                              resolution=[50, 50, 50],
+                              path_o=path_to_data + "model5_orientations.csv",
+                              path_i=path_to_data + "model5_surface_points.csv")
+
+    # Assigning series to formations as well as their order (timewise)
+    gp.map_stack_to_surfaces(geo_data, {"Fault_Series": 'fault',
+                                        "Strat_Series": ('rock2', 'rock1')})
+    geo_data.set_is_fault(['Fault_Series'])
+
+    # detect fault names
+    f_id = geo_data._faults.df.index.categories[
+        geo_data._faults.df.isFault.values]
+    # find fault points
+    fault_poi = geo_data._surface_points.df[
+        geo_data._surface_points.df.series.isin(f_id)]
+
+    # find neighbours
+    knn = gp.select_nearest_surfaces_points(geo_data, fault_poi, 1)
+    radius = gp.select_nearest_surfaces_points(geo_data, fault_poi, 200.)
+
+    # sort neighbours, necessary for equal testing
+    knn = [k.sort_values() for k in knn]
+    radius = [r.sort_values() for r in radius]
+
+    # define reference
+    reference = [[16,17],[16,17],[18,19],[18,19],[20,21],[20,21]]
+
+    assert np.array_equal(reference, knn) and np.array_equal(reference, radius)
+
+
+def test_set_orientation_from_neighbours():
+    data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
+    path_to_data = data_path + "/data/input_data/jan_models/"
+
+    geo_data = gp.create_data('fault', extent=[0, 1000, 0, 1000, 0, 1000],
+                              resolution=[50, 50, 50],
+                          path_o=path_to_data + "model5_orientations.csv",
+                          path_i=path_to_data + "model5_surface_points.csv")
+
+    # Assigning series to formations as well as their order (timewise)
+    gp.map_stack_to_surfaces(geo_data, {"Fault_Series": 'fault',
+                                    "Strat_Series": ('rock2', 'rock1')})
+    geo_data.set_is_fault(['Fault_Series'])
+
+    # detect fault names
+    f_id = geo_data._faults.df.index.categories[
+        geo_data._faults.df.isFault.values]
+    # find fault points
+    fault_poi = geo_data._surface_points.df[
+        geo_data._surface_points.df.series.isin(f_id)]
+    # find neighbours
+    neighbours = gp.select_nearest_surfaces_points(geo_data, fault_poi, 5)
+    # calculate one fault orientation
+    gp.set_orientation_from_neighbours(geo_data, neighbours[1])
+    # find the calculated orientation
+    test = geo_data._orientations.df.sort_index().iloc[-1][['dip', 'azimuth']].values
+
+    # calculate reference
+    reference = [90-np.arctan(0.5)/np.pi*180, 90]
+
+    assert np.array_equal(reference, test)
+
+
+def test_set_orientation_from_neighbours_all():
+    data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'
+    path_to_data = data_path + "/data/input_data/jan_models/"
+
+    geo_data = gp.create_data('fault', extent=[0, 1000, 0, 1000, 0, 1000],
+                              resolution=[50, 50, 50],
+                          path_o=path_to_data + "model5_orientations.csv",
+                          path_i=path_to_data + "model5_surface_points.csv")
+
+    # count orientations before orientation calculation
+    length_pre = geo_data._orientations.df.shape[0]
+
+    # find neighbours
+    neighbours = gp.select_nearest_surfaces_points(geo_data, geo_data._surface_points.df, 2)
+    # calculate all fault orientations
+    gp.set_orientation_from_neighbours_all(geo_data, neighbours)
+
+    # count orientations after orientation calculation
+    length_after = geo_data._orientations.df.shape[0]
+
+    assert np.array_equal(geo_data._surface_points.df.shape[0],
+                          length_after-length_pre)
```

### Comparing `gempy-2.2b10.dev1/test/test_assets/test_gravity.py` & `gempy-2.3.0/test/test_assets/test_gravity.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,37 +1,35 @@
-# These two lines are necessary only if GemPy is not installed
-# sys.path.append("../..")
-
-# Importing GemPy
-import gempy as gp
-
-# Importing auxiliary libraries
-import numpy as np
-
-
-def test_gravity(interpolator_gravity):
-    geo_model = gp.create_model('2-layers')
-    gp.init_data(geo_model, extent=[0, 12, -2, 2, 0, 4], resolution=[500, 1, 500])
-    geo_model.add_surfaces('surface 1')
-    geo_model.add_surfaces('surface 2')
-    geo_model.add_surfaces('basement')
-    dz = geo_model._grid.regular_grid.dz
-    geo_model._surfaces.add_surfaces_values([dz, 0, 0], ['dz'])
-    geo_model._surfaces.add_surfaces_values([2.6, 2.4, 3.2], ['density'])
-    geo_model.add_surface_points(3, 0, 3.05, 'surface 1')
-    geo_model.add_surface_points(9, 0, 3.05, 'surface 1')
-
-    geo_model.add_surface_points(3, 0, 1.02, 'surface 2')
-    geo_model.add_surface_points(9, 0, 1.02, 'surface 2')
-
-    geo_model.add_orientations(6, 0, 4, 'surface 1', [0, 0, 1])
-    device_loc = np.array([[6, 0, 4]])
-
-    geo_model.set_centered_grid(device_loc, resolution=[10, 10, 100], radius=16000)
-    geo_model.set_theano_function(interpolator_gravity)
-    geo_model._interpolator.set_theano_shared_gravity(pos_density=2)
-    print(geo_model._additional_data)
-    gp.compute_model(geo_model, set_solutions=True, compute_mesh=False)
-    print(geo_model.solutions.fw_gravity)
-    np.testing.assert_almost_equal(geo_model.solutions.fw_gravity,
-                                   np.array([-1624.1714]), decimal=4)
-
+# These two lines are necessary only if GemPy is not installed
+# sys.path.append("../..")
+
+# Importing GemPy
+import gempy as gp
+
+# Importing auxiliary libraries
+import numpy as np
+
+
+def test_gravity(interpolator_gravity):
+    geo_model = gp.create_model('2-layers')
+    gp.init_data(geo_model, extent=[0, 12, -2, 2, 0, 4], resolution=[500, 1, 500])
+    geo_model.add_surfaces('surface 1')
+    geo_model.add_surfaces('surface 2')
+    geo_model.add_surfaces('basement')
+    dz = geo_model._grid.regular_grid.dz
+    geo_model._surfaces.add_surfaces_values([dz, 0, 0], ['dz'])
+    geo_model._surfaces.add_surfaces_values([2.6, 2.4, 3.2], ['density'])
+    geo_model.add_surface_points(3, 0, 3.05, 'surface 1')
+    geo_model.add_surface_points(9, 0, 3.05, 'surface 1')
+
+    geo_model.add_surface_points(3, 0, 1.02, 'surface 2')
+    geo_model.add_surface_points(9, 0, 1.02, 'surface 2')
+
+    geo_model.add_orientations(6, 0, 4, 'surface 1', [0, 0, 1])
+    device_loc = np.array([[6, 0, 4]])
+
+    geo_model.set_centered_grid(device_loc, resolution=[10, 10, 100], radius=16000)
+    geo_model.set_aesara_function(interpolator_gravity)
+    geo_model._interpolator.set_aesara_shared_gravity(pos_density=2)
+    print(geo_model._additional_data)
+    gp.compute_model(geo_model, set_solutions=True, compute_mesh=False)
+    print(geo_model.solutions.fw_gravity)
+    np.testing.assert_almost_equal(geo_model.solutions.fw_gravity, np.array([-1624.1714]), decimal=4)
```

### Comparing `gempy-2.2b10.dev1/test/test_assets/test_magnetics.py` & `gempy-2.3.0/test/test_assets/test_magnetics.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,86 +1,85 @@
-# Importing GemPy
-import gempy as gp
-from gempy.assets.geophysics import MagneticsPreprocessing
-
-# Importing auxiliary libraries
-import numpy as np
-import pytest
-
-
-def test_magnetics_api(interpolator_magnetics):
-    # TODO add the check
-
-    geo_model = gp.create_model('test_center_grid_slicing')
-    geo_model.set_default_surfaces()
-    geo_model.add_surface_points(X=-1, Y=0, Z=0, surface='surface1')
-    geo_model.add_surface_points(X=1, Y=0, Z=0, surface='surface1')
-    geo_model.add_orientations(X=0, Y=0, Z=0, surface='surface1', pole_vector=(0, 0, 1))
-    geo_model._surfaces.add_surfaces_values([0.037289, 0.0297], ['susceptibility'])
-
-    # needed constants
-    mu_0 = 4.0 * np.pi * 10e-7  # magnetic permeability in free space [N/A^2]
-    cm = mu_0 / (4.0 * np.pi)  # constant for SI unit
-    incl = 77.0653  # NOAA
-    decl = 6.8116
-    B_ext = 52819.8506939139e-9  # T
-
-    geo_model.set_regular_grid(extent=[-5, 5, -5, 5, -5, 5], resolution=[5, 5, 5])
-    geo_model.set_centered_grid(np.array([[0, 0, 0]]), resolution=[10, 10, 15], radius=5000)
-    geo_model.set_theano_function(interpolator_magnetics)
-    geo_model._interpolator.set_theano_shared_magnetics(V='auto', pos_magnetics=1,
-                                                        incl= incl, decl=decl, B_ext=B_ext)
-
-    gp.compute_model(geo_model)
-    print(geo_model._interpolator.theano_graph.lg0.get_value())
-    print(geo_model.solutions.fw_magnetics)
-    np.testing.assert_almost_equal(geo_model.solutions.fw_magnetics,
-                                   np.array([473.7836]), decimal=4)
-    return geo_model
-
-
-@pytest.fixture(scope="module")
-def test_magnetics_no_regular_grid(interpolator_magnetics):
-    # TODO add the check
-
-    geo_model = gp.create_model('test_center_grid_slicing')
-    geo_model.set_default_surfaces()
-    geo_model.add_surface_points(X=-1, Y=0, Z=0, surface='surface1')
-    geo_model.add_surface_points(X=1, Y=0, Z=0, surface='surface1')
-    geo_model.add_orientations(X=0, Y=0, Z=0, surface='surface1', pole_vector=(0, 0, 1))
-    geo_model._surfaces.add_surfaces_values([0.037289, 0.0297], ['susceptibility'])
-
-    # needed constants
-    mu_0 = 4.0 * np.pi * 10e-7  # magnetic permeability in free space [N/A^2]
-    cm = mu_0 / (4.0 * np.pi)  # constant for SI unit
-    incl = 77.0653  # NOAA
-    decl = 6.8116
-    B_ext = 52819.8506939139e-9  # T
-
-    geo_model.set_centered_grid(np.array([0, 0, 0]), resolution=[10, 10, 15], radius=5000)
-
-    Vmodel = MagneticsPreprocessing(geo_model._grid.centered_grid).set_Vs_kernel()
-    # gp.set_interpolator(geo_model, output=['magnetics'])
-    geo_model.set_theano_function(interpolator_magnetics)
-    geo_model._interpolator.set_theano_shared_magnetics(V= Vmodel, pos_magnetics=1,
-                                                        incl= incl, decl=decl, B_ext=B_ext)
-
-    # geo_model.interpolator.theano_graph.V.set_value(Vmodel)
-    # geo_model.interpolator.theano_graph.incl.set_value(incl)
-    # geo_model.interpolator.theano_graph.decl.set_value(decl)
-    # geo_model.interpolator.theano_graph.B_ext.set_value(B_ext)
-
-    gp.compute_model(geo_model)
-    np.testing.assert_almost_equal(geo_model.solutions.fw_magnetics,
-                                   np.array([473.7836]), decimal=4)
-    gp.compute_model(geo_model)
-    return geo_model
-
-
-def test_center_grid_slicing(test_magnetics_no_regular_grid):
-    geo_model = test_magnetics_no_regular_grid
-
-    geo_model.set_centered_grid(np.array([[0, 0, 0],
-                                [1, 1, 1]]), resolution=[10, 10, 15], radius=5000)
-
-    gp.compute_model(geo_model)
-    print(geo_model._interpolator.theano_graph.lg0.get_value())
+# Importing GemPy
+import gempy as gp
+from gempy.assets.geophysics import MagneticsPreprocessing
+
+# Importing auxiliary libraries
+import numpy as np
+import pytest
+
+
+def test_magnetics_api(interpolator_magnetics):
+    # TODO add the check
+
+    geo_model = gp.create_model('test_center_grid_slicing')
+    geo_model.set_default_surfaces()
+    geo_model.add_surface_points(X=-1, Y=0, Z=0, surface='surface1')
+    geo_model.add_surface_points(X=1, Y=0, Z=0, surface='surface1')
+    geo_model.add_orientations(X=0, Y=0, Z=0, surface='surface1', pole_vector=(0, 0, 1))
+    geo_model._surfaces.add_surfaces_values([0.037289, 0.0297], ['susceptibility'])
+
+    # needed constants
+    mu_0 = 4.0 * np.pi * 10e-7  # magnetic permeability in free space [N/A^2]
+    cm = mu_0 / (4.0 * np.pi)  # constant for SI unit
+    incl = 77.0653  # NOAA
+    decl = 6.8116
+    B_ext = 52819.8506939139e-9  # T
+
+    geo_model.set_regular_grid(extent=[-5, 5, -5, 5, -5, 5], resolution=[5, 5, 5])
+    geo_model.set_centered_grid(np.array([[0, 0, 0]]), resolution=[10, 10, 15], radius=5000)
+    geo_model.set_aesara_function(interpolator_magnetics)
+    geo_model._interpolator.set_aesara_shared_magnetics(V='auto', pos_magnetics=1,
+                                                        incl= incl, decl=decl, B_ext=B_ext)
+
+    gp.compute_model(geo_model)
+    print(geo_model._interpolator.aesara_graph.lg0.get_value())
+    print(geo_model.solutions.fw_magnetics)
+    np.testing.assert_almost_equal(geo_model.solutions.fw_magnetics,
+                                   np.array([473.7836]), decimal=4)
+
+
+@pytest.fixture(scope="module")
+def test_magnetics_no_regular_grid(interpolator_magnetics):
+    # TODO add the check
+
+    geo_model = gp.create_model('test_center_grid_slicing')
+    geo_model.set_default_surfaces()
+    geo_model.add_surface_points(X=-1, Y=0, Z=0, surface='surface1')
+    geo_model.add_surface_points(X=1, Y=0, Z=0, surface='surface1')
+    geo_model.add_orientations(X=0, Y=0, Z=0, surface='surface1', pole_vector=(0, 0, 1))
+    geo_model._surfaces.add_surfaces_values([0.037289, 0.0297], ['susceptibility'])
+
+    # needed constants
+    mu_0 = 4.0 * np.pi * 10e-7  # magnetic permeability in free space [N/A^2]
+    cm = mu_0 / (4.0 * np.pi)  # constant for SI unit
+    incl = 77.0653  # NOAA
+    decl = 6.8116
+    B_ext = 52819.8506939139e-9  # T
+
+    geo_model.set_centered_grid(np.array([0, 0, 0]), resolution=[10, 10, 15], radius=5000)
+
+    Vmodel = MagneticsPreprocessing(geo_model._grid.centered_grid).set_Vs_kernel()
+    # gp.set_interpolator(geo_model, output=['magnetics'])
+    geo_model.set_aesara_function(interpolator_magnetics)
+    geo_model._interpolator.set_aesara_shared_magnetics(V= Vmodel, pos_magnetics=1,
+                                                        incl= incl, decl=decl, B_ext=B_ext)
+
+    # geo_model.interpolator.aesara_graph.V.set_value(Vmodel)
+    # geo_model.interpolator.aesara_graph.incl.set_value(incl)
+    # geo_model.interpolator.aesara_graph.decl.set_value(decl)
+    # geo_model.interpolator.aesara_graph.B_ext.set_value(B_ext)
+
+    gp.compute_model(geo_model)
+    np.testing.assert_almost_equal(geo_model.solutions.fw_magnetics,
+                                   np.array([473.7836]), decimal=4)
+    
+    return geo_model
+
+
+def test_center_grid_slicing(test_magnetics_no_regular_grid):
+    geo_model = test_magnetics_no_regular_grid
+
+    geo_model.set_centered_grid(np.array([[0, 0, 0],
+                                [1, 1, 1]]), resolution=[10, 10, 15], radius=5000)
+
+    gp.compute_model(geo_model)
+    print(geo_model._interpolator.aesara_graph.lg0.get_value())
```

### Comparing `gempy-2.2b10.dev1/test/test_assets/test_topology_np.py` & `gempy-2.3.0/test/test_assets/test_topology_np.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,80 +1,82 @@
-import pytest
-from gempy.assets import topology as tp
-import numpy as np
-import gempy as gp
-import matplotlib.pyplot as plt
-
-
-@pytest.fixture(scope='module')
-def topology_fabian(one_fault_model_solution):
-    """Return a GemPy Vista instance with basic geomodel attached."""
-    geo_model = one_fault_model_solution
-
-    edges, centroids = tp.compute_topology(geo_model, voxel_threshold=1)
-
-    return edges, centroids
-
-
-@pytest.fixture(scope='module')
-def topology_jan_unconf(unconformity_model):
-    geo_model = unconformity_model
-    gp.plot.plot_2d(unconformity_model)
-    plt.show()
-    edges, centroids = tp.compute_topology(geo_model, voxel_threshold=1)
-    return edges, centroids
-
-
-def assert_centroids(centroids, centroids_test):
-    for key in centroids_test.keys():
-        for i in range(2):
-            assert pytest.approx(centroids[key][i]) == centroids_test[key][i]
-
-
-@pytest.fixture
-def edges_fabian_test():
-    return {(1, 2), (4, 10), (2, 7), (6, 7), (5, 10), (4, 9), (4, 5), (2, 8),
-            (3, 8), (8, 9), (9, 10), (3, 9), (2, 3), (1, 6), (1, 7), (3, 4),
-            (7, 8)}
-
-
-@pytest.fixture
-def centroids_fabian_test():
-    return {1: np.array([12.16046912, 24.8310141, 40.65527994]),
-            2: np.array([8.93961983, 24.92955647, 28.73667536]),
-            3: np.array([7.95101873, 24.71784318, 23.43445153]),
-            4: np.array([6.85111073, 24.53773105, 17.19230117]),
-            5: np.array([4.92739115, 23.20962489, 7.25340731]),
-            6: np.array([35.9145365, 25.00458115, 39.16981059]),
-            7: np.array([33.7571116, 24.83114515, 26.98018478]),
-            8: np.array([32.89434051, 24.74326391, 21.65431227]),
-            9: np.array([32.08333333, 24.65390105, 15.5167301]),
-            10: np.array([31.04821962, 23.66595199, 5.89393366])}
-
-
-def test_edges_fabian(topology_fabian, edges_fabian_test):
-    assert topology_fabian[0] == edges_fabian_test
-
-
-def test_centroids_fabian(topology_fabian, centroids_fabian_test):
-    assert_centroids(topology_fabian[1], centroids_fabian_test)
-
-
-@pytest.fixture
-def edges_jan_unconf_test():
-    return {(1, 2), (1, 3), (1, 4), (2, 3), (3, 4)}
-
-
-@pytest.fixture
-def centroids_jan_unconf_test():
-    return {1: np.array([24.5, 20.5, 27.5]),
-            2: np.array([24.5, 20.5, 21.37869822]),
-            3: np.array([24.5, 20.5, 19.12100139]),
-            4: np.array([24.5, 20.5, 9.71685136])}
-
-
-def test_edges_jan_unconf(topology_jan_unconf, edges_jan_unconf_test):
-    assert topology_jan_unconf[0] == edges_jan_unconf_test
-
-
-def test_centroids_jan_unconf(topology_jan_unconf, centroids_jan_unconf_test):
-    assert_centroids(topology_jan_unconf[1], centroids_jan_unconf_test)
+import pytest
+from gempy.assets import topology as tp
+import numpy as np
+import gempy as gp
+import matplotlib as mpl
+mpl.use('Agg')
+import matplotlib.pyplot as plt
+
+
+@pytest.fixture(scope='module')
+def topology_fabian(one_fault_model_solution):
+    """Return a GemPy Vista instance with basic geomodel attached."""
+    geo_model = one_fault_model_solution
+
+    edges, centroids = tp.compute_topology(geo_model, voxel_threshold=1)
+
+    return edges, centroids
+
+
+@pytest.fixture(scope='module')
+def topology_jan_unconf(unconformity_model):
+    geo_model = unconformity_model
+    gp.plot.plot_2d(unconformity_model)
+    plt.show()
+    edges, centroids = tp.compute_topology(geo_model, voxel_threshold=1)
+    return edges, centroids
+
+
+def assert_centroids(centroids, centroids_test):
+    for key in centroids_test.keys():
+        for i in range(2):
+            assert pytest.approx(centroids[key][i]) == centroids_test[key][i]
+
+
+@pytest.fixture
+def edges_fabian_test():
+    return {(1, 2), (4, 10), (2, 7), (6, 7), (5, 10), (4, 9), (4, 5), (2, 8),
+            (3, 8), (8, 9), (9, 10), (3, 9), (2, 3), (1, 6), (1, 7), (3, 4),
+            (7, 8)}
+
+
+@pytest.fixture
+def centroids_fabian_test():
+    return {1: np.array([12.16046912, 24.8310141, 40.65527994]),
+            2: np.array([8.93961983, 24.92955647, 28.73667536]),
+            3: np.array([7.95101873, 24.71784318, 23.43445153]),
+            4: np.array([6.85111073, 24.53773105, 17.19230117]),
+            5: np.array([4.92739115, 23.20962489, 7.25340731]),
+            6: np.array([35.9145365, 25.00458115, 39.16981059]),
+            7: np.array([33.7571116, 24.83114515, 26.98018478]),
+            8: np.array([32.89434051, 24.74326391, 21.65431227]),
+            9: np.array([32.08333333, 24.65390105, 15.5167301]),
+            10: np.array([31.04821962, 23.66595199, 5.89393366])}
+
+
+def test_edges_fabian(topology_fabian, edges_fabian_test):
+    assert topology_fabian[0] == edges_fabian_test
+
+
+def test_centroids_fabian(topology_fabian, centroids_fabian_test):
+    assert_centroids(topology_fabian[1], centroids_fabian_test)
+
+
+@pytest.fixture
+def edges_jan_unconf_test():
+    return {(1, 2), (1, 3), (1, 4), (2, 3), (3, 4)}
+
+
+@pytest.fixture
+def centroids_jan_unconf_test():
+    return {1: np.array([24.5, 20.5, 27.5]),
+            2: np.array([24.5, 20.5, 21.37869822]),
+            3: np.array([24.5, 20.5, 19.12100139]),
+            4: np.array([24.5, 20.5, 9.71685136])}
+
+
+def test_edges_jan_unconf(topology_jan_unconf, edges_jan_unconf_test):
+    assert topology_jan_unconf[0] == edges_jan_unconf_test
+
+
+def test_centroids_jan_unconf(topology_jan_unconf, centroids_jan_unconf_test):
+    assert_centroids(topology_jan_unconf[1], centroids_jan_unconf_test)
```

### Comparing `gempy-2.2b10.dev1/test/test_community_bugs/test_community_bugs.py` & `gempy-2.3.0/test/test_community_bugs/test_community_bugs.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,105 +1,107 @@
-import pytest
-
-import gempy as gp
-import pandas as pd
-import matplotlib.pyplot as plt
-
-
-def test_issue_566():
-    from pyvista import set_plot_theme
-    set_plot_theme('document')
-
-    geo_model = gp.create_model('Model1')
-    geo_model = gp.init_data(geo_model, extent=[0, 791, 0, 200, -582, 0],
-                             resolution=[100, 10, 100])
-
-    geo_model.set_default_surfaces()
-    geo_model.add_surface_points(X=223, Y=0.01, Z=-94, surface='surface1')
-
-
-@pytest.mark.skip(reason="Expensive test. It should be ran manually.")
-def test_issue_569(data_path):
-    surface_points_df = df = pd.read_csv(data_path + "/coordinates_mwe.csv")
-    orientations_df = pd.read_csv(data_path + "/orientations_mwe.csv")
-
-    geo_model = gp.create_model("Deltatest")
-    gp.init_data(geo_model,
-                 [df.X.min() - 50, df.X.max() + 50, df.Y.min() - 50, df.Y.max() + 50,
-                  df.Z.min() - 50, df.Z.max() + 50, ], [50, 50, 50],
-                 surface_points_df=surface_points_df,
-                 orientations_df=orientations_df,
-                 default_values=True)
-
-    fault_list = []
-    series = {"Strat_Series": surface_points_df.loc[
-        ~surface_points_df["formation"].str.contains(
-            "fault"), "formation"].unique().tolist()}
-
-    for fault in surface_points_df.loc[
-        surface_points_df["formation"].str.contains("fault"), "formation"].unique():
-        series[fault] = fault
-        fault_list.append(fault)
-
-    gp.map_stack_to_surfaces(geo_model,
-                             series,
-                             remove_unused_series=True)
-
-    geo_model.set_is_fault(fault_list)
-
-    geo_model.reorder_features(['fault_a', 'fault_b', 'Strat_Series'])
-    geo_model.add_surfaces("basement")
-
-    plot = gp.plot_2d(geo_model, show_lith=False, show_boundaries=True,
-                      direction=['z'])
-    plt.show(block=False)
-
-    gp.set_interpolator(geo_model,
-                        compile_theano=True,
-                        theano_optimizer='fast_compile',
-                        )
-    gp.get_data(geo_model, 'kriging')
-
-    sol = gp.compute_model(geo_model, sort_surfaces=True)
-
-    gp.plot_2d(geo_model, show_scalar=True, series_n=0)
-    gp.plot_2d(geo_model, series_n=0)
-
-    gp.plot_3d(geo_model, image=True)
-
-
-@pytest.mark.skip(reason="Private data missing from the repo")
-def test_issue_564(data_path):
-    geo_model = gp.create_model('SBPM')
-
-    gp.init_data(geo_model, [550, 730, -200, 1000, 20, 55], [50, 50, 50],
-                 path_i=data_path + "/564_Points.csv",
-                 path_o=data_path + "/564_Orientations_.csv",
-                 default_values=True)
-
-    gp.map_stack_to_surfaces(geo_model,
-                             {"Q": 'Quartaer',
-                              "vK": 'verwKeuper',
-                              "Sa": 'Sandstein',
-                              "Sc": 'Schluffstein',
-                              "b": 'basement'},
-                             remove_unused_series=True)
-
-    gp.set_interpolator(geo_model,
-                        compile_theano=True,
-                        theano_optimizer='fast_compile')
-
-    sol = gp.compute_model(geo_model)
-    gp.plot_2d(geo_model)
-
-    gpv = gp.plot_3d(geo_model, image=True, plotter_type='basic', ve=5,
-                     show_lith=False)
-
-    geo_model.set_bottom_relation(["Q", "vK", "Sa", "Sc", "b"],
-                                  ["Onlap", "Onlap", "Onlap", "Onlap",
-                                   "Onlap"])
-
-    sol = gp.compute_model(geo_model)
-    gp.plot_2d(geo_model)
-
-    gpv = gp.plot_3d(geo_model, image=True, plotter_type='basic', ve=5,
-                     show_lith=True)
+import pytest
+
+import gempy as gp
+import pandas as pd
+import matplotlib as mpl
+mpl.use('Agg')
+import matplotlib.pyplot as plt
+
+
+def test_issue_566():
+    from pyvista import set_plot_theme
+    set_plot_theme('document')
+
+    geo_model = gp.create_model('Model1')
+    geo_model = gp.init_data(geo_model, extent=[0, 791, 0, 200, -582, 0],
+                             resolution=[100, 10, 100])
+
+    geo_model.set_default_surfaces()
+    geo_model.add_surface_points(X=223, Y=0.01, Z=-94, surface='surface1')
+
+
+@pytest.mark.skip(reason="Expensive test. It should be ran manually.")
+def test_issue_569(data_path):
+    surface_points_df = df = pd.read_csv(data_path + "/coordinates_mwe.csv")
+    orientations_df = pd.read_csv(data_path + "/orientations_mwe.csv")
+
+    geo_model = gp.create_model("Deltatest")
+    gp.init_data(geo_model,
+                 [df.X.min() - 50, df.X.max() + 50, df.Y.min() - 50, df.Y.max() + 50,
+                  df.Z.min() - 50, df.Z.max() + 50, ], [50, 50, 50],
+                 surface_points_df=surface_points_df,
+                 orientations_df=orientations_df,
+                 default_values=True)
+
+    fault_list = []
+    series = {"Strat_Series": surface_points_df.loc[
+        ~surface_points_df["formation"].str.contains(
+            "fault"), "formation"].unique().tolist()}
+
+    for fault in surface_points_df.loc[
+        surface_points_df["formation"].str.contains("fault"), "formation"].unique():
+        series[fault] = fault
+        fault_list.append(fault)
+
+    gp.map_stack_to_surfaces(geo_model,
+                             series,
+                             remove_unused_series=True)
+
+    geo_model.set_is_fault(fault_list)
+
+    geo_model.reorder_features(['fault_a', 'fault_b', 'Strat_Series'])
+    geo_model.add_surfaces("basement")
+
+    plot = gp.plot_2d(geo_model, show_lith=False, show_boundaries=True,
+                      direction=['z'])
+    plt.show(block=False)
+
+    gp.set_interpolator(geo_model,
+                        compile_aesara=True,
+                        aesara_optimizer='fast_compile',
+                        )
+    gp.get_data(geo_model, 'kriging')
+
+    sol = gp.compute_model(geo_model, sort_surfaces=True)
+
+    gp.plot_2d(geo_model, show_scalar=True, series_n=0)
+    gp.plot_2d(geo_model, series_n=0)
+
+    gp.plot_3d(geo_model, image=True)
+
+
+@pytest.mark.skip(reason="Private data missing from the repo")
+def test_issue_564(data_path):
+    geo_model = gp.create_model('SBPM')
+
+    gp.init_data(geo_model, [550, 730, -200, 1000, 20, 55], [50, 50, 50],
+                 path_i=data_path + "/564_Points.csv",
+                 path_o=data_path + "/564_Orientations_.csv",
+                 default_values=True)
+
+    gp.map_stack_to_surfaces(geo_model,
+                             {"Q": 'Quartaer',
+                              "vK": 'verwKeuper',
+                              "Sa": 'Sandstein',
+                              "Sc": 'Schluffstein',
+                              "b": 'basement'},
+                             remove_unused_series=True)
+
+    gp.set_interpolator(geo_model,
+                        compile_aesara=True,
+                        aesara_optimizer='fast_compile')
+
+    sol = gp.compute_model(geo_model)
+    gp.plot_2d(geo_model)
+
+    gpv = gp.plot_3d(geo_model, image=True, plotter_type='basic', ve=5,
+                     show_lith=False)
+
+    geo_model.set_bottom_relation(["Q", "vK", "Sa", "Sc", "b"],
+                                  ["Onlap", "Onlap", "Onlap", "Onlap",
+                                   "Onlap"])
+
+    sol = gp.compute_model(geo_model)
+    gp.plot_2d(geo_model)
+
+    gpv = gp.plot_3d(geo_model, image=True, plotter_type='basic', ve=5,
+                     show_lith=True)
```

### Comparing `gempy-2.2b10.dev1/test/test_core/UPDATE_data.py` & `gempy-2.3.0/test/test_core/UPDATE_data.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,243 +1,247 @@
-import gempy as gp
-import pandas as pn
-import numpy as np
-import os
-import pytest
-
-import gempy.core.data_modules.geometric_data
-import gempy.core.data_modules.stack
-
-
-@pytest.fixture(scope="module")
-def test_read_surface_points():
-    surface_points = gempy.core.data_modules.geometric_data.SurfacePoints()
-    surface_points.read_surface_points(os.pardir + "/input_data/FabLessPoints_Points.csv", inplace=True)
-
-    # Test setting series
-    series = gempy.core.data_modules.stack.Series(series_distribution={"fault": 'MainFault',
-                                            "Rest": ('SecondaryReservoir', 'Seal3', 'Reservoir', 'Overlying'),
-                                                                       })
-    surface_points.map_data_from_series(series, 'id')
-    return surface_points
-
-
-@pytest.fixture
-def test_model_init(scope="module"):
-    # Create empty model
-    model = gp.Project()
-    return model
-
-@pytest.fixture
-def test_create_series():
-    series = gp.create_series(series_distribution={"fault": 'MainFault',
-                                                   "Rest": ('SecondaryReservoir', 'Seal3', 'Reservoir', 'Overlying'),
-                                                  })
-    return series
-
-@pytest.fixture()
-def test_create_faults(test_create_series):
-    faults = gempy.core.data_modules.stack.Faults(test_create_series)
-    return faults
-
-@pytest.fixture()
-def test_create_formations():
-    formations = gp.Surfaces(values_array=np.arange(1, 8).reshape(-1, 1),
-                             properties_names=np.array(['density']))
-   # formations.set_surfaces_names(['MainFault', 'SecondaryReservoir','Seal',
-   #                                 'Reservoir', 'Overlying'])
-
-    return formations
-
-@pytest.fixture(scope='module')
-def test_load_model():
-    model = gp.load_model(os.pardir + "/input_data/test_solution.pickle")
-    return model
-
-
-class TestModel:
-    def test_modify_inteterfaces(self, load_model):
-        load_model.modify_surface_points([0, 10, 5], X=[90, 20, 30], Y=[30, 20, 40])
-        load_model.modify_surface_points(0, X=[60])
-
-        load_model.modify_surface_points([0, 1, 4], X=[60])
-
-
-class Testsurface_points:
-    def test_map_all_to_data(self, test_create_series, test_read_surface_points, test_create_formations,
-                             test_create_faults):
-        test_read_surface_points.map_data_from_series(test_create_series)
-        test_create_formations.set_surfaces_names(['MainFault', 'SecondaryReservoir', 'Seal',
-                                                    'Reservoir', 'Overlying'])
-
-        test_read_surface_points.map_formations_to_data(test_create_formations)
-        test_read_surface_points.map_formations_to_data(test_create_formations)
-
-        test_read_surface_points.map_data_from_faults(test_create_faults)
-        test_read_surface_points.update_annotations()
-        print(test_read_surface_points)
-
-    def test_map_formations_to_data(self, test_read_surface_points, test_create_formations):
-        test_read_surface_points.map_formations_to_data(test_create_formations)
-
-
-class TestOrientations:
-    @pytest.fixture(scope='class')
-    def test_read_orientations(self):
-        orientations = gempy.core.data_modules.geometric_data.Orientations()
-        orientations.read_orientations(os.pardir + "/input_data/FabLessPoints_Foliations.csv", inplace=True)
-        return orientations
-
-    def test_map_all_to_data(self, test_create_series, test_read_orientations, test_create_formations,
-                             test_create_faults):
-        test_read_orientations.map_data_from_series(test_create_series)
-        test_create_formations.set_surfaces_names(['MainFault', 'SecondaryReservoir', 'Seal',
-                                                    'Reservoir', 'Overlying'])
-
-        test_read_orientations.map_formations_to_data(test_create_formations)
-        test_read_orientations.map_formations_to_data(test_create_formations)
-
-        test_read_orientations.map_data_from_faults(test_create_faults)
-        test_read_orientations.update_annotations()
-        print(test_read_orientations)
-
-
-class TestGrid:
-    def test_set_regular_grid(self):
-        # Test creating an empty list
-        grid = gp.Grid()
-        print(grid.create_regular_grid_3d([0,2000, 0, 2000, -2000, 0], [50, 50, 50]))
-
-        # Test set regular grid by hand
-        grid.create_regular_grid([0, 2000, 0, 2000, -2000, 0], [50, 50, 50])
-
-    def test_grid_init(self):
-        # Or we can init one of the default grids since the beginning by passing
-        # the correspondant attributes
-        grid = gp.Grid('regular_grid', extent=[0, 2000, 0, 2000, -2000, 0],
-                       resolution=[50, 50, 50])
-
-    def test_grid_front(self):
-        gp.create_grid('regular_grid', extent=[0, 2000, 0, 2000, -2000, 0],
-                       resolution=[50, 50, 50])
-
-
-class TestSeries:
-
-    def test_set_series(self, test_read_surface_points):
-        series = gempy.core.data_modules.stack.Series()
-        # We can pass a pandas categories_df
-        series.set_series_categories(pn.DataFrame({"fault": ['test2'],
-                                        "Rest": 'SecondaryReservoir'}))
-
-        # We can even pass an interface object since sometimes (GeoModeller) we
-        # can import the surface in the same table
-        series.set_series_categories(test_read_surface_points)
-        print(series)
-
-        # Test init series
-        series = gempy.core.data_modules.stack.Series(series_distribution={"fault": 'MainFault',
-                                                "Rest": ('SecondaryReservoir', 'Seal3', 'Reservoir', 'Overlying'),
-                                                                           })
-        return series
-
-    @pytest.fixture
-    def test_series_front(self, test_model_init):
-        model = test_model_init
-
-        # Assigning series to surface as well as their order (timewise)
-        gp.set_series(model, {"Fault_Series": 'Main_Fault',
-                                 "Strat_Series": ('Sandstone_2', 'Siltstone',
-                                                  'Shale', 'Sandstone_1')},
-                      order_series=["Fault_Series", 'Strat_Series'],
-                      order_formations=['Main_Fault',
-                                        'Sandstone_2', 'Siltstone',
-                                        'Shale', 'Sandstone_1', 'basement'
-                                        ], verbose=0)
-
-        print(model._stack)
-        return model
-
-    def test_sequential_pile(self, test_series_front):
-        gp.get_sequential_pile(test_series_front)
-
-
-class TestFaults:
-    def test_set_faults(self, test_create_series):
-        faults = gempy.core.data_modules.stack.Faults(test_create_series)
-        faults.set_is_fault(['Rest'])
-        print(faults)
-
-    def test_default_faults(self, test_create_series):
-        faults = gempy.core.data_modules.stack.Faults(test_create_series)
-        print(faults)
-
-    def test_set_fault_relations(self, test_create_faults):
-        test_create_faults.set_fault_relation(np.array([[0, 1],
-                                                        [0, 0]]))
-
-        print(test_create_faults.faults_relations_df)
-
-
-class TestFormations:
-    def test_create_formation(self, test_create_formations):
-        print(test_create_formations)
-
-    def test_map_formations_from_series(self, test_create_formations, test_create_series):
-        test_create_formations.map_formations_from_series(test_create_series)
-        print(test_create_formations)
-
-    def test_map_formations_from_series2(self, test_create_series):
-        formations = gp.Surfaces()
-        formations.map_formations_from_series(test_create_series)
-        print(formations)
-
-    def test_set_formation_names(self, test_create_formations):
-        test_create_formations.set_surfaces_names(['MainFault', 'SecondaryReservoir', 'Seal',
-                                'Reservoir', 'Overlying'])
-
-        print(test_create_formations)
-        formations = gp.Surfaces(values_array=np.arange(1, 8).reshape(-1, 1),
-                                 properties_names=np.array(['density']))
-
-        formations.set_surfaces_names(['MainFault', 'SecondaryReservoir', 'Seal',
-                                'Reservoir', 'Overlying'])
-        print(formations)
-
-        formations = gp.Surfaces(values_array=np.arange(1, 2).reshape(-1, 1),
-                                 properties_names=np.array(['density']))
-
-        formations.set_surfaces_names(['MainFault', 'SecondaryReservoir', 'Seal',
-                                        'Reservoir', 'Overlying'])
-
-        print(formations)
-    def test_add_formation(self, test_create_formations):
-        test_create_formations.add_basement()
-        print(test_create_formations)
-        # Test that break
-        try:
-            test_create_formations.add_basement('basement2')
-        except AssertionError:
-            print('assertion captured')
-
-    def test_set_formations_values(self, test_create_formations):
-        test_create_formations.set_formations_values(np.random.rand(2,2))
-        test_create_formations.set_formations_values(np.random.rand(5,2))
-        test_create_formations.set_formations_values(np.random.rand(10,3))
-
-
-class TestSolution:
-    def test_representation(self, load_model):
-        sol = load_model.solutions
-        sol.set_values(np.random.rand(4, 2, 3), compute_mesh=False)
-        print(sol)
-
-    def test_get_surfaces(self, load_model):
-        model = load_model
-        print(model.solutions)
-        print(model.solutions.compute_all_surfaces())
-        print(gp.get_surfaces(model))
-
-
-def test_export_vtk(load_model):
-    model = load_model
+import gempy as gp
+import pandas as pn
+import numpy as np
+import os
+import pytest
+
+import gempy.core.grid
+import gempy.core.surfaces
+import gempy.core.data_modules.geometric_data
+import gempy.core.data_modules.orientations
+import gempy.core.data_modules.stack
+import gempy.core.data_modules.surface_points
+
+
+@pytest.fixture(scope="module")
+def test_read_surface_points():
+    surface_points = gempy.core.data_modules.surface_points.SurfacePoints()
+    surface_points.read_surface_points(os.pardir + "/input_data/FabLessPoints_Points.csv", inplace=True)
+
+    # Test setting series
+    series = gempy.core.data_modules.stack.Series(series_distribution={"fault": 'MainFault',
+                                            "Rest": ('SecondaryReservoir', 'Seal3', 'Reservoir', 'Overlying'),
+                                                                       })
+    surface_points.map_data_from_series(series, 'id')
+    return surface_points
+
+
+@pytest.fixture
+def test_model_init(scope="module"):
+    # Create empty model
+    model = gp.Project()
+    return model
+
+@pytest.fixture
+def test_create_series():
+    series = gp.create_series(series_distribution={"fault": 'MainFault',
+                                                   "Rest": ('SecondaryReservoir', 'Seal3', 'Reservoir', 'Overlying'),
+                                                  })
+    return series
+
+@pytest.fixture()
+def test_create_faults(test_create_series):
+    faults = gempy.core.data_modules.stack.Faults(test_create_series)
+    return faults
+
+@pytest.fixture()
+def test_create_formations():
+    formations = gempy.core.Surfaces.Surfaces(values_array=np.arange(1, 8).reshape(-1, 1),
+                                              properties_names=np.array(['density']))
+   # formations.set_surfaces_names(['MainFault', 'SecondaryReservoir','Seal',
+   #                                 'Reservoir', 'Overlying'])
+
+    return formations
+
+@pytest.fixture(scope='module')
+def test_load_model():
+    model = gp.load_model(os.pardir + "/input_data/test_solution.pickle")
+    return model
+
+
+class TestModel:
+    def test_modify_inteterfaces(self, load_model):
+        load_model.modify_surface_points([0, 10, 5], X=[90, 20, 30], Y=[30, 20, 40])
+        load_model.modify_surface_points(0, X=[60])
+
+        load_model.modify_surface_points([0, 1, 4], X=[60])
+
+
+class Testsurface_points:
+    def test_map_all_to_data(self, test_create_series, test_read_surface_points, test_create_formations,
+                             test_create_faults):
+        test_read_surface_points.map_data_from_series(test_create_series)
+        test_create_formations.set_surfaces_names(['MainFault', 'SecondaryReservoir', 'Seal',
+                                                    'Reservoir', 'Overlying'])
+
+        test_read_surface_points.map_formations_to_data(test_create_formations)
+        test_read_surface_points.map_formations_to_data(test_create_formations)
+
+        test_read_surface_points.map_data_from_faults(test_create_faults)
+        test_read_surface_points.update_annotations()
+        print(test_read_surface_points)
+
+    def test_map_formations_to_data(self, test_read_surface_points, test_create_formations):
+        test_read_surface_points.map_formations_to_data(test_create_formations)
+
+
+class TestOrientations:
+    @pytest.fixture(scope='class')
+    def test_read_orientations(self):
+        orientations = gempy.core.data_modules.orientations.Orientations()
+        orientations.read_orientations(os.pardir + "/input_data/FabLessPoints_Foliations.csv", inplace=True)
+        return orientations
+
+    def test_map_all_to_data(self, test_create_series, test_read_orientations, test_create_formations,
+                             test_create_faults):
+        test_read_orientations.map_data_from_series(test_create_series)
+        test_create_formations.set_surfaces_names(['MainFault', 'SecondaryReservoir', 'Seal',
+                                                    'Reservoir', 'Overlying'])
+
+        test_read_orientations.map_formations_to_data(test_create_formations)
+        test_read_orientations.map_formations_to_data(test_create_formations)
+
+        test_read_orientations.map_data_from_faults(test_create_faults)
+        test_read_orientations.update_annotations()
+        print(test_read_orientations)
+
+
+class TestGrid:
+    def test_set_regular_grid(self):
+        # Test creating an empty list
+        grid = gempy.core.grid.Grid()
+        print(grid.create_regular_grid_3d([0,2000, 0, 2000, -2000, 0], [50, 50, 50]))
+
+        # Test set regular grid by hand
+        grid.create_regular_grid([0, 2000, 0, 2000, -2000, 0], [50, 50, 50])
+
+    def test_grid_init(self):
+        # Or we can init one of the default grids since the beginning by passing
+        # the correspondant attributes
+        grid = gempy.core.grid.Grid('regular_grid', extent=[0, 2000, 0, 2000, -2000, 0],
+                                    resolution=[50, 50, 50])
+
+    def test_grid_front(self):
+        gp.create_grid('regular_grid', extent=[0, 2000, 0, 2000, -2000, 0],
+                       resolution=[50, 50, 50])
+
+
+class TestSeries:
+
+    def test_set_series(self, test_read_surface_points):
+        series = gempy.core.data_modules.stack.Series()
+        # We can pass a pandas categories_df
+        series.set_series_categories(pn.DataFrame({"fault": ['test2'],
+                                        "Rest": 'SecondaryReservoir'}))
+
+        # We can even pass an interface object since sometimes (GeoModeller) we
+        # can import the surface in the same table
+        series.set_series_categories(test_read_surface_points)
+        print(series)
+
+        # Test init series
+        series = gempy.core.data_modules.stack.Series(series_distribution={"fault": 'MainFault',
+                                                "Rest": ('SecondaryReservoir', 'Seal3', 'Reservoir', 'Overlying'),
+                                                                           })
+        return series
+
+    @pytest.fixture
+    def test_series_front(self, test_model_init):
+        model = test_model_init
+
+        # Assigning series to surface as well as their order (timewise)
+        gp.set_series(model, {"Fault_Series": 'Main_Fault',
+                                 "Strat_Series": ('Sandstone_2', 'Siltstone',
+                                                  'Shale', 'Sandstone_1')},
+                      order_series=["Fault_Series", 'Strat_Series'],
+                      order_formations=['Main_Fault',
+                                        'Sandstone_2', 'Siltstone',
+                                        'Shale', 'Sandstone_1', 'basement'
+                                        ], verbose=0)
+
+        print(model._stack)
+        return model
+
+    def test_sequential_pile(self, test_series_front):
+        gp.get_sequential_pile(test_series_front)
+
+
+class TestFaults:
+    def test_set_faults(self, test_create_series):
+        faults = gempy.core.data_modules.stack.Faults(test_create_series)
+        faults.set_is_fault(['Rest'])
+        print(faults)
+
+    def test_default_faults(self, test_create_series):
+        faults = gempy.core.data_modules.stack.Faults(test_create_series)
+        print(faults)
+
+    def test_set_fault_relations(self, test_create_faults):
+        test_create_faults.set_fault_relation(np.array([[0, 1],
+                                                        [0, 0]]))
+
+        print(test_create_faults.faults_relations_df)
+
+
+class TestFormations:
+    def test_create_formation(self, test_create_formations):
+        print(test_create_formations)
+
+    def test_map_formations_from_series(self, test_create_formations, test_create_series):
+        test_create_formations.map_formations_from_series(test_create_series)
+        print(test_create_formations)
+
+    def test_map_formations_from_series2(self, test_create_series):
+        formations = gempy.core.Surfaces.Surfaces()
+        formations.map_formations_from_series(test_create_series)
+        print(formations)
+
+    def test_set_formation_names(self, test_create_formations):
+        test_create_formations.set_surfaces_names(['MainFault', 'SecondaryReservoir', 'Seal',
+                                'Reservoir', 'Overlying'])
+
+        print(test_create_formations)
+        formations = gempy.core.Surfaces.Surfaces(values_array=np.arange(1, 8).reshape(-1, 1),
+                                                  properties_names=np.array(['density']))
+
+        formations.set_surfaces_names(['MainFault', 'SecondaryReservoir', 'Seal',
+                                'Reservoir', 'Overlying'])
+        print(formations)
+
+        formations = gempy.core.Surfaces.Surfaces(values_array=np.arange(1, 2).reshape(-1, 1),
+                                                  properties_names=np.array(['density']))
+
+        formations.set_surfaces_names(['MainFault', 'SecondaryReservoir', 'Seal',
+                                        'Reservoir', 'Overlying'])
+
+        print(formations)
+    def test_add_formation(self, test_create_formations):
+        test_create_formations.add_basement()
+        print(test_create_formations)
+        # Test that break
+        try:
+            test_create_formations.add_basement('basement2')
+        except AssertionError:
+            print('assertion captured')
+
+    def test_set_formations_values(self, test_create_formations):
+        test_create_formations.set_formations_values(np.random.rand(2,2))
+        test_create_formations.set_formations_values(np.random.rand(5,2))
+        test_create_formations.set_formations_values(np.random.rand(10,3))
+
+
+class TestSolution:
+    def test_representation(self, load_model):
+        sol = load_model.solutions
+        sol.set_values(np.random.rand(4, 2, 3), compute_mesh=False)
+        print(sol)
+
+    def test_get_surfaces(self, load_model):
+        model = load_model
+        print(model.solutions)
+        print(model.solutions.compute_all_surfaces())
+        print(gp.get_surfaces(model))
+
+
+def test_export_vtk(load_model):
+    model = load_model
     gp.plot.export_to_vtk(model, os.path.dirname(__file__)+'/vtk/expert_test')
```

### Comparing `gempy-2.2b10.dev1/test/test_core/test_data_classes.py` & `gempy-2.3.0/test/test_core/test_data_classes.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,277 +1,282 @@
-# Importing GemPy
-import gempy as gp
-
-
-# Importing auxiliary libraries
-import numpy as np
-import pandas as pn
-import matplotlib.pyplot as plt
-import pytest
-
-import gempy.core.data_modules.geometric_data
-import gempy.core.data_modules.stack
-
-
-@pytest.fixture(scope='module')
-def create_faults():
-    faults = gempy.core.data_modules.stack.Faults()
-    return faults
-
-
-@pytest.fixture(scope='module')
-def create_series(create_faults):
-    faults = create_faults
-
-    series = gempy.core.data_modules.stack.Series(faults)
-    series.set_series_index(['foo', 'foo2', 'foo5', 'foo7'])
-    series.add_series('foo3')
-    series.delete_series('foo2')
-    series.rename_series({'foo': 'boo'})
-    series.reorder_series(['foo3', 'boo', 'foo7', 'foo5'])
-
-    faults.set_is_fault(['boo'])
-
-    fr = np.zeros((4, 4))
-    fr[2, 2] = True
-    faults.set_fault_relation(fr)
-
-    series.add_series('foo20')
-
-    return series
-
-
-@pytest.fixture(scope='module')
-def create_surfaces(create_series):
-    series = create_series
-    surfaces = gp.Surfaces(series)
-    surfaces.set_surfaces_names(['foo', 'foo2', 'foo5'])
-
-    print(series)
-
-    # We can add new surfaces:
-    surfaces.add_surface(['feeeee'])
-    print(surfaces)
-
-    # The column surface is also a pandas.Categories.
-    # This will be important for the Data clases (SurfacePoints and Orientations)
-
-    print(surfaces.df['surface'])
-
-    ### Set values
-
-    # To set the values we do it with the following method
-    surfaces.set_surfaces_values([2, 2, 2, 5])
-
-    print(surfaces)
-
-    # #### Set values with a given name:
-
-    # We can give specific names to the properties (i.e. density)
-    surfaces.add_surfaces_values([[2, 2, 2, 6], [2, 2, 1, 8]], ['val_foo', 'val2_foo'])
-    print(surfaces)
-
-    ### Delete surfaces values
-    #
-    # To delete a full propery:
-    surfaces.delete_surface_values(['val_foo', 'value_0'])
-
-    # #### One of the surfaces must be set be the basement:
-
-    surfaces.set_basement()
-    print(surfaces)
-
-    # #### Set surface values
-    #
-    # We can also use set values instead adding. This will delete the previous properties and add the new one
-
-    surfaces.set_surfaces_values([[2, 2, 2, 6], [2, 2, 1, 8]], ['val_foo', 'val2_foo'])
-    print(surfaces)
-
-    # The last property is the correspondant series that each surface belong to. `series` and `surface`
-    # are pandas categories. To get a overview of what this mean
-    # check https://pandas.pydata.org/pandas-docs/stable/categorical.html.
-
-    print(surfaces.df['series'])
-
-    print(surfaces.df['surface'])
-
-    # ### Map series to surface
-
-    # To map a series to a surface we can do it by passing a dict:
-    # If a series does not exist in the `Series` object, we rise a warning and we set those surfaces to nans
-
-    d = {"foo7": 'foo', "booX": ('foo2', 'foo5', 'fee')}
-
-    surfaces.map_series(d)
-    surfaces.map_series({"foo7": 'foo', "boo": ('foo2', 'foo5', 'fee')})
-
-    print(surfaces)
-
-    # An advantage of categories is that they are order so no we can tidy the df by series and surface
-
-    surfaces.df.sort_values(by='series', inplace=True)
-
-    # If we change the basement:
-
-    surfaces.set_basement()
-
-    # Only one surface can be the basement:
-
-    print(surfaces)
-
-    # ### Modify surface name
-
-    surfaces.rename_surfaces({'foo2': 'lala'})
-
-    print(surfaces)
-
-    surfaces.df.loc[2, 'val_foo'] = 22
-
-    print(surfaces)
-
-    # We can use `set_is_fault` to choose which of our series are faults:
-    return surfaces
-
-
-@pytest.fixture(scope='module')
-def create_surface_points(create_surfaces, create_series):
-    # # Data
-    # #### SurfacePoints
-    # These two DataFrames (df from now on) will contain the individual information of each point at an interface or
-    # orientation. Some properties of this table are mapped from the *df* below.
-    surfaces = create_surfaces
-    surface_points = gempy.core.data_modules.geometric_data.SurfacePoints(surfaces)
-
-    print(surface_points)
-
-    surface_points.set_surface_points(pn.DataFrame(np.random.rand(6, 3)), ['foo', 'foo5', 'lala', 'foo5', 'lala', 'feeeee'])
-
-    print(surface_points)
-
-    surface_points.map_data_from_surfaces(surfaces, 'series')
-    print(surface_points)
-
-
-    surface_points.map_data_from_surfaces(surfaces, 'id')
-    print(surface_points)
-
-
-    surface_points.map_data_from_series(create_series, 'order_series')
-    print(surface_points)
-
-    surface_points.sort_table()
-    print(surface_points)
-    return surface_points
-
-
-@pytest.fixture(scope='module')
-def create_orientations(create_surfaces, create_series):
-    surfaces = create_surfaces
-
-    # ### Orientations
-    orientations = gempy.core.data_modules.geometric_data.Orientations(surfaces)
-
-    print(orientations)
-
-    # ### Set values passing pole vectors:
-
-    orientations.set_orientations(np.random.rand(6, 3) * 10,
-                                  np.random.rand(6, 3),
-                                  surface=['foo', 'foo5', 'lala', 'foo5', 'lala', 'feeeee'])
-
-    print(orientations)
-
-    # ### Set values pasing orientation data: azimuth, dip, pole (dip direction)
-
-    orientations.set_orientations(np.random.rand(6, 3) * 10,
-                                  orientation=np.random.rand(6, 3) * 20,
-                                  surface=['foo', 'foo5', 'lala', 'foo5', 'lala', 'feeeee'])
-
-    print(orientations)
-
-    # ### Mapping data from the other df
-    orientations.map_data_from_surfaces(surfaces, 'series')
-    print(orientations)
-
-    orientations.map_data_from_surfaces(surfaces, 'id')
-    print(orientations)
-
-    orientations.map_data_from_series(create_series, 'order_series')
-    print(orientations)
-
-    orientations.update_annotations()
-    return orientations
-
-
-def test_add_orientation_with_pole(create_surfaces):
-    orientations = gempy.core.data_modules.geometric_data.Orientations(create_surfaces)
-    orientations.add_orientation(1, 1, 1, 'foo', pole_vector=(1, 0, 1))
-    orientations.add_orientation(2, 2, 2, 'foo', orientation=(0, 0, 1))
-    orientations.add_orientation(1, 1, 1, 'foo', pole_vector=(.45, 0, .45))
-    orientations.modify_orientations(2, G_x=1, G_z=1)
-
-    print(orientations)
-
-
-@pytest.fixture(scope='module')
-def create_grid():
-    # Test creating an empty list
-    grid = gp.Grid()
-    # Test set regular grid by hand
-    grid.create_regular_grid([0, 2000, 0, 2000, -2000, 0], [50, 50, 50])
-    return grid
-
-
-@pytest.fixture(scope='module')
-def create_rescaling(create_surface_points, create_orientations, create_grid):
-    rescaling = gempy.core.data_modules.geometric_data.ScalingSystem(create_surface_points, create_orientations, create_grid)
-    return rescaling
-
-
-@pytest.fixture(scope='module')
-def create_additional_data(create_surface_points, create_orientations, create_grid, create_faults,
-                           create_surfaces, create_rescaling):
-
-    ad = gp.AdditionalData(create_surface_points, create_orientations, create_grid, create_faults,
-                           create_surfaces, create_rescaling)
-    return ad
-
-
-class TestDataManipulation:
-
-    def test_series(self, create_series):
-        return create_series
-
-    def test_surfaces(self, create_surfaces):
-        return create_surfaces
-
-    def test_surface_points(self, create_surface_points):
-        return create_surface_points
-
-    def test_orientations(self, create_orientations):
-        return create_orientations
-
-    def test_rescaling(self, create_rescaling):
-        return create_rescaling
-
-    def test_additional_data(self, create_additional_data):
-        return create_additional_data
-
-
-def test_stack():
-    stack = gempy.core.data_modules.stack.Stack()
-    stack.set_series_index(['foo', 'foo2', 'foo5', 'foo7'])
-    stack.add_series('foo3')
-    stack.delete_series('foo2')
-    stack.rename_series({'foo': 'boo'})
-    stack.reorder_series(['foo3', 'boo', 'foo7', 'foo5'])
-    stack.set_is_fault(['boo'])
-
-    faults = stack
-    faults.set_is_fault(['boo'])
-
-    fr = np.zeros((4, 4))
-    fr[2, 2] = True
-    faults.set_fault_relation(fr)
-
-    stack.add_series('foo20')
+# Importing GemPy
+import gempy as gp
+
+
+# Importing auxiliary libraries
+import numpy as np
+import pandas as pn
+import matplotlib.pyplot as plt
+import pytest
+
+import gempy.core.grid
+import gempy.core.surfaces
+import gempy.core.data_modules.geometric_data
+import gempy.core.data_modules.orientations
+import gempy.core.data_modules.scaling_system
+import gempy.core.data_modules.stack
+import gempy.core.data_modules.surface_points
+
+
+@pytest.fixture(scope='module')
+def create_faults():
+    faults = gempy.core.data_modules.stack.Faults()
+    return faults
+
+
+@pytest.fixture(scope='module')
+def create_series(create_faults):
+    faults = create_faults
+
+    series = gempy.core.data_modules.stack.Series(faults)
+    series.set_series_index(['foo', 'foo2', 'foo5', 'foo7'])
+    series.add_series('foo3')
+    series.delete_series('foo2')
+    series.rename_series({'foo': 'boo'})
+    series.reorder_series(['foo3', 'boo', 'foo7', 'foo5'])
+
+    faults.set_is_fault(['boo'])
+
+    fr = np.zeros((4, 4))
+    fr[2, 2] = True
+    faults.set_fault_relation(fr)
+
+    series.add_series('foo20')
+
+    return series
+
+
+@pytest.fixture(scope='module')
+def create_surfaces(create_series):
+    series = create_series
+    surfaces = gempy.Surfaces(series)
+    surfaces.set_surfaces_names(['foo', 'foo2', 'foo5'])
+
+    print(series)
+
+    # We can add new surfaces:
+    surfaces.add_surface(['feeeee'])
+    print(surfaces)
+
+    # The column surface is also a pandas.Categories.
+    # This will be important for the Data clases (SurfacePoints and Orientations)
+
+    print(surfaces.df['surface'])
+
+    ### Set values
+
+    # To set the values we do it with the following method
+    surfaces.set_surfaces_values([2, 2, 2, 5])
+
+    print(surfaces)
+
+    # #### Set values with a given name:
+
+    # We can give specific names to the properties (i.e. density)
+    surfaces.add_surfaces_values([[2, 2, 2, 6], [2, 2, 1, 8]], ['val_foo', 'val2_foo'])
+    print(surfaces)
+
+    ### Delete surfaces values
+    #
+    # To delete a full propery:
+    surfaces.delete_surface_values(['val_foo', 'value_0'])
+
+    # #### One of the surfaces must be set be the basement:
+
+    surfaces.set_basement()
+    print(surfaces)
+
+    # #### Set surface values
+    #
+    # We can also use set values instead adding. This will delete the previous properties and add the new one
+
+    surfaces.set_surfaces_values([[2, 2, 2, 6], [2, 2, 1, 8]], ['val_foo', 'val2_foo'])
+    print(surfaces)
+
+    # The last property is the correspondant series that each surface belong to. `series` and `surface`
+    # are pandas categories. To get a overview of what this mean
+    # check https://pandas.pydata.org/pandas-docs/stable/categorical.html.
+
+    print(surfaces.df['series'])
+
+    print(surfaces.df['surface'])
+
+    # ### Map series to surface
+
+    # To map a series to a surface we can do it by passing a dict:
+    # If a series does not exist in the `Series` object, we rise a warning and we set those surfaces to nans
+
+    d = {"foo7": 'foo', "booX": ('foo2', 'foo5', 'fee')}
+
+    surfaces.map_series(d)
+    surfaces.map_series({"foo7": 'foo', "boo": ('foo2', 'foo5', 'fee')})
+
+    print(surfaces)
+
+    # An advantage of categories is that they are order so no we can tidy the df by series and surface
+
+    surfaces.df.sort_values(by='series', inplace=True)
+
+    # If we change the basement:
+
+    surfaces.set_basement()
+
+    # Only one surface can be the basement:
+
+    print(surfaces)
+
+    # ### Modify surface name
+
+    surfaces.rename_surfaces({'foo2': 'lala'})
+
+    print(surfaces)
+
+    surfaces.df.loc[2, 'val_foo'] = 22
+
+    print(surfaces)
+
+    # We can use `set_is_fault` to choose which of our series are faults:
+    return surfaces
+
+
+@pytest.fixture(scope='module')
+def create_surface_points(create_surfaces, create_series):
+    # # Data
+    # #### SurfacePoints
+    # These two DataFrames (df from now on) will contain the individual information of each point at an interface or
+    # orientation. Some properties of this table are mapped from the *df* below.
+    surfaces = create_surfaces
+    surface_points = gempy.core.data_modules.surface_points.SurfacePoints(surfaces)
+
+    print(surface_points)
+
+    surface_points.set_surface_points(pn.DataFrame(np.random.rand(6, 3)), ['foo', 'foo5', 'lala', 'foo5', 'lala', 'feeeee'])
+
+    print(surface_points)
+
+    surface_points.map_data_from_surfaces(surfaces, 'series')
+    print(surface_points)
+
+
+    surface_points.map_data_from_surfaces(surfaces, 'id')
+    print(surface_points)
+
+
+    surface_points.map_data_from_series(create_series, 'order_series')
+    print(surface_points)
+
+    surface_points.sort_table()
+    print(surface_points)
+    return surface_points
+
+
+@pytest.fixture(scope='module')
+def create_orientations(create_surfaces, create_series):
+    surfaces = create_surfaces
+
+    # ### Orientations
+    orientations = gempy.core.data_modules.orientations.Orientations(surfaces)
+
+    print(orientations)
+
+    # ### Set values passing pole vectors:
+
+    orientations.set_orientations(np.random.rand(6, 3) * 10,
+                                  np.random.rand(6, 3),
+                                  surface=['foo', 'foo5', 'lala', 'foo5', 'lala', 'feeeee'])
+
+    print(orientations)
+
+    # ### Set values pasing orientation data: azimuth, dip, pole (dip direction)
+
+    orientations.set_orientations(np.random.rand(6, 3) * 10,
+                                  orientation=np.random.rand(6, 3) * 20,
+                                  surface=['foo', 'foo5', 'lala', 'foo5', 'lala', 'feeeee'])
+
+    print(orientations)
+
+    # ### Mapping data from the other df
+    orientations.map_data_from_surfaces(surfaces, 'series')
+    print(orientations)
+
+    orientations.map_data_from_surfaces(surfaces, 'id')
+    print(orientations)
+
+    orientations.map_data_from_series(create_series, 'order_series')
+    print(orientations)
+
+    orientations.update_annotations()
+    return orientations
+
+
+def test_add_orientation_with_pole(create_surfaces):
+    orientations = gempy.Orientations(create_surfaces)
+    orientations.add_orientation(1, 1, 1, 'foo', pole_vector=(1, 0, 1))
+    orientations.add_orientation(2, 2, 2, 'foo', orientation=(0, 0, 1))
+    orientations.add_orientation(1, 1, 1, 'foo', pole_vector=(.45, 0, .45))
+    orientations.modify_orientations(2, G_x=1, G_z=1)
+
+    print(orientations)
+
+
+@pytest.fixture(scope='module')
+def create_grid():
+    # Test creating an empty list
+    grid = gempy.core.grid.Grid()
+    # Test set regular grid by hand
+    grid.create_regular_grid([0, 2000, 0, 2000, -2000, 0], [50, 50, 50])
+    return grid
+
+
+@pytest.fixture(scope='module')
+def create_rescaling(create_surface_points, create_orientations, create_grid):
+    rescaling = gempy.core.data_modules.scaling_system.ScalingSystem(create_surface_points, create_orientations, create_grid)
+    return rescaling
+
+
+@pytest.fixture(scope='module')
+def create_additional_data(create_surface_points, create_orientations, create_grid, create_faults,
+                           create_surfaces, create_rescaling):
+
+    ad = gp.AdditionalData(create_surface_points, create_orientations, create_grid, create_faults,
+                           create_surfaces, create_rescaling)
+    return ad
+
+
+class TestDataManipulation:
+
+    def test_series(self, create_series):
+        return create_series
+
+    def test_surfaces(self, create_surfaces):
+        return create_surfaces
+
+    def test_surface_points(self, create_surface_points):
+        return create_surface_points
+
+    def test_orientations(self, create_orientations):
+        return create_orientations
+
+    def test_rescaling(self, create_rescaling):
+        return create_rescaling
+
+    def test_additional_data(self, create_additional_data):
+        return create_additional_data
+
+
+def test_stack():
+    stack = gempy.core.data_modules.stack.Stack()
+    stack.set_series_index(['foo', 'foo2', 'foo5', 'foo7'])
+    stack.add_series('foo3')
+    stack.delete_series('foo2')
+    stack.rename_series({'foo': 'boo'})
+    stack.reorder_series(['foo3', 'boo', 'foo7', 'foo5'])
+    stack.set_is_fault(['boo'])
+
+    faults = stack
+    faults.set_is_fault(['boo'])
+
+    fr = np.zeros((4, 4))
+    fr[2, 2] = True
+    faults.set_fault_relation(fr)
+
+    stack.add_series('foo20')
```

### Comparing `gempy-2.2b10.dev1/test/test_core/test_data_mutation.py` & `gempy-2.3.0/test/test_core/test_data_mutation.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,96 +1,96 @@
-# These two lines are necessary only if GemPy is not installed
-# Importing GemPy
-import gempy as gp
-
-# Importing auxiliary libraries
-import numpy as np
-import pytest
-import os
-
-mm = gp.ImplicitCoKriging()
-mm.add_surfaces(['surface1', 'foo1', 'foo2', 'foo3'])
-
-
-def test_add_surface_points_raise_non_surface():
-    with pytest.raises(ValueError):
-        mm.add_surface_points(400, 300, -500, 'surface5')
-
-
-def test_add_surface():
-    mm.add_surfaces(['a_foo1', 'a_foo2'])
-    with pytest.raises(ValueError, match=r'.* not include old categories.*'):
-        mm.add_surfaces('a_foo1')
-
-    mm.add_surfaces('a_foo3')
-
-
-def test_delete_surface():
-    mm.delete_surfaces('foo1')
-    mm.delete_surfaces(['surface1', 'foo2'])
-
-
-def test_rename_surface():
-    mm = gp.ImplicitCoKriging()
-    mm.add_surfaces(['surface1', 'foo1', 'foo2', 'foo3'])
-    mm.rename_surfaces({'foo1': 'changed'})
-    assert mm._surfaces.df.loc[1, 'surface'] == 'changed'
-
-
-def test_modify_order_surfaces():
-    mm = gp.ImplicitCoKriging()
-    mm.add_surfaces(['surface1', 'foo1', 'foo2', 'foo3'])
-    mm.modify_order_surfaces(3, 2)
-    assert mm._surfaces.df.iloc[2, 0] == 'foo2'
-
-
-def test_add_surface_values():
-    pass
-
-
-def test_delete_surface_values():
-    pass
-
-
-def test_modify_surface_values():
-    mm = gp.ImplicitCoKriging()
-    mm.add_surfaces(['surface1', 'foo1', 'foo2', 'foo3'])
-    mm.add_surface_points(400, 300, -500, 'foo2')
-    print(mm._surface_points)
-    mm.modify_surface_points(0, Y=800)
-    print(mm._surface_points)
-
-
-def test_set_surface_values():
-    pass
-
-
-def test_add_surface_points():
-    mm = gp.ImplicitCoKriging()
-    mm.add_surfaces(['surface1', 'foo1', 'foo2', 'foo3'])
-    mm.add_surface_points(400, 300, -500, 'foo2')
-
-
-def test_add_default_orientation():
-    mm = gp.ImplicitCoKriging()
-    mm.set_default_surfaces()
-    mm.set_default_orientation()
-
-
-def test_set_is_fault():
-    mm = gp.ImplicitCoKriging()
-    mm.add_features(['foo1', 'foo2', 'foo3'])
-    assert (mm._faults.df.index == np.array(['Default series', 'foo1', 'foo2', 'foo3'])).all()
-    assert (mm._faults.faults_relations_df.index == ['Default series', 'foo1', 'foo2', 'foo3']).all()
-    mm.set_is_fault(['foo2'])
-    assert mm._faults.faults_relations_df.loc['foo2', 'foo3'] == True
-    assert mm._faults.faults_relations_df.iloc[2, 3] == True
-    mm.set_is_fault(['foo2'], toggle=True)
-
-
-def test_read_data():
-    data_path = os.path.dirname(__file__)+'/../../examples/'
-    model = gp.Model()
-    model.read_data(path_i=data_path + "/data/input_data/tut_chapter1/simple_fault_model_points.csv",
-                    path_o=data_path + "/data/input_data/tut_chapter1/simple_fault_model_orientations.csv")
-
+# These two lines are necessary only if GemPy is not installed
+# Importing GemPy
+import gempy as gp
+
+# Importing auxiliary libraries
+import numpy as np
+import pytest
+import os
+
+mm = gp.ImplicitCoKriging()
+mm.add_surfaces(['surface1', 'foo1', 'foo2', 'foo3'])
+
+
+def test_add_surface_points_raise_non_surface():
+    with pytest.raises(TypeError, match=r'.*surface passed does not exist in the pandas categories..*'):
+        mm.add_surface_points(400, 300, -500, 'surface5')
+
+
+def test_add_surface():
+    mm.add_surfaces(['a_foo1', 'a_foo2'])
+    with pytest.raises(ValueError, match=r'.* not include old categories.*'):
+        mm.add_surfaces('a_foo1')
+
+    mm.add_surfaces('a_foo3')
+
+
+def test_delete_surface():
+    mm.delete_surfaces('foo1')
+    mm.delete_surfaces(['surface1', 'foo2'])
+
+
+def test_rename_surface():
+    mm = gp.ImplicitCoKriging()
+    mm.add_surfaces(['surface1', 'foo1', 'foo2', 'foo3'])
+    mm.rename_surfaces({'foo1': 'changed'})
+    assert mm._surfaces.df.loc[1, 'surface'] == 'changed'
+
+
+def test_modify_order_surfaces():
+    mm = gp.ImplicitCoKriging()
+    mm.add_surfaces(['surface1', 'foo1', 'foo2', 'foo3'])
+    mm.modify_order_surfaces(3, 2)
+    assert mm._surfaces.df.iloc[2, 0] == 'foo2'
+
+
+def test_add_surface_values():
+    pass
+
+
+def test_delete_surface_values():
+    pass
+
+
+def test_modify_surface_values():
+    mm = gp.ImplicitCoKriging()
+    mm.add_surfaces(['surface1', 'foo1', 'foo2', 'foo3'])
+    mm.add_surface_points(400, 300, -500, 'foo2')
+    print(mm._surface_points)
+    mm.modify_surface_points(0, Y=800)
+    print(mm._surface_points)
+
+
+def test_set_surface_values():
+    pass
+
+
+def test_add_surface_points():
+    mm = gp.ImplicitCoKriging()
+    mm.add_surfaces(['surface1', 'foo1', 'foo2', 'foo3'])
+    mm.add_surface_points(400, 300, -500, 'foo2')
+
+
+def test_add_default_orientation():
+    mm = gp.ImplicitCoKriging()
+    mm.set_default_surfaces()
+    mm.set_default_orientation()
+
+
+def test_set_is_fault():
+    mm = gp.ImplicitCoKriging()
+    mm.add_features(['foo1', 'foo2', 'foo3'])
+    assert (mm._faults.df.index == np.array(['Default series', 'foo1', 'foo2', 'foo3'])).all()
+    assert (mm._faults.faults_relations_df.index == ['Default series', 'foo1', 'foo2', 'foo3']).all()
+    mm.set_is_fault(['foo2'])
+    assert mm._faults.faults_relations_df.loc['foo2', 'foo3'] == True
+    assert mm._faults.faults_relations_df.iloc[2, 3] == True
+    mm.set_is_fault(['foo2'], toggle=True)
+
+
+def test_read_data():
+    data_path = os.path.dirname(__file__)+'/../../examples/'
+    model = gp.Model()
+    model.read_data(path_i=data_path + "/data/input_data/tut_chapter1/simple_fault_model_points.csv",
+                    path_o=data_path + "/data/input_data/tut_chapter1/simple_fault_model_orientations.csv")
+
     assert model._surface_points.df.shape[0] == 57
```

### Comparing `gempy-2.2b10.dev1/test/test_core/test_data_mutation2.py` & `gempy-2.3.0/test/test_core/test_data_mutation2.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,41 +1,44 @@
-
-
-# These two lines are necessary only if GemPy is not installed
-import sys, os
-sys.path.append("../..")
-
-# Importing GemPy
-import gempy as gp
-import pytest
-
-
-def test_add_point():
-    extend = [0.0, 1.0, 0.0, 1.0, 0.0, 1.1]
-    discretization = [5, 20, 20]
-
-    x, y, z, f = 0.0, 0.0, 0.5, 'surface2'
-
-    # %%
-    geo_model = gp.create_model('test')
-    gp.init_data(geo_model, extend, discretization)
-
-    geo_model.set_default_surfaces()
-    geo_model.set_default_orientation()
-
-    strats = ['surface1', 'surface2', 'basement']
-
-    gp.map_stack_to_surfaces(geo_model, {'Strat_Series': strats})
-
-    geo_model.add_surface_points(x, y, z, f)
-    geo_model.add_orientations(x, y, z, f, pole_vector=(1,0,0))
-
-
-def test_restricting_wrapper():
-    from gempy.core.model import RestrictingWrapper
-    surface = gp.Surfaces(gp.core.data_modules.stack.Series(gp.core.data_modules.stack.Faults()))
-
-    s = RestrictingWrapper(surface)
-
-    print(s)
-    with pytest.raises(AttributeError):
-        print(s.add_surfaces)
+
+
+# These two lines are necessary only if GemPy is not installed
+import sys, os
+
+import gempy.core.surfaces
+
+sys.path.append("../..")
+
+# Importing GemPy
+import gempy as gp
+import pytest
+
+
+def test_add_point():
+    extend = [0.0, 1.0, 0.0, 1.0, 0.0, 1.1]
+    discretization = [5, 20, 20]
+
+    x, y, z, f = 0.0, 0.0, 0.5, 'surface2'
+
+    # %%
+    geo_model = gp.create_model('test')
+    gp.init_data(geo_model, extend, discretization)
+
+    geo_model.set_default_surfaces()
+    geo_model.set_default_orientation()
+
+    strats = ['surface1', 'surface2', 'basement']
+
+    gp.map_stack_to_surfaces(geo_model, {'Strat_Series': strats})
+
+    geo_model.add_surface_points(x, y, z, f)
+    geo_model.add_orientations(x, y, z, f, pole_vector=(1,0,0))
+
+
+def test_restricting_wrapper():
+    from gempy.core.model import RestrictingWrapper
+    surface = gempy.Surfaces(gp.Series(gp.Faults()))
+
+    s = RestrictingWrapper(surface)
+
+    print(s)
+    with pytest.raises(AttributeError):
+        print(s.add_surfaces)
```

### Comparing `gempy-2.2b10.dev1/test/test_core/test_grids/test_diamond_square.py` & `gempy-2.3.0/test/test_core/test_grids/test_diamond_square.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,148 +1,148 @@
-import gempy.core.grid_modules.diamond_square
-import pytest  # to add fixtures and to test error raises
-import numpy as np  # as another testing environment
-
-
-def test_class_nocrash():
-    """Simply check if class can be instantiated"""
-    gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(5, 5))
-
-
-def test_grid_generation():
-    """Test grid generation and extension for non-suitable grid sizes"""
-    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(5, 5))
-    assert ds.grid.shape == (5, 5)
-    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(8, 10))
-    assert ds.grid.shape == (9, 17)
-
-
-def test_diamond_selection():
-    """Test selection of diamond positions"""
-    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(5, 5))
-    z = ds.get_selection_diamond(1)
-    assert np.all(z == np.array([[2, 0, 0, 0, 2],
-                                 [0, 0, 0, 0, 0],
-                                 [0, 0, 1, 0, 0],
-                                 [0, 0, 0, 0, 0],
-                                 [2, 0, 0, 0, 2]]))
-    z = ds.get_selection_diamond(0)
-    assert np.all(z == np.array([[2, 0, 2, 0, 2],
-                                 [0, 1, 0, 1, 0],
-                                 [2, 0, 2, 0, 2],
-                                 [0, 1, 0, 1, 0],
-                                 [2, 0, 2, 0, 2]]))
-
-
-def test_square_selection():
-    """Test selection of diamond positions"""
-    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(5, 5))
-    z = ds.get_selection_square(0)
-    assert np.all(z == np.array([[0, 0, 2, 0, 2, 0, 0],
-                                 [0, 2, 1, 2, 1, 2, 0],
-                                 [2, 1, 2, 1, 2, 1, 2],
-                                 [0, 2, 1, 2, 1, 2, 0],
-                                 [2, 1, 2, 1, 2, 1, 2],
-                                 [0, 2, 1, 2, 1, 2, 0],
-                                 [0, 0, 2, 0, 2, 0, 0]]))
-    z = ds.get_selection_square(1)
-    assert np.all(z == np.array([[0, 0, 0, 0, 2, 0, 0, 0, 0],
-                                 [0, 0, 0, 0, 0, 0, 0, 0, 0],
-                                 [0, 0, 2, 0, 1, 0, 2, 0, 0],
-                                 [0, 0, 0, 0, 0, 0, 0, 0, 0],
-                                 [2, 0, 1, 0, 2, 0, 1, 0, 2],
-                                 [0, 0, 0, 0, 0, 0, 0, 0, 0],
-                                 [0, 0, 2, 0, 1, 0, 2, 0, 0],
-                                 [0, 0, 0, 0, 0, 0, 0, 0, 0],
-                                 [0, 0, 0, 0, 2, 0, 0, 0, 0]]))
-
-
-def test_random_initialization():
-    """Test random initialization of corner points"""
-    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(5, 6), seed=52062)
-    ds.random_initialization()
-    m_pow_max = min(ds.n, ds.m)
-    step_size = int(2 ** m_pow_max)
-    np.testing.assert_array_almost_equal(ds.grid[::step_size, ::step_size],
-                                         np.array([[0.35127005, 0.55476571, 0.93745213],
-                                                   [0.66668382, 0.85215985, 0.53222795]]))
-
-
-def test_random_initialization_level():
-    """Test random initialization on lower level"""
-    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(33, 33), seed=52062)
-    level = 3
-    ds.random_initialization(level=level)
-    step_size = int(2 ** level)
-    np.testing.assert_array_almost_equal(ds.grid[::step_size, ::step_size],
-                                         np.array([[0.35127005, 0.55476571, 0.93745213, 0.66668382, 0.85215985],
-                                                   [0.53222795, 0.55800027, 0.20974513, 0.74837501, 0.64394326],
-                                                   [0.0359961, 0.22723278, 0.56347804, 0.13438884, 0.32613594],
-                                                   [0.20868763, 0.03116471, 0.1498014, 0.20755495, 0.86021482],
-                                                   [0.64707457, 0.44744272, 0.36504945, 0.52473407, 0.27948164]]))
-
-def test_reset_grid():
-    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(5, 6), seed=52062)
-    ds.random_initialization()
-    ds.reset_grid()
-    np.testing.assert_array_almost_equal(ds.grid,
-                                         np.array([[0., 0., 0., 0., 0., 0., 0., 0., 0.],
-                                                   [0., 0., 0., 0., 0., 0., 0., 0., 0.],
-                                                   [0., 0., 0., 0., 0., 0., 0., 0., 0.],
-                                                   [0., 0., 0., 0., 0., 0., 0., 0., 0.],
-                                                   [0., 0., 0., 0., 0., 0., 0., 0., 0.]]))
-
-
-def test_random_func():
-    """Test random function implementation"""
-    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(33, 33), seed=52062)
-    np.testing.assert_array_almost_equal(ds.random_func(2, 2),
-                                         np.array([-0.14872995, 0.05476571]))
-    # testing for correct default implementation
-    ds.r_type = 'default'
-    np.testing.assert_array_almost_equal(ds.random_func(2, 2),
-                                         np.array([0.43745213, 0.16668382]))
-    # testing long-range correlation
-    ds.r_type = 'long_range'
-    np.testing.assert_array_almost_equal(ds.random_func(2, 2),
-                                         np.array([0.04401998, 0.00402849]))
-    # testing level-scale correlation
-    ds.r_type = 'level_scale'
-    np.testing.assert_array_almost_equal(ds.random_func(2, 2),
-                                         np.array([0.18600009, 0.06991504]))
-    # testing deterministic implementation (no random value)
-    ds.r_type = 'deterministic'
-    assert ds.random_func(2, 2) == 0.0
-
-
-def test_random_func_raises_error():
-    """Test if random function raises NonImplementedError correctly"""
-    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(33, 33), seed=52062)
-    ds.r_type = 'fail'
-
-    with pytest.raises(NotImplementedError):
-        ds.random_func(2, 2)
-
-
-def test_interpolate():
-    """Test interpolation step itself"""
-    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(9, 9), seed=52062)
-    ds.interpolate()
-    np.testing.assert_array_almost_equal(ds.grid,
-                                         np.array([[0., 0.2951411, 0.21781267, 0.29361906, 0.01037812,
-                                                    -0.0376406, -0.59889259, 0.01136296, 0.],
-                                                   [-0.13102895, -0.07079394, 0.40240191, -0.24139454, -0.64535709,
-                                                    -0.25358984, -0.20811689, -0.38977623, -0.02280871],
-                                                   [-0.32311967, -0.08246826, 0.03236034, -0.72313104, -0.6863271,
-                                                    -0.09742037, 0.16154592, -0.41643384, -0.23968483],
-                                                   [-0.53344647, -0.09313507, -0.66247738, -0.42849468, -0.06519284,
-                                                    -0.50628043, -0.31159035, 0.53516982, 0.07387422],
-                                                   [0.23421434, 0.32817758, -0.45156142, -0.24627659, -0.2974599,
-                                                    0.16071127, 0.36261452, 0.62070397, 0.60516641],
-                                                   [-0.20172896, -0.05668301, -0.26331217, -0.22196496, 0.42029741,
-                                                    0.35078669, 0.77129922, 0.38999358, 0.95701668],
-                                                   [-0.41296032, -0.04377428, -0.23235603, 0.60954786, 0.72643437,
-                                                    0.37788456, 0.62211967, 0.16198846, 0.61709021],
-                                                   [0.00192109, -0.28399285, 0.28596529, 0.54081866, 1.00235637,
-                                                    0.25454729, 0.1248549, 0.85789169, 0.23511424],
-                                                   [0., -0.54507578, -0.33592062, 0.62216544, 0.77575097,
-                                                    0.5338132, 0.22007596, 0.02926128, 0.]]))
+import gempy.core.grid_modules.diamond_square
+import pytest  # to add fixtures and to test error raises
+import numpy as np  # as another testing environment
+
+
+def test_class_nocrash():
+    """Simply check if class can be instantiated"""
+    gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(5, 5))
+
+
+def test_grid_generation():
+    """Test grid generation and extension for non-suitable grid sizes"""
+    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(5, 5))
+    assert ds.grid.shape == (5, 5)
+    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(8, 10))
+    assert ds.grid.shape == (9, 17)
+
+
+def test_diamond_selection():
+    """Test selection of diamond positions"""
+    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(5, 5))
+    z = ds.get_selection_diamond(1)
+    assert np.all(z == np.array([[2, 0, 0, 0, 2],
+                                 [0, 0, 0, 0, 0],
+                                 [0, 0, 1, 0, 0],
+                                 [0, 0, 0, 0, 0],
+                                 [2, 0, 0, 0, 2]]))
+    z = ds.get_selection_diamond(0)
+    assert np.all(z == np.array([[2, 0, 2, 0, 2],
+                                 [0, 1, 0, 1, 0],
+                                 [2, 0, 2, 0, 2],
+                                 [0, 1, 0, 1, 0],
+                                 [2, 0, 2, 0, 2]]))
+
+
+def test_square_selection():
+    """Test selection of diamond positions"""
+    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(5, 5))
+    z = ds.get_selection_square(0)
+    assert np.all(z == np.array([[0, 0, 2, 0, 2, 0, 0],
+                                 [0, 2, 1, 2, 1, 2, 0],
+                                 [2, 1, 2, 1, 2, 1, 2],
+                                 [0, 2, 1, 2, 1, 2, 0],
+                                 [2, 1, 2, 1, 2, 1, 2],
+                                 [0, 2, 1, 2, 1, 2, 0],
+                                 [0, 0, 2, 0, 2, 0, 0]]))
+    z = ds.get_selection_square(1)
+    assert np.all(z == np.array([[0, 0, 0, 0, 2, 0, 0, 0, 0],
+                                 [0, 0, 0, 0, 0, 0, 0, 0, 0],
+                                 [0, 0, 2, 0, 1, 0, 2, 0, 0],
+                                 [0, 0, 0, 0, 0, 0, 0, 0, 0],
+                                 [2, 0, 1, 0, 2, 0, 1, 0, 2],
+                                 [0, 0, 0, 0, 0, 0, 0, 0, 0],
+                                 [0, 0, 2, 0, 1, 0, 2, 0, 0],
+                                 [0, 0, 0, 0, 0, 0, 0, 0, 0],
+                                 [0, 0, 0, 0, 2, 0, 0, 0, 0]]))
+
+
+def test_random_initialization():
+    """Test random initialization of corner points"""
+    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(5, 6), seed=52062)
+    ds.random_initialization()
+    m_pow_max = min(ds.n, ds.m)
+    step_size = int(2 ** m_pow_max)
+    np.testing.assert_array_almost_equal(ds.grid[::step_size, ::step_size],
+                                         np.array([[0.35127005, 0.55476571, 0.93745213],
+                                                   [0.66668382, 0.85215985, 0.53222795]]))
+
+
+def test_random_initialization_level():
+    """Test random initialization on lower level"""
+    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(33, 33), seed=52062)
+    level = 3
+    ds.random_initialization(level=level)
+    step_size = int(2 ** level)
+    np.testing.assert_array_almost_equal(ds.grid[::step_size, ::step_size],
+                                         np.array([[0.35127005, 0.55476571, 0.93745213, 0.66668382, 0.85215985],
+                                                   [0.53222795, 0.55800027, 0.20974513, 0.74837501, 0.64394326],
+                                                   [0.0359961, 0.22723278, 0.56347804, 0.13438884, 0.32613594],
+                                                   [0.20868763, 0.03116471, 0.1498014, 0.20755495, 0.86021482],
+                                                   [0.64707457, 0.44744272, 0.36504945, 0.52473407, 0.27948164]]))
+
+def test_reset_grid():
+    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(5, 6), seed=52062)
+    ds.random_initialization()
+    ds.reset_grid()
+    np.testing.assert_array_almost_equal(ds.grid,
+                                         np.array([[0., 0., 0., 0., 0., 0., 0., 0., 0.],
+                                                   [0., 0., 0., 0., 0., 0., 0., 0., 0.],
+                                                   [0., 0., 0., 0., 0., 0., 0., 0., 0.],
+                                                   [0., 0., 0., 0., 0., 0., 0., 0., 0.],
+                                                   [0., 0., 0., 0., 0., 0., 0., 0., 0.]]))
+
+
+def test_random_func():
+    """Test random function implementation"""
+    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(33, 33), seed=52062)
+    np.testing.assert_array_almost_equal(ds.random_func(2, 2),
+                                         np.array([-0.14872995, 0.05476571]))
+    # testing for correct default implementation
+    ds.r_type = 'default'
+    np.testing.assert_array_almost_equal(ds.random_func(2, 2),
+                                         np.array([0.43745213, 0.16668382]))
+    # testing long-range correlation
+    ds.r_type = 'long_range'
+    np.testing.assert_array_almost_equal(ds.random_func(2, 2),
+                                         np.array([0.04401998, 0.00402849]))
+    # testing level-scale correlation
+    ds.r_type = 'level_scale'
+    np.testing.assert_array_almost_equal(ds.random_func(2, 2),
+                                         np.array([0.18600009, 0.06991504]))
+    # testing deterministic implementation (no random value)
+    ds.r_type = 'deterministic'
+    assert ds.random_func(2, 2) == 0.0
+
+
+def test_random_func_raises_error():
+    """Test if random function raises NonImplementedError correctly"""
+    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(33, 33), seed=52062)
+    ds.r_type = 'fail'
+
+    with pytest.raises(NotImplementedError):
+        ds.random_func(2, 2)
+
+
+def test_interpolate():
+    """Test interpolation step itself"""
+    ds = gempy.core.grid_modules.diamond_square.DiaomondSquare(size=(9, 9), seed=52062)
+    ds.interpolate()
+    np.testing.assert_array_almost_equal(ds.grid,
+                                         np.array([[0., 0.2951411, 0.21781267, 0.29361906, 0.01037812,
+                                                    -0.0376406, -0.59889259, 0.01136296, 0.],
+                                                   [-0.13102895, -0.07079394, 0.40240191, -0.24139454, -0.64535709,
+                                                    -0.25358984, -0.20811689, -0.38977623, -0.02280871],
+                                                   [-0.32311967, -0.08246826, 0.03236034, -0.72313104, -0.6863271,
+                                                    -0.09742037, 0.16154592, -0.41643384, -0.23968483],
+                                                   [-0.53344647, -0.09313507, -0.66247738, -0.42849468, -0.06519284,
+                                                    -0.50628043, -0.31159035, 0.53516982, 0.07387422],
+                                                   [0.23421434, 0.32817758, -0.45156142, -0.24627659, -0.2974599,
+                                                    0.16071127, 0.36261452, 0.62070397, 0.60516641],
+                                                   [-0.20172896, -0.05668301, -0.26331217, -0.22196496, 0.42029741,
+                                                    0.35078669, 0.77129922, 0.38999358, 0.95701668],
+                                                   [-0.41296032, -0.04377428, -0.23235603, 0.60954786, 0.72643437,
+                                                    0.37788456, 0.62211967, 0.16198846, 0.61709021],
+                                                   [0.00192109, -0.28399285, 0.28596529, 0.54081866, 1.00235637,
+                                                    0.25454729, 0.1248549, 0.85789169, 0.23511424],
+                                                   [0., -0.54507578, -0.33592062, 0.62216544, 0.77575097,
+                                                    0.5338132, 0.22007596, 0.02926128, 0.]]))
```

### Comparing `gempy-2.2b10.dev1/test/test_core/test_grids/test_grid.py` & `gempy-2.3.0/test/test_core/test_grids/test_grid.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,62 +1,64 @@
-# Importing GemPy
-import gempy as gp
-
-
-# Importing auxiliary libraries
-import numpy as np
-
-
-class TestGrid:
-    def test_set_regular_grid(self):
-        # Test creating an empty list
-        grid = gp.Grid()
-
-        # Test set regular grid by hand
-        grid.create_regular_grid([0, 2000, 0, 2000, -2000, 0], [50, 50, 50])
-
-    def test_grid_init(self):
-        # Or we can init one of the default grids since the beginning by passing
-        # the correspondant attributes
-        grid = gp.Grid(extent=[0, 2000, 0, 2000, -2000, 0],
-                       resolution=[50, 50, 50])
-
-    def test_section_grid(self):
-        geo_data = gp.create_data('section_grid', [0, 1000, 0, 1000, 0, 1000], resolution=[10, 10, 10])
-        geo_data.set_topography()
-        section_dict = {'section1': ([0, 0], [1000, 1000], [100, 80]),
-                        'section2': ([800, 0], [800, 1000], [150, 100]),
-                        'section3': ([50, 200], [100, 500], [200, 150])}
-
-        geo_data.set_section_grid(section_dict)
-
-        print(geo_data._grid.sections)
-        np.testing.assert_almost_equal(geo_data._grid.sections.df.loc['section3', 'dist'], 304.138127,
-                                       decimal=4)
-
-    def test_set_section_twice(self):
-        geo_data = gp.create_data(extent=[0, 1000, 0, 1000, 0, 1000], resolution=[10, 10, 10])
-        section_dict = {'section1': ([0, 0], [1000, 1000], [100, 80]),
-                        'section2': ([800, 0], [800, 1000], [150, 100]),
-                        'section3': ([50, 200], [100, 500], [200, 150])}
-
-        geo_data.set_section_grid(section_dict)
-        geo_data.set_section_grid(section_dict)
-        print(geo_data._grid.sections)
-
-    def test_custom_grid(self):
-        # create custom grid
-        grid = gp.Grid()
-        cg = np.array([[1, 2, 3],
-                        [4, 5, 6],
-                        [7, 8, 9]])
-        grid.create_custom_grid(cg)
-        # make sure the custom grid is active
-        assert grid.active_grids[1]
-        # make sure the custom grid is equal to the provided values
-        np.testing.assert_array_almost_equal(cg, grid.custom_grid.values)
-        # make sure we have the correct number of values in our grid
-        l0, l1 = grid.get_grid_args('custom')
-        assert l0 == 0
-        assert l1 == 3
-
-
+# Importing GemPy
+import gempy as gp
+
+
+# Importing auxiliary libraries
+import numpy as np
+
+import gempy.core.grid
+
+
+class TestGrid:
+    def test_set_regular_grid(self):
+        # Test creating an empty list
+        grid = gempy.core.grid.Grid()
+
+        # Test set regular grid by hand
+        grid.create_regular_grid([0, 2000, 0, 2000, -2000, 0], [50, 50, 50])
+
+    def test_grid_init(self):
+        # Or we can init one of the default grids since the beginning by passing
+        # the correspondant attributes
+        grid = gempy.core.grid.Grid(extent=[0, 2000, 0, 2000, -2000, 0],
+                                    resolution=[50, 50, 50])
+
+    def test_section_grid(self):
+        geo_data = gp.create_data('section_grid', [0, 1000, 0, 1000, 0, 1000], resolution=[10, 10, 10])
+        geo_data.set_topography()
+        section_dict = {'section1': ([0, 0], [1000, 1000], [100, 80]),
+                        'section2': ([800, 0], [800, 1000], [150, 100]),
+                        'section3': ([50, 200], [100, 500], [200, 150])}
+
+        geo_data.set_section_grid(section_dict)
+
+        print(geo_data._grid.sections)
+        np.testing.assert_almost_equal(geo_data._grid.sections.df.loc['section3', 'dist'], 304.138127,
+                                       decimal=4)
+
+    def test_set_section_twice(self):
+        geo_data = gp.create_data(extent=[0, 1000, 0, 1000, 0, 1000], resolution=[10, 10, 10])
+        section_dict = {'section1': ([0, 0], [1000, 1000], [100, 80]),
+                        'section2': ([800, 0], [800, 1000], [150, 100]),
+                        'section3': ([50, 200], [100, 500], [200, 150])}
+
+        geo_data.set_section_grid(section_dict)
+        geo_data.set_section_grid(section_dict)
+        print(geo_data._grid.sections)
+
+    def test_custom_grid(self):
+        # create custom grid
+        grid = gempy.core.grid.Grid()
+        cg = np.array([[1, 2, 3],
+                        [4, 5, 6],
+                        [7, 8, 9]])
+        grid.create_custom_grid(cg)
+        # make sure the custom grid is active
+        assert grid.active_grids[1]
+        # make sure the custom grid is equal to the provided values
+        np.testing.assert_array_almost_equal(cg, grid.custom_grid.values)
+        # make sure we have the correct number of values in our grid
+        l0, l1 = grid.get_grid_args('custom')
+        assert l0 == 0
+        assert l1 == 3
+
+
```

### Comparing `gempy-2.2b10.dev1/test/test_core/test_grids/test_topography.py` & `gempy-2.3.0/test/test_core/test_grids/test_topography.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,140 +1,139 @@
-import os
-import sys, os
-sys.path.append("../../..")
-
-os.environ["THEANO_FLAGS"] = "mode=FAST_RUN,device=cpu"
-import warnings
-
-try:
-    import faulthandler
-    faulthandler.enable()
-except Exception as e:  # pragma: no cover
-    warnings.warn('Unable to enable faulthandler:\n%s' % str(e))
-
-import gempy as gp
-import matplotlib.pyplot as plt
-from gempy.core.grid_modules.topography import Topography
-import pytest
-
-import numpy as np
-data_path = os.path.dirname(__file__)+'/../../input_data'
-
-
-@pytest.fixture(scope='module')
-def artificial_grid(one_fault_model_no_interp):
-    geo_model = one_fault_model_no_interp
-    topo = Topography(geo_model._grid.regular_grid)
-    topo.load_random_hills()
-    print(topo.values, topo.values_2d)
-    return topo
-
-
-@pytest.mark.skipif("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true",
-                    reason="Skipping this test on Travis CI because gdal.")
-def test_real_grid_ales():
-    resolution = [30, 20, 50]
-    extent = np.array([729550.0, 751500.0, 1913500.0, 1923650.0, -50, 800.0])
-    path_interf = data_path + "/2018_interf.csv"
-    path_orient = data_path + "/2018_orient_clust_n_init5_0.csv"
-    path_dem = data_path + "/_cropped_DEM_coarse.tif"
-
-    geo_model = gp.create_model('Alesmodel')
-    gp.init_data(geo_model, extent=extent, resolution=resolution,
-                 path_i=path_interf,
-                 path_o=path_orient)
-
-    geo_model.set_topography(source='gdal', filepath=path_dem)
-
-    p2d = gp.plot_2d(geo_model, section_names=['topography'], show_topography=True,
-                     kwargs_topography={'hillshade': False, 'fill_contour': False})
-    plt.show()
-
-    p2d = gp.plot_2d(geo_model, section_names=['topography'], show_topography=True,
-                     kwargs_topography={'hillshade': False, 'fill_contour': True})
-    plt.show()
-
-    p2d = gp.plot_2d(geo_model, section_names=['topography'], show_topography=True,
-                     kwargs_topography={'hillshade': True, 'fill_contour': True})
-    plt.show()
-
-    if False:
-        gp.map_stack_to_surfaces(geo_model, {'fault_left': ('fault_left'),
-                                              'fault_right': ('fault_right'),
-                                              'fault_lr': ('fault_lr'),
-                                              'Trias_Series': ('TRIAS', 'LIAS'),
-                                              'Carbon_Series': ('CARBO'),
-                                              'Basement_Series': ('basement')}, remove_unused_series=True)
-
-        geo_model.set_is_fault(['fault_right', 'fault_left', 'fault_lr'], change_color=True)
-        gp.set_interpolator(geo_model,
-                                  output=['geology'], compile_theano=True,
-                                  theano_optimizer='fast_run', dtype='float64',
-                                  verbose=[])
-
-        gp.compute_model(geo_model, compute_mesh=True)
-
-        geo_model._grid.regular_grid.set_topography_mask(geo_model._grid.topography)
-
-    gpv = gp.plot.plot_3d(geo_model,
-                          plotter_type='basic', off_screen=True,
-                          show_topography=True,
-                          show_scalar=False,
-                          show_lith=True,
-                          show_surfaces=False,
-                          kwargs_plot_structured_grid={'opacity': 1,
-                                                       'show_edges': False},
-                          ve=10,
-                          image=True,
-                          kwargs_plot_topography={'scalars': 'topography'})
-    #
-    # gpv.p.set_scale(zscale=10)
-    #
-    # img = gpv.p.show(screenshot=True)
-    # plt.imshow(img[1])
-    # plt.show()
-
-
-def test_plot_2d_topography(one_fault_model_no_interp, artificial_grid):
-    geo_model = one_fault_model_no_interp
-    #geo_model._grid.topography = artificial_grid
-    geo_model.set_topography()
-    p2d = gp.plot_2d(geo_model, section_names=['topography'], show_topography=True,
-                     kwargs_topography={'hillshade': False})
-    plt.show()
-
-    p2d = gp.plot_2d(geo_model, section_names=['topography'], show_topography=True,
-                     kwargs_topography={'hillshade': True, 'fill_contour': False})
-    plt.show()
-
-    p2d = gp.plot_2d(geo_model, section_names=['topography'], show_topography=True,
-                     kwargs_topography={'hillshade': True})
-    plt.show()
-
-
-def test_plot_3d_structure_topo2(unconformity_model_topo, artificial_grid):
-
-    geo_model = unconformity_model_topo
-    with pytest.raises(AssertionError):
-        geo_model._grid.regular_grid.set_topography_mask(artificial_grid)
-
-    # geo_model._grid.regular_grid.set_topography_mask(geo_model._grid.topography)
-
-    p2d = gp.plot_2d(geo_model, section_names=['topography'], show_topography=True,
-                     show_lith=False,
-                     kwargs_topography={'hillshade': True})
-    plt.show()
-
-    gpv = gp.plot.plot_3d(unconformity_model_topo,
-                          plotter_type='basic', off_screen=True,
-                          show_topography=True,
-                          show_scalar=False,
-                          show_lith=True,
-                          show_surfaces=True,
-                          kwargs_plot_structured_grid={'opacity': .5,
-                                                       'show_edges': True},
-                          image=True,
-                          kwargs_plot_topography={'scalars': 'topography'})
-
-    # img = gpv.p.show(screenshot=True)
-    # plt.imshow(img[1])
-    # plt.show()
+import os
+import sys
+
+import gempy as gp
+import matplotlib as mpl
+mpl.use('Agg')
+import matplotlib.pyplot as plt
+
+from gempy.core.grid_modules.create_topography import GDAL_IMPORT
+from gempy.core.grid_modules.topography import Topography
+import pytest
+
+import numpy as np
+
+sys.path.append("../../..")
+os.environ["aesara_FLAGS"] = "mode=FAST_RUN,device=cpu"
+data_path = os.path.dirname(__file__) + '/../../input_data'
+
+pytest.importorskip("osgeo.gdal")
+
+
+@pytest.fixture(scope='module')
+def artificial_grid(one_fault_model_no_interp):
+    geo_model = one_fault_model_no_interp
+    topo = Topography(geo_model._grid.regular_grid)
+    topo.load_random_hills()
+    print(topo.values, topo.values_2d)
+    return topo
+
+
+@pytest.mark.skipif(("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true") or
+                    ("GITHUBACTION" in os.environ and os.environ["GITHUBACTION"] == "true"),
+                    reason="Skipping this test on Travis CI because gdal.")
+def test_real_grid_ales():
+    resolution = [30, 20, 50]
+    extent = np.array([729550.0, 751500.0, 1913500.0, 1923650.0, -50, 800.0])
+    path_interf = data_path + "/2018_interf.csv"
+    path_orient = data_path + "/2018_orient_clust_n_init5_0.csv"
+    path_dem = data_path + "/_cropped_DEM_coarse.tif"
+
+    geo_model = gp.create_model('Alesmodel')
+    gp.init_data(geo_model, extent=extent, resolution=resolution,
+                 path_i=path_interf,
+                 path_o=path_orient)
+
+    geo_model.set_topography(source='gdal', filepath=path_dem)
+
+    p2d = gp.plot_2d(geo_model, section_names=['topography'], show_topography=True,
+                     kwargs_topography={'hillshade': False, 'fill_contour': False})
+    plt.show()
+
+    p2d = gp.plot_2d(geo_model, section_names=['topography'], show_topography=True,
+                     kwargs_topography={'hillshade': False, 'fill_contour': True})
+    plt.show()
+
+    p2d = gp.plot_2d(geo_model, section_names=['topography'], show_topography=True,
+                     kwargs_topography={'hillshade': True, 'fill_contour': True})
+    plt.show()
+
+    if False:
+        gp.map_stack_to_surfaces(geo_model, {'fault_left'     : ('fault_left'),
+                                             'fault_right'    : ('fault_right'),
+                                             'fault_lr'       : ('fault_lr'),
+                                             'Trias_Series'   : ('TRIAS', 'LIAS'),
+                                             'Carbon_Series'  : ('CARBO'),
+                                             'Basement_Series': ('basement')}, remove_unused_series=True)
+
+        geo_model.set_is_fault(['fault_right', 'fault_left', 'fault_lr'], change_color=True)
+        gp.set_interpolator(geo_model,
+                            output=['geology'], compile_aesara=True,
+                            aesara_optimizer='fast_run', dtype='float64',
+                            verbose=[])
+
+        gp.compute_model(geo_model, compute_mesh=True)
+
+        geo_model._grid.regular_grid.set_topography_mask(geo_model._grid.topography)
+
+    gpv = gp.plot.plot_3d(geo_model,
+                          plotter_type='basic', off_screen=True,
+                          show_topography=True,
+                          show_scalar=False,
+                          show_lith=True,
+                          show_surfaces=False,
+                          kwargs_plot_structured_grid={'opacity'   : 1,
+                                                       'show_edges': False},
+                          ve=10,
+                          image=True,
+                          kwargs_plot_topography={'scalars': 'topography'})
+    #
+    # gpv.p.set_scale(zscale=10)
+    #
+    # img = gpv.p.show(screenshot=True)
+    # plt.imshow(img[1])
+    # plt.show()
+
+
+def test_plot_2d_topography(one_fault_model_no_interp, artificial_grid):
+    geo_model = one_fault_model_no_interp
+    # geo_model._grid.topography = artificial_grid
+    geo_model.set_topography()
+    p2d = gp.plot_2d(geo_model, section_names=['topography'], show_topography=True,
+                     kwargs_topography={'hillshade': False})
+    plt.show()
+
+    p2d = gp.plot_2d(geo_model, section_names=['topography'], show_topography=True,
+                     kwargs_topography={'hillshade': True, 'fill_contour': False})
+    plt.show()
+
+    p2d = gp.plot_2d(geo_model, section_names=['topography'], show_topography=True,
+                     kwargs_topography={'hillshade': True})
+    plt.show()
+
+
+def test_plot_3d_structure_topo2(unconformity_model_topo, artificial_grid):
+    geo_model = unconformity_model_topo
+    with pytest.raises(AssertionError):
+        geo_model._grid.regular_grid.set_topography_mask(artificial_grid)
+
+    # geo_model._grid.regular_grid.set_topography_mask(geo_model._grid.topography)
+
+    p2d = gp.plot_2d(geo_model, section_names=['topography'], show_topography=True,
+                     show_lith=False,
+                     kwargs_topography={'hillshade': True})
+    plt.show()
+
+    gpv = gp.plot.plot_3d(unconformity_model_topo,
+                          plotter_type='basic', off_screen=True,
+                          show_topography=True,
+                          show_scalar=False,
+                          show_lith=True,
+                          show_surfaces=True,
+                          kwargs_plot_structured_grid={'opacity'   : .5,
+                                                       'show_edges': True},
+                          image=True,
+                          kwargs_plot_topography={'scalars': 'topography'})
+
+    # img = gpv.p.show(screenshot=True)
+    # plt.imshow(img[1])
+    # plt.show()
```

### Comparing `gempy-2.2b10.dev1/test/test_core/test_model.py` & `gempy-2.3.0/test/test_core/test_model.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,173 +1,203 @@
-import gempy as gp
-import matplotlib.pyplot as plt
-import pandas as pn
-import numpy as np
-import os
-import pytest
-input_path = os.path.dirname(__file__)+'/../input_data'
-
-# ## Preparing the Python environment
-#
-# For modeling with GemPy, we first need to import it. We should also import any other packages we want to
-# utilize in our Python environment.Typically, we will also require `NumPy` and `Matplotlib` when working
-# with GemPy. At this point, we can further customize some settings as desired, e.g. the size of figures or,
-# as we do here, the way that `Matplotlib` figures are displayed in our notebook (`%matplotlib inline`).
-
-
-# These two lines are necessary only if GemPy is not installed
-import sys, os
-sys.path.append("../..")
-
-
-@pytest.fixture(scope="module")
-def load_model():
-    verbose = False
-    geo_model = gp.create_model('Model_Tuto1-1')
-
-    # Importing the data from CSV-files and setting extent and resolution
-    gp.init_data(geo_model, [0, 2000., 0, 2000., 0, 2000.], [50 ,50 ,50],
-                 path_o=input_path+"/simple_fault_model_orientations.csv",
-                 path_i=input_path+"/simple_fault_model_points.csv", default_values=True)
-
-    df_cmp_i = gp.get_data(geo_model, 'surface_points')
-    df_cmp_o = gp.get_data(geo_model, 'orientations')
-
-    df_o = pn.read_csv(input_path + "/simple_fault_model_orientations.csv")
-    df_i = pn.read_csv(input_path + "/simple_fault_model_points.csv")
-
-    assert not df_cmp_i.empty, 'data was not set to dataframe'
-    assert not df_cmp_o.empty, 'data was not set to dataframe'
-    assert df_cmp_i.shape[0] == df_i.shape[0], 'data was not set to dataframe'
-    assert df_cmp_o.shape[0] == df_o.shape[0], 'data was not set to dataframe'
-
-    if verbose:
-        gp.get_data(geo_model, 'surface_points').head()
-
-    return geo_model
-
-
-def test_load_model_df():
-
-    verbose = True
-    df_i = pn.DataFrame(np.random.randn(6,3), columns='X Y Z'.split())
-    df_i['formation'] = ['surface_1' for _ in range(3)] + ['surface_2' for _ in range(3)]
-
-    df_o = pn.DataFrame(np.random.randn(6,6), columns='X Y Z azimuth dip polarity'.split())
-    df_o['formation'] = ['surface_1' for _ in range(3)] + ['surface_2' for _ in range(3)]
-
-    geo_model = gp.create_model('test')
-    # Importing the data directly from the dataframes
-    gp.init_data(geo_model, [0, 2000., 0, 2000., 0, 2000.], [50, 50, 50],
-                 surface_points_df=df_i, orientations_df=df_o, default_values=True)
-
-    df_cmp_i = gp.get_data(geo_model, 'surface_points')
-    df_cmp_o = gp.get_data(geo_model, 'orientations')
-
-    if verbose:
-        print(df_cmp_i.head())
-        print(df_cmp_o.head())
-
-    assert not df_cmp_i.empty, 'data was not set to dataframe'
-    assert not df_cmp_o.empty, 'data was not set to dataframe'
-    assert df_cmp_i.shape[0] == 6, 'data was not set to dataframe'
-    assert df_cmp_o.shape[0] == 6, 'data was not set to dataframe'
-
-    # try without the default_values command
-
-    geo_model = gp.create_model('test')
-    # Importing the data directly from the dataframes
-    gp.init_data(geo_model, [0, 2000., 0, 2000., 0, 2000.], [50 ,50 ,50],
-                 surface_points_df=df_i, orientations_df=df_o)
-
-    df_cmp_i2 = gp.get_data(geo_model, 'surface_points')
-    df_cmp_o2 = gp.get_data(geo_model, 'orientations')
-
-    if verbose:
-        print(df_cmp_i2.head())
-        print(df_cmp_o2.head())
-
-    assert not df_cmp_i2.empty, 'data was not set to dataframe'
-    assert not df_cmp_o2.empty, 'data was not set to dataframe'
-    assert df_cmp_i2.shape[0] == 6, 'data was not set to dataframe'
-    assert df_cmp_o2.shape[0] == 6, 'data was not set to dataframe'
-
-    return geo_model
-
-
-@pytest.fixture(scope='module')
-def map_sequential_pile(load_model):
-    geo_model = load_model
-
-    # TODO decide what I do with the layer order
-
-    gp.map_stack_to_surfaces(geo_model, {"Fault_Series": 'Main_Fault',
-                                          "Strat_Series": ('Sandstone_2', 'Siltstone',
-                                                           'Shale', 'Sandstone_1', 'basement')},
-                             remove_unused_series=True)
-
-    geo_model.set_is_fault(['Fault_Series'])
-    return geo_model
-
-
-def test_get_data(load_model):
-    geo_model = load_model
-    return gp.get_data(geo_model, 'orientations').head()
-
-
-def test_define_sequential_pile(map_sequential_pile):
-    print(map_sequential_pile._surfaces)
-
-
-def test_compute_model(interpolator, map_sequential_pile):
-    geo_model = map_sequential_pile
-    geo_model.set_theano_graph(interpolator)
-
-    gp.compute_model(geo_model, compute_mesh=False)
-
-    test_values = [45, 150, 2500]
-    if False:
-        np.save(input_path+'/test_integration_lith_block.npy', geo_model.solutions.lith_block[test_values])
-
-    # Load model
-    real_sol = np.load(input_path + '/test_integration_lith_block.npy')
-
-    # We only compare the block because the absolute pot field I changed it
-    np.testing.assert_array_almost_equal(np.round(geo_model.solutions.lith_block[test_values]), real_sol, decimal=0)
-
-    gp.plot.plot_2d(geo_model, cell_number=25,
-                    direction='y', show_data=True)
-    plt.savefig(os.path.dirname(__file__)+'/../figs/test_integration_lith_block')
-
-    gp.plot.plot_2d(geo_model, cell_number=25, series_n=1, N=15, show_scalar=True,
-                    direction='y', show_data=True)
-
-    plt.savefig(os.path.dirname(__file__)+'/../figs/test_integration_scalar')
-
-
-def test_kriging_mutation(interpolator, map_sequential_pile):
-    geo_model = map_sequential_pile
-    geo_model.set_theano_graph(interpolator)
-
-    gp.compute_model(geo_model, compute_mesh=False)
-    gp.plot.plot_2d(geo_model, cell_number=25, show_scalar=True, series_n=1, N=15,
-                    direction='y', show_data=True)
-    print(geo_model.solutions.lith_block, geo_model._additional_data)
-    #plt.savefig(os.path.dirname(__file__)+'/figs/test_kriging_mutation')
-
-    geo_model.modify_kriging_parameters('range', 1)
-    geo_model.modify_kriging_parameters('drift equations', [0, 3])
-
-    print(geo_model.solutions.lith_block, geo_model._additional_data)
-    # copy dataframe before interpolator is calculated
-    pre = geo_model._additional_data.kriging_data.df.copy()
-
-    gp.set_interpolator(geo_model, compile_theano=True,
-                        theano_optimizer='fast_compile', update_kriging=False)
-    gp.compute_model(geo_model, compute_mesh=False)
-
-    gp.plot.plot_2d(geo_model, cell_number=25, series_n=1, N=15, show_boundaries=False,
-                    direction='y', show_data=True, show_lith=True)
-
-    print(geo_model.solutions.lith_block, geo_model._additional_data)
-    plt.savefig(os.path.dirname(__file__)+'/../figs/test_kriging_mutation2')
+import gempy as gp
+import matplotlib as mpl
+mpl.use('Agg')
+import matplotlib.pyplot as plt
+import pandas as pn
+import numpy as np
+import os
+import pytest
+input_path = os.path.dirname(__file__)+'/../input_data'
+
+# ## Preparing the Python environment
+#
+# For modeling with GemPy, we first need to import it. We should also import any other packages we want to
+# utilize in our Python environment.Typically, we will also require `NumPy` and `Matplotlib` when working
+# with GemPy. At this point, we can further customize some settings as desired, e.g. the size of figures or,
+# as we do here, the way that `Matplotlib` figures are displayed in our notebook (`%matplotlib inline`).
+
+
+# These two lines are necessary only if GemPy is not installed
+import sys, os
+sys.path.append("../..")
+
+
+@pytest.fixture(scope="module")
+def load_model():
+    verbose = False
+    geo_model = gp.create_model('Model_Tuto1-1')
+
+    # Importing the data from CSV-files and setting extent and resolution
+    gp.init_data(geo_model, [0, 2000., 0, 2000., 0, 2000.], [50 ,50 ,50],
+                 path_o=input_path+"/simple_fault_model_orientations.csv",
+                 path_i=input_path+"/simple_fault_model_points.csv", default_values=True)
+
+    df_cmp_i = gp.get_data(geo_model, 'surface_points')
+    df_cmp_o = gp.get_data(geo_model, 'orientations')
+
+    df_o = pn.read_csv(input_path + "/simple_fault_model_orientations.csv")
+    df_i = pn.read_csv(input_path + "/simple_fault_model_points.csv")
+
+    assert not df_cmp_i.empty, 'data was not set to dataframe'
+    assert not df_cmp_o.empty, 'data was not set to dataframe'
+    assert df_cmp_i.shape[0] == df_i.shape[0], 'data was not set to dataframe'
+    assert df_cmp_o.shape[0] == df_o.shape[0], 'data was not set to dataframe'
+
+    if verbose:
+        gp.get_data(geo_model, 'surface_points').head()
+
+    return geo_model
+
+
+def test_load_model_df():
+
+    verbose = True
+    df_i = pn.DataFrame(np.random.randn(6,3), columns='X Y Z'.split())
+    df_i['formation'] = ['surface_1' for _ in range(3)] + ['surface_2' for _ in range(3)]
+
+    df_o = pn.DataFrame(np.random.randn(6,6), columns='X Y Z azimuth dip polarity'.split())
+    df_o['formation'] = ['surface_1' for _ in range(3)] + ['surface_2' for _ in range(3)]
+
+    geo_model = gp.create_model('test')
+    # Importing the data directly from the dataframes
+    gp.init_data(geo_model, [0, 2000., 0, 2000., 0, 2000.], [50, 50, 50],
+                 surface_points_df=df_i, orientations_df=df_o, default_values=True)
+
+    df_cmp_i = gp.get_data(geo_model, 'surface_points')
+    df_cmp_o = gp.get_data(geo_model, 'orientations')
+
+    if verbose:
+        print(df_cmp_i.head())
+        print(df_cmp_o.head())
+
+    assert not df_cmp_i.empty, 'data was not set to dataframe'
+    assert not df_cmp_o.empty, 'data was not set to dataframe'
+    assert df_cmp_i.shape[0] == 6, 'data was not set to dataframe'
+    assert df_cmp_o.shape[0] == 6, 'data was not set to dataframe'
+
+    # try without the default_values command
+
+    geo_model = gp.create_model('test')
+    # Importing the data directly from the dataframes
+    gp.init_data(geo_model, [0, 2000., 0, 2000., 0, 2000.], [50 ,50 ,50],
+                 surface_points_df=df_i, orientations_df=df_o)
+
+    df_cmp_i2 = gp.get_data(geo_model, 'surface_points')
+    df_cmp_o2 = gp.get_data(geo_model, 'orientations')
+
+    if verbose:
+        print(df_cmp_i2.head())
+        print(df_cmp_o2.head())
+
+    assert not df_cmp_i2.empty, 'data was not set to dataframe'
+    assert not df_cmp_o2.empty, 'data was not set to dataframe'
+    assert df_cmp_i2.shape[0] == 6, 'data was not set to dataframe'
+    assert df_cmp_o2.shape[0] == 6, 'data was not set to dataframe'
+
+    return geo_model
+
+
+@pytest.fixture(scope='module')
+def map_sequential_pile(load_model):
+    geo_model = load_model
+
+    # TODO decide what I do with the layer order
+
+    gp.map_stack_to_surfaces(geo_model, {"Fault_Series": 'Main_Fault',
+                                          "Strat_Series": ('Sandstone_2', 'Siltstone',
+                                                           'Shale', 'Sandstone_1', 'basement')},
+                             remove_unused_series=True)
+
+    geo_model.set_is_fault(['Fault_Series'])
+    return geo_model
+
+
+def test_get_data(load_model):
+    geo_model = load_model
+    return gp.get_data(geo_model, 'orientations').head()
+
+
+def test_define_sequential_pile(map_sequential_pile):
+    print(map_sequential_pile._surfaces)
+
+
+def test_sequential_pile_colors(load_model):
+    geo_model = load_model
+
+    gp.map_stack_to_surfaces(geo_model, {"Fault_Series": 'Main_Fault',
+                                          "Strat_Series": ('Sandstone_2', 'Siltstone',
+                                                           'Shale', 'Sandstone_1', 'basement')},
+                             remove_unused_series=True)
+
+    color1 = geo_model._surfaces.colors.colordict['Main_Fault']
+    geo_model.set_is_fault(['Fault_Series'], toggle=True)
+    color2 = geo_model._surfaces.colors.colordict['Main_Fault']
+    geo_model.set_is_fault(['Fault_Series'], toggle=True)
+    color3 = geo_model._surfaces.colors.colordict['Main_Fault']
+    assert color1 == color3
+    #print(color1, color2, color3)
+
+
+def test_compute_model(interpolator, map_sequential_pile):
+    geo_model = map_sequential_pile
+    geo_model.set_aesara_graph(interpolator)
+
+    gp.compute_model(geo_model, compute_mesh=False)
+
+    test_values = [45, 150, 2500]
+    if False:
+        np.save(input_path+'/test_integration_lith_block.npy', geo_model.solutions.lith_block[test_values])
+
+    # Load model
+    real_sol = np.load(input_path + '/test_integration_lith_block.npy')
+
+    # We only compare the block because the absolute pot field I changed it
+    np.testing.assert_array_almost_equal(np.round(geo_model.solutions.lith_block[test_values]), real_sol, decimal=0)
+
+    gp.plot.plot_2d(geo_model, cell_number=25,
+                    direction='y', show_data=True)
+    plt.savefig(os.path.dirname(__file__)+'/../figs/test_integration_lith_block')
+
+    gp.plot.plot_2d(geo_model, cell_number=25, series_n=1, N=15, show_scalar=True,
+                    direction='y', show_data=True)
+
+    plt.savefig(os.path.dirname(__file__)+'/../figs/test_integration_scalar')
+
+
+def test_save_model(interpolator, map_sequential_pile):
+    geo_model = map_sequential_pile
+    geo_model.set_aesara_function(interpolator)
+    gp.compute_model(geo_model, compute_mesh=False)
+    gp.save_model(geo_model, name='test_save_model', path=input_path+'/save_model/', save_solution=True,
+                  compress=False)
+
+    lith_block_sol = np.load(input_path+'/save_model/test_save_model/test_save_model_lith_block.npy')
+    np.testing.assert_array_almost_equal(geo_model.solutions.lith_block, lith_block_sol, decimal=0)
+
+
+def test_kriging_mutation(interpolator, map_sequential_pile):
+    geo_model = map_sequential_pile
+    geo_model.set_aesara_graph(interpolator)
+
+    gp.compute_model(geo_model, compute_mesh=False)
+    gp.plot.plot_2d(geo_model, cell_number=25, show_scalar=True, series_n=1, N=15,
+                    direction='y', show_data=True)
+    print(geo_model.solutions.lith_block, geo_model._additional_data)
+    #plt.savefig(os.path.dirname(__file__)+'/figs/test_kriging_mutation')
+
+    geo_model.modify_kriging_parameters('range', 1)
+    geo_model.modify_kriging_parameters('drift equations', [0, 3])
+
+    print(geo_model.solutions.lith_block, geo_model._additional_data)
+    # copy dataframe before interpolator is calculated
+    pre = geo_model._additional_data.kriging_data.df.copy()
+
+    gp.set_interpolator(geo_model, compile_aesara=True,
+                        aesara_optimizer='fast_compile', update_kriging=False)
+    gp.compute_model(geo_model, compute_mesh=False)
+
+    gp.plot.plot_2d(geo_model, cell_number=25, series_n=1, N=15, show_boundaries=False,
+                    direction='y', show_data=True, show_lith=True)
+
+    print(geo_model.solutions.lith_block, geo_model._additional_data)
+    plt.savefig(os.path.dirname(__file__)+'/../figs/test_kriging_mutation2')
     assert geo_model._additional_data.kriging_data.df['range'][0] == pre['range'][0]
```

### Comparing `gempy-2.2b10.dev1/test/test_core/test_pile_manipulation.py` & `gempy-2.3.0/test/test_core/test_pile_manipulation.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,367 +1,367 @@
-import gempy as gp
-import matplotlib.pyplot as plt
-import pandas as pn
-import numpy as np
-import os
-import pytest
-input_path = os.path.dirname(__file__)+'/../input_data'
-
-# ## Preparing the Python environment
-#
-# For modeling with GemPy, we first need to import it. We should also import any other packages we want to
-# utilize in our Python environment.Typically, we will also require `NumPy` and `Matplotlib` when working
-# with GemPy. At this point, we can further customize some settings as desired, e.g. the size of figures or,
-# as we do here, the way that `Matplotlib` figures are displayed in our notebook (`%matplotlib inline`).
-
-
-# These two lines are necessary only if GemPy is not installed
-import sys, os
-sys.path.append("../..")
-
-import sys, os
-
-sys.path.append("../../../gempy")
-import gempy as gp
-
-import numpy as np
-import matplotlib.pyplot as plt
-import pandas as pd
-
-
-def test_pile_geomodel(interpolator):
-    ve = 3
-    extent = [451e3, 456e3, 6.7820e6, 6.7840e6, -2309 * ve, -1651 * ve]
-
-    geo_model = gp.create_model('Topology-Gullfaks')
-
-    gp.init_data(geo_model, extent, [30, 30, 30],
-                 path_o=input_path + "/filtered_orientations.csv",
-                 path_i=input_path + "/filtered_surface_points.csv", default_values=True)
-
-    series_distribution = {
-        "fault3": "fault3",
-        "fault4": "fault4",
-        "unconformity": "BCU",
-        "sediments": ("tarbert", "ness", "etive"),
-    }
-
-    gp.map_stack_to_surfaces(geo_model,
-                             series_distribution,
-                             remove_unused_series=True)
-
-    geo_model.reorder_features(["unconformity", "fault3", "fault4",
-                              "sediments", "Basement"])
-
-    geo_model.set_is_fault(["fault3"])
-    geo_model.set_is_fault(["fault4"])
-
-    rel_matrix = np.array([[0, 0, 0, 0, 0],
-                           [0, 0, 0, 1, 1],
-                           [0, 0, 0, 1, 1],
-                           [0, 0, 0, 0, 0],
-                           [0, 0, 0, 0, 0]])
-
-    geo_model.set_fault_relation(rel_matrix)
-
-    surf_groups = pd.read_csv(input_path + "/filtered_surface_points.csv").group
-    geo_model._surface_points.df["group"] = surf_groups
-    orient_groups = pd.read_csv(input_path + "/filtered_orientations.csv").group
-    geo_model._orientations.df["group"] = orient_groups
-
-    geo_model._surface_points.df.reset_index(inplace=True, drop=True)
-    geo_model._orientations.df.reset_index(inplace=True, drop=True)
-
-    geo_model.set_theano_function(interpolator)
-    gp.compute_model(geo_model)
-
-    gp.plot.plot_2d(geo_model, cell_number=25,
-                    direction='y', show_data=True)
-
-    plt.savefig(os.path.dirname(__file__) + '/../figs/test_pile_lith_block')
-
-    return geo_model
-
-
-def test_pile_geomodel_2(interpolator):
-    ve = 3
-    extent = [451e3, 456e3, 6.7820e6, 6.7840e6, -2309 * ve, -1651 * ve]
-
-    geo_model = gp.create_model('Topology-Gullfaks')
-
-    gp.init_data(geo_model, extent, [30, 30, 30],
-                 path_o=input_path + "/filtered_orientations.csv",
-                 path_i=input_path + "/filtered_surface_points.csv", default_values=True)
-
-    series_distribution = {
-        "fault3": "fault3",
-        "fault4": "fault4",
-        "unconformity": "BCU",
-        "sediments": ("tarbert", "ness", "etive"),
-    }
-
-    gp.map_stack_to_surfaces(geo_model,
-                             series_distribution,
-                             remove_unused_series=True)
-
-    geo_model.reorder_features(["unconformity", "fault3", "fault4",
-                              "sediments", "Basement"])
-
-    geo_model.set_is_fault(["fault3"])
-    geo_model.set_is_fault(["fault4"])
-
-    rel_matrix = np.array([[0, 0, 0, 0, 0],
-                           [0, 0, 0, 1, 1],
-                           [0, 0, 0, 1, 1],
-                           [0, 0, 0, 0, 0],
-                           [0, 0, 0, 0, 0]])
-
-    geo_model.set_fault_relation(rel_matrix)
-
-    surf_groups = pd.read_csv(input_path + "/filtered_surface_points.csv").group
-    geo_model._surface_points.df["group"] = surf_groups
-    orient_groups = pd.read_csv(input_path + "/filtered_orientations.csv").group
-    geo_model._orientations.df["group"] = orient_groups
-
-    geo_model._surface_points.df.reset_index(inplace=True, drop=True)
-    geo_model._orientations.df.reset_index(inplace=True, drop=True)
-
-    geo_model.set_theano_function(interpolator)
-    gp.compute_model(geo_model)
-
-    gp.plot.plot_2d(geo_model, cell_number=25,
-                         direction='y', show_data=True)
-
-    from gempy.plot.plot_api import plot_2d
-
-    p = plot_2d(geo_model, cell_number=[25])
-
-    plt.savefig(os.path.dirname(__file__) + '/../figs/test_pile_lith_block')
-
-    return geo_model
-
-
-def test_reorder_series():
-
-    geo_model = gp.create_model('Geological_Model1')
-    geo_model = gp.init_data(geo_model, extent=[0, 4000, 0, 2775, 200, 1200], resolution=[100, 10, 100])
-    # Adding a fault
-    geo_model.rename_features(['Cycle1'])
-
-    geo_model.add_features(['Fault1'])
-    geo_model.set_is_fault(['Fault1'])
-    geo_model.reorder_features(['Fault1', 'Cycle1'])
-    assert (geo_model._stack.df['BottomRelation'] == ['Fault', 'Erosion']).all()
-    assert (geo_model._stack.df.index == ['Fault1', 'Cycle1']).all()
-    print(geo_model._stack.df)
-
-
-def test_complete_model(tmpdir, interpolator):
-    # ### Initializing the model:
-    compute = True
-
-    geo_model = gp.create_model('Geological_Model1')
-    geo_model = gp.init_data(geo_model, extent=[0, 4000, 0, 2775, 200, 1200], resolution=[100, 10, 100])
-
-    if compute is True:
-        geo_model.set_theano_function(interpolator)
-
-    from gempy.plot import visualization_2d as vv
-
-    # In this case perpendicular to the z axes
-    p2d = vv.Plot2D(geo_model)
-    p2d.create_figure((15, 8))
-    ax = p2d.add_section(direction='z', ax_pos=121)
-
-    ax2 = p2d.add_section(direction='y', ax_pos=122)
-    ax2.set_xlim(geo_model._grid.regular_grid.extent[0], geo_model._grid.regular_grid.extent[1])
-    ax2.set_ylim(geo_model._grid.regular_grid.extent[4], geo_model._grid.regular_grid.extent[5])
-
-    geo_model.add_surfaces(['D', 'C', 'B', 'A'])
-
-    # surface B
-    geo_model.add_surface_points(X=584, Y=285, Z=500, surface='B')
-    geo_model.add_surface_points(X=494, Y=696, Z=500, surface='B')
-    geo_model.add_surface_points(X=197, Y=1898, Z=500, surface='B')
-    geo_model.add_surface_points(X=473, Y=2180, Z=400, surface='B')
-    geo_model.add_surface_points(X=435, Y=2453, Z=400, surface='B')
-    # surface C
-    geo_model.add_surface_points(X=946, Y=188, Z=600, surface='C')
-    geo_model.add_surface_points(X=853, Y=661, Z=600, surface='C')
-    geo_model.add_surface_points(X=570, Y=1845, Z=600, surface='C')
-    geo_model.add_surface_points(X=832, Y=2132, Z=500, surface='C')
-    geo_model.add_surface_points(X=767, Y=2495, Z=500, surface='C')
-    # Surface D
-    geo_model.add_surface_points(X=967, Y=1638, Z=800, surface='D')
-    geo_model.add_surface_points(X=1095, Y=996, Z=800, surface='D')
-
-    geo_model.add_orientations(X=832, Y=2132, Z=500, surface='C',
-                               orientation=[98, 17.88, 1])
-
-    p2d.plot_data(ax, direction='z')
-    p2d.plot_data(ax2, direction='y')
-
-    gp.compute_model(geo_model) if compute else None
-    p2d.plot_contacts(ax, direction='z', cell_number=-10)
-    p2d.plot_lith(ax, direction='z', cell_number=-10)
-
-    p2d.plot_contacts(ax2, direction='y', cell_number=5)
-    p2d.plot_lith(ax2, direction='y', cell_number=5)
-
-    plt.savefig(os.path.dirname(__file__) + '/../figs/test_pile_complete')
-
-    # -----------
-    # Adding a fault
-    geo_model.rename_features(['Cycle1'])
-
-    geo_model.add_features(['Fault1'])
-    geo_model.set_is_fault(['Fault1'])
-
-    geo_model.modify_order_features(1, 'Fault1')
-    geo_model.add_surfaces(['F1'])
-    gp.map_stack_to_surfaces(geo_model, {'Fault1': 'F1'})
-
-    # Add input data of the fault
-    geo_model.add_surface_points(X=1203, Y=138, Z=600, surface='F1')
-    geo_model.add_surface_points(X=1250, Y=1653, Z=800, surface='F1')
-    # Add orientation
-    geo_model.add_orientations(X=1280, Y=2525, Z=500, surface='F1', orientation=[272, 90, -1])
-
-    gp.compute_model(geo_model)
-
-    p2d.remove(ax)
-    p2d.plot_data(ax, direction='z', cell_number=-10)
-    p2d.plot_contacts(ax, direction='z', cell_number=-10)
-    p2d.plot_lith(ax, direction='z', cell_number=-10)
-
-    p2d.remove(ax2)
-    # Plot
-    p2d.plot_data(ax2, cell_number=5)
-    p2d.plot_lith(ax2, cell_number=5)
-    p2d.plot_contacts(ax2, cell_number=5)
-
-    # surface B
-    geo_model.add_surface_points(X=1447, Y=2554, Z=500, surface='B')
-    geo_model.add_surface_points(X=1511, Y=2200, Z=500, surface='B')
-    geo_model.add_surface_points(X=1549, Y=629, Z=600, surface='B')
-    geo_model.add_surface_points(X=1630, Y=287, Z=600, surface='B')
-    # surface C
-    geo_model.add_surface_points(X=1891, Y=2063, Z=600, surface='C')
-    geo_model.add_surface_points(X=1605, Y=1846, Z=700, surface='C')
-    geo_model.add_surface_points(X=1306, Y=1641, Z=800, surface='C')
-    geo_model.add_surface_points(X=1476, Y=979, Z=800, surface='C')
-    geo_model.add_surface_points(X=1839, Y=962, Z=700, surface='C')
-    geo_model.add_surface_points(X=2185, Y=893, Z=600, surface='C')
-    geo_model.add_surface_points(X=2245, Y=547, Z=600, surface='C')
-    # Surface D
-    geo_model.add_surface_points(X=2809, Y=2567, Z=600, surface='D')
-    geo_model.add_surface_points(X=2843, Y=2448, Z=600, surface='D')
-    geo_model.add_surface_points(X=2873, Y=876, Z=700, surface='D')
-
-    # Compute
-    gp.compute_model(geo_model)
-
-    # Plot
-    p2d.remove(ax)
-    p2d.plot_data(ax, direction='z', cell_number=-10)
-    p2d.plot_contacts(ax, direction='z', cell_number=-10)
-    p2d.plot_lith(ax, direction='z', cell_number=-10)
-
-    p2d.remove(ax2)
-    p2d.plot_lith(ax2, cell_number=5)
-    p2d.plot_data(ax2, cell_number=5)
-
-    plt.savefig(os.path.dirname(__file__) + '/../figs/test_pile_complete')
-
-    # ----------------
-    # Second cycle
-    geo_model.add_features(['Cycle2'])
-    geo_model.add_surfaces(['G', 'H'])
-    gp.map_stack_to_surfaces(geo_model, {'Cycle2': ['G', 'H']})
-    geo_model.reorder_features(['Cycle2', 'Fault1', 'Cycle1'])
-
-    # Surface G
-    geo_model.add_surface_points(X=1012, Y=1493, Z=900, surface='G')
-    geo_model.add_surface_points(X=1002, Y=1224, Z=900, surface='G')
-    geo_model.add_surface_points(X=1996, Y=47, Z=800, surface='G')
-    geo_model.add_surface_points(X=300, Y=907, Z=700, surface='G')
-    # Surface H
-    geo_model.add_surface_points(X=3053, Y=727, Z=800, surface='G')
-    # Orientation
-    geo_model.add_orientations(X=1996, Y=47, Z=800, surface='G', orientation=[272, 5.54, 1])
-
-    # Compute
-    gp.compute_model(geo_model)
-
-    # Plot
-    p2d.remove(ax)
-    p2d.plot_data(ax, direction='z', cell_number=-10)
-    p2d.plot_contacts(ax, direction='z', cell_number=-10)
-    p2d.plot_lith(ax, direction='z', cell_number=-10)
-
-    p2d.remove(ax2)
-    p2d.plot_lith(ax2, cell_number=5)
-    p2d.plot_data(ax2, cell_number=5)
-    p2d.plot_contacts(ax2, cell_number=5)
-
-    plt.savefig(os.path.dirname(__file__) + '/../figs/test_pile_complete')
-
-
-    # ----------------
-    # Second Fault
-    geo_model.add_features('Fault2')
-    geo_model.set_is_fault('Fault2')
-    geo_model.add_surfaces('F2')
-
-    geo_model.reorder_features(['Cycle2', 'Fault1', 'Fault2', 'Cycle1'])
-    gp.map_stack_to_surfaces(geo_model, {'Fault2': 'F2'})
-
-    geo_model.add_surface_points(X=3232, Y=178, Z=1000, surface='F2')
-    geo_model.add_surface_points(X=3132, Y=951, Z=700, surface='F2')
-    # geo_model.add_surface_points(X=2962, Y=2184, Z=700, surface='F2')
-
-    geo_model.add_orientations(X=3132, Y=951, Z=700, surface='F2', orientation=[95, 90, 1])
-
-    # Compute
-    gp.compute_model(geo_model)
-
-    # Plot
-    p2d.remove(ax)
-    p2d.plot_data(ax, direction='z', cell_number=5, legend='force')
-    p2d.plot_lith(ax, direction='z', cell_number=5)
-    p2d.plot_contacts(ax, direction='z', cell_number=5)
-
-    p2d.remove(ax2)
-    p2d.plot_lith(ax2, cell_number=5)
-    p2d.plot_data(ax2, cell_number=5)
-    p2d.plot_contacts(ax2, cell_number=5)
-
-    plt.savefig(os.path.dirname(__file__) + '/../figs/test_pile_complete')
-
-    geo_model.add_surface_points(X=3135, Y=1300, Z=700, surface='D')
-    geo_model.add_surface_points(X=3190, Y=969, Z=700, surface='D')
-
-    geo_model.add_surface_points(X=3031, Y=2725, Z=800, surface='G')
-    geo_model.add_surface_points(X=3018, Y=1990, Z=800, surface='G')
-    geo_model.add_surface_points(X=3194, Y=965, Z=700, surface='G')
-
-    geo_model.add_surface_points(X=3218, Y=1818, Z=890, surface='H')
-    geo_model.add_surface_points(X=3934, Y=1207, Z=810, surface='H')
-
-    # Compute
-    gp.compute_model(geo_model)
-
-    # Plot
-    p2d.remove(ax)
-    p2d.plot_data(ax, direction='z', cell_number=5, legend='force')
-    p2d.plot_lith(ax, direction='z', cell_number=5)
-    p2d.plot_contacts(ax, direction='z',cell_number=5)
-
-    p2d.remove(ax2)
-    p2d.plot_lith(ax2, cell_number=5)
-    p2d.plot_data(ax2, cell_number=5)
-    p2d.plot_contacts(ax2, cell_number=5)
-
-    plt.savefig(os.path.dirname(__file__) + '/../figs/test_pile_complete')
-
-
-
+import gempy as gp
+import matplotlib.pyplot as plt
+import pandas as pn
+import numpy as np
+import os
+import pytest
+input_path = os.path.dirname(__file__)+'/../input_data'
+
+# ## Preparing the Python environment
+#
+# For modeling with GemPy, we first need to import it. We should also import any other packages we want to
+# utilize in our Python environment.Typically, we will also require `NumPy` and `Matplotlib` when working
+# with GemPy. At this point, we can further customize some settings as desired, e.g. the size of figures or,
+# as we do here, the way that `Matplotlib` figures are displayed in our notebook (`%matplotlib inline`).
+
+
+# These two lines are necessary only if GemPy is not installed
+import sys, os
+sys.path.append("../..")
+
+import sys, os
+
+sys.path.append("../../../gempy")
+import gempy as gp
+
+import numpy as np
+import matplotlib.pyplot as plt
+import pandas as pd
+
+
+def test_pile_geomodel(interpolator):
+    ve = 3
+    extent = [451e3, 456e3, 6.7820e6, 6.7840e6, -2309 * ve, -1651 * ve]
+
+    geo_model = gp.create_model('Topology-Gullfaks')
+
+    gp.init_data(geo_model, extent, [30, 30, 30],
+                 path_o=input_path + "/filtered_orientations.csv",
+                 path_i=input_path + "/filtered_surface_points.csv", default_values=True)
+
+    series_distribution = {
+        "fault3": "fault3",
+        "fault4": "fault4",
+        "unconformity": "BCU",
+        "sediments": ("tarbert", "ness", "etive"),
+    }
+
+    gp.map_stack_to_surfaces(geo_model,
+                             series_distribution,
+                             remove_unused_series=True)
+
+    geo_model.reorder_features(["unconformity", "fault3", "fault4",
+                              "sediments", "Basement"])
+
+    geo_model.set_is_fault(["fault3"])
+    geo_model.set_is_fault(["fault4"])
+
+    rel_matrix = np.array([[0, 0, 0, 0, 0],
+                           [0, 0, 0, 1, 1],
+                           [0, 0, 0, 1, 1],
+                           [0, 0, 0, 0, 0],
+                           [0, 0, 0, 0, 0]])
+
+    geo_model.set_fault_relation(rel_matrix)
+
+    surf_groups = pd.read_csv(input_path + "/filtered_surface_points.csv").group
+    geo_model._surface_points.df["group"] = surf_groups
+    orient_groups = pd.read_csv(input_path + "/filtered_orientations.csv").group
+    geo_model._orientations.df["group"] = orient_groups
+
+    geo_model._surface_points.df.reset_index(inplace=True, drop=True)
+    geo_model._orientations.df.reset_index(inplace=True, drop=True)
+
+    geo_model.set_aesara_function(interpolator)
+    gp.compute_model(geo_model)
+
+    gp.plot.plot_2d(geo_model, cell_number=25,
+                    direction='y', show_data=True)
+
+    plt.savefig(os.path.dirname(__file__) + '/../figs/test_pile_lith_block')
+
+    return geo_model
+
+
+def test_pile_geomodel_2(interpolator):
+    ve = 3
+    extent = [451e3, 456e3, 6.7820e6, 6.7840e6, -2309 * ve, -1651 * ve]
+
+    geo_model = gp.create_model('Topology-Gullfaks')
+
+    gp.init_data(geo_model, extent, [30, 30, 30],
+                 path_o=input_path + "/filtered_orientations.csv",
+                 path_i=input_path + "/filtered_surface_points.csv", default_values=True)
+
+    series_distribution = {
+        "fault3": "fault3",
+        "fault4": "fault4",
+        "unconformity": "BCU",
+        "sediments": ("tarbert", "ness", "etive"),
+    }
+
+    gp.map_stack_to_surfaces(geo_model,
+                             series_distribution,
+                             remove_unused_series=True)
+
+    geo_model.reorder_features(["unconformity", "fault3", "fault4",
+                              "sediments", "Basement"])
+
+    geo_model.set_is_fault(["fault3"])
+    geo_model.set_is_fault(["fault4"])
+
+    rel_matrix = np.array([[0, 0, 0, 0, 0],
+                           [0, 0, 0, 1, 1],
+                           [0, 0, 0, 1, 1],
+                           [0, 0, 0, 0, 0],
+                           [0, 0, 0, 0, 0]])
+
+    geo_model.set_fault_relation(rel_matrix)
+
+    surf_groups = pd.read_csv(input_path + "/filtered_surface_points.csv").group
+    geo_model._surface_points.df["group"] = surf_groups
+    orient_groups = pd.read_csv(input_path + "/filtered_orientations.csv").group
+    geo_model._orientations.df["group"] = orient_groups
+
+    geo_model._surface_points.df.reset_index(inplace=True, drop=True)
+    geo_model._orientations.df.reset_index(inplace=True, drop=True)
+
+    geo_model.set_aesara_function(interpolator)
+    gp.compute_model(geo_model)
+
+    gp.plot.plot_2d(geo_model, cell_number=25,
+                         direction='y', show_data=True)
+
+    from gempy.plot.plot_api import plot_2d
+
+    p = plot_2d(geo_model, cell_number=[25])
+
+    plt.savefig(os.path.dirname(__file__) + '/../figs/test_pile_lith_block')
+
+    return geo_model
+
+
+def test_reorder_series():
+
+    geo_model = gp.create_model('Geological_Model1')
+    geo_model = gp.init_data(geo_model, extent=[0, 4000, 0, 2775, 200, 1200], resolution=[100, 10, 100])
+    # Adding a fault
+    geo_model.rename_features(['Cycle1'])
+
+    geo_model.add_features(['Fault1'])
+    geo_model.set_is_fault(['Fault1'])
+    geo_model.reorder_features(['Fault1', 'Cycle1'])
+    assert (geo_model._stack.df['BottomRelation'] == ['Fault', 'Erosion']).all()
+    assert (geo_model._stack.df.index == ['Fault1', 'Cycle1']).all()
+    print(geo_model._stack.df)
+
+
+def test_complete_model(tmpdir, interpolator):
+    # ### Initializing the model:
+    compute = True
+
+    geo_model = gp.create_model('Geological_Model1')
+    geo_model = gp.init_data(geo_model, extent=[0, 4000, 0, 2775, 200, 1200], resolution=[100, 10, 100])
+
+    if compute is True:
+        geo_model.set_aesara_function(interpolator)
+
+    from gempy.plot import visualization_2d as vv
+
+    # In this case perpendicular to the z axes
+    p2d = vv.Plot2D(geo_model)
+    p2d.create_figure((15, 8))
+    ax = p2d.add_section(direction='z', ax_pos=121)
+
+    ax2 = p2d.add_section(direction='y', ax_pos=122)
+    ax2.set_xlim(geo_model._grid.regular_grid.extent[0], geo_model._grid.regular_grid.extent[1])
+    ax2.set_ylim(geo_model._grid.regular_grid.extent[4], geo_model._grid.regular_grid.extent[5])
+
+    geo_model.add_surfaces(['D', 'C', 'B', 'A'])
+
+    # surface B
+    geo_model.add_surface_points(X=584, Y=285, Z=500, surface='B')
+    geo_model.add_surface_points(X=494, Y=696, Z=500, surface='B')
+    geo_model.add_surface_points(X=197, Y=1898, Z=500, surface='B')
+    geo_model.add_surface_points(X=473, Y=2180, Z=400, surface='B')
+    geo_model.add_surface_points(X=435, Y=2453, Z=400, surface='B')
+    # surface C
+    geo_model.add_surface_points(X=946, Y=188, Z=600, surface='C')
+    geo_model.add_surface_points(X=853, Y=661, Z=600, surface='C')
+    geo_model.add_surface_points(X=570, Y=1845, Z=600, surface='C')
+    geo_model.add_surface_points(X=832, Y=2132, Z=500, surface='C')
+    geo_model.add_surface_points(X=767, Y=2495, Z=500, surface='C')
+    # Surface D
+    geo_model.add_surface_points(X=967, Y=1638, Z=800, surface='D')
+    geo_model.add_surface_points(X=1095, Y=996, Z=800, surface='D')
+
+    geo_model.add_orientations(X=832, Y=2132, Z=500, surface='C',
+                               orientation=[98, 17.88, 1])
+
+    p2d.plot_data(ax, direction='z')
+    p2d.plot_data(ax2, direction='y')
+
+    gp.compute_model(geo_model) if compute else None
+    p2d.plot_contacts(ax, direction='z', cell_number=-10)
+    p2d.plot_lith(ax, direction='z', cell_number=-10)
+
+    p2d.plot_contacts(ax2, direction='y', cell_number=5)
+    p2d.plot_lith(ax2, direction='y', cell_number=5)
+
+    plt.savefig(os.path.dirname(__file__) + '/../figs/test_pile_complete')
+
+    # -----------
+    # Adding a fault
+    geo_model.rename_features(['Cycle1'])
+
+    geo_model.add_features(['Fault1'])
+    geo_model.set_is_fault(['Fault1'])
+
+    geo_model.modify_order_features(1, 'Fault1')
+    geo_model.add_surfaces(['F1'])
+    gp.map_stack_to_surfaces(geo_model, {'Fault1': 'F1'})
+
+    # Add input data of the fault
+    geo_model.add_surface_points(X=1203, Y=138, Z=600, surface='F1')
+    geo_model.add_surface_points(X=1250, Y=1653, Z=800, surface='F1')
+    # Add orientation
+    geo_model.add_orientations(X=1280, Y=2525, Z=500, surface='F1', orientation=[272, 90, -1])
+
+    gp.compute_model(geo_model)
+
+    p2d.remove(ax)
+    p2d.plot_data(ax, direction='z', cell_number=-10)
+    p2d.plot_contacts(ax, direction='z', cell_number=-10)
+    p2d.plot_lith(ax, direction='z', cell_number=-10)
+
+    p2d.remove(ax2)
+    # Plot
+    p2d.plot_data(ax2, cell_number=5)
+    p2d.plot_lith(ax2, cell_number=5)
+    p2d.plot_contacts(ax2, cell_number=5)
+
+    # surface B
+    geo_model.add_surface_points(X=1447, Y=2554, Z=500, surface='B')
+    geo_model.add_surface_points(X=1511, Y=2200, Z=500, surface='B')
+    geo_model.add_surface_points(X=1549, Y=629, Z=600, surface='B')
+    geo_model.add_surface_points(X=1630, Y=287, Z=600, surface='B')
+    # surface C
+    geo_model.add_surface_points(X=1891, Y=2063, Z=600, surface='C')
+    geo_model.add_surface_points(X=1605, Y=1846, Z=700, surface='C')
+    geo_model.add_surface_points(X=1306, Y=1641, Z=800, surface='C')
+    geo_model.add_surface_points(X=1476, Y=979, Z=800, surface='C')
+    geo_model.add_surface_points(X=1839, Y=962, Z=700, surface='C')
+    geo_model.add_surface_points(X=2185, Y=893, Z=600, surface='C')
+    geo_model.add_surface_points(X=2245, Y=547, Z=600, surface='C')
+    # Surface D
+    geo_model.add_surface_points(X=2809, Y=2567, Z=600, surface='D')
+    geo_model.add_surface_points(X=2843, Y=2448, Z=600, surface='D')
+    geo_model.add_surface_points(X=2873, Y=876, Z=700, surface='D')
+
+    # Compute
+    gp.compute_model(geo_model)
+
+    # Plot
+    p2d.remove(ax)
+    p2d.plot_data(ax, direction='z', cell_number=-10)
+    p2d.plot_contacts(ax, direction='z', cell_number=-10)
+    p2d.plot_lith(ax, direction='z', cell_number=-10)
+
+    p2d.remove(ax2)
+    p2d.plot_lith(ax2, cell_number=5)
+    p2d.plot_data(ax2, cell_number=5)
+
+    plt.savefig(os.path.dirname(__file__) + '/../figs/test_pile_complete')
+
+    # ----------------
+    # Second cycle
+    geo_model.add_features(['Cycle2'])
+    geo_model.add_surfaces(['G', 'H'])
+    gp.map_stack_to_surfaces(geo_model, {'Cycle2': ['G', 'H']})
+    geo_model.reorder_features(['Cycle2', 'Fault1', 'Cycle1'])
+
+    # Surface G
+    geo_model.add_surface_points(X=1012, Y=1493, Z=900, surface='G')
+    geo_model.add_surface_points(X=1002, Y=1224, Z=900, surface='G')
+    geo_model.add_surface_points(X=1996, Y=47, Z=800, surface='G')
+    geo_model.add_surface_points(X=300, Y=907, Z=700, surface='G')
+    # Surface H
+    geo_model.add_surface_points(X=3053, Y=727, Z=800, surface='G')
+    # Orientation
+    geo_model.add_orientations(X=1996, Y=47, Z=800, surface='G', orientation=[272, 5.54, 1])
+
+    # Compute
+    gp.compute_model(geo_model)
+
+    # Plot
+    p2d.remove(ax)
+    p2d.plot_data(ax, direction='z', cell_number=-10)
+    p2d.plot_contacts(ax, direction='z', cell_number=-10)
+    p2d.plot_lith(ax, direction='z', cell_number=-10)
+
+    p2d.remove(ax2)
+    p2d.plot_lith(ax2, cell_number=5)
+    p2d.plot_data(ax2, cell_number=5)
+    p2d.plot_contacts(ax2, cell_number=5)
+
+    plt.savefig(os.path.dirname(__file__) + '/../figs/test_pile_complete')
+
+
+    # ----------------
+    # Second Fault
+    geo_model.add_features('Fault2')
+    geo_model.set_is_fault('Fault2')
+    geo_model.add_surfaces('F2')
+
+    geo_model.reorder_features(['Cycle2', 'Fault1', 'Fault2', 'Cycle1'])
+    gp.map_stack_to_surfaces(geo_model, {'Fault2': 'F2'})
+
+    geo_model.add_surface_points(X=3232, Y=178, Z=1000, surface='F2')
+    geo_model.add_surface_points(X=3132, Y=951, Z=700, surface='F2')
+    # geo_model.add_surface_points(X=2962, Y=2184, Z=700, surface='F2')
+
+    geo_model.add_orientations(X=3132, Y=951, Z=700, surface='F2', orientation=[95, 90, 1])
+
+    # Compute
+    gp.compute_model(geo_model)
+
+    # Plot
+    p2d.remove(ax)
+    p2d.plot_data(ax, direction='z', cell_number=5, legend='force')
+    p2d.plot_lith(ax, direction='z', cell_number=5)
+    p2d.plot_contacts(ax, direction='z', cell_number=5)
+
+    p2d.remove(ax2)
+    p2d.plot_lith(ax2, cell_number=5)
+    p2d.plot_data(ax2, cell_number=5)
+    p2d.plot_contacts(ax2, cell_number=5)
+
+    plt.savefig(os.path.dirname(__file__) + '/../figs/test_pile_complete')
+
+    geo_model.add_surface_points(X=3135, Y=1300, Z=700, surface='D')
+    geo_model.add_surface_points(X=3190, Y=969, Z=700, surface='D')
+
+    geo_model.add_surface_points(X=3031, Y=2725, Z=800, surface='G')
+    geo_model.add_surface_points(X=3018, Y=1990, Z=800, surface='G')
+    geo_model.add_surface_points(X=3194, Y=965, Z=700, surface='G')
+
+    geo_model.add_surface_points(X=3218, Y=1818, Z=890, surface='H')
+    geo_model.add_surface_points(X=3934, Y=1207, Z=810, surface='H')
+
+    # Compute
+    gp.compute_model(geo_model)
+
+    # Plot
+    p2d.remove(ax)
+    p2d.plot_data(ax, direction='z', cell_number=5, legend='force')
+    p2d.plot_lith(ax, direction='z', cell_number=5)
+    p2d.plot_contacts(ax, direction='z',cell_number=5)
+
+    p2d.remove(ax2)
+    p2d.plot_lith(ax2, cell_number=5)
+    p2d.plot_data(ax2, cell_number=5)
+    p2d.plot_contacts(ax2, cell_number=5)
+
+    plt.savefig(os.path.dirname(__file__) + '/../figs/test_pile_complete')
+
+
+
```

### Comparing `gempy-2.2b10.dev1/test/test_core/test_sort_surfaces.py` & `gempy-2.3.0/test/test_core/test_sort_surfaces.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,36 +1,37 @@
-import pytest
-import gempy as gp
-import matplotlib.pyplot as plt
-import numpy as np
-
-
-def test_sort_surfaces_by_solution(one_fault_model_topo_solution):
-    geo_model = one_fault_model_topo_solution
-    section_dict = {'section_SW-NE': ([250, 250], [1750, 1750], [100, 100]),
-                    'section_NW-SE': ([250, 1750], [1750, 250], [100, 100])}
-    geo_model.set_section_grid(section_dict)
-
-    geo_model.set_active_grid('sections', reset=True)
-
-    s1 = geo_model.solutions.scalar_field_at_surface_points
-    geo_model.update_additional_data()
-    geo_model.update_to_interpolator()
-    gp.compute_model(geo_model, sort_surfaces=True)
-    gp.plot_2d(geo_model, section_names=['section_NW-SE'],
-               show_topography=True)
-    plt.show()
-    s2 = geo_model.solutions.scalar_field_at_surface_points
-
-    gp.compute_model(geo_model, sort_surfaces=True)
-    gp.plot_2d(geo_model, section_names=['section_NW-SE'],
-               show_topography=True)
-    plt.show()
-    s3 = geo_model.solutions.scalar_field_at_surface_points
-    np.testing.assert_array_equal(s2, s3)
-
-    gp.compute_model(geo_model, sort_surfaces=True)
-    gp.plot_2d(geo_model, section_names=['section_NW-SE'],
-               show_topography=True)
-    plt.show()
-
-    return geo_model
+import matplotlib as mpl
+mpl.use('Agg')
+import matplotlib.pyplot as plt
+import numpy as np
+
+import gempy as gp
+
+
+# ? This test does not seem to be testing what it says it is testing
+def test_sort_surfaces_by_solution(one_fault_model_topo_solution):
+    geo_model = one_fault_model_topo_solution
+    section_dict = {'section_SW-NE': ([250, 250], [1750, 1750], [100, 100]),
+                    'section_NW-SE': ([250, 1750], [1750, 250], [100, 100])}
+    geo_model.set_section_grid(section_dict)
+
+    geo_model.set_active_grid('sections', reset=True)
+
+    s1 = geo_model.solutions.scalar_field_at_surface_points
+    geo_model.update_additional_data()
+    geo_model.update_to_interpolator()
+    
+    gp.compute_model(geo_model, sort_surfaces=True)
+    gp.plot_2d(geo_model, section_names=['section_NW-SE'], show_topography=False)
+    plt.show()
+    s2 = geo_model.solutions.scalar_field_at_surface_points
+
+    gp.compute_model(geo_model, sort_surfaces=True)
+    gp.plot_2d(geo_model, section_names=['section_NW-SE'], show_topography=True)
+    plt.show()
+    s3 = geo_model.solutions.scalar_field_at_surface_points
+    np.testing.assert_array_equal(s2, s3)
+
+    gp.compute_model(geo_model, sort_surfaces=True)
+    gp.plot_2d(geo_model, section_names=['section_SW-NE'], show_topography=True)
+    plt.show()
+
+    return geo_model
```

### Comparing `gempy-2.2b10.dev1/test/test_integrations/test_map2loop.py` & `gempy-2.3.0/test/test_integrations/test_map2loop.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,185 +1,200 @@
-import gempy as gp
-import numpy as np
-import pandas as pd
-import pytest
-import matplotlib.pyplot as plt
-import os
-
-# Input files
-from gempy.addons.map2gempy import loop2gempy
-
-root = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/turner_syncline/'
-root2 = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/australia/'
-path = os.path.dirname(__file__) + '/../input_data/'
-
-orientations_file = root + 'orientations_clean.csv'
-orientations_file2 = root2 + 'orientations_clean.csv'
-
-contacts_file = root + 'contacts_clean.csv'
-contacts_file2 = root2 + 'contacts_clean.csv'
-faults_contact = root + 'faults.csv'
-faults_contact2 = root2 + 'faults.csv'
-faults_orientations = root + 'fault_orientations.csv'
-faults_orientations2 = root2 + 'fault_orientations.csv'
-series_file = root + 'all_sorts_clean.csv'
-series_file2 = root2 + 'all_sorts_clean.csv'
-
-faults_rel_matrix = root + 'fault-fault-relationships.csv'
-faults_rel_matrix2 = root2 + 'fault-fault-relationships.csv'
-series_rel_matrix = root + 'group-fault-relationships.csv'
-series_rel_matrix2 = root2 + 'group-fault-relationships.csv'
-
-ff = root2 + 'fault-fault-relationships.csv'
-fg = root2 + 'group-fault-relationships.csv'
-
-fp = path + 'dtm_rp.tif'
-fp2 = path + 'dtm_rp2.tif'
-
-bbox = (500000, 7490000, 545000, 7520000)
-model_base = -0  # Original 3200
-model_top = 800
-extent_g = [515687.3100586407, 562666.8601065436,
-            7473446.765934078, 7521273.574077863,
-            -3200, 1200.0]
-
-extent = [515687.3100586407, 7473446.765934078,
-          562666.8601065436, 7521273.574077863,
-          -3200, 1200.0]
-
-
-@pytest.mark.skipif("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true",
-                    reason="Skipping this test on Travis CI. For some reason there is a linalg "
-                           "error.")
-def test_loop2gempy():
-    topo = fp
-    topo = None
-
-    loop2gempy(contacts_file, orientations_file, bbox, series_file, model_base,
-               model_top, topo, faults_contact, faults_orientations, 'testing_map',
-               vtk=True, vtk_path=None, image_2d=True)
-
-
-def test_map2loop2relmatrix():
-    ff_ = pd.read_csv(ff).set_index('fault_id')
-    fg_ = pd.read_csv(fg).set_index('group')
-    p = pd.concat((ff_, fg_.T), axis=1)
-    print(p)
-
-
-@pytest.mark.skipif("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true",
-                    reason="Skipping this test on Travis CI beacuse travis.")
-def test_loop2gempy2():
-    topo = fp2
-    # topo = None
-
-    loop2gempy(contacts_file2, orientations_file2, extent[:4], series_file2,
-               extent[4],
-               extent[5],
-               dtm_reproj_file=topo,
-               faults_contact=faults_contact2,
-               faults_orientations=faults_orientations2,
-               faults_faults_rel=ff,
-               faults_groups_rel=fg,
-               model_name='testing_map',
-               compute=True,
-               vtk=True, vtk_path=None, image_2d=True)
-
-
-@pytest.mark.skipif("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true",
-                    reason="Skipping this test on Travis CI beacuse travis.")
-def test_map2loop_model_import_data():
-    geo_model = gp.create_model('test_map2Loop')
-    gp.init_data(
-        geo_model,
-        extent=[bbox[0], bbox[2], bbox[1], bbox[3], model_base, model_top],
-        resolution=[50, 50, 50],
-        path_o=orientations_file,
-        path_i=contacts_file
-    )
-
-    # Load Topology
-    geo_model.set_topography(source='gdal', filepath=fp)
-
-    gp.plot_2d(geo_model, ve=10, show_topography=True)
-    plt.show()
-
-    # Plot in 3D
-    gp.plot_3d(geo_model, ve=None, show_topography=False, image=True,
-               kwargs_plot_data={'arrow_size': 400}
-               )
-    print(geo_model.orientations)
-
-
-@pytest.mark.skipif("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true",
-                    reason="Skipping this test on Travis CI beacuse travis.")
-def test_map2loop_model_no_faults():
-    # Location box
-    bbox = (500000, 7490000, 545000, 7520000)
-    model_base = -3200  # Original 3200
-    model_top = 800
-
-    # Input files
-    geo_model = gp.create_model('test_map2Loop')
-    gp.init_data(
-        geo_model,
-        extent=[bbox[0], bbox[2], bbox[1], bbox[3], model_base, model_top],
-        resolution=[50, 50, 80],
-        path_o=orientations_file,
-        path_i=contacts_file
-    )
-
-    gp.set_interpolator(geo_model)
-
-    # Load Topology
-    geo_model.set_topography(source='gdal', filepath=fp)
-    # Stack Processing
-    contents = np.genfromtxt(series_file,
-                             delimiter=',', dtype='U100')[1:, 4:-1]
-
-    map_series_to_surfaces = {}
-    for pair in contents:
-        map_series_to_surfaces.setdefault(pair[1], []).append(pair[0])
-
-    gp.map_stack_to_surfaces(geo_model, map_series_to_surfaces,
-                             remove_unused_series=False)
-
-    gp.plot_2d(geo_model, ve=10, show_topography=False)
-    plt.show()
-
-    # Plot in 3D
-    gp.plot_3d(geo_model, ve=10, show_topography=False, image=True)
-
-    # Stack Processing
-    contents = np.genfromtxt(series_file,
-                             delimiter=',', dtype='U100')[1:, 4:-1]
-
-    map_series_to_surfaces = {}
-    for pair in contents:
-        map_series_to_surfaces.setdefault(pair[1], []).append(pair[0])
-
-    gp.map_stack_to_surfaces(geo_model, map_series_to_surfaces,
-                             remove_unused_series=False)
-
-    # Adding axial rescale
-    # geo_model._rescaling.toggle_axial_anisotropy()
-
-    # Increasing nugget effect
-    geo_model.modify_surface_points(
-        geo_model.surface_points.df.index,
-        smooth=0.001
-    )
-
-    geo_model.modify_kriging_parameters('drift equations', [9, 9, 9, 9, 9])
-
-    gp.compute_model(geo_model)
-
-    gp.plot_2d(geo_model,
-               section_names=['topography'],
-               show_topography=True,
-               )
-    plt.show()
-
-    gp.plot_3d(geo_model, ve=10, show_topography=True,
-               image=True,
-               show_lith=False,
-               )
+import gempy as gp
+import numpy as np
+import pandas as pd
+import pytest
+import matplotlib as mpl
+mpl.use('Agg')
+import matplotlib.pyplot as plt
+import os
+
+# Input files
+from gempy.addons.map2gempy import loop2gempy
+from gempy.core.grid_modules.create_topography import GDAL_IMPORT
+
+root = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/turner_syncline/'
+root2 = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/data/input_data/australia/'
+path = os.path.dirname(__file__) + '/../input_data/'
+
+orientations_file = root + 'orientations_clean.csv'
+orientations_file2 = root2 + 'orientations_clean.csv'
+
+contacts_file = root + 'contacts_clean.csv'
+contacts_file2 = root2 + 'contacts_clean.csv'
+faults_contact = root + 'faults.csv'
+faults_contact2 = root2 + 'faults.csv'
+faults_orientations = root + 'fault_orientations.csv'
+faults_orientations2 = root2 + 'fault_orientations.csv'
+series_file = root + 'all_sorts_clean.csv'
+series_file2 = root2 + 'all_sorts_clean.csv'
+
+faults_rel_matrix = root + 'fault-fault-relationships.csv'
+faults_rel_matrix2 = root2 + 'fault-fault-relationships.csv'
+series_rel_matrix = root + 'group-fault-relationships.csv'
+series_rel_matrix2 = root2 + 'group-fault-relationships.csv'
+
+ff = root2 + 'fault-fault-relationships.csv'
+fg = root2 + 'group-fault-relationships.csv'
+
+fp = path + 'dtm_rp.tif'
+fp2 = path + 'dtm_rp2.tif'
+
+bbox = (500000, 7490000, 545000, 7520000)
+model_base = -0  # Original 3200
+model_top = 800
+extent_g = [515687.3100586407, 562666.8601065436,
+            7473446.765934078, 7521273.574077863,
+            -3200, 1200.0]
+
+extent = [515687.3100586407, 7473446.765934078,
+          562666.8601065436, 7521273.574077863,
+          -3200, 1200.0]
+
+
+@pytest.mark.skipif(("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true") or
+                    ("GITHUBACTION" in os.environ and os.environ["GITHUBACTION"] == "true"),
+                    reason="Skipping this test on Travis CI. For some reason there is a linalg "
+                           "error.")
+def test_loop2gempy():
+    topo = fp
+    topo = None
+
+    loop2gempy(contacts_file, orientations_file, bbox, series_file, model_base,
+               model_top, topo, faults_contact, faults_orientations, 'testing_map',
+               vtk=True, vtk_path=None, image_2d=True)
+
+
+def test_map2loop2relmatrix():
+    ff_ = pd.read_csv(ff).set_index('fault_id')
+    fg_ = pd.read_csv(fg).set_index('group')
+    p = pd.concat((ff_, fg_.T), axis=1)
+    print(p)
+
+
+@pytest.mark.skipif(("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true") or
+                    ("GITHUBACTION" in os.environ and os.environ["GITHUBACTION"] == "true" or
+                     GDAL_IMPORT is False),
+                    reason="Skipping this test on Travis CI. For some reason there is a linalg "
+                           "error.")
+def test_loop2gempy2():
+    topo = fp2
+    # topo = None
+
+    loop2gempy(contacts_file2, orientations_file2, extent[:4], series_file2,
+               extent[4],
+               extent[5],
+               dtm_reproj_file=topo,
+               faults_contact=faults_contact2,
+               faults_orientations=faults_orientations2,
+               faults_faults_rel=ff,
+               faults_groups_rel=fg,
+               model_name='testing_map',
+               compute=True,
+               vtk=True, vtk_path=None, image_2d=True)
+
+
+@pytest.mark.skipif(("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true") or
+                    ("GITHUBACTION" in os.environ and os.environ["GITHUBACTION"] == "true" or 
+                     GDAL_IMPORT is False
+                     ),
+                    reason="Skipping this test on Travis CI. For some reason there is a linalg "
+                           "error.")
+def test_map2loop_model_import_data():
+    geo_model = gp.create_model('test_map2Loop')
+    gp.init_data(
+        geo_model,
+        extent=[bbox[0], bbox[2], bbox[1], bbox[3], model_base, model_top],
+        resolution=[50, 50, 50],
+        path_o=orientations_file,
+        path_i=contacts_file
+    )
+
+    # Load Topology
+    geo_model.set_topography(source='gdal', filepath=fp)
+
+    gp.plot_2d(geo_model, ve=10, show_topography=True)
+    plt.show()
+
+    # Plot in 3D
+    gp.plot_3d(geo_model, ve=None, show_topography=False, image=True,
+               kwargs_plot_data={'arrow_size': 400}
+               )
+    print(geo_model.orientations)
+
+# skip test i
+@pytest.mark.skipif(("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true") or
+                    ("GITHUBACTION" in os.environ and os.environ["GITHUBACTION"] == "true" or
+                     GDAL_IMPORT is False
+                     ),
+                    reason="Skipping this test on Travis CI. For some reason there is a linalg "
+                           "error.")
+def test_map2loop_model_no_faults():
+    # Location box
+    bbox = (500000, 7490000, 545000, 7520000)
+    model_base = -3200  # Original 3200
+    model_top = 800
+
+    # Input files
+    geo_model = gp.create_model('test_map2Loop')
+    gp.init_data(
+        geo_model,
+        extent=[bbox[0], bbox[2], bbox[1], bbox[3], model_base, model_top],
+        resolution=[50, 50, 80],
+        path_o=orientations_file,
+        path_i=contacts_file
+    )
+
+    gp.set_interpolator(geo_model)
+
+    # Load Topology
+    geo_model.set_topography(source='gdal', filepath=fp)
+    # Stack Processing
+    contents = np.genfromtxt(series_file,
+                             delimiter=',', dtype='U100')[1:, 4:-1]
+
+    map_series_to_surfaces = {}
+    for pair in contents:
+        map_series_to_surfaces.setdefault(pair[1], []).append(pair[0])
+
+    gp.map_stack_to_surfaces(geo_model, map_series_to_surfaces,
+                             remove_unused_series=False)
+
+    gp.plot_2d(geo_model, ve=10, show_topography=False)
+    plt.show()
+
+    # Plot in 3D
+    gp.plot_3d(geo_model, ve=10, show_topography=False, image=True)
+
+    # Stack Processing
+    contents = np.genfromtxt(series_file,
+                             delimiter=',', dtype='U100')[1:, 4:-1]
+
+    map_series_to_surfaces = {}
+    for pair in contents:
+        map_series_to_surfaces.setdefault(pair[1], []).append(pair[0])
+
+    gp.map_stack_to_surfaces(geo_model, map_series_to_surfaces,
+                             remove_unused_series=False)
+
+    # Adding axial rescale
+    # geo_model._rescaling.toggle_axial_anisotropy()
+
+    # Increasing nugget effect
+    geo_model.modify_surface_points(
+        geo_model.surface_points.df.index,
+        smooth=0.001
+    )
+
+    geo_model.modify_kriging_parameters('drift equations', [9, 9, 9, 9, 9])
+
+    gp.compute_model(geo_model)
+
+    gp.plot_2d(geo_model,
+               section_names=['topography'],
+               show_topography=True,
+               )
+    plt.show()
+
+    gp.plot_3d(geo_model, ve=10, show_topography=True,
+               image=True,
+               show_lith=False,
+               )
```

### Comparing `gempy-2.2b10.dev1/test/test_model_types/test_one_fault_model.py` & `gempy-2.3.0/test/test_model_types/test_one_fault_model.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,33 +1,35 @@
-import gempy as gp
-import pandas as pn
-import numpy as np
-import os
-import pytest
-import matplotlib.pyplot as plt
-input_path = os.path.dirname(__file__)+'/../../notebooks/data'
-
-
-class TestFabianModel:
-
-    def test_init_model(self, one_fault_model):
-        print(one_fault_model)
-
-    def test_get_data(self, one_fault_model):
-        print(gp.get_data(one_fault_model))
-        print(gp.get_data(one_fault_model, itype='additional_data'))
-
-    def test_plotting_data(self, one_fault_model):
-        gp.plot.plot_2d(one_fault_model, show_data=True, show_results=False)
-
-    def test_compute_model(self, one_fault_model_solution):
-        sol = one_fault_model_solution.solutions
-        print(sol)
-        return sol
-
-    def test_plot_section(self, one_fault_model):
-
-        gp.plot.plot_2d(one_fault_model, cell_number=25,
-                        direction='y', show_data=True)
-
-       # plt.savefig(os.pardir+'/../figs/example1.png')
-
+import gempy as gp
+import pandas as pn
+import numpy as np
+import os
+import pytest
+import matplotlib as mpl
+mpl.use('Agg')
+import matplotlib.pyplot as plt
+input_path = os.path.dirname(__file__)+'/../../notebooks/data'
+
+
+class TestFabianModel:
+
+    def test_init_model(self, one_fault_model):
+        print(one_fault_model)
+
+    def test_get_data(self, one_fault_model):
+        print(gp.get_data(one_fault_model))
+        print(gp.get_data(one_fault_model, itype='additional_data'))
+
+    def test_plotting_data(self, one_fault_model):
+        gp.plot.plot_2d(one_fault_model, show_data=True, show_results=False)
+
+    def test_compute_model(self, one_fault_model_solution):
+        sol = one_fault_model_solution.solutions
+        print(sol)
+        return sol
+
+    def test_plot_section(self, one_fault_model):
+
+        gp.plot.plot_2d(one_fault_model, cell_number=25,
+                        direction='y', show_data=True)
+
+       # plt.savefig(os.pardir+'/../figs/example1.png')
+
```

### Comparing `gempy-2.2b10.dev1/test/test_model_types/test_simple_models.py` & `gempy-2.3.0/test/test_model_types/test_simple_models.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,295 +1,297 @@
-import pytest
-
-import numpy as np
-import sys, os
-
-sys.path.append("../..")
-import gempy
-import matplotlib.pyplot as plt
-
-input_path = os.path.dirname(__file__) + '/../input_data'
-update_sol = False
-test_values = [45, 150, 2500, 67000, 100000]
-
-
-class TestNoFaults:
-    """
-    I am testing all block and potential field values so sol is (n_block+n_pot)
-    """
-
-    def test_a(self, interpolator):
-        """
-        2 Horizontal layers with drift 0
-        """
-        # Importing the data from csv files and settign extent and resolution
-        geo_data = gempy.create_data(extent=[0, 10, 0, 10, -10, 0], resolution=[50, 50, 50],
-                                     path_o=input_path + "/GeoModeller/test_a/test_a_Foliations.csv",
-                                     path_i=input_path + "/GeoModeller/test_a/test_a_Points.csv")
-
-        geo_data.set_theano_function(interpolator)
-
-        # Compute model
-        sol = gempy.compute_model(geo_data)
-
-        if update_sol:
-            np.save(input_path + '/test_a_sol.npy', sol.lith_block[test_values])
-
-        # Load model
-        real_sol = np.load(input_path + '/test_a_sol.npy')
-
-        # Checking that the plots do not rise errors
-        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
-        plt.savefig(os.path.dirname(__file__) + '/../figs/test_a.png', dpi=100)
-
-        gempy.plot.plot_2d(geo_data, cell_number=25, show_scalar=True)
-
-        # We only compare the block because the absolute pot field I changed it
-        np.testing.assert_array_almost_equal(np.round(sol.lith_block[test_values]), real_sol, decimal=0)
-
-    def test_b(self, interpolator):
-        """
-        Two layers a bit curvy, drift degree 1
-        """
-
-        # Importing the data from csv files and settign extent and resolution
-        geo_data = gempy.create_data(extent=[0, 10, 0, 10, -10, 0], resolution=[50, 50, 50],
-                                     path_o=input_path + "/GeoModeller/test_b/test_b_Foliations.csv",
-                                     path_i=input_path + "/GeoModeller/test_b/test_b_Points.csv")
-
-        geo_data.set_theano_function(interpolator)
-
-        # Compute model
-        sol = gempy.compute_model(geo_data)
-
-        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
-        plt.savefig(os.path.dirname(__file__) + '/../figs/test_b.png', dpi=200)
-
-        if update_sol:
-            np.save(input_path + '/test_b_sol.npy', sol.lith_block[test_values])
-
-        # Load model
-        real_sol = np.load(input_path + '/test_b_sol.npy')
-
-        # Checking that the plots do not rise errors
-        gempy.plot.plot_2d(geo_data, cell_number=25)
-
-        # We only compare the block because the absolute pot field I changed it
-        np.testing.assert_array_almost_equal(np.round(sol.lith_block[test_values]), real_sol, decimal=0)
-
-    def test_c(self, interpolator):
-        """
-        Two layers a bit curvy, drift degree 0
-        """
-
-        # Importing the data from csv files and settign extent and resolution
-        geo_data = gempy.create_data(extent=[0, 10, 0, 10, -10, 0], resolution=[50, 50, 50],
-                                     path_o=input_path + "/GeoModeller/test_c/test_c_Foliations.csv",
-                                     path_i=input_path + "/GeoModeller/test_c/test_c_Points.csv")
-
-        geo_data.set_theano_function(interpolator)
-
-        # Compute model
-        sol = gempy.compute_model(geo_data)
-
-        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
-        plt.savefig(os.path.dirname(__file__) + '/../figs/test_c.png', dpi=200)
-
-        if update_sol:
-            np.save(input_path + '/test_c_sol.npy', sol.lith_block[test_values])
-
-        # Load model
-        real_sol = np.load(input_path + '/test_c_sol.npy')
-
-        # Checking that the plots do not rise errors
-        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
-        gempy.plot.plot_2d(geo_data, cell_number=25, show_scalar=True)
-
-        # We only compare the block because the absolute pot field I changed it
-        np.testing.assert_array_almost_equal(np.round(sol.lith_block[test_values]), real_sol, decimal=0)
-
-
-class TestFaults:
-
-    def test_d(self, interpolator):
-        """
-        Two layers 1 fault
-        """
-
-        # Importing the data from csv files and settign extent and resolution
-        geo_data = gempy.create_data(extent=[0, 10, 0, 10, -10, 0], resolution=[50, 50, 50],
-                                     path_o=input_path + "/GeoModeller/test_d/test_d_Foliations.csv",
-                                     path_i=input_path + "/GeoModeller/test_d/test_d_Points.csv")
-
-        gempy.map_stack_to_surfaces(geo_data, {'fault1': 'f1', 'series': ('A', 'B')})
-
-        geo_data.set_is_fault('fault1')
-
-        geo_data.set_theano_function(interpolator)
-
-        # Compute model
-        sol = gempy.compute_model(geo_data)
-
-        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
-        plt.savefig(os.path.dirname(__file__) + '/../figs/test_d.png', dpi=200)
-
-        if update_sol:
-            np.save(input_path + '/test_d_sol.npy', sol.lith_block[test_values])
-
-        # Load model
-        real_sol = np.load(input_path + '/test_d_sol.npy')
-
-        # We only compare the block because the absolute pot field I changed it
-        np.testing.assert_array_almost_equal(np.round(sol.lith_block[test_values]), real_sol, decimal=0)
-
-    def test_e(self, interpolator):
-        """
-        Two layers a bit curvy, 1 fault
-        """
-        # Importing the data from csv files and settign extent and resolution
-        geo_data = gempy.create_data(extent=[0, 10, 0, 10, -10, 0], resolution=[50, 50, 50],
-                                     path_o=input_path + "/GeoModeller/test_e/test_e_Foliations.csv",
-                                     path_i=input_path + "/GeoModeller/test_e/test_e_Points.csv")
-
-        gempy.map_stack_to_surfaces(geo_data, {'fault1': 'f1', 'series': ('A', 'B')})
-        geo_data.set_is_fault('fault1')
-
-        geo_data.set_theano_function(interpolator)
-
-        # Compute model
-        sol = gempy.compute_model(geo_data)
-
-        if update_sol:
-            np.save(input_path + '/test_e_sol.npy', sol.lith_block[test_values])
-
-        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
-        plt.savefig(os.path.dirname(__file__) + '/../figs/test_e.png', dpi=200)
-
-        # Load model
-        real_sol = np.load(input_path + '/test_e_sol.npy')
-
-        # We only compare the block because the absolute pot field I changed it
-        np.testing.assert_array_almost_equal(np.round(sol.lith_block[test_values]), real_sol, decimal=0)
-
-    def test_f_sort_surfaces(self, interpolator):
-        """
-        Two layers a bit curvy, 1 fault. Checked with geomodeller
-        """
-
-        # Importing the data from csv files and settign extent and resolution
-        geo_data = gempy.create_data(extent=[0, 2000, 0, 2000, -2000, 0], resolution=[50, 50, 50],
-                                     path_o=input_path + "/GeoModeller/test_f/test_f_Foliations.csv",
-                                     path_i=input_path + "/GeoModeller/test_f/test_f_Points.csv")
-
-        gempy.map_stack_to_surfaces(geo_data, {'fault1': 'MainFault',
-                                               'series': ('Reservoir',
-                                                          'Seal',
-                                                          'SecondaryReservoir',
-                                                          'NonReservoirDeep'
-                                                          ),
-                                               },
-                                    )
-
-        geo_data.set_theano_function(interpolator)
-        geo_data.set_is_fault('fault1')
-
-        # Compute model
-        sol = gempy.compute_model(geo_data, sort_surfaces=True)
-
-        if update_sol:
-            np.save(input_path + '/test_f_sol.npy', sol.lith_block[test_values])
-
-        real_sol = np.load(input_path + '/test_f_sol.npy')
-        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
-        plt.show()
-        plt.savefig(os.path.dirname(__file__) + '/../figs/test_f.png', dpi=200)
-
-        gempy.compute_model(geo_data)
-        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
-        plt.show()
-
-        gempy.compute_model(geo_data)
-        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
-        plt.show()
-
-        # We only compare the block because the absolute pot field I changed it
-        np.testing.assert_array_almost_equal(np.round(sol.lith_block[test_values]), real_sol, decimal=0)
-
-        ver, sim = gempy.get_surfaces(geo_data)
-        print(ver, sim)
-
-    def test_compute_model_multiple_ranges(self, interpolator):
-
-        # Importing the data from csv files and settign extent and resolution
-        geo_data = gempy.create_data(extent=[0, 2000, 0, 2000, -2000, 0], resolution=[50, 50, 50],
-                                     path_o=input_path + "/GeoModeller/test_f/test_f_Foliations.csv",
-                                     path_i=input_path + "/GeoModeller/test_f/test_f_Points.csv")
-
-        gempy.map_stack_to_surfaces(geo_data, {'fault1': 'MainFault',
-                                               'series': ('Reservoir',
-                                                          'Seal',
-                                                          'SecondaryReservoir',
-                                                          'NonReservoirDeep'
-                                                          ),
-                                               },
-                                    )
-
-        geo_data.set_theano_function(interpolator)
-        geo_data.set_is_fault('fault1')
-        geo_data.modify_kriging_parameters('range', [3000, 3500, 0])
-        geo_data._additional_data.kriging_data.set_default_c_o()
-        # Compute model
-        sol = gempy.compute_model(geo_data, sort_surfaces=True)
-        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
-        plt.show()
-
-
-def test_simple_model_gempy_engine():
-    import numpy
-    numpy.set_printoptions(precision=3, linewidth=200)
-
-    g = gempy.create_data("test_engine", extent=[-4, 4, -4, 4, -4, 4], resolution=[4, 1, 4])
-    sp = np.array([[-3, 0, 0],
-                   [0, 0, 0],
-                   [2, 0, 0.5],
-                   [2.5, 0, 1.2],
-                   [3, 0, 2],
-                   [1, 0, .2],
-                   [2.8, 0, 1.5]])
-
-    g.set_default_surfaces()
-
-    for i in sp:
-        g.add_surface_points(*i, surface="surface1")
-
-    g.add_orientations(-3, 0, 2, pole_vector=(0, 0, 1), surface="surface1")
-    g.add_orientations(2, 0, 3, pole_vector=(-.2, 0, .8), surface="surface1")
-
-    g.modify_orientations([0, 1], smooth=0.000000000001)
-    g.modify_surface_points(g._surface_points.df.index, smooth=0.0000000001)
-
-    gempy.set_interpolator(g, verbose=[
-        "n_surface_op_float_sigmoid",
-        "scalar_field_iter",
-        "compare",
-        "sigma"
-    ])
-
-    g.modify_kriging_parameters("range", 50)
-    # g.modify_kriging_parameters("$C_o$", 5 ** 2 / 14 / 3)
-    g.modify_kriging_parameters("drift equations", [0])
-
-    import theano
-    dtype = "float32"
-
-    g._interpolator.theano_graph.i_reescale.set_value(np.cast[dtype](1.))
-    g._interpolator.theano_graph.gi_reescale.set_value(np.cast[dtype](1.))
-
-    gempy.compute_model(g)
-
-    print(g.additional_data)
-    print(g.solutions.scalar_field_matrix)
-
-    gempy.plot_2d(g)
-    print(g.grid.values)
-
-    print(g.solutions.weights_vector)
+import pytest
+
+import numpy as np
+import sys, os
+
+sys.path.append("../..")
+import gempy
+import matplotlib as mpl
+mpl.use('Agg')
+import matplotlib.pyplot as plt
+
+input_path = os.path.dirname(__file__) + '/../input_data'
+update_sol = False
+test_values = [45, 150, 2500, 67000, 100000]
+
+
+class TestNoFaults:
+    """
+    I am testing all block and potential field values so sol is (n_block+n_pot)
+    """
+
+    def test_a(self, interpolator):
+        """
+        2 Horizontal layers with drift 0
+        """
+        # Importing the data from csv files and settign extent and resolution
+        geo_data = gempy.create_data(extent=[0, 10, 0, 10, -10, 0], resolution=[50, 50, 50],
+                                     path_o=input_path + "/GeoModeller/test_a/test_a_Foliations.csv",
+                                     path_i=input_path + "/GeoModeller/test_a/test_a_Points.csv")
+
+        geo_data.set_aesara_function(interpolator)
+
+        # Compute model
+        sol = gempy.compute_model(geo_data)
+
+        if update_sol:
+            np.save(input_path + '/test_a_sol.npy', sol.lith_block[test_values])
+
+        # Load model
+        real_sol = np.load(input_path + '/test_a_sol.npy')
+
+        # Checking that the plots do not rise errors
+        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
+        plt.savefig(os.path.dirname(__file__) + '/../figs/test_a.png', dpi=100)
+
+        gempy.plot.plot_2d(geo_data, cell_number=25, show_scalar=True)
+
+        # We only compare the block because the absolute pot field I changed it
+        np.testing.assert_array_almost_equal(np.round(sol.lith_block[test_values]), real_sol, decimal=0)
+
+    def test_b(self, interpolator):
+        """
+        Two layers a bit curvy, drift degree 1
+        """
+
+        # Importing the data from csv files and settign extent and resolution
+        geo_data = gempy.create_data(extent=[0, 10, 0, 10, -10, 0], resolution=[50, 50, 50],
+                                     path_o=input_path + "/GeoModeller/test_b/test_b_Foliations.csv",
+                                     path_i=input_path + "/GeoModeller/test_b/test_b_Points.csv")
+
+        geo_data.set_aesara_function(interpolator)
+
+        # Compute model
+        sol = gempy.compute_model(geo_data)
+
+        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
+        plt.savefig(os.path.dirname(__file__) + '/../figs/test_b.png', dpi=200)
+
+        if update_sol:
+            np.save(input_path + '/test_b_sol.npy', sol.lith_block[test_values])
+
+        # Load model
+        real_sol = np.load(input_path + '/test_b_sol.npy')
+
+        # Checking that the plots do not rise errors
+        gempy.plot.plot_2d(geo_data, cell_number=25)
+
+        # We only compare the block because the absolute pot field I changed it
+        np.testing.assert_array_almost_equal(np.round(sol.lith_block[test_values]), real_sol, decimal=0)
+
+    def test_c(self, interpolator):
+        """
+        Two layers a bit curvy, drift degree 0
+        """
+
+        # Importing the data from csv files and settign extent and resolution
+        geo_data = gempy.create_data(extent=[0, 10, 0, 10, -10, 0], resolution=[50, 50, 50],
+                                     path_o=input_path + "/GeoModeller/test_c/test_c_Foliations.csv",
+                                     path_i=input_path + "/GeoModeller/test_c/test_c_Points.csv")
+
+        geo_data.set_aesara_function(interpolator)
+
+        # Compute model
+        sol = gempy.compute_model(geo_data)
+
+        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
+        plt.savefig(os.path.dirname(__file__) + '/../figs/test_c.png', dpi=200)
+
+        if update_sol:
+            np.save(input_path + '/test_c_sol.npy', sol.lith_block[test_values])
+
+        # Load model
+        real_sol = np.load(input_path + '/test_c_sol.npy')
+
+        # Checking that the plots do not rise errors
+        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
+        gempy.plot.plot_2d(geo_data, cell_number=25, show_scalar=True)
+
+        # We only compare the block because the absolute pot field I changed it
+        np.testing.assert_array_almost_equal(np.round(sol.lith_block[test_values]), real_sol, decimal=0)
+
+
+class TestFaults:
+
+    def test_d(self, interpolator):
+        """
+        Two layers 1 fault
+        """
+
+        # Importing the data from csv files and settign extent and resolution
+        geo_data = gempy.create_data(extent=[0, 10, 0, 10, -10, 0], resolution=[50, 50, 50],
+                                     path_o=input_path + "/GeoModeller/test_d/test_d_Foliations.csv",
+                                     path_i=input_path + "/GeoModeller/test_d/test_d_Points.csv")
+
+        gempy.map_stack_to_surfaces(geo_data, {'fault1': 'f1', 'series': ('A', 'B')})
+
+        geo_data.set_is_fault('fault1')
+
+        geo_data.set_aesara_function(interpolator)
+
+        # Compute model
+        sol = gempy.compute_model(geo_data)
+
+        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
+        plt.savefig(os.path.dirname(__file__) + '/../figs/test_d.png', dpi=200)
+
+        if update_sol:
+            np.save(input_path + '/test_d_sol.npy', sol.lith_block[test_values])
+
+        # Load model
+        real_sol = np.load(input_path + '/test_d_sol.npy')
+
+        # We only compare the block because the absolute pot field I changed it
+        np.testing.assert_array_almost_equal(np.round(sol.lith_block[test_values]), real_sol, decimal=0)
+
+    def test_e(self, interpolator):
+        """
+        Two layers a bit curvy, 1 fault
+        """
+        # Importing the data from csv files and settign extent and resolution
+        geo_data = gempy.create_data(extent=[0, 10, 0, 10, -10, 0], resolution=[50, 50, 50],
+                                     path_o=input_path + "/GeoModeller/test_e/test_e_Foliations.csv",
+                                     path_i=input_path + "/GeoModeller/test_e/test_e_Points.csv")
+
+        gempy.map_stack_to_surfaces(geo_data, {'fault1': 'f1', 'series': ('A', 'B')})
+        geo_data.set_is_fault('fault1')
+
+        geo_data.set_aesara_function(interpolator)
+
+        # Compute model
+        sol = gempy.compute_model(geo_data)
+
+        if update_sol:
+            np.save(input_path + '/test_e_sol.npy', sol.lith_block[test_values])
+
+        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
+        plt.savefig(os.path.dirname(__file__) + '/../figs/test_e.png', dpi=200)
+
+        # Load model
+        real_sol = np.load(input_path + '/test_e_sol.npy')
+
+        # We only compare the block because the absolute pot field I changed it
+        np.testing.assert_array_almost_equal(np.round(sol.lith_block[test_values]), real_sol, decimal=0)
+
+    def test_f_sort_surfaces(self, interpolator):
+        """
+        Two layers a bit curvy, 1 fault. Checked with geomodeller
+        """
+
+        # Importing the data from csv files and settign extent and resolution
+        geo_data = gempy.create_data(extent=[0, 2000, 0, 2000, -2000, 0], resolution=[50, 50, 50],
+                                     path_o=input_path + "/GeoModeller/test_f/test_f_Foliations.csv",
+                                     path_i=input_path + "/GeoModeller/test_f/test_f_Points.csv")
+
+        gempy.map_stack_to_surfaces(geo_data, {'fault1': 'MainFault',
+                                               'series': ('Reservoir',
+                                                          'Seal',
+                                                          'SecondaryReservoir',
+                                                          'NonReservoirDeep'
+                                                          ),
+                                               },
+                                    )
+
+        geo_data.set_aesara_function(interpolator)
+        geo_data.set_is_fault('fault1')
+
+        # Compute model
+        sol = gempy.compute_model(geo_data, sort_surfaces=True)
+
+        if update_sol:
+            np.save(input_path + '/test_f_sol.npy', sol.lith_block[test_values])
+
+        real_sol = np.load(input_path + '/test_f_sol.npy')
+        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
+        plt.show()
+        plt.savefig(os.path.dirname(__file__) + '/../figs/test_f.png', dpi=200)
+
+        gempy.compute_model(geo_data)
+        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
+        plt.show()
+
+        gempy.compute_model(geo_data)
+        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
+        plt.show()
+
+        # We only compare the block because the absolute pot field I changed it
+        np.testing.assert_array_almost_equal(np.round(sol.lith_block[test_values]), real_sol, decimal=0)
+
+        ver, sim = gempy.get_surfaces(geo_data)
+        print(ver, sim)
+
+    def test_compute_model_multiple_ranges(self, interpolator):
+
+        # Importing the data from csv files and settign extent and resolution
+        geo_data = gempy.create_data(extent=[0, 2000, 0, 2000, -2000, 0], resolution=[50, 50, 50],
+                                     path_o=input_path + "/GeoModeller/test_f/test_f_Foliations.csv",
+                                     path_i=input_path + "/GeoModeller/test_f/test_f_Points.csv")
+
+        gempy.map_stack_to_surfaces(geo_data, {'fault1': 'MainFault',
+                                               'series': ('Reservoir',
+                                                          'Seal',
+                                                          'SecondaryReservoir',
+                                                          'NonReservoirDeep'
+                                                          ),
+                                               },
+                                    )
+
+        geo_data.set_aesara_function(interpolator)
+        geo_data.set_is_fault('fault1')
+        geo_data.modify_kriging_parameters('range', [3000, 3500, 0])
+        geo_data._additional_data.kriging_data.set_default_c_o()
+        # Compute model
+        sol = gempy.compute_model(geo_data, sort_surfaces=True)
+        gempy.plot.plot_2d(geo_data, cell_number=25, direction='y', show_data=True)
+        plt.show()
+
+
+def test_simple_model_gempy_engine():
+    import numpy
+    numpy.set_printoptions(precision=3, linewidth=200)
+
+    g = gempy.create_data("test_engine", extent=[-4, 4, -4, 4, -4, 4], resolution=[4, 1, 4])
+    sp = np.array([[-3, 0, 0],
+                   [0, 0, 0],
+                   [2, 0, 0.5],
+                   [2.5, 0, 1.2],
+                   [3, 0, 2],
+                   [1, 0, .2],
+                   [2.8, 0, 1.5]])
+
+    g.set_default_surfaces()
+
+    for i in sp:
+        g.add_surface_points(*i, surface="surface1")
+
+    g.add_orientations(-3, 0, 2, pole_vector=(0, 0, 1), surface="surface1")
+    g.add_orientations(2, 0, 3, pole_vector=(-.2, 0, .8), surface="surface1")
+
+    g.modify_orientations([0, 1], smooth=0.000000000001)
+    g.modify_surface_points(g._surface_points.df.index, smooth=0.0000000001)
+
+    gempy.set_interpolator(g, verbose=[
+        "n_surface_op_float_sigmoid",
+        "scalar_field_iter",
+        "compare",
+        "sigma"
+    ])
+
+    g.modify_kriging_parameters("range", 50)
+    # g.modify_kriging_parameters("$C_o$", 5 ** 2 / 14 / 3)
+    g.modify_kriging_parameters("drift equations", [0])
+
+    import aesara
+    dtype = "float32"
+
+    g._interpolator.aesara_graph.i_reescale.set_value(np.cast[dtype](1.))
+    g._interpolator.aesara_graph.gi_reescale.set_value(np.cast[dtype](1.))
+
+    gempy.compute_model(g)
+
+    print(g.additional_data)
+    print(g.solutions.scalar_field_matrix)
+
+    gempy.plot_2d(g)
+    print(g.grid.values)
+
+    print(g.solutions.weights_vector)
```

### Comparing `gempy-2.2b10.dev1/test/test_plotting/test_2d.py` & `gempy-2.3.0/test/test_plotting/test_2d.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,118 +1,122 @@
-import gempy as gp
-import matplotlib.pyplot as plt
-import numpy as np
-import pytest
-
-
-def test_plot_2d_data_default(one_fault_model_no_interp):
-    gp.plot.plot_2d(one_fault_model_no_interp)
-    plt.show()
-
-
-def test_plot_2d_data_default_all_none(one_fault_model_no_interp):
-    gp.plot.plot_2d(one_fault_model_no_interp, show_data=True, show_results=False)
-    plt.show()
-
-
-def test_basic(one_fault_model_no_interp):
-    fig = plt.figure()
-    ax = fig.add_subplot(111)
-    ax.imshow(np.arange(25).reshape(5,5))
-    fig.show()
-
-
-def test_plot_2d_test_labels(one_fault_model_no_interp):
-    geo_model = one_fault_model_no_interp
-    section_dict = {'section_SW-NE': ([250, 250], [1750, 1750], [100, 100]),
-                    'section_NW-SE': ([250, 1750], [1750, 250], [100, 100])}
-    geo_model.set_section_grid(section_dict)
-    geo_model.set_topography(fd=1.2, d_z=np.array([600, 2000]), resolution=np.array([60, 60]))
-
-    gp.plot_2d(geo_model,
-               section_names=['section_NW-SE', 'section_NW-SE', 'topography'],
-               direction=['x'], cell_number=['mid'],
-               show_topography=True,
-               )
-    plt.show()
-
-    gp.plot_2d(geo_model,
-               section_names=['section_NW-SE', 'section_NW-SE', 'topography'],
-               direction=['x'], cell_number=['mid'],
-               show_topography=True,
-               projection_distance=100)
-    plt.show()
-
-    gp.plot_2d(geo_model,
-               section_names=['section_NW-SE', 'section_NW-SE', 'topography'],
-               direction=['x'], cell_number=['mid'],
-               show_topography=True,
-               projection_distance=1000)
-    plt.show()
-
-    gp.plot.plot_section_traces(geo_model)
-    plt.show()
-
-
-@pytest.fixture(scope='module')
-def section_model(one_fault_model_topo_solution):
-    geo_model = one_fault_model_topo_solution
-    section_dict = {'section_SW-NE': ([250, 250], [1750, 1750], [100, 100]),
-                    'section_NW-SE': ([250, 1750], [1750, 250], [100, 100])}
-    geo_model.set_section_grid(section_dict)
-
-    geo_model.set_active_grid('sections', reset=False)
-
-    one_fault_model_topo_solution.update_additional_data()
-    one_fault_model_topo_solution.update_to_interpolator()
-    gp.compute_model(geo_model, sort_surfaces=False)
-    return geo_model
-
-
-def test_topo_sections_iterp2(section_model):
-    # Test 1 single
-    gp.plot_2d(section_model, section_names=['section_NW-SE'],
-               show_topography=True)
-    plt.show()
-
-    # Test 2 plots
-    gp.plot_2d(section_model, section_names=['section_NW-SE', 'section_NW-SE'],
-               show_topography=True)
-    plt.show()
-
-    # Test 3 plots
-    gp.plot_2d(section_model, section_names=['section_NW-SE', 'section_NW-SE', 'topography'],
-               show_topography=True)
-    plt.show()
-
-    # Test 4
-    gp.plot_2d(section_model, section_names=['section_NW-SE', 'section_NW-SE', 'topography'],
-               direction=['x'], cell_number=['mid'],
-               show_topography=True)
-    plt.show()
-
-    gp.plot.plot_section_traces(section_model)
-    plt.show()
-
-
-def test_show_results(section_model):
-    p2d = gp.plot_2d(section_model,
-                     show_data=False,
-                     show_topography=False,
-                     show_results=True,
-                     show=True)
-
-
-def test_ve(section_model):
-    # Test ve
-    p2d = gp.plot_2d(section_model, section_names=['section_NW-SE', 'section_NW-SE'],
-                     show_topography=True, ve=3)
-
-    plt.show()
-
-
-def test_topo_resize(one_fault_model_topo_solution):
-    geo_model = one_fault_model_topo_solution
-    geo_model.set_topography(fd=1.2, d_z=np.array([600, 2000]), resolution=np.array([60, 60]))
-    sol = gp.compute_model(geo_model, compute_mesh=False)
-    gp.plot_2d(geo_model, section_names=['topography'])
-    plt.show()
+import gempy as gp
+import matplotlib as mpl
+mpl.use('Agg')
+import matplotlib.pyplot as plt
+import numpy as np
+import pytest
+
+
+def test_plot_2d_data_default(one_fault_model_no_interp):
+    gp.plot.plot_2d(one_fault_model_no_interp)
+    plt.show()
+
+
+def test_plot_2d_data_default_all_none(one_fault_model_no_interp):
+    gp.plot.plot_2d(one_fault_model_no_interp, show_data=True, show_results=False)
+    plt.show()
+
+
+def test_basic(one_fault_model_no_interp):
+    fig = plt.figure()
+    ax = fig.add_subplot(111)
+    ax.imshow(np.arange(25).reshape(5, 5))
+    fig.show()
+
+
+def test_plot_2d_test_labels(one_fault_model_no_interp):
+    geo_model = one_fault_model_no_interp
+    section_dict = {'section_SW-NE': ([250, 250], [1750, 1750], [100, 100]),
+                    'section_NW-SE': ([250, 1750], [1750, 250], [100, 100])}
+    geo_model.set_section_grid(section_dict)
+    geo_model.set_topography(fd=1.2, d_z=np.array([600, 2000]), resolution=np.array([60, 60]))
+
+    gp.plot_2d(
+        model=geo_model,
+        section_names=['section_NW-SE', 'section_NW-SE', 'topography'],
+        direction=['x'], cell_number=['mid'],
+        show_topography=True,
+        show_section_traces=True
+    )
+    plt.show()
+    
+    gp.plot_2d(geo_model,
+               section_names=['section_NW-SE', 'section_NW-SE', 'topography'],
+               direction=['x'], cell_number=['mid'],
+               show_topography=True,
+               projection_distance=100)
+    plt.show()
+
+    gp.plot_2d(geo_model,
+               section_names=['section_NW-SE', 'section_NW-SE', 'topography'],
+               direction=['x'], cell_number=['mid'],
+               show_topography=True,
+               projection_distance=1000)
+    plt.show()
+
+# gp.plot.plot_section_traces(geo_model)
+    plt.show()
+
+
+@pytest.fixture(scope='module')
+def section_model(one_fault_model_topo_solution):
+    geo_model = one_fault_model_topo_solution
+    section_dict = {'section_SW-NE': ([250, 250], [1750, 1750], [100, 100]),
+                    'section_NW-SE': ([250, 1750], [1750, 250], [100, 100])}
+    geo_model.set_section_grid(section_dict)
+
+    geo_model.set_active_grid('sections', reset=False)
+
+    one_fault_model_topo_solution.update_additional_data()
+    one_fault_model_topo_solution.update_to_interpolator()
+    gp.compute_model(geo_model, sort_surfaces=False)
+    return geo_model
+
+
+def test_topo_sections_iterp2(section_model):
+    # Test 1 single
+    gp.plot_2d(section_model, section_names=['section_NW-SE'],
+               show_topography=True)
+    plt.show()
+
+    # Test 2 plots
+    gp.plot_2d(section_model, section_names=['section_NW-SE', 'section_NW-SE'],
+               show_topography=True)
+    plt.show()
+
+    # Test 3 plots
+    gp.plot_2d(section_model, section_names=['section_NW-SE', 'section_NW-SE', 'topography'],
+               show_topography=True)
+    plt.show()
+
+    # Test 4
+    gp.plot_2d(section_model, section_names=['section_NW-SE', 'section_NW-SE', 'topography'],
+               direction=['x'], cell_number=['mid'],
+               show_topography=True)
+    plt.show()
+
+    gp.plot.plot_section_traces(section_model)
+    plt.show()
+
+
+def test_show_results(section_model):
+    p2d = gp.plot_2d(section_model,
+                     show_data=False,
+                     show_topography=False,
+                     show_results=True,
+                     show=True)
+
+
+def test_ve(section_model):
+    # Test ve
+    p2d = gp.plot_2d(section_model, section_names=['section_NW-SE', 'section_NW-SE'],
+                     show_topography=True, ve=3)
+
+    plt.show()
+
+
+def test_topo_resize(one_fault_model_topo_solution):
+    geo_model = one_fault_model_topo_solution
+    geo_model.set_topography(fd=1.2, d_z=np.array([600, 2000]), resolution=np.array([60, 60]))
+    sol = gp.compute_model(geo_model, compute_mesh=False)
+    gp.plot_2d(geo_model, section_names=['topography'])
+    plt.show()
```

### Comparing `gempy-2.2b10.dev1/test/test_plotting/test_plot_3d.py` & `gempy-2.3.0/test/test_plotting/test_plot_3d.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,76 +1,78 @@
-import gempy as gp
-import pyvista as pv
-import matplotlib.pyplot as plt
-import warnings
-
-try:
-    import faulthandler
-    faulthandler.enable()
-except Exception as e:  # pragma: no cover
-    warnings.warn('Unable to enable faulthandler:\n%s' % str(e))
-
-
-def test_pyvista_running():
-    from pyvista import examples
-    examples.plot_wave()
-
-def test_plot_3d_data_default(one_fault_model_no_interp):
-    gpv = gp.plot.plot_3d(one_fault_model_no_interp,
-                          plotter_type='basic', off_screen=True, image=True, notebook=False)
-    # img = gpv.p.show(screenshot=True)
-    # plt.imshow(img[1])
-    # plt.show()
-
-
-def test_plot_3d_geo_map(unconformity_model):
-    gpv = gp.plot.plot_3d(unconformity_model,
-                          plotter_type='basic', off_screen=True,
-                          show_topography=True,
-                          show_scalar=False,
-                          show_lith=False,
-                          image=True,
-                          kwargs_plot_structured_grid={'opacity': .5})
-    # img = gpv.p.show(screenshot=True)
-    # plt.imshow(img[1])
-    # plt.show()
-
-
-def test_plot_3d_geo_map2(one_fault_model_topo_solution):
-    gpv = gp.plot.plot_3d(one_fault_model_topo_solution,
-                          plotter_type='basic', off_screen=True,
-                          show_topography=True,
-                          show_scalar=False,
-                          show_lith=False,
-                          image=True,
-                          kwargs_plot_structured_grid={'opacity': .5})
-    # img = gpv.p.show(screenshot=True)
-    # plt.imshow(img[1])
-    # plt.show()
-
-
-def test_plot_3d_structure_topo(one_fault_model_topo_solution):
-    one_fault_model_topo_solution._grid.regular_grid.set_topography_mask(
-        one_fault_model_topo_solution._grid.topography)
-    gpv = gp.plot.plot_3d(one_fault_model_topo_solution,
-                          plotter_type='basic', off_screen=True,
-                          show_topography=True,
-                          show_scalar=False,
-                          show_lith=True,
-                          image=True,
-                          kwargs_plot_structured_grid={'opacity': .5})
-    # img = gpv.p.show(screenshot=True)
-    # plt.imshow(img[1])
-    # plt.show()
-
-
-def test_plot_3d_structure_topo2(unconformity_model_topo):
-    gpv = gp.plot.plot_3d(unconformity_model_topo,
-                          plotter_type='basic', off_screen=True,
-                          show_topography=True,
-                          show_scalar=False,
-                          show_lith=True,
-                          image=True,
-                          kwargs_plot_structured_grid={'opacity': .5})
-    # img = gpv.p.show(screenshot=True)
-    # plt.imshow(img[1])
-    # plt.show()
+import gempy as gp
+import pyvista as pv
+import matplotlib as mpl
+mpl.use('Agg')
+import matplotlib.pyplot as plt
+import warnings
+
+try:
+    import faulthandler
+    faulthandler.enable()
+except Exception as e:  # pragma: no cover
+    warnings.warn('Unable to enable faulthandler:\n%s' % str(e))
+
+
+def test_pyvista_running():
+    from pyvista import demos
+    demos.plot_wave()
+
+def test_plot_3d_data_default(one_fault_model_no_interp):
+    gpv = gp.plot.plot_3d(one_fault_model_no_interp,
+                          plotter_type='basic', off_screen=True, image=True, notebook=False)
+    # img = gpv.p.show(screenshot=True)
+    # plt.imshow(img[1])
+    # plt.show()
+
+
+def test_plot_3d_geo_map(unconformity_model):
+    gpv = gp.plot.plot_3d(unconformity_model,
+                          plotter_type='basic', off_screen=True,
+                          show_topography=True,
+                          show_scalar=False,
+                          show_lith=False,
+                          image=True,
+                          kwargs_plot_structured_grid={'opacity': .5})
+    # img = gpv.p.show(screenshot=True)
+    # plt.imshow(img[1])
+    # plt.show()
+
+
+def test_plot_3d_geo_map2(one_fault_model_topo_solution):
+    gpv = gp.plot.plot_3d(one_fault_model_topo_solution,
+                          plotter_type='basic', off_screen=True,
+                          show_topography=True,
+                          show_scalar=False,
+                          show_lith=False,
+                          image=True,
+                          kwargs_plot_structured_grid={'opacity': .5})
+    # img = gpv.p.show(screenshot=True)
+    # plt.imshow(img[1])
+    # plt.show()
+
+
+def test_plot_3d_structure_topo(one_fault_model_topo_solution):
+    one_fault_model_topo_solution._grid.regular_grid.set_topography_mask(
+        one_fault_model_topo_solution._grid.topography)
+    gpv = gp.plot.plot_3d(one_fault_model_topo_solution,
+                          plotter_type='basic', off_screen=True,
+                          show_topography=True,
+                          show_scalar=False,
+                          show_lith=True,
+                          image=True,
+                          kwargs_plot_structured_grid={'opacity': .5})
+    # img = gpv.p.show(screenshot=True)
+    # plt.imshow(img[1])
+    # plt.show()
+
+
+def test_plot_3d_structure_topo2(unconformity_model_topo):
+    gpv = gp.plot.plot_3d(unconformity_model_topo,
+                          plotter_type='basic', off_screen=True,
+                          show_topography=True,
+                          show_scalar=False,
+                          show_lith=True,
+                          image=True,
+                          kwargs_plot_structured_grid={'opacity': .5})
+    # img = gpv.p.show(screenshot=True)
+    # plt.imshow(img[1])
+    # plt.show()
```

### Comparing `gempy-2.2b10.dev1/test/test_plotting/test_vista.py` & `gempy-2.3.0/test/test_plotting/test_vista.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,11 +1,13 @@
 import os
 import pytest
 import gempy as gp
 import numpy as np
+import matplotlib as mpl
+mpl.use('Agg')
 import matplotlib.pyplot as plt
 from gempy.plot.vista import GemPyToVista
 
 input_path = os.path.dirname(__file__) + '/../../notebooks/data'
 
 
 @pytest.mark.skipif("TRAVIS" in os.environ and os.environ["TRAVIS"] == "true",
@@ -78,14 +80,15 @@
         np.testing.assert_almost_equal(sp.loc[4, 'X_c'],  0.486942, 5)
 
         sp2 = vista_object_only_data._select_surfaces_data(data_df=vista_object_only_data.model._surface_points.df,
                                                            surfaces=['Sandstone_2'])
         with pytest.raises(KeyError):
             sp2.loc[4, 'X_r']
 
+    @pytest.mark.skip(reason= "github actions does not like background plot")
     def test_plot_surface_points_poly_live(self, vista_object_only_data_interactive):
         """
         Args:
             vista_object_only_data:
         """
         vista_object_only_data_interactive.live_updating = True
         vista_object_only_data_interactive.plot_surface_points()
@@ -94,38 +97,42 @@
         """
         Args:
             vista_object_only_data:
         """
         vista_object_only_data.live_updating = False
         vista_object_only_data.plot_surface_points()
         img = vista_object_only_data.p.show(screenshot=True, auto_close=False)
+        img = vista_object_only_data.p.last_image
         plt.imshow(img[1])
         plt.show(block=False)
         print('foo')
 
     def test_plot_surface_points_poly_clear(self, vista_object_only_data):
         """
         Args:
             vista_object_only_data:
         """
         vista_object_only_data.live_updating = False
         vista_object_only_data.plot_surface_points()
         vista_object_only_data.plot_surface_points()
         img = vista_object_only_data.p.show(screenshot=True, auto_close=False)
+        img = vista_object_only_data.p.last_image
         plt.imshow(img[1])
         plt.show(block=False)
         print('foo')
 
     def test_plot_data_static(self, vista_object_only_data):
         vista_object_only_data.plot_data()
         img = vista_object_only_data.p.show(screenshot=True, auto_close=False)
+        img = vista_object_only_data.p.last_image
         plt.imshow(img[1])
         plt.show()
         print('foo')
 
+    @pytest.mark.skip(reason="github actions does not like background plot")
     def test_plot_orientations_poly_live(self, vista_object_only_data_interactive):
         """
         Args:
             vista_object_only_data:
         """
         vista_object_only_data_interactive.live_updating = True
         vista_object_only_data_interactive.plot_orientations()
@@ -136,64 +143,69 @@
         """
         Args:
             vista_object_only_data:
         """
         vista_object_only_data.live_updating = False
         vista_object_only_data.plot_orientations()
         img = vista_object_only_data.p.show(screenshot=True, auto_close=False)
+        img = vista_object_only_data.p.last_image
         plt.imshow(img[1])
         plt.show()
 
         print('foo')
 
     def test_plot_surfaces(self, vista_object_computed):
         """
         Args:
             vista_object_computed:
         """
         a = vista_object_computed.plot_surfaces()
         img = vista_object_computed.p.show(screenshot=True, auto_close=False)
+        img = vista_object_computed.p.last_image
         plt.imshow(img[1])
         plt.show()
 
     def test_plot_surfaces_data(self, vista_object_computed):
         """
         Args:
             vista_object_computed:
         """
         a = vista_object_computed.plot_surfaces()
         vista_object_computed.plot_data()
         img = vista_object_computed.p.show(screenshot=True, auto_close=False)
+        img = vista_object_computed.p.last_image
         plt.imshow(img[1])
         plt.show()
 
     def test_plot_topography_lith(self, one_fault_model_topo_solution):
         """
         Args:
             vista_object_computed_topo:
         """
 
         vista_object_computed_topo = GemPyToVista(one_fault_model_topo_solution,
                                                   plotter_type='basic', off_screen=True)
 
         vista_object_computed_topo.plot_topography(scalars='geomap')
         img = vista_object_computed_topo.p.show(screenshot=True)
+        img = vista_object_computed_topo.p.last_image
         plt.imshow(img[1])
         plt.show()
 
     def test_plot_topography_high(self, one_fault_model_topo_solution):
         """
         Args:
             vista_object_computed_topo:
         """
         vista_object_computed_topo = GemPyToVista(one_fault_model_topo_solution,
                                                   plotter_type='basic', off_screen=True)
 
         vista_object_computed_topo.plot_topography(scalars='topography')
         img = vista_object_computed_topo.p.show(screenshot=True)
+        img = vista_object_computed_topo.p.last_image
         plt.imshow(img[1])
         plt.show()
         print('foo')
 
     def test_plot_topography_high_clear(self, one_fault_model_topo_solution):
         """
         Args:
@@ -204,27 +216,29 @@
 
         vista_object_computed_topo.plot_topography(scalars='topography')
         one_fault_model_topo_solution.set_topography()
         gp.compute_model(one_fault_model_topo_solution)
 
         vista_object_computed_topo.plot_topography(scalars='topography')
         img = vista_object_computed_topo.p.show(screenshot=True)
+        img = vista_object_computed_topo.p.last_image
         plt.imshow(img[1])
         plt.show()
         print('foo')
 
 
     def test_plot_regular_grid_lith(self, vista_object_computed):
         """
         Args:
             vista_object_computed:
         """
         vista_object_computed.plot_structured_grid('lith', render_topography=False,
                                                    opacity=.8)
         img = vista_object_computed.p.show(screenshot=True)
+        img = vista_object_computed.p.last_image
         plt.imshow(img[1])
         plt.show()
 
         print('foo')
 
     def test_plot_regular_grid_scalar_0(self, vista_object_computed):
         # Add all scalar fields to the pyvista object and plot lith
@@ -254,14 +268,15 @@
         vista_object_computed_topo = GemPyToVista(one_fault_model_topo_solution,
                                                   plotter_type='basic', off_screen=True)
 
         vista_object_computed_topo.plot_structured_grid('lith', render_topography=False)
         vista_object_computed_topo.plot_surfaces()
         # vista_object_computed_topo.set_scalar_bar()
         img = vista_object_computed_topo.p.show(screenshot=True)
+        img = vista_object_computed_topo.p.last_image
         plt.imshow(img[1])
         plt.show()
         print('foo')
 
     def test_plot_regular_grid_scalar_1(self, vista_object_computed):
         """
         Args:
@@ -277,40 +292,42 @@
         """
 
         vista_object_computed = GemPyToVista(one_fault_model_solution,
                                              plotter_type='basic',
                                              off_screen=True
                                            )
         vista_object_computed.plot_structured_grid('lith')
-        with pytest.raises(AttributeError):
+        with pytest.raises(KeyError):
             vista_object_computed.set_active_scalar_fields(scalar_field='scalar')
         # vista_object_computed.plot_structured_grid('scalar')
         print('foo')
 
     def test_plot_several(self, one_fault_model_topo_solution):
         vista_object_computed_topo = GemPyToVista(one_fault_model_topo_solution,
                                                   plotter_type='basic', off_screen=True)
 
         vista_object_computed_topo.plot_surface_points()
         vista_object_computed_topo.plot_surfaces()
         vista_object_computed_topo.plot_structured_grid('scalar',
                                                         series='Strat_Series',
                                                         render_topography=False)
         img = vista_object_computed_topo.p.show(screenshot=True)
+        img = vista_object_computed_topo.p.last_image
         plt.imshow(img[1])
         plt.show()
 
     def test_plot_several2(self, one_fault_model_topo_solution):
         vista_object_computed_topo = GemPyToVista(one_fault_model_topo_solution,
                                                   plotter_type='basic', off_screen=True)
 
         vista_object_computed_topo.plot_surface_points()
         vista_object_computed_topo.plot_surfaces()
         vista_object_computed_topo.plot_structured_grid(render_topography=False)
         img = vista_object_computed_topo.p.show(screenshot=True)
+        img = vista_object_computed_topo.p.last_image
         plt.imshow(img[1])
         plt.show()
 
     def test_plot_several3(self, one_fault_model_topo_solution):
         vista_object_computed_topo = GemPyToVista(one_fault_model_topo_solution,
                                                   plotter_type='basic', off_screen=True)
 
@@ -318,9 +335,10 @@
         vista_object_computed_topo.plot_surfaces()
         vista_object_computed_topo.plot_structured_grid(render_topography=True,
                                                         scalar_field='scalar',
                                                         series='Strat_Series',
                                                         )
         vista_object_computed_topo.plot_topography(scalars='topography')
         img = vista_object_computed_topo.p.show(screenshot=True)
+        img = vista_object_computed_topo.p.last_image
         plt.imshow(img[1])
         plt.show()
```

### Comparing `gempy-2.2b10.dev1/test/test_prob_modeling/TEST_pymc3.py` & `gempy-2.3.0/test/test_prob_modeling/TEST_pymc3.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,47 +1,49 @@
-import os
-import gempy as gp
-from gempy.bayesian.theano_op import GemPyThOp
-import pytest
-pm = pytest.importorskip("rgeomod")
-# import pymc3 as pm
-import arviz as az
-import numpy as np
-import matplotlib.pyplot as plt
-import theano
-np.random.seed(4003)
-
-
-def test_basic():
-    y_obs_list = [2.12, 2.06, 2.08, 2.05, 2.08, 2.09,
-                  2.19, 2.07, 2.16, 2.11, 2.13, 1.92]
-
-    with pm.Model() as model:
-        mu = pm.Normal('$\mu$', 2.08, .07)
-        sigma = pm.Gamma('$\sigma$', 0.3, 3)
-        y = pm.Normal('$y$', mu, sigma, observed=y_obs_list)
-
-        prior = pm.sample_prior_predictive(1000)
-        trace = pm.sample(1000, discard_tuned_samples=False, cores=1)
-        post = pm.sample_posterior_predictive(trace)
-
-    pm.plot_posterior(trace)
-    plt.show()
-
-
-def test_gempy_th_op_test():
-    path_dir = os.getcwd() + '/../../examples/tutorials/ch5_probabilistic_modeling'
-    geo_model = gp.load_model(r'2-layers', path=path_dir, recompile=False)
-    gto = GemPyThOp(geo_model)
-    sol = gto.test_gradient('lith', 'surface_points')
-    print(sol)
-
-
-def test_gempy_th_op_set_grav():
-    path_dir = os.getcwd() + '/../../examples/tutorials/ch5_probabilistic_modeling'
-    geo_model = gp.load_model(r'2-layers', path=path_dir, recompile=False)
-    gp.set_interpolator(geo_model, output='grav')
-
-    gto = GemPyThOp(geo_model)
-    th_op_grav = gto.set_th_op('gravity')
-    i = geo_model.interpolator.get_python_input_block()
-    th_f = theano.function([], th_op_grav(*i), on_unused_input='warn')
+import os
+import gempy as gp
+from gempy.bayesian.aesara_op import GemPyThOp
+import pytest
+pm = pytest.importorskip("rgeomod")
+# import pymc as pm
+import arviz as az
+import numpy as np
+import matplotlib as mpl
+mpl.use('Agg')
+import matplotlib.pyplot as plt
+import aesara
+np.random.seed(4003)
+
+
+def test_basic():
+    y_obs_list = [2.12, 2.06, 2.08, 2.05, 2.08, 2.09,
+                  2.19, 2.07, 2.16, 2.11, 2.13, 1.92]
+
+    with pm.Model() as model:
+        mu = pm.Normal('$\mu$', 2.08, .07)
+        sigma = pm.Gamma('$\sigma$', 0.3, 3)
+        y = pm.Normal('$y$', mu, sigma, observed=y_obs_list)
+
+        prior = pm.sample_prior_predictive(1000)
+        trace = pm.sample(1000, discard_tuned_samples=False, cores=1)
+        post = pm.sample_posterior_predictive(trace)
+
+    az.plot_posterior(trace)
+    plt.show()
+
+
+def test_gempy_th_op_test():
+    path_dir = os.getcwd() + '/../../examples/tutorials/ch5_probabilistic_modeling'
+    geo_model = gp.load_model(r'2-layers', path=path_dir, recompile=False)
+    gto = GemPyThOp(geo_model)
+    sol = gto.test_gradient('lith', 'surface_points')
+    print(sol)
+
+
+def test_gempy_th_op_set_grav():
+    path_dir = os.getcwd() + '/../../examples/tutorials/ch5_probabilistic_modeling'
+    geo_model = gp.load_model(r'2-layers', path=path_dir, recompile=False)
+    gp.set_interpolator(geo_model, output='grav')
+
+    gto = GemPyThOp(geo_model)
+    th_op_grav = gto.set_th_op('gravity')
+    i = geo_model.interpolator.get_python_input_block()
+    th_f = aesara.function([], th_op_grav(*i), on_unused_input='warn')
```

